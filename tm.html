<!DOCTYPE html>
<html lang="zh">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<title>CardMemo</title>
	<meta content="width=device-width,initial-scale=1,maximum-scale=1.0" name="viewport">
<style>
body{color:#111;background-color:#f4f4f4;font-family:Montserrat, sans-serif;}
h1{font-size:2em;background-color:#202020;color:#e7e7e7;margin:0;padding-top:0.5em;padding-left:0.5em;}
h2{font-size:1.5em;color:#037;padding-top:0.2em;margin:0.2em;}
h3{color:#409eff;}
p{font-size:1.2em;}
em{color:#00f;font-style:normal;}strong{color:#f00;font-style:normal;}
pre{white-space:pre-wrap;font-size:1.1em;}
code{background-color:#f1f1f1;font-size:1.1em;color:#d73737;}
pre code{display: block;border: 1px solid #cccccc;}
blockquote{border-left:5px solid #bbb;padding-left:0.5em;}
ul li{list-style:circle;}ol li{list-style:hiragana;}
table{border-collapse:collapse;border:1px solid;}th{border:1px solid;}td{border:1px solid;}
textarea{font-family:Montserrat, sans-serif;width:100%;height:80vh;font-size:1.1em}
article{background-color:hsl(60, 9%, 87%);max-width:80rem;margin:0 auto;padding:0 1rem;}
.card{opacity: 0.87;position: relative;max-width:80rem;margin:0 auto 8px;
box-shadow: 0 2px 2px 0 rgba(0, 0, 0, .14), 0 3px 1px -2px rgba(0, 0, 0, .2), 0 1px 5px 0 rgba(0, 0, 0, .12);
border-radius: 8px;background: white;}
div.card h1{font-size:1.8em;color:#026;background-color:#f0f0f0;}
.sec_pad{padding: 8px 12px;}
.art_pad{padding: 2px 12px;}
.kwd_pad{padding: 0px 12px;}
div.edit_zone{border: 4px solid blue;}
div.auto_high{position: relative;}
span.auto_high{display: block;white-space: pre-wrap;word-wrap: break-word;visibility: hidden;}
textarea.auto_high{position: absolute;top: 0;height: 100%;line-height: 20px;padding:0px 4px;box-sizing: border-box;}
div.sd_by_sd{flex:1;}
.prv_pad{padding-left:8px;}
span.kwd_em{color:red}
.footer{margin: 0 auto;text-align: center}
nav {background: #202020;max-width:80rem;padding:0 12px;margin:0 auto;display: flex;}
nav h1 {flex: 3;}
nav label {color: #fff;padding-top: 0.5em;}
.s_item{margin: 10px auto;text-decoration: underline;color: blue;}
@media screen and (max-width: 400px) { #kwd{width: 100px;} }
</style>
<script type="text/javascript">
!(function(top){ top.$tm||(top.$tm={})
var jctx=[];
function load_jctx(){
/*include_mds_start*/
jctx.push(JSON.parse('{"id": "140225", "tag": "lang", "text": "# 【译】Scheme的面向对象呈现（部分）\\n\\n## 关于Scheme的OO呈现。\\n\\n话题因为读者疑议而起，川合先亮出自己的观点，Scheme的OO呈现和别的语言并无太多不同，只是因为规范里没有定义，导致了多种不同的实现。如果采用CLOS的风格（他自己的Gauche就是），形式上就是（动词 名词）。这和很多OO语言采用名词.动词在语法顺序上是反的。但这不是更自然吗？川合先是吐槽，很多人认为名词 动词的方式更合理，只是他们早就习惯了这种方式，并没有真正去思考为什么。\\n\\n## 抽象的角度\\n\\n程序常说要抽象，是以对象还是函数来抽象？川合觉得如果以函数为抽象，将函数互相传递可以带来更丰富的表现力。\\n\\n以树的遍历为例子，如果是面向类的话，需要事先定义tree, leaf, node这些类。\\n\\n如果是函数导向，则将对树操作的函数是这个样子：\\n\\n```\\n(define (tree-walk tree proc leaf? walker)\\n    (define (rec node)\\n      (walker (lambda (n) (if (leaf? n) (proc n) (rec n))) node))\\n    (if (leaf? tree) (proc tree) (rec tree)))\\n```\\n\\nleaf?取树的节点，返回是不是叶子，walker是取得树节点的函数，对node所有子节点进行高阶函数调用的方法。如果树是用列表来表现，leaf?就是(lambda (x) (not (pair? x)))，walker就是for-each。树如果具现化为文件系统，leaf?就替换为file-is-directory?，walker就是(lambda (proc x) (for-each proc (list-directory x)))\\n\\n类指向的好处是，看到数据定义，可以知道要如何操作，但操作就必须要从具体的类或树开始继承（如果支持接口继承，会好一点）\\n\\n函数指向的好处是，在呈现概念时比较纯粹，对树可能的操作并不作限制，如果要让tree-walk运行起来，只要传入适当的leaf?和walker函数就可以。但是也存在可能需要传入的函数不止2、3个，可能会是5个甚至10个，如果看这10个函数，就很难发现tree-walk的本来用意了。\\n\\n## 实例解读\\n\\n看了翻译的文章，看个实际的Gauche-Scheme对象系统，它上承STklos，是从最早的TinyCLOS继承下来的概念，有三个最重要的概念\\n\\n* Class\\n* Generic Function\\n* Method\\n\\nCLOS系统中，Method并不属于特定的Class。通过define-method宏定义出来的变量，\\n是Generic Function的实例。\\n\\nGauche的write/display函数，面对一个复杂对象，会调用和这个对象有关的\\nwrite-object函数，通过它来呈现。类似Lua的`__tostring`或JavaScript的toString方法。"}'));jctx.push(JSON.parse('{"id": "140303", "tag": "security", "text": "# 精巧的安全和DH算法\\n\\n连续的每周六天上班着实太累，周日外面阳光明媚可却在家睡了一下午觉，到了晚上才缓过劲来。基本就在昏睡中度过一个周日。周末只有一天的感觉真是太不好了。\\n\\n一周的工作计划总是被意外的紧急情况打断，这周是安全问题。以前总是看到××公司安全意识薄弱，今天算是到自家头上了，由于协议久远，从现在看来几乎是弱智般的加密防范，也许那个时代根本不知安全为何物吧。从去年年中开始不停地爆出安全漏洞，今次又发现一个问题。因为这次的问题加上上周刚做的加密方案，把以前模糊不清的各种加密原理重新梳理一遍，不需要明白算法，至少对称非对称和信息摘要的应用场合，以及如何组合这些算法达到安全加密的过程，有了个完整的概念。回过头去看，就发现加密算法的精巧。就算知道了加密流程和算法，但设计完整的流程就是能让人徒呼奈何。\\n\\n因为工作太多，自己的学习也被耽搁了。写了小段Scheme代码，但解释器不给力，报了变量未定义错误，却不知道究竟是哪一行的变量，而Scheme的移植性又相当差，稍微有用点的函数都是与实现相关，换个解释器还不知道要修改多少代码。看来以后还是要用Racket，其他的实现都不够完整。用Emacs写代码暂时还没发现特别的好处，一切都可以定制的特性让它成为神的编辑器，可是对不熟悉的人来说实在太难用，我还算是对Lisp比较了解的，用到今天才明白它的设计思路和好处，但真正掌握还需要慢慢熟练，就如这篇教程说的，花一年时间，并且做到理解而不是判断。\\n\\n在不安全的信道建立加密会话，又叫密钥协商，RSA是密钥传输算法，但它完全由客户端决定密钥，严格得说不算协商，只有Diffie–Hellman，简称DH算法是真正的协商，它基于离散对数，A准备a,g,p三个数，B准备b。其中g取2或5，a,b,p则是非常大的质数。p至少1024位，相当于300多位的十进制数。\\n\\n```\\nAlice --- g, p , (g^a) % p, 正文用A表示 --> Bob\\nAlice <--   (g^b) % p, 下文用B表示      --- Bob\\n```\\n\\n也有些文章把A和a称为Alice的DH公私钥，B和b称为Bob的DH公私钥。通过以上交互，Alice和Bob分别计算 (B^a) % p = (A^b) % p = K，接着K就可以用于对称加密的密钥。\\n\\n以上算法解决保密，认证还是要依赖PKI或其它方式。\\n\\nDH算法又细分静态DH和临时DH(EDH)两种，静态的p是不变的，保存在硬盘上，固然节约了计算开销，但和RSA一样都不能实现前向安全，只有临时DH才满足前向安全。DH的生成步骤比RSA要多一步，先生成参数（上文提到的p），再根据参数文件生成DH公私钥对。对应的openssl命令分别是dhparam和genpkey。\\n\\n除了离散对数，也可以用椭圆曲线实现，ECDH。但是从量子计算角度看，椭圆曲线弱于离散对数，考虑到量子计算还不成熟，ECDH还是被广泛接受的。"}'));jctx.push(JSON.parse('{"id": "140307", "tag": "net", "text": "# UDP广播多播和IPv6记要\\n\\n## 广播与多播\\n\\nUDP的socket才有的特性，其中广播是socket级的特性，需要setsockopt时指定SO_BROADCAST选项，而多播是IP级的，比如加入一个多播组，用的是`IP_ADD_MEMBERSHIP`和`IP_DROP_MEMBERSHIP`。\\n\\n为什么一个是IP级，另一个是socket级，大概是因为广播包一定会通过IP层，直到UDP层才会做处理，因此用SO前缀；而多播地址是D类网段，加入多播组时，网卡会知道，会在网卡级收到消息时就过滤，连驱动层都不能到，更别说UDP层了，所以用了IP为前缀的选项。\\n\\n广播时socket如果要接收，要先将自己绑定到INADDR_ANY和广播的端口，一旦感知到消息再通过recvfrom从`INADDR_BROADCAST`的相同端口接受数据。发送则不需要绑定，直接sendto到`INADDR_BROADCAST`的约定端口就可以了。广播的接收与发送因为地址只有一个`IPADDR_BROADCAST`，所以只能靠端口区分，接收端也必须作一次bind。\\n\\n多播是与地址相关，只要bind地址就可以了，和端口关系不大，之所以现在的代码都要绑定地址和端口，是因为历史上Solaris对多播要求必须做端口的绑定，所以后来的代码出于跨平台的考虑，都加入了端口绑定。\\n\\n加入多播组有三个选择，IP_ADD_MEMBERSHIP，`IPV6_JOIN_GROUP`和`MCAST_JOIN_GROUP`。前两个是与IP协议版本相关，不能混用，而MCAST是协议无关，使用的地址结构体也要大得多，至于功能是一样的。\\n\\n## IPv6\\n\\n源和目的地址从32位扩大到128位，分为高低两个64位，高位表示网络类型(单播/组播/任播)、子网标识，低64位则表示网卡地址，可以由MAC地址计算。加上其它的控制标志，IPv6的报头从20字节扩大到40字节。\\n\\nMAC地址48位同样分为上下两个24位，高24位是厂商标识，低24位则是网卡标识。从最高位开始数的第7、8位有特殊的含义，第7位如果是0表示IEEE分配，如果是1则表示本地分配。没见过是1的，第8位是0表示单播MAC，1表示组播MAC。当发送广播包时，会在发送前把MAC地址的第8位改成1，静态情况下通过ifconfig无法看出来，只有运行期抓包才能发现。由于第7和8都是0，所以正常12数字的MAC地址的第2个数字一定0bXX00即4的倍数。\\n\\nIPv6的socket默认可以接收IPv4的连接请求，除非显示打开`IPV6_V6ONLY`选项。所以如果用netstat看到只监听v6端口，不妨先尝试v4的连接。"}'));jctx.push(JSON.parse('{"id": "140313", "tag": "lang", "text": "# 数字的精确与不精确\\n\\n很久不写Scheme，写了个判断质数的函数却永远返回成功，看代码逻辑看不出问题，于是只能一个个函数去试验，好在Scheme交互式写法很容易就能逐个函数地检查问题。终于发现问题出在数字运算的精度上。\\n\\n简单的质数判断逻辑是从2开始，直到这个数的平方根为止挨个去试，如果有一个能被整除，就不是质数；反之就是。但取余是个整数运算，而平方根的结果就算做了取整依然是浮点数，于是用浮点数对整数取余的结果，哪怕它实际上是0，但反应在浮点数里却可能是37e-52这种结果，而这和0是不相等的，导致每次计算的判断都为假，最后这个数就被作为一个质数报上来了。原因找到后，只要在开平方取整后，再做个inexact->exact的操作就可以把浮点变成等值的整数。计算结果也就正常了。\\n\\n出这个错的原因，一方面因为Scheme是弱类型语言，而在强类型语言里浮点和整形计算是要做区分的，像C会报类型不匹配警告，而ML则干脆就区分了整形和浮点数的运算符，但Scheme是在运行时悄悄地执行，也不报错。难怪历史上总有弱类型语言容易出错的报怨，大家也都是一路吃着苦头过来的。另一方面在RnRS里有一个完整的章节就用来描述数字的概念及相应的操作，以前看的时候不明白为什么要花费这么多笔墨描述数字的概念，以及那一族奇怪的exact?,inexact?inexact->exact，这回算是彻底明白了。正因为Scheme弱类型的特点，需要人为地判定并做显示的数字类型转换，才能得出正确的计算结果。\\n\\n说个C语言的浮点数处理，float/double是可以memset的，结果就是0.000000。估计也是为了兼容吧。"}'));jctx.push(JSON.parse('{"id": "140523", "tag": "protocol", "text": "# UTF8编码规范小记\\n\\n看了Lua5.3的work2代码，从简单但个人觉得最常用的UTF8库看起，通过代码很快就明白UTF8的规则。\\n\\n以前看中文UTF8编码，总是奇怪为什么一定是0xEx打头的三个字节，比如“中国”这两个字的编码分别是：E4 B8 AD和E5 9B BD。如今明白UTF8的解析规则，这一切就很好理解了。说句题外话，Unicode的当前最大值范围是0x10FFFFFF(17个位面)，共有21字节，short类型表示不下。\\n\\n首先UTF8是照顾ASCII编码的，毕竟人家是老前辈了，所以第一个字节在0x80以下，UTF8的解析规则就直接结束。如果是大于等于0x80，则最高位1后的1的个数表示后面还跟着几个字节，这些跟在首字节后的字节数据，术语称为continuation byte。因此欧洲编码占用两个字节，则首字节一定是0xCx(110x xxxx)，而CJK的编码占用三个字节，首字节必然是0xEx(即1110 xxxx)。如果不符合此规则，则为非法。\\n\\n首字节的规则看完了，接下来说continuation byte的约束，代码是这样写的：\\n```\\nif ((cc & 0xC0) != 0x80)  /* not a continuation byte? */\\n        return NULL;\\n```\\n也就是说，continuation byte的值范围一定是在0x8*~0xB*之间(必须是10** ****)。由于continuation byte的范围被限定了，能表达的有效位数只有6位，每个字节的低6bit被按序组装成完整的值，就可以得到对应的Unicode值了。\\n\\n附更全的考古\\n\\nRob Pike 在 2003 发的邮件，讨论的是 UTF-8 编码诞生之初的故事。Rob 和 Ken 是 UTF-8 的共同发明人。读罢不仅深化了对 UTF-8 编码的理解，更为大师们的智慧所折服。现在整理成文分享给大家。\\n\\n故事是从 Plan 9 操作系统开始的。为了让 Plan 9 支持 Unicode (ISO 10646)，Rob 和 Ken 选用了 UCS 编码（标准制定的 16 位编码方案，后来扩展成了 UTF-16）。虽然使用了 UCS 编码，但对 USC 编码并不满意，原文是 but we hated it。当整个工作几近完成的时候（大约在 1992 年的九月份），X/Open 组织有人给他们打电话，让 Rob 和 Ken 投票支持所谓的 FSS/UTF 编码方案。Rob 和 Ken 提出要根据自己的经验设计一个更好的编码方案。X/Open 的人接受了这个提议，但要求尽快提交方案。吃晚饭的时候，Ken 在餐桌上就完成了编码规则的设计。回到实验室，他们给 X/Open 发邮件说明了新编码的设计大纲。X/Open 的人则回复说 Rob 和 Ken 的方案比他们自己方案更好，并且询问什么时候能实现这一编码。当天是周三，Rob 以为 X/Open 会在下周一开始投票，所以就保证说下周一给出完整实现。\\n\\nRob 和 Ken 当晚就开始编码，Ken 负责实现 UTF-8 编解码逻辑，Rob 负责改造现有的 c 库和图形库。到了第二天，编码工作就已完成，俩个人开始使用新编码对 Plan 9 上的文本文件进行转码。到周五，Plan 9 系统完全基于新编码运行了。Rob 和 Ken 称这种新的编码为 UTF-8。然后，UTF-8 改变了历史。\\n\\n根据 Google 2012 年的统计，当年 web 领域 UTF-8 编码的占比就已经超过了 60%。\\n\\n可是，Rob 和 Ken 为什么没有采用 X/Open 的编码方案呢？Rob 指出 X/Open 的编码方案和当时的好多编码一样，没有自同步这一特性，所以他们提出了 UTF-8 方案。我们会在下文解释这个自同步特性。\\n\\n为了把事情说清楚，Rob 联系 Russ Cox 查询当年的来往邮件。然后 Russ 真的找到了相关邮件，甚至还给出了 1992 年的邮件发送记录！邮件记录了 UTF-8 最早的设计方案。\\n\\nFSS/UTF 编码全称是 File System Safe Universal Character Set Transformation Format。为什么要考虑这个文件系统安全呢？因为在 unicode 出现之前，计算机普遍使用 ASCII 编码。UNIX 的文件系统使用 /，也就是 0x2f，作为路径分隔标志。另一方面，c 语言使用 0x00 表示字符串的结尾。而 ISO/IEC 10646 (Unicode) 制定 UCS-2 编码使用双字节编码，最多支持表示 65535 个字符（code point）。UCS-2 编码一定会出现某个字符编码包含 0x2f 或 0x00 情况。例如，「⼀」的 UCS-2 编码是 0x2f00，同时包含了 0x2f 和 0x00。UNIX 系统和 c 语言基本没法处理使用 UCS-2 编码的数据。如果非要使用 UCS-2 编码，那就只有一个办法——将老数据使用 UCS-2 转码。这显然不现实。\\n\\n所以 Rob 和 Ken 给新编码制定了几条指导原则：\\n\\n兼容历史文件系统，文件名不能包含 0x2f 和 0x00\\n兼容现有程序，非 ASCII 字符编码不能部分包含 ASCII 编码\\n与 UCS 编码转换要简单\\n首字节需要指明后续字节长度\\n编码格式不要浪费空间\\n自同步\\n前两条讲得是一个事情。ASCII 编码范围是 0x00-0x7f，新编码方案中非 ASCII 字符的编码序列不能包含 0x00-0x7f 范围的内容，不然现有的系统和程序会把这部分内容当成 ASCII 处理而导致混乱。\\n\\n第六条说的是错误恢复。简单来说，程序从文件的任意部分开始读取，可能只读到一个字符的部分编码字节，从而无法实别这一字符。但没关系，编码方案需要支持程序快速跳过有问题的字节，然后正常解码。\\n\\n这六条原则一言一蔽之，多快好省。\\n\\n最终的编码方案使用变长字节编码，不同范围的字符使用不同长度的字节编码，最多使用 6 个字节，可表示范围为 [0,0x7fffffff]。\\n\\n其中，ASCII 字符 [0x00-0x7f] 的编码方式与现有 ASCII 编码保持一致，已有的 ASCII 编码无需做任何改动。其他字符使用多字节编码。\\n\\n为了实现第一条和第二条原则，多字节编码的每个字节的最高位永远是 1，而 ASCII 字符编码的最高位是 0，所以从根本上杜绝了编码冲突。\\n\\n为了实现第四条原则，多字节编码以 11{1,5}0 开头。1 和 0 之间 1 的数量表示后续字节的长度（这里借用了正则的表示方式）。\\n\\n为了实现第五条原则，编码规定，如果一个字符的编码可以有多种表示方式，则选用最短的表示。\\n\\n为了实现第六条原则，编码序列的后续字节都是以 10 开头的。如果程序读到了受损的文件，只能有三种情况：1、当前字节最高位是 0，则是合法 ASCII 字符；2、当前最高两位是 11，则是合法的多字节编码；3、当前字节最高两位是 10，则是其他字符编码的一部分，跳过，直到读到最高位为 0 或最高两位为 11 为止。\\n\\n举个例子，汉字「吕」的 Unicde 编码是 U+5415，对应二进制为 0b0101010000010101，需要 15 bit，所以使用三字节编码，对应二进制拆成（从低位到高位）三部分，分别是 0b0101, 010000, 0b010101，再拼上编码前缀得到 0b11100101, 0b10010000, 0b10010101，对应十六进制为 0xe5, 0x90, 0x95。所以汉字「吕」的 UTF-8 编码是 0xe59095。\\n\\n完整的编码规则如下表：\\n\\nBits  Hex Min  Hex Max  Byte Sequence in Binary\\n1    7  00000000 0000007f 0vvvvvvv\\n2   11  00000080 000007FF 110vvvvv 10vvvvvv\\n3   16  00000800 0000FFFF 1110vvvv 10vvvvvv 10vvvvvv\\n4   21  00010000 001FFFFF 11110vvv 10vvvvvv 10vvvvvv 10vvvvvv\\n5   26  00200000 03FFFFFF 111110vv 10vvvvvv 10vvvvvv 10vvvvvv 10vvvvvv\\n6   31  04000000 7FFFFFFF 1111110v 10vvvvvv 10vvvvvv 10vvvvvv 10vvvvvv 10vvvvvv\\n最终 ISO 标准化的 FSS/UTF 编码方案可以从这里获取。\\n\\nIETF 也制定了 RFC3629 对 UTF-8 做了进一步标准化。RFC3629 制定的版本将 UTF-8 的表示范围限制在了 [0-10FFFF]，所以只需要 4 个字节就够了。标准原文\\n\\nRestricted the range of characters to 0000-10FFFF (the UTF-16 accessible range)\\n如果大家对这个问题感兴趣，可以参考 Stijn de Witt 的这篇文章。此处就不展开讨论了。"}'));jctx.push(JSON.parse('{"id": "140712", "tag": "design", "text": "# 功能重用与接口设计\\n\\n最近在做内部的维基网站，内容是从Word文档解析然后以页面形式呈现。Word可以导出Html，解析也就是针对Html的标签做些过滤并对需要的内容做分类提取。第一期的工作，原有的协议内容绝大多数是一份表格为一个请求/应答，由于表格和章节号都是一一对应关系，即一个标题下也只会有一张张表，解析的时候，就以表结束作为时机，在此时刻插入数据库。这种做法其实是比较死板的，只适合于这一类文档，当出现一个标题下有多张表格，或是除表格外有文字甚至图片时，就难以处理。虽然这类文档都以网页形式呈现，但其中少量的图片，除非对原有解析代码做伤筋动骨的改动，修改起来是十分困难的。\\n\\n第二期开始的文档，格式就变得多变了。这时我才意识到，只有以章节标题来划分，才是比较通用的做法。并需要对章节内的信息作归类，把标题下的内容按类别加入数据库，这样才更符合日常的整理思维。\\n\\n虽然第一期作了很多解析功能，函数却不容易被复用，由于接口的注释不明，或是对入参有些隐含的期望，在第二期的工作时，很多函数看起来能用，却忘记了原先的期望，得到的结果自然也就不正确了。这和我虽然计划要做单元测试，却没有真正去实现也有关系。好在函数本身还是可重入的，补上测试用例，单个都可测，测完补上注释就好。回想起来，接口文档里除了描述接口功能，对出入参的描述也是非常重要的。像Python或者Common Lisp都有函数功能描述的专门语法，是个很好的语言设计。\\n\\n对于表格的解析，一期的文档是按列解析，而二期的文档由于关联性不强，按行比较方便。按最小功能划分，把功能细分成每个单元格才是最通用的设计。这个编译原理中视单元格为词法，将词法按需要的语法规则拼装是一个道理。\\n"}'));jctx.push(JSON.parse('{"id": "141002", "tag": "lang", "text": "# setjmp的机制及lua中的异常\\n\\nsetjmp/longjmp是C标准的函数，常用的做法是用来实现异常/跳转。原型如下：\\n\\n* int setjmp(jmp_buf env);\\n* int longjmp(jmp_buf env, int err);\\n\\n这组函数依赖于`jmp_buf`的变量类型，从接口声明看，\\n`jmp_buf`是值类型的，但每次调用setjmp都会把当前的各个寄存器值包括PC保存起来，\\n供以后longjmp来恢复，所以这个`jmp_buf`一定是指针语义的。\\n看了GCC 3.4.5的定义，将宏简化之后就是 typedef int `jmp_buf`[16];\\n也就是说`jmp_buf`类型其实是个数组，而数组在传参时又是作为指针来处理，\\n所以setjmp能改变`jmp_buf`所对应的值，之后的longjmp才能恢复回来。\\n实测在32位的XP系统上，只用了0~6共7个值，其余都是置0。\\n\\n如果没有setjmp就直接longjmp，因为PC值和各种寄存器值一定是乱的，\\n必然导致系统崩溃。调试模式下是ntdll下抛异常。\\n而每一次的setjmp都将当前状态写入到jmp_buf中并返回0，\\n因此多次调用setjmp以后，longjmp会回到最后一次setjmp的地方。\\n\\n再说说setjmp在lua中的应用。\\n\\nlua在内部执行操作时，大都是调用luaD\\\\_pcall，\\n这内部调用到了luaD\\\\_rawrunprotected，在内部会进入LUAI\\\\_TRY这个宏。\\n如果用C++编译，这个宏就被展开成try{}块；如果是C，\\n这个宏就被展开成if (setjmp() == 0) {action}这样的形式。\\njmp\\\\_buf的值会随着L带到action中，一旦发生无法补救的错误，\\n就会通过luaD\\\\_throw函数，在判断了存在jmp\\\\_buf后，\\n再调用LUAI\\\\_THROW宏，实质就是longjmp的形式直接返回。\\n由于先判断了L中是否有jum\\\\_buf，也就不会有异常的死机问题。\\n\\nLua的语法层面并不支持try/catch/throw这种显式的异常处理方式，\\n但是做一些不符合规定的操作，比如数字加nil，\\n字符串和nil拼接等等动作，Lua会执行出错，\\n如果不是在pcall内执行，导致程序提前终止，\\n这其实就是一种变相的固定类型的异常，\\n只是自定义异常类这块功能没有开放罢了。\\n\\n只有系统自带的操作，在执行非法时抛出个可捕获的异常，\\n用pcall/xpcall来模拟try/catch，而用类似`1+nil`的方式模拟throw。\\n要想程序能够跑完，就要时刻注意用pcall的方式把函数执行做个封装，\\n而如果想提前终止，也可以用故意写非法语句来达到类似的效果。\\n但是写的非法语句毕竟不能携带自定义信息，只能靠代码行号来反推，\\n效果上就差强人意了。\\n\\n"}'));jctx.push(JSON.parse('{"id": "150329", "tag": "lang", "text": "# Lua的编译期和运行期区分\\n\\n虽然是一门解释型语言，但Lua其实也分了编译期和运行期，只是通常在lua的程序里顺带把luac的功能给自动执行了。但作为一个运行效率为第一位的语言，编译期更多的意义在于把源码转译为伪字节码，不会作过多语义上的校验。比如下面这个例子。\\n\\nfunction a:foo()  print(\\"hello\\") end\\n\\n如果直接用lua运行，会报attempt to index global \'a\'(a nil value)，但实际上在编译期，这仍然是可以通过的。\\n\\n如果用luac先执行，会得到两个chunk，一个是main，一个是函数定义。main中有四条语句：\\n\\nGETGLOBAL    CLOSURE   SETTABLE  RETURN\\n\\n前两句是可以顺利执行的，a虽然不存在，会默认赋值nil。但到SETTABLE时，这个nil就原型毕露了。也就对应上面运行时那句attempt to报错。\\n\\n也就是说luac只能做到语法层面的校验，但基于性能的考虑，不会做语义层面的判断(如果要做的话，代码量可就不止当前的2万行了)。\\n\\n说下MetaLua对编译的作法，在编译理论里，parse和compile是两个阶段，source经过parse只能生成AST，再把AST送compile才能生成执行码(可以是机器指令或VM指令)。YACC也好ANTLR也好，都只是parse工具。Lisp语法就直接是AST了所以不需要parse但还是要有compile。由于有两个阶段，MetaLua也提供了mlp和mlc两个工具对应。非Lisp风格的编程语言如果要扩展，多少都要在parse阶段做些处理，典型如增加关键字，就在parse阶段把新增的关键字转译成AST里的function，才能在compile后正常执行。\\n\\n因为MetaLua的存在，将源程序先编译成luac再执行就能看出明显的区别，compile阶段的操作可以在编译成luac时很直观地看出来，且不会带到执行期。\\n\\n最后补充几个Lua的语法细节\\n\\nLua的函数到底是传值还是传引用？这是我从王垠的\\n[这篇文章](http://www.yinwang.org/blog-cn/2016/06/08/java-value-type)\\n想到的。\\n\\n上面这篇文章的结论是Java从语义层面，只有引用类型。原生类型看起来像值类型，\\n只是一种实现的优化。既然Lua也是从Lisp/Scheme系继承而来，\\n就做个实验验证下，到底Lua是否符合王垠所定义的引用类型。\\n\\n字符串拼接如果报nil错误，假如有多个nil只会提示最后一个错误，不确定是否lua编译器按从右向左计算参数的方式？"}'));jctx.push(JSON.parse('{"id": "150616", "tag": "lang", "text": "# 函数参数的传值与传引用及语义\\n\\n一年前因为工作上的需要，把一些文档在Apache上以网页的形式呈现出来，当时为赶着快速上线，就边学PHP边对着HTML语法，用最原始的方式把网站给搭出来了，做完后又忙着其它事，网站就放着没去优化它。\\n\\n最近偶然看网页时，看到有文章提到PHP的函数是显式区分传值和传引用的，如果不在参数前加上&，就按传值调用。可怜我之前一直以为PHP和Java一样，是自动根据类型做判断，复杂对象类型自动转引用的。结果回头再看代码，大量的数据库中查找出来的记录，在传参时都把array以值的方式复制了一遍再做处理。因为流程是单向的，数据库中取到的数据也就是在网页上展现一下，当时能看到效果就没去深究，才导致这个问题一直过了一年才发现。\\n\\n今天和大牛聊起这个事情，大牛说学任何语言，第一步就是要搞明白函数的传递模型。在任何语言中，函数都是最基本的抽象单元，一门语言可以没有类，可以没有原生Hash，但一定会有函数。而函数的边界，也基本就是语言的边界了。比如是传值还是传引用，静态词法定界还是动态词法定界，函数是否可匿名等。\\n\\n简单地记一下，C/C++，PHP默认是传值调用，可以用&显示指定传引用调用。\\n\\nLua，Python的函数定义中参数没有修饰符，也没有提领提作，因此语法上没有传值还是传引用的区分。数字和字符串出于实现的方便，会被inline，表现出的行为类似传值调用，复杂类型如Lua的table，Python的List、Dict的行为类似传引用。\\n\\n除函数之外，像foreach的循环，PHP也是可以使用引用的。比如\\n\\n$vec1  = array([1, 2], [3, 4], [5, 6]);// 此处语法不正确的，只为示例二维数组\\n\\nforeach ($vec1 as $r) {$r}这里的$r也是值，即使它指向的是个数组，但仍然是复制了一份，不能修改。如果想显示地表示引用，需要写成foreach($vec1 as &$r)。而像这种for循环，在Lua里如果值是简单的数字/字符串，是值类型，如果是复杂结构，就是个引用，可以修改原始值。\\n\\n以我所知的语言像Java，Ruby，JavaScript都不提供语法级的值和引用区分，当然像Perl这种词法超级复杂的语言是支持通过\'\\\\\'显示引用的。\\n\\n追记：在读R5RS的1.1语义节看到这么一句，Scheme过程的参数总以值的方式传递，即无论过程是否需要实参的值，实参表达式都会在过程获得控制权之前被求值。ML、C和APL是另外三种总以值的方式传递参数的语言。也就是说从Scheme的层面来看，不论是传值还是传引用，由于都是eager eval，都算是Call-by-Value，至于传的是值是引用，都是要计算的。这与Haskell语言懒惰求值(Lazy-evaluation)的语义，或Algol 60语言按名调用(Call-by-name)的语义截然不同。在Haskell和Algol 60的这两种语义中，直到过程需要实参表达式的值时，才会对它们求值。为什么Scheme中不区分传引用和传值呢？一来因为函数式语义，根本就不赞成传引用这种会改变参数的行为，在那里变量只有在返回时才允许被改变，另外Scheme也多少有点脱离实际机器，更偏向于理论研究的语言，那么为了提高速度而只传一个const&的方式，在它的语言规范里也被认为不是必须的，所以没有被记录。因此在Scheme看来，这些过程式语言中传值与传引用的区别，那都不是事，究竟是Call-by-Value还是Call-by-Name才是它真正要关心的语义。\\n\\n学一门语言，最重要的是学idiom，而最基础的，则是理解函数的行为，是为记。\\n"}'));jctx.push(JSON.parse('{"id": "150628", "tag": "lang", "text": "# lua闭包和其他语言比较以及修改upvalue\\n\\n## 闭包能力比较\\n\\n构建闭包的特殊性在于捕获非本地的栈上变量，如果是访问全局变量，不能称为闭包。最早明确这个特性的大约是scheme吧，lua和js也照样实现。而python则用nonlocal关键字更加显示地表明要捕获上级栈的变量，但同时又不能是global，所以看似怪异，细想倒也有几分道理。\\n\\n```\\ndef foo():\\n    conf = 555  #  newclo捕获这个变量稀松平常，都能做到\\n    def newclo():\\n        nonlocal conf\\n        print(conf)\\n\\ndef main():\\n    conf = 111  # 起初以为即使foo中不定义conf，lua和js能捕获这个定义，但python和scheme不行，实际是lua和js把变量提升为全局变量，能引用但已不是闭包了\\n    foo()\\n```\\n\\n## 修改闭包自由变量\\n\\nlua闭包中引用的upvalue类似于面向对象中实例的私有成员，是不应该被外界修改的，或者说外界也感知不到这个存在。今天看lua的手册，debug库中存在getupvalue/setupvalue函数对，利用这两个函数可以获取/修改upvalue。这两个函数访问upvalue的方式是用一个int类型的index编号，而文档对这个编号的含义也不作保证，所以这个功能放在debug库也算合理吧。\\n\\n首先对闭包来说，upvalue是什么时候创建的呢？是在lparser.c中由解析过程创建的，当解析器每识别一个变量，如果这个变量在函数栈上未定义，则会逐级地往上找直到找到为止，之后就在函数的proto中增加一个upvalue。因为每个闭包都含有独立的upvalue列表，所以upvalue必然是词法定界的。\\n\\n虽然文档说index的含义是随意的，但通过代码还是可以知道，就是upvalue在函数中被最先引用的顺序。如果一个函数定义如下：\\n\\n```\\nlocal function foo()\\n  local b = 2\\n  local a = 1\\n  return function () print(a) b = b+1 end\\nend\\n```\\n\\n内部返回函数先调用了print(a)，print在栈上未定义，则它就是第一个upvalue，又因为print是定义在顶级函数的`_ENV`变量中，所以这个函数的第一个upvalue就是_ENV，第二个自然是a，第三个是b。这个a、b的定义顺序无关。另外由于`_ENV`是在lua5.2后引入的定义，在lua5.1中的话，1就指a，而2是b。也就是说这个功能是版本不兼容的。不过本来lua的兼容性就不是完美向后，且这个又是个debug函数，考虑到引入`_ENV`后的概念统一性，这个变动还是值得的。\\n\\n至于在其它语言中是否存在修改upvalue的机制，暂时还没有找到，等找到了再补上。\\n"}'));jctx.push(JSON.parse('{"id": "150719", "tag": "os", "text": "# 在CentOS和FreeBSD上安装OpenResty的一些记录\\n\\n花了两个周末的时间，分别在CentOS6.6和FreeBSD10.1上安装并跑起了OpenResty，虽说没什么技术难度，但有些遇到的问题还是记录一下，方便以后查找。\\n\\n一开始我是想在cygwin上编译，但是卡在MAP_BIT32宏上过不去，想想cygwin毕竟只够练手，真正的编译还得用正牌的系统，就装上了VMWare9，上真正的OS。\\n\\n先说CentOS，这个问题比较少，因为我的硬盘和内存都不足，所以下的是CentOS6.6的minimal版，默认的安装包非常少，像GCC、Perl、OpenSSL都没有，好在yum非常成熟，这些很快就装好了。但有两个问题要说一下：\\n\\n1.安装完系统，没有eth网卡，通过ifconfig只能看到lo，不知道为什么采用这么谨慎的策略。简单地话通过ifup eth0就行了，但关机就不行了，还是得改/etc/sysconfig/network-script/ifcfg-eth0，把ONBOOT=yes写上，这样从windows才能访问虚拟机。\\n\\n2.编译和安装其实问题都不大，一把直接过，但nginx启动后，windows下却怎么也连不上，始终报超时。netstat看到端口是开放的，ssh也能用啊。这个问题想了一个多小时，改nginx配置不少于10次始终无果，最后终于有网上文章说是防火墙作祟，最后chkconfig iptables off一把，问题解决。今天再看，发现CentOS默认是打开SELinux的，也许这就是原因吧，SELinux还没细研究，总之能用就算OK了。\\n\\n再说FreeBSD，这个问题就麻烦多了，由于文档少，国内用得人不多，理解它的ports系统就花了很久。我以10这个版本说说：\\n\\nports是以源代码编译为导向的软件包机制，又名ports collection，这是BSD家族的正牌安装方式，默认安装时如果没有装，需要通过portsnap工具先生成目录结构。原理就是在/usr/ports/下生成一个巨大的目录树，其中的顶级的Makefile和README等文件，各种软件又按类别放在子目录下，比如devel/、www/等等。因为顶级有Makefile，所以可以在/usr/ports目录下通过make执行查找，（其实用whereis命令更简单）。要安装时，再进到具体的目录，通过make install方式就自动编译装好了，在这个目录的Makefile会记录源代码的下载地址、编译选项等等。默认不需要configure，这点比较方便。ports也是需要更新的repository，更新工具就是portsnap fetch命令。第一次要执行portsnap extract，但这个操作非常耗时，执行一次以后就不要再执行了。下载后的repository保存在/var/db/portsnap/目录下，都是分散的文件，我目前的版本有大概2万5千个文件。\\n\\n但每次都要自己编译未免太费时间，于是就有了直接下载编译好的文件方式，这就是pkg。在版本10以前，是pkg_***工具集，到10之后，统一成pkg一个命令。所以官方对pkg的命名是pkgng以示区别。在执行之间一样要先下载repository，使用pkg update命令。但默认的repository用的美西服务器，速度太慢，始终只有10k，导致update一直无法完成，好像是FreeBSD不同意其它网站同步源，国内源很少，也许根本没有。只能在pkg.freebsd.org上找，最后尝试了pkg0.ydx.freebsd.org后，速度终于上到20～30k，总算完成了pkg update。和ports不一样，pkg方式是保存在/var/db/pkg/repo.sqlite文件里，就是个sqlite3的文件，里面记录了2万5千个软件的地址、描述信息等。除了ydx源，2017年6月又发现了几个新源：\\n\\n* pkg0.bme.freebsd.org\\n* pkg0.nyi.freebsd.org\\n* pkg0.isc.freebsd.org\\n* pkg1.chinafreebsd.cn\\n\\nupdate完成后，后面的安装软件就顺利了，把OpenResty依赖的包装上，需要注意的是，OpenResty是用gmake编译的，在Linux下，就等同于make，但FreeBSD的make却不同于gmake，所以还要另外再安装gmake。我自己也手欠，装了个gmake-lite，真搞不懂make这么个小玩意还有lite版。结果还是报错，于是又对gmake-lite做了个软链接生成gmake，接下来的编译都很顺利了。编译并安装后，从windows访问也没有问题。\\n\\n不管CentOS和FreeBSD，编译都不是问题，说明OpenResty的软件包做得很好，主要还是对系统的配置等外围工作花费时间。"}'));jctx.push(JSON.parse('{"id": "150725", "tag": "think", "text": "# 信息的价值与一篇机器学习文章读后感\\n\\n当媒体说互联网带来了知识的普及，这句话并没有全部说对。我一直就疑惑，\\n虽然互联网上看似能搜索到很多东西，但是有两个问题：\\n\\n1. 信息是谁放上去的，他出于什么样的利益放到网上？\\n2. 谁让你看到这些放上去的信息，你又怎么知道你看到的信息，就是全部的信息？\\n\\n先说1，在互联网出现以前，我们获取知识的途径可以买书，也可以去图书馆，\\n但是不管怎么样，一定要有人来出版书。互联网的出现，\\n简化的只是出版一篇文章的成本（注意是文章，而不是书）。\\n你可能会问，为什么我能从网上搜索到这么多资料？早期借着互联网的东风，\\n很多人无偿地贡献着各种次数，或者有人在blog上发表文章。这些行为的背后，\\n一定是有背后的利益驱动。对于真正有价值的内容，往往由于利益无法匹配，\\n不可能出现在网络上。也就是你能看到的内容，往往是他人不在意的内容。\\n\\n再说2，回忆一下你是怎么找到内容的？最常见的就是通过搜索引擎，\\n但是搜索引擎的算法不是使用者能够控制的，这也正是百度的信用日下，\\n而内容无法保证的原因。\\n\\ntinyfool的一篇文章，提到机器学习就是对人脑的一种模仿，那么反过来这种模仿也是对我们理解大脑的一种方式。\\n\\n机器学习最常见的理论是：模型+数据，看书看报，好一点的是可以拿到新的、有价值的数据，而更好的则是了解一种新的模型。 数据要经过梳理，并和模型结合，才真正被机器所用，我们也一样。好比学英语，背单词只是数据，只有结合语法语境，才不会出现一篇文章，所有单词都认识，但就是看不懂的情况。\\n\\n编程亦然，我学lua快9年了，却一直没有输入高质量的数据，没有看过好的代码，manual看了一遍又一遍，却总感觉雾里看花。最近因为想把一个web服务从apache+php切到异步模型，找到了alilua这个项目，突然觉得以前没有接触过的方面好多，甚至连lua_thread都刚看到该怎么用。如果我只看手册，再学10年我也不会明白coroutine的价值。 同样的，看异步网络编程的书，提到2.6.28内核开始提供的accept4调用，只有当我结合代码和实际的需求，我才真正理解它的价值。\\n\\n学习的意义，在于把接触到的例子，总结成共性并正交化的点。共性后的规律，再应用到新问题，反过来完善规律，正交则是使点的数量达到最小，从而减少记忆负担。\\n\\n输入和输出间的变换，可以叫函数，也叫模型。输入是训练集，之所以这么叫，是为了将函数打磨得更通用和简洁。\\n\\n思维导图的用法，核心是连接，又叫索引。建立一个点，是不是中心没关系，只要这个点推演生长，中心最终会被发现。把所知的概念融汇在名词性的点或动词性的线上，让你的知识精炼，连结并产生新的知识。"}'));jctx.push(JSON.parse('{"id": "150904", "tag": "lang", "text": "# Chomsky的4型文法与BNF\\n\\n按序有4种文法，从强到弱排列如下\\n\\nType-0：也称短语文法，产生式为A-〉B，A和B均包含terminal和nonterminal，表达力最强，等价与图灵机\\n\\nType-1：也称为上下文相关文法，CSG。是0型的特例，要求|A|<=|B|。与0型的差异暂时还不明白。\\n\\nType-2：也称为上下文无关文法，CFG。是1型的特例，要求A只能是一个nonterminal，由于只有一个，因此也就没有上下文，故而当然是上下文无关了。对应下推自动机Push Down Automaton，是带一个栈的有限状态机扩展，比图灵机的双栈要弱。下推自动机也分确定型和非确定型，两者的能力不相等，其中非确定型等价于CFG。\\n\\nType-3：也称正则文法，是2型的特例，由于2型已经限定了左侧，故3型的限制在于右侧至多有两个符号，且只能是两种形式，A->a，或者A->aB。a是terminal，A->a很好理解，状态已经推导确定，A->aB我的理解是3型文法具备cleene闭包特性，可以无限推导，但由于不带栈，故不能记忆状态。而A->Ba这种文法，必须要先把B压栈，再lookahead一次，才能确定是否符合文法规则，因此不属于文法3类型。3型对应的自动机是有限状态机。\\n\\n前面说的是语言学的纯理论部分，接下来看BNF方法记述\\n\\nBackus Naur Form定义于1960年代，是一种格式化的语法记法。\\n所谓格式化是可以严格推导、能用数字证明的方法。\\n\\n原始的BNF格式能表达Context Free Grammar。只是由于语法偏少，\\n所以后人又做了扩充。扩充有两大流派\\n\\n* EBNF Extended BNF，是PASCAL的作者wirth做的扩展，后来也被ISO标准化定案\\n* ABNF Augmented BNF，有IETF的RFC标准定义的扩展格式\\n\\n与我最初想像的不同，有RFC背书的ABNF并不是最广泛使用的格式，\\n还是EBNF用得更多一些。比如Lua5.1的EBNF定义，使用了22条规则就把所有语法规则定义完了。\\n两套表示法以及BNF的表达能力是一样的，只是书写时的简便程度不同。\\n似乎并不是所有的语言都能用EBNF来表达，不过语言最好还是要设计得符合简洁才好。\\n\\nBNF只是一种记述法，对应编译的语法分析阶段，像YACC的语法就和BNF很类似，\\n但不完全一致，典型的比如`::=`这个符号就直接简写成`=`了。\\n好在没有特别大的差异，基本都是一眼就能看得懂的转义。"}'));jctx.push(JSON.parse('{"id": "150926", "tag": "design", "text": "# 软件可靠性硬件可靠\\n\\n通常我们在写软件时，总会做各种各样的错误或异常判断，比如输入非法啊，执行异常之类的。但我们很少去怀疑是不是硬件本身出现问题，仿佛这个世界，只有逻辑错误而不会有电路错误一样。\\n\\n以前听一次云存储的入门讲座，其中就讲到硬盘的存储位出错机率是10e-12，换算下来一块1个T的硬盘，在一年里总会发生一次非正常的bit位翻转。那是我第一次听到有人这么仔细地计算硬件错误机率给软件设计带来的影响。\\n\\n今天在吃饭时，又听到两个有意思的异常问题\\n\\n1.软件经常莫名其妙地死机，甚至一天之内死机十数次，经过调试发现总是内存地址的最高位变成错误的1，把1改成0就不会发生死机。从软件层面问题已经无法解答，最后硬件部的人承认是电路设计有问题，类似是电磁兼容一类的，导致内存受影响，引起最高的bit位翻转。\\n\\n2.某个版本的主程序启动后，会引起busybox死机，但只在那个版本上会出现，经过反复调查，最后偶然发现死机版本的busybox的内存映像竟然和静态编译出的汇编代码不同。考虑到其它版本没有问题，排除加载器问题，于是只好对主程序的内核调用一条条地排查，最后果然发现是某条内核调用，因为代码写得不完善，将某一内存地址的bit位做了翻转，而busybox正好加载到该内存地址。通常code页的内容是不可修改的，但因为这个奇怪的bit翻转，导致汇编指令从Mov变成了Shift，进而导致后续的内存映射异常。又因为异常的内存地址是编译期固定的，所以只在某个版本会影响到busybox的代码段，引起奇怪异常。\\n\\n这两个问题我没有亲身参与，具体细节也是听说而已，但却让我对软件的底层可靠性有了不一样的认识。平时我们写程序，一般是不考虑内存bit位异常翻转，一方面民用的内存、主板在出厂前还是做了相对完善的检验，电磁兼容也必须要通过3C认证，故这种问题反映较少，但公司产品，尤其低成本平台，研发周期又短，发生这种问题，也就不足为奇了。\\n\\n第二个问题则是系统层的奇怪异常，以前我自己写代码，如果遇到底层的函数异常，一般也就不去深究了，一方面是信任，另一方面也确实是看不懂。但从实际情况来看，只要是人写的代码，不论它在哪一层，都有出错的可能。\\n\\n以前还听说过IBM的Z系列大型机，用在金融领域，有个特性就是两个一模一样的CPU同时计算，如果计算出的结果不一致，则丢弃该次计算，当时我看到这段介绍，觉得根本就不可能，今天再去反观，才发觉自己真是见识太少。"}'));jctx.push(JSON.parse('{"id": "151006", "tag": "os", "text": "# Andoird上用kbox模拟linux环境\\n\\n随着这几年安卓机的军备竞赛，一拨拨的性能“落后”的旧手机被淘汰下来闲置在家，却又不能发挥作用。手头就有一个13年的老机，A8单核，1G内存放在角落蒙灰已经一年多了，想想自己好歹算个程序员，这个设备不利用起来甚是可惜，这些年也不爱折腾设备了，这次国庆闲来有空，就想着把安卓装个linux，多少也能跑个apache搭个服务器，多少也算物尽其用。\\n\\n由于是老机，root挺顺利的，顺便熟悉了下adb和fastboot的一些命令。安装好busybox，按说明busybox是自带httpd的，但是只有httpd没有PHP或其它脚本，这服务器也是没什么实际价值，还好集成PHP的APK非常丰富，比如anmpp这个项目，在android上部署nginx、mysql、php和postgre，可以实现一个完整的服务器功能。要注意apk只是个UI，毕竟体积摆那儿，还需要另外下载anmpp.zip包才行，第一次不知为何下载下来的二进制包不正确，解压后无法运行，又重新下了一次，运行后用浏览器打开，熟悉的phpinfo界面弹出，这算是基本可用了。有了服务器，再配上路由自带的花生壳域名绑定，这样随便在哪里，都可以访问自己的网页了，不用花一分钱，而且因为是手机还特别省电，非常好。\\n\\n## kbox\\n\\n到2019年2月，kbox共4个版本，kbox1已经不维护，kbox2在ls时总有些小问题，\\n加上busybox带的工具似乎-h选项总是没用，kbox4安装不成功，只能用kbox3。按作者自己的介绍，\\nkbox3是为Android5适配的，但我刷了Andoird5.1再安装kbox3总是报dlopen not found，\\n一度只能在Android4.4下使用kbox3。直到有一天偶然在stackoverflow上看到有人提和我一样的问题，\\n才在这个页面的2015年6月30日日志下看到月个fix版的libfakechroot.so可以下载，\\n将这个重命名成libfakechroot.so并替换原来/lib/下的文件，Android5下也可以用kbox3了。\\nkbox用deb的包格式，所说是busybox支持，所以工作量可以少一点。\\n\\nkbox3配备的GCC版本是4.9，但默认安装后，哪怕编译最简单的文件，也会报cannot create temporary file in /tmp/:错误，我按这个关键字，\\n都说是TMPDIR环境变量设置有问题，可我看脚本写的TMPDIR=/tmp却看不出错误，\\n换成/home，就报类似的/home/:错误，导致我一直以为是多了后面的:引起的路径非法。\\n因为手头还有一部Andoird4.4上跑的是GCC4.7没有问题，再看GCC4.7的写法，\\n是TMPDIR=$KBOX/tmp，再看KBOX=/data/data/jackpal.androidterm，并按这个方式改写了GCC4.9，\\n终于成功运行，虽然还会报unused DT type 0x1d in libmpc.so之类，\\n在另一篇文章中看到，通过readelf -d libmpc.so可以看到0x1d段类型是RUNPATH的信息段，即使丢弃也没有影响，这才放心。\\n\\n那么为什么GCC在kbox下一定要写成TMPDIR=$KBOX/tmp这种完整写法，其它软件却没有这个问题呢？\\n联想到上面提到的libfakechroot问题，查了些资料，大概是这样的：\\n因为kbox旨在未root的手机上安装类linux环境，但显然安卓的app是被安装到/data/data目录下各自的目录，\\n因此就需要伪造一个根目录环境，这也是fake这个名字的由来。\\nfakechroot的原理，就是改写环境变量LD_PRELOAD=/data/data/.../lib/fakechroot.so，\\n让linker先行加载这个动态库，并在这个库中提供open/chroot/dlopen等一系列接口，\\n让程序以为自己是在/目录下。但是也许是GCC没有用到linker动态加载（似乎说得通），\\n所以当TMPDIR目录直接写成/tmp，找到的是安卓设备真正的/tmp，显然kbox无法向这个目录写入数据，因此一直不能正常运行。\\n可惜kbox的作者在GCC4.7版本中并未注释TMPDIR必须是完整路径，可能在了解的人看来，这不值一提吧。\\n\\ngit也有点小问题，连接https域名会报ssl证书不对，解决方法是git config --global http.sslVerify false去掉校验即可。\\n\\n另外Andoird5.1上的dropbear无法使用，提示不是position independent execution。\\n难道作者自己都没有测试过吗？还好有utelnet程序，这个程序虽然能跑，\\n却每次在putty上输入用户名就结束，看帮助文档才发现需要utelnetd -l /bin/bash指定程序才可以。\\n作者给dropbear作了一个sshd_daemon.sh的wrap脚本，参数很多，其中-A,-U,-G,-N,-C这5个，\\n都是为了解决Android系统去掉了用户概念导致程序不兼容。\\ntelnet也可以作个类似的wrap脚本。用telnet连上后速度好像比ssh稍快，shell下显示也正常，\\n但vim打开文件，显示的行数只有20行，似乎是哪个TERM的参数没有设置对，这个问题暂时还没有解决掉，留待以后。\\n\\nroot与非root安装linux的区别是这样的：没有root的设备最麻烦的就是权限问题，虽然是你的手机，可是程序却不能随意地写和执行，如果是root过的手机，就可以很明显地在/data/data目录下看到，每个程序的用户名都是不一样的，类似app12这样带了数字(当然会有些预装app的用户名是system，这种会有多个)，由于每个程序只能在自己的目录下为所欲为(这样也防止了程序往SD卡乱写)，因此kbox的安装包必须要放在这个jackpal目录下。所以我通过电脑把安装包放到SD卡，在terminal看来却是root用户，好在SD卡可读，于是通过cat命令把安装包移到jackpal目录下(原生可能没有mv)，然后在jackpal下运行。kbox的网站提供了一些deb包，像coreutils、dropbear、gcc等，下载到本机用dpkg安装，因为只是个人作品，没有仓库也没有apt。建议先装dropbear，是个轻量级的ssh server，有了这个就可以通过电脑来远程执行手机上的命令了。由于安卓的单用户特性，dropbear提供了6个专门的选项，好在作者提供了`ssh_daemon.sh`可供学习。kbox上提供的最重量级的是gcc，拿lua试编译了一次，问题多多，列举如下\\n\\nlocale.h里的localeconv()->decimal_point[0]这个函数是个假实现，原因是bionic C库把它阉割了，导致编译不过，好在这个地方直接写死返回\'.\'就行，然后没有ranlib命令，更坑的是ar好像也不支持s选项，其实原因是默认的ar是指向busybox的软链接，功能不完整。只要找到gcc所在的真实目录，在PATH路径下做个软链接或写个shell脚本，再删除原来指向busybox的ar以可以用解决了。最后在链接时又报没有log2，看了源代码这个是属于C89后加入的函数，看来bionic把这个也给阉割了，唉，还好luaconf.h已经预料到这种情况，打开C89宏，总算编译成功了。\\n\\n看了kbox3，也是对android的C库各种吐槽，包括奇怪的权限设置、服务缺失、乱用UID、奇葩的API等等问题，连lua这么简单的程序都被编译得如此恶心，想来那些大神们只会遇到更奇怪的问题吧。\\n\\n折腾半个下午加晚上，以后配上一个键盘，至少出门在外可以简单地用手机做点事情了，前提是最好有个大点的屏幕。等有空再试试kbox3，或者GNURoot Wheezy等类似的非Root版linux，手机也要发挥工作机的作用才行。\\n\\nkbox只能算半截的工程，它不是完整的apk程序，而是依赖能提供shell环境的apk，并利用这个环境内可写可执行(/sdcard只能写，不能执行也不能创建软链接)，构造一个属于kbox的环境。而Termux，相当于把kbox做的事情和apk整合到一起。"}'));jctx.push(JSON.parse('{"id": "151129", "tag": "os", "text": "# 两个一直理解错误的编译问题\\n\\n1.dll是可以直接替换而不需要重新编译的。\\n\\n一直以来，我都以为只有so可以做到直接替换，而dll则不同。因为dll可以选择在编译时候通过.lib方式将dll中的符号表进行绑定。此前我一直认为只有代码中显示的调用LoadLibrary方式调用才是真正安全的。但简单写了个例子，发现如果dll导出的全是C函数的话，则可以直接替换，至少在我验证中是没有问题的。而所说的dll hell更多的是发生在导出类的场景下。反正我是严格使用C风格，也不喜欢导出类这种使用方式。至于具体原因，还要再仔细看看书。\\n\\n2.MingW可以使用第三方提供的.lib/.dll方式编译，且可正常用。\\n\\n遇到目标机器只安装了MingW，但库却是给VC准备的。但既然MingW可以编译出.lib/.dll，且看了下MingW自带的.a，二进制文件从结构上和.lib是大致一致的。于是修改.lib为.a，当然还要加上前缀lib，用-l选项可以编译成功，跑了几段程序都正常运行。原因我想是在windows平台，.a只是个命名习惯，最终二进制层面还是要遵守习惯，.dll肯定是PE结构，现阶段大胆猜测.a也是和.lib是一样的。\\n\\n以上两点只有不完整测试，不敢保证一定正确。后面如果从资料里看到解释的原因，再回到这里修正。"}'));jctx.push(JSON.parse('{"id": "160109", "tag": "lang", "text": "# GCC编译4阶段的一些理解\\n\\n起因是这样的，安装了GCC4.7和4.8两个版本，但是4.8不知什么原因输出临时目录总是出错，原因及修改方法见这里，\\n所以只能用4.8配合-pipe选项先生成.o文件，再用4.7链接成可执行程序。于是想了解下这么做为什么是可行的。\\n\\nC语言的编译分4个步骤，第一步cpp预编译，后缀名.i，这一步因为宏的机制几乎没有新特性，且功能也不多，不会有太大的变化。这个不详细研究了。第二步cc1编译成汇编语言，这是整个编译最复杂的地方，涉及语言特性支持和优化，一般说的版本就是指cc1，C++则是cc1plus。\\n由这步生成后缀.s的汇编文件。第三步as(又名gas)将汇编语言转机器码并生成对应平台的目标文件，如ELF或COFF文件，最后由ld将多个目标文件生成可执行程序或库，文件格式为ELF或PE。\\n\\n其中的第三、四步用的as和ld，其实并不在gcc的范畴内，其版本号是属于binutils这个项目下，\\n因为as的工作在于把汇编语言转机器码，并生成对应平台的目标文件，\\n生成机器码这步没什么好说的，不同指令集有各自的代码，相对比较直观。\\n但要生成各种平台对应的目标文件，这就涉及到一个抽象层，而一般用得最多的，\\n就是BFD库，如果输入as -v也会出现as BFD version字样，生成的目标文件经ld链接，\\n而ld只是个软链接，真正的文件可能是ld.bfd，也可能是ld.gold。\\n看名字就知道ld.bfd表示使用BFD库来生成平台相关文件，而ld.gold则是google研发的链接版本，\\n据说速度很快，但我的机器上没有安装，也不清楚依赖的gold库到底是个什么库，\\n只知道gold版只支持ELF，所以GNU必然不变采用作为默认实现，其功能应该和BFD是类似。\\n\\n由于是两个软件包，怎么配套并没有一个非常严格的要求，因此用gcc4.8编译，最后用4.7链接也问题不大。只是默认会链接到4.7的库目录。如果想用4.8的目录，则可用用--sysroot选项来指定。\\n综上来看，编译的几个阶段，重心是不一样。而每两个阶段间都需要有一个规范。cc1和as之间采用的是AT&T规范，as和ld之间则是平台相关的目标格式。正是因为有了这些规范，4步编译才能看起来仿佛一步似地完成。\\n\\n## 一些有用的编译指令\\n\\n`gcc -print-file-name=libc.so`获得libc.so的位置\\n\\n`libstdc++`是`g++`的专属库，gcc命令不能自动和C++程序使用的库联接，使用`gcc -lstdc++`就可以。\\n\\n静态编译带运行时，`g++ -static-libgcc -static-libstdc++`\\n\\n编译时设置rpath和dynamic linker（绝对路径）：gcc -Wl,-rpath=\'/my/lib\',-dynamic-linker=\'/my/lib/ld-linux.so.2\'\\n\\nrpath，全名run-time search path，是elf文件中一个字段，它指定了可执行文件执行时搜索so文件的第一优先位置，一般编译器默认将该字段设为空。elf文件中还有一个类似的字段runpath，其作用与rpath类似，但搜索优先级稍低。搜索优先级:\\n\\n`rpath > LD_LIBRARY_PATH > runpath > ldconfig缓存 > 默认的/lib,/usr/lib等`\\n\\n如果需要使用相对路径指定lib文件夹，可以使用ORIGIN变量，ld会将ORIGIN理解成可执行文件所在的路径。`gcc -Wl,-rpath=\'$ORIGIN/../lib\'`\\n\\n无法编译程序时，可以通过patchelf修改rpath和interpreter。\\n\\n```\\npatchelf --set-rpath \'$ORIGIN\' your_program\\npatchelf --set-interpreter /my/lib/ld-linux.so.2 your_program\\n```\\n\\n利用$ORIGIN方式把依赖so放一起，portable化。也可以使用pwd获取当前路径，使用相对路径指向本地lib。\\n\\n```\\npatchelf --set-rpath `pwd`/../lib your_program\\npatchelf --set-interpreter `pwd`/../lib/ld-linux-x86-64.so.2 ./your_program\\n```"}'));jctx.push(JSON.parse('{"id": "160131", "tag": "os", "text": "# Widnows的编译库的理解\\n\\n## 生成动态库\\n\\nwindows下生成动态库，会输出3个文件。通过dumpbin把三者的段内容分别打印并比较一下。\\n\\nexp类型也是COFF OBJECT，即和编译生成的.obj是一样的。\\n\\n打印/symbols，只有exp有大量的输出，而dll和lib没有输出。因为/symbols表示COFF 符号表，只有exp和obj能输出。exp的symbols分两类，Static和External，意义很直接。\\n\\n打印/imports，只有dll有大量输出，大多是依赖系统库，如MVVCRT等，而lib和exp无输出。只对exe和dll有意义。\\n\\n打印/exports，dll和lib都有大量输出，而exp没有输出。dll和lib的输出差异在于，dll输出的符号和函数中一致(似乎是Name)，而lib的符号则多了一个下划线前缀(似乎是Symbol Name)。\\n\\n另外编译后的资源文件.res也是COFF OBJECT类型，也是按段来组织的。\\n\\n另外lib和exp都无法反编译，即/disasm无输出，应该是内部只有符号表，无text段的关系。而dll是有大量的反汇编代码。说明编译时导入的lib也就是起到了符号寻路的作用，没有真正有意义的代码段。\\n\\ndll的反汇编代码，尤其跳转类je/jne指令后面都是绝对地址，说明不是地址无关代码，需要运行时做基址重定位，即ReBase修正。\\n\\n## 使用动态库\\n\\n使用dll库时需要一个同名的.lib，称为导入库。而windows下的静态库的后缀也是.lib。这是经常让人迷惑的地方。由于Linux没有对应导入库的形态，编译时直接指定.dll已可以。\\n\\n但是MinGW移植的GCC做得更友好一点，编译时直接指定dll文件名，就可以生成可执行文件，其实是不需要导入库这东西。相比起来VC作为原生编译器，限制反而更多一点。MinGW作为Port，当然也能支持导入库。一般情况下VC生成的导入库可以直接被GCC读取(用cdecl导出的)，如果是stdcall导出的符号，因为VC会加上“`_`”前缀，所以把“`_`”去掉就可以给GCC用了。还有一种方式是用pexports从dll中导出.def文件，再用dlltool也能生成导入库。从这个角度看，MinGW直接支持编译时指定dll，也是理所当然的。\\n\\n另外MinGW下有一个工具叫reimp，整个代码都不大，简单地看了代码，导入库的格式如下，头部的MagicNumber是!<arch>\\\\n共8个字符，再之后是结构体\\n\\n```\\nstruct ar_hdr {\\n  char ar_name[16];\\n  char ar_date[12];\\n  char ar_uid[6];\\n  char ar_gid[6];\\n  char ar_mode[8];\\n  char ar_size[10];\\n  char ar_fmag[2];\\n};\\n```\\n\\n而且这个结构体会重复多次出现，此结构出现两次后，会出现一段字符串表，所有需要导入的符号都在这里。但是数量上会多一点。比如dll有128个符号，字符串表会有128x2+3=259个符号。x2是因为每个符号都是有一个对应的`__imp_`对应符号，另外+3是在首部有`__IMPORT_DESCRIPTOR_`和`__NULL_IMPORT_DESCRIPTOR`开头的字符串，末尾处有一个0x7F开头的字符串(对应ASCII的del键，不是个可打印字符)。这3个去掉之后，剩下的导出符号就可以对上了。\\n\\n最后用这个方法做了个试验，找到一个tcmalloc.dll，然后通过pexports生成.def文件，再用dlltool生成导入库，用gcc编译成功通过且能运行。直接用dll也运行正常。\\n"}'));jctx.push(JSON.parse('{"id": "160204", "tag": "security", "text": "# SSH点滴\\n\\n## 验证方式\\n\\n从日志能看到3种验证方式，debug3: preferred publickey,keyboard-interactive,password。后两种表现上都是密码输入，区别是password是RFC-4252(sec 8)定义的，而keyboard在RFC-4256定义。理论上keyboard会询问用户各种问题，但从实现角度看，只用了密码一种方式。所以两种不同的规范看起来就像一样了(甚至xshell面对keyboard模式能自动输入密码)。两者都可以在`sshd_config`中独立控制，keyboard是KbdInteractiveAuthentication(也可以不设置，用ChallengeResponseAuthentication)，password是PasswordAuthentication。\\n\\n使用的加密套件是一直在加强的，遇到过用15年的dropbear连接20年的版本，会报没有合适的mac套件，如果是openssh可以加`KexAlgorithms diffie-hellman-group1-sha1`强制允许不够安全的加密方式。\\n\\n## 公钥登陆\\n\\nTinysshd不支持用户名密码登陆(甚至还删除了RSA公钥，只支持ed25519)，又比如安卓的用户体系被裁剪，只有PubkeyAuthentication。部分魔改的安卓程序可以支持用户登陆，比如dory的nodejs，就支持将密码做了SHA256的值保存到~/.ssh/doryauth，不过不是通用做法。\\n\\n首先使用ssh-keygen -t rsa -C \\"your@email\\"工具产生公私钥对，会提示输入passphrase，这是私钥的一个密码，相当于做了二次的保密。如果是生产环境，这个私钥的密码是必须要设置的，我用在内网和虚拟机比较多，再说用公钥登陆本来就是为了方便，所以暂时先不设了，但从安全性角度看，为私钥加个密码，在私钥丢失的时候，还是很有作用的。除了rsa还有dss, dsa, ecdsa, ed25519等很多方式，从7.0版本开始默认不再支持dss。\\n\\nSSH2版本的公钥文件格式有IETF SECSH(似乎又叫SSL PEM)和OpenSSH两种格式，SSH1已经看不到，不去管它。\\n\\n* SSL PEM: 文件内容以`-----BEGIN RSA PUBLIC KEY-----`开头，以`-----END RSA PUBLIC KEY-----`结尾\\n* OpenSSH格式: 从OpenSSH 7.8版本(18年7月)开始作为默认格式，内容全在一行，以ssh-rsa开头，rsa可以换成其它加密技术\\n\\n命令执行后，生成密钥对，分别是私钥id\\\\_rsa和公钥id\\\\_rsa.pub(算法不同名字会有差异)。需要把公钥上传服务器你想登陆的用户名目录下。\\n把生成的公钥文件id\\\\_rsa.pub上传并导入ssh服务器的用户目录下的~/.ssh/authorized\\\\_keys文件(OpenSSH和Dropbear都是这个文件)。这样服务器的配置就完成了。补充一点权限相关内容，.ssh目录需要0700权限，而authorized\\\\_keys则需要更严格的0600权限。\\n\\n为什么上传公钥呢，因为公钥是你发送给运维的，当然不能含有密码，从这个角度看，私钥是更不能外泄的。\\n\\n接下来就是配置客户端了，只要能拿到RSA私钥的关键数据(即N、E数)，私钥的文本格式不重要。选用putty或SecureCRT的作法稍有不同，\\nputty用的格式比较特殊，需要使用puttygen这个工具把ssh-keygen生成的id\\\\_rsa转成.ppk后缀的文件，\\n不过这不影响私钥的数据。如果原始的私钥是带passphrase，puttygen在转换时也会要求输入原始密码，如果输入正确，可以修改密码，\\n如果输入错误，则是无法转换的。passphrase是用sha256加密，所以puttygen实际上是无法得知原始密码的。当然转换后保存的也是经sha256计算得到的值。**如果用命令行ssh，一定要保证id\\\\_rsa以LF结尾**，出现过误将回车符保存成CRLF，导致ssh报错Invalid format。如果本地有多份id\\\\_rsa私钥，用-i选择指定。虽然默认会用当前用户名路径下的id\\\\_rsa，但不代表绑定当前用户名，比如从A机器用u1用户登陆B机器的u2，即使私钥文件放在u1的目录下，只要指定了登陆B用u2用户，私钥就会和u2目录下的公钥匹配。*私钥放在哪里，并不代表绑定哪个用户，但公钥放在哪个用户的目录下，是绑定该用户的*。\\n\\n到这步，公钥和私钥都准备好了，怎么在登陆时让putty自动找到私钥呢？putty对不同的ssh服务器有个session的概念，首先load需要登陆的服务器session，在Connection->Data菜单的Auto-login Username输入登陆的用户名，\\n这样就能在服务器对应目录下寻找公钥，然后在Connection->SSH->Auth的Private key file for authentication中配置转换好的.ppk私钥路径。最后把这些改动save到putty的session中。之后对这个session直接点击open，就可以用公钥方式登服务器了。\\n\\n**归纳起来就是：先用ssh-keygen生成公私钥，公钥上传sshd服务器，私钥指定给ssh客户端。**\\n\\n在配置了公钥登陆后，甚至可以禁止密码登陆方式，修改/etc/sshd/sshd_config文件，PasswordAuthentication no。默认允许密码认证。\\n\\n为了方便使用公钥，专门设计出了ssh-agent和ssh-add这两个程序。首先用ssh-agent $shell启动代理，代理会在/tmp用域套接字监听，然后用ssh-add添加私钥，如果有phrase则输入，代理就得到了私钥。之后再连接远程就不再需要输入私钥的phrase。\\n\\n主流的生成公私钥对工具是ssh-keygen，偏偏putty提供了类似的puttygen，但格式又不同，生成公私钥对后，千万不要用save public key按钮，因为openssh不识别这种文件格式，需要把窗口中的内容复制出来。\\n\\n用termux时遇到了server refused our key的错误，折腾再三，将`/usr/etc/ssh/sshd_config`内容加上这几句。似乎0.73版本后没有问题。\\n\\n```\\nPasswordAuthentication no\\nPubkeyAuthentication yes\\nAuthorizedKeysFile ~/.ssh/authorized_keys\\n```\\n\\n通过看putty的log，了解公钥认证的流程。网络连接和加密算法协商之后，putty会从私钥中生成公钥并发给服务器，如果配置了该公钥，服务器会返回接受该公钥。然后putty再发送公钥的签名，签名也被接受后，就进入Access Granted状态。打开一个session，得知agent-forwarding port-forwarding pty user-rc x11-forwarding这些属性，设置pty的速度，双向都是38400kbps，至此会话建立成功。\\n\\n结合以上的流程，可能失败的原因是缺少最后一句配置，指定公钥文件保存的位置。对sshd来说，收到putty提供的公钥，如果不知道去哪里找，显示会refused。但是对多用户系统是否也能这么写？怀疑应该是可以的，因为即使是公钥登陆，也必须指定用户名（公私钥对和用户名没有关系）。有了用户名，sshd就能从~映射到对应的用户目录。\\n\\n## keygen的使用\\n\\n* ssh-keygen -y -f 私钥  # 从私钥计算公钥，可用-yf\\n* ssh-keygen -l -f 公钥  # 从公钥计算指纹，可用-lf\\n\\n## 隧道\\n\\n平时用ssh感觉永远是连上远程主机并打开shell，其实只有加密连接远程主机这步不可缺少，在远程主机上打开shell是个默认行为，如果选择不打开shell，这时连接已经建立，就可以利用这条加密连接做些其它事，这就是隧道（又叫端口转发，因为是基于ssh的端口，工作在TCP层）。\\n\\nssh连接建立后，双端配合启动隧道功能。隧道在客户端打开，所以是ssh在监听，而sshd负责消息转发。以L本地转发为例，客户侧的程序ClientProgram和ssh间是明文通信，ssh和sshd之间当然是密文，到了服务端的sshd侧，再按明文发给预设的端口，就完成了隧道的使命。\\n\\n因为ssh原本的任务就是加密并在server端启动shell进程，隧道无非是把启动shell改成向另一个指定端口转发消息，和整个流程是契合的。\\n\\n## 认证代理\\n\\n使用公私钥登陆时，如果所有主机用同一个私钥还好，但现实往往不同主机配不同私钥，ssh只认`id_rsa`一个名字（算法不同名字不同），这就导致要手动指定私钥。为解决这个问题，就有了ssh-agent和ssh-add这套方案，可以一次性手动把所有私钥通过ssh-add加到agent，如果私钥有passphrase，只要在add时输入一次，只要agent不挂，以后不用再输入，这样看起来私钥带上passphrase也并不麻烦。但有点让我介意的是，即使退出终端agent并不会结束，下一个人或者其他人登陆这台主机，可以可享agent规则登陆所有你登陆的主机，只是无法知道passpharse。虽说并没有更多的权限，但总感到有些不妥。\\n"}'));jctx.push(JSON.parse('{"id": "160214", "tag": "lang", "text": "# stackless和stackfull概念在VM上的一些理解\\n\\n以前知道有个stackless的python实现，但不明白是什么意思，看一篇分析Lua虚拟机的文章也提到了这个概念，就做个记录。\\n\\nstackless python的意义在于不需要C语言的call stack作为python的堆栈，因此CPython又被称为stackfull的实现。由于依赖了C语言的堆栈，必然对实现有了限制，典型的就是多线程之间需要Global Interpreater Lock，导致实际的单线程。又比如yield的一层限制。再比如GC就很难用tracing方式，而只能用引用计数方式。Lexical closure也没有实现，而是保存变量的引用，因此Python有个Vyper的OCaml实现，解决的好像就是这个问题。\\n\\n反观Lua的虚拟机实现，基本上是stackless方式的实现，摘一段奇异技术点博客的分析：基于虚拟机的语言的call stack有两种可能的设计，一是称为stackfull方案，借用Host主机的stack，Byte－Code的函数调用比如Call指令对应native代码的函数调用，即X86的call指令，这种情况下，虚拟机stack随Byte－Code函数调用层次的增加而增长。二是stackless方案，由虚拟机维护额外的call stack数据结构，Byte－Code的函数调用和其他指令一样，在虚拟机的同一个循环中完成，虚拟机的stack不体现Byte－code函数的调用层次。\\n\\nLua虚拟机的stack，存储在lua_State结构的StkID stack字段中，是个数组，包括函数指针（Lua和C都可以），函数的参数和返回值，Lua函数的局部变量。但在stack字段缺少C代码stack的东西，如C语言的call stack，函数的返回地址，帧指针栈指针EBP、ESP信息。那么这些信息保存在哪里呢？ 其实Lua虚拟机是双stack结构，保存在CallInfo＊ ci这个字段里。CallInfo结构保存了函数位置，这个函数可以是Lua或C。当Lua作为caller时，返回地址保存在CallInfo的u.l.savedpc里，如果C函数作为caller，返回地址在VM stack。C函数发生yield时，VM的stack被破坏，该coroutine下次resume的地址由u.c.k决定。\\n\\n所以对yield设计来说，相当于在整体stackless的Lua虚拟机设计中导入一个额外的stackfull，也因此Lua51要求C语言的yield必须在return时调用，只有这样，才能很好地衔接stackless和stackfull两种结构。就好像GC，在Lua整体采用的是root－tracing，或名mark and sweep方式，但为了方便C语言操作，也提供了`luaL_ref`／`luaL_unref`的引用计数方式让C语言影响虚拟机的工作状态。"}'));jctx.push(JSON.parse('{"id": "160218", "tag": "lang", "text": "# 使用Lazy-Stream方式实现Fibnacci数列\\n\\n起因是看到一篇讲stackless方式coroutine的文章，给的例子是用js写的。用Lua重写了一遍，感觉有些思路上以前没有想到过，做点纪录。\\n\\n要实现Lazy，假设采用function fibNext()的形式，每一次调用fibNext()，都会返回下一个数，且可以无限调用。显然这个函数要return一个数字，那么要怎么实现状态的更新从而在下一次调用时得到下一个数据呢？如果用OO的方式，很简单把状态和方法绑定到一个对象上就可以了，那么函数式中对应的就是闭包，在Lua中的名字就是upvalue。\\n\\n首先函数的基本形态应该是这样的：function fibNetx() return ?, fibresult  end。?处肯定只能是一个function（因为限定了不用OO方式）。传入的function会替换掉fibNext，因此需要在fibNext外面做一个wrap\\n\\n<pre>\\nwrapNext function()\\n  local i, j, next = 0, 1\\n  local yld = function(k, i)\\n  next = k\\n  return i\\nend\\n\\n next = function() yld(function()\\n   local tmp = i; i = j; j = temp + j\\n  j) end\\n\\n  return next()\\nend\\n</pre>"}'));jctx.push(JSON.parse('{"id": "160304", "tag": "web", "text": "# Openresty代码初读\\n\\n我在公司内网的服务器从Apache httpd换成Openresty也有半年左右了，切换之后没有去深入研究，最近重新开始研究，一点初步的理解，记录在这里。\\n\\nnginx给我最初的印象不是快或者节省资源，而是它居然的扩展机制。现在的软件都说自己是插件化体系，放个dll或so进去就可以增加功能，但nginx却需要每次重新编译，把扩展代码和执行程序编在一起才行。好像淘宝有个Tengine的扩展，可以用动态库的方式扩展，不过openresty没有用，那就还是看nginx的代码好了。\\n\\nopenresty的编译也是用configure脚本，却不是用GNU的auto系，而是在平级目录下有个auto目录，里面有各式各样的脚本检测OS或编译器选项，这块不清楚是不是个独立的项目，又或者是作者自己手工写的。\\n\\nnginx编译添加模块的方式是在./configure后面用--add-module=指定路径方式，从configure脚本可以看到，是在指定目录下寻找config文件，如果有再从config文件读入相应的源代码和模块名信息。config定法也不复杂，就定义一些shell变量，然后统一被写入编译文件列表。nginx内一个很重要的概念是模块，代码中是个名为ngx_module_t的结构体，官方提供的http和mail功能是用模块，扩展功能也是同样实现这个模块。在core目录下，可以找到`extern ngx_module_t  *ngx_modules[];`这样一句声明，而在main函数中就直接循环遍历这个数组了。找遍nginx目录也没有找到这个变量定义的地方，再结合每次扩展需要重新编译，恍然大悟去编译目录objs/下果然找到`ngx_modules.c`这个文件，里面赫然定义了`ngx_module_t *ngx_modules[] = {`以及之后的若干个模块，之就是nginx静态编译扩展的原理了。模块分了CORE、CONF、HTTP和MAIL四个大类但定义是分散在core/http/mail三个目录下，似乎除了CORE会用于逻辑判断，其它几个并没有严格地规定。模块版本号目前都是1，也没有做逻辑判断，可能是为了将来扩展吧。另外模块中真正起作用的，就是content指针和7个函数指针。不过有些扩展模块并未实现函数指针，只有content是必须实现。或许是因为大多数模块并不需要参与nginx的核心调度，只要有content环境能和核心进行交互即可。像openresty中非常重要的lua扩展，也只不过实现了7个函数指针中的`init_process`这一个函数。\\n\\n由于模块是编译进程序，运行自然也就和nginx在同一个地址空间，遍观如今排名前20的主流语言，体积小功能完整的，还真就只有lua了。因为扩展是直接在nginx的worker进程跑，如果扩展出点问题，worker进程是会直接挂掉的，开始我不知道，用ngx.say去遍历打印ngx内部的成员名和类型，结果浏览器就没有结果显示，后来看了代码才发现，因为table中有ngx.say不支持的类型值，结果lua扩展直接触发了abort();这个问题后续还是要注意，如果nginx中要执行长会话动作，这种abort还是很危险的。"}'));jctx.push(JSON.parse('{"id": "160313", "tag": "design", "text": "# 模块功能的划分与解耦\\n\\n这周工作上解决了一个困惑我很久的需求，记一些要点。\\n\\n在C-S模型中，向来都是客户端发请求服务端应答，偶尔也会有服务端推送业务，但已经是比较不常规的方法了。服务器的推送是不做确认的，即发了就发了，也不会要求确认，更没有重传机制。至少我看iOS的推送也是不承诺这些的。但是需求总会时不时来一个推送确认/重传来恶心一下。\\n\\n当前代码的订阅推送是采用传统的观察者模型，事件源向事件中心发消息，所有向事件中心订阅过的模块都会收到消息。事件中心是与业务无关的，即不关心事件来自哪里，也不关心事件发给了谁。在这种前提下要做事件确认，而且必然是向事件源确认，是件很困难的事情。现在留存的确认机制，是直接向事件中心确认，向分发器发送确认，但真正需要关心的，是事件源，这就把两个功能放在一个模块里，造成了职责的混乱。也许当初认为这两个都是事件相关，就放在一处了吧。\\n\\n不过好在内部实现时，事件分发dispatch和事件确认receipt最终还是分成了两个组件，只是在dispatch组件中直接调用receipt的接口，把消息又转出来了，需要关心事件是否被客户端确认的源模块，主动向receipt注册，在收到事件确认后，会回调出确认函数。考虑到事件确认毕竟是定制化为主的需求，即使增加事件源模块的注册代码量，也是比较容易接受的做法。\\n\\n这周因为又收到了事件重传的需求，起初我理解重传restore既然在确认步骤之后，这两个功能就可以放在一个组件里面，但代码实现时意外发现receipt的代码是实现在基础组件的(原来我以为是在定制模块实现的)，这就直接导致了restore不可能和receipt做到一起，因为基础组件组是不可能接受这样的业务需求的。也正因为这种组织上的制约，反而让我重新思考，确认和重传真的需要放在一起吗？还是我想当然地一种认识。只能说重传依赖于确认，但不能说确认会推导出重传。这是典型的必要非充分条件。既然这样，那就更应该把这两者给区分开来，所以最终dispatch、receipt、restore是按三个组件的接口来划分。\\n\\n这件事的反思就是，需求分解要做到好的解耦，其实是非常难。稍一被客户表示的需求给带着，就会把并不强相关的内容合并到一起。不知为什么往一个接口或组件里增加内容似乎总是很容易，但要从原有的接口把内容剥离出来，则是千难万难。软件工程所追求的高内聚低耦合，又或者正交的高组合性，需要对概念非常清晰的认识，稍一含糊可能就会破坏两个概念的边界，进而造成模块间职责错位，再往后就是代码一团麻无法理清。\\n\\n这周正好读到一些文章，也是讲到人类的认识原理中，概念是个非常重要的东西，概念的多少，区分度直接导致了知识的广度和深度的不同，甚至语言对概念描述的详实程度，都会影响认识。比如英语单词数量之多是有目共睹的，甚至很多就是完全无意义的组合，但即使这样，所包含的信息量，和各信息之间的区别，就天然地会在单词不同目有体现，也就迫使人去理解单词间的不同，进而区分、明确概念，这就是语言对认识的推进作用。姑且不论对错，这个观点至少是有启发性的。"}'));jctx.push(JSON.parse('{"id": "160328", "tag": "protocol", "text": "# PNG格式的启发\\n\\n都说PNG格式是二进制格式中的优秀范例，文档也写得非常好。这周断断续续看了RFC2083，常有拍案之处。\\n\\nPNG的总体格式是8字节的格式头和一系列的chunk构成。\\n\\n先说8字节头，8字节分别是137 80 78 71 13 10 26 10。第一字节特意用了一个非ASCII字符，防止编辑器将PNG文件误认为是文本文件，同时可以检测程序是否过滤了最高位(似乎说的是邮件处理程序？)。Lua编译出的二进制文件也用了类似的思路，不过那里用还是ASCII的不可打印字符027。\\n\\n头部之后就是一连串的Chunk。Chunk也有个固定格式，4字节的长度+4字节的类型+数据+CRC32。为什么把长度放在类型前面？因为CRC是流式计算的，也许一开始并不知道最终的长度，所以如果把类型和长度互换，可能会造成CRC的计算困难。而且因为最开始已经有文件头，先放长度也不会造成识别的困难。再说一个小细节，4字长度文档特意标注是一个无符号整数，但范围是2^31-1，即最高位一定是0，原因是考虑到部分编程语言无法表示4字节的无符号整数(至少Java就是这样)。另一个我在工作中遇到有点类似的情况是，可能会有代码一开始错误地按int来实现，当发生对接错误的时候，才意识到要改代码，这时只要限定范围即可，算是保留了一点裕量。\\n\\n类型部分很有趣，PNG的Chunk类型有两种。一种是大写字母开头，称为Critical，比如IHDR、IEND，再一种是小写字母开头，如sPHY。如果增加了新的Critical类型，客户端无法识别，可以提示用户升级客户端，而不重要的Chunk又可以跳过。当然Critical不是必须要带，只是携带的时候，就相当于需要服务端和客户端做一个版本同步保证。这种策略不需要版本号，也可以达到C/S各自地升级兼容。\\n\\nPNG的设计目标是用于文件的保存和传输，但其中Chunk的设计策略对交互式的协议也是有借鉴作用的。"}'));jctx.push(JSON.parse('{"id": "160412", "tag": "lang", "text": "# C++模板引起的一个二进制兼容问题\\n\\n问题来源是这样的，公司的基础库里，用于实现Observer模式的Signal库是模板写的。模板嘛实现代码都在.h头文件里，在之前的一个版本里，因为要解决一个bug，对Signal模板类增加了两个成员变量，在提交时内部几个人评审，都觉得模板既然是在各自的cpp内实例化，且不涉及对象的传递，即使改变了类大小，也不会引起问题。然而最终集成的时候，就是挂在Signal类里。\\n\\n一度我以为是应用的使用者在两个不同的库之间（这两个库编译时引用不同版本的头文件），传递了Signal的实例引起，但后来经同事提醒，加上回忆起之前做的一个实验，发现确实是增加类变量引起的不兼容问题。原因如下：\\n\\n模板类在编译时，的确是在每个编译单元即cpp生成的.o中实例化出来的，但是这个实例化出来的函数（或类）的链接属性是Weak。通过readelf -s命令可以查看。正常如果不是手写attribute((weak))属性，编译出的要么是Global要么是Local。由于是Weak属性，如果实例化时的参数类型一样，生成的函数名也一样，而在不同模块生成的.o中的模板代码尽管不同，但因为名字相同，在最终的链接环节，会因为Weak的原因随机挑一个进入最终的可执行程序。而挑选哪一个是由链接器决定的，无法预测。因此当A库用了size更大的模板类，而B库用了原始版本，链接时如果恰巧选择了A库实例化的Signal类最终进入可执行程序，则会破坏B库中紧跟在Signal类后的变量。反过来，如果链接时选择了B的类进入可执行程序，则A在执行时还是用的原始库，不会破坏数据，但修改Signal的bug的期望也落空了。\\n\\n怎么在A、B库不同步更新头文件的情况下，解决这个问题呢？目前能想到的只是保证不崩溃，但做不到百分百修复bug。方法就是模板类也用pImpl方式实现，即模板类的成员变量仅使用一个void* internal指针，具体的数据在这个指针所指向的堆上扩展。这样不论链接器选择哪个版本的模板类，大小始终是一样的。如果用的不是模板类，也一样要遵守这个原则，只是非模板类因为是Global，所以可以控制最终链接进的版本，而使用模板就没这么幸运了。换句话说，如果要用C++的类作为接口，不论是普通类或模板类，为了扩展并保证二进制兼容，一定要遵守pImpl守则。"}'));jctx.push(JSON.parse('{"id": "160424", "tag": "design", "text": "# 程序的被集成性\\n\\n算是一点杂想吧。起因是调试一个bug引起的。\\n\\n公司产品的通信协议一直都是明文，为了达到安全审计的要求，就对信令做了RSA+AES的加密，虽然达到了安全的要求，可是对开发来说再也不能抓包看到数据，调试就很不方便了。组里的同事在转岗前做了一个小工具，但我也一直没关心过这一块，这次重新提起这事，却发现解密小工具不能用了。好在向已经转岗的同事要到了小工具的源码，源码是用MFC写的，我以前一直没有好好学过MFC，也不知道该怎么下手，决定还是从源码中，把GUI之外的解密部分，做成个命令程序，先把问题解决了再看。\\n\\n还好解密和GUI部分代码是分开的，写了命令行的wrap，跟踪后很快就发现问题，是个Base64反解后长度处理不对，没有对齐到16的倍数，导致无法进入AES解密流程。可能当时测试的时候用例正好没触发，也没现这个问题。改了长度，在命令行下面很快就调试通过了。于是我把修改的两处代码给了另一个同事，让他重新编译一个MFC程序，却不知道什么原因在MFC下一直失败。我和同事聊了下，既然解密部分和GUI已经分离，那就不用MFC做界面，自己重新写一个好了。事实证明，我和同事各自用Lua和Python重写一个界面，工作量的确不大。\\n\\n这里的问题就在于，解密的接口原来是用C++写的，在MFC程序里，这种做法没有问题，但要整合到其它语言时，C++就非常地困难了，这次因为只有一个接口，改写成C并导出成dll的改动量不大，但如果有大量的接口都是用C++写成，恐怕做Wrap也是件很烦燥的事情。我们写软件，通常都是先集成其它人的库，然后能力到了，自己做的东西也期望能被集成，在被集成这一点上，C是当之无愧的王者。从接口的封装性上来说，C++并没有比C抽象得更高，\'.\'语法的调用，也只是把this指针从函数的第一个参数移到了函数的前面，仅仅是一个写法上的差异，Go的语法就很清楚地体现了这一点。但这种风格却很难更广泛地被各种语言所兼容，再加上更花样繁多的参数重载、默认参数，却没有一个统一的二进制规范，也使得各种语言最终选择了虽然简陋却也朴实无华的C作为约定。C语言的规范进化了好几版，似乎也没有引入甚至以后也不会引入参数重载、默认参数这样的机制。\\n\\n写一个小工具，按我的个人偏好，也是先有个命令行（或者有相同入出参格式的so/dll），然后基于此做个GUI的Wrap。但做Windows开发的人来说，似乎这种做法也显得老土，这大约也是习惯使然，至少*nix系下，先有命令行，再有GUI的传统现在依然保留着。"}'));jctx.push(JSON.parse('{"id": "160505", "tag": "os", "text": "# 安卓野Rom手动清毒记\\n\\n去年底换了个TCL手机，因为原生Rom不好用恰好网上的Rom也比较多，反复尝试就Flyme还算好用，可惜在ROM之家或ROM基地等几个网站上下到的Flyme多少有点问题。有一天偶然在论坛上看到有人自制的Flyme包，使用后觉得算是做得比较好的Rom，就一直用到现在。期间发现流量开关经常会被自动打开，但正好过去的三个月移动送了好几个G的流量，也没觉得有关系，甚至一次被自动下了软件，也没下决心去查。直接上个月底手机自动发短信并且自动读取验证码，然后被扣6块钱时，我才觉得彻底被愚弄了。此时发现原本的root权限也没有了。此时即使查出了病毒，也无计可施了。\\n\\n从种种迹象来看，中毒的可能性有两个，一是野Rom自带的病毒，但是这病毒的潜伏期4个月也太长了吧，再一个就是上个月曾经下载了一个免费的VPN软件。其它都是从豌豆荚下载，可能性很小。缩小疑问点开始确认。\\n\\n先重新线刷野Rom，并查杀病毒，果然立刻查出一个病毒文件。但是这个文件和上一个病毒的名字也不一样，难道现在的刷机脚本还会在安装时起个随机化的名字了？然后再重装那个免费VPN软件，没有问题。且网上查了下那个VPN软件是个相当知名的软件，看来问题不是在VPN上。\\n\\n这样一来，就肯定可以锁定野Rom了，既然已经查出一个，那很可能就还有别的，永远不要相信杀毒软件报的无病毒假象。因为之前简单研究过安卓的文件布局，重点就落在/system/app和/system/priv-app目录里，并结合Kingroot的预装软件分析结果，陆陆续续找出有5、6个疑似病毒。比如有个叫Boot.apk的程序，居然在app和priv-app下都安装了一份，简直丧心病狂，删！再一个名字叫System.apk的程序，虽然名字很高大上，但安卓怎么会取这么个名字呢，删。安卓apk有个好处，文件内容可以直接看，尤其是AndroidManifest.xml这个文件能看出很多蛛丝马迹。举个例子，有个apk的package写的是com.android.sadk。名字一个就露着古怪，网上只查到一条有人说360报是病毒，但其它没有报。宁可错杀不能漏过，删。还有个APK，minSdkVersion居然是8，正常至少也会是15以上吧。用这么低的版本图个啥？删。还有个APK，居然申请了DELETE_PACKAGE权限，靠就凭这点，不是病毒都把丫给删了。如是断断续续地看了两天，把所有名字可疑的APK看了个遍，到后来几乎要对PicoTTS下手，还好查到svox是被google收购的公司，才放过一马。不过其实就算删了，对我日常使用也没什么影响。\\n\\n回想起来，最大的问题还是我自己大意了，之前虽然也听过野Rom的各种危害，但没往深处想，被自动打开流量开关也没在意。直到被自动订阅增值服务扣了6块钱才醒觉被人当了羊沽。幸运的是一方面自己多少还对系统有点了解，加上安卓毕竟比Windows要简单得多，什么dll注入，二进制感染似乎还没有发展起来（或许是我不知道），要清除还是容易多。对不想折腾的人，建议还是买iPhone算了。\\n\\n手机对于现在的人，已经关联了太多的隐私和金钱，这个很多人已经说得很透了。所以在这上面，投入再多的安全性关注都是有必要的。至少我自己的主手机就是iPhone，安卓上装的无非就是新闻、阅读和游戏之类的app。但这次事件之后，我也感觉到后怕，今天我还有精力去逐个APK查看是否可疑，未来还有这样的精力去做吗？安卓Rom我是不敢再刷了，下一部手机，我想也只能换iPhone（或者Nokia的1系，不知还能不能买得到），安卓终究只能作为一台游戏机般的存在了。\\n"}'));jctx.push(JSON.parse('{"id": "160515", "tag": "design", "text": "# 我对两种同步异步的认识\\n\\n网络编程中经常会遇到如上四个概念，网上也有很多讲解，我想讲一个\\n至少是没有看到过的提法。\\n\\n先给我的认识：\\n\\n* 同步异步：针对的是函数调用者，即caller而言\\n* 阻塞非阻塞：针对的是函数实现者，即callee而言\\n\\n先说阻塞非阻塞，落实到代码就一句话，文件句柄有没有设置过`NONBLOCK`。\\n一旦设置了`NONBLOCK`，则耗时的网络操作就不会等待，立即返回。\\n因此函数就不会**阻塞**在网络IO上。由于默认的文件句柄都是BLOCK，\\n所以对这概念需要一点时间来理解。\\n\\n同步异步说的是业务层的一种逻辑做法，它的前提就是函数区分了阻塞和非阻塞。\\n由于函数的实现有了阻塞和非阻塞的区分，一旦调用非阻塞函数，\\n看起来函数是返回了，但结果却还在网络的另一端，此时有两种做法：\\n\\n1. 等着消息返回，不停地查询IO结果，等结果出来了流程再继续走下去\\n2. 先做别的事，等消息返回了再回过头来处理这个非阻塞的消息\\n\\n1的做法，是同步，而2的做法，则是异步。\\n\\n从上面可以看出，由于调用阻塞函数只能等待，因此一定是同步调用。\\n只有非阻塞函数才会出现同步和异步两种情况。虽然理论上非阻塞函数\\n可以按同步的方法做逻辑，但这样一来就与调用阻塞函数没有区别，\\n体现不出非阻塞函数的优点，因此实际运用时，\\n非阻塞函数通常都是按异步模式来处理。\\n\\n异步模式最明显的风格就是设置回调函数，原因很明显：因为不知道什么时候\\n非阻塞函数会返回，所以只能把一个callback函数往下设，由下层来回调这个函数。\\n由于这种写法不符合普通人的逻辑，因此异步的逻辑很不好写。\\n也有人会将非阻塞函数按同步的逻辑来写，就是常说的异步转同步，\\n其实我倒觉得更严谨的说法，是同步地调用非阻塞函数，更准确。\\n\\n另外针对回调函数不直观的做法，业界也有诸如coroutine，promise等方案，\\n可以做到看上去像同步的写法，但实质上并不会导致CPU空转的做法，\\n这块还没研究透，就先不铺开了。\\n\\n再说说同步回调和异步回调\\n\\n程序中经常会遇到钩子函数和回调，这里就引申出回调函数何时执行的问题。一个函数最终都会在确定的线程中执行，先考虑触发形式的回调，执行触发逻辑的线程，和回调函数执行线程是否在同一个线程，就分为了同步回调和异步回调两种类型。\\n\\n同步回调方式，比如外部触发一个notify，所有注册的回调函数就会在notify的内部依次执行，所有都执行结束notify才会返回。坏处是notify可能会等待很久，但是逻辑非常清楚，调用者可以很确定地知道注册的回调业务执行完毕，在notify之后可以放心地做其它工作。\\n\\n与之相对应的是异步回调，这时触发notify可以很快返回，然后另一个线程就会被唤醒，但因为另一个线程什么时候开始执行，更重要的是什么时候结束是完全无法预测的，导致notify之后业务状态不确定，很多的复杂逻辑是无法开展的。\\n\\n这两种回调，在公司代码中都有体现，其中异步回调是网络框架的Close和`handle_close`，这也是一个初学者经常犯错误的地方，由于Close之后什么时候执行`handle_close`未知，也就不能在Close之后对NetHandler做任何操作，一旦赋值或delete就很容易招来死机。同步回调则是上层的事件中心notify，触发事件后，把所有注册函数执行完才返回，从调用者来看，notify之后，至少业务是完了状态，不过回调函数的成功或失败状态无法返回，不过到底要不要返回，似乎也无必要。\\n\\n至于定时回调，比较多的是有个独立线程进行异步回调。但也有单线程模式下在同一个线程内回调，如果业务执行得比较久，定时器的精度会比较成问题。"}'));jctx.push(JSON.parse('{"id": "160522", "tag": "web", "text": "# Url Rewrite和PHP路由的初步认识\\n\\n使用PHP开发网站，最基本的做法是将Url路径指向某个php页面，然后通过GET或POST方法向这个页面传递参数来实现。如果是GET方式，Url通常是这样(POST因为Url上看不出什么，不在本篇讨论之列)：\\n\\n* web.site/index.php?key1=value1&key2=value2\\n\\n这种风格比较基本，但存在一些问题：\\n\\n1. 如果Url固定后不允许更改(在大型系统内很正常)，则后期重构会受到限制\\n2. 代码实现时会不自觉地受制于这种模式，很难做到逻辑分离\\n3. 风格不够Restful，内容没有资源化\\n\\n因此我看到业界更提倡的方式，是转化成这样：\\n\\n* web.site/key1/value1/key2/value2\\n\\n显然这种Url是无法直接定位到PHP脚本的，必须要借助Url Rewrite。Apache和Nginx都支持Url Rewrite，除了可以通过配置文件进行设置，\\nApache还可以在每个目录下通过.htaccess文件进行自定义，也更灵活。\\n别小看了.htaccess自定义，如果你使用的是虚拟主机，根本没有可能去修改Web服务器的主配置，这时想做Url Rewrite，修改.htaccess几乎是惟一的方式。在.htaccess中配置这样一条规则 `RewriteRule !\\\\.(js|ico|gif|jpg|png|css)$ index.php`\\n\\n意思是把所有不是js、css等结尾的Url请求，统统重新定位到index.php文件。\\n经过这一步，请求就进到PHP的处理领域了。这个index.php并不是通常意义上包含内容的首页，而是一个动态分发器。\\n先把Url进行分解，这里你可以自定义分割符，最传统的是\'/\'，当然也可以用一些古怪的符号，不过我不建议这么做，毕竟会造成理解上的困难。\\n如果有些虚拟服务商不允许改写web server的配置，也可以手动地使用index.php/key/value/param的Url风格。\\n\\n## 超小型框架CEPHP的实现\\n\\n把Url分解成数组后，CEPHP的做法比较死板，取数组的[0]为class名，[1]为method名，后面的就做为参数传递给method了。做了这样的转换，后续就可以对数组如何创建对象做些重定向。\\n\\n通过Url得到class名，接下来的关键是如何实例化这个class。直接new一定会提示找不到类定义，就必须依赖语言的动态特性。这里岔开提一句，从表达力上来说比较公认的是Lisp > Ruby == Python > PHP。PHP在灵活性上能和Ruby比肩的也只有OO方面，而函数级别的魔性还是远不如Ruby的。\\n\\nPHP5支持`__autoload`函数，随后的SPL又定义了6个`spl_autoload`开头的函数，其中`spl_autoload_register`且于替代`__autoload`。它能接受一个string表示的函数名，在new的时候使用register的函数去寻找类的定义。除此之外用define给`CLASS_DIR`赋值，再配合`spl_autoload_extensions`也能正常地工作。\\n\\n说完了类，再说method。PHP的类支持包括`__construct`/`__call`在内的多种魔术方法。比如实现了`__call`方法，如果调用的方法不存在，就会fallback到`__call`的实现，然后根据第一个入参即方法名，可以决定要如何处理这个请求。这个特性在Ruby称为`method_missing()`方法。\\n想像一下通过这个特性，像getByName、getById、getByAge这三种Url就可以只实现一个getBy方法，然后把Name、Id、Age作为参数传递到getBy方法中，非常简洁。\\n\\n## YXcms的路由实现\\n\\n基于CanPHP的二次开发系统，路径使用index.php?r=default/column/index&col=demoshow风格，估计是为解决在虚拟主机上无法直接配置的缘故，方便一些小企业。index.php入口首先reqiure了protected/core.php并执行run函数。按顺序最关键的两个函数urlRoute和autoload。\\n\\nurlRoute将`$_REQUEST[\'r\']`拆分成app/controller/action三级并用define函数保存，如果没有则分别赋予默认值default/index/index。app似乎是区分Mobile或PC。接着注入的autoload，定义一个array，其中包含9条类名到文件路径的映射。用foreach逐一匹配，一旦匹配就加载这个文件。为什么要设置这么多路径？一方面不会把所有的类放在同一个目录下，另一方面由于是二次开发系统，要保留原有框架的autoload机制，用多路径逐条匹配就成了很好的选择。最后用controller拼接上\\"Controller\\"作为类名，通过`class_exists`判断是否存在，存在则构造对象并调用action方法。默认的首页路径映射到indexController.php，它又层层继承向上5次才能找到根类，每次类声明时的extends语句，同样会触发autoload。\\n\\n默认的controller动作是display，需要用于模板引擎的知识，暂时放一放，从构造函数跟踪进去发现又new了baseModel类，最终使用了CanPHP的cpModel类。"}'));jctx.push(JSON.parse('{"id": "160601", "tag": "security", "text": "# SSL杂记\\n\\nSSL和OpenSSL的关系，就好比C++和Visual C++的关系。OpenSSL是业界公认的烂代码，但也许是出来比较早，在江湖上已立稳了脚跟，因此尽管有很多人不爽，但毕竟现有项目大量的依赖，就我所知的一些fork项目都是采用头文件兼容，而重新实现的方式，也许若干年后OpenSSL会变成一个接口标准，那也是后话了。\\n\\nOpenSSL库在Linux下就一个文件，而在Windows下是分为libeay32和ssleay32两个文件，其中libeay是和加密算法相关的，包括AES、RSA、MD5等，而ssleay则是SSL握手、网络收发数据相关，因而需要依赖于libeay。取这么怪的名字是因为最初的作者是Eric A. Young而得名。\\n\\n用vc6编译openssl，自带perl脚本生成makefile，但还是有很多遗漏，有两点\\n\\n1. ms目录下有个文件要加no-asm，否则自带的汇编文件在vc6的masm无法编译，类似编nginx也遇到过md5和sha1有使用汇编的选项，大概hash类算法规律，用汇编效率提升明显。\\n2. 编译要加’__i386__\'选项，否则编crypt库会有链接错误，原因不明国内网站没有答案，是在英文站上看来的，不确定是否ssl部分也需要。\\n\\n## 实现SSL连接(PHP为例)\\n\\n在我的安卓手机上运行PHP，由于域名解析机制不知什么原因，无法正常工作，只能先在PC上解析出IP，用PHP的socket机制完成连接。如果是HTTP连接使用\\"tcp://ip\\"的方式，再手工构造HTTP的GET请求，网页的内容就拿到了，如果是HTTPS则麻烦一点。\\n\\n首先PHP支持\\"ssl://ip\\"或者\\"tls://ip\\"，虽然看起来是不同的协议，但至少我安装的PHP环境发起的Client Hello请求都是TLS1.0(请求包头是16 03 01)，但是握手结束PHP会报类似这样的错误 `Peer certificate CN=`example.server\' did not match expected CN=`ip\'`\\n\\n原因是TLS连接时服务端会发送它的数字证书，证书的CN(CommonName)记载的内容和请求的IP地址不符合。\\n\\nfsockopen是PHP4时代的接口，设计时并没有考虑传入SSL连接的选项，到了PHP5，提供了整套Stream Classes，包括了socket、context、filter、bucket等完整的网络连接设施。这些中可以用`stream_socket_client`函数，配合最后一个参数`stream_context`。使用`stream_context_create`构造一个不做检验的TLS请求(内网很多证书都是自签名，必须要跳过)，构造语法array(\'ssl\' => array(\'verify_peer_name\'=>FALSE, \'verify_peer\'=>FALSE)); 同时关闭验证证书和CN。这里的verify_peer_name是配合peer_name选项，允许用户对站点设置指定名称。\\n\\n题外话，不同的语言都提供类似的操作，比如Go提供了InsecureSkipVerity:true关闭校验。默认情况会提示x509: certificate signed by unknown authority。\\n\\nSSL_connect并不关心证书校验，成功返回后可以对SSL结构体进一步分析，有60多种X509_V_ERR_的定义，对DEPTH_ZERO_SELF_SIGN_CERT会网开一面，否则不予承认这个连接。\\n\\n注意必须是二维的array结构，而且这里只能是ssl，如果传入\'tls\'无法构造合法的context。一切准备妥当就可以完成SSL握手了，接下来在这个连接上发送HTTP的GET请求，对读和写数据来说就是透明的。\\n\\n`stream_context`由option和parameter两部分组成，option除了前面提到的ssl，还有socket/http/ftp。parameter目前我只看到一种notification，用于设置回调，在`STREAM_NOTIFY_*`事件发生时触发回调。context不仅能用于stream，也能用于fopen和`file_get_contents`。\\n\\n再来分析TLS握手流程，从数据上看客户端发送的数据要远小于服务端回复的数据，大约是<1K和5K这个量级。原因是服务器会带回完整的证书和cipher list，而客户端只做验证并选择一个cipher方式，因此数据量才会有这么大的差距，其中光是Server Hello中的Certificate环节的内容就长达2960字节。握手结束服务器会生成session ticket，长度192字节，有效期18小时。"}'));jctx.push(JSON.parse('{"id": "160611", "tag": "web", "text": "# PHP与Web服务器的集成方式\\n\\nPHP早期作为Web开发语言，监听HTTP请求并不在PHP做（虽然可以用-S选项来监听http请求，但毕竟不专业），产生环境中往往是由Web服务器(如Apache或Nginx)完成，当检测到是一个动态网页的请求，比如Url的后缀是.php，则把请求转给PHP程序，由它来处理后续的工作。在Windows上个人觉得比较好的集成工具是[PhpStudy](http://www.phpstudy.net)，集成了Apache/Nginx/Lighttpd等多种服务器(最新的2016版把Lighttpd去掉了)，而且支持多种PHP版本，就以PhpStudy安装后为例，分别说说两者的集成方式。\\n\\n## Apache\\n\\n官方标准的方式有三种，经常用到的有两种(CGI基本用不到，完全被FastCGI替代)。分别是\\n\\n* 作为Apache内建模块运行，官方文档称为handler方式\\n* 以FastCGI方式运行\\n\\nhandler方式就是在httpd的worker进程直接执行php程序，这种方式的配置会加载一个php-sapixx.conf文件(PhpStudy的写法，非官方)，xx是PHP的版本号，\\n比如55、70等。从conf文件可以看到，其通过LoadFile和LoadModule指令加载了php5.dll和php5apache2_4.dll。数字随着使用的版本而变。\\nLoadModule直接和Apache交互，从dll名字也可以看出，包含了php和apache两个程序，像PHP这么复杂的应用，不可能完全通过module代码完全实现，\\nmodule更像是个桥接器，真正的任务还是要通过PHP来完成，因此和LoadModule配套，还要用LoadFile指令载入php5.dll，负责真正的PHP执行代码。\\n另外PHP5.2版本，还通过LoadFile载入了libmysql.dll。也许是PHP和MySQL没有打通吧。如果module载入成功，通过\\n\\n`PHPIniDir \\"D:/phpstudy/php52/\\"`\\n\\n这句指令来设置php.ini的路径。(命令行的php方式可以使用-c选项，在宿主环境下就要配置了)。岔开一句，载入lua扩展只要LoadModule就可以，不需要LoadFile来指定lua.dll的位置。\\n遍观所有配置，除了PHP的SAPI方式，也只有httpd-proxy-html.conf配置，用了LoadFile来加载zlib.dll,iconv.dll,libxml2.dll。\\n\\nFastCGI方式则不同，需要先加载FastCGI的运作器，注意模块名是fcgid，而不是fastcgi，这是两个不同的项目，差别我引用网上的说法：\\n\\n> `mod_fastcgi`因为实现方式的限制，所以可能会创建了很多不必要的进程，\\n  而实际上只需要更少的进程就能处理同样的请求。\\n  `mod_fastcgi`的另外一个问题是每一个CGI的多个进程都共享同一个管道文件，\\n  所有到同一个fastcgi的通讯都通过这个同名的管道文件进行，\\n  这样当出现通讯错误的时候，根本不知道正在通讯的是哪一个fastcgi，\\n  于是也没有办法将这个有问题的进程杀死。\\n\\n> `mod_fcgid`尝试使用共享内存来解决这个问题。共享内存里面有当前每个fastcgi进程的信息\\n  （包括进程号，进程使用的管道文件名等），当 每次尝试请求fastcgi工作的时候，\\n  Apache将会首先在共享内存里面查询，只有在共享内存里面发现确实没有足够的fastcgi进程了，\\n  才会创建 新的进程，这样可以保证当前创建的进程数量刚好能够处理客户的请求。\\n  另外，由于每一个fastcgi进程使用不同名称的管道文件，\\n  所以可以在通讯失败的时候知道到底哪个fastcgi进程有问题，而能够尽早的将其剔除。\\n\\n所以现在apache官方推荐使用的模块就是fcgid了。有一个专门的fcgid.conf文件，fcgid的参数很多，\\n比较典型的，如FcgidMaxProcesses表示最多允许打开多少个进程。由于参数由Apache来读取，创建进程，控制进程的数量也同样是Apache。\\n所以这种模式下可以看到的httpd进程中，有些并不是执行Web请求，而是执行PHP的宿主。有了宿主，接下来就是找到PHP并执行，和php关联的是这句指令\\n\\n`FcgidWrapper \\"D:/phpstudy/php55n/php-cgi.exe\\" .php`\\n\\n把请求直接导向了php-cgi程序。php-cgi本身就依赖于php5.dll，\\n因此FastCGI方式下不需要通过LoadFile来载入php5.dll。指定php.ini仍然不能少，通过\\n\\n`FcgidInitialEnv PHPRC \\"D:/phpstudy/php55n\\"`\\n\\n这种方式，Apache会常驻进程，减少每次请求的创建进程开销。fcgid的耦合度比Handler方式更小，体现在\\n\\n1. httpd进程的作用分离，Web请求和PHP执行在两个进程\\n2. 载入PHP方式，从.dll换成了.exe，从而避免了代码的强耦合。换句话说，Handler方式必须依赖php5apache2_4.dll，而CGI方式调用PHP的程序即可。\\n\\nHandler和FastCGI的方式，进程的所有者都是Apache，随着PHP自身的演化，5.3.3版本后的PHP官方代码也支持FastCGI模式，就是PHP-FPM(FastCGI-Process-Manager)，\\n这个包还没有windows的移植版本。从命名就能看出，它是一个进程管理软件。\\nPHP-FPM是daemon程序，它启动一个进程池，和Web之间通过监听TCP端口或Unix域套接字来进行通信。\\n并会随着负载大小动态地增加或减少进程数量(可配置)。因此Apache的2.4版本之后，又增加了一种模式`mod_proxy_fcgi`，这种模式下Apache不需要知道PHP的文件或库位置，只管把请求发到指定的端口或域套接字就可以了。\\n\\n## nginx\\n\\n与Apache相比，nginx官方实现不支持动态载入模块，所有的功能都需要在编译时指定，也就没有对应Apache的handler方式一说。\\nnginx也没有和PHP做整合，在nginx里不会看到PHP路径配置，仅支持类似Apache的mod_proxy_fcgi配置方式，由于Windows版本没有PHP-FPM，因此运行PHP并监听端口，通过phpstudy这个管理程序来实现。\\n\\n从nginx的配置可以看出，在和PHP通信时，有大量的fastcgi_xx的指令。其中的`fastcgi_param`指令，就对应CGI规范中的Request Meta-Variables。\\n比如`SRIPT_NAME`、`QUERY_STRING`。这些值需要在nginx.conf中设置，nginx会把`fastcgi_param`设置的值传递到PHP。从而在PHP中`_SERVER[\\"SCRIPT_NAME\\"]`的方式可以取值。\\n\\n比起CGI的RFC规范，PHP可用的Meta-Variables要多一些。比如RFC只定义了`SCRIPT_NAME`和`QUERY_STRING`，\\nPHP多定义了`SCRIPT_FILENAME`和`REQUEST_URI`。`REQUEST_URI`是`SCRIPT_NAME`和`QUERY_STRING`的字符串连接。`SCRIPT_NAME`和\\n`SCRIPT_FILENAME`的差别在于`SCRIPT_FILENAME`是绝对路径，nginx中一定要通过指定`SCRIPT_FILENAME`才能真正调用到PHP脚本，`SCRIPT_NAME`就是相对路径了。\\n\\n现在RESTFul大行其道，以资源形态表示的URL上，是肯定不会看到script.php的字样的，最直接的做法，就是在nginx配置这样一句：\\n\\n`fastcgi_param  SCRIPT_FILENAME  $document_root/script.php;`\\n\\n也就是说虽然在URL上看到的只是个资源，但是到了Web端仍然是对应到具体的PHP文件。在这个script.php中可以再从`REQUEST_URI`分离出资源信息，\\n从`REQUEST_METHOD`得到操作信息，这样就可以完成资源到操作的转换。因为CGI出现的背景就是执行独立程序，因此规范直接定义`SCRIPT_NAME`就不奇怪了。如果请求报错no input file，说明nginx找不到php文件所在位置，一种解决方法是用root指令设置完整的根路径，保证`$document_root`值是对的。如果不设置root，默认会指向nginx程序所在的html目录，再以这个为根，自然就找不到php文件。\\n\\n像`REQUEST_URI`这种值，其实都是由Web服务器来设置的，如果不在RFC规范，就完全看Web服务器的实现了，因此会有些框架做些兼容处理。\\n\\n## 小结与比较\\n\\n比较两种Web服务器的加载后进程列表，选择apache启动方式，进程管理器只能看到数个httpd进程，而选择nginx的话，除了nginx还能看到数个php-cgi程序。\\n原因就是apache的FastCGI方式是以自身程序模块在运行，在httpd进程中执行php程序，因此进程管理器看不到php的名字。而nginx更有代理的味道，把请求数据向php-cgi监听的端口送去后，就和nginx无关了，因此php-cgi是以独立进程方式存在。\\n\\n这方面还遇到过一个奇怪的问题，本地调试网页用httpd正常打开，用nginx却总是超时。nginx下php-cgi默认分配的是9000端口，于是用netstat -ano查了到底哪个进程占用了9000端口，果然这个端口被其它程序给占住了，但是phpstudy并不会报异常，也就表现在nginx超时，如果用openresty方式运行就不会有这个问题，因为openresty也是类似httpd方式，直接在nginx内执行业务逻辑。\\n\\n"}'));jctx.push(JSON.parse('{"id": "160621", "tag": "design", "text": "# 我理解的面向对象设计原则\\n\\n面向对象的程序设计和面向对象的程序语言，两者并不完全一样。\\n面向对象的程序设计是一系列原则，是指导思想；而面向对象的语言，则是把这些原则和思想，用一些规范化的语法给规定下来。\\n\\n初学面向对象时，教科书都会提三大概念：封装、继承、多态。\\n但是我的理解，这里面只有多态才是面向对象的核心观念，继承分接口继承和实现继承，接口继承勉强算是，实现继承则不算。\\n而封装更是和面向对象关系不大。\\n\\n## 面向对象设计的几条重要设计原则\\n\\n* 开闭原则(Open-Close-Principle)\\n* 里氏替换原则(Liskov Substitution Principle)\\n* 依赖倒置原则(Dependence Inversion Principle)\\n\\n除了这三条还有许多，但我觉得这些就够了。这其中最原则性的，就是开闭原则。即**软件要对扩展开放，对修改封闭**。我对这句话的解读是：**当你修改了代码并替换后，其它的使用者是感知不到的。**\\n上面这个例子中的开放，就是对代码做修改；而封闭，就是使用者感知不到。在《松本行弘的程序世界》和陈天的《谈谈编程思想》中，也都认为OCP是最根本、最基础的原则。\\n\\n从刚才的说明来看，就是在交互的双方之间，要保持接口的一致性。好的接口不是泛泛而谈功能，\\n不是任意地扩展参数，而是在屏蔽细节的基础上，完成具体而明确的行为。比如接口是阻塞或是非阻塞的，出现错误时是返回错误码还是抛异常，这些都是要明确的，而接口的大O值是O(N)或O(logN)，则是偏重实现层面。\\n其它的里氏替换原则说的是怎么界定基类和子类，依赖倒置则是说细节要依赖于抽象，抽象不应依赖于细节。相比之下都是更具体的操作手法。\\n\\n因此只要能实现OCP原则的语言，就完成了最核心的功能，都可以称之为OO语言。\\nC++实现OCP的机制是多态，但多态从语法层面是强依赖于继承的，而C++的继承又只有实现继承，\\n因此多数人会自然地关注类的特性，偏偏C++的类有public、protected、private关键字，且非常直观易懂，导致很多人在入门的时候\\n把认知的重心放在封装上。加上对象二字又和现实世界中的具体的实体对应，\\n这又强化了面向对象即封装的认识。其实很多动态语言，根本没有提供封装的语法关键字，但不妨碍很优雅地实现OCP。\\n\\n很多教科书在讲授面向对象时，都用鸟能飞，于是继承自鸟的子类大雁也能飞，但一碰到企鹅就傻眼了。\\n我反倒奇怪，为什么很少有教科书拿Duck Typing作例子，如果一种东西能飞，\\n那它就是一只抽象的鸟，即便它其实是飞机，又有什么关系呢，反正它满足了我们对于飞的期望，而且比鸟飞得更好。\\n\\n以上讲了面向对象中最核心的概念是开闭原则，接下来结合我的经历说说这个原则的具体应用。\\n\\n先说句题外话，在面向对象思想发展之前，讨论更多的是结构化编程思想。\\n今天已经很少有人提了，但是并不代表结构化编程思想过时，而是两者的出现时代，要解决的问题不同。\\n结构化编程的年代，代码规模还很小，也没有什么代码规范，更多的时候都是用汇编甚至机器码写程序，因此怎么抽象机器，\\n怎么规范化地表达程序，是当时重点要解决的问题。而随着结构化思想被众人接受，程序规范化提高，\\n给大规模编程提供了基础设施，使得多人合作完成程序成为可能。这时怎样更好地配合，怎样使软件更稳定，成为了那个时代的痛点(今天依然是)。当人们为解决这些问题时，才催生了面向对象思想。\\n\\n因为多人配合，互相之间不会去关注对方的实现细节，这时接口就成了联系的纽带。要让这个纽带好用，就要满足开闭原则所说的对扩展开放，对修改封闭。\\n\\n比如一开始有这样一个接口：`int getVersion(void* ver);`。\\n这个接口被定下来的时候，ver指针指向的真实内容是`char*`，\\n一段类似\\"2.1.11.3.R\\"这样的字符串。为什么要用`void*`而不是`char*`呢？\\n据说是制定的时候为了扩展性，因为`void*`可以转换成任何类型嘛。\\n\\n果然没过多久，需求就来了，原始版本只能表示软件版本号，\\n可现在需求要SVN版本号，怎么办，扩展呗。把参数改成\\n\\n```\\nstruct Version{\\n  const char* softVer;\\n  uint32_t svnVer;\\n};\\n```\\n\\n因为结构体的第一个字段也是`char*`，所以不影响即有代码。而且能通过`void*`强制转换得到想要的结果。看，当初使用`void*`多么明智啊。\\n\\n可是这样真的对吗，是不是还漏考虑了另一种情况，即使用者已经按struct来使用了，可是因为一些原因，\\n提供实现的人也许漏实现了或者提供错了版本，这时svnVer尽管也能取到值，可是这个值所指向的内存，根本不是期望的内容啊。\\n更正确的做法，是一开始就把接口定义成`int getVersion(struct Version * ver);`结构体的定义类似\\n\\n```\\nstruct Version{\\n  const char* softVer;\\n  int resv[3];\\n};\\n```\\n\\n则使用者在扩展后，即使库没有更新，因为取到的内存值就是0。而0显然是个非法的SVN版本号，使用者可以因此做到区分。\\n\\n那么是不是增加保留位就可以了呢？不够，如何正确地扩展保留位，也是有技巧的。考虑这样一个场景：原来的产品都有NAT穿透功能，\\n因为产品细分做CostDown，为了做到市场区分，部分产品从软件层面屏蔽了该功能。可是界面需要根据是否有NAT来配置界面啊，那就继续扩展吧。\\n增加一个`int8_t hasNAT`？可是这样就不对了。因为原来的产品其实是有NAT的，按hasNAT的意思，原有产品都得修改代码这样，这就增加了无谓的工作量，\\n所以正确的扩展应该是noNAT，这样才是对修改关闭的。说来简单的一个小技巧，可从我的经历来看，却很少有人注意到。\\n\\n在我刚工作不久的时候，我的主管和我说：在做大型项目的时候，一定要有面向对象思想。\\n那时我的对面向对象还停留在类、封装这些概念上，并没有体会出面向对象在大型项目里有什么应用，今天想来，也许就是想说在大型项目中接口的重要程度吧。"}'));jctx.push(JSON.parse('{"id": "160718", "tag": "lang", "text": "# 几种语言作用域的比较\\n\\n## 起因\\n\\n一段lua程序\\n\\n```\\nwhile do\\n  local ctx = ...\\nend\\nsaveToFile(ctx)\\n```\\n\\n程序执行到最后，总会报一个写入nil的错误。我一度以为是在处理数据时没有赋值，但反复核对都没有遗漏，\\n最后也不知怎么就想到可能是执行saeToFile函数时，ctx出了while作用域，导致引用了一个新的变量，这时ctx就是nil。\\n果然尝试把ctx的local限定词去掉，程序就执行正常了。\\n\\n## lua\\n\\n这个疑问引起了很大的好奇，在C语言里，变量的构造和使用是严格区分的，带了类型就是声明变量，而不带类型则是使用。由于动态类型语言没有类型，该如何区分？重新看了Lua的手册，local的说明中有一句：Notice that each execution of a local statement defines new local variables.\\n说明用local声明的变量，是定义(即创建一个存储位置)。那么没有用local声明的变量，文档中并没有明确的说明，按我的理解，没有local则是变量查找。\\n\\n如果这个scope之前有local定义或是同名变量，则引用已定义变量。如果没有，由于Lua的可见性是内部可以看到外部，\\n即`_ENV`层层向外的链表结构，在本层找不到，会向外部寻找，直到最外层的global范围。如果global也没有的话，\\n就会自动在global创建这个变量。可见沿着`_ENV`向上查找才是本意，找不到情况下创建变量只是个副产物。\\n因此Lua语言中尽量使用local的意义就在于，避免对外部环境的污染。又或者不经意间就修改了同名的global变量(在好的编码风格中不太会发生)。\\n\\n如果拿Lua的local和JavaScript的var相比较，作用很相似，带var表示定义一个变量，没有var则是向上查找，\\n同样也会在全局空间创建该变量。(但是注意，这两门语言的祖先Scheme，却不允许这种未经声明的变量访问。\\n当然如果改写Lua中顶级_ENV的元表或是修改js的prototype，也能达到同样效果，只是默认是允许而已)。\\nJS的编程风格也一直倡导要尽可能用var定义变量，防止不经意间污染全局空间。\\n但是JS的作用域中没有block作用域这一层，因此对照上例，即使在while内用var定义变量，超出while的语法作用域，仍然访问到。\\n除非到了function定义结束标识，这个变量的作用域才结束。\\n\\n## JS\\n\\n作用域混合了动态和静态两种，用this捕获的变量是上下文决定，或者说可以用apply指定。非this捕获的变量是静态的词法作用域。动态作用域臭名昭著，定义lambda语法时，就限定了这种情况下的this是静态捕获的。固然好，但一个this有两种作用域，很多人是迷惑的。\\n\\n## PHP\\n\\n作用域和JS有点像，只有function能创建新的作用域，花括号不构成块作用域，但比JS更弱的是，PHP不能链式地向外查找变量。有人说因为解释器用了barrier方式控制变量的绑定，取巧地控制变量的解析规则，这样实现很简单。他认为，严格意义上PHP没有作用域概念。\\n\\n在PHP函数作用域内无法直接看到外部定义，所以PHP增加了global关键字，表示这个变量是向最外部环境的引用。以下两句话的效果是一样的。\\n\\n```\\nglobal $var;\\n$var =& $GLOBALS[\\"var\\"];\\n```\\n\\n同样，用unset($var)也不会影响全局变量，因为只是删除了局部作用域内创建的引用变量而已。\\n\\n但是global关键字的局限也很明显，试想定义一个嵌套函数，在内层嵌套中想访问外层函数，但非全局变量，就没有办法了。\\n只能在访问全局变量或者访问本函数定义变量中二选一。\\n至少我在PHP5.6版本，是无法实现内层函数访问外层函数变量的效果。\\n因此PHP也不是一个lexical scope的语言（Lua和JS是的）。在闭包的实现时，\\n需要用和global类似的use语句，才能实现向上一级的变量引用。但也不能等同于穿越作用域，而是在这个函数域内新建变量而已。\\n至于use中使用&，是被Scheme放弃的动态词法范围语义，在PHP和C++11中，都还是被保存了下来。\\n\\n链式访问我能想到的典型应用是用函数来实现对象，即让函数有状态。Lua或JS通过定义一个函数，并返回这个函数内嵌套定义的另一个函数来实现。\\nPHP无法链式访问，但和C语言一样，支持函数内的static关键字，使得函数可以记录一些状态。但是PHP创建的函数，无法多次实例化，而且PHP虽然可以在函数内嵌套定义函数，但语法的限制(变量必须带$前缀，函数没有，类似lisp-2的双命名空间)，不能返回这个函数，也就没有很多烧脑的写法。\\n从灵活性来看，使用static变量的函数显然是弱于链式访问构造的闭包。\\n\\n**PHP虽然加入了namespace机制，但只能保护类、函数、常量。global访问的变量，仍然共享全局命名空间。**\\n\\n## Python\\n\\n没有块作用域，也没有链式作用域。Py3加入了nonlocal，可以在定义空间向上访问。\\n\\nPython的global关键字，和PHP有两点区别。\\n\\n1. Python只能访问全局空间的变量，加上global的目的，是未了改写这个全局变量，如果以只读方式用这个变量，不需要加global。\\n1. Python的global只能访问这个文件的命名空间，相当于寻找module内的变量\\n\\n## Ruby\\n\\n由于语法要素没有花括号，没有块作用域，遇到module/class/def这三个关键字会打开一个新的作用域，这个作用域和外部是隔绝的，无法链式向上级访问。这就造成一个很奇怪的现象，class内定义def却不能访问def外的局部变量。不过Ruby的思想是用`@`代表实例变量，`@@`代表类变量的方式来控制。而不是简单的局部变量。加上Ruby的全局变量用$表示，就造成了Ruby有四种变量命名的特色。\\n\\n如果想打破常规的作用域，可以用Module.new/Class.new/define_method这三个等价的方法名来替换关键字，使作用域平铺。\\n\\n## 环境和实现\\n\\nSICP介绍计算模型有个很重要的概念环境。在教学概念中环境是个链接，当前函数栈帧是链表的最末端，如果当前环境找不到变量unbound，会向外层层寻找。\\n\\nlua的环境没有使用outer的概念，但mujs为求简单是这么用的。catch和with会创建新env并用outer指向当前环境，JS除了这两个关键字，callfunction会创建，等执行完再restore旧环境。\\n\\n## 总结\\n\\n从作用域访问灵活性看：Lua/ES6（有块有链式） > ES5（无块有链式）> Python（无块有受限链） > PHP/Ruby（无块无链式）\\n\\nPython和Ruby本来就没有块作用域的语法要素，比较有无块作用域有失公允。"}'));jctx.push(JSON.parse('{"id": "160812", "tag": "design", "text": "# 接入协议、账户体系和权限\\n\\n视频监控行业有个Onvif协议，作用是通过这种协议来控制设备。\\n由于Onvif是个行业级的通用标准，修订比较漫长，甚至很多定制的协议根本不可能纳入Onvif标准。\\n一般稍大一些的厂商，都会有自己的接入标准。对于网络接入来说，\\n因为涉及权限，就一定有身份概念。对存在两套接入标准的设备来说，\\n账户体系究竟该怎么设置，这是本文想讨论的问题。\\n\\n如果把Onvif仅仅看成是一套XML格式的网络接入协议，那么它就和账户体系没有关联，\\n但是Onvif标准定义了4种用户组，同时也规定了每个组所对应的权限，\\n而账户，或者说身份，应该包括完整的四层概念，又名4A。\\n包括Account、Authentication、Authorization、Audit。由于Onvif定义了登陆的加密方式，\\n和登陆后的权限定义，包括了Authentication和Authorization这两级。\\n也就是说是有完整的账户体系的。\\n\\n而厂商如果也定义了账户加密方式和权限，且两者不能一一对应，这时两种接入协议，\\n就可以认为是两套独立的账户，互相并不干扰。即使能对应，也只是为了简化模型而做的优化。\\n从这个角度再去看产品的逻辑：第一次用admin登陆会提醒用户修改密码，\\n同时把这个密码也同步到Onvif账户的admin(注意这里只是恰好重名而已，\\n完全可以做到一个体系用root作为管理员名称)。而后续对admin的修改，并不会同步到Onvif。\\n因为第一次，可以认为是用户的初始化动作，做一次自动同步是出于简化操作的目的。\\n而当用户体系已建立，从一个账户体系下修改另一个体系，显然就不合适了。\\n\\n但这种做法最初我是很困惑的：私有协议和Onvif协议只是一种接入方式，和用户没有关系，\\n既然要做密码同步，就应当每次都同步，或者不同步，同步一次这种半调子的行为，让我非常难理解。\\n\\n但是看了Kerberos的一些介绍后，对这个问题重新理解后，觉得应该是这样的：\\n客户端希望向服务端申请做一些业务，服务端需要对这个申请作一个判断，\\n是否允许客户执行这个操作。即客户提供一个双方都知道的信息，当这个信息被验证后，\\n才会让客户去执行。在这里用户名和密码，除了证明客户是否作假，\\n有了一个更重要的作用，即业务的授权性。\\n甚至更进一步，把用户名这种带有强烈倾向性的命名，换成服务名理解起来会更容易。\\n客户端向服务端提交一个服务名和密码，服务端验证后，允许操作。\\n又因为服务端提供了很多种服务，如果把服务种类分得太细，\\n会导致客户端不停地验证，比较烦琐，此时把多个服务名称合并成一个，\\n产品把这个多合一的名称取名为用户名，就造成了一些概念上的混淆。\\n\\n那么在广义的C-S模式下，这个会话开始之初发送的名称、密码究竟归属谁呢？\\n这就取决于业务形态和资源的归属了。\\n\\n对监控相机而言，所提供的服务主要是音视频流，或者磁盘的存储功能，\\n这些都是属于设备，不会因使用者而改变的。\\n这种情况下，建立会话的这个名称就归属服务端，更准确的叫法，应该是服务集名称。\\n\\n再对比经常使用的微信或者QQ，虽然我们发送文字或语音，要经过服务器的中转，\\n但是我们选择发给谁，即这些好友名单并不属于服务器。\\n这些好友都是使用者一个一个地添加进通讯录的，从资源所有权角度看，理应属于客户端。\\n\\n最后来看私有协议和Onvif协议的问题：这两套协议都是在设备上，也就拥有各自的服务集，因此两套体系之间是不能同步的。为什么第一次又要做同步呢？\\n可以理解为产品在发到用户手中，需要做一个初始服务集密码的修改操作，\\n如果不做同步，就要用户操作两遍，显得比较烦琐。为了提高使用便利性，\\n才做了这个相当于全局初始化的动作。"}'));jctx.push(JSON.parse('{"id": "160813", "tag": "lang", "text": "# RAII、智能指针和GC\\n\\nC++作为接近底层控制的语言，天然地要负责资源管理。资源并不单指内存，\\n还包括了文件句柄。从这个角度看，动态语言所带的垃圾回收只管理内存，\\n却不能正确地回收文件句柄。`C++`在长期发展的历程中，实践总结出了RAII这个特性，\\n也是这门语言区别于其它语言的最大特征。\\n\\n在解释RAII之前，先来看`C++`的一个特性：栈上变量的自动析构。\\n`C++`是打着A Class With C的名号发展起来的，类是最初区别于C的地方，\\n通过定义类，然后使用类来创建/销毁对象就是最基本的动作。\\n加之变量可以在栈上分配，一个在栈上分配的对象，在函数结束后由于内存已经被回收，\\n必须要在内存回收前执行析构，所幸这个动作由编译器替我们做了。\\n\\n就是这么个看似很普通的特性，却在实践中发展成了资源管理的最佳方式。\\n试想如果在函数执行过程中，会涉及很多资源(包括内存和句柄)。在执行过程中如果发生错误，\\n需要结束函数并释放资源，如果每次都写if/else，并写上很多重复代码，代码一定很难看。\\n这时就可以把这些需要的资源，封装成一个类，在开始执行前，通过构造对象的方式，\\n在对象的构造函数中获取这些资源，接下来执行逻辑，一旦发生了错误，直接退出函数即可。\\n因为编译器会自动执行对象的析构函数，只要我们写好析构函数，不管在函数的哪个地方出错，\\n相当于编译器都会自动地替我们回收这些资源。\\n\\n这里的构造函数中获取资源，就是RAII：Resource Acquisition Is Initialization。\\n两句话表述的方向不同，但强调的意思是一样的：把构造和获取资源等同起来。\\n\\n刚才给的例子使用栈上变量，那么堆上变量怎么办？办法就是把堆上变量封装成栈上变量。\\n把new的操作结果，作为一个栈上对象的构造参数传递，\\n从而在栈上对象析构时把new的结果delete。而承担了这种任务的对象，就是智能指针。\\n随着使用场景的不同，智能指针又细化出了多种类型\\n\\n* 资源共享型：shared_ptr以及为了解决环形计数而引入的weak_ptr\\n* 所有权控制型：auto_ptr、unique_ptr\\n\\n这些指针的实现方式和差异，各种文章介绍的很多，这里就不细说了。\\n\\n写这篇文章的缘由，是在公司内网看到有人发帖提问，通过一个构造函数的出参返回一个指针好不好？\\n虽然这个问题相当的愚蠢，但我想也许正是因为`C++`的复杂和灵活，才会让这样的蠢问题出现。\\n结合上面的介绍，指针往往代表了一个资源(否则要指针干嘛？)，如果把资源放出来，\\n一定会带来资源的手动管理问题，显然也违背了RAII的最佳实现实践方针。\\n\\n## RAII的感知和函数动态创建\\n\\nRAII无非就是让使用者在退出栈之前，得到一个感知的机会，本质还是汇编层面才能做，所以C语言在这里一点办法都没有。脚本语言的栈是在C层面控制的，因此可以记录和追踪生命周期，但在C语言自身，除非扩展语法，在函数退出前能注入一段行为，才能解决这个问题。\\n\\n延续也类似，在语言层面把运行的流程暴露出来，让人可以介入并控制。C语言的函数不仅不能嵌套定义，也不能在运行过程中定义。所有的函数都被编译到text段，整个生命周期永远存在，这使它比堆上数据就多了一份持久，但也少了运行期动态变化的能力。\\n\\n## Lua的GC\\n\\n使用三色标记法，对象分为白灰黑三种颜色。白表示死对象，可以用白事来简单记忆。经过标记为灰，灰再到黑。剩下的白对象就被收集了。先把所有的对象放在白链上，然后扫描这条链，把能reach到的对象放在灰链，再遍历灰链，把所有对象都mark成黑后，在灰链为空时把白链的对象清空，从而达到垃圾收集的目的。\\n\\nLua对表的GC做了特别的优化。5.1的时代只要表具备weak属性，全放在g对象的weak链处理。到了5.2时代作了细化，weak链被拆成三条链，只有weak value的表记录在g对象的weak，weak key的表记录在g对象的ephemeron，key和value都是weak则记录在allweak。\\n\\n每次扫描时会用sweeplist遍历，最多遍历count次，如果是白对象，则释放它。"}'));jctx.push(JSON.parse('{"id": "160815", "tag": "protocol", "text": "# 协议工作该如何演进\\n\\n协议岗位作为职能部门，工作本身不容易出彩。出了问题会被追责，做得好无非就是不出问题，但不出问题这个标准在组织内部是没有意义的。\\n\\n曾经有比较理想化的言论，协议就像法律，但事实上迫于现场的压力或者设备以出货等名义，妥协是难以避免的。除此之外日常工作中的扯皮、认识不对等造成的心力损耗更是难以承受。\\n\\n首先要尽可能地团结友方的力量，协议分为服务器端和Web及NetSDK两个客户端，Web隶属产品线且经常被界面牵着鼻子走，通常很难想到一起，但服务端和NetSDK作为同在一个楼层的兄弟团队，想法利益往往一致。两种客户端因为服务对象不同，协议风格会产生差异。\\n\\n目前的想法还是要区分Web协议和NetSDK协议，往往Web先定义一套协议，到NetSDK实现时，视情况做一层桥接，不把Web协议直接暴露给NetSDK，而是由服务端调整成更纯粹的协议，实现上可以迁就Web。因此必须要有一支能调动肯拼搏的服务端实现团队作为支撑，否则难以落地。"}'));jctx.push(JSON.parse('{"id": "160930", "tag": "protocol", "text": "# 大华设备协议兼容策略说明\\n\\n大华设备在发展的过程中，产生了二代和三代两套协议。\\n三代协议使用前期由于缺乏管控，同样功能的三代协议会有不同的表现形式，\\n(比如摄像头属性的配置)。且在不同产品线间使用也不一致。\\n另外同样功能也存在三代协议和二代协议的冗余，\\n曾经试图不再使用二代协议，但从市场接受度和技术角度两方面看，\\n这种作法既不可行，也没有必要。\\n但是存在多套协议的混乱局面，必须要明确协议与业务功能的对应关系，\\n本文档定义两套协议的适用场景、及如何选择的原则。\\n\\n## 二、三代协议的使用总原则\\n\\n先来简单看看两套协议的特性：\\n\\n* 二代协议：所有设备都支持，但协议为二进制，Web无法使用\\n* 三代协议：协议扩展性好，支撑业务迅速\\n\\n综上协议总原则：SDK的基础业务使用二代协议，扩展业务则使用三代协议。\\nWeb全部使用三代协议。\\n\\n## 登陆协议\\n\\n* SDK -- 0xA0\\n* Web -- global.login\\n\\n登陆协议作为使用设备的第一步，基础性不言而喻。\\n由于二代和三代协议有各自的登陆协议，\\n但是一台设备显然只需要一种登陆协议就够了，\\n综合考虑设备使用面、协议扩展性，NetSDK使用二代协议作为设备的登陆协议。\\n设备保留三代登陆协议给Web使用。\\n\\n## 音视频类协议\\n\\n作为一个监控厂商，视频是基础功能。音视频部分包含流的获取、\\n音视频参数设置、语音对讲等功能。\\n\\n### 媒体流协议\\n\\n* SDK -- 0xF4\\n* Web -- RTSP(前端)/0xF4(存储)\\n\\n视频流协议有三种，其中二代支持静态多连接和动态多连接两种，\\n同时三代协议也有部分产品线在使用。\\n从协议使用的覆盖面和演进方向综合评估，\\nNetSDK使用二代的动态多连接协议，即0xF4作为未来的支持重点。\\n使用登陆返回的版本号是否为6，来区分设备是否支持动态多连接。\\n\\n### 摄像头属性(SDK/Web使用相同协议)\\n\\n* 如果产品定义包含CameraAttribute，则使用VideoInXX配置族\\n* 如果产品定义不包含，则使用VideoInOptions/VideoInPreviewOptions配置\\n\\n### 通道标题\\n\\n* SDK -- 0xA8\\n* Web -- VideoIn/ChannelTitle\\n\\n## 存储类协议\\n\\n设备通常都带有一定的存储介质，比如相机的SD卡或者存储类设备带硬盘，\\n这部分涉及的协议，主要包括管理这些介质，或者查找存储介质上的录像/图片。\\n其中尤其以查找录像/图片最为重要。磁盘管理对于运维平台来说，也有很大的价值。\\n\\n### 录像查询\\n\\n* SDK -- 0xF6 or 0xA5\\n* Web -- MediaFileFind.xxx\\n\\nSDK通过0xA4查询设备的返回，如果xxx，则支持0xF6，否则使用0xA5。\\n\\n## 外设功能\\n\\n### 云台控制\\n* SDK -- 0x12(基础)+0xF6/Json(扩展)\\n* Web -- Json Over HTTP\\n\\n### 事件上报\\n\\n* SDK -- 0x68/0x69+0xF6\\n* Web -- 如何保持长连接？\\n\\n## 网络功能\\n\\n包括有线、无线网卡的管理\\n\\n## 用户管理\\n\\n* SDK -- 0xA6\\n* Web -- UserManager.xxx\\n"}'));jctx.push(JSON.parse('{"id": "161011", "tag": "lang", "text": "# Lua调试器clidebug使用说明\\n\\n用lua -lclidebug xxx.lua来启动，进入后会停在第一行。\\n接下来介绍常用命令。\\n\\n* setb linenum [file] -- 设置指定行号的断点，默认打在当前文件\\n* tb linenum [file] -- 设置临时断点，执行到该断点后，即取消断点\\n* delb linenum [file] -- 删除指定行号的断点，默认打在当前文件\\n* listb -- 列出所有断点\\n* run/cont -- 执行程序\\n* s [num] -- 单步进入，默认1步，可指定步数\\n* n [num] -- 单步跳过，默认1步，可指定步数\\n* fin -- 跳出函数\\n* p varible -- print, but format is somewhat different\\n* display varible -- 增加一个变量名到列表，以后每次单步会打印列表中的变量值\\n* undisplay -- 清空display列表\\n* vars [levelnum] -- 显示指定层级变量，默认1\\n* what funcname -- 显示函数信息\\n* exit -- stop debug\\n\\n最后以上这些命令可以写在执行路径下的./clidebug.cmd里，比如文件里写setb 10，就能在启动后在10行打个断点。程序启动后会读这个文件，在经常调试时会比较方便。\\n\\n大概说下原理，通过-lclidebug导入调试库，但这个库会先执行一个pause函数，\\n在pause里创建好一个协程coro_debug，这个函数会执行yield。\\n并通过debug.sethook(debug_hook, \\"crl\\")，\\n在debug_hook函数内，又通过debug.getinfo(level, \\"S\\")的方式得到执行的脚本名，\\n当debug_hook被回调出后，如果没有断点，则直接return，从回调返回，\\n把控制权交给主函数进行，即sethook的函数，如果有断点，会resume这个coro_debug函数，\\n在coro_debug里做while循环并io.read(\\"*l\\")，等待用户输入动作，\\n只有run/step/next这三个命令，会触发yield动作，其它命名处理后，等待下一次用户输入。\\n\\n这个流程的关键一环，是Lua自带了sethook这个函数，因为有了它Lua会在执行的过程中，\\n每次的call或单步，都会回调进hook函数。如果仅仅是这样，只能在hook函数中做一些固定的动作，\\n要让debug真正可用，就要在hook中引入协程，hook先让渡执行权，由用户来输入，\\n在协程中判断用户输入，如果是打印或设置断点，则执行后还在协程中，\\n只有step/next/run等命令，才会让渡回hook函数，每次hook函数被回调出来，\\n都会计算当前行号，如果这个行号上没有断点，hook回调结束，让主程序继续走下去。如果有断点，则resume协程。\\n\\n通过这种方式，从而托管了后面的脚本文件的执行。\\n\\n编程语言说到底还是函数的调用，调用成链必然会形成层次，debug.getlocal的第1个参数，表示的就是调用栈的层数。不同的语言可能表示法会有不同，lua用1表示当前的函数层（即调用链最末端的函数），然后以此为基准向main函数逐层递增。C语言的当前层是0，语言风格使然。恐怕不会有语言以main函数为1开始计算，这样的话很难定位到当前调用函数的层级，而出问题的往往是当前函数。"}'));jctx.push(JSON.parse('{"id": "161019", "tag": "web", "text": "# 表单的请求类型\\n\\n有很多的文章会讲http协议里，Post和Get的区别，记录我的理解。\\n\\n不管是Get或者Post请求，除非是单纯获取信息类请求，总是会带些参数，如果参数有多个，就存在多参数的区分问题。Get请求通常只使用Url(注意这只是HTML的用法，不是HTTP的规定)。所以就需要定义规范，在1994年的时候Berners Lee等人制定了RFC1738规范(URL定义)。特殊字符用%[0-9A-F]{2}方式转义，使用&来区分多个参数，每个参数再通过=分成key和value。\\n\\n所以Get的URL往往像这样：`example.com/act.cgi?key1=value1&key2=value2`。\\n但是Post的请求内容并不在Url中，而是在http协议头之后，这段内容没有规定，只是一段无格式的Buffer。为了解决Post的body无约束的缺失，在http规范里有个Context-Type字段，比如定一个Application/Json，Application/XML等等的格式。\\n\\n## Application/x-www-form-urlencoded\\n\\nhtml中表单Form元素，使用post method时默认会使用`Application/x-www-form-urlencoded`格式。这个命名的`x-`表示它是个扩展规范，`www-form-`和HTML的表单能很自然地联系，最后的urlencoded表示它和Get请求在Url中带参数的风格是一样的，也是用&和=来区分，从而减少开发者的学习成本。如果输入内容包含=或+，也会按urlencoded方式转义，也就意味着内容如果是base64的内容，不需要额外对=进行转码。\\n\\n我不知道为什么当时会用这么一个略显冗长的格式，也许在定义的时候，JSON或XML都还不引人注目，而Get又是urlencode编码，也许为保持一致于是就用了它。\\n\\n当`Content-Type`使用了`x-www-form-urlencoded`时，PHP会把Post内容按上面说的格式来解析，最终赋值给`$_POST`变量，其它方式不会赋值到`$_POST`。\\njQuery的post方式也使用HTML的默认格式，在js语言层面看起来写的是json数据，但网络传输时最终把json转化成用`=`和`&`分隔的URL方式，\\n到了PHP侧再用`$_POST`来提取。这个过程中，js/传输/PHP各自用符合自己特性的方式，但最终仍是无疑地进行交互。\\n\\njson比urlencoded方式更有表现力的地方在于支持数组，抓包后发现jQuery把数组arr:[1, 2]转换成arr%5B%5D=1&arr%5B%5D=2来发送，\\n相当于服务端依次收到arr[]=1和arr[]=2两个值。至少PHP能够识别这种数组表示法。\\n\\n## multipart/form-data\\n\\nurlencoded的方式有个不足，就是传输二进制数据的效率非常低，极端情况如果全是不可打印字符的话，数据量会增大3倍。\\n如果是传输图片或大文件，Form表单的input使用file类型，enctype要使用`multipart/form-data`(如果不指定则默认urlencoded方式)。\\n\\nmultipart表示这个请求有多个部分，每个部分会标记`Content-Disposition: form-data; name=\\"xxx\\"`，如果是file，会额外多出一个filename=\\"file real name\\"。这时二进制数据就不做任何转换地发送到服务器。\\n如果有多个二进制数据(即multipart)，就用Boudary来区分。`$_POST`能解析不带filename的部分，惟独文件不能解析，即使`file_get_contents(php://input)`方式也不支持(就这一种不支持)，还不知道该怎么读取。\\n\\nGet是否支持在body中携带参数？标准没有规定不允许，但是浏览器不支持。为了兼容性考虑，只在URL中带参数是更好的选择。如果真的构造了在body的get请求，可以用原生内容，也可以从`$_REQUEST`变量读取。但PUT请求时，无法解析，也许是PHP的原因，暂未追究根因。\\n\\n[[浏览器的网络请求发展史]] [[C语言的HTTP请求]]# 表单的请求类型\\n\\n有很多的文章会讲http协议里，Post和Get的区别，记录我的理解。\\n\\n不管是Get或者Post请求，除非是单纯获取信息类请求，总是会带些参数，如果参数有多个，就存在多参数的区分问题。Get请求通常只使用Url(注意这只是HTML的用法，不是HTTP的规定)。所以就需要定义规范，在1994年的时候Berners Lee等人制定了RFC1738规范(URL定义)。特殊字符用%[0-9A-F]{2}方式转义，使用&来区分多个参数，每个参数再通过=分成key和value。\\n\\n所以Get的URL往往像这样：`example.com/act.cgi?key1=value1&key2=value2`。\\n但是Post的请求内容并不在Url中，而是在http协议头之后，这段内容没有规定，只是一段无格式的Buffer。为了解决Post的body无约束的缺失，在http规范里有个Context-Type字段，比如定一个Application/Json，Application/XML等等的格式。\\n\\n## Application/x-www-form-urlencoded\\n\\nhtml中表单Form元素，使用post method时默认会使用`Application/x-www-form-urlencoded`格式。这个命名的`x-`表示它是个扩展规范，`www-form-`和HTML的表单能很自然地联系，最后的urlencoded表示它和Get请求在Url中带参数的风格是一样的，也是用&和=来区分，从而减少开发者的学习成本。如果输入内容包含=或+，也会按urlencoded方式转义，也就意味着内容如果是base64的内容，不需要额外对=进行转码。\\n\\n我不知道为什么当时会用这么一个略显冗长的格式，也许在定义的时候，JSON或XML都还不引人注目，而Get又是urlencode编码，也许为保持一致于是就用了它。\\n\\n当`Content-Type`使用了`x-www-form-urlencoded`时，PHP会把Post内容按上面说的格式来解析，最终赋值给`$_POST`变量，其它方式不会赋值到`$_POST`。\\njQuery的post方式也使用HTML的默认格式，在js语言层面看起来写的是json数据，但网络传输时最终把json转化成用`=`和`&`分隔的URL方式，\\n到了PHP侧再用`$_POST`来提取。这个过程中，js/传输/PHP各自用符合自己特性的方式，但最终仍是无疑地进行交互。\\n\\njson比urlencoded方式更有表现力的地方在于支持数组，抓包后发现jQuery把数组arr:[1, 2]转换成arr%5B%5D=1&arr%5B%5D=2来发送，\\n相当于服务端依次收到arr[]=1和arr[]=2两个值。至少PHP能够识别这种数组表示法。\\n\\n## multipart/form-data\\n\\nurlencoded的方式有个不足，就是传输二进制数据的效率非常低，极端情况如果全是不可打印字符的话，数据量会增大3倍。\\n如果是传输图片或大文件，Form表单的input使用file类型，enctype要使用`multipart/form-data`(如果不指定则默认urlencoded方式)。\\n\\nmultipart表示这个请求有多个部分，每个部分会标记`Content-Disposition: form-data; name=\\"xxx\\"`，如果是file，会额外多出一个filename=\\"file real name\\"。这时二进制数据就不做任何转换地发送到服务器。\\n如果有多个二进制数据(即multipart)，就用Boudary来区分。`$_POST`能解析不带filename的部分，惟独文件不能解析，即使`file_get_contents(php://input)`方式也不支持(就这一种不支持)，还不知道该怎么读取。\\n\\nGet是否支持在body中携带参数？标准没有规定不允许，但是浏览器不支持。为了兼容性考虑，只在URL中带参数是更好的选择。如果真的构造了在body的get请求，可以用原生内容，也可以从`$_REQUEST`变量读取。但PUT请求时，无法解析，也许是PHP的原因，暂未追究根因。\\n\\n[[浏览器的网络请求发展史]] [[C语言的HTTP请求]]"}'));jctx.push(JSON.parse('{"id": "161023", "tag": "os", "text": "# 一次安卓刷机失败的修复过程\\n\\n手头有个华为手机，自带的EMUI实在太难用，偶然在华为论坛找到一个flyme的链接，大喜过望马上准备刷机。那篇帖子提供了两个链接，并且告诫说，\\n如果其中一个ROM导致黑屏，可以刷另一个ROM。本来这个时候，应该把两个ROM都下载后再开始刷机，但因为下载速度实在太慢，加之自己的大意，下载完一个ROM就急切地开始刷机了。果然悲剧发生了，刷完之后一进入系统就黑屏了。\\n\\n在这个状态下，电脑不能识别手机，也就无法把新的ROM再拷贝进去，本想试着把新的ROM拷贝到TF卡，让Recovery从TF卡升级，\\n但进到Recovery，可能是Recovery的缺陷，一旦执行mount TF卡，就失去响应了。这时我已经有点着急了，难道只能线刷？网上线刷包倒不难找，\\n但是一来下载要花时间，二来线刷包和卡刷包的区别在哪里？既然有卡刷包，也能进到Recovery，非要线刷不可吗？\\n\\n又在Recovery的菜单里找起来，惊喜地看到有个sideload的选项，说明写着通过adb sideload命令，可以把文件导入到手机。\\n看来可以在电脑上把卡刷包给写到flash上，但是操作之后却提示无法找到设备。猜想很可能是没有驱动，去哪里找驱动是个麻烦的问题。好在现在有各种方便的刷机工具，靠它来装上驱动，还是挺方便的。于是随便找了个下载安装，\\n再输入adb devices命令，果然手机被识别出来了。接下来手机侧点击sideload，有了驱动后再一次电脑上输入sideload命令，把卡刷包写入手机。经过漫长的等待，手机总算活过来了。\\n\\n手机修复后，重新去思考修复过程，发现只要Recovery能用，且和卡刷包的版本是配对的，就能救回来。因为遇到过问题，从Android4.4系统，下载的5.0的卡刷包，升级后就不能引导进应用系统了。接下来就仔细缕缕这其中的关系：\\n\\n先从系统结构说起：比如一个跑在x86上的linux，启动流程是先进入BIOS，然后引导kernel，最后执行init程序，就能进入shell或GUI了。那么对应手机，分别有如下这几个阶段：\\n\\n* fastboot 也叫bootloader 对应BIOS，一般是u-boot来实现，功能比较简陋，无法交互，目的是引导到下一个阶段，比如Meta,factorymode,recovery,normal这几种模式。这种模式下的刷机，俗称线刷。\\n* recovery 这个就包含了kernel和定制的init的程序。这种模式下的刷机，俗称卡刷。\\n* normal 就是我们平时打开手机的flyme或MIUI系统，当然有kernel和init。\\n\\nrecovery和normal都带有kernel，可以分别独立启动，通常按电源键，会直接运行normal模式，只有同时按下音量键（具体取决于手机厂设置），才会选择recovery模式。只要这两个中任何一个正常，就能看到开机画面了。所以上文提到的就是recovery可用时的刷机策略。\\n\\n但是如果Recovery坏了，或者Recovery和想升级的rom包不匹配，就需要更新Recovery了。更新Recovery有两种方式：\\n\\n1. fastboot工具。如果Recovery有问题，这时选择进入手机的bootloader模式，(比如我这个华为手机，音量+和电源键是进入Recovery，音量-和电源是进入fastboot/bootloader)。\\nbootloader模式和adb是不同的，驱动也不一样，会出现adb能识别而fastboot识别不了的情况。要用fastboot flash recovery filename命令，\\n来写入第三方的Recovery。bootloader比Recovery的阶段早，所以这个阶段可以写Recovery，fastboot模式由于不具备交互界面，只能在电脑上操作，\\n2. 使用厂商提供的专用工具，还需要刷机包有分区表(通常卡刷包是不会有的)，\\n从分区表可以看到第一个和最后一个分区名为pgpt(primary gpt)和sgpt(secodary gpt)，\\n说明是按GUID Partition Table而不是MBR方式管理分区的。我手头的手机Recovery分区是16M，有了这个基础，下一步就是卡刷了。\\n\\n很多厂商不希望玩家刷机，就故意把Recovery的功能做得很简陋，或者限制刷入包的签名，同时又在bootloader上做限制，不允许更新Recovery。\\n这就需要先解除bootloader的限制，即俗称的unlock。经过这一步，手机便失去了保修，换来的是可以自由地写入Recovery，然后各种Rom就可以烧入手机了。\\n\\n前文还提到Recovery和Rom会不匹配，这就涉及另一个概念：底包。\\n经常在刷机论坛能看到底包说法，打开底包可以看到非常多的文件，\\n包括上文提到过的recovery，system.img,boot.img,userdata.img等文件，\\n还有些像moden_ltg.img,trustzone.bin,logo.bin等文件，\\n还有在操作中惟一可以由用户选择的文件——分区表。\\n\\n不管卡刷也好，fastboot重写recovery，如果没有正确的分区表，也是不可能的。\\n从这里可以看出，如果要把系统写到一块完全空白的flash，确实需要线刷底包，\\n但是一般说的黑屏啊救砖什么的，通常分区表不至于损坏，只要下载到版本合适的Rom或Recovery，\\n就一定能救砖成功。\\n\\n底包含有基带moden，还有用于DRM版权及支付的trustzone.bin文件，\\n这些文件都是厂商不愿意开放出来，且ROM的作者也不会去修改的地方。\\n可以认为卡刷包是把底包中和应用相关部分给替换的部分。\\n\\n底包中往往有完整的分区表，比如MTK6752有24个分区，有ext4和RAW两种格式。\\n但是并不是每个分区都会写文件进去，像NVRAM分区保存的是IMEI串号，\\n就只定义了分区大小为5M，但不管哪种刷机方式都不会去改写它。\\n从这里也能看出：分区表绝对不能破坏，否则IMEI一旦丢失就没有任何方式能挽回，\\n除非保存过NVRAM的内容，否则只能返厂重写。\\n\\n手机变砖后能和线刷工具通信，说明内部有一块固化的代码，MTK平台称为Bootrom，\\n代码固化在NOR flash上，同时还有一小块SRAM，执行DA程序，DA是Download\\nAgent的简称，用于接收线刷工具发到手机的数据。\\n所以至少MTK平台的启动第一步，并不是uboot，而是这块Bootrom。\\n这部分是无法访问的，如果被破坏，只能返厂维修了。\\n\\n最后附一个MTK6752的分区实录，总计有24个分区，列出部分。\\n<pre>\\npreloader 256K\\npgpt(first) 512K\\nproinfo  3M\\nnvram(IMEI) 5M\\nboot      20M\\nrecovery  20M\\nlogo      8M\\ntee1(trustzone)  5M\\ntee2(trustzone)  5M\\nsystem    1.5G\\ncache     320M\\nuserdata  1180M\\nsgpt(last)    512K\\n</pre>\\n"}'));jctx.push(JSON.parse('{"id": "161031", "tag": "protocol", "text": "# 变倍与聚焦\\n\\n监控行业的相机有枪式和球式两种，还有种半球但实质上和枪式一样，只是安装方式不同。\\n两种相机因为外形和机械结构的不同，使用场景也有很大差异。\\n比如枪式相机主要安装在室内，而球式相机装在室外的较多。\\n这种场景的不同，导致对图像的调校也不一样，典型如白平衡，两者的侧重点就很不一样。\\n\\n这里从变倍和聚焦出发，谈谈两者的不同。先说说两者的异同：\\n\\n* 变倍的主要作用是调节透镜的物距，进而影响成像的大小，变倍主要有光学变倍和电子变倍。\\n* 聚焦则是使物体成像于焦点上，能看到清晰锐利的图像。\\n\\n从光学镜片的物理特性来说，单个镜头的曲率固定，焦距也固定，无法实现变倍。要变倍必须有多片镜头组，通过调节互相之间的位置，得到一个整体的等效焦距，这个焦距才能变化，焦距变化后就能达到变倍效果(准确的说是视角的变化)。而调焦是由于焦平面没有落在sensor上，整体移动镜头组，在此过程中焦距不会变。\\n\\n为什么很多人会说分不清楚两者呢，因为在使用的过程中，\\n变倍和聚焦在直观上都有一个物体由模糊变清晰的过程，所以会觉得两者很相似。\\n但仔细区分的话，会发现，变倍会引起物体大小的变化，而聚焦只会变清晰，\\n但并不会改变成像的大小。而且更进一步说，变倍并不会使物体自动地变清晰，\\n往往是镜头实现了自动聚焦这一动作。\\n\\n变倍尤其是光学变倍，都会调整透镜和CCD或CMOS的距离，因此都需要配备电机，\\n或者更高级的会使用步进电机，这就必然导致成本上升。\\n因而低价位的枪式相机大多不具备变倍功能，因为没有变倍，焦距也能在出厂前就调节完成，\\n所以既没有变倍，也没有调焦功能。\\n\\n而球式相机由于自带云台，能够各种方向的旋转，在旋转的过程中很自然的有了变倍的需求，\\n因此球式相机在行业里又称为PTZ，P和T是Pan(水平)和Tile(垂直)的意思，\\n指的是云台底座的运动方向，而Z则是Zoom，即相机镜头的变倍。\\n当然带云台的相机也可以没有变倍，两者并不强关联。\\n由于球式相机大都具备变倍功能，在日常使用的过程中也经常要调节倍率进行物体的跟踪，\\n往往要配备比较强大的聚焦算法，否则跟踪物体就会发虚模糊，用户是不能接受的。\\n因此对球式相机来说，变倍是其基本功能点，而自动聚焦则是必备条件，\\n但是又由于球式相机经常处于运动状态，对于聚焦只要能达到人眼可见的清晰程度，\\n就能满足用户的使用了。\\n\\n枪式相机，如果具备变倍功能，通常也会同时提供聚焦的调节功能。\\n当用户购买了变倍相机，并在安装时根据场景选择好倍率，就会仔细地调节聚焦，\\n力求画面清晰锐利，因为枪式相机的视野比较固定，一旦安装好，变倍就固定下来不会轻易改变，\\n因此对聚焦就会有更多微调节的需求。\\n\\n因此在枪式相机上，能看到单独的变倍和聚焦页面，而球式相机则往往只有变倍的按钮可以使用。\\n\\n上文说到聚焦的目的是使物体变清晰，那么这个清晰要如何定义呢？\\n如果是手动聚焦，一切依赖肉眼那就全由人来完成，但是往往相机都能自动地调整好焦距，\\n这又是怎么做到的？这就涉及图像处理的算法了：比如在画面中有一个人，\\n那么这个人的轮廓和画面的背景交界处，一定会出现较大的差距\\n(当然如果你非要穿着黑衣在黑夜里，就没得谈了)。\\n那么我们就可以通过计算图像中这些亮度差距较大的地方，来勾勒出轮廓，\\n并通过调节画面，找出亮度差最大的一个场景，这时从理论上说，就是焦距最准确的位置。\\n这个找最大差的原理则类似数学中的求导，当然具体细节复杂得多，只是一个约略的近似。\\n除了这种自动聚焦的方式，还有一种辅助聚焦，在手动调节焦距时，\\n由相机反馈一个当前聚焦峰值，一边手动调焦一边观察聚焦峰值，当这个峰值达到最大的一刻，\\n就找到了焦点。有种把自动聚焦的内部参数，开放给手动调节的感觉。\\n\\n所以虽然都是变倍和聚焦，由于相机的使用方式不同，这两个功能的呈现和侧重也会有所差异。\\n概括地说就是\\n\\n* 枪式相机更注重聚焦，达到更好的画质\\n* 球式相机更注重变倍，达到运动过程中更好的观看体验\\n"}'));jctx.push(JSON.parse('{"id": "161102", "tag": "design", "text": "# 设计方案的不动点和弱化点\\n\\n软件开发领域里有句教训：手里拿了锤子，看什么都是钉子。这句话也可以反过来看，并不是所有的需求都是钉子，面对不是钉子的需求，也就不应该用锤子的解决方案。架构也是一样，并没有一个包罗万象、适用于所有需求的架构。必须要先理解需求，到底是木钉子还是螺丝钉又或是水泥钉，再选择合适的工具。\\n\\n我把设计架构的法则称为定义不动点，设计一个系统前必须有一个核心前提是不能变动的，也可以称为约束点。所有的演化都是基于这个约束前提得到的，约束的宽度和系统最终演化的宽度成负相关关系。\\n\\n举17年4月智能库重构的例子，应用层视频智能库的不动点就是基于视频分析器做业务。首先要定义分析器是什么，它是这样一个实体，必须接受一路YUV数据，包含了若干个算法(这些算法统一以Scene的名义暴露给外层)，并输出各种分析后的元数据的物件。为什么很多的系统会遇到未来无法扩展，是因为前期的约束条件太多太严苛，比如基本约束太接近原始需求，导致需求稍有变化，尤其发生冲突时，基本约束就被破坏，整体体系的不动点也随之动摇。所以在设计前，对基本约束的定义，一定要原子、明确化。原子是便于组合，明确是把各种条件正交化，不要耦合。\\n\\n说完约束点，再说说弱化点。以设备初始化需求为例，一直以来设备出厂会有默认用户和密码，由于安全因素被提到越来越高的位置，要求去掉设备上的默认密码，\\n演化为用户第一次开机时，必须要输入初始密码。此处有两点要关心：\\n\\n1. 不仅要初始化大华用户密码，也要同步Onvif密码\\n2. 传输密码必须加密，且加密算法要可逆，进而能还原出明文密码(Onvif要求保存明文)\\n\\n要对称加密，就必须要在初始化之前得到公钥，否则对称加密就无从下手。\\n传输有两种，单机的HTTP方案和批量的组播方案。HTTP方案无非就是请求公钥，传输密文密码。\\n而组播方案，由于UDP报文长度的限制，获取密钥要和组播发现分开，经两次交互来完成初始化密码过程。\\n\\n明文密码到了设备后，接着就是怎么存储的问题。大华帐号仍使用带Salt的MD5方式，\\n\\n从以上内容看到，设计一个方案是由非常多步骤组成，这些步骤间的组合性就是评价方案的关键。\\n就像函数式编程一样，如果每个函数都是无状态，则整个流程一定是可并发不会受限的，一旦有一个函数包含了状态(全局或静态变量，又或是成员函数)，\\n则整个调用链就受制于这个环节。方案设计也是一样，如果每个环节的流转都是无损的，则整个方案就不会有问题。上面的例子，激活密码从客户端经明文发送到设备，\\n一旦保存到大华账号，就退化成hash值，这个过程发生信息丢失，以后想用明文密码的地方，就不能再使用序列化后的内容，必须在客户端再一次输入明文，\\n因此这个明文密码的序列化过程，就成了方案中的弱化点，会在某些程度上限制方案的拓展空间，在设计时要特别注明存在弱化的环节。弱化也是约束的一种延伸。\\n\\n很多系统在开始阶段缺少约束和弱化的说明，仿佛害怕他人知道这个架构的短处，但这样做的后果往往是，过一段时间，随着需求的变化，原始的架构约束已经被破坏，于是整个架构呈现出很多的不适，后来加入团队的新人不知道前期留下的约束是什么，以致被破坏了还不自知，然后抱怨为什么这个架构这么差，其实这个差，从需求改变那刻起就已注定。"}'));jctx.push(JSON.parse('{"id": "161104", "tag": "lang", "text": "# 一个GDB和GCC版本不同引起的定位问题\\n\\n有同事问起调试过程中，触发了SIGFPE除0错误，但是通过core的bt命令，\\n却发现出在pthread_create函数上，非常不可思议。今天找了部门对汇编最熟悉的大师，\\n原来问题是出在编译使用的是GCC5.2版本，但是调试用的GDB因为使用的libc和GCC不匹配，\\n导致符号表错误，而GDB是通过偏移量并从符号表中读取符号，\\n一旦版本不匹配，读到的符号也是错误的。\\n\\n解决方案是通过GDB的set sysroot命令来重新定位到GCC的库中，强制确保libc库的正确性。\\n怎么知道正确的sysroot路径呢？就从编译的信息来，通过ld的-t选项，能得到libc的路径。\\n比如写一个gcc hello.c -Wl,-t的方式，就知道从哪个目录下引用了哪些库。\\n把这个目录再通过set sysroot在GDB环境中设置一遍。\\n但是仅有sysroot还不够，因为出问题的往往是自己写的库，因此还要用\\nsolib-search的方式把自己编写的库，导入GDB的搜索路径下，\\n经过这样一遍的尝试，再用bt命令就能定位到正确的函数了。\\n\\n顺便再说说用GDB查看栈帧的理解：\\n\\n程序被加载到内存后，以windows为例，程序数据如main，func这些函数的汇编语言代码，用disas main来观察，保存在0x00401300左右的内存空间，而栈空间在0x0028ff00左右位置。用i reg仔细看eip,ebp,esp这三个寄存器，eip始终在代码区徘徊，而ebp和esp沿着栈空间一直向下生长（值不停地变小）。\\n\\n每次汇编的call一执行，会把当前的ebp、eip、函数参数(如果有的话)依次保存在栈上，所以入参从0x8(%ebp)开始算，而eip的值通过反汇编可以看到，是call的下一条指令位置。从而在leave指令可以用上次的栈和pc值回到上层函数的call之后继续执行。也可以用disas eip的值，看eip要执行的汇编代码是什么。\\n\\n所以递归的时候，每一次的函数入参和返回地址eip，用x/50x ebp address命令能看得很清楚。这就是bt能打印函数执行地址的原因，那些值其实都沿着栈内存写着，bt只是帮人翻译出来罢了。"}'));jctx.push(JSON.parse('{"id": "161112", "tag": "design", "text": "# 通过限制来降低沟通成本\\n\\n看了王垠的[对Rust语言的分析](http://www.yinwang.org/blog-cn/2016/09/18/rust)，\\n其中提到一点，少用类型推导而用明确的类型声明，大概这种大逆不道的话，也只有王垠敢说吧。\\n但是他的原因我是深以为然的，代码写出来是给人阅读和交流的，\\n甚至更多的时候只有你会读你的代码，所以更具备更读性，也是对自己好的一种方式。\\n\\n想起工作中的一件事，公司的接口和协议使用Json有5、6年了，协议使用Json没什么大问题，\\n但是如果头文件也直接用Json，然后在注释段直接来一句：参见XX文档，就很有问题。\\n现在做产品的，都提倡不要让用户想，不要增加用户的获取成本，\\n如果把程序员也当成设计人员的用户，那么这条准则依然适用。\\n因为有可能，程序员根本不知道所谓的XX文档是什么，也不知道去哪里获取，\\n即使有了文档，还是会不确定。比如我在昨天遇到的一个例子，当时文档上很清楚地标明了，\\nJson格式是这个样子的：\\n<pre>\\n{\\n\\"content\\" : {},\\n\\"alarm\\" : 1\\n}\\n</pre>\\n但是他还是不确定alarm和content是否平级，并为此还特意拉了几个人，在群里确认了一遍。\\n虽然这样的例子不多，但是随着组织的扩大，人员平均水平的下滑(这几乎是一定的)。\\n这就造成了非常大的重复沟通浪费和注意力分散。\\n\\n我一直提倡在头文件中，用struct来替代Json。能做到自解释，也能明确的规定类型，\\n规定类型是一种限制，可是这种限制带来的确定性，在一个组织变得庞大后，\\n更多的仍是明确含义，减少沟通的益处。组织庞大及随之而来的低效，往往是沟通不畅造成的，\\n在程序员这一级，我们有很好的技术手段来简化这种沟通成本，为什么不用呢？\\n"}'));jctx.push(JSON.parse('{"id": "161113", "tag": "web", "text": "# 简说CSRF\\n\\n网络攻击中有种技巧，叫CSRF(Cross-site Request Forgery)，跨站请求伪造。\\n什么意思呢：\\n\\n正常用户和服务器之间的请求是真实的请求，而CSRF的请求，仍然是用户和服务器之间的请求，\\n但这种请求并不是用户主动有意发起的，而是被黑客施以社工的方式，诱导用户点击，\\n由于最终仍是用户发起，所以服务器在技术上是无法区分到底是客户真实的用途，\\n还是被社工诱骗的结果。这种攻击技法技巧在技术上是这样的：\\n\\n首先HTTP协议是无连接的协议，但实际的应用场景很多时候是需要连接的，在编程上就会通过\\nsession方式来记录这个会话。但是和C-S模式往往使用TCP连接不同，浏览器的socket连接是无法控制的。\\n因此服务端无法做到把session和连接绑定，只能退而求其次和IP绑定。\\n可想而知，如果用户的浏览器有多个标签页，这些页签发起的请求，在服务器看来都是合法的。\\n这时黑客布置一个诱骗点击，用户点击后，会触发一个向服务器的请求，比如向黑客汇款，\\n因为是在同一个浏览器上发出的，就让服务器以为是用户主动向黑客汇款，于是一次攻击就成功了。\\n\\n原因是浏览器发起连接的行为不可控制，而根本恐怕还在于HTTP在协议设计之初的无连接性。\\n因为无连接，所以默认是短连接，而浏览器为了提高加载速度，又以用户不可控的方式去建立连接。\\n当然HTTP的设计之初，只是一个内部的信息交互系统，正是这个系统的极大成功，\\n被告后人用来做各种各样的业务，才引入这样一种本不该有的问题吧。\\n"}'));jctx.push(JSON.parse('{"id": "161120", "tag": "web", "text": "# PHP两种模式下的调试功能\\n\\nPHP语言相较于其它语言一个很大的不同，从一开始就定位在一种宿主语言。\\n它是由Web服务器来调用，而不像其它脚本语言，如Perl或Python那样用于命令行。\\n因此在PHP5以前，默认的主程序都是以cgi的SAPI模式运行，到了PHP5以后，\\n默认的php.exe才切换为cli的SAPI模式，而php-cgi.exe则代表cgi方式的执行体。\\n这两种模式支持的语法和特性是一样的，差异点有：\\n\\n1. 输出是否会带上html标签(CGI带，cli不带)\\n2. daemon时作用不同\\n\\n先说监听模式，php-cli能通过-S选项打开build-in的Web Server模式，这时就不需要开Apache了，\\n初学者使用这种方式上手PHP还是挺不错的，但比起完整的Web服务器，不能做URL Rewrite等功能。\\n而php-cgi的-b选项是FastCGI Server模式，这种模式不支持HTTP请求，只支持FastCGI请求。\\nFastCGI的specification比较简单，开始的请求头是8字节描述，包括版本号、类型信息，\\n接着就是各种CGI定义的元数据，比如`SCRIPT_FILENAME`等字段，php-cgi判定协议头，\\n并读取这些信息，执行完成后再将应答返回给Web服务器。因此这两种模式的作用差异是很大的。\\n\\ncli和cgi的调试也很不一样。cli模式使用phpdbg.exe程序，用法和GDB等类似，\\n在命令行下进行操作，而cgi模式需要用到扩展模块xdebug，且开启xdebug还不够了，\\n需要和另一个进程以C-S模式交互才行。\\n\\ncli模式使用phpdbg，最开始是5.4版本以补丁形式出现，到了PHP5.6以上，官方合入了这个补丁，\\n通过命令行方式启动，载入程序后可以打断点、单步或查看栈帧等。\\n和普通的命令行调试器很像，就不多做介绍了。\\n\\nxdebug是个远程调试扩展插件，需要在php.ini中载入对应的dll，\\n且还要配置`xdebug.remote_enable`为1才能用，\\n离奇的是，即使仅载入dll也会造成性能开销，因此如果不需要调试时，\\n务必把载入dll行给注释掉。\\n前面提到xdebug是C-S形的调试器，xdebug自身嵌在PHP内，是S端，因而必须要配置C端的地址，\\n指令就是如下两条：\\n<pre>\\nxdebug.remote_host = \\"127.0.0.1\\"\\nxdebug.remote_port = 9000\\n</pre>\\n通常C和S在同一台机器上，`remote_port`代表的是C端的监听端口。\\n当xdebug收到`XSESSION_DEBUG_START`这个特殊的字段，\\n就表示要开始调试，并向上例中的9000端口发起协商，通常xdebug客户端集成在IDE中，\\n在IDE内进行单步/设断点等操作，遵循xdebug协议向PHP服务发请求，就能达到调试的目的。\\n"}'));jctx.push(JSON.parse('{"id": "161124", "tag": "security", "text": "# X509证书与GPG验证\\n\\n## 证书定义\\n\\n加密体系中证书是非常重要的一环，最有名的标准就是X.509。它使用ASN1格式描述，这个标准有3个版本，主要用的是V1和V3版本。证书大小通常在1K字节左右。\\n\\nX509证书有几种格式，openssl默认使用PEM格式(Privacy Enhanced Mail)，而12306则使用了DER格式(Distinguished Encoding Rules)。DER是ASN.1这种二进制编码标准的一个实现方案(还有一种叫BER)，C函数中的`d2i_X509`和`i2d_X509`，d就代表DER，i则指internal，即C的struct格式。用openssl看的话，要加上-inform der才能正确地打开。\\n\\n证书的开始是版本号(1或3)，然后是证书序列号(Serial Number)。序列号是整数形式，比如：ab:a5:7c:fb:27:3c:50:91。是个64位数字。虽然名字叫序列号，但不能只靠这个做惟一区分，因为X509标准只要求序列号在同一个发行者或者颁发者(Issuer)下惟一即可（通常是每签发一个证书就加一）。\\n接下来是签名，签名算法一般是非对称+散列，比如sha1WithRSAEncryption。再是发行者，Issuer有很多个字段，其中必须有的是C国家，ST省，O组织，OU组织单元和CN通用名称(CommonName必须是域名，比如`*.waer.com`)。比如发行者就是德国某州的Apache测试组织。组织后面是证书有效期，包含不早于和不晚于两个时间点。然后是主体或授与者(Subject)信息，同样有C国家、ST省份、O组织等类似的部分，身份介绍后是授与者的公钥，比如1024bit的RSA公钥，这部分显示时似乎总是以00:开头，然后是RSA的exponent，0x1001。\\n\\n最后是整份证书的签名，否则无法证明公钥及其所有者的信息一致。这里再次用了sha1WithRSAEncryption方式，计算方式我猜测是这样：\\n先用sha1计算，然后用私钥生成签名，拿到证书的人，用公钥解密后的值，和证书的sha1值比对，只有对上了，说明这份证书才是正确的，防止被人伪造。\\n\\n上面列的字段都是X509的V1版本，V3在签名前面还会多出许多内容，从结构和原理上差不多就是这些。V3多出了扩展(颁发机构，CRL，使用者密钥标识)，关键扩展(密钥用法)，属性(指纹和指纹算法)。\\n\\n一份数字证书，最核心的内容就是这几件事：\\n\\n1. 谁给你签发的(Issuer)\\n2. 证书有效期\\n3. 你的身份是谁(Subject)\\n4. 你的公钥，用于通信时交换密钥\\n5. 使用签发者公钥对以上信息hash做的签名，防伪造\\n\\nX509覆盖的范围比较多，从头文件看，除用于认证的X509，还有CRL(证书吊销)、REQ(证书申请)、NAME(证书持有者信息名字)、ATTRIBUTE、EXTENSION五种扩展功能。\\n\\n## 证书签发流程与自签证书\\n\\nPKI体系的证书存在链式依赖，下游证书由上游证书签发，最顶级的根证书没有签发者，只能是自己给自己签发，但因为各种浏览器都集成了这些签发者的公钥，所以仍被认为有效，反之如果签发证书使用的顶级公钥没有被集成进浏览器，就会提示用户有风险。12306的根证书就是没有被广泛集成进浏览器的自签发证书。使用证书给别人签发证书，就是上游签发。\\n\\n从上一节数字证书包含的内容来看，包含两个不同的公钥。当我们在学习做自签发证书的时候，为简单起见，这两个公钥会用同一个。下面来看步骤：\\n\\n1. 第一步生成私钥，RSA用`openssl genrsa`命令，ECDSA用`openssl ecparam -name secp521r1 -genkey -param_enc explicit`。带上`param_enc`的私钥会把参数都嵌入，体积大一点，否则只有曲线名称，但遇到版本不匹配时，可能无法构造曲线。另外如果担心私钥泄密，还可以在生成私钥的时候用AES-CBC或其它算法对私钥进行保护。得到的私钥文件已经包含了公钥信息。虽然有了私钥，可是没有任何表明身份的信息啊。\\n2. 第二步生成证书申请，使用`openssl req`，这步要输入上一步生成的私钥。如果没有私钥，你的申请信息就可以被随意篡改，这显然不是证书的本意。申请文件一般用.csr作为后缀。\\n3. 最后一步签发证书，用`openssl x509 -req -signkey`命令，signkey是自签名的关键，生成的就是根证书了。还有另一种生成自签名证书方式，把申请和签发证书两步合二为一，命令`openssl req -new -x509 -days 365 -key keyca.pem -out pubca.pem`。\\n\\n有了自签发的根证书，服务器证书类似，第一步先生成私钥，第二步也是生成申请，其中带上服务器的信息，第三步将申请和服务器的公钥交给根机构，由根机构用根私钥对服务器申请加密，输出的文件就是服务器证书了，这时用的命令是`openssl x509 -req -CA -CAkey`。和自签名的差异是参数从signkey换成了CA和CAkey。从这个流程看，证书显然包含了信息和公钥。\\n\\n还有另一种签发方式`openssl ca -keyfile keyca.pem -cert pubca.pem -in svr.csr -out pubsvr.pem -days 99`，这种方式有几个限制\\n\\n1. 必须在当前目录下创建demoCA目录，这个目录内还要有newcerts目录，空的index.txt文件、内容为01的serial文件。\\n2. 根证书（自签名证书）和申请者的Province和Unit必须一致，否则无法签发。\\n\\n最后看一张图了解客户端对证书的认证过程\\n\\n![x509-verify](/img/x509-verify.png)\\n\\n## 使用GPG来验证文件\\n\\n常见的方式有MD5验证，但是问题在于你怎么确信看到的MD5就是真实的呢？使用更高级别的GnuPG吧，它是符合OpenPGP标准的加密软件，可以加解密，还能签名或验证。最早由德国人开发了PGP软件并大受欢迎，但由于是个商业软件，就出现了OpenPGP标准，而gpg则是最广泛使用的实现，全名GNU Privacy Guard，名字如此相似，不知是故意还是巧合。\\n\\n先从最常用的验证说起吧。签名文件一般是.asc或.sig结尾，命令 `gpg2 --verify check.asc filename`\\n\\n签名文件放在前面，在这个流程里还是依赖一个中心化的公钥服务器，比如Openresty的声明如下：\\n\\n    releases are signed by the public PGP key A0E98066 of Yichun Zhang\\n\\n可以在pgp.mit.edu网站查到，A0E98066是RSA key ID，可以检索。不知道这算不算PKI。"}'));jctx.push(JSON.parse('{"id": "161125", "tag": "web", "text": "# Apache和Nginx配置的理解\\n\\n前文有提到过PHP是怎么和Apache和Nginx整合的，作为最流行的两大Web服务器，从配置文件来看看这二者对Web业务的理解。\\n\\n还是先从和外部程序(如PHP)的结合性说起，Web服务器要想实现动态网页效果，最早是CGI方式，\\n另外还有Python定义的WSGI(包括衍生出的uwsgi)，以及不太常见的SCGI。Nginx支持这三种方式都是比较松的耦合，\\n通过`fastcgi_pass`把HTTP请求转给CGI服务器处理。另外一个很像的指令是`proxy_pass`，\\n二者的差异是`proxy_pass`是纯透传，即Back-to-back。而`fastcgi_pass`要做的工作则多得多，\\n不仅要构造一堆的CGI变量定义，还要在这些定义之前增加符合FastCGI规范的协议头。\\n另外php的cli方式不支持，一定要使用php-cgi -b port方式才支持fastcgi协议的请求。\\n用`uwsgi_pass`则是转成uwsgi协议给对应的程序处理。所以Nginx只做协议转换，不会调用外部进程。\\n\\n正是因为Nginx支持各种非HTTP协议的适配和转换，又不集成外部程序，它被普遍地认为是反向代理的模板。\\n\\nApache当然也支持转发，通过加载`mod_proxy`插件和相应的配置，把HTTP请求转给独立的外部进程。除些之外，Apache和PHP还有一种结合更紧密的方式，\\n即通过`AddHandler fcgid-script .php`这条指令，把路径名是.php结尾的请求，\\n识别成fcigd方式，进而通过FcgidWrapper指令声明的执行程序，直接运行PHP程序了。\\n虽然这种方式也是调用php-cgi.exe程序，但不是-b监听的方式。\\n因此在我的win8.1系统上出现一个很奇怪的故障，即Apache的`mod_fcgid`可以运行，\\nNginx却死活跑不起来。OpenResty深度整合了lua(主要还是程序小)，达到像Apache的效果。\\n\\nApache和Nginx在Web功能的配置上还是很像的，比如统一定向到错误页面\\n\\n这是Apache\\n> ErrorDocument 404 /missing.html\\n\\n这是Nginx\\n> error_page  404              /404.html;\\n\\n这里有个初学者很容易误解的坑，用PHP返回的错误码，服务器是不理会的。\\n原理是Web服务器只认自身产生的错误码，对外部程序返回的HTTP头内的错误码不做识别。\\nNginx还好一点，可以用`fastcgi_intercept_errors on;`这条指令强制打开，进而达到错误码重定向的功能，Apache就比较惨了，如果是Proxy的返回，\\n还能用ProxyErrorOverride来识别，但对FastCGI方式没有直接支持，只能以WorkAroud方式绕过，具体怎么绕，还没搞明白。\\n\\n## nginx和tomcat协作\\n\\ntomcat是符合servlet规范的一个实作，规范定义了web.xml，包含servlet类名，很多MIME项，所以很大，一般不用看。\\n\\n业务配置在conf/server.xml中，最多可配6层结构。最外层定义惟一的server，是整个tomcat大的业务入口，这层要监听一个关闭端口，默认是8005。server下可以有多个service，其中可以定义多个connector和惟一的engine，每个connector负责一种protocol和端口，支持的protocol有ajp/1.3和http/1.1。ajp是Apache JServ Protocol，似乎只有httpd支持，如果要和nginx配合，要依赖http的connector才行。engine下层是若干个host元素，每个host通过appBase属性规定了war包的位置。context中指定url路由对应的servlet，不过这套做法已经近乎绝迹，最里还有Logger等就不提了。\\n\\n之所以会有这么多层，也是需求使然。服务要拆分，每个服务监听不同端口，就要在service层实现。对虚机运营商来说，监听端口惟一，但想尽量多卖主机，于是Host就有存在的价值。service和engine是一对一绑定，我觉得可以合一，而context也没有存在的必要。但最起码，service和host是无法被简化的。\\n\\n由上可知tomcat自身是可以做web服务器的，类似PHP支持http和cgi两种协议。但真正部署时，还是用动态处理能力。\\n\\nnginx可以配置upstream，层级在http之下和server平级。比如upstream tomcat，在location定义`proxy_pass http://tomcat;`一句就能反向代理过去了。其实直接在`proxy_pass`后面写ip和port应该也可以。\\n\\n从命令行启动tomcat的入口是catalina.bat，使用了cmd的一个语法`start title dosth`，即start特殊命令，从而可以打开一个名为title的新cmd窗口，并执行dosth命令。否则就在窗口下直接执行。\\n\\n### nginx打印变量\\n\\n1. `add_header X-debug \\"$var\\" always;`指令，客户端就能看到某个变量。如果不加always，只有成功的响应才会添加头，不过这个参数在1.7.5以上版本才支持。\\n2. `add_header Content-Type text/plain;return 200 \\"$var1 $var2\\";`，直接在内容上显示变量，没有header内容会变成下载，不利于调试。\\n\\n## 在小米路由的使用\\n\\n小米路由器使用Nginx监听80端口，配置文件在/tmp/sysapihttpdconf/目录下，\\n首页目录在/www下，这个目录没有什么内容，index.htm中最主要的就是这句：\\n`<meta http-equiv=\\"refresh\\" content=\\"0; url=/cgi-bin/luci/web\\">`。\\n这个标签含有浏览器刷新和重定向两种功能，最终被重定向到了url所指向的地方。\\n在Nginx的配置脚本中，有`set $script_name /cgi-bin/luci`\\n在/www目录下，有cgi-bin/目录，其中又有luci这个文件，\\n\\nluci只是个入口，这其中会require相当多的文件，比如sgi.cgi，dispatcher等等。"}'));jctx.push(JSON.parse('{"id": "161204", "tag": "web", "text": "# CGI与FASTCGI规范的理解\\n\\n## CGI语义以及基于Busybox使用\\n\\n作为最早的Web交互规范，由于足够简单甚至连busybox都能支持，只要做到以下两点就可以\\n\\n1. 在网站根目录下创建cgi-bin目录（必须是这个名字，否则作为普通的目录，只会读取文本不会执行）\\n2. 在cgi-bin目录下创建文件，子目录也可以，并具有执行权限，但文件名不要和系统自带命令同名，我就遇到过命名为env后，程序一直执行不会退出\\n\\n然后在浏览器端，只要访问/cgi-bin/xxx，就可以触发执行CGI程序。RFC规范定义了以下环境变量给脚本读取使用：\\n\\n* REQUEST_METHOD: GET/POST等HTTP方法，busybox只实现了GET/POST，其它方法会报错501 Not Implemented\\n* REQUEST_URI: 请求的完整路径\\n* QUERY_STRING: 把URI的?之后部分提取出来，保存到这个变量\\n* SCRIPT_NAME: 被执行脚本的相对路径，Web根目录为/\\n* PATH_INFO: 额外的路径信息，由客户端给出的。换句话说，脚本可以由他们的虚拟路径名来访问，在这个路径的末尾附带额外的信息。这个额外信息被作为`PATH_INFO`发送。这个信息如果在传递给CGI脚本之前来自URL就可以由服务器来解码。如果请求http://example.com/test/test.php/a/b?k=v，则PATH_INFO的值为/a/b。\\n* PATH_TRANSLATED: 服务器提供的PATH_INFO的转换版本，它需要路径并且为它做虚拟到物理的映射。busybox不支持。\\n* SERVER_PROTOCOL/GATEWAY_INTERFACE/SERVER_SOFTWARE: 值类似HTTP/1.0、CGI/1.1，告知服务器运行版本\\n* stdout: 这并不是环境变量，对于POST请求的内容来说，URI之外的数据，需要脚本从stdout来读取，所以也提一下\\n\\n## FastCGI协议\\n\\nCGI规范了传输数据的环境变量命名（以及stdin/stdout用法），但只适用父子进程。FastCGI是网络化的，可以跨进程甚至节点使用，协议为8字节对齐，头是个8字节的标志位：\\n\\n```\\ntypedef struct _fcgi_header {\\n    unsigned char version;\\n    unsigned char type;\\n    unsigned char requestIdB1;\\n    unsigned char requestIdB0;\\n    unsigned char contentLengthB1;\\n    unsigned char contentLengthB0;\\n    unsigned char paddingLength;\\n    unsigned char reserved;\\n} fcgi_header;\\n```\\n\\n这个格式缺少协议头标志(MagicFlag)，大概那个时代都是如此吧。版本好像只有1，type是消息类型共有10种：\\n\\n```\\ntypedef enum _fcgi_request_type {\\n    FCGI_BEGIN_REQUEST      =  1, /* [in]                              */\\n    FCGI_ABORT_REQUEST      =  2, /* [in]  (not supported)             */\\n    FCGI_END_REQUEST        =  3, /* [out]                             */\\n    FCGI_PARAMS             =  4, /* [in]  environment variables       */\\n    FCGI_STDIN              =  5, /* [in]  post data                   */\\n    FCGI_STDOUT             =  6, /* [out] response                    */\\n    FCGI_STDERR             =  7, /* [out] errors                      */\\n    FCGI_DATA               =  8, /* [in]  filter data (not supported) */\\n    FCGI_GET_VALUES         =  9, /* [in]                              */\\n    FCGI_GET_VALUES_RESULT  = 10  /* [out]                             */\\n} fcgi_request_type;\\n```\\n\\n比较常见的有`BEGIN_REQUEST`/`END_REQUEST`(网络化后标识请求应答状态用)，PARAMS(代替环境变量)，STDIN/STDOUT(名字和CGI一样，含义则作了泛化)。\\n\\nBEGIN/END的payload部分是定长的，BEGIN定义\\n\\n```\\ntypedef struct _fcgi_begin_request {\\n    unsigned char roleB1;\\n    unsigned char roleB0;\\n    unsigned char flags;\\n    unsigned char reserved[5];\\n} fcgi_begin_request;\\n```\\n\\nrole表示Web服务器期望应用扮演的角色。分为三个角色\\n\\n```\\ntypedef enum _fcgi_role {\\n    FCGI_RESPONDER  = 1,\\n    FCGI_AUTHORIZER = 2,\\n    FCGI_FILTER = 3\\n} fcgi_role;\\n```\\n\\nflags包含一个控制线路关闭的位：FCGI_KEEP_CONN：\\n\\n* 0，则应用在对本次请求响应后关闭线路。\\n* 非0，应用在对本次请求响应后不会关闭线路。一般都是非0，减少连接开销。\\n\\nEND定义：\\n<pre>\\ntypedef struct _fcgi_end_request {\\n    unsigned char appStatusB3;\\n    unsigned char appStatusB2;\\n    unsigned char appStatusB1;\\n    unsigned char appStatusB0;\\n    unsigned char protocolStatus;\\n    unsigned char reserved[3];\\n} fcgi_end_request;\\n</pre>\\nappStatus是应用级别的状态码。protocolStatus组件是协议级别的状态码；\\nprotocolStatus的值可能是：\\n\\n* `FCGI_REQUEST_COMPLETE`：请求的正常结束。\\n* `FCGI_CANT_MPX_CONN`：拒绝新请求。这发生在Web服务器通过一条线路向应用发送并发的请求时，后者被设计为每条线路每次处理一个请求。\\n* `FCGI_OVERLOADED`：拒绝新请求。这发生在应用用完某些资源时，例如数据库连接。\\n* `FCGI_UNKNOWN_ROLE`：拒绝新请求。这发生在Web服务器指定了一个应用不能识别的角色时。\\n\\n另外PARAMS、STDIN/STDOUT由于受协议单次数量64K的限制，如果要分包，\\n则采用最后带一个长度为0的请求表示结束。有点类似HTTP的CHUNK传输方式。\\n\\n详细说下chunked方式，回复的HTTP包头如果标识是chunked方式，包头结束后(即单独的一个空行`\\\\r\\\\n`)，接下来就是若干个chunk，格式遵循这个格式：该chunk的字节长度加上回车，然后是正文数据加上一个回车结束。\\n\\n比如发送abcd四个字节，这个chunk是`34 0d 0a 61 62 63 64 0d 0a`，34和回车表示这个块有4字节，正文数据的长度匹配后再跟一个回车，当所有带内容的chunk都结束后，要再发送一个结束包`30 0d 0a 0d 0a`，30和回车表示块有0个字节，这个不存在的正文后再跟一个回车，内容结束。长度按16进制表示，比如一个附件是44307字节，抓包是`61 64 31 33 0d 0a`，表示ad13，转成十进制正好是44307。\\n\\n## FastCGI在nginx和PHP的应用\\n\\nFastCGI作为解决CGI协议的后继者，已深得人心，在Nginx和PHP中都默认支持。比如php-cgi虽然名字是cgi，但是-b模式开启的其实是FastCGI模式。再配合上Nginx的`fastcgi_pass`指令，动态网页的环境就完成了。\\n\\n从Nginx的配置语句也可以看出点端倪，fastcgi部分一共支持两个预置变量\\n\\n* $`fastcgi_script_name`\\n* $`fastcgi_path_info`\\n\\n从命名看出和CGI规范也是符合的，那么这两个变量怎么赋值呢？\\n\\n答案就是通过`fastcgi_split_path_info`这个命令字。这个命令的参数是捕获两个变量的正则表达式，捕获对象是$uri，前一个赋值给`script_name`，\\n后一个赋值给`path_info`。`PATH_TRANSLATED`这个变量好像没什么用，没有在nginx内赋值程序也能正常执行。\\n\\n看一段PHP代码时，发现URL映射很不寻常，用了/index.php/article/?s=a这种格式。印象里.php这个SCRIPT_NAME在末尾，最多就是再跟个`QUERY_STRING`。查了CGI规范，允许这种写法，且后面的/article/还有标准名字，叫`PATH_INFO`。\\n\\nPHP对`PATH_TRANSLATED`的支持有点问题，以前是和`SCRIPT_FILENAME`一样，但这不符合CGI规范，现在默认已修正，但还有个cgi.fix_pathinfo=1选项能倒退回以前的行为。归根结底CGI就是先定位到一个文件，在这个文件基础上附带参数。参数分两段，`/`之后(含/)的`PATH_INFO`和`？`之后的`QUERY_STRING`。在Apache或PHP -S选项下，只能写成/index.php/article，而nginx由于用了更灵活的正则匹配方式，写成/index.php-article也可以识别并正确引导。\\n\\n`parse_url`函数会拆解成5个部分，scheme, host, path, query, fragment。在这套定义中`script_name`是path的一部分，不是独立元素。"}'));jctx.push(JSON.parse('{"id": "161213", "tag": "web", "text": "# BW博客系统简探\\n\\n从index.php开始看，先用`include_once`手动导入system.php，这里有个逻辑很有意思：\\n检查conf这个目录下有没有info.php文件，如果没有则使用header的Location重定向到install向导。\\n然后定义了`spl_autoload_register`，把类文件的目录确认到inc目录。\\n\\n准备工作之后，index.php自动加载Canonicalization类，在构造Canonicalization时会读取一个全局的\'M\'变量，根据M的值会决定一个mode目录下的文件，这个M的值通过loader方法返回作为`include_once`的参数，触发了mode目录下对应的文件。\\n\\n首页没定义M，默认值是index，经switch的计算变成cate.mod.php。mode目录下都是php文件，且不是定义，都是执行流程。\\n先读取数据，创造View类，这是BW自己写的模板引擎，\\n其思路是把页面拆成若干部分，每次在输出前选择需要的部分，\\n选取后调用View->setWorkFlow保存，支持preg替换实现了load/loop/if三种语法结构。\\n替换后的结果送给浏览器渲染。\\n\\n在代码层面，具体的mode代码只管调用View的finalize。会调用generateOutput，这里引入components.php并把一个$parts的变量赋值。\\n设置theme成员变量。比如default，\\n进而把theme/default设为文件的读入源。通过`ob_start`方式把文件载入，最终输出。\\n\\n路由用的是`$_SERVER[\'PHP_SELF\']`。这个变量和`$_SERVER[\\"REQUEST_URI\\"]`相比，\\n少了`QUERY_STRING`部分，比`$_SERVER[\'SCRIPT_NAME\']`会多一些脚本后的值。\\n至于`__FILE__`和`$_SERVER[\'SCRIPT_FILENAME\']`这两个是一样的，不过使用场景不一样，\\n因为表示的是本地的路径(即Windows是D:\\\\这种风格，当然这在nginx.conf还是有大用的)。\\n\\nbw甚至还有一套插件系统，会把注册的手册写入SQLite的extensions表，在启动时读入，\\n然后去根目录的extension目录找同名文件夹，然后加上`ext_`前缀构造类，\\n并调用类的init方法。网页的插件大约就是这个模样。"}'));jctx.push(JSON.parse('{"id": "161217", "tag": "web", "text": "# PHP的SESSION机制\\n\\nHTTP/HTML起初是为展示文件而设计的，天然就是短连接没有状态。\\n像登陆业务却需要长连接，加之PHP又不具备daemon化特征，因此解决这个问题就要有些技巧。\\n\\n先说短连接，TCP基于无连接的IP能达到流式效果，大概是有TCP首部的序号和确认序号机制，\\n要在HTTP的短连接上要达到同样的效果，一样要有类似TCP序号的标记，这就是COOKIE。\\n比如第一次登陆后返回一个特殊的COOKIE值，下次客户端把COOKIE带上，就能在短连接上模拟长连接的效果了。浏览器出于安全方面的考虑，不会主动添加COOKIE，都是由服务端增加，有时会对COOKIE设置超时时间，到了之后浏览器删除。\\n\\n传输层面的问题解决了，接着就是服务端识别问题。如果像C或Java一直在监听，只需要把会话号记在内存就可以了，PHP却只能依靠持久化的方式，比如写文件来标记。\\n前面提到COOKIE必须是服务端主动添加，要开启该功能就要调用`session_start`函数，也可以理解为服务端要向HTTP回复中写入Set-Cookie了。\\n\\n通过HTTP请求抓包中的COOKIE部分进一步地理解(如果是服务端返回则用Set-Cookie)：\\n\\n* Cookie: TRACKID=6a366db255a08732cc44b1e1913dd2da; PHPSESSID=hamehnglgsj2sg6nbguq2146o3\\n\\nTRACKID是Lighttpd的`mod_usertrack`模块产生的，用于配合clickstream功能，不去分析它，只关注PHPSESSID。PHP的session和上例的Key=Value类似，对应PHP的两个函数：\\nKey是`session_name()`，可以在php.ini自定义，对应HTTP包头中的标记，不同的语言都会有不同定义，JSP默认用JSESSIONID定义。\\n\\n* session.name = PHPSESSID\\n\\nValue是`session_id()`，同样在php.ini有两个设置项\\n\\n* `session.hash_function` = 0  // 0-MD5，1-SHA1\\n* `session.hash_bits_per_character` = 5 // 每5bit生成一个可打印字符\\n\\nvalue不能由用户定义，但可以变换表现形式。以上的例子使用MD5且每5bit表现成一个字符，因此128/5=26。和抓包符合。\\n\\n下一个问题，每次请求来的时候PHP被唤醒，因此必然会把持久化的session恢复到内存。持久化方式有files、memcache、redis等，当然最简单的还是files。\\n\\n* `session.save_handler` = files  // 对应的方法`session_module_name()`\\n* `session.save_path` = \\"/tmp\\"\\n\\n如果files就要配置保存路径。对应memcache的话就是IP和端口。\\nfiles的名称一般是`sess_idvalue`，对应刚才的抓包，持久化的文件名就是`sess_hamehnglgsj2sg6nbguq2146o3`。每次请求到来，根据Cookie构造出session文件名，如果能读取文件，说明会话存在，从这个文件就可以还原回上一个状态。\\n\\n当然session的id值不能一成不变，默认3小时一换。通过`session.cache_expire = 180`来调整。\\n会话的id值如果想省事可以交给PHP来生成。高级点的玩法比如通过浏览器请求的其它数据来构造，\\n然后先调用`session_id`再调用`session_start`，就能自定义会话号了。\\n不过看反馈，似乎把`session.use_strict_mode`置为1会失效。\\n\\n如果要在PHP中打开会话，调用`session_start()`，先检查`$_COOKIE`变量(由HTTP包头的Cookie构造得来)里的PHPSESSID。\\n如果存在和COOKIE[PHPSESSID]对应的文件，就读取这个文件，并通过`session_decode()`得到`$_SESSION`变量，\\n除非我们手动管理会话的持久化方式(比如用redis或其它数据库)，否则不调用`session_start`直接访问`$_SESSION`，因为变量没有构造，PHP会报警告。\\n\\n`$_SESSION`里的键值对的持久化方式可配\\n\\n* session.serialize_handler = php\\n\\nphp和serialize()一样，还有binary等其它方式。至于会话内容可以通过`session_encode()`看到，修改后再用`session_decode()`设置回`$_SESSION`。\\n\\n说完服务端，再说说浏览器端。每次发起请求，看似只是个地址，但头部至少有Host, Connection, Agent, Referer, Cookie字段。即使跨域也会携带Cookie，这也是引起CSRF的根本原因。\\n\\n总结起来可以说，Cookie是有形的手，而Session是无形的手，要启动这只无形的手，需要`session_start`的一声令下。"}'));jctx.push(JSON.parse('{"id": "161219", "tag": "web", "text": "# PHP模板引擎学习\\n\\n用了3种模板引擎，从Smarty入手，但是这个库很大，文件又多。另外找了两个模板库，\\nTinyButStrong(简称TBS)和RainTPL。TBS这个库很有欺骗性，可能和Smarty比确实小，\\n但也有近150K。说真的不能算tiny，而且它的功能有点过于强大了。\\n可以直接把SQL查询语句写到模板赋值里，\\n这大大超过了我的期望。RainTPL是个约30K的单文件，在3者中最符合我胃口。\\n\\n既然是模板引擎，除了最常用的赋值，次常用的就是循环了，TBS太复杂，\\n就比比Smarty和RainTPL吧。\\n\\nSmarty的循环语法相当不直观，类似下面这样\\n<pre>\\n<% foreach item=rs from=$arivList %>\\n<% $rs %>\\n<% /foreach %>\\n</pre>\\n尤其是item=和from=那两句，每次都让人无法记住，而且你还不知道怎么表示key。\\n反观RainTPL，简单到爆啊有没有\\n<pre>\\n{loop=\\"arivList\\"}\\n{$value}\\n{/loop}\\n</pre>\\nRainTPL直接把键值命名固定，和Tiny一样。其实我觉得这种地方真没有定制化的必要，\\n都是程序员，简单直观就行了。有现成的$key和$value，谁愿意自定义啊。\\n而且自定义又增加了上下文关注的成本，我觉得是非常不划算的。\\n\\n从刚才的循环可以看出，RainTPL使用了`{}`花括号对方式来标记，\\n和TBS的`[[]]`又或者Smarty的自定义一样，和HTML区分开。这里又要说说Smarty，\\n这种没有必要的自定义，挺分散精力的。\\n\\nRainTPL除了{loop}和{/loop}之外，也提供了常用的其它语法\\n\\n* {include=\\"xxx\\"} 从html模板的目录下导入文件，由于RainTPL可以配置后缀，\\n所以这里不用填.html字样\\n* {if=\\"expr(true/false)\\"}{elseif=\\"\\"}{else}{/if} 分支语法，风格一致很好记\\n* {function=\\"foo($bar)\\"} 在html写函数，不过暂时觉得没什么用？\\n* {$value.name|strtoupper} 把一个变量作为`|`后面的函数的参数，用返回值替换，\\n有点pipe的味道，不过我还是倾向尽量不要在模板中引进这种太花巧的语法。\\n* {noparse}{/noparse} 在这中间的变量不作转换\\n* {ignore}{/ignore} example没有示例\\n"}'));jctx.push(JSON.parse('{"id": "170106", "tag": "tool", "text": "# 排版软件的故事\\n\\n英文中把文字处理分为Typewrites和Word Processors两大类。平常用的Microsoft Word\\n是所见即所得的字处理系统，适合日常的书信、报告。而专业的书籍排版由于周期长，\\n版面要求精细往往有更高的要求。当前最有名的是TeX，在TeX之前是贝尔实验室诞生的roff系统\\n(GNU实现版叫groff)，不过现在比较式微。另外还有XSL-FO也经常被企业用来制作文档，\\n好像Apple的一些文档就是用这个格式。不过这个标准实在不怎么样，2013年11月后，\\nW3C推荐CSS3 Page作为替代标准，这个XSL也就永远地停留在1.1版本不再演进了。\\n\\n先说句题外话，由于这两个排版工具出现的年代还是Unix的远古时期，那时的编辑器分为\\nline editor和screen editor。line的典型就是sed，screen则是现在耳熟能详的vim/Emacs。\\n不过现在硬件性能提高，各种编程语言也很易用，惟一还有人知道的sed也显得无关紧要了。\\n\\nTeX的第一版是1978年发布的，通常也称为TeX78。而roff要早一点1973年。\\n既然roff的历史更早，就从它说起吧。roff的全称是run off，和所见既所得的排版区分，用off表示离线的概念。\\nroff分为nroff和troff两种实现。现在我们用的GNU groff则是对这两个版本的封装，和gcc封装\\ncpp、cc1、as、ld是一个意思。\\n\\nnroff使用等宽字体，行为像打字机，man的背后就是用它，在终端上至今都运行得很好。\\n而troff可以用各种字体，适合于打印机。最早的nroff只能用在C/A/T打印机上(phototypesetter)，\\n原因就是贝尔实验室在1973年买了台C/A/T。这是台1971年设计的打印机，共支持4种字体：\\n英文字符Roman的regular/bold/italic再加一个特殊记号的Special。\\n买了之后Ossanna才基于C/A/T硬件写出了nroff，在今天看来，只为一种打印机写程序是很死板的，\\n直到1979年Brian Kernighan重写了ditroff，取意device independent troff。\\n现在看到的troff都是ditroff了。直接的现象是groff程序字体目录下devps、\\ndevlbp这些带dev前缀的目录，就是能被ditroff处理的字体。\\n\\n高德纳发布的TeX由于只支持英文，在东亚国家是无法使用的。最早着手解决这个问题的\\n是日本的ASCII社，发布了pTeX程序，p是publishing的意思。慢慢的TeX社区也意识到这个问题，\\n就有了XeTeX，后来又有了luaTeX，都能支持Unicode编码。\\n\\n中文地区很有名的是CTeX套装包，安装后程序的目录结构是这样的：\\n最重要的是miktex目录，是个windows下很好的移植版本。这个目录下的miktex/bin包含各种可执行程序。\\n包括pdfTeX、XeTeX、luaTeX三大著名引擎以及其它各种需要的程序。\\n其中pdfTeX是三者中最老的，它最早支持了pdf特征，不过似乎不支持Unicode。\\n和bin平级的还有各种辅助目录，比如font等等。\\n\\n其次重要的就是CTeX目录，这里包含了旧式的cct包和其它中文宏包。\\n也是这个套装的命名来源。处理程序有了，Ghostscript和GSview则用于预览。\\nWinEdt目录是TeX的集成开发环境，最后一个UserData放的好像也是字体和配置。\\n\\n想要从命令行直接运行LaTeX，即使是我都感到非常困难，背后的概念实在太多。\\n所以有Lyx这样的套件来简化，它只用到了XeTeX和luaTeX这两种引擎。"}'));jctx.push(JSON.parse('{"id": "170108", "tag": "tool", "text": "# 排版和字体的关系\\n\\n上一篇说了排版，排版之所以这么复杂，和字体有很大关系。\\n西文字体每个词长度不一致，在排版上首先要处理的是一行文字的fill/justify/hyphen问题。\\nroff的任务就是处理文字的这3大问题，其它的诸如表格、公式、图片则需要tbl/eqn/pic来辅助。\\n\\n要解决好justify问题，必须要知道每个文字的宽度。至于文字怎么描绘，\\n其实排版软件可以不关心，丢给打印机就行。这里要引入两个字体中基础而重要的概念：\\n\\n* metric 指文字尺寸，具体包含字符编码定义、字符宽度和四个角的坐标。\\n* glyph 指某个文字的外形，即要怎么描绘。早期是点阵方式，现在都是矢量字库，给定字符的一些点，并用贝塞尔贝曲线把这些点连接起来。\\n\\n刚才提到排版软件不关心glyph，roff也确实是这么做的。它的字体就只含metric不含glyph。发送给output device的只是文字的编码和尺寸。\\n\\nroff和TeX把字体中的metric和glyph分离，二者由于历史久远，用的都是现在很少见的字体格式(严格说是metric)。\\nroff叫DIT(Device Independent Troff)。而CTeX目录下能找到很多后缀是.TFM文件(TeX Font Metric)。\\n\\nAdobe的metric叫AFM文件(Adobe Font Metric)，含文字的宽度和四角坐标。字形glyph是PFB格式。\\nPFB是Type1字体的Binary形式，可以用pfbtops转成pfa文件(其实就是ps源码)，因而支持矢量方式放大无锯齿。\\n\\n以上3种metric格式可以互相转换，roff目录下的afmtodit和tfmtodit，miktex下的afm2tfm，都是用于metric转换。\\n\\nroff做完排版，渲染就交给具体的机器，不关心字形，用的glyph也是随着不同的机器而不同。比如devps，输出为ps就依赖pfa文件。而高德纳为了追求TeX的效果优美，给制作glyph开发了METAFONT。这是一个独立完整的工具链。\\n\\nTeX输出的字体格式，早期当然是 MetaFont -> 点阵 GF(generic font) -> 输出设备驱动；后来有 pk 点阵字体(其实是gftopk转换后的压缩格式，是PacKed简写，好随便啊)；再后来有 PostScript 矢量格式的 Bluesky 人工重制的 computer modern字体和程序自动重制的 cm-super 字体等。\\n\\n最早的TeX只支持读取tfm文件，一个完整的TeX字体（MetaFont生成的）为一个tfm文件和pk文件，前者负责字体的抽象部分（如ligature，kern等），后者负责描述字体的实体部分（即字体的glyph具体长什么样子）。TeX出现的时候Adobe还没成立，为了让打印机能复用pk字体，后来一些开发者将MetaFont的字体转换成PostScript的字体，通过dvips或者dvipdfm将dvi转换成ps或者pdf文件。\\n\\n## 现代字体格式\\n\\nroff和Tex都是相对古早和偏极客的技术了，说说更被大众熟知的字体吧，按历史发展脉络大致如下\\n\\nType1 -> TrueTypeFont -> OpenTypeFont(Type2) -> WebOpenFontFormat\\n\\n从名字就能看出，Type1是Adobe众多Type X中最早也是最有名的，原因有几个:和PostScript一起出现得最早，标准开放，支持hint因此在小字号效果较好。作为对比Type3虽然支持完整的PS特性，但没有hint，也缺少在各平台编辑软件。所以尽管现在不是主流格式(相对TrueType)，但在技术上无法忽略。\\n\\n为了对抗Adobe，微软和苹果联合发布了目前依然是最常用的TrueType字体，但后来微软又和Adobe一起发布OpenType，由于微软同时参与两个标准，所以OpenType如果包含TrueType字体，后缀仍用.ttf；如果包含PostScript，则用.otf后缀(叫Type2顺理成章)。也许大家都觉得分离式字体不好，所以自TrueType以后，都是整合成一个文件的路数。\\n\\nwindows上常见的字体还是TrueType，一般以.ttf结尾。中文宋体的后缀是.ttc，意思是TrueType Font Collection，是把多个文件整合到一个文件中，多用于CJK的字体包。\\n\\n随着Web化普及，为克服传统的字体文件过大问题，2009年诞生了WOFF字体，使用压缩技术，通常比TrueType小40%。后来的WOFF2则更进一步用brotli替代了原先的zlib算法，达到更高的压缩率。这些字体都采用sfnt封装技术。\\n"}'));jctx.push(JSON.parse('{"id": "170109", "tag": "design", "text": "# 业务分离和厘清概念\\n\\n所有服务端的程序，都离不开3A(Authentication Authorization and Accounting)。其中又以前两个最容易混淆。一般把鉴权称为A1，授权称为A2。在Apache中的简称则是authN和authZ。我们的程序在校验权限时，一般是长连接，所以A1交给登陆认证模块，后续不再考虑，加上没有计费，所以只有A2。\\n\\n校验权限的回调接口是这样的：`bool cbCheckAuth(const char*, void*, char*);`第1个入参是请求的方法名，第2个入参是对应的参数，第3个出参是对应的权限名称。返回值为true表示找到权限，而false表示不关心，采用默认策略。这时有个新需求，某些敏感操作比如重置系统即使用admin登陆，还需要再次确认用户身份。显然现有的接口无法满足需求，我本来想通过返回false，并且用第3个参数表示错误码的形式来做，但是这个想法不被认同。于是仔细查了3A的概念，既然身份确认属于A1，放在A2的阶段确实不合适。有了理论依据接下来就简单了，在检查A2前增加一个A1的检查函数。\\n\\n平时做很多业务，都没有把业务划细。虽然平时经常说分层，但对于怎么分层并没有标准，我的理解就是只要能把业务里的每个概念、差异点给明确了，把不相同的概念隔离开，层次自然就出来了。否则只能是拍脑袋凭感觉，是无法让其他人信服的。"}'));jctx.push(JSON.parse('{"id": "170110", "tag": "tool", "text": "# groff中间格式翻译\\n\\n使用x作为控制命令，#号后面是注释(不确定是否必须放在开头)。\\n输出分为prologue和body两大部分。\\n通过man的例子可以看到，最简单的骨架大概是这样的：\\n\\n```\\nx T xxx    # device name like ps or X100\\nx res x y z\\nx init\\npnum       # this is page\\nx font 1 R # this 3 line indicate font has been chosen\\nfnum\\nsnum\\n# text begin position\\nVxx\\nHxx\\n# your text\\ntyour\'s input letter\\n# end\\nx trailer # this is actually just ignored\\nVxx\\nx stop\\n```\\n\\ngroff的中间语言为简单命令、画图命令(D族Graphics Commands)和\\n控制命令(x族Device Control Commands)三大系列。\\n这个例子大量使用了x这个指令族。\\n\\nD族中最灵活的指令是D~画B样条，另外有画arc、cicrle、line等各自形状，\\n加上填充颜色。这些指令构成了pic这条扩展命令的基础。\\npic能画的图形也就是上述说的这些。\\n\\n说完中间格式再说说字体。字体文件放在devxx目录下，分为DESC和其它两大类。\\n两种文件的指令集不同。\\n具体的字体文件分为两段式，先是开头的字段说明如name或spacewidth，\\n接下来是kernpairs(可选)和charset(必选)。charset格式如下：\\n\\n    name metrics type code [entity_name] [-- comment]\\n\\n真实的例子像这样：\\n\\n    u0041_0300\\t24\\t0\\t0x00C0\\n"}'));jctx.push(JSON.parse('{"id": "170121", "tag": "lang", "text": "# Json中的null和undefined\\n\\n由于Json是来自于JavaScript，因此讨论Json中的字段必须要回归到JS中。\\nnull在JS语言定义里是一个字面量，且是基本类型。如果typeof null会返回Object。\\n据说是因为想把一切变量都作为对象，所以会有这种定义。虽然这是个历史错误，组委会也曾经讨论过改成null，\\n但是考虑到大量代码已经在使用，就不去改变它了。\\nnull的类型是Object这点争议很大，但既然规范如此只能按这个思路去理解它。\\n大概就是null不是空引用，而是一个原始值，它期望被引用成一个对象，因此null自己也是Object。\\n\\n而另一个undefined则不是基本类型，它是全局对象的一个属性，更像是值。\\ntypeof undefined比较明确直观，还是undefined。\\n\\n然后回到Json，构造一个变量比如val = {a:1, b:2}，此时val.c的值是undefined。\\n原因是这里本来就没有c这个属性，也并不期望c会引用另一个对象，\\n所以值不能是null。另外我觉得，比如把a的值赋为null，在动态类型的角度\\n这样做也无可厚非，但是静态类型是有严格的界限的，如果a应该是string，\\n结果被置为null，会改变它的类型。\\n\\nJavaScript秘密花园称undefined更像其它语言的NULL，而js的NULL在语言内部另有它有。\\n比如js的函数未定义返回值，返回undefined。在PHP中未定义函数返回的是NULL。\\nLua函数未定义也是返回类似nil的效果(我理解这更像是一种编译器的优化作用，而非固有语义)。\\n比如function foo(a) a=a+2 end这样一个函数，直接print(foo(1))会输出一个空行，\\n而如果显示地return nil，则print会输出nil，说明Lua的VM在某种程序区分了undefined和nil，\\n只是无法在Lua中表现而已。\\n\\n再说一个关于undefined的事，将一个JSON串序列化成对象，如果取一个不存在的值，jsoncpp库会根据取的类型赋以默认值，\\n如asInt是0，asString则是\\"\\"。但在JS里，则直接返回undefined，如果对这个值进行parseInt，返回的也是NaN，而不是0。\\n所以严格来说，jsoncpp对不存在的值进行asDouble要返回NaN，但并没有这么做。\\n一方面是因为`C++`语言没有对应undefined的概念，加上又是一门强类型语言，用之前必须要指定一个值，\\n所以只能拿近似的NULL并转换成对应类型的0或\\"\\"充数了。"}'));jctx.push(JSON.parse('{"id": "170202", "tag": "os", "text": "# procfs记录\\n\\n## 历史\\n\\nprocfs诞生于1984年的Unix第8版，愿望是对ptrace的一种改良。起初是每个进程对应一个文件，经过Plan9改造成伪文件系统，且成了Linux的代码来源，所以在Linux用得非常多。Linux多年的改进，已经不限于进程的内容，还加入了CPU、内存、中断等各种信息。\\n\\nFreeBSD用的是sysctl，并对procfs说`Gone but not forgotten`。原因大概是sysctl最初就是4.4BSD开发出来的，而BSD社区的人更倾向用sysctl，加之procfs的代码在BSD社区中没什么人维护，所以就逐渐转移了。Linux的/proc/sys/也具备类似sysctl的功能，命名风格很像但不相同。类似的，solaris的kstat的实现是用ioctl去操作/dev/kstat。sysctl和solaris都是专属命令工具。相应的，/proc伪文件系统，可以直线用各种命令行工具操作。\\n\\n因为procfs下被塞进了太多东西，所以Linux的2.5版开发了/sys/虚拟文件系统。\\nsysfs最初是设计用于提供设备驱动的统计数据，后来不断扩展，能察看和操作内核对象。在2.6内核出现了configfs用于创建和销毁内核对象，两者互为补充。不过在configfs并不是都有的。\\n\\n造成两个系统差异的根本是内核对sysctl支持程度不同。BSD内核直接开放sysctl，所以整个社区也倾向用它，而Linux虽然也有sysctl，但却是基于procfs的一个wrap，性能上会差很多。\\n\\n## 解读\\n\\n* smaps: 程序自身以及加载so的段内存映射。第1个似乎是程序自身程序\\n\\n* task目录: 只有多线程程序，进入这个目录才会发现更多的TID对应的具体信息\\n"}'));jctx.push(JSON.parse('{"id": "170203", "tag": "web", "text": "# CSS的一些理解\\n\\n## 写在前面\\n\\nHTML是SGML/XML的一种特殊应用或者说DSL，标准的网页写法是`<!DOCTYPE html>`，与之对照的DocBook的首行写法是`<!DOCTYPE article>`，而SVG图像的写法是`<!DOCTYPE svg PUBLIC >`。\\n(`<!DOCTYPE>`是SGML的语法，和注释语法`<!-- -->`参照就好理解了)。\\n凡是符合XML定义的文档都必须通过DOCTYPE指定DTD，而浏览器天生就为显示HTML，即使不指定DTD，只要开头有`<html>`标签就默认当作网页来解析了。\\n既然是SGML系，整体风格都是树状。原生如h1,p,table等标签就属于CSS1范围的选择器，浏览器内建了各种HTML标签的CSS基础样式，因此最简单的网页，哪怕不定义任何CSS也具备一定可读性。当然除了原生的选择器，还有类选择器、ID选择器以及伪类等高级用法(当然对应CSS的级别也更高)，这时就必须由用户指定样式，浏览器只负责渲染。\\n\\nCSS作为大HTML的一部分往往会被浏览器缓存，虽然在HTML层面可以用一些方法控制缓存策略(比如PHP的setheader或者在HTML用<meta HTTP-EQUIV>>标签强制修改缓存策略为no-cache，但CSS作为外链的附加属性就没这么幸运了。通常的作法是在引入CSS文件的末尾加上?v=1标志，当CSS内容有更改时，则改变v的值，由于CSS文件链接在HTML中，HTML可以控制不用缓存，浏览器读取到新的v值就会重新获取CSS文件。否则只能用Ctrl-F5的方式强制更新，界面才会用上新样式。\\n\\n前端领域一直在快速变化着，对CSS的认识也有很多流派，就有一些人认为 [[不合时宜的CSS]]\\n\\n## 视口\\n\\n手机版页面的文字非常小，且经常要来回地拖动。几经查找看到viewport概念，是Apple的mobile safari首先提出，后来各个移动浏览器厂商都跟进了。具体地说在html的head部分加这这样一句，网页效果会如你所预期那样：\\n\\n```\\n<meta name=\\"viewport\\" content=\\"width=device-width,height=device-height,initial-scale=1.0,maximum-scale=1.0,user-scalable=no\\" />\\n```\\n\\n这里面最重要的莫过于width=device-width和inital-scale=1.0两句，由于不同设备的宽度不同，有了device-width指定可以大致做到不同页面如预期，但如果没有inital-scale，至少在这个博客上会非常难看，正文栏所占的宽度很窄，加上之后所有的内容就正常了。再说一句user-scalable，如果没有这句，每次焦点到输入框，页面会稍稍扩大一点，有种跳变感。再者对手机网页来说一旦可以缩放，反而会来回拖动体验未必就好，不如一开始就把布局字体设置妥当，之后就不必调整了。\\n\\n## CSS五大主题 up 18年3月24日\\n\\n第一次学以为CSS就是布局，随着看文章变多，才知道范围庞杂，至少包括\\n\\n* 样式: 范围最广，包括但不限于颜色/字体\\n* 数字/单位/函数\\n* 布局: 盒模型\\n* 层叠和继承\\n* 选择器: 很难记忆，但它是理解CSS的关键 [[论为什么CSS难学]]\\n\\n### 样式\\n\\n这可能是相对比较好理解的主题，也是最早就有的内容。HTML5丰富了b/i等各种样式元素，使HTML更专注于语义层面。\\n\\nvalue是元素的属性值，比如form控件当前的值。而innerText和innerHTML是元素开始和结束标签之间的值，可能不能编辑，比如div元素。\\n\\n### 数字/单位/函数\\n\\n这块内容比较繁琐，也很难记，加上还要考虑各种不同屏幕的差异，细节非常多。\\n\\n* px/em/rem: 默认字体大小16px，对应1em\\n* vw/vh: 相对宽高，1表示1%的总宽度/高度\\n* fr: grid布局的单位\\n\\n关于px单位，引用hax的解释\\n\\n>    CSS规定，浏览器应该对像素值进行缩放调节，以保持阅读体验的大体一致。也就是要保持一定像素的长度在不同设备输出上看上去的大小总是差不多。 因此CSS提出了“参考像素”（reference pixel）概念。规范使用视角来定义“参考像素”，1参考像素即为从一臂之遥看解析度为96DPI的设备输出（即1英寸96点）时，1点（即1/96英寸）的视角。 请注意这个差别——CSS规范定义的参考像素并不是1/96英寸，而是1/96英寸在一臂之遥的看起来的视角。通常认为常人臂长为28英寸，所以其视角可以计算出来是0.0213度，即(1/96)in / (28in * 2 * PI / 360deg)。\\n\\n可以看到px和物理分辨率并不等价，对PC而言，由于人眼和显示器的距离与CSS定义基本一致，二者近似划等号；而手机的分辨率虽然高于PC，但仍然要符合规范，因此手机屏幕宽度px值会比分辨率小很多，具体多少px由每个厂商各自定义。从而保证了16px字号在不同显示设备上看起来的视觉效果是接近的。\\n\\n函数只有预定义函数，比如counter/calc可以进行数值计算，url则可以进行外部资源的导入。要想添加自定义函数还得靠预处理器。\\n\\n### 布局\\n\\n盒模型包括margin, border, padding, conntent 四个部分。差别是对高宽的范围定义。\\n\\nCSS最初并没有定位在布局功能，只是意外地发现盒模型配合float可以实现布局效果，但用float方式不仅需要很多hack手法，还破坏元素间关系，所以增加了flex和grid作为更专门的布局手段。\\n\\n规范定义的盒模型只有block和inline两大类，block的原始语义是一个元素占有一行，主要有div/list-item/table这几种。block能内嵌block/inline，而inline只能内嵌inline。（题外话：由于table的历史比CSS更早，所以CSS用在table时，会有特殊的地方。再提下CSS与HTML历史的兼容性，由于CSS出现得比HTML晚，因此它一定要把HTML中所有的元素的特性纳入到自身的体系结构中。比如HTML的head标签不会显示，对应盒模型的属性就是display:none，不会影响布局，而body就是display:block，作为顶层的BOX容器呈现。任何新生事物都要能包容已有系统的能力，才是可被推广的系统。）\\n\\n和布局相关的三个关键字的优先顺序为display(不为none)>float(不为none)>position。CSS早期的术语来自印刷排版，被用于布局的float就来自印刷的图文混排，而position虽然字面意思就是定位，有relative、absolute、fixed等多种方式，且确实能实现精确定位，但强依赖尺寸计算，有些场景反而不如float好用。\\n\\nfloat用在布局时，一个父div内顺序放置多个div，每个div都设置成float，宽度未满时从左向右排列，如果宽度达到父div的上限，另起一行排列。举例来说，如果父div的宽度是90%，第一个子div是50%，第二个子div是40%，这两个就在同一行，如果第二个也是50%，就会被挤到下一行。\\n\\n归根结底本来每个div单独占据一行，如果想让多个div在同一行，就要破坏div的block特性，让想处在同一行的多个div能float(漂浮)起来，注意必须都float才行。一旦这样块之间就再不是固定的排列关系，而要取决于div宽度总和，如果宽度够就被放在一行了。如果超出了，还是排列到下一行。排到下一行后，可以用left或right来决定对齐方式。\\n\\ninline-block方式是对早期bug的一种不得已的合理化。比如有3个顺序的div，如果1和3都是inline-block且总宽度和小于父block，直接把1和3排列到一行里，如果这一行的剩余宽度还能放下第2个div，就放在同一行，否则在下一行排列。但是如果第二个div是float:left，会放在第一个div前面。\\n\\n### 层叠和继承\\n\\n两个相近但不同的概念，先说层叠，CSS的C代表层叠，也是CSS与其它布局方式最大的不同。CSS的所有变量定义是全局的，因此必然存在冲突，解决的办法就是层叠的规则。样式来源有5个\\n\\n* `<a style=\\"\\">`  属性样式，又称内联样式\\n* `<style >`  内部样式表\\n* `<link>` 外部样式表，又名外部样式表\\n* 浏览器用户自定义样式\\n* 浏览器默认样式\\n\\nCSS权重规则的特殊性可以用4个整数来表示，例如1，0，2，0这样一个4元数表示，计算规则从高到低排列如下：\\n\\n1. 对于内联规则，权重值表示为1，0，0，0\\n1. 对于规则中的每个ID选择符，权重值表示为0，1，0，0\\n1. 对于规则中每个类选择符和属性选择符以及伪类，权重值表示为0，0，1，0\\n1. 对于规则中的每个元素名或者伪元素，权重值表示为0，0，0，1\\n1. 对于通配符，权重值表示为0，0，0，0.\\n\\n最终得到结果就是这个规则的权重。两个权重值的比较类似字符串大小的比较，是从左往右依次比较，第一个数字大的规则的权重高。\\n\\n还有一种层叠，`<p class=\\"A B C\\">`，这时ABC三种样式会层叠后作用在p元素上，ABC属性的层叠原则，和class属性中的排列顺序无关，而是取决于怎么定义，其中规则非常复杂，这里就提最简单的一种，所有都是单独定义（没有父子、兄弟或important时），最后的定义覆盖早先的定义。如果A最后被定义，层叠的结果就是A。\\n\\n继承这个特性是由HTML的结构化特性导入的。像color、font-size、font-family、text-align这些属性，会在给父元素设定后传递到子元素甚至孙元素的样式中，这些子元素/孙元素会得到样式的渲染，就是CSS的继承机制。不是所有属性都会继承，像margin/float等都不会继承\\n\\n### 选择器\\n\\n由于HTML的树状结构，对元素渲染时一定会遇到对某种具有父子或兄弟的元素采用特殊属性的场景，选择器提供了丰富的语法来支持如何选中树结构的某类元素\\n\\n## HTML转PDF的技巧\\n\\nCSS的@media print可以单独控制打印稿的样式，格式\\n\\n```\\n<style>\\n@font-face {font-family:\\"MyF\\";src:url(\\"file:///C:/Windows/Fonts/lucon.ttf\\");}\\n@media print {\\np.xx_font { font-family:\\"MyF\\"; !important}\\n}\\n</style>\\n```\\n\\n用wkhtmltopdf一定要加上--print-media-type才生效。-s 指定页大小，格式化的有 A0-A9, B0-B10，另外还有数种Letter, Ledger, Folio, Tabloid格式。要控制页边距，则用 -B -T -L -R 后面跟实际的物理单位控制。一台5.5寸手机大约在B7和B8之间。\\n\\n指定字体更复杂一些，首先通过font-face定义一个字体名，并用绝对路径方式定位到字体，因为是src:url导入的外部ttf文件，所以必须通过css类关联到元素才能改变字体。\\n"}'));jctx.push(JSON.parse('{"id": "170207", "tag": "design", "text": "# 仔细打磨写过的程序\\n\\n从去年12月到最近，把公司内的AppWiki网站还有这个博客网站的代码，重新进行了调整，颇多感触。\\n\\n比如代码中早期很多地方因为求快都是HardCode，最典型的比如AppWiki的更新日期居然都是每天手动修改PHP，直到昨天才忽然想到可以利用stat函数取出数据库文件的mtime来自动更新，把依赖降到数据库文件本身。同样如博客的首页，原来是手写的2016、2017年，过了一年还要手动创建目录，改成每页固定显示10篇，用下部的页号签来自动导引。凡此种种都是让整个网站环环相扣，互相关联，自然就能有牵一发而动全身。\\n\\n还有就是AppWiki的解析代码，因为发现Win7的cmd用chcp65001转成UTF-8的显示效果比XP好了很多，就切过来了。但是原来的代码由于用ls来判断文件是否被更新，就依赖于终端的编码环境，造成移植的困难，加之需要批处理、VBScript和Lua三种语言共同使用，在Windows下速度慢不说，还屡次因不熟悉VBScript而苦恼，后来发现核心的VBS就三行代码，用luacom实现也不难，中途还顺手编译了luaiconv解决GBK到UTF-8的问题。整个切换完用一种语言实现，不仅速度快了，代码文件和中间文件也变少了。(因为不同语言只能靠中间文件来交互，导致目录下非常凌乱而难看)\\n\\n新的段落式解析代码，也一直有bug，多个文件只能解析第一个文件，当时不愿意解决，就用批处理的方式分次处理，后来为了提高自动化程度，把批处理也改用Lua来实现，就必须解决这个bug，直到早上通过打印才发现原来是解析完第一个文件后，协程状态就变成dead了。原因是协程代码在结束时用了return，必然会导致dead。这是我第一次用协程，对语义不熟悉造成的。一个dead的协程无法resume，而我整个程序始终用这个协程变量处理文件，所以超过一个文件就失败了。找到这个问题后，顺带发现原来的协程变量还是全局的，坏味道。把协程变量的范围缩小到函数内，并增加了协程状态判断，\\n保证每个新的文件解析开始创建一个新协程，解决问题。然后也按照三代协议解析代码重构的思路，用lua实现了比较文件时间，生成HTML和SQL并写数据库等配套环节。重构后的流程非常清晰，增加一份文档只要三步：\\n\\n1. 在man.old里添加源Word名称、更新时间和输出HTML名(这里必须用GBK，没办法)\\n2. 在解析代码增加一个入口，并确定文件的归类(我用了生物学上的Tribe)和层级，这个环节必须要人工干预\\n3. SQL脚本里加一项.read xxx.sql\\n\\n三个步骤分别对应Word->HTML->SQL->DB，任何人接手都能很简单地增加文档了。3月份的时候又做了一次合并，把1和2的内容都记入man.old，再通过中间得到的差分结果来生成SQL脚本，因此需要个性的就只有一个文件，是目前能想到的极限了。\\n\\n写代码是个不断打磨自己思路的过程，让流程更自然，环节更严密。"}'));jctx.push(JSON.parse('{"id": "170219", "tag": "lang", "text": "# 函数式和对象式，表达式和语句\\n\\n伞哥在微博提到，ML的函数语法如果有多个参数，当参数没有完整传入时，并不是像Lua/PHP等一样赋值为nill，而是返回一个curry化的函数。这种思路如果移到协议处理上来，和组件化的实现是不同的拆分方式。\\n\\n协议入口收集所有的参数，如果用curry化的思路，则每个步骤只处理一个参数，然后返回新的函数，并处理剩下的参数。如果第一个参数要做分派，则可能会返回两个不同的函数。通过这种方式，把过程拆分。\\n\\n如果是对象化的拆分，则根据业务划分若干阶段，每个阶段对应一个类，这种方式不会严格限定参数个数，可能第一次就处理所有的参数。不过函数式其实也可以处理所有参数，返回的函数接收新的参数也无妨。不管怎么样都是一个拆分的过程。\\n\\n## 函数式典型函数的理解\\n\\nscala没有break和continue关键字，因为它并不鼓励中途退出或跳过机制，而应先待循环的数据进行过滤再完整处理。引申出对函数式几个最典型函数的思考。\\n\\n* filter 传入函数 x => bool，只保留返回true的内容，达到缩减原始数据的效果\\n* map 传入函数 x => z，返回一个新的，但长度不变的向量数据集\\n* reduce 传入函数 x, y => z，返回一个“标量值”。之所以打引号，是形式上返回的结果可能不是一个简单的数字，但维度上，和原始向量数据的任一项是相同的\\n\\n如果要取向量的前3项怎么办？这时可以在filter中传入闭包，用闭包的状态是否到3来控制返回true还是false，因此这三个构成函数式处理的完备集合。另外从这种处理方式可以看出，只要顺序迭代器就能满足计算，并不需要随机迭代器，但从处理的便利性和效率上来说，随机迭代器有其不可替代的优势。\\n\\n对一个数据集做groupBy操作的结果，就是典型的顺序迭代器，一方面不知道总长度，更重要的是内部数据的无序性，导致随机访问没有意义。\\n\\n## 表达式和语句\\n\\n在PL界，不管平时有没有注意，大都会区分expression和statement。expression的定义是计算并返回值，而statement表示操作，对返回值没有要求，甚至干脆禁止。看似都有计算过程，无非是对返回值的区别，但细想下去，如果没有返回值，就只能靠全局变量来通信，显然是不行的。对函数式编程而言，expression是强要求。\\n\\nJS细分了语句和批语句，批语句必须有{}，典型如switch,try,catch,finally。而像if,for,while都可以省略。Lua严谨，只有批语句的概念。\\n\\n最直观体现两者区别的就是赋值。lua或python的赋值是statement，没有返回值，因此print(a=1)会报语法非法。而C、JS则把赋值后的左值返回，python3.8也加入了:=，使赋值成为表达式。还有scheme的set!实现了赋值，但返回是未定义值，可以打印但无意义。\\n\\nLua的函数返回0到多个值，而JS的函数只能且一定会返回一个值。返回多值的函数如Lua和Go，一种惯用法是返回值第一个为bool表示成功或失败，剩下的是实际需要的返回值。而JS和PHP都只能返回单值，加上JS的函数签名不支持显式引用，如果JS要从函数出参取值，只有使用对象才可以。"}'));jctx.push(JSON.parse('{"id": "170224", "tag": "web", "text": "# Openresty的应用开发\\n\\n每个版本都是在nginx的基础上做扩充，所以版本号会多出一位。ngx_lua、memc、srcache都是扩展。自带resty的命令行工具，启动一个`master_process off`的nginx程序，主要用于验证扩展的lua程序是否正确，配合测试极好。\\n\\n用lor框架开发，首先要记录关于路径的部分。启动脚本是通过nginx加载指定的配置文件来启动，从而实现dev或prod的简单分离。从nginx.conf看，整个流程的路径从app/main.lua进入，所有的路由也都记在这里。\\n\\n先在main.lua打印看lua的package.path，lor的默认配置类似\\"./app/?.lua;?.lua;...\\"，\\n当前路径的.到底是哪里的？开始我错以为是main.lua所在的路径，这是受了PHP的影响。\\n因为nginx和PHP的开发，说到底nginx只是个fastcgi的转发器，最终还是用PHP来跑，\\n所以PHP的话，路径是首个PHP文件入口，但是openresty方式不是，利用的是nginx的prefix path，默认是/usr/local/openresty/ngingx/这个。\\n但是我们的程序显然不可能放在这里，所以这个路径没有意义。幸好nginx提供了-p选项，在lor的start.sh脚本写法是这样：\\n\\n* nginx -p `pwd`/ -c conf/nginx-${PROFILE}.conf\\n\\n通过-p的方式把prefix path导引到lor所在的目录，于是main.lua中require(\'app.server\')就能顺利找到了。\\n\\n使用lord脚手架生成的程序，在根目录有main,server和router这三个文件，\\nmain的注意事项上面已经介绍过了，接下来说router。Web应用开发最主要的就是处理URL请求，\\n再细化一点，要根据方法要区分GET/POST。这个过程行话称为后端route。\\n能看到router文件中有类似app:get(\\"/hello\\", function(req, res, next) end)这样的定义，\\n这是一种框架定义的简写法，表明有GET请求到/hello路径时，触发与之关联的方法。\\nURL的写法似乎只支持原始的和/hello/:id/这一种扩展。不过即便是这样，\\n要实现PHP的Cemvc框架的路由效果也足够了。比如定义一个/lor/:cls/:mth/:param/的路由规则，\\n根据cls从已加载的业务代码中找对应的类。(因为lua语言的require如果失败会强制退出，\\n只能先加载再查询，这是语言不同带来的使用风格不同)。\\n另外function处理细节也比较多，后续再写了。\\n\\nserver是封装lor库的内容，使用app:erroruse函数，可以增加一些错误处理机制。简单的Web开发通过这三个脚手架差不多可以搞定了。\\n\\nnginx程序共四大阶段， 初始化 -> 重写 ->  内容  ->  日志。初始化阶段只在启动时会执行一次，以后再也不会执行，一般定义全局变量或加载常用模块，之后的请求就不用去磁盘加载文件了。如果这个环节的代码抛异常，会导致nginx启动失败。重写和内容对应客户端的一次请求，而日志在响应之后，因为是异步操作，不会影响响应时间。\\n\\n初始化分 init(作用于master) 和 `init_worker`(作用于worker进程)，重写有 ssl_certificate,(这是可选的) set, rewrite, access ，内容有 content(balancer), `header_filter`, `body_filter` ，日志只有 log 。\\n\\n每个阶段能做的操作是不同的，比如init阶段由于还没有收到连接，所以ngx.say没有地方可以输出，显然是不能执行的，只能执行ngx.log操作。相应的指令是 `error_log`，要指定写入的文件名和级别，如果代码中的级别低于`error_log`设置的级别，就不会输出。这条指令的名称略带迷惑性，不限于error级别，所有的级别都可以打印。最低级别的debug，需要编译时打开--with-debug选项才行，当然如果用户指定这个级别也能输出。\\n\\n开发阶段会开启`lua_code_cache off;`，这句指令只影响请求到来时要不要创建新的VM，显然对初始化阶段的语句是无效的。\\n\\n请求的值可以从 ngx.var.xx 中得到，比如地址是 ngx.var.uri ， 参数是 `ngx.var.query_string`。其实一旦存在，还有更简便的方法，ngx.var.arg_keyname直接可以获取。\\n\\n取body稍有些不同，因为nginx的定位是消息转发而不是处理，只要读出Header就能满足，默认不会读内容。需要的话用ngx.req.read_data()，再调用local body = ngx.req.get_body_data()\\n\\n支持响应请求后再做事情，有ngx.eof()和ngx.timer.at(delay, callback)两种做法。\\n\\n数据库很方便，集成MySQL连接池后，简单的两句话得到值，用ipairs遍历res，每次遍历的值，再用数据库的列定义去取值。\\n\\n```\\nlocal mysql_pool = require \'applua/mysql_pool\'\\nlocal ok, res, state = mysql_pool:query(\'select * from one_table;\')\\nif ok then\\n  for k,v in ipairs(res) do ngx.say(k..\' : \'..v.name) end -- change name to other column\\n  ngx.say(res[1].name)  -- direct access first result\\nend\\n```\\n\\n正常结束，则返回的res是table，异常时res就代表错误码，此时state也会被赋值，额外介绍下，根据 X/Open 和 SQL Access Group SQL CAE 规范 (1992) 所进行的定义，SQLERROR 返回 SQLSTATE 值。SQLSTATE 值是包含五个字符的字符串 。五个字符包含数值或者大写字母， 代表各种错误或者警告条件的代码。SQLSTATE 有个层次化的模式：头两个字符标识条件的通常表示错误条件的类别， 后三个字符表示在该通用类中的子类。成功的状态是由 00000 标识的。SQLSTATE 代码在大多数地方都是定义在 SQL 标准里的。\\n\\n如果SQL语句是INSERT或UPDATE，得到的res是key-value的table，会记录数据库受影响的状态。打印结果像这样\\n\\n```\\ninsert_id : 3\\naffected_rows : 1\\nserver_status : 2\\nwarning_count : 0\\n```\\n\\n* 注意，SELECT返回的table格式，和另外三种都不一样。查询是数字下标，且值还要展开一层，而修改类的操作就是普通的k-v对。\\n\\n在worker进程执行os.execute有个很坑的特性，sh的环境变量不一样。原因是我做了个升级脚本，在命令行下怎么运行都正常，但work就会报java版本不匹配，拉不起程序。最后发现在shell中执行的java是/etc/profile中额外加入的java8，而worker中是看不到这个路径的，于是找了版本7。用env打印会发现少非常多变量。最后把/usr/bin/java定位到java8得到解决。"}'));jctx.push(JSON.parse('{"id": "170227", "tag": "lang", "text": "# LuaJIT的编译过程和FFI接口\\n\\n编译LuaJIT比Lua要复杂很多，共分三个步骤。先看src目录下的host目录，首先要编译出host内的minilua，用它驱动dynasm/dynasm.lua并配合`vm_xxx.dasc`来生成`buildvm_arch.h`(但是也可以在Makefile中指定minilua的替代品，所以它并不是严格意义的必须)，这个头文件是生成buildvm程序的关键文件。有了buildvm之后，再用它生成`lj_vm.o`和一系列的`lj_xxx.h`以及jit/vmdef.lua文件，都具备后才能最终生成LuaJIT程序。\\n\\n但是偶尔也有意外，比如我在Win7环境用gcc编译，本来期望生成`lj_vm.o`，却生成了`lj_vm.s`汇编文件，用gcc转成.o会报错，大意是.hidden位置不对。我查了原因似乎是这样，.hidden是ELF格式的指示符，在windows平台没有这种特性，所以会报错。说明虽然gcc本身跨平台，但如果用了些汇编级别的文件格式相关的指令，还是会编译不过的。但这个可以规避，至少vc就没有这个问题，应该是某个编译开关没考虑周全导致的。除了这个，生成的动态文件名也有些差异，windows平台是51，而其它平台是5.1，不知道为什么windows会少一个点，莫非又搞特殊化？LuaJIT的接口一直保持和5.1兼容，后来也慢慢导入5.2的接口，到2.1.0版本共引入了8个5.2的C-API。\\n\\nbuildvm的作用是，它会先执行`build_code`，再根据处理器和OS生成汇编码，比如windows就是`emit_peobj`。\\n\\nOpenResty的核心模块`ngx_lua`是用Lua的CFunction方式实现的，\\n从issue得知有lua-resty-core是基于ffi的实现，且后续会放弃对CFunction方式的支持。\\n看了LuaJIT的FFI介绍并简单看了源码，才发现错过了这么好东西。\\n\\nFFI简单的说就是只要能拿到动态库(dll/so)均可，并且有相应的函数声明，\\n就可以直接地从LuaJIT中调用C语言函数。而且调用方式非常简单直观，\\n就和调用C语言一样，完全不需要像Lua那样的各种压栈操作。\\n\\n实现原理是需要先调用ffi.load(\\"ssl\\")，这个函数的内部实现就是LoadLibrary/dlopen。\\n再通过ffi.cdef中定义的函数名，通过GetProcAddress/dlsym找到函数地址就能调用了。\\n当然这里还有些cdecl/stdcall的转换动作。\\n如果在Windows平台上还会默认加载kernel32/user32/gdi32这三大默认库，\\n因此常用函数甚至不需要load就能调用了。\\n\\n有这么好用的功能，难怪`ngx_lua`的实现都换成FFI方式了。"}'));jctx.push(JSON.parse('{"id": "170301", "tag": "lang", "text": "# LuaUnit记录\\n\\n单元测试的条件如果是函数，则首4字母为test，如果是表，则表名和函数名前4字母都为test，均忽略大小写。判断代码\\n\\n* if string.sub(s,1,4):lower() == \'test\' then\\n\\n可以这样来执行测试命令\\n\\n* lua example.lua test1 test2\\n\\n表示只测试test1和test2，注意这里大小写必须匹配上才行。\\n如果没有，则还按全局搜索出来的测试。\\n\\n函数入口上看，首先是runSuiteByNames，然后会从`_G`中取合适的名字，\\n生成table后再调用runSuiteByInstances\\n\\n用过luaunit的两个版本，3.0和3.2。其中3.0的内部函数大量使用了全局函数，甚至一些标记开关都用了全局函数，这显然破坏了环境。\\n到了3.2版本则全面收敛了这种往全局空间写符号的恶习，包括assertEquals等都在table里，不再是全局函数。\\n但是3.2在执行时一定要用.run(...)语法。开始我误写成:run()语法，在3.0能正常执行，到了3.2总是出错，经过打印才恍然大悟把self给压栈了。\\n执行的时候可以传入各种参数，非常灵活方便。\\n\\n* ut.run(\'-v\', \'-o\', \'tap\', \'testA\', \'testAa1\')\\n\\n再比如执行测试时，有些函数需要一些特殊的参数，比如一个文本解析函数，需要传入一个文件对应的fd，这时使用class的测试方式就能提供额外的便利，可以给这个class定义setUp和tearDown方法(命名全小写也可以)，而且用testA:setup() self.xxx end这种格式也是允许的。luaunit框架这部分的执行流程是这样：\\n每个test函数都会进入execOneFunction执行一次，执行前后判断有无setup/teardown，有就自动调用这两个方法，执行则通过xpcall因此即使内部assert/error也不会异常退出。执行结果保存下来后，退出前执行endTest函数，会根据PASS/FAIL/ERROR分别增加计数结果。\\n\\n如何非侵入式地写测试呢？比如有个lib.lua库，想对其中很多的内部函数写测试，\\n直接在lib.lua写显然相当不友好，肯定再建立一个ut.lua来放置测试用例。两者如何关联呢？\\n\\n1.lib.lua中require \'ut\'，这种方式相当于把require之前的lib.lua的环境作为ut的ENV，所有想导入ut.lua的符号只能走这个ENV，\\n显然只能以全局函数的方式传递给ut.lua，明显不合理，放弃。\\n\\n2.ut.lua中require \'lib\'，这种方式可以把lib.lua中要测试的函数封装在另一个专门做ut的导出表，并在ut.lua中接收并测试，\\n但是有个问题，就是lib.lua到底要返回正常的导出表，还是给测试的导出表，无法区分。目前想到的办法，只能在导出的附近定义一个常量，\\n通过修改常量的方式来测试。虽然还是有改动，但也是目前惟一能想到的方式了。\\n\\n说完luaunit，再引申说说PHPUnit，其实单元测试在我理解，就是语言有机制能提供当前环境中的所有符号名，lua用`_G`变量，而PHP有`get_defined_functions`和`get_declared_classes`这两个方法，通过同样的策略可以实现和luaunit一样的调用方式。不过PHPUnit似乎要指定类名才能执行测试，我觉得这种方式未免笨拙了。\\n\\n最后附记两个Lua小技巧：\\n\\n1.检查一个字符串是否全落在字符集中，执行string.gsub(\'[]\', \'\')，并检测结果是否为空串\\n\\n2.判断string.find的返回布尔值，使用return not not string.find方式"}'));jctx.push(JSON.parse('{"id": "170304", "tag": "design", "text": "# 并发和并行\\n\\n先比较两者的定义：\\n\\n* 并行是parallel，指多进程可以互不干扰地执行程序，与之相对应的则是串行。如果处理的数据不同，自然不用加锁。并行存在数据的归集操作，Perl6也提供了Promise等原语支持。\\n* 并发是concurrent，指多个程序同时运行的现象，注意用词，并发的重点在于它是一种现象，至于实现并发是并行，还是快速切换的串行，反而不重要。所以并发就涉及锁是不严谨的，要说对同一资源的多核并发时，才会涉及锁。\\n\\n并发更多的强调的是有没有这样的能力或特征，它是从事物的性质和对外表现上来说的，它不在乎内部如何实现，相对而言是在更高层次上的概括；而并行则规定了它们在物理上一定是同时进行的，相对而言更严格。\\n\\n存在很多的[[并发编程模型]]，有一本《七周七并发模型》的书介绍了诸如：多进程/多线程的并发模型、异步事件并发模型，Erlang 的 Actor 并发模型和 Golang 的 CSP 并发模型。\\n\\n## 并行涉及的概念解析\\n\\n并行在软件层面大多是创建线程，线程有两种属性join和detach。pth的线程实现有5个队列NRWSD，分别是new/ready/wait/suspend/dead。join属性的线程在退出时加入dead队列，因此依然被调度，而detach属性的线程则不会，因此直接把线程控制变量free掉不再调度。所以退出时也不一样，join用`pthread_exit`可以捕获退出状态，detach可以直接用return。\\n\\n条件变量必须配合锁，在wait前显式地获取锁，在wait函数内进入cond等待队列并释放锁，然后线程block住，将将调度权交还系统。直到另一个线程signal或broadcast才重新执行。而signal函数如果发现cond队列为空，不执行任何动作直接返回。\\n\\n信号量并不是pthread定义的，各个平台函数名也不同，等效于mutex和condition再外加一个计数器的总和。因此mutex和condition可以认为是线程同步的原语。\\n\\n比如公司的RPC网络框架库，后台启动4个业务线程，平时以semaphore的方式等待，消息到了就在epoll线程执行加1操作，接着就会有一个业务线程被执行。但是这个场景中直接用condition是不行的，试想如果4个业务线程都还在执行中，此时又来一个请求，如果是condition的语义，由于所有业务线程都在执行导致cond队列没有等待，这时的signal没有任何意义，导致这个请求丢失。当然如果真用condition，RPC框架也不是这么实现了。\\n\\n## perl6对于同步和并发的探索\\n\\n从slide上摘录要点。\\n\\n* 线程 存在数据竞争\\n* 锁 会导致死锁\\n* 条件变量 spurious wakeups？不清楚是什么\\n\\nPerl6给出的解决方式，用start启动一个promise，再await就可以得到promise结果。\\n\\n支持monitor和actor模式，类似Java的synchronizised同步块语法，可见多线程抢夺资源是如此的普遍，编程语言都会作出方便的支持，Perl6提供了OO::Monitor和OO::Actor两种原语。\\n\\n## 异步接口转为同步接口案例\\n\\n起因是图片识别人脸的协议最早的对接方式是阻塞的，新品改成异步方式，本来以为异步转同步很简单，真正实做才发现细节值得思考。\\n\\n首先异步通常意味着执行的结束时间很长且不确定的，但转同步的时候必须要加上限制约不能无限等待，等待的最长时间全凭经验，是无法量化的因素。\\n\\n接着考虑多线程同步的问题，异步通常需要订阅回调函数，执行并等待的线程A和回调执行结果的线程B间就必然存在资源竞争的问题。常见的等待方式就在是A线程启动一个带超时的信号量(semaphore/event)，并由线程B来释放它。但是如果线程B被触发时线程A的信号量已超时并过期，B就不应该释放。但目前基础库中并没有办法探测A的信号量是否还在等待。因此提高了复杂性。\\n\\n再进一步考虑，执行函数能否并发执行，如果不能并发则在上层调用前就要加锁防止重入。"}'));jctx.push(JSON.parse('{"id": "170305", "tag": "os", "text": "# 系统性能分析的理解\\n\\n曾经以为性能分析一定要用看起来很高深的工具，实际上重点还是在于对系统各个方面的理解。对《性能之巅》观测指标做个分类，分为软件和硬件，软件类包含操作系统、文件系统和进程，而硬件包含CPU、内存、磁盘和网络。\\n\\n## 进程状态\\n\\nps会显示多种状态\\n\\n* S 可中断睡眠，可以被外部信号或内核唤醒，比如网络等待\\n* D 不可中断睡眠，只能被内核唤醒，比如读写磁盘，虽然不占CPU但占着其它硬件，且必须一直拿着这个硬件，否则会导致硬件损坏\\n* T或Z 停止或僵尸\\n\\n另有几种文档说BSD状态，但好像也会显示\\n\\n* <和N 高低优先级\\n* s session leader\\n* l 多线程\\n* \\\\+ 前台进程组，不理解，似乎不重要\\n\\n## CPU\\n\\n最粗略的观察通过uptime和top，看变化趋势和整体分布，要注意的是load和usage是不是维度的度量，两者甚至可能出现很大的偏差。因为load统计可以大体等同于R和D状态的进程总数，表示运行中的进程数，但是D状态不会占用usage，所以如果出现有大量读磁盘的进程时，load会明显高于usage；理论上猜测（没有遇到过），当进程数较少，但某些进程使用多核计算，会出现usage高于load的情况。\\n\\nCPU的计时分了很多状态:  usr, sys, nic,  idle,  io(wa),   irq(hi),   sirq(si)\\n\\nusr、sys和nic是某个进程的耗时，nic是低优先级(1~19)进程的用户态耗时，而io、irq计算整个系统的耗时，类似于公摊，不计入进程耗时。进程还要观察上下文切换，也会导致CPU过高。\\n\\n## 内存\\n\\n内存首先分为物理内存和虚拟内存（swap分区）。\\n\\n内存有cache和buffer。buffer对应block device，比如文件系统的MetaData，量并不大，知道就好不用太关注。\\n\\ncache比较重要，它表示程序曾经往Disk写入的数据，除非系统判断内存不足，不会去清理cache，所以经常看起来很大，但不必担心。\\n\\nps有个-o选项，可以输出非常多的信息，说说内存。\\n\\n* rss，resident set size，表示常驻物理内存的大小。这里有个要注意的，在计算so共享库的时候，会全部计算进去，实际上so的多存往往是多个进程共用，对系统的占用并没有表面上来得严重。累计了CODE段和DATA段的总大小。用pss做总和才是正确的值，p表示比例，共享的内存按比例均分。\\n* sz，比rss大\\n* vsz，虚拟内存，最大。等于swap和rss总和。\\n\\n另有pss(proportional set size)是将so内存按比例统计，对每个进程来说更准确。uss则完全不计入so内存。\\n\\npmap可以给出更细的检测报告，每个so库的每种段，堆和栈占用多少内存全部统计分明。\\n\\n内存在系统中有4种状态\\n\\n1. 未载入(不用关心)\\n2. 已载入，但未映射\\n3. 已载入，且已映射\\n4. 已载入，但被换到虚拟内存\\n\\n通过工具看到最多的，3代表常驻内存RSS，2,3,4合起来又名VSS\\n\\n监测可以针对系统级进程。监测的原理分为计数器和跟踪，另外profile也有，但使用面会窄些。\\n\\n* 计数器方式：由于内核本就维护各种统计数据，因此计数方式的采集可以认为是零开销。基于计数器方式有sysstat工具包，涵盖了一系列专项的工具，如pidstat/mpstat/iostat等。另外sar是system active report的简写，虽然没有stat但也是sysstat的一员。其它各自针对不同资源进行监测。还有一个procps-ng包，包括了vmstat/free/ps/top等经常会用到的工具，形成两大派别。netstat是早已有之，不在这两个派别内。\\n* 跟踪方式：又叫事件，系统级典型如perf/systemtap，进程级有strace/gdb，基于系统事件方式的采样。找到哪个环节出问题，针对性的采集数据。Perf是Linux内核自带的性能监测工具，自2.6.31版开始引入所以发行版都会带这个功能。它配合内核的`perf_events_open`接口(也是perf惟一的接口)使用。而systemtap更像是CentOS专门的工具，默认不带要另外安装。\\n\\n## 计数器方式\\n\\n计数器方式可以很快地看出系统的负载，最复杂的命令是sar，用sar -A可以看到所有数据，底层有sadc(采集数据)和sadf(输出格式化数据)支持。再说几个工具的特性。\\n\\niostat可以监视IO(-d)和CPU(-c)，类似的top命令观测CPU时也有iowait指标，也体现了IO的度量，IO不仅受磁盘影响，也会影响CPU的使用率。\\n\\npidstat从名字可以看出，用于找出问题出在哪个进程，指标包括IO，内存缺页，栈的使用大小。\\n\\n## 跟踪方式\\n\\n2.5版本内核支持了ftrace特性，并以tracefs文件系统方式展现给用户。如果打开了该特性，可以在/proc/mounts查找tracefs的挂载点，并切换到root（sudo不行！）进入该目录（一般是/sys/kernel/debug/tracing/）。既然是类文件系统，通过修改文件来打开跟踪和观察。这种方式操作不友好，trace-cmd包可以简化一些。ftrace的实现依赖于内核在gcc编译阶段留的桩，编译内核的参数缺省会用\\"-pg -mfentry -mrecord-mcount\\"，前两个参数给每个函数开头插入5个字节的callq指令，而最后一个参数则在vmlinuz的`mcount_loc`段记录了所有内核函数的地址。但是所有函数都留桩显然开销太大（下降13%），所以ftrace在内核启动时会callq指令替换成nop指令。当用户对特定函数开启了追踪，用callq替换nop，将追踪信息写入ring buffer输出给用户。\\n\\n2.6版本出现了perf，因为ftrace只管抓trace数据并没有分析，perf在trace数据分析方面做出了很多成果。在trace数据采集方面，perf复用了ftrace的所有插桩点，并且加入了采样法(硬件PMU)。PMU是一种非常重要的数据采集方法，因为它大部分是硬件的，所以可以做到一些软件做不到的事情，获取到一些底层硬件的信息。\\n\\n> PMU是什么：像L1 cache失效、分支预测失败等几种处理器特性对软件的性能有很大的影响，然而依赖时钟进行定期采样的 profiler 模式无法揭示程序对这些处理器硬件特性的使用情况。处理器厂商针对这种情况，在硬件中加入了 PMU 单元，即 performance monitor unit。PMU 允许软件针对某种硬件事件设置 counter，此后处理器便开始统计该事件的发生次数，当发生的次数超过 counter 内设置的值后，便产生中断。比如 cache miss 达到某个值后，PMU 便能产生相应的中断。捕获这些中断，便可以考察程序对这些硬件特性的利用效率了。\\n\\nBPF源于1992年的Berkeley Packet Filter论文，触发Linux社区在97年也跟进并实现了Linux Socket Filter机制，但长久以来只有tcpdump这个应用。BPF原理如下图。经网卡驱动层的报文在上报给协议栈的同时会多出一路来传送给BPF，再经后者过滤后最终拷贝给用户态的应用。除开tcpdump，当时的 RARP 协议也可以利用 BPF 工作(Linux 2.2  起，内核开始提供 rarp 功能，因此如今的 RARP 已经不再需要 BPF 了)\\n\\n![bpf-germ](/img/bpf-germ.jpg)\\n\\n其中的filter是类似汇编码的指令，为了防止注入，对BPF的指令做了很多数量和长度的限制。由于内核态开销大，3.x时代出现了JIT for BPF，2013年对BPF做了彻底重写，命名为eBPF，最终在3.17时代进化出全新的eBPF，并持续发展了seccomp、XDP、traffic control等机制。"}'));jctx.push(JSON.parse('{"id": "170309", "tag": "design", "text": "# 接口设计的原则与反思\\n\\n先说说VideoEncode类的感想，\\n目前的Encode类的构造函数，需要传入一个视频通道号和编码类型，然后返回一个对象。现阶段遇到有个需求，需要解码后的YUV数据经过智能分析，对分析结果的区域进行局部抠图。这时也需要编码资源，但这个编码器似乎又和视频通道并不强关联，再多的还是和解码器的输出有关，这时原先的假设就不再适用了，需要定义新的构造函数才能使用。\\n\\n再说两个接口的反思\\n\\n在MCU头文件增加了一种读数据的枚举值。看起来小得不能再小的改动，但还是发现了问题。\\n\\n原来的头文件中有两个类似接口，分别是recv和recvData，接口注释分别是阻塞等待事件和读取数据，但是看阻塞等待事件的接口，返回的数据结构似乎也能表示数据，为什么偏偏要加在recvData，这两个接口的差异在哪里？\\n\\n细问之下才知道原来recv的内部实现是把代表MCU的fd加到select的读和异常集合，且超时时间为无限，recvData只是个读数据的接口，不会阻塞。看了实现才明白原来是用recv来等待数据到来，结束后调用recvData。说实话这样的命名方式实在太糟糕，加上接口注释又不清晰，导致这次新增的枚举在recvData中又增加了select操作，原来是上层没有调用recv。这种改动虽然不影响原有逻辑，但从整体功能上造成了recvData的含义不同，阻塞或非阻塞的特性还会随着读取的数据类型而变化，这就很明显地破坏了接口含义的一致性。\\n\\n再说一个错误的例子，有个createNetBrigde接口，入参有个`const char *name`，从接口看，无非创建一张网桥，然后用name来标识一下，类似创建线程操作，何曾想实现代码中竟然要求name必须是br开头且第3个字符必须是数字，否则不予创建。无论怎么看接口注释，都看不出有这样的限制。而且既然限制必须用br开头，何不把参数定义成uint8，只让调用者传入数字，在实现层构造出br0这样的名字，不仅没有歧义还减少空间。\\n\\n以前看接口，最多能看出参数是否合适，最近越来越意识到接口的用法、使用前提、使用预期等隐含的语义。\\n\\n软件工程总是提复用，我的理解复用是有范围的，比如接口恰恰是最不能复用的，一个萝卜一个坑，绝对不能有二意性，且最好功能尽可能单一。只有接口不复用，业务代码才能尽可能地复用。"}'));jctx.push(JSON.parse('{"id": "170312", "tag": "lang", "text": "# Lua中引入对象风格的价值和loop的实现\\n\\n用弱类型语言写代码，函数多了以后参数具备明确含义就很重要了。就好比web开发不可能总是用原生的json包打天下，定义一个类，更多的也是对接口的一个契约，使其在函数名之外具备更详细的自解释性。至于C++面向对象三要素的封装尤其访问性封装和继承，目前我还没觉得有什么用处，对动态语言来说多态已经在语法层面失去价值，反而使接口和实现分离这个最本初的愿望更直接地体现出来了。\\n\\n接下来先分析loop.base的实现原理，base是基本，就做了最简单的引入类和实例概念：整段代码20行，如下\\n\\n```\\nfunction rawnew(class, object)\\n\\treturn setmetatable(object or {}, class)\\nend\\n\\nfunction new(class, ...)\\n\\tif class.__init then\\n\\t\\treturn class:__init(...)\\n\\telse return rawnew(class, ...)\\n\\tend\\nend\\n\\nfunction initclass(class)\\n\\tif class == nil then class = {} end\\n\\tif class.__index == nil then class.__index = class end\\n\\treturn class\\nend\\n\\nlocal MetaClass = { __call = new }\\nfunction class(yourDef)\\n\\treturn setmetatable(initclass(yourDef), MetaClass)\\nend\\n```\\n\\n创建类需要指定具名字段并返回一个可以call的物件，因此创建是function，返回的则是设置了metatable中`__call`字段的table。如果没有定义任何东西，库也会默认生成个{}，而接下来这句设置`__index`的作用要在new中才会体现。先来看`__call`对应的的函数new。触发这个方法时，第一个传入的参数是class这个function生成的物件，从rawnew函数可以看到这个物件被当作一个object的元表，此时object需要能访问到类中定义的成员，显然需要`__index`方法，又因为这个object不能再创建对象，所以也不会有`__call`字段定义。到此功能原型就出来了。\\n\\n上面说完了base类，这时还不具备继承功能，先说单继承，这是loop.simple的职责，simple要实现继承，在base基础上要再做两件事：\\n\\n1. 要能够访问到基类的属性\\n2. 既然是继承类，也要能够构造实现，也就要有`__call`方法\\n\\n来看simple的代码\\n<pre>\\nlocal DerivedClass = ObjectCache {\\n\\tretrieve = function(self, super)\\n    -- return a new class extended super with __call, so it\'s different from origin super\\n\\t\\treturn base.class { __index = super, __call = new }\\n\\tend,\\n}\\nfunction class(subDef, super)\\n\\tif super then\\n\\t\\treturn DerivedClass[super](initclass(subDef))\\n\\telse return base.class(subDef)\\n\\tend\\nend\\n</pre>\\n如果class的第二个参数(父类)非空，则通过DerivedClass[super]的方式生成一个带`__call`的强化版super类，且索引也指向super。再以subDef为参数向super类上附着子类的参数，这样继承的目的就达到了。"}'));jctx.push(JSON.parse('{"id": "170318", "tag": "net", "text": "# ARQ可靠传输协议\\n\\nTCP是可靠传输协议，但并不是惟一的，甚至在无线环境下都不是最好的选择。可靠传输有三种算法模型:\\n\\n1. Stop-and-wait ARQ\\n2. Go-Back-N ARQ\\n3. Selective Repeat ARQ\xa0/ Selective Reject\\n\\nTCP是Go-Back-N的一个变种。已经有非常多的文章提及TCP的特性并不适合无线网络。另外有种KCP协议，两种协议的设计初衷不同：\\nTCP是为流量设计的（每秒内可以传输多少KB的数据），讲究的是充分利用带宽。而 KCP是为流速设计的（单个数据包从一端发送到一端需要多少时间），以10%-20%带宽浪费的代价换取了比 TCP快30%-40%的传输速度。TCP信道是一条流速很慢，但每秒流量很大的大运河，而KCP是水流湍急的小激流。为什么TCP会选择方式，我猜想大约是和LAN的碰撞特性相关，LAN是基于碰撞检测模型，如果每个节点都频繁地向网络发送消息，网络很容易堵塞，为了充分利用带宽，设计TCP的时候就以必须配合LAN的特性。但到了无线通信时代，如果发送数据不是基于碰撞检测，这个模式就未必是最优的模型。\\n\\nKCP可以跑在UDP上实现可靠传输，如果客户端服务端都是自己的，可以利用这种模式来做业务优化。\\n\\nTCP的拥塞控制算法的简要状态机，加性增窗和乘性减窗。TCP会一直尝试动态调整窗口，如果增大成功，则线性地以常量方式增加滑窗，一旦发送失败，减少一半滑窗。这种机制是非常克制的，在多个节点共同组成网络时，可以尽最大可能利用网络但又不会堵塞。4.9内核引入了google的BBR算法，对计算策略做了优化，发送失败会等待10个周期才减窗，且幅度只有3/4，防止线路噪音造成的意外衰减。"}'));jctx.push(JSON.parse('{"id": "170323", "tag": "lang", "text": "# Python自学手册\\n\\n整个执行包是目录不敏感的，比如编译时指定安装目录是/usr/py3/目录，安装后整体移动到/opt/py3/目录后，依然能正常运行。熟用dir/help函数帮助，不过help依赖pydoc，如果是精简环境会出异常。\\n\\n常用的sys和os，级别并不一样，sys是built-in模块，os只是个普通的py脚本文件。比如sys.path和os.path就很不一样：sys.path是普通数组，而os.path是个module，主要提供一系列操作函数。\\n\\n## 类型\\n\\n从大的分类来说，有两种分类，类型（Type）和实例（Non-Type）。类型中有两个特殊的存在，type和object。所有的内置类型如tuple、list都继承自object（即`list.__bases__`是(object,)），同时它们的type就是type（即`list.__class__`是type）。\\n\\n所有的值，不管是简单的数字、字符串、None或复杂的容器类型，都有所属的class。不同的class具备的特性不同，比如sequence属性就是tuple/list/str还有range类型特有的(range不仅是一个函数，其生成对象的类型就是range，可以迭代)。\\n\\n## 类和继承体系\\n\\n从py3开始，声明一个新的class默认继承自object，前面提过除了object外，还有个特殊的type，因为class关键字其实是对type的封装，class A:声明形式等价于A=type(\\"A\\", (object,), dict=())，所有的类对象，都是type的派生（严格的说是type产生了metaclass，而由此再产生普通类）。\\n\\npy支持多继承，使用MRO解析方法调用顺序，这就对继承有了约束。比如B(A)，那么只能C(B, A)，不可以C(A, B)，因为后者无法满足MRO的要求。当super作用在多继承的子类时，也只会解析出最优先的惟一类，不会把所有父类都调用一遍。\\n\\n## 迭代\\n\\n有两个容易混淆的概念，iterable和iterator。iterable只要支持`__iter__`，可以配合for使用，list、tuple等可迭代对象都是要迭代的。而iterator除了要支持`__iter__`外，还要支持`__next__`，但只能迭代一次，不能重复迭代，优势则是占用内存较少。最简单的构造iterator方式是通过iter()方法转换。\\n\\n## 模块的查找（finder）与加载（loader）\\n\\n最小的代码单元称为module，主要有2种类型\\n\\n1. pure python module: 纯用py写的单元，最简单的情况下，单个py文件就是一个module\\n2. extension module: 用C语言写的py扩展，so或dll文件\\n\\n多个module可以组成package，一般含有`__init__.py`的文件夹称为regular package，还有种namespace package。\\n\\n不管是module还是package，都可以用import xxx来导入，但深入去看还是有区别的。通过import导入的模块可以用del删除，但千万别把自带的给删了，那就再也找不回了。import语句本质是`__import__`函数的二次封装，还有一个importlib包，可以修改一些导入细节，实现特殊效果。\\n\\nimport动作的背后，分为find、load、bind三个阶段动作：find失败会执行load，有些文章会把finder和loader合起来称为importer。find过程可以加hook，通过`sys.meta_path`或`sys.path_hooks`变量来调整行为。bind则是把sys.modules中这次被导入的变量加到globals()或locals()对应的字典，这样代码中才能直接引用。这里有个非常triky的地方，比如import mod，找到mod.py（或者`mod/__init__.py`）并执行到结尾，import语句会往sys.modules写mod变量，再将modules[\'mod\']也绑定到globals()。但是如果mod.py自己向sys.modules写mod，import语句就会直接将这个变量导入globals()，这样就能使import的模块不再是module类型，而是任意指定类型。反观lua，require必须显示赋值给某个变量，把加载和绑定分开，非常清晰，而python最终引入as显然也是认识到import存在的问题。\\n\\nimport可以导入包、模块、函数、变量，如果包和模块同名，会优先加载包。寻找的顺序：builtin包 --> sys.path（这里又按当前路径、py库目录、二进制库、site-package顺序查找）。加载前会先判断是否已经在sys.modules字典，已经加载过的变量不会再次加载，可以用importlib.reload来强制重新加载。import语句执行后，会绑定一个新的本地变量，变量名是left-most值。比如import a.b.c，执行后会隐式创建a变量，如果要重命名，就要用额外的as关键字，我觉得是不优雅的。sys空间下，共有4个和加载相关的变量\\n\\n1. sys.path: 查找路径列表\\n2. sys.modules: 保存已加载模块的字典，启动后这里就会有很多预加载模块，但因为没有在全局命名空间bind到变量，不能直接引用，这时import只需要绑定变量即可，速度很快\\n3. sys.path_importer_cache: 类似sys.path，但内容更多\\n4. sys.meta_path: 查找器finder列表，一般用内置实现，也可以自定义（实现一个定义了`find_spec`类方法的类）\\n\\n导入变量额外说一句，据不完全观察，导入的变量是当前时刻的状态值，导入后，即使被导入模块的值定义发生改变，在引用方无法察觉到，这是件好事，本来也不应该以这种方式来共享一个全局变量。\\n\\n实际中一般会用from package import subpack/module方式，这个语法甚至可以从module加载函数，个人觉得有点过于灵活了。另外from import加载的时间，要慢于import整个加载。\\n\\n`__import__`的细节要复杂得多，因为from/import这套组合可以有多个参数，而`__import__`只有一个字符串，这就带来一个歧义，导入a.b时，究竟是返回a还是b？此时就要通过fromlist来区分，不带fromlist时，返回最左侧的a；如果fromlist是个tuple或list且全部是str值，返回最右侧的b，fromlist只要有str值即可，随便填什么都行。之所以做成这样，我猜测原来想利用fromlist来指定加载的子模块，后来发现多此一举，干脆就退化成指标加载最左或最右的标记位了。\\n\\nimport能导入3个层面的对象，造成这么复杂的原因，猜想可能是最初的import只能导入module，后来随着规模变大，又引入了package的概念，语法上增加了from，可能为了适用性，把from适用于module，导入函数。虽然简单，背后却不简洁。\\n\\n总结两者的差异如下\\n\\n* package: 有特有属性`__path__`，而且可以在`__init__.py`通过`__all__`列表控制`import *`的导出。无法通过getattr获取module\\n* module: 只能整体内容导出，似乎不能控制。可以用getattr获取function或class\\n\\n## 文件身份的识别\\n\\n前面说过一个py文件就是一个module，其自带很多内置属性，加载的方式不同，会导致这些内置属性的值发生变化。\\n\\n* `__all__` ，控制导出的符号列表，但又只适用于部分导出场合\\n* `__file__`，在磁盘上的绝对路径，.py结尾\\n* `__name__`，如果在命令行被调用，则被赋予`__main__`这个特殊名，如果是被import，是不带py的相对文件名（取决于顶级调用路径）。\\n* `__package__`属性，如果这个文件平级没有`__init__.py`文件，那么`__package__`的值是None，否则就是这个文件所属文件夹的名字。\\n* `__doc__`，文件开头的整体声明，不得不说对文档的重视程度还是不错的\\n* `__spec__`和`__loader__`，模块在加载器的对象描述，不同类型模型的加载器各不相同\\n\\n展开说下`__loader__`，随着载入模块的不同，有3种\\n\\n1. _frozen_importlib.BuiltinImporter 用在内嵌模块，比如sys\\n2. _frozen_importlib_external.SourceFileLoader 用在标准库的py文件，比如os\\n3. _frozen_importlib_external.ExtensionFileLoader 用在C写的so扩展库\\n\\n虽然语法中没有类似package或namespace关键字，实际上会把每个文件中创建的函数、变量限定在一个范围内，猜测是`__name__`这个命名空间。\\n\\n## 对代码格式统一的努力\\n\\n1. 缩进曾被作为卖点之一，但现在似乎更倾向用外置format工具来做。用了缩进后，不能做压缩，也多出了特有的类似pass的占位语句。\\n2. 函数形参可以加`*`或`**`，表示这个变量是tuple或dict。只看效果是个很简单的语法糖，但用这种形式强制规定了元组在前，字典在后的形式，并引出了posional argument和keyword argument两个概念。\\n\\n## 装饰器\\n\\n@方式在函数外部引入的装饰器，会导致实体函数的元属性被装饰器拦截，如果想保留实体函数的元属性，要额外地import functools import wraps\\n\\n```\\nfrom functools import wraps # 引入functools模块的wrap装饰器方法\\n\\ndef repeat_twice(func):\\n    @wraps(func)\\n    def wrapper(*args, **kwargs):\\n        func(*args, **kwargs)\\n        func(*args, **kwargs)\\n    return wrapper\\n\\n@repeat_twice\\ndef foo():\\n    print \'hello world\'\\n\\nprint foo.__name__      # Out: foo\\n```\\n\\n## 搭建PyPI仓库\\n\\n仓库本质上是个http服务，目录包含若干压缩包和这些包的索引，PEP定义过仓库的规范，通常仓库的目录结构类似下面这样：\\n\\n```\\n/pypi\\n|__packages\\n    |__/51/36/32/cc660efa43e482b97d4c2c2bcfdfde03b4f88c82f261d128cf/pandas-1.0.1-cp38-cp38-linux_aarch64.whl\\n|__simple\\n    |__pandas\\n```\\n\\npackages下放whl或tar包，包名必须带版本号，否则无法进行语义化比较，不能放其它类型的文件；simple是索引目录（通过dir2pi /pypi命令，递归遍历目录内容后自动生成），pip查找或安装时，先在索引目录定位到包。包有wheel和源码两种形式，wheel是编译好的格式，安装比较快，如果只有源码包，则会下载到本地并编译成wheel（默认在~/.cache/pip/wheels/），在下次安装时能加速。"}'));jctx.push(JSON.parse('{"id": "170324", "tag": "security", "text": "# VPN概念解释\\n\\nVPN的本意是把来自不同子网的设备放在同一个子网内，构建虚拟网络。既然要并网，肯定要做身份认证，而PPP点对点协议天生就带认证属性，这也是家庭网络都是PPPoE方式接入。\\n\\n实现VPN的协议很多，举我所知的几种\\n\\n1. PPTP  微软出的规范，RFC2637。必须基于IP或TCP协议(至少要3层网络)，加密密钥最高支持到128bit，强度比较弱，甚至在iOS10的时代直接被苹果给抛弃了，但是因为是微软自家的东西，又出了SSTP后继，好像没什么人在用\\n2. L2TP  思科提出，RFC2661，广泛使用\\n3. IPSec 用XAuth认证用户，model config分配IP。由于XAuth有版权且没有标准化，兼容性不如L2TP。运行在用户态的IKE daemon和处理实际IP报文并运行在内核态的IPSec协议栈，不同的OS实现不同。\\n4. IKEv2 iOS10去掉PPTP后，新支持的类型。特性是IKEv2的MOBIKE(见RFC4555)扩展，VPN建立后切换网络(如从4G到3G)不会掉线。另外认证也支持EAP，比IPSec只支持XAuth好像更高级\\n5. OpenVPN/ShadowSocks/V2Ray 这些更多的是穿越工具，分类上有些并不属于VPN，也没有RFC标准，一般都只是某个开源软件的实现，因此Android/iOS系统都需要额外安装对应的客户端软件，系统本身不自带\\n\\n## L2TP\\n\\nLayer 2 Tunnel Protocol的缩写，Layer 2这里指的是PPP协议，通俗地说，就是为了运输二层协议PPP而存在的。L2TP因为有PPP，负责AAA，也就是认证、授权、计费（Authentication, Authorization, Accounting）。除了IP网，还可以跑在ATM, MPLS, 帧中继等网络。由于L2TP 传输安全性太差，于是人们在 L2TP 外层再套一个 IPSec 来保证传输过程的安全性，传输HTTP的话就是这样一个层级\\n\\n```\\nIP/UDP(4500)/ESP/UDP(1701)/L2TP/PPP/IP/TCP/HTTP\\n```\\n\\nIPSec使用ESP加密，除上面介绍的传输模式外，还有另一种方式IP/ESP/UDP(1701)/L2TP/PPP，也叫隧道模式。这种方式IP层的负载是ESP，往往过不了NAT，并不适用于发起VPN者的网络环境。而前面提到的方式虽然会有两层UDP，但容易过NAT，这也是单纯技术上最佳的选择并不会被市场接受。\\n\\nL2TP似乎只有6个字节，每两字节一段，分为3段。第1段是协议和标志位，第2段是Tunnel ID，第3段是Session ID。后面这两个ID看起来是绑定的，但方向不同值不一样，命名为Session ID有点不对题。其上的PPP只有4个字节，1字节Address，1字节Control，2字节的承载协议类型（此例中指明是IP）。比TCP三卷本的说明少了最开始的0x7E。\\n\\n## IPSec和IKE\\n\\nIPSec方式工作在IP层，其涵盖的ESP和AH协议主要是规定IP包的格式，因此在连接对端时，只要服务器域名不需要端口。\\n\\n中间人攻击是针对加密会话的初始化阶段进行的，IPSec 的初始化阶段显然要考虑这个问题，所以提出了XAuth规范，但该规范不如IKE的EAP，说到这里就要引出IKE协议了。IKE 协议在1988年11月发布v1版，2005年升级到v2版。是在奥克利协议（Oakley protocol）与ISAKMP协议的基础之上发展出来的，它和IPSec是独立的两套协议，但人们发现二者组合非常互补，所以现在往往一起提。由于IKE使用X.509安全认证，问题就转化成了面对中间人攻击，我们要如何去验证 IKE peer 的身份呢？也就是说，我们要如何确定对方就是我们要联络的人呢？IKE 协议里Message type 5 和 type 6 就是负责这个事情的。具体来讲有三种方法：\\n\\n1. 预共享密钥：Pre Shared Key，简称PSK。用大白话就是双方商定一个密钥作为彼此认证的手段\\n2. 公钥加密：需要配置用户证书/CA证书/服务器证书\\n3. 数字签名\\n\\nXAuth似乎只支持预共享密钥和公钥加密，对应了XAuth和PSK/RSA选项，EAP不再依赖PSK。\\n\\n### StrongSwan\\n\\n基于IPSec最早的项目名叫FreeS/WAN，所以现在都沿用了swan这个名字，是Secure Wide-Area Networking首字母的缩写。这个项目停止维护后，衍生出OpenSwan、LibreSwan、StrongSwan。StrongSwan的主程序名就叫ipsec。\\n\\n## OpenVPN\\n\\n通过四层的TCP/UDP建立连接，然后客户端会从服务端得到私有网络的配置信息，进而客户端会在其主机上创建TUN网卡，该网卡的地址和服务器在同一个网段，从而构成私有网络。\\n\\nTUN/TAP网卡是linux2.4版本出现的最早的虚拟网络，TUN网卡工作在三层，主要和应用程序直接打交道，为了模拟一张完整的网卡，再配套一张工作在二层的TAP网卡，整个网络栈就齐备了。\\n\\n使用iproute2的ip命令来创建TUN网卡，需要root权限。此外TUN还用于做IP隧道，IP4和IP6组合起来共有4种类型。"}'));jctx.push(JSON.parse('{"id": "170325", "tag": "think", "text": "# 辛弃疾的青玉案赏析\\n\\n```\\n东风夜放花千树，更吹落，星如雨。\\n宝马雕车香满路。\\n凤萧声动，玉壶光转，一夜鱼龙舞。\\n\\n蛾儿雪柳黄金缕，笑语盈盈暗香去。\\n众里寻他千百度。\\n蓦然回首，那人却在，灯火阑珊处。\\n```\\n\\n这首词最为人熟知的是最后一句，但整首词其实非常有讲究。从后往前解读，最后一句不消多说，为了衬托寻找的那个她，先来个铺垫，于是有蛾儿雪柳黄金缕，这三个词都是女性饰物，泛指元宵节时街道上来来往往的女子，而且这些女子笑语盈盈而去，但作者却偏偏要寻找那个她，这里便是强烈的反差的对最后找到伊人的烘托。\\n\\n既然下半阙写人，上半阙便是写景。东风夜放花千树的**放**字用得极好，因风吹过而绽放的花便活灵活现起来，从更吹落星如雨到宝马雕车香满地，镜头从天下拉到地下，再经过凤萧声动，玉壶光转，一夜鱼龙舞的描写，开始将景向人的活动迁移，从而引出后面对人的描写。这样看下来，整首词的逻辑、顺序简直无可挑剔，在这么小的篇幅里把内容都写到，且过渡自然，不愧是名篇。"}'));jctx.push(JSON.parse('{"id": "170329", "tag": "protocol", "text": "# 协议为什么要分包\\n\\nTCP是流式传输协议，每次在传输就要告知对端一个这次数据的长度，否则在流上无从断句。像HTTP就有Content-Length字段用于标识包长度。但是公司的协议除了总长度，还有分包长度，比如数据超过32K后，每次只发送32K，这个特性有什么意义呢？\\n\\n这个特性和数据发送模型有关，公司协议是一条连接上可以并发地发送多条请求，即第一条请求的应答还没到，就可以发出第二个请求。HTTP则没有这个特性，HTTP的多请求利用同时创建多个TCP连接来实现。但是如果在一个连接上有多组请求应答，假设第一个应答有100K,第二个应答只有10字节，但是如果把第一个100K直接写入socket，再写入第二个10字节，则后面的10字节必须要等待100K发送完成才会继续发送，这对简单应答就很不利，所以强制将数据拆散32K,只要发送中途线程被调度到，就有机会把这10字节发出去，如此一来就可以尽早收到简短的回复包了。"}'));jctx.push(JSON.parse('{"id": "170403", "tag": "web", "text": "# php-fpm记录\\n\\nPHP的组成，从内到外大致分3层\\n\\n1. 解析器核心，在形态上表现成php.dll，实质是zend引擎，做语法解析和字节码执行。对应配置php.ini\\n2. 函数和标准库\\n3. 外覆层，引出SAPI概念，进入解析器的入口可以有多种模式，这些模式就称为SAPI。比如php-fpm，对应配置php-fpm.conf\\n\\n写web程序时，可以很方便地调用`$_GET`，这个变量不是核心层的特性，而是在SAPI层解析了CGI环境变量后，再传给核心的。所以不同的SAPI，会提供不同的外围特性。\\n\\n比如在linux下默认编译出的有php(cli)、php-cgi(cgi)和phpdbg(dbg)这3个可执行程序，如果要配合nginx，在编译选项增加`--enable-fpm`就能得到php-fpm(fpm)。它们都能解析PHP，PHP-FPM存放在/usr/sbin/下，其它几个则在/usr/bin/下。但是不知为何linux并没有用动态库，上述4个程序都是静态编译，每个29M，这样做很浪费空间，也许是我编译选项没有打开？逐个说明这几种SAPI：\\n\\n* cli : 命令行接口，也是其它语言最常见的模式，像python/ruby等程序都可以理解为cli模式。\\n* debug : 调试接口，和`perl -d`方式效果相同(也许其它语言也有类似的)。这个接口似乎是5.6或稍早的版本被合进主干的。\\n* cgi : 这个接口就体现PHP天生为Web语言的一面了，支持FastCGI/CGI规范，相当于在PHP的语言内核外，增加了对FastCGI网络请求的解析，在windows版的phpstudy默认就是运行4个`php-cgi`进程常驻后台。\\n* fpm : 最初只是个第三方开发的PHP进程管理器，后来在5.4时代被官方合并，并支持PHP解析。是目前主流的FastCGI容器方案，由于用了fork只能运行在`*nix`上。\\n\\n由于php-fpm只是外围入口，很多php自身的参数仍然需要设置，所以它有两个配置选项，-c指定php.ini路径，-y指定fpm路径。重启使用kill -USR2 PID方式，关闭使用-INT。如果要快速找到pid可以打开配置中定义的pid文件路径，默认因为不保存所以要用ps加grep来查找。\\n\\n要想加速php，少不了opcache模块，从5.5.3开始默认包含。它属于zend extensions，并且要指定完整so路径。原理是把编译后的PHP字节码缓存到内存，下次请求来的时候，根据文件名找到编译后的字节码，就能极大地节省时间。PHP对应cli模式，执行完毕就退出，显然这种模式无法利用缓存在内存的字节码，但不知为何7.1版本默认打开cli模式下的缓存。既然cli模式不行，通过PHP-FPM常驻内存，并fork多个子程序，子程序和父进程使用共享内存，子程序能完整地执行PHP字节码，并不依赖cli程序。一个佐证是Android上的phprunner程序中，就只有惟一的PHP-FPM程序配合lighttpd运行；而PHP Server这个包选择php和php-cgi程序，没有web服务器和php-fpm，靠php的web模式也能接收网络请求。\\n\\n还要注意的一点，一旦打开缓存，所有的PHP的内容就都会用缓存的数据。我之前页面中的一些数据采用PHP的方式内嵌，导致缓存后无法更新，只有重启PHP进程才能更新数据，后来改成从txt文本读取才解决这个问题。"}'));jctx.push(JSON.parse('{"id": "170405", "tag": "protocol", "text": "# HTTP2特性学习\\n\\nHTTP2在制定时要保证不破坏语义且要尽可能地兼容，为了平滑地从HTTP/1.1升级到HTTP/2，会用到Upgrade协议头，但这样就会消耗一整个来回做升级动作，在标准制定时Google/FireFox的人都非常反对这一点，且HTTP2的前身SPDY就是利用TLS握手阶段进行协商，还定义了一套称为NPN的协议，HTTP2也类似，最终规范要求至少要TLS1.2版本，且协商协议换成了ALPN。这两者的差异在于ALPN是服务端最终确认协议细节，而NPN则是客户端确认。\\n\\nHTTP1.1有个很大的限制，每次请求在应答到来之前不能发下一个请求。因为协议本身没有标识请求序号的字段，导致只有等待响应收完才能发新的请求，要么干脆建立多个连接，在每个连接上并行地发请求。但是建立连接的开销是非常大的，在HTTP2时代，终于通过在请求头，规范叫Frame里加上了一个31bit的无符号sequence id的方式把问题解决了。用31bit是考虑到跨语言，比如Java没有unsigned int，如果一定要用uint32，就必须使用int64方式，显然划不来。\\n\\nFrame是个9字节的二进制段，包含长度、类型、标志和请求序号四部分，非常紧凑。长度只有24bit。请求序号采用客户端奇数服务端偶数的方式配对。"}'));jctx.push(JSON.parse('{"id": "170421", "tag": "think", "text": "# 练习健身纪要\\n\\n健身不必追求健子肉，平衡也很重要\\n\\n> 外行看腹，新手看胸，高手看背，大师看腿。\\n\\n## 部位练习法\\n\\n### 练习肱二头肌\\n\\n提臀收腹，腰部要正。因为我腰椎前倾，一定要摆正。不耸肩夹紧肘关节，手腕必须和臂平直。发力过程吐气，想象抗东西要大喝“起”，大喝就是吐气！发力后恢复过程中吸气，为下次运动储能。练习肱二不同的速度会造成形状不同，如果始终快上快下，则只会造成中部发达，如果下放时速度缓慢，则可以使整个上臂都变得粗壮。\\n\\n### 练习卷腹\\n\\n腿呈90度，手沿腿向上肩离开地面以背不离开地面为宜。下巴收起，脖子不要上拉，否则就是颈部肌肉带动用力。\\n\\n### 练习背部肌群\\n\\n长期桌前久坐导致胸小肌过紧，背部无力，人就会圆肩驼背。\\n\\n坐立下拉，拉到锁骨位置，肩部与背交汇处发力。向上时吸气，向下发力到最后吐气。\\n\\n### 练习腿\\n\\n小腿垂直站立，大腿与小腿平齐，背靠墙站立，坚持1分钟。\\n\\n1. 鸟飞，站直，膝盖不弯，上身放松，前脚掌用力，练习浅面股群。\\n1. 半蹲鸟飞，膝盖弯曲，上身不用力（站直），后跟不着地，前脚掌用力托起身体，练习膝内侧，膑骨。\\n1. 台阶步，前脚掌站于台阶，后跟悬空，用力顶起身体，练足弓\\n1. 单腿抬，一脚踏楼梯，另一脚悬空，靠单脚力弹支撑身体。练单腿力量\\n1. 三弓同动，身弓（髋和腰之间夹角，上身笔直）\\n1. 箭蹲，弓步蹲，上身下压，手可上举，缓解下压力。两脚三脚宽。\\n\\n大成拳摩擦步，步行过程中，后脚尖先抬起，想像脚底踩着滚木向前，脚不要抬太高。\\n\\n## 不当健身影响\\n\\n练胸大肌脖子会疼的原因\\n\\n1. 发力时使用了后背的斜方肌，左右斜方肌力量不平衡，挤压颈椎。\\n1. 推时腰部会发力，后腰左右两块肌肉通过脊柱带动，力量传递到颈椎，使颈部发力导致紧张。\\n1. 颈椎僵硬加上左右斜方肌力量不对等，产生侧倾，长期造成颈部歪曲，双肩不平衡。\\n\\n## 器械要点\\n\\n划船机：小腿垂直站地，拉下时肘不要弯，背略向后，脖子不前倾，拉开背和肩。\\n"}'));jctx.push(JSON.parse('{"id": "170423", "tag": "design", "text": "# 对《谈谈架构》的理解\\n\\n以下是《谈谈架构》这本书的目录，内容没有看，但从目录上已经有很多启发。\\n\\n第一部分 认识架构\\n\\n第 1 章 生命周期\\n\\n1.1 生命周期的识别\\n\\n1.2 核心与非核心生命周期\\n\\n1.3 生命周期与分工\\n\\n第 2 章 时间\\n\\n第 3 章 为什么会产生架构\\n\\n3.1 分工\\n\\n3.2 分工和生命周期\\n\\n第 4 章 什么是架构\\n\\n4.1 架构产生的条件\\n\\n4.2 什么是架构\\n\\n4.3 架构的生命周期\\n\\n第 5 章 架构和树\\n\\n5.1 树与增长\\n\\n5.2 架构和树\\n\\n第 6 章 概念\\n\\n6.1 何为名相\\n\\n6.2 究竟什么才是相\\n\\n6.3 概念是沟通的基础\\n\\n6.4 把握概念的力量\\n\\n第六章说概念，经常我们会被要求用一句话把一件事件概括出来，看似是考验我们的表达能力，但却有个前提就是双方必须有共同的概念基础。概念是对一件事件的浓缩提炼，要想一句话把一件复杂的事件说清楚，必须是把很多复杂的事件，以一种合乎逻辑的顺序表述出来，如果缺少对概念的共识，一句话就不可能达到好的效果。\\n\\n第 7 章 什么是抽象\\n\\n7.1 个性与共性\\n\\n7.2 个性是基础\\n\\n经常会经历过度抽象的错误，一方面原因是对忽略了两个事件之间细节的差异，导致认为可以抽象，典型的是把监视和回放合二为一。我也认为个性即差异是根本，在不确定的时候宁可分开，分开也许会造成冗余，但冗余后如果发现合并就是了，但如果开始就合并在一起，随着对细节认识的加深，就会在一份代码中加入越来越多的分支判断，导致代码无法拆解，最后变成一个大麻团。合并易于拆分，所以我对抽象持谨慎态度。\\n\\n第 8 章 识别问题\\n\\n8.1 面对问题有哪些困难\\n\\n8.2 如何识别问题\\n\\n8.3 寻找问题主体\\n\\n第 9 章 切分的原则\\n\\n9.1 切分就是利益的调整\\n\\n9.2 为什么需要切分\\n\\n9.3 切分的原则 \\n\\n9.4 树和分层\\n\\n9.5 切分与建模\\n\\n9.6 切分的输出和组织架构\\n\\n前段时间在公众号上看到类似的观点，架构是发现stakeholder，然后解决之间concerns的工作。使用视点和视角与利益相关者合作。\\n\\n第 10 章 架构与流程\\n\\n10.1 什么是流程\\n\\n10.2 流程和架构拆分的关系\\n\\n第 11 章 什么是架构师\\n\\n11.1 架构师做什么\\n\\n11.2 架构师也是人 \\n\\n11.3 人人都是架构师 \\n\\n11.4 架构师和权利 \\n\\n第二部分 软件架构 \\n\\n第 12 章 什么是软件 \\n\\n12.1 以模拟人为目标的冯诺依曼结构和图灵机 \\n\\n12.2 成本为王 \\n\\n12.3 天空才是极限 \\n\\n12.4 软件的作用 \\n\\n第 13 章 软件的生命周期 \\n\\n13.1 软件的开发生命周期 \\n\\n13.2 软件开发的增长 \\n\\n13.3 软件开发的迭代 \\n\\n13.4 软件的运行生命周期 \\n\\n第 14 章 什么是软件架构 \\n\\n14.1 要解决什么问题 \\n\\n14.2 分别是谁的问题呢 \\n\\n14.3 分别有什么问题 \\n\\n14.4 分析问题 \\n\\n14.5 会生成哪些架构 \\n\\n14.6 什么是软件架构 \\n\\n第 15 章 什么是软件架构师 \\n\\n15.1 软件架构师的区别 \\n\\n15.2 软件架构师的困境 \\n\\n15.3 生命周期的思考 \\n\\n15.4 软件架构师的权力 \\n\\n15.5 软件架构师和技术人员对技术的态度区别 \\n\\n15.6 架构师是技术的使用者 \\n\\n15.7 如何保障架构落地 \\n\\n第 16 章 业务、架构和技术三者的关系 \\n\\n16.1 什么是技术 \\n\\n16.2 业务和架构及技术之间的关系 \\n\\n16.3 技术人员和业务人员的关系 \\n\\n16.4 重新发明轮子 \\n\\n16.5 开源技术 \\n\\n第 17 章 软件研发 \\n\\n17.1 软件工程师的兴起和使命 \\n\\n17.2 分工的困境 \\n\\n17.3 软件的迭代 \\n\\n17.4 软件开发的分工 \\n\\n17.5 软件开发模式和架构 \\n\\n17.6 软件工程师的支持者 \\n\\n第 18 章 软件的架构拆分 \\n\\n18.1 软件拆分的原动力 \\n\\n18.2 软件开发团队的拆分 \\n\\n18.3 软件的拆分 \\n\\n18.4 软件开发的基础技术 \\n\\n18.5 软件拆分的第二动力 \\n\\n18.6 架构一步到位 \\n\\n第 19 章 如何写好代码 \\n\\n19.1 什么叫业务逻辑 \\n\\n19.2 业务逻辑分散的危害 \\n\\n19.3 业务逻辑内聚的好处 \\n\\n19.4 代码架构实例 \\n\\n19.5 代码误解 \\n\\n19.6 软件的拆分 \\n\\n第 20 章 单元测试 \\n\\n20.1 什么是单元测试 \\n\\n20.2 单元测试的困境 \\n\\n20.3 单元测试测什么 \\n\\n20.4 如何改造代码 \\n\\n20.5 为什么要做单元测试 \\n\\n20.6 如何做单元测试 \\n\\n第 21 章 软件架构和面向对象 \\n\\n21.1 什么是面向过程 \\n\\n21.2 什么是面向对象 \\n\\n21.3 生命周期和面向对象及面向过程 \\n\\n21.4 架构和面向对象及面向过程 \\n\\n21.5 面向对象的误区 \\n\\n21.6 对象和生命 \\n\\n第 22 章 软件架构与设计模式 \\n\\n22.1 模式以及模式的意义 \\n\\n22.2 什么是设计模式 \\n\\n22.3 软件设计模式 \\n\\n22.4 设计模式和架构 \\n\\n22.5 设计模式的误区 \\n\\n第 23 章 软件架构和软件框架 \\n\\n23.1 访问类框架 \\n\\n23.2 业务类框架 \\n\\n23.3 什么是框架 \\n\\n23.4 框架的特点 \\n\\n第 24 章 软件运维 \\n\\n24.1 软件运行生命周期\\n\\n24.2 什么是软件运维\\n\\n24.3 运维的业务模型\\n\\n24.4 控制变化\\n\\n24.5 监控变更\\n\\n24.6 预警变更\\n\\n24.7 主导变更 \\n\\n24.8 提升变更质量 \\n\\n24.9 运维的架构拆分 \\n\\n第 25 章 软件访问生命周期 \\n\\n25.1 软件访问的业务模型 \\n\\n25.2 软件访问路径的架构拆分 \\n\\n25.3 大规模软件访问的架构拆分 \\n\\n25.4 集群 \\n\\n25.5 数据中心 \\n\\n第 26 章 软件架构和大数据 \\n\\n26.1 什么是大数据 \\n\\n26.2 如何做好大数据 \\n\\n26.3 软件大数据 \\n\\n第 27 章 软件架构和建筑架构 \\n\\n27.1 软件架构和建筑架构的目标之异同 \\n\\n27.2 软件和建筑的架构扩展之异同 \\n\\n第三部分 软件架构的应用 \\n\\n第 28 章 交易 \\n\\n28.1 什么是交易 \\n\\n28.2 货币的出现 \\n\\n28.3 企业的实质 \\n\\n28.4 软件对交易的影响 \\n\\n28.5 软件的交易 \\n\\n28.6 企业的核心 \\n\\n第 29 章 产品 \\n\\n29.1 什么是产品 \\n\\n29.2 什么是商品 \\n\\n29.3 识别产品 \\n\\n29.4 产品系统 \\n\\n29.5 产品列表 \\n\\n29.6 产品详情 \\n\\n29.7 商品的规则 \\n\\n第 30 章 用户 \\n\\n30.1 什么是用户 \\n\\n30.2 为什么需要用户 \\n\\n30.3 客户的出现 \\n\\n30.4 用户的生命周期\\n\\n30.5 用户的识别\\n\\n第 31 章 订单\\n\\n31.1 什么是订单\\n\\n31.2 订单的生命周期架构拆分\\n\\n31.3 订单支付\\n\\n31.4 订单生命周期\\n\\n第 32 章 交易系统\\n\\n32.1 企业的架构拆分\\n\\n32.2 软件系统的建模\\n\\n32.3 访问业务模型\\n\\n32.4 交易软件系统的架构拆分\\n\\n32.5 服务的产生和粒度\\n\\n32.6 用户系统的拆分\\n\\n第 33 章 事务\\n\\n33.1 什么是事务\\n\\n33.2 软件中的事务\\n\\n33.3 数据库事务的滥用\\n\\n33.4 数据库的正确使用方式\\n\\n33.5 服务调用"}'));jctx.push(JSON.parse('{"id": "170424", "tag": "protocol", "text": "# 协议是什么，要定义什么\\n\\n## 定义和期望\\n\\n每一个软件只要不是像HelloWorld那样纯入门性质的软件，它一定承载了某种功能，想让它完成某种功能就要有固定的格式，这种格式便是接口，如果网络化了又可以称之为协议。Unix时代的软件多是单机执行，也存在着格式的要求，比如grep就要求第一个参数是搜索关键词，第二个及以后是要搜索的文件名，缺少或者乱了都不行，到了网络时代因为传输的复杂性，接口的要求也愈加复杂，但本质都是对输入的一种约定。有了输入，则软件会按预设的行为给出结果，同样拿grep为例，它会将文件拆分成以行为单位，并将每行和给定关键词进行匹配，一旦匹配成功则输出这行的内容。至于正则表达式如何被编译，又如果匹配，使用者无需关心。\\n\\n同样的对于业务层协议，要定义一种业务的输入格式及反应行为的期望结果，至于背后的实现逻辑不需要也不应该在协议定义，当然如果我们对这块业务很熟悉，看到接口大致能推断出背后的逻辑是什么样的，当然这不是必须。\\n\\n比如大华的configManager.deleteFile协议，历史原因它是没有入参的，自然也无法知道到底删除什么文件，相应地就我们需要严格定义它的行为，比如让设备回到出厂状态，只要删除的文件让设备看起来是恢复出厂，这个协议目标就达到了。更进一步最好要规定出厂状态的指标，在做测试时更有依据。\\n\\n再比如有个需求要实现抽帧播放，可以保留I帧后的若干个P帧，也可以若干个I帧只保留1个。如果只是这样定义，似乎也没有问题。但是考虑到H264规范有一种特殊的P帧，比一般的P帧大且只依赖于I帧，这时按照若干个I帧回放1个的定义，对这种视频就应该是若干个I帧加重定位P帧中抽取一个。随着视频格式的不同，协议竟然要跟着变化，说明这样的定义没有触及更根本的东西。更好的定义就是以最少几秒看到一个视频切面来定义能观察到的行为，这种方式不依赖实现细节，协议才能稳定。\\n\\n## 协议的层次\\n\\n对于分层OSI给出了七层模型，通常业务协议不需要如此复杂，传输层(TCP/UDP)\\\\+标识层\\\\+载荷就够了。通常TCP占主流，UDP更多的用在实时的音视频流或NAT中，标识层衔接了传输层和载荷，作用是指示分包、加密、校验和等功能，这一层要考虑不同客户端的便利性。载荷层负责描述业务内容，多为消息封装格式，常见的有XML或JSON，如果觉得文本格式浪费体积也有Protobuff或MsgPack这类Binary的消息封装。对于秒级的消息通信业务而言，消息大小、解析时间并不是瓶颈，我认为简单易懂且普及(JS天生支持使得在Web领域更是加分)的JSON是够用了。像Protobuff则是到了毫秒级的通信场景下才能发挥更大的作用。\\n\\n## 协议设计的关联性原则\\n\\n比如登陆和是否支持静态/动态多连接在同一个交互里，现在看来就属于过耦合。因为登陆不意味着要取流，但由于多连接的存在，导致登陆的处理代码非常复杂。比如静态要建立所有的连接，如果是动态则必须把状态内化，以期在真正拉流时能确定设备的调性，可是这就把这个特性的周期延长了，理想的设计特性是用完即丢，从概念上尽量做到stateless为好。比如在真正开始取视频流时，在应答中告知客户端接下来的连接特性，客户端依此做反应，这个状态的周期就被约束在真正的取流过程。\\n\\n视频流协议的业界标准RTSP就是这样，先发请求信令并根据回复的地址/端口建立子连接，而公司的私有协议是先请求建立连接，再创建子连接，最后再发信令。虽然看起来建立连接必不可少，但发信令比起来显然更重要一些，既然更重要，就应该更放在前面，也许后一个看起来也很重要的操作，就可以省掉了。比如大华的P2P网络，实际的连接只有一个，创建一个子连接反而是一种累赘。所以尽量不要额外地假设一些条件，只要保证更高优先级的操作被更早更完整地处理掉。那些额外的假设条件最好要明确地写出来，以便让以后的人知道当环境改变时，可以毫不犹豫地对协议进行调整。\\n\\n## 协议体系的自洽\\n\\n曾经和夏杰聊过，协议要能自圆其说。如果从更哲学的角度来理解，尼采有句描述：这个世界没有事实，只有诠释。即所有的现象都是诠释/解释，解释的方式可以有很多种，但是只有最具有说服力的解释，才能占得主流地位。大华协议也是对监控领域这个小世界的诠释，因此只有具备最好的解释性的协议，才能生存到最后。一个好的解释体系，根基有两件事，定义(或概念)和逻辑推演。没有体系内明确的定义(只要明确，不过度追求“正确”)，逻辑推演就是无本之木容易陷入诡辩和循环认证，没有正确的推演，衍生的结果往往会冲突。\\n\\n## QA(17年6月初)\\n\\n1. 协议的本质是什么，好的衡量标准(金线)是什么？\\n* 协议是被网络化的接口，接口的本质是契约。即在什么样的规定前提下，通过什么样给定的输入，最终达成怎样的输出。衡量标准就是契约的定义，越详细越无歧义越好。至于扩展性的权重，是第二位甚至更靠后，大不了重新订一份新的契约就好了。\\n2. 大华协议有4千多条，粒度是什么或者说应该依据什么来制定协议？(此处是两个原始问题)\\n* 有4千多条，就说明有4千多个应用场景，分别有不同的输入，有不同的期望输出。考虑到大华是个OEM导向的公司，光IPC一年软件版本能达到1万多个，4千并不多。至于粒度，对超过90%的定制协议，满足定制客户的使用场景就是好的协议。如果一定要说粒度，两件事，如果以普通消费者能够区分的差异度来区分协议。但也不要把从软件上可以归并的行为硬生生归在一起。我想到微信的例子，把小视频和拍照合并到一起后，我的母亲就再也不会用小视频了。(因为那个按键短按是拍照，长按是视频，母亲不会用长按这种操作方法)\\n3. 协议要包含哪些元素？\\n* 同问题1，界定什么场景下用，输入和输出，这些要素是第一性的。至于其它request-ID，session-ID，就好比是合同中的签名，如果再有时间戳，相当于合同的有效期，就更好了。\\n4. RPC要定义哪些方法，如何让调用者更简单？比如做到RESTful风格。\\n* 简单的定义要从理解角度看，如果用户懂业务背景，或者需求就是用户定制的，那么和定制需求完全契合的协议，就是最简单的。说实话RESTful风格未必就是简单，把一切都认为是资源的行为，然后基于资源的操作，这种思想适用于互联网，或者反过来说，正是基于互联网的基础设施，提出了RESTful。但不同的领域，未必都要按RESTful方式设计。让使用者最自然的使用方式，就是简单。这方面有很多理论，最少知识/最少惊奇原则。"}'));jctx.push(JSON.parse('{"id": "170429", "tag": "protocol", "text": "# P2P及SIP和xinetd\\n\\nP2P穿透涉及的协议有STUN/TURN/ICE，STUN是真正的UDP打洞，但只适用于cone NAT的网络环境下(完全、限制、端口限制三种都支持)，因为STUN的核心是子网内的客户端和公网建立连接后，NAT映射后的公网地址要能被另一个客户端使用，只有cone NAT才满足这个条件，symmetric NAT不允许公网端口复用，因此无法即使从公网上获取了NAT后的地址，也不能用来和另一个对端连接。\\n\\n对symmetric网络，只能使用中继方式，就用到TURN的方式，ICE要解决的问题和TURN类似，但两者的差异还没有完全清楚。\\n\\nP2P之后两个端就要建立会话，SIP是定义非常严谨的协议，明确地分了4个层级，基础的用ABNF规定了文档用语的格式，然后是传输层，接着是和业务关联最紧密的事务层，事务层之上还有个可选的事务用户(TU)，但这一层并不是必须的，比如无状态的proxy就没有TU一说。\\n\\n## xinetd类程序\\n\\n知道xinetd这玩意属于偶然，本想尝试着在linux上跑cvs的server端，然而还是失败了。所有的服务端程序都需要监听端口，比如httpd就自己监听80，但是如果有大量非高频程序，要监听各式各样的端口，全数都启动显然是浪费资源，super server daemon也就是xinetd就是解决这类问题。这个程序的前身是inetd，不过现在都切换到xinetd了。\\n它的功能是配合/etc/service配置项，监听各种各样的端口，然后把端口请求转发给相应的程序。比如在/etc/xinetd.d/目录下配置2401端口由cvs监听，平时cvs不会启动只有2401端口来请求时就唤醒cvs来处理。很多本身不带网络服务的程序，通过xinetd就具备了通信功能，有点CGI的味道。\\n\\n从功能上可以看出xinetd属于优化类程序，并不是默认自带程序，Alpine linux甚至都没有包。在Cent7下通过yum install xinetd安装，也可以通过下载包手动安装，依赖很少。xinetd程序也很小，x64版本不到200K。安装后还需要通过service xinetd start启动，这样才真正开始监听。\\n\\n用xined监听telnet遇到问题，系统默认telnet只能监听23端口，但是这要求有root权限，这种情况下要先在service增加一个伪telnet服务，让这个服务监听新端口，然后配置这个伪服务，最终导给telnet监听。\\n\\nbusybox有类似的程序tcpsvd，配套telnetd和ftpd一起使用。"}'));jctx.push(JSON.parse('{"id": "170516", "tag": "os", "text": "# OpenBSD学习与使用\\n\\n系统分为内核文件和应用层套件，根目录下放置启动器boot和内核文件bsd，对一些支持多核的芯片，会另有bsd.mp文件，但不清楚此时bsd是否仍必须。\\n\\n用ksh作为默认shell，功能少很多。每个版本升级会带来若干改动，升级换内核前必须做好充分准备工作。\\n\\n## 系统工具\\n\\n* syspatch 更新系统的应用层套件\\n* pkg_add 包管理器，修改/etc/installurl可以换源\\n\\n## ps程序走读\\n\\nps程序要从内核读取进程消息，BSD内核上承SunOS使用了kvm.h，这并不是Linux下的虚拟机，而是kernel virtual memory的意思。是用户态读取内核的交互接口，kvm的一些操作需要root权限，这也是BSD系列的ps和Linux的ps不同的原因。\\n\\n大致来说，先用`kvm_openfiles`打开一个kvm句柄，然后用`kvm_getprocs`读取内核参数，并返回一个`kinfo_proc`数组，用qsort对数组进行排序，排序的比较方式有DEFAULT/CPU/MEM三种，内存排序值得说说，`kinfo_proc`是个非常大的结构，计算内存使用了其中有的tsize/dsize/ssize三个变量，分别表示text/data/stack size，另外还有rssize，即RSS，注释是current resident set size指包括栈和堆在内的占用物理内存。但排序并不把这个值计算在内。显示的时候还有VSZ表示virtual size，但奇怪的是在OpenBSD上，VSZ却比RSS还小。\\n\\nps在检测进程状态有个-t选项，表示只显示与这个tty关联的进程，/dev/下有100多个tty，命名都是/dev/tty开头，这是在paths.h的`_PATH_TTY`宏来定义，这个文件定义了很多与路径相关的变量，Linux也有，应该是为了让程序跨平台用的。与操作者相关的是ttyp0和ttyp1，另外还有ttyC，ttyc、ttyP、ttyVI等好几个大类的终端。\\n\\n另外还有大量的代码都是在处理各种参数，因为ps的参数实在太多了。"}'));jctx.push(JSON.parse('{"id": "170525", "tag": "protocol", "text": "# 网络相关头文件所属目录的关系\\n\\nunix下的网络文件分布的目录比较多，初看会觉得很乱且难记，试着整理一下。\\n\\n本着unix下一切皆文件，所有的网络操作都通过抽象的socket操作，即socket是这些网络的承载者，不同的网络主机有各自的socket，并处在不同地址上。socket的头文件是sys/socket.h，比较直观也很好记。\\n\\n对网络来说，不同的网络不能直接通信，所以socket首先要和地址绑定，不同的网络方式地址格式不同，要确定地址就要先确定网络方式，这里引入第一个概念`AF_XXX`宏，AF指Address Family，除了常见的IP网络(有`AF_INET/AF_INET6`两种)，还有像Bluetooth、AppleTalk、IPX(Novell)等不常见格式。OpenBSD支持36种，而Linux支持40种。从数量来看好像差不多，但两个系统间互相之间的交集并不多。Linux支持的NFC/CAN格式在BSD下不存在，同样BSD也有很多Linux没有的，不过总的来看BSD的网络协议更冷门一点，也许和它历史更久，用得也少有关系。\\n\\n因为不同的地址族使用不同的协议，所以还定义了一套`PF_XXX`的宏，PF指Protocol Family，除了前缀不同，其它和AF宏完全一样。既然有三十多种地址，地址的格式必然不会相同，struct sockaddr解决的就是这个问题，这是个变长的结构，否则无法支持未来的网络协议族，因此这个结构最重要的就是长度和family字段，定义方式和TLV的思想是一致的。sockaddr相当于父类，具体每种协议族有各自的表示，像`sockaddr_in`是IP网络地址，而appletalk就是`sockaddr_at`，命名风格非常统一。不过并不是每个协议族都有专用地址，net80211/就没有。\\n\\n虽然socket.h文件比较长，但和操作相关的accept/bind/connet/listen等占比重不高，其余大量各种宏和数据结构操作的定义。比如`SOCK_STREAM/SOCK_DGRAM`，这样看起来，这两个定义适合各种网络，而不仅仅是TCP/UDP。\\n\\n理解了socket.h，就能知道网络的family有非常多，每种family下肯定还有很多的选项，这么多的协议族肯定要分开保存管理，所以在/usr/include/目录下有net/目录，还有形如netinet/、netmpls/、netatalk/、netax25/等等具体协议族的目录。\\n\\n先说net/目录，这下面的文件特点是大都`if_xxx.h`风格，主要的用途是查询(inquery)各种network interface。比如`IFF_UP/IFF_MULTICAST`操作。BSD和Linux在这里又显出很大的差别，BSD中定义了名为ifnet的结构，用于内核操作网络接口man(9)，但Linux没有。\\n\\nnet的作用更多在于操作网卡，具体的协议比如IP协议则定义在netinet/目录下，这里的in.h(我猜应该in是internet的简写)定义了IP协议的各种应用，如TCP/UDP/ICMP/IGMP/ESP/AH等。这些定义都以`IPPROTO_`作为前缀，是IP PROTOCOL的简写。\\n\\n这样一路看下来，网络头文件的规律就很清晰了。最后再说一个稍有点特殊的头文件，arpa/inet.h，这里定义了各种IP地址的数字表示和字符串表示的转换函数，为什么放在arpa目录，我猜是因为：IP网络的定义是由IEEE提出的，但第一个实现这个网络的是arpanet(1968年构想，直到1975年才有60个节点)，可能是当时开发时觉得，需要一个工具性质的地址转换函数，就放在arpa这个有点项目专用性质的目录下了，但后来随着用的人很多，所以就保留至今，没有移到netinet目录。另外arpa/目录下还有telnet.h/ftp.h/tftp.h等文件，原因是arpanet要求主机实现telnet/ftp/tftp协议，这也是一个网络最基本且必须的功能。所以arpa/目录作为历史的见证一直保留到今天。"}'));jctx.push(JSON.parse('{"id": "170526", "tag": "net", "text": "# 从ifconfig接口看网卡\\n\\nifconfig显示的除了网卡，还有网桥bridge，因为if表示接口，没有限定必须是网卡。\\n\\nip命令比ifconfig显示的网卡数量多一些，ip能显示的网卡，都在/proc/net/dev里保存着。\\n\\nip区分了link和address命令，link显示的接口，会显示出attach到ether/loopback/ipip。address显示的是link的超集，有些网卡有多地址，用link只有一条，而address就会把所有的地址都显示出来。\\n\\n## 网络工具包的变迁\\n\\nifconfig/route/netstat/arp/rarp等网络管理经典软件（属于net-tools包），起源于BSD TCP/IP工具箱，旨在配置老式Linux内核的网络功能。自2001年以后，它在Linux社区的发展就止步不前，很多发行版默认不安装该包，甚至有弃用net-tools的打算，改而使用iproute2替代。net-tools通过procfs(/proc)和ioctl系统调用去访问和改变内核网络配置，而iproute2则通过netlink协议与内核通讯（这套协议和unix域套接字、inet在同一层级）。由于netlink是Linux独有，BSD社区依然使用net-tools工具。\\n\\n网卡的模式在if.h定义，有十多种。这些状态大多是可以组合，少数互斥(环回LOOPBACK，bond的MASTER/SLAVE)。说几个可能不那么常见的\\n\\n* LOWER\\\\_UP：注释表明Driver signals L1 up (since Linux 2.6.17)，是物理层的标志。LOWER\\\\_UP表示以太网线已插入，并且设备接入到网络。而UP在LOWER\\\\_UP的基础上，还要求网卡使能（个人理解是被ifup）。\\n* NO-CARRIER：可以和UP一起，但表示网络不通。可能的原因有：网线故障、无线未在SSID认证、驱动故障（极少数）。\\n* NOARP：对于BORADCAST型网络（以太网或无线电packet radio），ARP标志默认打开，如果显示NOARP则表示ARP被禁用，可能是网络形态不同，也可能确实遇到故障。\\n* PROMISC: 混杂模式，接受目的MAC不是本网卡的包。抓包软件和虚拟网卡会用到。\\n\\nifconfig会显示发送和收到的包数据，单位多见MiB，这个单位表示2^20，在1998年12月定义的ISO/IEC80000规范里可查，同一家族有kibi, mebi, gibi, tebi, pebi, exbi, zebi, yobi，i取自binary的第2个字母，所以这些单位都用bi后缀。而平时常见的MB往往会视场景，可能是10^6，也可能是2^20。以精确而言，MiB是更好的写法。\\n\\nRX和TX的包数据里，会另外显示5种异常状态的数据（frame和carrier是单向）\\n\\n* Errors: The total number of transmit or receive errors detected by the device driver.\\n* Dropped: The total number of packets dropped by the device driver.\\n* Overruns: 驱动拿到的包，会放到内核的Ring Buffer（FIFO队列），如果网络流量过大超过CPU处理速度，就会导致overrun。ethtool -g查看，ethtool -G修改参数。\\n* Frame: 收包特有，一般表示收到的帧过小或过大，比如不符合8bit的帧。\\n* Carrier: 发包特有，carrier原意是调制用的载波，此处表示因载波异常或不匹配导致数据发不出去。\\n\\n## Linux与BSD的网卡差异\\n\\nLinux下的网卡只有lo和eth两张，但是OpenBSD还额外多两张虚拟网卡，enc和pflog。这两张网卡都是基于pf而存在，因此也就好理解为什么是OpenBSD特有的网卡。\\n\\nenc和ipsec特性配套，pflog则是pf log的简写。IPSec有四大特点：\\n\\n1. 数据加密\\n2. 内容完整\\n3. 身份认证\\n4. 防重放攻击\\n\\nIPSec有两个协议族，ESP(Encapsulating Security Payload)和AH(Authentication Header)，差异在于\\n\\n* ESP具备以上四条特性，但只对IP的负载生效，不保证IP头的安全\\n* AH重心在认证，因此缺少数据加密功能，但它能保护IP头\\n\\n如果要让socket启用IPSec，OpenBSD的netinet/in.h下定义了很多IPSec的宏，如`IP_AUTH_LEVEL/IP_ESP_TRANS_LEVEL/IP_ESP_NETWORK_LEVEL`以及`IPSEC_`开头的很多宏，可惜这些并不跨平台，Linux系统定义在linux/ipsec.h中，且是通过枚举方式，数量也没有OpenBSD详细。\\n\\n从默认网卡的配置和头文件定义就能看出，OpenBSD的确是在践行着最安全操作系统的理念。\\n\\n## bond网卡制作\\n\\n服务器通常有多张网卡，要求配置为bond模式，对cent系来说，并不用特殊的命令，只要添加一个ifcfg-bond0的纯文本文件，重新启动网络服务就好。\\n\\n展开了说，bond是由普通eth网卡组成，同时修改那几个ifcfg-eth的文本，使它们映射到bond，而所有的IP，网关，掩码都在bond配置。似乎还要启动一个内核模块，具体原因不明。\\n"}'));jctx.push(JSON.parse('{"id": "170530", "tag": "design", "text": "# 组件化与线程模型及缺陷\\n\\n今天夏杰和我看了他的PPT，讲到组件化在实现过程中留下的缺点，很值得反思。\\n\\n组件化以类为单位，并提供接口给外部操作。这种开发模式更像是提供一堆的工具类，而不是程序的框架。因此在开发时，必须要另外提供线程模型来执行这些组件，对设备而言，线程就在各个接入协议里自顾自地跑起来了。这样带来两个问题\\n\\n1. 随着接入协议变多，线程池和线程数量肯定会越来越多。\\n2. 对组件实现者而言，由于不确实组件的执行环境，为了确保多线程安全，最简单粗暴的做法就是大量的加锁，所以代码中经常可见不知有用还是无用的锁。\\n\\n原因就是程序是静态的代码组织和动态的代码执行两部分组成的，组件化解决了面条代码的问题，但在大华的执行期上却处理得很糟糕，虽然有RPCFramework这一理论上可用的公用业务线程池，比如Onvif也可以把请求转交到这里执行，但想用RPCFramework却强依赖继承的方式，侵入性太高，且接口又过度地和大华私有业务绑定，导致三方接入库不愿意用。\\n\\n分析下来，也不能全怪组件化，只是它缺少一个好的动态运行框架，才导致组件层面实现沉重无比。下一步就是要想办法提出一个好的动态运行模型，和组件化一起承担完整的业务模型。\\n\\n通过给NetSDK培训了协议和组件化的课件，也让我自己梳理出如果从协议角度看组件化，最核心的概念就是反射。根据字符串消息，找到类和方法进而执行。\\n公司的组件化从接口层看就是带了工厂的类，但从全局的角度看其实是更大粒度的模块。一个组件的接口可以由很多个类来分担实现，每个实现类可以具备自己的public接口，但并不是所有实现类的public接口都需要暴露给组件层面。\\n组件更多的是用于外部网络或者不同库之间的协作，包含的功能会更大一些。既然组件是不同库之间的契约，因此参数就更需要明确，不能使用Json式的灵活接口。\\n\\n6月份7日追记：\\n\\n由于组件化又和RPC协议联合使用，而RPC方式即意味着一个请求到来变成了对另一个模块的调用，这种模式对测试很不友好，只能打桩测或者整体测试了。如果整体测，出了问题无法确定出在哪个模块，而打桩测又必须对接口有很严格的定义，而大华接口定义的不严谨根本无法支撑打桩所需要的提前。\\n\\n软件作为一个新兴行业，只要验证和测试这关难过，就无法成为一个成熟的行业。硬件由于物理的限制，一个特性呈现出的行为是固定的，而软件因为完全由人实现，几乎可以达到无限的自由度，因此对接口的定义一定要严格，否则可测试性也就无从谈起。"}'));jctx.push(JSON.parse('{"id": "170531", "tag": "tool", "text": "# Word的标题样式和多级列表关系\\n\\n对一篇有结构层次的文档而言，章节标题的编号是很重要的，它能很直观地给出这部分内容在整个文章中的位置和前后关系。虽然通过给标题刷上样式，也能出现编号，但这种编号只能是简单的一个数字，想要达到类似1.1，1.2.1这样具备层次的效果，只靠标题样式无法实现。需要利用Word中被称为`多级列表`功能，它不同于简单的编号，也无法在样式的菜单中实现。\\n\\n定义一个想要的多级列表，需要通过独立的多级列表菜单进入。在备选的列表库中，提供了几种多级列表样式。如果要自定义的话，有几个很重要的点要注意\\n\\n1. 将定义后的多级列表链接到样式，这点非常重要。我猜测是样式只记录了自身编号，所以样式的编号菜单不论再怎么折腾，只能实现一级数字的效果，无法实现多级序号并列。要显示多级序号，必然要参照更高一级别的编号，如果实现在样式中，按程序员的行话，就会造成标题间的强耦合，而微软又是一个非常强调工程师文化的地方，并不考虑使用者是否好用，所以没有把多级列表的设定放进样式菜单。\\n2. 怎么让多级列表能识别上一级标题，不要出现明明第二章了，却还是1.4这种荒诞的样式呢？在设定新的多级列表中，又有两个选项，此级别的编号样式和包含的级别编号两项，包含的级别编号就能自动继承上一级标题。但要注意这两个编号的顺序不要反，否则会出现本级标题在前，大标题在后的怪异效果，即明明是第二章第一节，应该显示2.1却显示成了1.2。搞不懂为什么要有这种灵活性，按我想法，直接固定上级标题在前，本级标题在后，岂不是更方便使用。难道在多语言环境中，会出现本级标题在前高级标题在后的需要吗？"}'));jctx.push(JSON.parse('{"id": "170601", "tag": "design", "text": "# PPT到底做什么\\n\\n不是动画也不是美学，是观点以合理的逻辑顺便呈现。\\n\\n提到Jobs在第一代iPhone发布会上，三种功能因为是并列关系，不能以开门的方式展现。也许观众不会注意，但从组织观点角度看，平铺的方式确实是对的。\\n\\n幻灯片根据使用场景不同，制作方式的差别是非常大的。如果是用于看的幻灯，内容可以多，更像写一个Word，只是在呈现上每个版面空间有限放的内容更少。但如果是给人讲的幻灯，则重点在于控制观众的注意力。控制注意力就是把控焦点，所以内容呈现上决不可出现大量的内容，即使有，也要用渐隐方式每次只呈现一点，这样才能始终引导焦点。\\n\\n定位mp4播放失败，先看http抓包以为是回复的MIME类型错误application/http，但改成octet-stream和video/mp4均没用。后者甚至是RFC规范。\\n\\n看mp4包头似乎也没有大问题，但拿到完整文件才发现中间少了一截，50M的文件在9M处少了260K就一点都放不了，这和MP4非流式的文件特性有关。可能是wireshark本身的问题，数据是完整的，但就会存在数据丢失的情况，怎么证明抓TCP包会丢，seq和ack明显不连续，从IP包序号看源端发出了但收端没有捕获。一般只能重抓。"}'));jctx.push(JSON.parse('{"id": "170604", "tag": "design", "text": "# 从串口功能的封装看如何抽象\\n\\n串口并不是不可分割的一体，就好像网络socket的TCP和UDP是差异巨大的两个类别，232和485的差别也是非常之大。之所以会混为一谈，只是对它了解不够，所以必须区别对待。\\n\\n232串口有点类似TCP，类似虚电路的点到点连接，且一个串口只能连接一个设备。而485串口则类似UDP，一条总线挂载多台设备，以类似广播方式发送消息。从硬件层面(PAL)抽象无非就是把一个串口作为一个对象，把设置串口属性、读、写都作为独立接口，这无可厚非，但应用层如果也只是简单封装，232可能没问题，485则会有严重不足。\\n\\n设想485上挂的两台设备使用的波特率、奇偶位都不相同，但又因为硬件限制要共用一个硬件，每次发送消息前都要先设置串口属性再发送，如果是等待结果的消息，还必须等待读返回。三步操作如果任何一个被其它线程从中切入都会造成数据异常。因此485串口属性设置和读写必须是原子化的，应用层的操作接口要基于硬件层原始接口封装,而且PAL要提供锁接口才能保证不同上层使用同一把锁。\\n\\n综上，485串口比较理想的抽象应该是PAL层提供原子化的设置/读/写接口，并提供接口间的锁。应用层基于这些基础设施，提供更高一级的设置写读一体化接口，才能满足一个串口接不同设备的通信需求。"}'));jctx.push(JSON.parse('{"id": "170608", "tag": "design", "text": "# 灯光和相机差异的关联和协议需求\\n\\n不同相机对灯光的需求差异很大，交通相机、普通IPC、球式相机都有各自的特点。\\n\\n比如交通相机工作重点在于车牌抓拍，最主要的就是如何把车牌拍清晰，重在静态的图片而不是视频，另外车牌和相机的距离必须在一个固定值，否则拍出来的照片内车牌尺寸就不合适。基于此，交通相机补光的范围只要保证在一个固定范围能恰好能打亮就行，加上车牌必须是彩色，只能用白光灯，红外灯是没有价值的。因此交通相机的补光灯有频闪、爆闪和常亮三种灯，频闪和爆闪更是只追求瞬间亮度，保证这一时刻车牌清晰就足够了。\\n\\n球机除了旋转功能，缩放也是一大亮点。目前球机的比拼很大一块也投入了比谁看得更远。30倍甚至40倍变焦都已出现。所以球机的指标里距离是很重要的。为了配合距离灯光也有近中远的区分。而灯光又分为红外、白光、激光。红外主要用于晚上距离可以达到几百米，白光可以照亮但距离也短得多，往往只有几十米。\\n\\nIPC主要使用场景是室内，一般只配备红外灯，和IPC体积小散热结构有关，白光的热能比红外更大。\\n\\n可见仅仅是补光一项，必须根据不同相机的使用场景搭配适当的灯光。\\n\\n灯光差异这么大，灯光协议也很容易入坑。比如球机的灯光配置要从全时扩展成分时，就怎么修改都无法满足。\\n\\n最初的灯光协议只说明是补光，未说明是红外还是白光。了解到原来球机因为只有一种灯，如果是复合灯则用另一套配置。虽然暂时解决了问题，但Lighting配置的作用到底是夜视还是全彩，依然不确定。这是协议的第一个问题。教训，不要把一种配置作多种明显不同的用途。\\n\\n配置的形式是数组，但只用了第一维元素。不知道最初设计数组的目的是什么，然后需求来了，对不同的时间段要有不同的灯光配置。但问题又出在是否启用日夜模式并不在Lighting配置，就会出现A客户端修改了灯光模式，结果B客户端无论如何修改都无法成功。所以模式必须也在Lighting配置中。"}'));jctx.push(JSON.parse('{"id": "170610", "tag": "os", "text": "# dmesg和BSD初期版本的故事\\n\\ndmesg最早出现在3BSD时代。\\n\\n1975年Ken Thompson请了一年休假并来到Berkeley担任客座教授，Ken在Berkeley安装了Version 6的Unix，并实现Pascal编译器。这时Bill Joy因为优化这个编译器而出现在历史舞台上。因为其它学校对这个系统也很感兴趣，Joy在77年着手完成系统的拷贝并最终在1978年3月发布了称为1BSD的版本，共卖出30份。接着1979年5月发布了2BSD版本，这个版本有两个程序至今还在用，就是vi和csh，共卖了75份。\\n\\n头两个版本是Joy初试牛刀，同期发生的重要事件是1978年Berkeley买了VAX机，当时贝尔实验室也为VAX做了适配并命名为UNIX/32V（基于Version 7 Unix）。但这个系统并没有优化好VAX的虚拟内存特性，于是Berkeley的学生大幅重写了内核并把2BSD的程序也移植到了VAX机，最终在1979年底发布了3BSD。从这个版本起，BSD便不再是UNIX的clone了。\\n\\ndmesg在OpenBSD的实现并不复杂，利用sysctl接口的`CTL_KERN`和`KERN_MSGBUFSIZE`命令字获取信息的长度。再用`KERN_MSGBUF`获取真正的内容。不过这两个枚举在FreeBSD上没有定义，OpenBSD中定义的KERN操作枚举值要比FreeBSD来得多，大概也是两套系统在逐渐演化过程中发生的差异吧。\\n\\n内核文件是名为bsd的大约10M的文件，不像Linux的vmlinuz文件，bsd就是个普通的ELF执行文件，内核文件不止一个，比如bsd.mp用于多核系统，还有bsd.rd是类似光盘镜像的文件，如果用syspatch升级内核，还会产生一个bsd.syspatch61的备份文件。根目录下还有boot文件，类似于grub，启动顺序也是BIOS->boot->bsd这个顺序。\\n\\n安装包使用`pkg_xxx`系列，应该是和FreeBSD类似，使用tar包方式，tar包其实有多种格式，GNU的tar用的默认格式是gnu，但OpenBSD用的是ustar，是1988年的posix版本，另外有2001版posix标准的tar，GNU宣称未来也会切换到这种方式。安装包的地址从/etc/installurl获取，目前我只找到清华的repo是\\nhttps://ftp.openbsd.org/pub/OpenBSD和https://mirrors.tuna.tsinghua.edu.cn/OpenBSD。\\n\\nOpenBSD的代码是用cvs管理的，看来落伍但社区觉得已经足够。先说说分支管理：风格很固定，每个版本有`OPENBSD_6_1_BASE`和`OPENBSD_6_1`两个标签(symbolic name)，其中BASE是revision，也就是Milestone，一般是决定开发新版本时，创建一个后续不再更新；而`OPENBSD_6_1`则是基于这个revision的branch，是真正的发行代码。\\n"}'));jctx.push(JSON.parse('{"id": "170613", "tag": "protocol", "text": "# 礼让行人和车流量协议问题反思\\n\\n礼让行人协议的问题是，在说明时忽略了背景介绍。原文是这样的\\n\\n    Direction : [\\"Left\\", \\"Right\\"]; Left表示向左，Right表示向右，数组为空表示表示不关心方向，即行人即使不动也表示违规。\\n\\n这句注释的后半句还好，但前半句就很可笑了，谁不知道Left表示左呢。因为左右是相对的概念，如果不说明坐标系是没有意义的。我初以为是俯视图，但怎么也想不出来，另外同事认为是面对红绿灯的视角，直到问了做过这块业务的开发才知道是以相机预览画面视角，车为上下行故人为左右行。因此把视角补上才完整，另外方向已经解释，但单方向如左表示违规的情况没有给出示例，需要说明比如左车道只有左行，即和车方向靠近时才表示违规，这样的解释才是个好的说明。\\n\\n再说车流量协议，原稿描述很简单，分别显示机动车/非机动车流量。初看并没有问题，但车流量有很多分类，除了机/非方式，还有按左转/右转/直行分类，也可以按轿车/卡车分类。所以在显示之前要先定下分类模式，然后展示。另外机和非的定义其实也不够确定，比如按车长定义，以4/6/9/12米长度为界把车分为5类，这样的定义相对更严谨一些。"}'));jctx.push(JSON.parse('{"id": "170620", "tag": "lang", "text": "# 从Javascript函数类型理解计算和对象\\n\\n对任何程序语言来说，函数的设计是最核心的特质，函数涉及的变量作用域、参数的值和引用语义这些基础概念体现了语言设计的核心价值。JS的原则是一切皆对象，typeof null的结果是Object，自然function也是对象。定义一个function foo变量，可以用foo.xxx语法取成员变量。原因是凡是对象都可以用点号来索引成员，既然foo是函数（对象），当然也可以用点号语法。\\n\\nJS的对象可以和Lua元素的`__call`元方法或者`C++`的operator()比较。由于JS的函数是对象，因此可以用`.`符号从对象中索引成员，这就是[].push.apply这种神奇语法的来由。这里的两个点号分两段理解，第一个点从[]这个空的数组对象中取到push方法，第二个点从push方法提取apply方法。注意push是函数，但同时也是对象，因为函数对象有apply成员，所以可以从push索引到apply。\\n\\n以上这几种语言中，函数可以认为是一种拥有计算能力的对象，而计算则是在一个有限的环境下进行变量操作。对JS来说，环境就是this变量，对Lua则是`_ENV`。换句话说把`C++`成员函数的第一个this参数理解成环境，也未尝不可。这一点从MuJS的C接口`js_call`必须先压入一个this参数可以体现出来。\\n\\n## prototype和constructor\\n\\nJS的对象体系最大特色是原型和constructor。记住一个概念，JS的12种类型里，所有变量都有隐式原型`__proto__`，只有Function类型才有显式prototype，由于prototype是Object类型对象，所以它只有`__proto__`属性。\\n\\n通过new Function获得的值，如果不是Function，就不会有prototype，只有隐式的`__proto__`，且指向Function的prototype。这样做的目的是维持继承体系。用代码展示更直观：\\n\\n```\\nvar obj = new afunc()\\nobj.__proto__ === afunc.prototype    // 非函数类型的值没有prototype，但会有个隐式的变量指向其构造者的原型\\n```\\n\\nconstructor也是函数衍生出的概念，只有函数和prototype指向的对象才有constructor。用function foo()定义一个函数，foo.constructor指向Function()，而foo.prototype.constructor指向foo，这是两个不同的对象，要注意区分。new一个构造函数在MuJS通过专用的`js_constructor`语法来调用，和`js_call`惟一的差异就是少了压入this这步操作。\\n\\n任何函数都可以作为构造函数被使用，考虑new的语义是先创建一个空的对象，把这个函数中涉及this的语句操作，作用在新创建出的空对象上。最后返回这个对象，因此return语句就自动失效了。"}'));jctx.push(JSON.parse('{"id": "170621", "tag": "design", "text": "# 云升级项目的反思\\n\\n这个项目大概是我在大华经历最失败的项目了，因为不确定最初的需求到底是什么，我自己的理解应该只是客户无法下载升级包，如果是这样提供工具可以\\n下载升级，而不是执着于必须由设备主动从云下载。\\n\\n嵌入式设备的升级包包含的分区非常多，比如一个典型的NVR升级包，去掉签名包还有6个分区，分别是uBoot、kernel、rootfs、web、custom、logo。前三个是执行所不可少的，web一般来说也是必须的，custom和logo则和公司的商业模式有关，因为有些大的OEM商不会修改功能，只要把logo换掉，最多把web界面的配色换了就可以，所以这两个分区独立是有价值的，custom分区则给一些小的定制功能使用，通过配置来打开/关闭某些功能。uboot和kernel不需多说，rootfs包括了执行程序，和busybox等接触最多的程序。\\n\\n正是因为多个分区具有独立升级的需求，导致需求分散极难实现。\\n\\n因为云升级项目考虑到法务上的风险(不明白为什么会有这样的顾虑？)，在初始化的阶段又加入一个云升级自动检测的开关，最初在做初始化需求的时候并没有考虑会有多个步骤，认为只要账号初始化整个过程就完成了。结果多了一个步骤后，导致原来一个原子化的操作有了状态。一旦有了状态，就必然要考虑中间的异常情况，另外还涉及到多个库间的兼容性问题，变得非常难处理。\\n\\n经过一个星期的理解，突然意识到云升级自动检测、云接入并不是必须的，和账号初始化的重要性不同，云升级只是个可选项，并不影响设备的使用，因此就不应该和初始化使用同一个状态机。把云接入总结为开机向导的概念，和初始化分离开。所以协议最重视的，就是概念或定义一定要清晰，市场或需求包会统称为初始化，但在程序实施时必须要把不同的概念分开处理。\\n\\n考虑到云升级可能会没有网络(神设定啊！)又在NVR上增加一层代理设计。代理本身是个专门的领域也有专门的SOCK5协议，但由于时间关系显然不可能集成SOCK5的情况下，领导安排手动实现一个代理，且最好两端都能做到无感知。可是显然是不可能的，因为作为代理方，必须要知道下一跳去哪里，或者说请求发必须要知道代理的存在，这个下一跳的存在就不可能作到和直连完全等价，因此一定有一方需要做出区分。但是总有人妄图用一套接口实现两个流程，可惜当时没能把下一跳这个关键点亮出来，花了很多唇舌才说服众人保持方案不变。"}'));jctx.push(JSON.parse('{"id": "170707", "tag": "data", "text": "# 使用xapian和scws进行全文检索\\n\\n中文的全文检索最难的是分词，暂时只有scws结合xapian能跑起来。scws是个分词库，用在生成倒排索引阶段，建立索引和查询还是要利用xapian才能完成。\\n\\n生成索引是查询是两个相反的过程，输入一个或多个document的描述到index，生成B-tree或其它格式的数据库，输出一个关键字给search，search从索引数据库把document还原出来。\\n\\nxapian的索引和查询命令分别是simpleindex和simplesearch，索引生成的数据库是个目录，内部的文件比较多，simplesearch指定到数据库目录，再输入关键字，会按匹配程度从高到低排列出来。"}'));jctx.push(JSON.parse('{"id": "170728", "tag": "lang", "text": "# wren语言记录\\n\\n一门很小且很快的语言，EOS的作者BM对wren语言非常推崇，并整合到EOS中。\\n\\n下载源码后先到src目录下看看wren的代码结构。目录结构很简洁，核心代码都在vm目录，一万行出头，光有vm还不够，另外的module目录实现了基本的io/os/timer功能，代码才800多行，代码少的原因是依赖libuv。还有optional目录，不需要uv，支持了随机数和元的功能。以上3个是库，还有个单独的cli生成可执行文件。\\n\\n在windows下无法通过make自动编译成功，原因是Makefile的调用Python脚本，使用了Linux下的#!语法，在windows需要调用前显示地加上python字样。首先将vm下的代码生成libwren.so，这步比较顺利。但编译cli版本会失败，原因是需要下载uv，但用的机制是git和python的gyp机制，gyp的源码地址无法访问，好在cli程序的.o目标文件能编译出来，只要手动修改支持uv的头文件和库，就可以用了。\\n\\n前面提到编译wren需要python，原因是这样的。一个编译器如果纯用C写，工作量是很大的，如果在实现了语言分析的基础(或最小子集)后，直接用新的语言来定义扩展功能显然更方便，wren用的方法就是用wren语言写扩展，然后用python把这个扩展用文字替换方式变成C风格的字符串，通过C语言的include机制在虚拟机加载字符串，最后调用`wrenInterpret`接口加载到vm。所以换个角度想，作者直接用python把wren转换好再上传，就不需要客户端安装python了。但这种写完虚拟机，并用新语言进行扩展的作法值得学习。\\n\\n通过wren.h来一窥与C语言的交互，毕竟作为wren目的是提供一种快的可嵌入的纯粹的脚本引擎，vm部分没有集成任何外围库。在C语言宿主程序要用wren源码，只有上面提到过的`wrenInterpret`接口，它支持传入字符串，但不支持传入文件名或文件指针，原因是它没有IO库。载入脚本后最自然的想法就是传参并调用函数，传参用`wrenSetSlot***`函数族，Slot类似Lua中栈的索引，比较好理解。但是函数调用就很不一样了，共有3个步骤\\n\\n1. `WrenHandle* wrenMakeCallHandle(WrenVM* vm, const char* signature)` 构造一个函数签名对象\\n2. `wrenGetVariable(WrenVM* vm, const char* module, const char* name, int slot)` 加载包含method的变量，另外准备好参数\\n3. `WrenInterpretResult wrenCall(WrenVM* vm, WrenHandle* method)` 执行第一步构造得到的函数签名\\n\\nwren是class-based的语言，且为了支持大规模开发，支持module，因此作为最小执行粒度的函数，要经过module->class->method这样一条路才能找到。module一般对应文件，class包含两个特殊的函数定义allocate/finalize，构造是必须的，析构可选。allocate需要从wren中调用，它的原型是`typedef void (*WrenForeignMethodFn)(WrenVM* vm);`，没有返回值是因为wren的函数必须且只能返回一个值(默认返回null)，所以就省略了。finalize的原型是`typedef void (*WrenFinalizerFn)(void* data);`，没有vm参数是原因是它in the middle of GC。为了减少查找method的开销，甚至把函数签名放到C的空间，而不是vm上。另外函数签名也是wren特有的，目的都是为了提高执行速度。\\n\\nwrenInterpreter的执行流程是先加载`main`模块(指cli下运行，如果是host内执行可以是别的模块)。wren的编译把parser和compiler分成了两个类别，先把module和source保存在parser，再传入compiler输出一个ObjFn，再将这个Fn包装成Closure，最后把Closure包装成Fiber，到这一步才真正开始执行。"}'));jctx.push(JSON.parse('{"id": "170730", "tag": "think", "text": "# 思考、笔记与记忆\\n\\n学会正确地思考，不被欺骗(不被收智商税)，就一定要提升自己的认知能力。光说正确的思考方式比较抽象，就和读书的时候看教科书往往很难学到东西，只有做错了题目才能更进一步掌握，这是因为我们的思维对比较差异是很高效的。\\n\\n本文试图探讨如何将碎片时间的点滴，积累成完整的内容；如何更好的记忆和复习；如何将内容分类并形成体系。\\n\\n## 1. 记忆与间隔重复\\n\\n** 解决问题的公式=知识+逻辑 **\\n\\n知识需要记忆，如何才能达到高效的记忆？间隔重复SRS(Spaced Repetition Scheduler)，是对艾宾浩斯的更精确的量化方式。比较公认的是SuperMemo作者 Piotr Wozniak 提出的DSR(Dificulty-Stability-Retrievability)模型。Difficulty 难度，越大越难，Stability 稳定性指的是记忆的存储强度，越高，记忆遗忘得越慢。量化方式是回忆概率从 100% 下降到 90% 所需的天数，Retrievability 可提取性指的是记忆的检索强度，越低，记忆遗忘的概率越高。估计今天复习回忆成功的概率。\\n\\n这3个参数中S最难计算，也是核心。基于以下记忆规律来设计SRS的公式：\\n\\n* 记忆材料越难，记忆稳定性增长越慢\\n* 记忆稳定性越高，记忆稳定性增长越慢（又称为记忆稳定化衰减）\\n* 记忆可提取性越低，记忆稳定性增长越快（又称为记忆稳定化曲线）\\n\\n换成算法表述，对于一堆要复习的素材，就是以时间T为衰减项，根据难度D和稳定性S这两个系数值，更新召回率R。当R低于阈值后就进入复习序列，难度和稳定性影响召回率的下降速度。每次复习后的反馈会修正难度和稳定性（不是替换老的值，而是加权修正），进而影响召回率的更新速度。\\n\\n参考FSRS并简化后的计算公式如下\\n\\n* R = 1 / (pow(1+dT/S, -1) * D) # dT: 过去的天数\\n* D = D - d(Grade-1) - e(1-R) # Grade: 0-遗忘 1-一般 2-简单  d/e: 默认1\\n* S(成功) = S(1 + a * pow(D, -b) * pow(S, -c) * (exp(1-R)-1)) #\\n* S(失败) = pow(S, f * L) # L: 遗忘次数\\n\\n## 2.思考方式与思维误区\\n\\n传统的逻辑学分类是演绎和归纳两种。\\n\\n演绎的基本是我们所熟知的三段论，如果再细分的话，有直言三段论、假言三段论和析取三段论，这几种都是古典逻辑，现代逻辑的符号学或者更复杂的形式，我还不了解。演绎的推导是必然和确定的，但是这里存在一个弱点就是最初的出发点，要如何如证真？为了提炼出最初的前提，就会用到归纳法。\\n\\n归纳通常来自我们对外在世界的观察，并以类比的方式总结出一些结论，这也是经验主义者(如大卫休谟)所推崇的。归纳不像演绎，它是或然的(probable)。但不能因为这个就不否认归纳法，而是要用大量的事实来尽可能提高结论的适用性。但如果真的出现归纳前提不成立，也不见得是坏事，这时世界已经对你展现了另一面从未见识的地方，理应感到高兴才对。\\n\\n经常会有误区认为：做好了开发，就能做好架构。其实前者重在逻辑推理，算法构建，而后者更多是种权衡与取舍，甚至对人心的把握。做好了架构，不一定做得好技术白皮书，因为面向的是市场，又是完全不同的内容，对素材的要求也不一样。\\n\\n不同阶段不同人群，都是不一样的打法，可能其中有些粗看相同，但细看却差别很大。需要厘清概念分而解之。只有将思维误区必须和思考方式互为参照，才真正能提高。\\n\\n## 3. 实践与写作\\n\\n卡片笔记是一种思考方式，把它作为过程的外化和具象化。记录+链接的wiki未必是最好的载体。卢曼卡片有两个阶段，第1阶段是一种按目录组织的知识体系，第2阶段会给卡片标上类似3125分类，每位数字代表一个领域，逐级细化。\\n\\n还有一种是链接，尤其是双链。因为分类天然是深度优先，只有用链接重新跳出来，才会触发更多的灵感。双向链接有4种子分类，主题索引，前后逻辑，文本内容，卡片编码链接。主题用来确定大的类目，前后逻辑表示卡片的引用关系，文本内容则是更具体的内容详情展开，卡片编码似乎也是分类。链接的同时也是一个思考的过程。\\n\\n写作之难，在于把网状的思考，做成树状的结构，用线性的语言表达出来。三种结构，时序、逻辑、情绪。挑选一种作为推动故事发展的内核。文章运用修辞，如李笑来就是比喻和排比。手法上长短镜头结合。\\n\\n## 4.目标与积累 up at 23年1月\\n\\n我相信人都是有路径依赖，哪怕转型，过去也是财富。盯紧目标，有近的和远的，阶段性有几个具体的专项去做，更难的是要不时地去确认和修正远景目标。正因为远景定得宏大，所以走偏或发现不对十分正常，但又因为不是日常内容，如果不周期性核对，就会忘记导致忙碌一整年却没有沉淀。\\n\\n做的过程经常笔记，但更要时时地对内容做分类、合并，分类是为了建立知识体系，合并是因为新的总会修正旧的，而这个过程也是进一步夯实技能。\\n\\n分类会存在模糊或错误，曾经的分类，随着能力圈的扩大，会变成子分类，说明是好事。"}'));jctx.push(JSON.parse('{"id": "170802", "tag": "think", "text": "# 英语的谓语、表语和动词\\n\\n英语五大基本句型和人类历史发展史是完全一样的\\n\\n* 主谓就是一个男人和一个女人；\\n* 主谓宾就是一个男人和一个女人生个孩子；\\n* 一个孩子太寂寞再生一个就是主谓双宾；\\n* 孩子长大找自己的另一半那就是主谓宾宾补；\\n* 男人没一个好东西总是要变心的，于是找了一个新的媳妇叫做系，生了一个新的孩子叫做表；\\n\\n所以宾语和表语是同父异母的兄弟：\\n\\n* 主谓宾\\n* 主系表\\n\\n如果从词法角度来看，主谓是不及物动词，主谓宾是及物动词，而主系表则是系动词。\\n这三者在词法上都归在Verb大类下，但细分下来，还是会成为不同的句法。\\n还有个巧合，谓语predicate和表语predicative竟然如此得相像。表语补足语则是\\npredicative complement。\\n\\n谓语和动词并不等价，动词共有4类\\n\\n* 实义动词：run/walk有真实动作的词\\n* 系动词：is/am/are，作为联系词，不单独使用后面一定带词\\n* 情态动词：can/should/have to，不能单独使用，只表示态度\\n* 助动词：do/be/have，不单独使用，使整句话的语气由陈述句变为疑问/强调等"}'));jctx.push(JSON.parse('{"id": "170806", "tag": "protocol", "text": "# 区块链的运行机制\\n\\n区域链本质上是一种由交易驱动的，由共识确认并跃迁的状态机。区块链由区块以单向链表方式连接，并利用哈希的特性保证了数据的不可篡改性。\\n\\n交易可以是BTC的转账支付，也可以是ETH的智能合约。每个人都可以发起交易(相当于向区块链提交一个合并请求)，这笔交易会保存在矿工节点的内存中(普通节点只传播，但不保存)，当这笔交易没有记入主链前，就不具备合法性。要合入主链需要矿工的确认，由于每个块的容量有限，矿工只会选择手续费高的一些交易合入区块。如果块容量上限太小，或出现爆发性的交易数量，就一定会有交易驻留在矿工的内存(常说的网络堵塞了)，才有BTC的扩容争议。一旦交易被矿工commit，且最终被成功地seal(以上两个词取自ETH的日志)。这条交易就具备了永久的合法性(严格地说还要再加上若干次确认，否则有可能出现在分支上，最终还是被更长的链超越而视作无效)。\\n\\n众多矿工同时竞争向主链的提交，依赖共识算法来决定哪个矿工取得这一轮的权利。方式有很多，如PoW或PoS等。PoW算法达成共识非常消耗成本，因此对完成条件的个体会有激励，这个激励的形式就是增发的数字货币。\\n\\nBitcoin交易有Coinbase、P2PKH、P2SH几种（隔离见证后，又增加了P2WPKH和P2WSH）。\\n早期的交易（高度62061以下）的交易数都是1，这些交易都是coinbase交易，输入没有签名，长度也比较短，典型长度0.215K，sequence通常是0xFFFFFFFF。P2PKH的`tx_in`脚本比较长了，包含签名和公钥，71(签名)\\\\+65(公钥)\\\\+1\\\\+1=138(两个都分别是长度占位)。但是从密码学角度看，有了签名(即R和S)，只要再配上个`rec_id`(范围0-3)是可以反推出公钥的，如果采用这种方式能极大地减少输入脚本长度。\\nP2PKH交易的`tx_out`，脚本长度25(用1字节表示)，脚本中5字节是操作符，20字节是HASH160的结果，加上8字节的金额总共是34Bytes。\\n\\n以太坊来目前也是PoW共识机制，它的挖矿算法称为Ethash，这是个比较高层的概念，每个Ethash持有GenericFarm，这个Farm下再持有多个miner，从这个结构看，应该是受了farm和miner的关系就像矿池分解任务给节点的关系。最终的验证通过farm来完成。验证的术语是seal，cppeth自带的seal只有CPU，也许要用上GPU挖矿要用另外的程序吧。seal的封印对象是BlockHead，另外BlockChain对象的作用还没有明白。\\n\\n以太坊Trie的设计，对轻客户端友好，每个区块头的三个指针代表了三个核心的树：状态、交易、收据。\\n\\n交易树比较简单，收据是一个RLP编码的数据结构，除了索引变得更加简单，logbloom的使用也让轻客户端使用起来非常方便。\\n\\n区块头的设计和轻客户端是密切相关的。绝大多数节点并不需要完全同步，但要求访问数据的便利性。\\n\\n区块内的主要数据结构是MPT，这里面稀疏区域用KV节点。在状态和账户的树里，diverge nodes 深度为64，使用sha3(k)作为key，非常难以DOS攻击。\\n\\n目前整个状态的访问查询可以变得更快，全节点的全同步也可以变得很快。因为紫皮书带来了新的方向，压缩算法或是uncle区块实现等，紫皮书引入了POS机制，更友好的轻客户端同步实现，计分和测了实现， 分片以及跨分片通信等。\\n\\n作为公开链的区块链，必然需要密码学为依托，比特币选用了非对称算法中的椭圆曲线SECP256K1，经历了时间的考验被证明是安全可靠的，以太坊和BitShares也沿用了相同的椭圆曲线。\\n\\n以上是相同的部分，当然也有些不同的部分，不过这些不同只是在使用链的方式不同，不影响区块链的特性。\\n\\nBitcoin中只有一笔笔的交易，这些交易会存入一个地址，但并没有帐号。可以想象成有很多张支票，每张支票都有一个谜题，谁能解开这个谜题谁就能使用这张支票，如果一个人说他有很多比特币，或者他有一张大额支票，或者他有一堆小额支票。而以太和Bitshares是有帐号概念的。又比如链的生长速度差别就更大了，Bitcoin基本固定10分钟，以太则15秒，但是因为依赖PoW，并不是严格遵循这个周期，而Bitshares用的DPoS机制，能严格保证3秒出一个块(其实是1～30秒范围内可设置，取决于committee的投票结果)。\\n\\n按老董的讲解，至少符合三个条件的区块链的项目才有可能是好项目：\\n\\n1. 必须是在线上建立信任，并基于此信任生发出的项目\\n2. 逻辑必须是清晰明确且简单的，一方面区块链的计算能力偏弱，另外从技术上写出安全的智能合约极难，为避免风险，也应用用简单的方式\\n3. 使用区域链所带来的收益要高于成本(任何商业项目都适用)"}'));jctx.push(JSON.parse('{"id": "170808", "tag": "lang", "text": "# flex和bison的理解\\n\\n这两个工具是编译理论都会介绍的经典工具，分别用于词法和语法分析。词法比较简单，虽然有NFA和DFA的区分，但总的来说就是把原子的字符按规则合并成符号，但语法分析就有LL和LR两种差异很大的流派。从词法分析向LL演进，是比较自然的方式，但词法进到LR，中间存在一道鸿沟，这时我觉得更好的做法是先学习LR的语法分析，理解LR的思维，自然就明白为什么、何时需要词法，以及flex和bison两个工具的协作模式。\\n\\n为什么Bison这种通过工具生成解析代码的方式被称为LR分析器，而手写解析器一般都是LL分析法呢？这两种方式都是BNF的解析方式，而BNF属于产生式文法，指先定义文章包含段落，段落包含句子，句子再包含单词，着眼点是从最顶层的结构，逐步扩展细化，最终推演到单词环节结束的过程。\\n\\n不管是LL还是LR，解析词法符号都是从左向右，两者都是L，没有不同。如果将符号形成一个句子，就有了分歧。手写分析器是从左向右一旦符号成为一个合法句子，解析结束，优先从最左侧进行推导，所以称LL法。而Bison的解析思路，即使已经达到推演条件，还会继续读进符号，只有在读进的符号不能推演，才会结束，优先从最右侧进行推导，所以Bison的作法称为LR。看Bison的规则，人脑很难自然地联想出从文章细化到句子乃至单词是怎么结合上的，因此LR方式通常是用机器生成代码。\\n\\nLL的术语是First/Follow集，而LR则称为shift/reduce。读入符号(shift)再生成句子(reduce)，这和书写yacc的规则是逆过程，不过不用担心，工具会把正确地完成这个逆过程。既然要先shift，就一定会有栈保存符号，Bison在语法分析前，先创建200长度的数组作为栈。每条规则的执行都会改变栈的深度。默认规则动作$$=$1就是在栈保存值，有这个值后面的解析才能找回值。\\n\\n生成词法解析代码用flex一个二进制文件就够了，而生成语法解析代码不能只有bison二进制程序，必须配套多个m4脚本，这些文件称为skeleton（比如yacc.c或lalr.java等代码模板）和XSLT的输出模板目录，保存在/usr/share/bison。而且不同语言用到的文件也不一样。比如要实现C语言输出，至少要7个文件。\\n\\n## flex\\n\\n调用flex不需要特别的选项，windows平台可以加一个`--nounistd`防止编译错误。\\n\\nlex的外部输入源有文件和字符串两种形式，但内部归约到一个统一的宏`YY_CURRENT_BUFFER`，这个buffer在lex内部以栈的形式保存，可以存在多个，也可以push/pop。\\n\\nbuffer可以从`extern FILE* yyin;`创建，默认读出16K的内容来生成buffer，也可以是字符串，字符串可以包含0。使用文件方式比较简单，在yylex函数中，如果判定外部没有初始化yyin，则将它赋初值为stdin。\\n因此在函数入口需要申明`extern FILE* yyin;`并从希望读取的文件来给yyin赋值。\\n如果不使用yyin，也可以用字符串，方法是用`yy_scan_string(C风格字符串)`或`yy_scan_bytes(二进制串)`指定字符串，再将返回的`YY_BUFFER_STATE`指针传给`yy_switch_to_buffer`，这样yylex()的输入就自动定向到字符串了。当然记得最后不要忘记调用`yy_delete_buffer`把指针给释放了。\\n\\nlex的第一部分，要写上%option noyywrap(对版本有要求)，因为lex产生的代码会用到yywrap()这个函数，也可以把这个函数直接定义成`#define yywrap() 1`，上述这句也就是lex帮你定义这个宏。如果%option没用，变通方式直接定义yywrap()函数并返回1也可以(这也是flex库默认提供的实现，因为这个库太没用，基本都是手写这个函数)。\\nlex可以更改默认的变量名前缀，不用yy。如果把lex和其它语法分析器配合使用，会有效果。另外lex支持生成可重入代码，但在和bison配合时比较别扭，关于可重入的说明，在lex和lemon的文章中介绍。\\n\\n### 踩坑记\\n\\nflex的action部分如果要输出`[[`或`]]`，比须写成`\\"[\\"\\"[\\"`，否则不仅会被吞掉还会警告。示例将py的长注释转为lua格式，方括号要转义\\n\\n```\\n\\\\\\"\\\\\\"\\\\\\"|\\\\\'\\\\\'\\\\\' { EXATR(v); if(0==v->st_lc){ TRANS(\\"--[\\"\\"[\\"); v->st_lc=1;\\n```\\n\\n## bison\\n\\nbison处理文件最好加上-d和-t -r all选项，-d输出头文件，用于给flex指明终结符的定义，后面会详述。-t -r all输出详细报告，报告的内容分4部分\\n\\n1. Grammer：从0开始编号，0也是终结态$accept，自动生成。其它都是用户自定义规则\\n2. Terminal：每个条目都是一个符号且定义了int值，对应lex返回的枚举或该字符的ASCII值，有两个特殊终结符，$end(0，代表YYEOF)和error(256)\\n3. Nonterminal：对应rule。就包括$accept，还会详细标明每条规则出现在哪条grammar的左或右，左右是语法分析很重要的特性\\n4. 最后是各种state,从0开始编号，会显示具体的shift或reduce动作。如果有冲突，会提示哪几个state存在歧义，大多数state会带一个default的reduce规则，当然也有不存在default的。如果default对应的是accept，这个state就是最终态了\\n\\n除了-t -r all选项，还可以通过-g和-x选项输出automaton的graph和xml report，报告类似分为grammar和automaton两部分\\n\\n* Grammar是各条BNF规则的描述\\n* 接着是Terminal和Nonterminal定义,Nonterminal的第一条同样是隐式的$accept\\n* automaton是多个state的合集,描述的是各个state之间的转换关系,每个state下面有itemset、action、solved-conflicts\\n* action包括了transition（shift和goto状态）和reduction（和rule关联）\\n\\n通过yacc的规则，也生成了解析的C语言文件，但是数据(终结符，用%token定义的符号)需要从lex获取。前面提到bison -d会生成头文件，这个头文件就是给lex包含的，lex自己不需要生成头文件（因为就一个int yylex()函数原型）。除去注释，yacc生成的头文件包含4条内容\\n\\n1. 一个enum的枚举声明，对应yylex()的返回符号类型\\n2. 声明YYSTYPE类型，int或union，这里的S指semantic的意思\\n3. 声明一个YYSTYPE类型的变量，yylval\\n4. 声明int yyparse()函数原型(低版本bison不会生成)\\n\\n除了第4条比较显而易见，说说前3条必须存在的原因\\n\\n先说enum枚举。lex在识别词法后，yylex()的返回值要把词的类型告知yacc，所以需要yacc在首部申明`%token ***`，token对应终结符，正好对应lex，还有一种%type，对应的是非终结符，用在yacc内部。\\n这个头文件就包含了%token声明的枚举定义。%token/%type不是C语句，不需要;结尾，当然带了也没关系。\\n\\nyacc能支持递归，因此写规则时会出现循环引用和空规则。以下是最简化的lisp语法解析\\n\\n```\\nsexp: /*empty-rule*/ {}\\n  |   sexp one_exp {}\\n\\none_exp: \'(\' mul_em \')\' {}\\n  |   T_VARNAME {}\\n\\nmul_em: one_exp {}\\n  |  mul_em one_exp {}\\n```\\n\\n当规则引用自身时，**自己一定出现在左边**，否则会无限循环，又因为是产生式规则，右边的式子代表最新reduce的结果。规则互相引用时，也会有些微小的差别，不然又会引起循环。\\n\\n## 对外函数接口\\n\\nlex和yacc各自对外的惟一函数分别是int yylex()和int yyparse()，两个函数都无入参且返回int。虽然是自动生成的代码，但抛开各种表的数值不谈，流程还是能看明白的。\\n\\nyylex()看似没有入参但其实是通过外部变量作为输入源，一方面有历史原因，而且既要接受文件句柄，又要接收字符串，一种类型较难表达，只能退而求其次用一种并不巧妙的方式。出参是识别到的终结符类型枚举（文件结束时返回0），枚举值由bison定义，标识符枚举从258开始（跳过单个字符的范围），需要int来表示。\\n\\nyyparse()无参但有输入，输入就来自于其内部调用的yylex()。yyparse()返回的int表示错误码，共有0/1/2三种值，0代表正确，1表示异常，2表示内存耗尽（比如shift导致栈过深）。\\n\\n## 交互与变量传递\\n\\nyyparse()调用yylex()，涉及两种类型的数据传递\\n\\n1. 这次的token类型是什么？\\n2. 这次的token要表达什么含义？\\n\\n第1个简单，通过yylex()返回的int来表示，第2个就相对复杂，让我们进入lex看。lex的上下文，当前识别出的原始字符串，保存在yytext里，类型是`char*`，长度保存在yyleng，它和strlen(yytext)是一样的。但是yytext是yylex函数内的变量，yyparse()不能使用，正确的处理方式：**将yytext处理并保存到yylval变量**。\\n\\nyylval是由bison定义的全局变量，它是yy lookahead value的简写，代表了一次识别出的终结符的具体值，调用yylex()后，yylval就可能有了数据，在yyparse()内部将yylval依次保存到yyvsa数组（通过yyvsp指针），类型和yylval一样也是YYSTYPE。在bison的上下文，用$1、$2语法来引用yyvsp数组中的对应位置，从而实现了变量传递。YYSTYPE默认是int类型，不是玩具程序的话，肯定需要更复杂类型，就用到yacc的%union{}语法来替换int类型。YYSTYPE（就是刚才定义的union）包含在头文件中，lex才能看到union的声明，识别到符号后，进而将yytext转换成相应的类型。\\n\\nyyparse()是双栈式推进，yyssa表示state stack，yyvsa表示value stack，状态栈记录当前shift或reduce的阶段，而语法分析并不是最终目的，还需要输出分析结果，因此每一步的中间值也要记录下来，所以就有了值栈。两个栈的初始长度都是200，如果栈满了之后可以通过自定义的栈生长函数扩容，但最大不要超过10000。yyssa的当前状态经过yypact和yytable的转换，可以计算出要从yyvsa上POP多少个元素，根据.y文件的定义对yyvsa数组进行索引定位。\\n\\n## 实战flex和bison注意事项\\n\\n日常处理协议要做太多的转换工作，想试着能否用类似google的proto描述方式来自动化生成。决定用flex和bison再配合一个script语言如lua或js来做。期间走了不少弯路。\\n\\n语法解析的bison会强制要求实现`yyerror(char*)`函数，但其实回调的信息很简单，基本就是syntax error没有指向性，这是LALR的固有缺陷，有两个改善的办法。在yyparse()调用之前打开调试开关\\n\\n```\\nextern int yydebug;\\nyydebug = 1;\\n```\\n\\n能打印出每个符号读入，shift/reduce的步骤。\\n\\n如果嫌错误信息太长，可以语法分析错误时增加行号显示，要做两件事\\n\\n1. 让flex对行号自增，加这条规则 `\\\\n {yylineno++;}`\\n2. 让bison在yyerror中显示行号\\n\\n```\\nextern int yylineno;\\nvoid yyerror(const char* str){\\n  printf(\\"\\\\nBison error at line:%d, %s\\\\n\\",yylineno, str);\\n}\\n```\\n\\n还有个小的细节要注意，打印到stderr而不是用printf输出到stdout，在后期会体现出便利性。\\n\\nflex解析后的token的内容保存在yytext，同时yyleng记录了有效长度。通常这个值要传递给bison，并在语法规则匹配后再利用这些值做逻辑，但是最好不要在bison直接用yytext，因为等到触发bison的规则时，yytext/yyleng表示的是最后一个token，前几个token的值无法直接用yytext得到。通常作法是把词法匹配后的字符串dup一份，这就要求bison在匹配后还要做free的动作，不仔细配对很容易出错，我的办法比较讨巧，既然要dup字符串涉及内存管理，不如直接把这时的yytext传给script engine，利用脚本的垃圾收集机制管理内存。即脚本在flex阶段收集素材，而bison阶段处理素材。\\n\\nbison的规则允许直接用单字符的终结符，要用上这个特性，flex规则的末尾要写上`. {return yytext[0];}`，如果不写，yylex()不会返回这个单字符，而使用flex默认的ECHO规则将这个单字打印到console上，并不会传递给bison。\\n\\n脚本引擎和分析代码之间的交互有两个接口，分别是在flex调用的push(token, str)和bison调用的reach(rule)。语言先用lua，最终还是决定换成更大众的JavaScript，一是为了自己熟悉，另外JS的受众更多，维护人员会更好交接。关于JS的引擎单开一篇写。\\n"}'));jctx.push(JSON.parse('{"id": "170814", "tag": "tool", "text": "# 重新认识Makefile\\n\\n不要片面地把Makefile理解成程序编译工具，更广义地说是个基于文件依赖关系的管理工具。可以通过make制定规则、调用shell命令，也可以在Makefile中定义变量、条件和函数调用实现复杂的功能。Makefile包含五种块：显式规则、隐式规则、变量定义、指令和注释。\\n\\n## 显式或隐式规则rule\\n\\n```\\nTARGET ... : PREREQUISITES ...\\n        RECIPE1\\n        RECIPE2\\n```\\n\\nTARGET可以表示一个文件名或动作名(Phony Target)，PREREQUISITES是文件列表，并作为TARGET的输入。隐式规则的区别是有且只有一个`%`，用于匹配文件名，通常是文件类型的替换。\\n\\n先说TARGET，因为含有两个意思，如果指定的目标名恰好有个同名文件，文件名会优先于动作名。常见的all/clean规则一般表示的是动作名，如果Makefile所在的目录中恰好有文件名是all，那你就等着看all is update to date吧。要避免这种错误，就必须显式地声明Phony Target，告诉make不要管那个同名文件，使用的语法是`.Phony : all clean`。\\n\\n之所以有时候不指定phony，执行make clean也能成功，是因为make按文件名先去找clean文件，找不到才去执行该规则的动作，而该动作通常无论如何都不会生成一个clean文件，因此不写phony也没有问题。\\n\\n但以上说的是clean这种没有依赖的目标，如果有依赖，情况又不一样了：\\n\\n假设目录中有个clean文件，按说执行make clean是不会有动作的。但当我们把目标写成 `clean : *.o`，执行clean目标需要先找到.o文件，这时make就不理会有没有clean文件，而是去查找.o的隐式规则，找到后去生成.o文件，如果clean的recipe又恰好是删除操作，又会把关联的.o再删除一遍，很无厘头吧。做这个测试也只是为了理解make的运行规则。\\n\\n其实理顺了make的规则也就那么几点，无非就是显式/隐式规则的目标查找和一些内建函数的用法以及一些奇怪的变量名，好在我看来常用的特殊变量就三个，也有点规律。像$^就是显示规则中:后面依赖项，另外$<和$@则是隐式规则的源和目标，<表示源，@表示目标，基本上勉强能算上字面意思吧。\\n\\n## 变量与使用\\n\\n原始的Makefile的变量定义比较简单，只有`=`一种定义，`=`在使用时会递归地查找右边变量的定义，有时会引起不希望的副作用，GNU make引入了`:=`避免递归问题。另外还定义`?=`和`+=`两种赋值符，分别表示不存在才赋值和追加赋值。\\n\\n变量除了用`=`族显示定义，也会继承自同名的环境变量。可以在执行make前先export环境变量实现条件编译，以下示例实现了如果VENDOR变量为1，就额外链接一些库。如果环境变量不是想要的，但又不能改，可以用make -e遮蔽并重新定义。\\n\\n```\\nifeq ($(VENDOR), 1)\\n  EXTLIB = -llpeg -llsqlite3\\nelse\\n  EXTLIB =\\nendif\\n```\\n\\n自带很多函数实现很方便的操作。比如要找到所有含有jpg图片的目录，就可以这样：\\n\\n```\\nSUBDIRS = $(sort $(dir $(wildcard */*.jpg */*.jpeg)))\\nprint:\\n        @echo $(SUBDIRS)\\n```\\n\\n函数调用语句和变量引用是类似的，先用wildcard尝试通配jpg或jpeg的文件名，剩下的dir和sort是因为不关心图片内容，只要文件夹名。sort带去重功能，可有可无。\\n\\n命令前带@表示不打印命令本身，还有个更有用的前缀-，表示即使这行命令出错，也继续执行。比如-include，如果找不到要包含的文件，不会停下来，make会提示Error 1(ignored)且继续运行。直到遇到TARGET无法达成才报错，并显示`***`，也可以显示调用$(error your prompot)来提示错误。-可能是GNU扩展，如果要通用化，最好用sinclude代替。\\n\\n## automake\\n\\n1994年9月第一次提交，依赖于1992年开发的autoconf和更基础的m4。automake和autoconf的版本号演进各自独立，似乎不是一个团队开发。其做法从最初就没有大变化，从`*.am`文件生成`*.in`文件，只是规模从最初的500行代码发展到如今几万行规模。"}'));jctx.push(JSON.parse('{"id": "170816", "tag": "security", "text": "# RSA/DSA/EC三种算法记录\\n\\n从Openssl的命令行操作来一探这三种非对称加密的端倪。三者的操作命令并不对称，支持的列表如下\\n\\n* RSA：genrsa/rsa/rsautl\\n* DSA：dsaparam/gendsa/dsa\\n* EC：ecparam/ec\\n\\n## RSA说明\\n\\n生成私钥的命令是`openssl genrsa -out xxx.pem 2048`生成2048的私钥，但文件并不是2048bit，因为RSA私钥包含的内容很多，要看私钥文件的具体内容，可以用`openssl rsa -noout text xxx.pem`显示，从内容可以看出，modulus和privateExponent是2048bit，publicExponent是0x10001，其它的prime1/prime2等都是指定位长的一半，即1024bit。同理如果genrsa指定的长度是1024，modulus和privateExponent是1024bit，prime1/prime2等都是512bit。modulus和publicExponent共同构成了公钥文件的内容。RSA的加密会用到padding算法，解密必须指定相同的padding才能成功，因此其使用上的复杂度要高于椭圆曲线。\\n\\n使用openssl rsautl系列命令可以加解密。公钥加密私钥解密用`-encrypt -decrypt`，私钥加密公钥解密则是`-sign -verify`这对命令，但是libressl版的openssl支持用私钥调用-encrypt，却无法解密，不知道算不算bug。\\n\\n进行加密时为防止同样的明文得到的密文一样，都会填充数据，1.5版本填充方式适用于加密和签名，而OAEP只适用于加密，PSS只适用于签名。\\n\\nRSA的数字签名应用非常广泛，被固化到U盘作为签名私钥，有种更新的算法RSA-FDH(Full Domain Hash)。PDF的1.5版本只支持2048位的RSA签名。\\n\\n## DSA说明\\n\\nDSA生成公私钥比RSA要多一个步骤，先用dsaparam生成参数文件，这份参数文件可以被多个用户共用，生成每个用户各自的公私钥对。决定签名结果的因素有HASH算法和KEY的长度（推荐1024以上），生成参数命令`openssl dsaparam -out dsaprm.pem 1024`。可以看到生成文件就包含P/Q/G三个大数。P和Q都是素数，且P-1必须是Q的整数倍。\\n\\n用dsaparam指令的`-genkey`也能直接生成公私钥，独立的genkey指令则可以对生成的公私钥文件进行AES/Camellia加密。这样生成的文件内既有公钥又有私钥，显然不适合分发，需要把公钥提取出来，命令`openssl dsa -in dsakey.pem -out dsapub.pem -pubout`，坑爹的是`-pubout`参数在dsa的帮助命令里居然没有，但从rsa命令的帮助能看到。。。\\n\\n有了公私钥文件，接下来可以选择一个文件进行签名和验证。Openssl并没有直接提供类似dsautl命令验证签名，需要用dgst指令完成。签名命令`openssl dgst -sha1 -sign dsakey.pem -out sign.dat yourfile`。其中sha1可以换成任意想要的摘要算法。比如选用了1024bit的私钥，生成的sign.dat是46bytes，DER编码的二进制文件，解码DER的话能得到两个大数R和S（位数一样），这一点和RSA的签名不同，两个大数的验证算法和RSA不同，这也是为什么DSA不能用来做加密的原因。验证签名命令`openssl dgst -verify dsapub.pem -sha1 -signature sign.dat yourfile`，通过会显示Verified OK，反之显示Verified Failure。\\n\\nDSA的密钥强度标准和RSA是一样的，都推荐2048bit。\\n\\n## EC椭圆曲线\\n\\n共有三种用法\\n\\n1. Elliptic Curve DSA，用椭圆曲线做DSA，数字签名。\\n2. ECDH，用椭圆曲线做密钥交换。\\n3. ECIES，椭圆曲线的公钥加密。\\n\\nOpenssl的命令行工具支持前两种，并内建若干条曲线，比如下载的libressl自带了90条曲线，选好曲线的名字如secp256k1，则参数值（prime/A/B/Generator/Order/Cofactor）就确定了。曲线有prime域和binary域两种。域会有位宽，通过openssl的ecparam生成的参数长度和位宽正相关，但并不严格地成线性关系。\\n\\n使用椭圆曲线和DSA类似，也必须要两个步骤。先确定一条曲线参数，基于这条曲线参数生成公私钥。但Openssl的命令行没有genec指令，都是ecparam指令。\\n\\n1. 首先用`openssl ecparam -name secp256k1 -out secp256k1.pem`先生成一条曲线参数，生成的参数文件内容只有8字节（Base64后12字节）。如果直接用`openssl ecparam -text -noout`只能看到ASN1 OID: secp256k1描述，需要再加上`-param_enc explicit`参数，就能看到域类型和曲线的A/B值等很多值。前面提到了因为曲线描述一旦确定，则所有参数就确定了，所以这些参数我理解，并不是保存在参数文件，而是硬编码在Openssl内。所以8字节的参数文件看上去就有很多输出了。但是这样会有兼容性问题，因为具体的参数硬编码在Openssl程序内，那么高版本程序新加入的曲线，在低版本就会出现无法解析的错误。要避免这种情况，可以通过生成时加上`-param_enc explicit`，这样生成的曲线文件就会大很多，也完整很多。\\n\\n2. 有了参数文件，就可以生成私钥了，命令`openssl ecparam -genkey -in secp256k1.pem -out key256k1.pem`。同样的，要避免高版本和低版本的配套问题，加入`-param_enc explicit`参数就可以了。其实这步和上一步合并也没有问题。通过私钥文件生成公钥的命令是`openssl ec -pubout`，和DSA一样，`-pubout`在帮助中看不到。\\n\\n使用椭圆曲线进行签名和验证和DSA类似（但不确定是否就是ECDSA），签名`openssl dgst -sha1 -sign eckey.pem -out ecsign.dat yourfile`，验证`openssl dgst -sha1 -verify ecpub.pem -signature ecsign.dat yourfile`。选用secp256k1曲线的签名结果是71字节以DER编码的文件。简单说明一下：\\n\\n首字节是0x30，第二个字节是0x45，十进制69表示该字节之后的文件长度，69\\\\+2=71能够和文件总长度对上。第三个字节固定是0x02。第四字节0x21表示R的长度，偏移33字节后又是0x02，后一字节0x20表示S的长度，到此文件结束。不过没搞明白的是通过程序看到的R和S长度一样，为什么保存到文件R和S长度就不一样了。\\n\\n最后说下椭圆曲线的操作是点在操作，计算用加法，计算结果判断是否无限或在曲线上。\\n\\n椭圆曲线的操作体现在C函数的接口，则是`EC_KEY`和`EC_GROUP`这两个重要的概念。一条选定参数的曲线就是一个group，用`EC_GROUP_new_by_curve_name`获取一个group，从头文件找枚举代表一种算法。\\n用`EC_KEY_new`创建新的key，这样的key虽然名字叫key但只是个空的容器，必须先和group关联。当然也可以用`EC_KEY_new_by_curve_name`一步生成绑定好的key。\\n\\nkey和group有了关联之后，才能调用`EC_KEY_generate_key`生成公私钥。私钥是个很大的素数，在OpenSSL表现为BIGNUM类型，可以用`BN_print`看结果。公钥则是点，是`EC_POINT`类型，这个类型不开放，所以不能直接打印，如果看源码，POINT内部包含了X和Y两个BIGNUM（其实还有个Z也是BIGNUM，但不确定有什么用）。比如secp256k1的私钥是256bit的数(并不要求是素数)，公钥是形如(X, Y)的点对，计算方式是\\n>Q(x,y) = K * G(x,y)\\n\\nK就是256bit的大数，G随着椭圆曲线的确定是惟一确定的，对应ecparam的G参数。X和Y也都是256bit，所以公钥是512bit。比特币看不出来，但ETC的钱包采用的是HEX编码，容易看出pubKey的长度是privKey的两倍。\\n\\n虽然公钥保存成512bit没有错，但其实忽略了椭圆曲线一个重要特性**对称性**。来看椭圆曲线的公式：\\n>Y^2 = X^3 + aX + b\\n\\n只要知道公钥点的X，公钥点的Y就能通过开平方计算出来，只要再配合正负号，就可以知道完整的公钥点了。这个发现就是**压缩公钥格式**的来历，严格地说并不是压缩，只是去掉了一半冗余信息。甚至有人开玩笑地说中本聪不是密码学出身，否则怎么会一开始想不到要使用压缩公钥这种形式。\\n\\n私钥生成后就可以做签名和验证了。不同算法sign得出结果的长度从`ECDSA_size`获取，从48到153字节不一而足。ECDSA签名的结果同样是两个大数R和S，且位数一样。R和S的长度取决于算法，范围跨越20到71，因此把这个范围乘以2，再转成DER编码，就和前面提到的48~153能关联起来了。\\n\\n用椭圆曲线做密钥交换，即ECDH也很方便，BitShares的加密通信就是ECDH\\\\+AES，ECDH的流程比较简单，A和B各自持有一对椭圆曲线的公私钥，交换公钥后，再用自己的私钥乘对方的公钥，得到的结果就可以用来做AES密钥。比DH的流程要容易理解。"}'));jctx.push(JSON.parse('{"id": "170818", "tag": "lang", "text": "# 如何在struct里追加指针\\n\\n这在其它公司或开源项目没有什么用，但至少在我目前的工作上还是有一定价值的。想象一下不同的部门共用同一份头文件，头文件中复杂的类型只能用结构体。如果要在结构体增加任何元素，都要保证结构体长度不变。对char或是int32问题不大，指针在不同平台长度是不一样的，如果一个部门用32位编译，增加指针，试问要怎么减长度才能保证在64位平台长度不变？曾经考虑过32位平台加宏，在指针后面带一个int32并用宏控制，但是想找到各种平台都能识别的宏很困难。\\n\\n先说思路，既然要保证32位和64位相等，肯定是向上取长度，即让指针占据8字节，有三种做法：\\n\\n1. 把指针和int64用union包裹起来放到结构体里，如下\\n<pre>\\n    struct {\\n        int elem1;\\n        int elem2;\\n        union {\\n            char* p;\\n            int64_t placeholder;\\n        }u;\\n    };\\n</pre>\\n\\n这样做不好的地方在于取指针p必须要多一重u，使用者会感觉不方便。\\n\\n2. 既然用union看起来别扭用着也不方便，让struct强制以8字节对齐，然后把指针放在8字节位置，同时指针后面的元素必须是int64/double，这样32位系统下，指针后面会有4字节的隐藏字节，但也不能用，64位就是按8字节对齐的。缺点是指针后面的元素必须是8字节，有时会很浪费。如下\\n<pre>\\n    struct {\\n        int elem1;\\n        int elem2;\\n        char* p;      /// 32位系统，p后面有4字节空间，但不要使用\\n        int64_t ensureAlignBy8;\\n    };\\n</pre>\\n\\n3. 定义一个占位宏，根据系统特性将宏展开成int32_t或是空语句，也是最终我决定采用的方式，宏类似这样\\n<pre>\\n#ifdef (_WIN64)\\n#define POINTER_ALIGN8(n)\\n#elif (_WIN32)\\n#define POINTER_ALIGN8(n) int32_t unused##n;\\n</pre>\\n\\n这里有个小坑，宏的展开必须包含`;`，我最初的实现是宏的调用尾部加分号，过了几个月有人向我反馈编译不过。原因是VC在编译C语言模式(即.c后缀)时，要求结构体的定义中不能出现一行单独的`;`，但是在执行块中可以这么用。VC编译`C++`模式或GCC都没有这个限制。当我遇到这个错误时，曾尝试通过将64位下的宏扩展为一个空结构体，VC会报C标准不允许结构体没有成员。"}'));jctx.push(JSON.parse('{"id": "170820", "tag": "net", "text": "# libuv代码走读\\n\\n虽然并不提供Makefile，但通过CMake的脚本很容易就把要编译的文件找到，编译宏只有两个。\\n\\nuv的核心是loop，加上两个父级的抽象类型，handle和request。uv支持的18种句柄都是`uv_handle_t`或其子类。句柄派生出3个层级，如果只关心网络的读写，主要看`uv_stream_t`及衍生出的tcp，pipe,tty。从tcp的定义能很清晰地看出3层关系。\\n```\\nstruct uv_tcp_s {\\n  UV_HANDLE_FIELDS\\n  UV_STREAM_FIELDS\\n  UV_TCP_PRIVATE_FIELDS\\n};\\n```\\n\\nuv库多数接口都是非阻塞的，阻塞有`uv_run`，`uv_thread_join`，`uv_sem_wait`，`uv_rwlock_wrlock`等，线程类的好理解，但是文档并没有说run要阻塞多久。自己的测试结果来看，如果没有任何操作下执行run会立刻结束，如果在run之前执行一个内网连接并发送读取数据，大约会阻塞几毫秒。\\n\\n看`uv_run`的代码，最核心的数据loop里包含一个`uv_handle`的最小堆，run的时候每次从堆中取出顶点并执行。这就解释了如果一开始就执行run，因为堆中没有数据就立刻返回，如果有一个handle，则等待这个处理完成，run就结束了。\\n\\n因为`uv_run`的这种特性，必须要在执行它之前将所有会用到的句柄注册到loop，回调并不神秘，所有的接口如果允许传入回调函数，这个回调函数都会注册到loop中，并在符合条件时被触发。以TCP客户端为例说一下：\\n\\n传统上socket的connect操作如果用阻塞模式，执行时间是无法预期的。uv封装后的函数是`uv_tcp_connect`，最后一个参数是函数指针`uv_connect_cb`。这个指针就会先注册到loop，再尝试发起连接，直到connect成功或失败，这个回调就被执行。但这个回调只能被执行一次，显然我们肯定希望这个tcp连接收到数据就能持续地被回调，就要在`uv_connect_cb`的实现里注册一个读回调，函数名是`uv_read_start`，最后一个参数也是回调，这个回调会常驻loop，一旦有数据就能执行回调。除非显式地调用`uv_read_stop`。这两个函数没有tcp字样，原因是uv中把tcp/pipe/tty抽象成了`uv_stream_t`类型。\\n\\nstream的读写包含`uv_read_start`，`uv_read_stop`，`uv_write`。既然是读写，必然涉及`uv_buf_t`。读有两个回调，第一个回调是让用户分配buf空间，分配的大小是写死的！tcp和udp是65536，tty是8192或1024，只有pipe是运行中决定。当空间创建后，再把这块buf用来recv，把读出的数据写进去后，触发第二个回调。所以这两个每个都必不可少，且回调间有严格的时序关系。\\n\\n做到这一步还有个问题，此时流程已经运行到`uv_run`且已经阻塞住了，没法输入数据，这时就要用上三个并列的很有用的类型，idle/prepare/check，这三个实现代码很巧妙，用宏的方式定义，并通过传参的方式复制了三遍，第一次我用常规方式搜索代码无果，才发现是用了宏展开方式来实现的。\\n\\n三者和具体的业务态在loop的执行顺序是idle -> prepare -> specific poll -> check。由此可知poll执行前后会被调用，作一些校验和保证，类似Effiel的前验和后验概念。这三者都是寄生形态，如果没有tcp之类的事件，单独的idle不能永续存在。\\n\\nuv内部两个核心也是仅有的数据结构:heap和queue。heap查找最小值(似乎只用于timer)，queue遍历(loop, threadpool, pipe会用到)。实现得简洁干净，值得一读。\\n\\nuv的缓存`uv_buf_t`采用了和各自平台一致的定义方式，unix下是iovec，windows下则是WSABUF。因为内部实现时，如果buf数量大于1时会调用writev来替代write，所以参照iovec/WSABUF的定义就不奇怪了。\\n\\n`uv_run`返回之后要用`uv_loop_close`把loop关掉。和demo上演示得不同，这个函数不一定返回成功，就是说可能释放是失败的。释放包括iocp,timer,以及前面提到的idle,prepare,check句柄。\\n\\n说说线程库，创建用`int uv_thread_create`，返回成功与否，参数有3个，分别是tid，cbfunc,ud。调用之后要用`uv_thread_join`，内部实现是调用WaitForSingleObject。"}'));jctx.push(JSON.parse('{"id": "170822", "tag": "net", "text": "# 【翻译】select的历史和epoll的不足\\n\\n## 5种IO模型\\n\\n1. 阻塞IO\\n2. 非阻塞IO\\n3. 多路复用\\n4. 信号驱动\\n5. 异步IO\\n\\n阻塞IO不提，非阻塞IO只是减少了从请求发出到真正开始读的时间，但把数据从内核读到应用层，仍然会阻塞进程，只有异步IO才是完完全全的，从请求发出到得到数据的过程，应用侧完全感知不到，最典型的就是windows的IOCP了。据说Java的模型只用到了多路复用模型，IOCP无用武之地，所以为了跨平台考虑，还是Linux的epoll更好，如果到windows平台只能降级到select模型。但是不明白.Net怎么在Linux下实现异步IO模型？\\n\\n要谈多路复用，就要对Unix进行一次考古。\\n\\n诞生于1960年代中期的分时复用理念，相对于当时的批处理模式(batch-processing)，可谓是巨大的革新。而Unix是1970年才有的，因此它也要面对并试图解决批处理模式的问题。\\n此时Unix面临的阻塞有3种，CPU、磁盘IO、用户输入。\\n\\n接着谈谈pipe，此时并没有通用的进程间消息机制，也没有semaphore，pipe足以解决当时的问题。因为在3BSD的时候，每个进行只允许最多20个FD，每个用户最多只有20个进程，这种限定下确实不需要IPC和IO复用。同时正是这个限制，也导致了为什么select的接口参数`fd_set`会设计成一个长数组(在当时却并不长)。\\n\\n## TCP/IP诞生\\n\\n1983年诞生的4.2BSD引入了早期版本的TCP/IP协议栈和BSD socket API，虽然在今天看来似乎是理所当然的，其实当时还有一套System V Revision 3的STREAMS接口作为竞争者(现在已经没有人用了)。BSD socket API同时带来了select。\\n\\n同样的1983年，Rob Pike为Unix 8th Edition开发了Blit，一个图形化的终端。由于当时的BSD并没有类似System V的IPC机制，要实现Blit需要select来实现console的多路复用。\\n此处作者向Kirk McKusick求证了select的历史，非阻塞IO和select是同一时间出现的，但非阻塞并不好用，因此select成了最自然的选择。\\n\\n早期的Unix没有select，是因为当时只能做文件操作，而网络的出现也必然导致select的诞生。\\n\\n有4种避免阻塞的方式\\n\\n1. 非阻塞IO模式\\n2. 使用signal，即SIGIO，Linux上用`fcntl(F_SETSIG)`\\n3. 由系统提供接口，告知哪个FD可读写，select/epoll\\n4. 进程告诉系统，对哪些FD感兴趣，并注册回调，kqueue/IOCP\\n\\n三大平台IO复用的时间，依次是windows在1994年加入了IOCP，FreeBSD在2000年6月引入kqueue，Linux最晚，2002年引入epoll。\\n\\nBryan Cantrill(Joyent)曾猛烈地抨击epoll，提到两个缺陷，在Solaris系统的/dev/poll模型下存在惊群问题，而epoll的语义和/dev/poll很接近，因此也同样存在惊群问题。但是IOCP和kqueue的接口语义和epoll很不一样，似乎这样不容易引起惊群问题。\\n另一个问题则是epoll在应用层的语义是整形的fd，但内部实现却是内核对象，两者不一致导致在一些边缘场景下会出现奇怪的问题。\\n\\n惊群问题直到内核4.5版本，epoll加入了EPOLLEXCLUSIVE才得以解决，这就限制了epoll在多线程环境的运用。其实如果一开始就设计得好，是不会出现上述两个问题的。这也是要批评epoll的原因。\\n\\n先说惊群的问题，多线程使用epoll的典型场景是HTTP 1.0的短连接模型，很自然的会希望利用多CPU来均衡负载，但却做不到。\\n\\n## 电平触发 - 不必要的唤醒\\n\\n这种模式epoll和select的语义都会引发惊群问题\\n\\n1. 内核收到新的连接\\n2. 唤醒线程A和B\\n3. 线程A和B都结束`epoll_wait`\\n4. 线程A能成功的accept，但B会EAGAIN失败(或者反过来，总之只有一个成功)\\n\\n## 边沿触发 - 不必要的唤醒且饿死\\n\\n第一种没看懂\\n\\n第二种，达不到负载均衡效果\\n\\n1. 内核收到两个连接，同时有两个线程A和B，由于是边沿触发，只有一个线程被唤醒，假定A\\n2. 线程A结束`epoll_wait`且accept成功\\n3. 内核收到第三个连接，但是socket状态从readable到readable，因为是边沿触发，所以内核不会发起调度！\\n4. 线程A必须accept，期望EAGAIN，但是又得到一个socket\\n5. 内核收到第四个连接，线程A必须accept，期望EAGAIN，但又得到一个socket\\n\\n以上过程中socket只发生了一次从non-readable到readable的切换，因此内核只唤醒一次，导致永远在线程A。\\n\\n正确的解决办法\\n\\n有两种，最好的方式是用电平触发并加上EPOLLEXCLUSIVE标志(必须4.5内核后)，或者用边沿模式配合EPOLLONESHOT\\n\\n1. 内核收到两个连接，线程A和B在等待，由于边沿模式只触发一次，假定线程A被唤醒\\n2. 结束`epoll_wait`并调用accept，成功\\n3. 线程A执行`epoll_ctl(EPOLL_CTL_MOD)`，由于会重置EPOLLONESHOT标志，得以re-arm这个socket\\n\\n结论就是你必须理解EPOLLONESHOT和EPOLLEXCLUSIVE(还得内核足够新)。\\n\\n说下kqueue的接口语义和epoll的差异：\\n\\nepoll和kqueue都会创建一个监听句柄，但是epoll是直接把多个FD放入这个epoll句柄中，但是kqueue却多引入了一个kevent结构，FD通过kevent接口(是的，同名的)和kevent实例以及读写、添加删除等动作先关联，再将这样的一个或多个kevent放入kqueue中。FD和监听句柄中隔了一层。"}'));jctx.push(JSON.parse('{"id": "170826", "tag": "protocol", "text": "# 处理权限校验问题的反思\\n\\n公司产品的权限校验问题做了半年，前期我没有参与，最近因为人员调整所以换我来继续处理。说实话对于嵌入式产品却有多达6、70种权限的历史遗留问题，我很不认同。我觉得Onvif的权限模型把用户固定地划分到3个组，同时定义了几个固定的权限等级，语义清晰且一致性也很好。\\n\\n经过上半年的处理，总算把6、70种权限归约到15种权限，结果产品又开始不停地提增加权限需求，我本来想限制权限种类不允许扩充，想想这样做在理论上站不住脚，还是要思考权限问题真正重要的根本约束(出发点)是什么，以及要达成的归约状态又是什么。\\n\\n约束点就是每次的请求都需要权限校验。但是仅仅这样，就又会发散成不同产品各自定义权限，导致同一个请求却有五花八门的权限定义。甚至更加粗暴直接的是把权限和Web界面绑定。于是就出现今天开发提交给我的，增加一种日程这个请求的权限甚至包括了存储权限和编码权限，原因就是产品的惯性思维，因为录像和动检界面可以增加日程，所以增加日程的权限也要涵盖存储和编码。这类错误根本不值得讨论。\\n\\n不同的嵌入式产品最终归约到统一客户端来展现，为了达成操作的最终的一致性，有必要限制权限和请求的关系。权限涉及安全产品线、产品线、协议模块和客户端，各自有各自的诉求，初步设想的处理基调是这样。\\n\\n1. 原则上每种请求都要有权限，但如果是非敏感信息的只读操作，可以不校验权限，需要知会到安全产品线。\\n2. 协议模块对每种请求默认只提供一种预先定义的权限，且这种权限就是展示在客户端上的权限定义。多种权限增加使用认知难度，在处理上歧义也很多。\\n3. 如果产品线不认同这种权限，可以定制请求的权限列表，配合产品的Web界面，可以满足产品需求，不过这样的产品在接入统一客户端时还是会显示异常，终究无法做到全面的平衡。"}'));jctx.push(JSON.parse('{"id": "170829", "tag": "protocol", "text": "# Bitcoin中三种哈希的区别与关联\\n\\n区块链的不可篡改性是基于哈希函数的特性，Bitcoin中有3个地方用到了哈希的特性(都是SHA256)，分别是区块的哈希、区块的merkler树的哈希、每个交易的哈希。\\n\\n比特币实现区块链的数组结构比较简单，区块构成单向链表，区块结构的整体概貌：\\n<pre>\\nstruct Block {\\n  uint32 blockSize;\\n  struct BlockMeta; //80 bytes\\n  varint transactionCount;\\n  struct Transaction* transaction;\\n};\\n</pre>\\n每个区块含有一到N个交易，是个可变长结构，但不能无限增大，目前代码中人为地把区块大小限制在1M(分叉的BCC是8M)。这里还看不出哈希，接下来看看BlockMeta，这里面包含了两个Hash。\\n\\n<pre>\\nstruct BlockMeta {\\n  uint32 version;  // 最初是1，12年11月更新到2，最晚在17年已更新到0x20000002(隔离见证BIP141)，还有些0x20000012(BIP141和BIP91)。\\n  uint256 parentHash;// 指向前一个区块，以0x000000开头(至少八个0，工作量证明)，Genesis块这个位置全为0。\\n  uint256 merklerRoot;// 该块中所有交易通过构造merkler树生成的计算和，DoubleSHA256。\\n  uint32 timestamp;\\n  uint32 difficulty;//每2016块重新计算一次，早期都是1，直到第16个更新周期，即高度32256时第一次变化到1.18，后面一直在增加\\n  uint32 nonce;\\n};\\n</pre>\\nparentHash是把区块形成区块链的关键字段，计算这个Hash值异常困难，需要数亿次(甚至更多)地变换nonce值，进而使算出的Hash值小于difficulty。这也构成了Bitcoin共识机制PoW的基础，谁能算出这个值，网络上所有节点就承认TA挖到了这个块，从而获得了coinbase的奖励。但是区块并不保存自身的Hash值，因为一旦尝试出了nonce使得本区块符合链的条件，只要向全网广播这个刚算出的区块，其它所有看到这个广播的矿工都会保存这个区块的哈希。\\n\\nmerklerRoot也是SHA256，不过这个计算就没区块哈希这么变态了。区块只是个容器，重要的还是其中的交易，merkler树就是记录所有交易生成的摘要，使得不论多少笔交易，都只需要很少且恒定的数据，就能证明交易的存在。它也是SPV的验证基础，这部分内容还没看明白，以后再补充。如果区块只包含一笔交易(即coinbase交易)，merklerRoot就等于这个coinbase交易的ID(哈希)，如果有两笔以上交易ID，则两两作字符串拼接，并通过Double SHA256反复循环直到算出根值。\\n\\n每笔交易都是可变长结构，包含的输入和输入数量至少为1，无上限。\\n<pre>\\nstruct Transaction {\\n  uint32 version;\\n  varint tx_in;\\n  void* in;\\n  varint tx_out;\\n  void* out;\\n  uint32 locktime;  // 0指立即执行，1~5亿指到这个区块高度为止，5亿以上指时间戳(但4字节能表示的时间范围有限，难道不是问题吗？)\\n};\\n</pre>\\n\\n交易结构并不包含哈希，只有输入才包含哈希。\\n<pre>\\nstruct tx_in {\\n    uint256 pre_txhash;   //指向前一个交易的哈希\\n    uint32 pre_txout_index;// 定位到该交易的第几个output，必须是UTXO，否则会因余额不足而校验失败。\\n    varint scriptLen;\\n    void* script;    // 解锁脚本,signature+pubkey\\n    uint32 sequence;\\n};\\n\\nstruct tx_out{\\n    uint64 value;\\n    varint scriptLen;\\n    void* script;  // 锁定脚本\\n};\\n</pre>\\n由于Bitcoin没有账户的概念，只有UTXO，可以理解成一张支票吧。如果想交易，即证明有合法的input，就要向前找到一个或多个可用(未花费)的output，输入的哈希就用于寻找这个output。但交易可能不止一个output，所以还需要index来标识是第几个output，有了这两个值，就能惟一确定到UTXO，各节点也能验证余额是否足够。\\n\\n上面说了Bitcoin的结构，接下来对比下Bitshares的区块结构。Bitshares只有区块摘要的哈希算法用了SHA256，而区块ID、交易ID和MerklerRoot用的都是RIPEMD160。计算Merkler时的策略也有细微不同，Bitcoin在计算奇数个叶子节点时，会把最后一个节点复制一份，且每两个叶节点在向上计算上一级摘要用的是Double SHA256；而BitShares是直接把最后一个孤立节点放到下一轮计算，只用了Single SHA256，少了一半计算量。"}'));jctx.push(JSON.parse('{"id": "170831", "tag": "security", "text": "# SHA家族的哈希算法\\n\\n由于MD5早就被证明存在碰撞攻击，安全性在严肃场合肯定是不够的，SHA-1(160bit)作为替代品已被越来越多的观点认可，但是MD5有一个理论上的优点，计算长度无上限，而SHA家族的长度会限定在2^64-1或2^128-1内。SHA是一个很大的哈希算法家族，到目前共有0、1、2、3这四类。\\n\\n* SHA-0：这个很少提及，原因是MD5被成功碰撞后，几乎同时SHA-0也被碰撞，所以没有实际应用\\n* SHA-1：只有SHA160一种，不过目前在理论会产生碰撞，17年初Google发了paper声称找到了碰撞方法，git在计算对象摘要时用了SHA-1，但git用它作为完整性校验，并不在意碰撞。\\n* SHA-2：共有SHA-224/SHA-256/SHA-384/SHA-256这四种细分类型，224和384分别是256和512的截短版本，至少我还没有看到可靠的质疑的消息，Bitcoin计算交易哈希、MerklerRoot时，用的就是SHA-256算法\\n* SHA-3：虽然SHA-2没有明确的证据证明不安全，但NIST(美国国家标准技术研究所，也发布AES、若干种椭圆曲线等其它加密技术)还是未雨绸缪地于2007年开始征集新的下一代密码Hash算法，最终在2012年10月2日，Keccak被选为NIST竞赛的胜利者，对外称为SHA-3，Keccak和SHA-2在设计上存在极大差别(海绵结构 VS Merkle-Damgard)，支持256，384，512多种长度的输出。以太坊出现时间在SHA-3之后，用的是SHA-3算法\\n\\n## HMAC与HASH\\n\\nGo语言规整地把计算HASH的方法统一定义成hash.Hash接口，hmac.New(hash.Hash, []byte) hash.Hash。可以任意组合，不需要为每种HMAC增加特定方法。"}'));jctx.push(JSON.parse('{"id": "170905", "tag": "lang", "text": "# 给应届生出题看指针的易错点\\n\\n上周领到给18届毕业生出题目，我被分到OS方面的基本题和两道编程题，基本题不能简单考能查到的题目，最后出了几个Linux偏操作的题目。两道编程题中有一题，在自己实现时遇到了两个指针方面易错点。\\n\\n题目是这样：N个人排队，每个人都有个编号（数字），要求排序后让这些编号连在一起之后组成的那个整数最小\\n比如 14  78  132  56  8，排列后的顺序是132 14 56 78 8。这道题目难点并不在排序算法，主要是看能不能读懂排序比较函数，比较两个字符串，首字母小的认为小，如果前N个字母一样，先结束的认为小。\\n\\n我在提供标准答案时，直接用C语言的qsort函数，原型是这样 `void qsort( void *buf, size_t num, size_t size, int (*compare)(const void *, const void *) );`\\n\\n第一个参数显然要对数组排序，因此排序`*`后，void就要换成元素的真实类型，比如这道题目是`char*`，第二、三元素很好理解，重点在第四个函数指针的原型，刚才已经分析过，真实元素类型是void，对比函数原型是`void*`，说明函数参数要多一重指针，即`char*`传到比较函数时时`char**`，这个开始没发觉，反复调试并才意识到错误。\\n\\n再就是比较函数，这道题是比单个字符，如果两个字符串是`char *p1, *p2`，开始我用了`p1-p2`，并误以为是字符串首字母比较，其实从类型看到，相减的是`char*`即指针地址，这样比较结果不会影响数组排序，原因就是比较指针地址当然不可能影响排序，所以比较要用`*p1-*p2`才能得到想要的结果。"}'));jctx.push(JSON.parse('{"id": "170908", "tag": "lang", "text": "# 面向对象中的类与应用场景\\n\\n记得我刚学`C++`的时候，第一眼记住的特性就是引入了class关键字，但是由于一直以来的工作，更多是以C语言为主，自己编码也很少用到类，只能把我的理解记录下来，希望未来能有更好的认识。\\n\\n程序的基本元素是数据和函数，类的出现意味着数据和函数的绑定，类的构造函数会产生对象，而所有同一个类的对象共同持有相同的函数，即只有数据是对象的核心，面向对象就是面向数据的风格，从编码上看，数据拥有了自己的行为，这种方式很符合人的思维习惯，或者说面向对象就是以数据为轴心的思考方式，一个对象就是一个状态机，随着行为而不停地引起内在数据(状态)的变迁。类的特性一旦确定，那么适用于围绕数据的场合，就适合按类建模。但是以数据为中心，在并发环境下一定会遇到锁的问题，很难做到并发。\\n\\n来到数据的另一边，以函数为主体，数据只是构建结果的一部分，并不是核心要素，比如统计学等需要大量数据的情况下，如果围绕最终数据结果，可以是对象，但过程中那些海量的数据，并不适合作为对象来理解。\\n\\n映射到比特币和以太坊，似乎正是这两种思维的差异。以太坊的账户体系是典型的面向对象思维，每个人都有各自的账户，并针对账户操作，是集中式的。而比特并没有一个归总的数据，全是分散在各处的UTXO，每次UTXO操作完，就生成新的UTXO，以交易(操作为中心)，数据只是附带的产出物。\\n\\n是否类就是面向对象的惟一呢？由于`C++`/Java这些面向对象语言非常流行，导致绝大多数人把类和OO合一，从分类角度看，面向对象至少分为class-based和object-based两大类(其实还有些小的分类，还不熟悉先不介绍)。目前主流语言中最有名的object-based的是JavaScript，千万不要因为ES6导入了class关键字就认为JavaScript是class-based语言，它的核心仍然是object-based语言。更准确的说JavaScript是object-based分类中的prototype这个分类，还有一种称为closure的分类。\\n\\nprototype类型下又细分了embed和delegate两种，它们之间的区别是method的存储模型，把method放在对象内的，称为embed，而存储在对象外，用到的时候临时去找的方式，就是delegate了。"}'));jctx.push(JSON.parse('{"id": "170914", "tag": "lang", "text": "# C语言的类型长度\\n\\n## long类型该多长\\n\\nC语言的规范没有规定long必须是多长，只要求不小于int就可以。从我看到的情况int都是4字节，但long就有32/64两种长度。典型的像VC把long当成32字节，而Linux的GCC则把long当成64字节。\\n\\n造成这个差异的根本原因其实并不是编译器，因为今天意外地发现GCC在windows平台上是把long当成32字节，说明long长度不仅仅和编译器相关，那么为什么windows的long会是32字节呢？\\n\\n恰好昨天提交一个头文件，修改结构体定义BITMAPINFOHEADER中四个long类型为uint32，我查了下BITMAP的要求，明确说MUST BE 40bytes。但是这个结构体有10个字段，6个INT和4个LONG，而这个定义又是抄自windows.h的定义，说明当时在微软定义头文件的这个哥们就是把LONG当成UINT来用。没有看过所有头文件，也许那时所有人都认为32位已经足够用了。然而时至今日出现了64位，如果这时把LONG定义成64位，BITMAP头文件就不能和真实的文件匹配上了，必须让LONG保留32位，而且不仅微软自家编译器，是所有跑在windows平台的编译器都必须按32位来对待long。在Linux平台没有和文件格式强绑定的头文件定义，因此GCC就把long当成64位来处理了。\\n\\n由此可见头文件的定义，一旦落了地影响就无比深远，远到当初定下这个结构的人，都不曾预料到会演变成今天的情景。\\n\\n## int类型该多长\\n\\n历史上，不是所有计算机都是一个字节 8 个 bit 的。只是由于一系列优势 (比如刚好能容纳下 ASCII 码 + 1 位校验位)，所以 8 bit 的计算机成功吃鸡，成为了今天最常见的架构。\\n\\n如果你仔细的话，会发现 C 语言标准头文件 <limits.h> 中规定了一个宏 CHAR_BIT，用以表示字节位数。这个宏就像历史文物一样向今天的我们诉说历史的沧桑。我们今天写代码时，如果要计算一个 int 有几位，三流程序员可能直接返回 32。但是大家都知道，直接返回 32 的代码，没有考虑到标准中并没有承诺 int 就是 4 个字节，所以兼容性是要大打折扣的。一般人会返回 sizeof(int) * 8，但是这同样有问题。正如上面所说，不是所有计算机都是一个字节 8 位。所以正解应当是 sizeof(int) * CHAR_BIT。尽管在今天，99.99% 的情况下 CHAR_BIT 被 define 为了 8，但在有些特殊领域，仍要考虑到非 8 位的特殊情况。\\n\\n了解了这些，站在当年的角度思考这个问题，有些机器的硬件，是没法原生支持 int8_t, int16_t 等等的 (因为它们的整型位数就不是 8 的整数倍)。更别提就算是 8 的整数倍的 16 位的计算机都没法原生支持 int32_t, int64_t (超过它们的最大字节数了)。\\n\\nPDP-10，后期命名为 DECSystem 10 的字长是 36 位，字节是 9 位，一个机器字内可以有许多种不同的打包（Packing）方式，这机器的一个 CHAR_BIT 就是 9。\\n\\n对于 PDP-10 存储字符，还有其他的打包方式：\\n\\n* 六个 DEC Radix-50 字符打包进 32 位中，剩下 4 位留空\\n* 六个 6 位的字符（DEC SixBit，ASCII 0x20——0x5F 这一段）\\n* 五个 7 位 ASCII，1 位留空\\n* 四个 9 位字符（Multics 约定）\\n"}'));jctx.push(JSON.parse('{"id": "170920", "tag": "os", "text": "# 动态链接库与符号表\\n\\n起因是前天向吴惠敏请教gprofile的时候，这个工具要用.a库，不要用.so否则程序会挂掉，原因是gprofile的设计思想在20年前就已固化，而动态加载的重定位细节又经常变化，所以干脆gprofile就只支持静态库了。本篇不说gprofile，单说说动态链接库。内容并不会超出《程序员的自我修养》这本书，更多的还是个读书和操作记录。\\n\\n现在的Linux默认都用动态库，比如我最常用的CentOS，/lib/目录下几乎看不见.a库，gcc默认也找的是动态库(真实选项-Bdynamic)，除非用-static选项告诉ld只用静态库。(不过MinGW的gcc即使用了-Bdynamic，在静态和动态都存在的情况下依然会用静态库，原因不详)\\n\\n加载动态库是一段专门的程序，它和系统用的C语言库强关联，在不同的系统表现形式也不一样\\n\\n* CentOS(也是绝大多数Linux)：/lib/ld-2.xx.so 和 /lib/ld-linux-xx.so.2\\n* Alphine(一个轻量级的Linux)：因为库体积的原因，使用了musl这个C库(libc.musl-xxx.so)，动态加载库和libc是合二为一都指向/lib/ld-musl-xxx.so.1\\n* Aboriginal(一个更轻量的Linux)：使用uClibc库，动态链接/lib/ld-uClibc.so.0，从版本号看，libc、libm、libdl、libnsl、librt、libpthread、libcrypt、libresolv、libutil都在uClibc库的范围内\\n* FreeBSD：/libexec/ld-elf.so\\n* OpenBSD：/usr/libexec/ld.so\\n\\n其实Cent下ld-linux只是个指向ld.so的软链接，只是因为历史上ld.so处理a.out格式，ld-linux处理ELF格式，为了兼容名字一直保留到今天，其实程序是同一个。从FreeBSD的名字也可以看出，最初的名字叫ld.so，出现elf格式后，FreeBSD不再保留ld.so，全换成ld-elf.so了，但OpenBSD依然沿用。ld.so文件名在Linux中保留了版本号，我猜测这正是它和libc库强关联的证据，即根据编译时链接的libc库版本号，换算成对应的ld.so程序名，进而执行动态加载。\\n\\n动态加载必然涉及从遍历目录的过程，这必然涉及配置和更新目录集，虽然不同的系统配置名字不一样，Linux用ld.so.conf，而FreeBSD用libmap.conf，但最终都要通过ldconfig程序将配置转换成更高效率的格式，ldconfig和ldd最早都出现于SunOS 4.0，所以现在大家依然沿用这个名字。\\n\\n## 符号表\\n\\nso文件有.symtab和.dynsym两种符号表，dynsym看名字就知道是动态，而symtab是normal又称regular符号。用strip只能去掉symtab，但是dynsym不能被删。\\n\\nnm默认找symtab，如果被strip会提示no symbol，加-D能显示。objdump的-T是同样功能。\\n\\n## 动态库的版本规则\\n\\n使用GNU Autotools编译动态库会用到libtool工具，是对不同平台和编译器的封装，在编译前要指定三段式版本：current:revision:age。第一次发布时为0:0:0。这3个字段的变动规则是\\n\\n1. 只要源码有变动，revision加1\\n2. 如果是兼容性扩充，current和age加1，revision归0\\n3. 如果不兼容改动，current加1，age和revision归0\\n\\n最终生成的版本号：(current-age).age.revision\\n\\n编译出的动态库通常有3个文件\\n\\n1. libxx.so: 软链接，编译时用到\\n2. libxx.so.major: 软链接，运行时寻找so一般都会锁死major，这个值不匹配会报加载失败\\n3. libxx.so.major.age.fix: 按以上规则生成的完整版本号，age表示接口有过多少次兼容性增加，fix表示代码修改次数\\n\\n有时虽然major能匹配，但如果用到的是age更大的版本才加入的接口，虽然加载能成功，但运行过程中还是有可能报错。\\n"}'));jctx.push(JSON.parse('{"id": "171003", "tag": "book", "text": "# 劳动和交易创造的财富\\n\\n这些天看了很多水库的文章，回想《国富论》写点粗浅的认识，到底什么创造了财富，这个话题很大也很有争议性，希望能逐渐完善它\\n\\n先来对财富释义，最直接粗暴的标准就是可流通的货币，但实际上目前的富人真正持有的货币并没有账面上那么多，是股票、不动产等外延形式，这个话题会引申得太远，先直接对等到纸币上。那么这些财富是怎么来的？\\n\\n按照马克思主义的劳动创造价值理论，一个企业家即使7x24小时不停地劳作，生产出的产品堆满库房，财富是不会出现的，甚至还要缴纳仓库费用变为负资产，只有当这些产品给到另外一些需要他的人手上，这一刻两个人的财富同时得到了增加。此时交易增加了两人各自的财富。再补充一句，买家付出了货币得到了产品，则这件产品对他的使用上的回报必然是大于货币的(如果认为买家要贱卖这件商品则有点钻牛角尖了)，同样卖家出售产品换回货币。\\n\\n看完行为再来分析为什么交易增进了两个人的财富，因为人的需求繁多但人的生产能力单一，不论是谁他擅长的技能总是有限，而他的需求总是大于他的技能，可以简单地认为，当他越多的需求得到满足，则他的财富也越多，所谓藏富于民，即民众的各种需求都能满足。要达到一个人各方面的需求能满足，则交换/交易就很重要，甚至可以说是必不可少的。\\n\\n对于财富，交易是第一紧要的要素，再说劳动。即然要交换，必须要持有某物件才能交易，这个持有的物件如果不考虑中彩票或是摘野果之类，必须要靠劳动才能获得，同时劳动又是天然的，最公认的对这件物件产权的证明，是任何人都无正当理由剥夺的，利用合法产权，进行交易并获得财富增长的方式，无可辩驳。\\n\\n因此劳动确定产权，基于产权进行交易，交易促使财富增长。\\n\\n财富通常用货币衡量，但货币和任何商品一样都有保质期，只是这种腐化不像水果一样有形地腐烂，而是慢慢地缩水，粗浅地理解下缩水的必然性：在某一个时间点，货币总量和社会物质是对等的（先不考虑结构性失衡），但是随着时间发展，通过生产劳动，物质是会增加的， 如果货币不同步增加对等关系被打破，造成所有人持币等待，进而导致流通的货币更少，引起物价上涨。在这个过程中货币并没有超发，甚至都没有增发，这和股票市场的锁仓是一样的，总量和流动性要同时考虑。最理解的当然是增加同样多的货币，但还是存在分配的总量，如果交换不充分，就会存在货币积聚到某个行业，于是出现类似房价/股价大涨，但物资并没有涨价的现象。\\n\\n存款是过去劳动的凭证，但通过前述这些存款会慢慢腐化变少，因此财富真正自由必须是动态的，一旦静止货币腐化因子会蚕食你的财富，而且要使过去已固化的资产同步地当前收入增长保持同速，就必须利用自己的能力将它使用起来，因此往往富人没有存款，为了保住这些财富，必须全力使用不能一时松懈，一旦变成存款，和逆水中的船没有任何两样了。\\n"}'));jctx.push(JSON.parse('{"id": "171010", "tag": "lang", "text": "# 两个嵌入式JS引擎的介绍\\n\\n最近在开发一个协议转换工作，脚本决定使用JavaScript。JS的实现非常得多，除了浏览器里那些重型武器，还有非常多小型的实现版本，大多都实现了ES5.1的特性，这些之中我用了MuJS和Duktape，这两个接口风格和Lua很像，基于引擎按栈式操作，Duk速度比MuJS明显要快得多，也支持部分ES6的特性，但缺点就是接口也较多，掌握起来更难一些。以下逐一说明。\\n\\n我先用的是MuJS库，引擎类型是`js_State`完全和Lua一样，感觉是Lua出现后照着Lua的接口抄的，来看和C的交互接口(顺便对比Lua的定义)\\n\\n```\\ntypedef void (*js_CFunction)(js_State *J);\\ntypedef int (*lua_CFunction) (lua_State *L);\\n```\\n\\n惟一的差异在于不需要返回值，这个差异也是JS不支持multi-return导致的，规范(至少5.1)要求必须且只能返回一个值，在实现时哪怕没有值也要push undefined才能返回。(但是Duk有返回值，正文再述)\\n\\n再说说函数的执行，记得在call之前一定要压入this，这也是JS语言导致的，因为Function就是自带call/constructor方法的Object，执行后一定要记得弹出压入的返回值。\\n\\nMuJS在执行出错后直接abort非常不友好，因为abort会导致栈丢失，用GDB的bt无法追溯，这里我修改了jsrun.c改为exit，并在jsstate.c打印了调用栈，出了问题很容易回溯。\\n\\n它的值类型和Lua几乎一样，tag value风格，标记GC的字段。由于JS语言的特性，每个值对象还多出prototype和properties字段。以及配合ES5对象的extensible/seal/frozen特性的extensible字段。\\n\\nDuktape的函数声明和Lua一样\\n\\n`typedef duk_ret_t (*duk_c_function)(duk_context *ctx);`\\n\\n返回值有四种情况\\n\\n* 1 正常情况，向栈内压入一个值并返回\\n* 0 由Duk引擎自动压入undefined，感觉和1差别不大，不需要多此一举\\n* 小于0 相当于抛Error异常，并列举了几种Error的值。从完整性角度来看是有必要的，JS毕竟是门显式支持异常的语言，没有<0就强制剥夺了这个特性\\n* 大于1 预留，为了以后支持multi-return做的预留\\n\\n还是Duktape考虑得更全面。\\n\\nDuktape有多种编译脚本，比如命令行模式，会额外包含print, console, module, log共4个模块，因为这些接口在某些平台并不存在。甚至还有debug接口。\\n\\n## 和C语言的交互\\n\\n两种都是用了lua的语义，总体差不多。各种pushXXX和pop接口，但duk的接口比较冗余，比如pop竟然有4个接口，有`duk_pop_2`和`duk_pop_3`这样特化的接口，完全想不出有什么必要。\\n\\n在C语言执行JS函数也表现出duk的冗余，不仅区分了call和pcall，call还有自身,`call_method`和`call_prop`，后两个需要显示指定执行时的this，call没有指定，因此这个函数内了不要调用this。\\n\\n## 编码格式\\n\\njs标准规定字符串内部以Unicode保存，这两种实现都只支持外部输入UTF8，甚至外部输入带BOM的Unicode也会报转码失败，考虑到多语言编码的复杂性，可以接受。\\n\\n## MuJS裁剪\\n\\n首先Date和Math库是最没有依赖的，删除后完全不影响编译。\\n\\n接下来Regex就有点麻烦，因为gc中要释放regex，string的match,split,replace都依赖正则。\\n\\n删除URI相关的4个global函数。去掉ES5追加的extensible属性，大约300行代码左右，非核心。"}'));jctx.push(JSON.parse('{"id": "171015", "tag": "think", "text": "# 回看晚清七十年历史\\n\\n小时候因为清朝是满族统治关系，非常不愿意学。现在回看这段整个民族在转型过程中的历程，颇为沧桑。\\n\\n晚清的界定通常从第一次鸦片战争开始，到辛亥革命共七十一年。对个体来说这就是一辈子了，不能简单的把这么长一段岁月用一句苦难深重就带过了。我觉得这七十年分三段去描述。三个节点分别是第一次鸦片战争、第二次鸦片战争和中日甲午战争。\\n\\n第一次鸦片战争打开国门并开了五口通商，但朝野上下并没有深刻的震动，因为仗是在广州打的，开放的口岸也在长江以南地区，离北京太远，虽然领教了坚船利炮仍没有自醒。所以到第二次鸦片战争期间二十年，没有引起改革。倒是这场仗后十年的太平天国运动还更引起朝廷的重视，战争持续了十余年，人口大减，武汉更因三次攻防战彻底成为废墟。曾国藩中兴，但我更觉得湘军这种制度创新是这场战争为将来变革留下的伏笔。\\n\\n第二次鸦片战争则深深地触动了朝廷，这场战争的原因我不了解，不表。这里还有个小趣事，明清两朝都是一帝一年号，但同治在正式改元前还另有个祺祥年号，不过只用了咸丰死后剩下的半年，改元后用了同治，此后慈禧登上历史舞台。这场战争后，清廷才真正被打醒并开始走上变法图强的路子，洋务运动就此开始，不仅开始追赶科技，在国政上光绪年间收复了新疆并正式改为郡县制(之前一直是伯克制，有点像改土归流)，还神奇地从毛熊手上通过谈判拿回了伊犁，1883年更是和法国人打了一次少有的胜仗。后世称这段时间为同(治)光(绪)中兴，如果不是后来的甲午战争，还真是中兴了。\\n\\n甲午之败，导致全国上下的震动，所有人都陷入了怀疑，到底怎样才能真正走向强大？之后经过戊戌变法，还是无可避免地发生了庚子国变(八国联军)，此仗在南方各省引发的东南互保致中央威权消解，虽然清廷努力地改革新政，但大势已成，最终在十年后武昌起义导致了清帝的退位，从此进入了更为动荡混乱的民国时期。"}'));jctx.push(JSON.parse('{"id": "171023", "tag": "think", "text": "# 我国省份行政编码规则\\n\\n每个人身份证的前两位(企业则是社会信用代码)表示省份，比如上海是31，北京是11。省、地、市县这三级行政区划代码，从1982年到2007年，有专门的国标2260定义，期间修订10个版本，后来可能觉得修订太频繁，由标准改为民政部每年发布一份文件。省份的编码其实很有规律，试着发掘一下。\\n\\n省份是按区域大致划分的，从首都为中心按顺时针排布。北京作为首都自然排在首位，代码11，然后就是天津河北山西内蒙，这些省有个很熟悉的名字：晋察冀，至于内蒙大约和河北地缘较近，也被归类到中心区。\\n\\n中心区顺时针开始第一个片区是东三省，辽吉黑从21到23，耳熟能详了。接下来是华东六省一市，上海31领衔，后跟江苏浙江安徽福建江西山东，后面几个省的顺序比较杂乱，也没有明白排列顺序是什么。\\n\\n时针走到下方，则是湖广地块，包括湖北湖南广东广西海南，河南也归在这个片区，可能实在不好归类只能放在湖广区了，不过可能是作为弥补给了河南41的代号。湖广再往西就来到了云贵，包括重庆四川贵州云南西藏，藏民有很多住在四川，归入这个区很自然，这个区有点特殊的是重庆的代号是50，其它区第一个都是1，只有重庆是0，原因也很简单因为重庆成立直辖市晚于省份代号制定年份，又是直辖市，只好放在原来51的四川前面。\\n\\n最后来到以6开头的西北，陕西甘肃青海宁夏新疆，陕西和甘肃古有陕甘道，且李唐的关陇集团就是以陕西为中心，陕西和山西虽然听着近，但中间隔着太行山潼关，陕西自战国时代就秦朝的属地，所以还是划入西北片区。\\n\\n民政部官网上可以查到每个自然年的到市县的行政区划代码，省地市每级2位数字，共6位。同时也会把变动的乡镇街道编码公布出来，但不会公布全部的乡镇街道编码。乡镇街道会按类型划分，比如街道是0，镇是1，乡是2，还有些林场、开发区、农场也属于这一级。再往下的村和社区没有找到网上有可查的地方，乡镇和村社每级是3位数字，所以完整的到编码共12位。"}'));jctx.push(JSON.parse('{"id": "171110", "tag": "lang", "text": "# 比较词法分析和语法分析\\n\\n词法分析是一种单向的状态机。最简单的词法分析，只要不停的吞入字符并和状态表中的可选项进行匹配，并把匹配上的字符挑选出来就可以了。稍微复杂一点的则可以加入把匹配项里面的部分字符退回，但这个状态更多的像是一种人为的操纵，而不影响状态机的本质。另外在比较的时候有一个很简单的判断，就是称之为最长判断，但这种判断也不会造成过多的选择负担。\\n\\n由于输入的数据始终只有一种状态，所以不需要保存过去的数据，当然也不存在栈溢出问题。\\n\\n语法分析相比起来就要复杂很多，是一个带有栈的，且栈深度是可伸长的状态机。因为一个不带栈的语法分析器，比如LR(0)，能够分析的语法是非常少的。要想达到可用，至少要保存向前看的一个数据。另外归约时要根据向前看的数据进行选择，也要把一段时间内未归约的数据保存下来，这就需要栈，当归约的语法太复杂，或者歧义太多，保存在栈上的数据过多，就可能导致栈溢出的问题。\\n\\n从我查到的文献看，1965年的ACM就刊载了TMG compiler compiler语法分析文章，这个工具在70年代初移植到了最早版本的unix，但在用TMG给B语言扩展特性时却很困难，因此才基于LR解析理论重写了yacc（yet another就是针对TMG而言），并随着version 3 unix一起发布。而lex虽然更简单，但资源很少，只查到1975年lex论文发布（同年yacc论文也发表了）。由于年代久远，二者都是不可重入的。随着线程的出现就出现了可重入的需求，lex可以使用%option reentrant生成可重入代码，如果比较会发现和非重入版的代码差异极大，yacc也能生成可重入代码，而更新的语法生成工具如lemon，生成的都是可重入代码。"}'));jctx.push(JSON.parse('{"id": "171129", "tag": "data", "text": "# MySQL和Redis备忘\\n\\n## 连接与数据格式\\n\\nMySQL远程的访问，支持Unix的域套接字、Windows的共享内存和命名管道模式以及应用最广的TCP。TCP协议的首字节是版本号，官方文档可查最早是版本9，自3.21.0开始切换到10以后没再变过。这份协议格式符合GPL。\\n\\n连接要配置用户名(最多16个字符)，用`mysql -uxxx -pxxx`的方式登陆，注意`-u`和用户名中间没有空格，和一般的软件习惯有些不同。标准语句外，额外支持show,desc,use指令。\\n\\n数据格式比SQLite要细分得多，在SQLite里字符串就是TEXT类型，但MySQL的TEXT表示65535以内的字符串，如果需要更大的空间，要换成MEDIUMTEXT或LONGTEXT。编码支持多种，创建table时要注意指定，或者用`alter table xxx character set utf8`修改。varchar的长度只限制了取出，如果超过范围仍能写入，但取出会被截断。\\n\\n空有两种表示方法，NULL或者\'\'。在MySQL中，NULL会占用额外空间，MyISAM是1个bit，且不能被索引，所以关键字段如果用NULL会影响检索效率，而\'\'完全不占用空间。好比NULL是空气，看起来没有实则还是有的，\'\'是真空。用CHAR_LENGTH对这两种取值，NULL返回还是NULL，而\'\'返回是0。所以建议所有的字段都设置为NOT NULL。即使设置成NOT NULL，插入时如果不指定，CHAR默认是\'\'，而DATETIME默认是全0。\\n\\n## 数据存储\\n\\nMySQL的数据保存在datadir指定的目录（默认是data），生产部署时会把datadir指向单独分区，方便数据整盘迁移或调优。data目录的每个子目录对应一个数据库，因此数据库不能指定存储引擎，只有表需要引擎参数。\\n\\n不过把整个目录直接移到另一个MySQL，虽然可以看到这个目录和表，却不能进行操作，可能在其它地方还有记录库和表的关系吧，也因此迁移数据不能简单地移动文件。库目录一定有db.opt文件，通常用来指定创建新表用的character和collation。\\n\\n当第一次安装完成，会自带mysql目录，这个库里会有db/func/user等保存元信息的表。另有`information_schema`库，该库的机制是视图，所以没有外部文件。更高版本的MySQL还有`performance_schema`库，了解不深。\\n\\n### MyISAM引擎\\n\\n每张表对应3个文件，后缀分别是frm,MYD,MYI。\\n\\n* frm: 描述了表的结构\\n* MYD: 保存了表的数据记录，以行为单位记录数据，每写入一条数据，都会在文件大小上，精确到字节地反映出大小变化。\\n* MYI: 保存表的索引\\n\\n### Inno引擎\\n\\nwindows下，每张表有frm和ibd两个个文件存放数据（是否有ibd文件取决于 `innodb_file_per_table` 是否打开，低版本默认关闭就只能看到frm文件）。ibd在创建空表后就有96K，插入单条数据只能看到ibd文件时间有更新，但看不到大小变化，只有累积到一定数量（疑似16K）才会增长。和数据库目录平级的目录下，有ib_logfilex,ibdatax和若干个文件夹。ib文件记录了redo日志和inno引擎的事务消息。\\n\\n## 启动方式\\n\\n启动日志报各种奇怪的错，数据库不存在，InnoDB起不来。mariadb会默认装在/usr/var/lib/mysql/目录。\\n\\n1. 删掉三个文件：ibdata，ib_logfile0和1\\n2. mysql_install_db --user=mysql --basedir --ldata\\n\\n### mysqld_safe\\n\\n把my.cnf文件放到默认位置（通过mysqld --verbose --help查看），再执行mysqld就能启动监听，可能会报错，但似乎不影响执行。\\n\\n```\\n[mysqld]\\nuser = xx\\nbasedir = /pathto/mysql\\ndatadir = /pathto/mysql/data\\nport=3306\\nserver-id = 1\\n\\n[client-server]\\nsocket = /var/run/mysql.sock\\n```\\n\\n除了原始的mysqld命令，用safe脚本会多做以下几件事\\n\\n1. 从多个目录寻找mysqld，并配置额外参数（malloc、PRELOAD_LIB）\\n2. 对信号进行trap捕获，防止意外退出，配置日志目录\\n\\n### 用户机制\\n\\nuser表记录所有的用户密码和权限，似乎做了SHA1，另外MySQL5换过保存方式，不过手头没有版本4，也无从察看。因此安装包通常会告诉你初始密码是什么，否则没法登陆了。可以用mysqladmin工具修改密码，如果忘记密码就要让mysqld进行无授权模式启动，在my.ini的`[mysqld]`配置`skip-grant-tables`，这时就可以免密码登陆，然后再用`use mysql; update user set password=password(\'123456\') where user=\'root\' and host=\'localhost\';`语句修改mysql库的user表，退出后去掉免授权模式，重启mysqld就可以用新密码登陆了。\\n\\n要注意user表是host和user双字段联合主键，同样的用户名从不同地方登陆可以设置不同密码和权限。又比如常见的root用户不能远程登陆就是因为user表没有host为%的记录，不存在从任意主机连接过来的root用户，当然就会报错了。host是localhost代表unix socket，而127.0.0.1代表berkley socket。\\n\\n创建或修改用户密码\\n\\n使用`mysqld_safe --skip-grant-tables&`跳过检查，然后一定要`flush privileges;`，否则mariadb会报不能执行权限类操作。\\n\\n* mysql5.5: `update user set password=password(\'root\') where user=\'root\' and host = \'%\'; flush privileges;`\\n* mariadb: 从10.4版本开始，user表已变成视图，不能修改。要用`alter user user@\'%\' identified by \'user\'`，或者添加用户`create user user@\'%\' identified by \'user\'`。\\n\\n## binlog\\n\\n在项目中遇到数据库连接和表都在，但其中一张表的大量数据丢失，虽然到最后数据都没能恢复出来，但binlog和备份的重要性再一次刺激了我。\\n\\n命令行工具叫mysqlbinlog，但是变量命名是`log_bin`，因为日志除了bin，还有error、syslog等多种。binlog在主从同步时起关键作用，因此是数据库级别，不能针对某张表开启，因此binlog可以用 show master logs。\\n\\n最简单的用法：mysqlbinlog --no-defaults mysql-bin.00000x 就可以显示所有的执行日志。\\n\\n## 数据库备份\\n\\n* 备份整个库: mysqldump -h xx -uxx -pxx --databases db1 db2 > back.sql\\n* 备份表: mysqldump -h xx -uxx -pxx dbname tbl1 tbl2 > back.sql\\n\\n以上命令可以用--no-data方式只备份结构。除了表之外，默认只转储触发器，不会转储事件和过程，要加上-E(事件)或-R(过程)。视图无法导出，要备份视图定义的frm文件，导入后再次恢复。\\n\\n## Redis记录\\n\\n总计有1314099条时，占用内存近12G，平均下来一条9K，远超实际长度。设置 maxmemory防止无限增长。\\n\\n认证命令auth，不过只是一个很弱的安全措施。可以用config get requirepass查看。"}'));jctx.push(JSON.parse('{"id": "171130", "tag": "think", "text": "# 《天朝的崩溃》读后感\\n\\n草草地看完茅海建先生的天朝的崩溃一书，这本书有500多页，因为时间的关系，只看到其中的一大半的章节，现在留下来的都是一些情绪上的一些记忆。\\n\\n我对这段历史的细节并不太了解，包括这本书第一章节的绪论提到琦善卖国而想到的，我甚至都不知道琦善是一个什么样的人。我们的教科书往往只是列举这个关键时点的一些人物，比如林则徐，关天培，但是其实还有非常非常多的官员，像琦善，伊里布，这些人物在当时的官职并不比林则徐低，但是因为可能民族的关系，在教科书中并没有过多的涉及。\\n\\n鸦片战争是清朝在军事力量上和英国的不对等，坚船利炮不是文学上的描述，而事实上的差距，清国因为长期的产品，武器火炮弹药年久失修。比如清军之中最长的火枪，竟然有166年的历史之久，是康熙时代真法俄国留下来的战争器物。各种火炮的配方，因为不懂化学的关系，没有像英国制作的，如此复合化学原是，另外在烘干等各种工艺上的不成熟，导致火药的性能也非常的差。由于缺乏严谨细密的科学理念，所以在各种器物上的差异简直不可以道理计。铁器的铸造工艺也落后很多，所以炮管枪管内壁非常不均匀，射出的弹道也无法保证是预期的吻合，更会导致后管炸裂，未伤敌先伤已。\\n\\n一方面是科学技术和器物上的落后，另一方面，长达2000多年天朝上国的自尊，在面对英国是一种无法平等的外交状态。英国人提出以封锁海上贸易作为惩罚条件，在吾国看来根本就不是什么问题，甚至英国人不提出封锁海口，我们自己也会封关禁海。所以可以想象，当时要把吾国纳入世界贸易体系，在我们当时人看来是多么的难以理解。林则徐作为当时最积极的士子，提出的方略也没有作战的实用性，他提出的海上操舟作战之法，显然没有在水战之中得到过印证。\\n\\n因为前方战事情况，到朝廷的失真，道光皇帝在这个过程之中，也由勦到抚最终又到勦的思想转变。整个过程并没有发生实质性的改变。当然，在第一线的官员看来，其实这场仗已经完全没有胜算，也包括像伊里布这样的封疆大臣，虽然在云南有极其丰富的对少数民族的经验，但是面对强大的英国，其实心知肚明，不能硬扛。\\n\\n所谓的英勇抗战，顽强抵抗，不过是螳臂挡车的送死而已，道德上的正义不代表政治上的正确，明明知道落后，还要以血肉之躯去做抵抗，不是正确的反抗方式，但也是那个时代落后的我们最无奈的选择。\\n\\n战事结束，从道光到咸丰的十年之间，参加这场战事的12名官员，其思想也没有发生特别大的变化，包括像林则徐官复原职之后，也没有特别积极的改变。但反观日本人，佩里的黑船来袭之后，15年就促成了明治维新。并且一发不可收拾，成为东亚乃至世界强国，而我们却在百年后仍无力抵抗日寇的入侵。我们这样一个老大帝国的转变，比起日本人实在是慢得太多。\\n\\n当然幸运的是，比起印度人，至少已经发生了转变，并且迎头赶上。所以最后我还是想说，感谢英国人用坚船利炮，使我们融入了这个国际贸易体系。虽然疼痛，而且用了一百多年的时间，走了很多的弯路，流了很多的鲜血，但是今天我们能够享受这样的发展红利，其兆始就在于一百多年前的这场战争吧。"}'));jctx.push(JSON.parse('{"id": "171201", "tag": "security", "text": "# 一个加密协议定义不仔细的教训\\n\\n前天下午NetSDK组反馈在AES加密时数据，客户端和服务端对正文的padding采用了不一样的加密方式，导致无法解密。当时就觉得很蹊跷明明已经调试通过的功能，为什么这么久了还报问题。昨天下午花了两个半小时才把问题解决，现在想来都觉得是我接手协议以来遇到最屈辱的一次遭遇。\\n\\nAES加密是一种块加密，当数据不足一个块时需要填充，和RSA不一样的是，填充内容都常不在算法实现，而是由构造加密数据的人来填充。换句话说AES的API并不体现padding参数，而RSA是明确地预留了padding参数并给出了5种宏定义，这也是当初定协议时遗漏的诱因。\\n\\n于是想当然地，AES加密时不足部分就填了0x00。可是服务端在实现时从安全产品线得到一份文档，要求采用PKCS7方式填充，但并没有同步给其他团队。为什么需要PKCS7这种方式呢？要从填0x00有什么缺陷来考虑。AES块加密的特性决定了加密后的内容长度一定是16的整数倍，但源数据往往不是16的整数倍，因此接收方得到数据并解密后，需要把最后的padding数据排除掉。如果源数据是字符串，使用0x00来padding没什么关系，都能正确地解析，但如果源数据是二进制数，还用0x00做padding就没法界定源数据的边界。解决的思路就让padding数据自表示哪些是无效的，比如在所有数据的最后一个字节，表示有多少是被padding出来的。举例来说，明文数据是120字节，加密后变成128，多了8字节，加密前就在在明文数据后补上8个字节的0x08（或者补上7个0x00和1个0x08），解密后根据最后的0x08就能丢弃无用的padding字段。\\n\\n说完原因再说问题，服务端按PKCS7方式处理数据，而客户端根据0x00填充，在源数据长度不是16整数倍的情况下，填充若干个0，而服务端又根据数据最后一个字节向前回退0个字节的偏移（这里处理不严谨，按PKCS7的定义不允许出现尾字节是0的情况，一定是0x01到0x10之间的某个数），由于是0相当于把整段数据交给上层应用。目前协议是用json传输，多几个0没有关系。但当原始数据是16的整数倍时，没有做padding，但是由于json库实现的一些瑕疵，会在最后的\'}\'后带上\'\\\\n\'即0x10，在这种情况下服务端把数据回退10，导致上层得到的json数据缺失无法解析。数据长度恰好是16整数倍是个随机概率，测试时也很难发现，导致事情过了3个月才暴露。\\n\\n整个事故反思下来，教训有三条\\n\\n1. 制定加密协议时遗留了细节，导致出现流程上的盲点，还是需要自己加强知识学习\\n2. 多部门间未同步到位，致使关键信息没有同步\\n3. 服务端实现时未考虑异常情况，不是根据收到数据包来解析数据，而是预设条件导致错误解析"}'));jctx.push(JSON.parse('{"id": "171204", "tag": "protocol", "text": "# 修改能力协议的思考\\n\\n对一个视频通道获取智能能力的协议，原来的协议只有一条能力，这种描述不足在于能力有当前能力和潜在能力，嵌入式设备的能力不是孤立的，会受制于其它资源，因此协议上要有两个能力。如果只到这里为止，协议就结束了，但接下来的实现就相当地狗血。\\n\\n因为用了RPC方式，每个协议和接口对接，接口中只定义了一个caps参数，无法把协议的full节点映射到头文件。通常这种时候再增加一个接口，用来获取full能力，并在RPCServer中调用两次把能力返回也是可行的。此时第二个坑出现了，所有的接口定义在类当中，而类的接口数量是有上限的！此时这个类的32个接口都用完了。当然这种情况也遇到过，换一个类增加接口就是了。但偏偏这个类不是管理类，协议调用这个方法是通过工厂方法的instance，并传递通道号来获取类实例指针方式，比如当前的智能类名字是DevVideoAnalyse，客户端会先指定通道2获取对应的实例token，接下来通过token去访问getCaps方法，到了getCaps的实现只有token，无法映射到DevVideoAnalyse2这个实例(因为无法直接得到通道号)！变通的作法是建立token和两个类实例的绑定关系，这样一来又要多费很多周折，且为这一个方法也没有必要。\\n\\n最后的解决办法是在getCaps的请求中增加一个channel，通过channel重新获取DevVideoAnalyse2的类实例并调用方法获取full能力。当然这样做协议就显得很冗余，也是协议被实现绑架的一个例子。\\n\\n我一直对先获取资源指针并操作这种模式很反感，协议不应该暴露资源，如果不是这种模式，虽然类有32个接口数量限制，实现上并不会很丑陋。"}'));jctx.push(JSON.parse('{"id": "171205", "tag": "os", "text": "# 几个安卓ROM的体验报告\\n\\n因为手欠把flyme的stk.apk(SIM程序)删除之后，一直报com.android.phone停止运行，加上flyme用了两年也有些厌倦，TCL M2M这款机型各路网上爱好者做了很多ROM适配，故得以把几大主流厂商的ROM都体验一遍。机型为4.4，各ROM普遍是15年的版本，不新但能体验出很多差异。\\n\\nFlyme用得最久的系统，界面小清新风格比较对我的胃口，悬浮球是大特色，不过用起来总感觉会误触，还是关了。操作比较方便，各种UI设计都很赏心悦目(我的感受)，用得最久反而没什么想说的。\\n\\n锤子桌面，只用了桌面没有适配的ROM，桌面第一眼感觉很新鲜，很有设计感。九宫格布局但不能换壁纸只能换背景配色，用下来最大的不便就是非常耗内存，1G内存会经常出现回到桌面时要等待2到3秒的场景，2G的话会好很多，偶尔也会要等待不到1秒，可能3G内存会杜绝，但没有这样的手机，无法实测。操作上重于点选，对滑动支持很差，新鲜劲过去就不怎么样了。\\n\\n华为系统，EMUI桌面朴素得没法看，不知道算不算理工男的设计，总之和锤子桌面完全不具备可比性，系统功能也很理工化，但对我来说很贴心，各种流量控制、锁屏提示都很到位，内存管理不错，用了很久之后，清理任务后的内存占用和开机时是一样的，这点其它几个系统都做不到。\\n\\nOPPO的ColorOS系统，桌面中规中矩，最大的亮点是突出了音乐和拍照。桌面左划就是音乐界面，有个一键HiFi的按钮，开起后声场变大，没有具体的音效设置。打开相机甚至还有相机商店，可以下载自拍相机、慢动作相机等，不过我对相机不感兴趣，看看就好。设置界面划分成3个tab页，声音和显示各占一个，可以算是最日常的功能吧，这种划分对日常使用向的用户来说挺友好的。但开机时内存有1.1G剩余，用到后来不管怎么清理任务栏都只有700M左右的空余。一些小功能屏幕边角向中间划切换为单手模式，比如自带FTP方便的传数据，插入USB口后切换模式直接在通知栏完成，甚至可以选择仅照片模式，都是力求做到对普通用户友好。\\n\\nViVo的funtouchOS，我是和OPPO进行比较，毕竟这两个品牌的定位比较近似，但实际用下来总体感觉不如OPPO的思路清晰，系统设置的菜单做了些调整，但没有突出重点，把蓝牙藏得很深，也可能这是版本关系，至少从今年看蓝牙耳机非常普遍，因为做为一级菜单。开发者选项只能在拨号盘输入`*#*#7777#*#*`来临时打开一次，每次都要输入如此冗长的一段，不知道意图的是什么。音乐自带了BBE音效，回想起大学时买iRiver的MP3就以BBE为卖点，现在再看这种音效不过尔尔，不过其它系统都没有，也算是在音乐上做了优化。相机可以切换普通模式和专业模式，开放ISO、曝光时间，但是这些参数想来普通用户并不会买账吧。ViVo的桌面可以由用户自己创作，称之为情景桌面，完全看不到图标，只是一幅风景画，但新鲜感过后，还是用图标来得实在，对我来说手机终究是用的，不是看的。\\n\\n嘉域系统，因为ROM做得比较简洁，没有额外附加的程序，这是我用的第一个设置中直接集成ROOT开关的，可以配置每个程序是否可以访问su，定制度不高，缺少流量管理软件，真正用起来的时候后台程序流量控制不住。只能用原生的流量限制功能，限制流量的坐标轴滑条使用安卓原生，按对数增长，0～100M的操作区间很宽，越往上过渡得越快，比线性数轴要好。不过其它ROM也都一样，不算嘉域的亮点，作为原生系统的亮点也要写出来。\\n\\n联想ViBeUI系统，本来还有点期待，结果装上后彻底失望，制作者甚至都没有集成输入法，在常规的设置之外另有Tab页，但却都是些快捷操作，比如熄屏时双击home键拍照，甩手机锁屏之类。就是些奇技淫巧但又要单独出来，仿佛只有小聪明却找不到重心。开发者选项被阉割得连关闭动画的选项都没有了，每次新手机我都会把动画效果关闭，联想虽然不隐藏这个入口，却直接把功能删了，更加可恶。只用了一个下午，就决定不再使用了。\\n\\n金立Amigo系统，是西班牙语朋友的意思，起初我是不看好的，但可能是ROM制作者的用心，调整妥当后非常地好用，流量控制、后台关流量、也很省内存，是第一个原生支持修改字体的系统，缺点是铃声居然不能设置，只能按root方式直接修改系统文件夹，自带的相机程序无法使用(装第三方就行，不算问题)，另外开发者选项单单把进程统计给删除，不知何故。\\n\\n大可乐系统本身没什么要说的，制作者集成了xposed，故还在使用中\\n\\n另外小米系统最初也装过，不过时间久了没什么印象，这次就不再写报告了。\\n\\n总结下来一共8个系统加1个桌面，flyme的画风最好，OPPO的系统最友好，华为最理性，锤子桌面比较注重设计感，剩下的都没什么特色，甚至联想还要打负分。"}'));jctx.push(JSON.parse('{"id": "171222", "tag": "protocol", "text": "# 音频与声道的一些基本概念\\n\\n起因从一个对讲的bug说起。客户端在语音对讲时，一直发送的是双声道的音频文件，设备管理也按双声道解码，结果最近一款设备却实现成了只能解码单声道，最后非得客户端兼容才算把问题解决。\\n\\n所谓声道就是一个独立的可以播放的声音，对应的硬件可以简单的认为是个普通的民用麦克，采集人的声音并进行编码，这就是一个声道。虽然人只有一张嘴，却有两只耳朵，如果通过耳机播放一个声道的声音，就会出现仅单边有声单边静音的违和感，为了让听起来来自然，就把这个从麦克采集到的单声道声音复制一份，并按LRLR顺序按帧排列发送到对方，听起来就是两边有声音了。经过这样处理的声音就是双声道，尽管这两个声音是完全一样的。前文提到的那款设备，在解码时没有进行声道的处理，把每帧音频都送给同一个播放单元输出，因此造成了设备端回放声音的混乱。\\n\\n如果说对讲因为比较简单所以可以复制声道，音乐就不能这样做了，尤其是大型交响乐，舞台左右的乐器是不一样的，为了形成声音的方位感，在录制的时候会在舞台的多个点采集声音，并经过后期的调整叠加最终混合成左右两路声道，这两个声道的声音是同一首曲子，但不同的乐器会在响度和方位上的差异，给听者带来的感受就是能区分开各种乐器的方位，听起来声音就有了立体感，因此一般双声道的音乐又被称为立体声。\\n\\n家庭中常见的尤其是PC配备的2.1音箱和2声道又是什么关系呢？这个.1指的是低音单元，声音是有高中低频的(其实是连续的频谱)，一个音箱由于物理上的限制，无法完全地还原各个频段的声音，于是就有人想出把低频的声音通过低音单元放送，中高音则通过两个音箱播放。但是这就引出一个问题，音箱有3个，声道是2个还是3个？对民用产品来说，2.1音箱上播放的还是2声道声音，只是软件在播放前会把两个声道中低频部分通过低通滤波器过滤并送到低音炮播放，中高音部分送两个音箱播放，只是这种分离的做法有点生硬，所以讲究点的音乐爱好者会选择2.0的音箱，宁可牺牲低音效果，也要听到未被分离的声音。\\n\\n除了2.1，影院级的5.1或更高端的7.1就不再使用低通滤波器硬生生分离出来的声道，而是在采集的时候就额外采集一路单独的低音声道，这时就有6声道或8声道，这样播放的声音还原度、立体感也更强。"}'));jctx.push(JSON.parse('{"id": "171230", "tag": "think", "text": "# 《杀戮与文明》读后感\\n\\n这是一本相当西方自豪主义的书，写得很啰嗦很冗长，但揭示的理由还是值得看看。整本书为三大部分，创造、延续和控制。\\n\\n创造部分讲了三个希腊罗马时代的战争故事。萨拉米斯海战，希腊把自己的三艘战舰都以自由命名，将士用命，地米斯托克利也在战争的第一线，反观波斯的薛西斯却在遥远岸上看着自己的战士们死去。这一段有句话让我印象深刻，**城邦，以法律为准绳而运作，虽然规模有限，立于贫瘠的山地之上，却远胜于繁华而缺乏理性的的尼尼微都城**。正是引以为傲的希腊城邦制度催生的法制、自由使每个人都能为自己而战。\\n\\n马其顿国王亚历山大在高加米拉大败波斯帝国，依赖创造性的步骑配合，亚历山大利用长枪阵的优势，自己率领右翼军集中地如铁锤般打击在敌人战阵中，左翼则是稳如山的步兵方阵负责屠戮，这种配合下的杀人堪称高效。作者对亚历山大的评价，和希特勒的闪电战一样，都是战争上的天才。当然作为反衬，可怜的波斯人再一次因为没有信仰，只知道捡钱而缺乏持久的战斗力，最终败给了不杀光不罢休的马其顿军队。\\n\\n坎尼会战评价更绝，这是汉尼拔以新月战诱敌深入并歼灭的的经典之作，但作者并没有花重笔墨地赞美汉尼拔，而是用罗马军队在此战后一年迅速恢复元气为依据，再次强调公民兵组织的动员性，最终汉尼拔因为缺少支援只能返回腓尼基并最终以失败结束了布匿战争。\\n\\n延续的三场战役来到了中世纪，普瓦捷战役是查理马特率领的法兰克士兵抵挡了阿拉伯人的北进，终止了穆斯林对欧洲文明的入侵。这场战争是重装步兵对骑兵的胜利，步兵、骑兵或是弓箭兵没有谁完胜谁的说法，步兵最好的兵源来自农庄，因此要有一支强大的步兵，必须有健康的农庄经济，再一次作者强调了公民社会传统的影响，而骑兵显然是游牧民族的强项，而游牧民族是很难孕育公民社会的，但是从当时的浮雕看，马仅仅是运输工具，真正的战斗是下马的（个人理解是没有马鞍）。另外要给一支步兵提供给养，必须后方有强大的协调组织的资源支撑能力，非公民社会不具备这样的基础。另外中世纪的欧洲十字弓被称为穷人的武器，只要很低的成本就能打击需要巨大成本养成的骑兵，教会甚至限制了十字弓的使用。\\n\\n勒班陀海战中，欧洲军队拆掉了帆船的撞角换成火炮，虽然帆船数量少于奥斯曼舰队，但火炮数量却多很多，不仅数量，质量也精良得多。奥斯曼的火炮却只能用来作为原材料。除了火炮，欧洲舰队也广泛使用火枪，而奥斯曼却因担心民众不稳定，只敢训练弓箭手（甚至不敢印刷书籍），训练周期长不说，战时还容易疲劳，经此一战更折扣大量训练有素的弓箭手。另外分工的精细化，使当时威尼斯最快能在1小时内下水一条帆船。由于缺乏银行系统，奥斯曼的将帅们不得不在船上放着大量金币。\\n\\n罗克渡口是一场先败胜的战役，在大部队输掉之后，一股不足百人（投入战斗约80人）的分队顶住了4000祖鲁人进攻，原因就在于坚强的纪律性。作为反例的祖鲁人虽然早就从欧洲得到享受了火器，却始终无法有效地运用(前填充燧发枪没有好的战术素养确实起不到什么作用)，因此祖鲁人仍然习惯了使用短矛。英国人在战争中携带大量的辎重，一个150磅的士兵会携带10磅的武器和60磅的补给，而当地糟糕的交通环境导致在天气好的时候一天也只能行进5英里。而祖鲁人的轻装上阵也导致无法使用火器，在罗克渡口的士兵甚至两天没有吃饭，战场上检视尸体发现祖鲁人嘴里都还塞着食物。"}'));jctx.push(JSON.parse('{"id": "180101", "tag": "web", "text": "# 使用DroidScript开发安卓程序\\n\\n本来是想用ionic在手机上做些开发，但不知什么原因安装失败，发现一个叫DroidScript的安卓程序，可以在PC端浏览器连接手机，并在浏览器上进行编码调试。支持HTML和App两种开发模式，从通用性来说肯定是HTML好，App支持的插件丰富一些。\\n\\nHTML模式本质上是原生程序中内嵌了web页面，布局在四边稍有些空白，可以访问完整的window对象。虽然具备XMLHttpRequest，但可能是受限于跨域，另外提供了HttpRequest方法进行网络通信，可以向任意地址请求，HTTP头也没有Origin字段。至少支持get/post/put/delete方式(其它几乎没有使用，不测了)。参数只能以URL Encode方式编码，也就不能像jQuery那样写成json并由jQuery去转换，略有些不便。更坑的是分隔符居然用`|`而不是标准的`&`，如果用`&`程序会强行转码导致PHP上无法从`$_POST`找到希望的key。使用get或delete时，参数只能通过url方式携带，而post或put则一定在request body中。\\n\\n比如发起这样一个请求`httpAjax(\\"delete\\", \\"/index.php?t=3\\", \\"id=1|name=jojo\\", handleParam);`，抓包可以看到变成了`index.php?t=3?id=1&name=jojo`，强行把url和参数用?符号连接起来，导致后台如果用PHP解析，把`3?id=1`当作t的值。\\n\\n多字节字符支持得很差，界面上无法输入中文，甚至复制中文后就不能再输入了，只能尽量用英文。导致一个更不方便的问题，写的中文日记无法提交，只能先将中文用JS的encodeURI转码再附到提交数据上，但这样和PC端Web上提交的内容不同。比如**看**字，PC端抓包是`%E7%9C%8B`；而经过encodeURI转码后的看字，抓包则是`%25E7%259C%258B`，两者比较前者9字节后者15字节。重复的部分就是`%`后面的字符要怎么解释，encodeURI相当于%要转译两次，因此负载密度很低。通过base64解决这个问题，但base64的结果会有=，因此用encodeURIComponent方法把=也进行转码。建议用带Component的方法，因为encodeURI不对+=等特殊字符转码。\\n\\n支持很多特性，但Reference没有写只能从Demo去看。写好的程序可以打包成apk，Img目录如果有和工程同名的png文件，则该文件会作为apk的图标。支持debug和release签名。如果是release方式需要先生成私有的keystore文件，以后输入密码就可以打包了。\\n\\n## WebServer\\n\\n支持创建服务端，并能上传和下载文件，但是上传功能并不明显，通过自带demo发现，当在CreateWebServer的option指定Upload，就能以POST方式发起upload请求，形如` curl -F \\"DB=@a.db\\" -F \\"DB1=@b.db\\" ip:port/upload`，其中-F后面的字段可以随意指定，会自动创建同名文件夹。"}'));jctx.push(JSON.parse('{"id": "180102", "tag": "book", "text": "# 青泽《澄明之境》文摘\\n\\n前言：体悟金融市场的“炼金”之路\\n\\n1. 要成为一个投资家，你必须是一个投资思想家。\\n2. 哲学是观察世界的角度学，角度一变，世界就变了。\\n3. 不可能找到百战百胜、完美的市场交易理论，必须放弃寻找“投资圣杯”的努力。\\n4. 多则惑，少则得。\\n5. 单纯的眼睛看到的是单纯的世界，复杂的眼睛看到的是混乱的世界。\\n6. 所谓的交易境界，指的是投机者在洞悉了技术层面的局限性以后，有了自己的投资哲学和思想体系，通过构建相对合理的交易策略和风险管理办法，在交易世界放弃完美，进退有序，淡定从容的心境。\\n7. 交易绩效的稳定，并不是技术的问题，而是放弃的学问。\\n8. 如果交易和战争两者真的有相似之处的话，战争者应该具备什么样的精神态度，投机者也应该具备什么样的精神态度。\\n9. 收心、守心、修心。修心讲的是日常具体事情中修炼自己的心性。\\n10. 交易不仅仅是知识的学习、接受过程，更是一场投机者品性的修炼。\\n11. 如果只是看过，明白，就能懂得，做到，那和尚修成佛陀岂不是和上大学一样简单？\\n12. 投资投机的事业更接近佛学的修行，别人的规矩原则，是别人的，即使告诉你，也还需要你自己去领悟去证得。\\n13. 巴菲特说：“一个在小事上无法节制的人同样在大事情上无法节制。”\\n14. 知道不是力量，相信才是力量。\\n15. 有信仰的人，观点是单纯的，意志是坚定的。\\n16. 单纯的具有知识的人仍然容易陷入矛盾和纠结中，容易在市场交易中迷失方向。\\n17. 投机客是“行者”、“忍者”而非“学者”、“智者”。\\n18. 投资人生是一条艰难的路，需要经历一次茫茫荒野上的艰辛跋涉。\\n\\n第一章：我的投资人生\\n\\n19. 一个仅有十年投资经历的人，感悟和思想会有多深刻呢？也敢写书？\\n20. 书不是写出来的，而是无数金钱和痛苦绝望堆出来的。\\n21. 如果在读者看来这本书字字珠玑，那么在我看来这本书字字血泪。\\n22. 叔本华说，“一颗大树想要到达天堂就必须进入最深的土壤，它的根必须进入地狱”。\\n23. 人生的智慧一定来自于痛苦。\\n24. 少年得志乃人生之大不幸。\\n25. 斗争哲学最不适合做期货。\\n26. 一头猪飞起来的唯一办法是去寻找风口，而不是花时间精力去琢磨让自己长出翅膀。\\n27. 什么是哲学家/投资家：在理性的指导下，能够保持自我克制的人，而不管他知识多少。\\n28. 人只有被逼到万般无奈之中，才会去思考一些深层次的问题。\\n29. 如果要在市场取得成功，投机者应该做出正确的决策，而不是做出让自己感觉舒服的决策，心理上很舒服的交易，结果往往不好。\\n30. 成功的投机者离不开辩证思维的大智慧。\\n31. 模糊是美，缺陷是美，简单是美。在技巧上追求完美，在利润上追求极限则恰恰不是美，而是与美的真实背道而驰。\\n32. 从长远角度，期货交易成功必须要有一个系统、完整的交易思路，包括的合理的交易理念、策略、方法、工具；良好的风险管理制度；正确的人生观、价值观等。\\n33. 违反交易原则和体系的冲动是投资成功的大敌。\\n34. 知识可以传授，经验不可传授。\\n35. 即使你具备了足够的知识，没有经验，你连纸上谈兵都谈不清楚。\\n36. 期货交易是一个个人英雄主义的孤独游戏，需要自我独立决策，并承担由此引起的最终后果。\\n37. 投资成功的核心不是去抓更多的机会，而是耐心等待，把某一个机会用好，把一个品种做精，当机会来临时，用极大的意志力把交易机会用到极致。这样的交易效果远比发现十次交易机会，每一次都浅尝辄止要好得多。\\n38. 投资理念是一个内涵丰富的概念，包含着一个人的投资目的、投资哲学、投资理论、投资策略、投资风险管理等很多方面。完整的投资理念需要从抽象到具体，把交易各个环节、各个要素系统地整合在一起，形成一个能够自圆其说的逻辑链条。\\n39. 戒（有所不为）、定（目标专一）、慧（技术精进，由术转道）。\\n40. 收心（有舍有得）、守心（耐心等待）、修心（功夫在诗外）。\\n41. 知道、相信、信任、信仰。\\n42. 一旦选择了投资人生的冒险之路，回到过去已经不可能了，未来的命运已经远远超出了你的控制力和当初的想象。\\n43. 青泽投资哲学：投资的理论、模型、假设决定市场观察和操作。\\n44. 心由境造or境由心造\\n45. 为学日益，为道日损。内化于心，外化于行。尽人力，听天命。\\n46. 期货投资，与其说是技术，不如说是艺术，与其说是赌博，不如说是拼搏，与其说是做盘，不如说是做人。每一张单都透射出人性的色彩，品性的贵贱。\\n47. 推荐书籍：《股票大作手回忆录》丁圣元译。\\n\\n第二章-投资市场需要哲学智慧\\n\\n48. 你越急功近利，越想挣钱，反而越挣不到钱。\\n49. 马克思主义哲学简单归纳为三条：世界是物质的，物质是运动的，运动是有规律的。\\n50. 康德，先验哲学，三大批判。康德哲学是西方古典哲学和现代哲学的分水岭。\\n51. 哲学有一个功能是锻炼人的思维能力，如果你经常看康德的书，你会变聪明。\\n52. 康德的先验哲学综合了经验论和唯理论，试图更加深刻全面地解决科学知识为什么能成立的问题。\\n53. 在康德的哲学里，物质世界表象背后并不存在着一个秘密的规律、本质，等待着科学家去寻找、发现。自然科学规律的发现需要科学家带着理论模型、科学假设去观察世界、拷问世界，通过对比，才能知道自己的理论正确与否。\\n54. 如果投资者头脑中没有事先预定的理论、原则、框架、模型，毫无目的地观察市场，看到的只能是市场价格随机的波动。\\n55. 知识不能单纯从经验中得出，而只能从理智的发明同观察到的事实两者的比较中得出。\\n56. 先有理论，后有观察。理论不是发现，是发明。\\n57. 科学不是发现，而是发明。人为自然立法。\\n58. 人为市场立法。\\n59. 市场背后并没有什么所谓的规律、本质，你用什么样的理论和思想去看待市场，给市场定位，你就看到了什么样的市场，你就会有什么样的投资行为模式。经纬度的举例。键盘字母排序。\\n60. 什么样的理论选择决定了你看到什么样的世界。\\n61. 谁对谁错，重要吗？说得清楚吗？\\n62. 你如何看待市场，得出一个什么样的结论，完全取决于你自身的眼光。你用短期的眼光去看，得到短期的结论；长期、基本面、技术面。\\n63. 胡雪岩：你有一个乡的眼光就做一个乡的生意，你有一个县的眼光就做一个县的生意，你有天下的眼光就做天下的生意。\\n64. 投资市场需要大智慧、大格局。\\n65. 投资者不能像个傻瓜一样跟着市场跑，让市场价格变化决定你的投资行动。（难道不是让市场价格变化决定行动吗？量化就是这样啊）\\n66. 真理是有限的、相对的，没有规律性可言。\\n67. 如果金融市场有规律，那也不会是长久的、永恒的。\\n68. 投资哲学的高下决定了每个人不同的投资人生。有些人即使短期赚钱，志得意满表象下其内心世界是虚弱不安的，眼神是迷茫的，对未来是缺乏信心的；而有些人即使阶段性做得不好，其思路是清晰的，目标是明确的，说话是低调的，眼神是淡定的，内心是平静的，对未来是胸有成竹的，能够达到“未战而先胜”的境界。\\n69. 投资市场高手之间的较量，绝不是技术水平的较量，而是投资哲学、投资理论的较量。投资哲学和投资理论决定 了你的眼光和境界，也很大程度上决定了你是一个什么样的人。\\n70. 不要问别人行情，别人永远不可能告诉你正确答案。\\n71. 聪明的投机者只有在机会来临时才做事。\\n\\n第三章-投资理论\\n\\n72. 投资理论只是对市场的一种解释，不同的投资理论对市场有不同的解释，甚至可能相互矛盾。没有完美的理论。\\n73. 投资理论：价值投资理论、趋势跟踪理论、反身性理论、均值回归理论等等。\\n74. 单纯的眼睛看到清澈的世界，复杂的眼睛看到混乱的世界。\\n75. 世上很多事情道理是相通的，少而精往往胜过多而博。\\n76. “基本分析是一种让杠杆交易者死得很体面的理论”。\\n77. 对于杠杆交易者来说，一个短线交易者如果非要刻板地按照基本面方向操作，当市场出现不可避免的大幅逆向波动时，还固执已见、自以为是，即使长期方向没错，市场短期波动也可以置你于死地。\\n78. 你很对，但你死了，不过死得很体面。\\n79. 硬币都有两面，你在接受它优点的同时也得承受它缺陷。\\n80. 我用趋势和结构思想来理解市场，对市场进行定位。趋势、结构理论是我的投资理论的核心，也是我交易体系和别人区别较大的地方。\\n81. “虽有智慧，不如乘势”、“天下大势之所趋，非人力之所能移也”\\n82. 结构：通常是指市场趋在演化过程中间出现的停顿、反向运动的中间状态。\\n83. “耗散结构”：偏离平衡态的新的稳定有序的结构。煤气罐、水库里的鱼。\\n84. 我把市场价格运动分为结构内、结构外、结构临界状态三种情况。结构内，价格运动非常随机、无序，结构临界状态，价格运动非常不稳定，结构外，价格运动有很大的有序性、必然性。这个“趋势+结构”理论，是我制定操作策略的基本依据。\\n\\n第四章-投资风险和心态\\n\\n85. 投资心态的培养没有捷径可走。专注执着，追求自然而然的境界，是一个人做好任何事情应该具备的优良品质，期货行业更是如此。\\n86. 坏的结果往往是由好心促成的。\\n87. 围棋十诀：不得贪胜，入界宜缓；攻彼顾我，弃子争先；舍小就大，逢危须弃；慎勿轻速，动须相应；彼强自保，先势后地。\\n88. “我从不追求妙手”“我从不想一举击溃对手”\\n89. 四道防线：仓位管理；时间止损、主动止损；被动止损（价格止损）；单日风控底线、净值管理。\\n90. 空谈投资心态没有任何意义，良好的心态不可能一蹴而就，而是在艰难、漫长的死亡游戏中，只有死里逃生的残存者才有资格谈论的话题。\\n91. 《对冲基金回忆录》：只要你进入了投机这一行，这辈子就休想再有无忧无虑、安逸的日子，内心永远会处在焦虑和煎熬之中，世界上根本就不存在良好的投资心态这一说。\\n92. 期货交易的技术和知识，也许学一两年时间就够了，但是，投机者要培养一个稳定、良好的心态，即使花上十年工夫，也不算多。\\n93. 巴菲特说：“无论你多有天分，也无论你多么努力，有些事情就是需要时间。让九个女人同时怀孕，小孩也不可能在一个月内出生。”\\n94. 我们必须勒住自我欲望的缰绳，舍弃十八般武艺样样精通，企图打败市场的非份之想，永远只追求属于自己的利润。（应该具有投资心态）\\n95. 任何高超的交易技术背后都必须具备高度统一的精神支持，才能发挥巨大的威力。\\n96. 稳：耐心；狠：重仓；快：果断。\\n\\n第五章-投资思路与策略\\n\\n1. 交易之道由心开始，次正理念，再次策略，最后技术。世人反其道而行之，故事倍而功半，期货交易首正其心。\\n2. 林广茂棉花之战总结：目标明确、思路清晰、意志坚定、市场配合。\\n3. “如果你天天坐过山车，时间长了，就能在过山车上睡着了”\\n4. “风格就是你的背影”\\n5. 越是成熟的交易员，个人交易风格越鲜明，思维和行为方式具有逻辑性和前后一致性。\\n6. 两种成功的风格：顺势轻仓止损长线；顺势重仓，相对短的止损，中短线。\\n7. 频繁的交易基本判了你死刑：不要盼望你能在高抛低吸的短线交易中获胜。\\n8. 平仓策略取决于你是个什么样的交易者，也就是取决于你的交易风格。如果你是短线就用短线平仓策略，长线交易者就长线平仓策略:趋势反转了再出场。\\n9. 伯克希尔就是通过把赌注押在有把握的事情上而赚钱的。\\n10. 我越来越相信正确的投资方式是大部分的资金投入在自己认为了解且相信的事业之上，而不是将资金分散到自己不懂有特别信心的一大堆公司。\\n11. 幅度取胜、仓位取胜。\\n12. 期货市场是一个以金钱的输赢论英雄的游戏，而不是投资者之间谁掌握的知识多，谁的投资技巧高，谁就是赢家。\\n\\n第六章-投资信仰\\n\\n1. 信仰是什么？信仰就是桥上的栏杆。\\n2. 信仰是指某种主张、主义、宗教或对某人、某物的信奉和尊敬，有一种坚定不移的看法，并把它奉为自己的行为准则。\\n3. 有信仰的人，心底会有希望，意志会更坚定，遇到困境会迎难而上，去实现自己的理想。\\n4. 知道不是力量，相信才是力量。\\n5. 小智为财奴，中智为克已，大智为信仰。\\n6. 刘强：“资本市场就是把钱从内心狂躁的人的口袋里流到内心安静人的口袋里的一种游戏”\\n7. 只有信仰才是我们灵魂的拯救者，才是交易智慧的坚实基础。\\n8. 知道、相信、信任、信仰。相信与信任，走钢丝的例子。\\n9. “读八百本书，无外乎顺势而书”\\n10. 冯友兰先生在《中国哲学简史》中提到人生有四个境界：自然境界、功利境界、道德境界、天地境界。\\n"}'));jctx.push(JSON.parse('{"id": "180112", "tag": "os", "text": "# 安卓root原理小记\\n\\n最重要的两个分区system和data，这两分区默认只读，因此不能删除预装程序。要设法把su写到system分区，最好还要有daemonsu（守护的目的还不清楚），magisk能在不改动system分区的状态下实现root功能。data会做加密，具体原理不明。\\n\\n但并是不是把su写入system分区就完成了。这涉及安卓程序的启动顺序，系统是由boot加载的，如果boot内记录了出厂时system分区的签名值，就会拒绝启动写入su的系统，导致系统会halt住。所以锁机的型号一定要最先做unlock，使boot不再校验system分区是否和出厂一致，这样写入su才有意义。Nexus和杂牌不会锁机，像小米或华为的部分机型，需要在官网提交申请才能解锁。\\n\\n现在问题归结为怎么使system分区可写，有两种途径\\n\\n1. 利用运行期漏洞提权，重新mount system使它可写\\n2. 启动时将system分区加载为读写方式并写入su\\n\\n第一种方式常见的形态是一键root软件（安卓版或PC版），会根据系统版本选择合适的漏洞。\\n\\n第二种方式比如重新线刷boot.img，因为启动信息是以RamDisk方式打包在boot.img里，只能重新生成一个boot程序替换，强制引导为读写方式，如果没有好心人去编译对应硬件的boot，就只有等待了。Magisk就可以针对原始的boot.img打patch生成新的boot.img，将这个patch的boot.img重新写入bootloader就能达到root的效果(理论上，未试出来)。可以从厂商提供的线刷包提取，某些recovery也提供boot分区备份，也能得到boot.img。\\n\\nfastboot命令可以向flash烧写boot，但有两个前提：电脑上安装手机的驱动，使adb能识别出手机；手机要处在解锁状态，才能在adb reboot-bootloader后，再fastboot flash boot patchboot.img写入，否则进入bootloader会无限循环。\\n\\n## boot.img的内容\\n\\n文件解压得到kernel和ramdisk.gz两个文件，奇怪的是ramdisk用了多种解压软件都没辙。封包格式是安卓自定义格式，前8字节是`ANDROID!`，接着是kernel和ramdisk大小，board name/签名等一系列内容。\\n\\n## 启动流程\\n\\n通常开机到进入桌面会经历下面3个阶段（recovery模式不确定要不要经过boot.img）\\n\\n```\\nfastboot/bootloader -> boot.img -> system/data\\n```\\n\\n结合magisk的systemless做法和必须要给boot.img打补丁，大概率是在boot.img做了手脚，从而能旁路system的只读保护。但仍然需要解开BL锁，才能写入boot.img。"}'));jctx.push(JSON.parse('{"id": "180119", "tag": "protocol", "text": "# 人脸查询协议的理解\\n\\n一个人脸查询协议反复看了大半年，每次看都有新的体会，直到现在我也不确信是不是完整理解它。\\n\\n人脸比对涉及两种对像，历史库和注册库，保存的虽然都是人，但历史库是对人一瞬间的描述，注册库则是对人精确描述，两者差异极大。比如年龄，在历史库是年龄但到了注册库却变成了生日，同一件事要用两个角度去解释。\\n\\n既然两种不同性质的库，查询条件就应该不一样，合在一个接口已经容易引起误解，偏偏最重要的，从哪个库查询字段却放在中间很不起眼的位置，人的理解思维总是头尾相对容易重视，中间如果太多往往会不耐烦地跳过，偏偏这个协议的协议字段有二十多个。\\n\\n我的调整是，首先按历史库和注册库拆分成两条协议，并对查询条件分类。比如上面提到的年龄，另外像历史库用到的眼镜和注册库用到的家族住址。\\n\\n除了指定信息查找外，人脸还有种好玩的查询叫以图搜图。给一张照片，会返回若干张和这个照片最像的候选人像。如果有图片，图片本身就表示了一切属性，此时检索条件又不一样，因此又再细分为信息查询和以图搜图。而以图搜图的条件也多是一些模糊性的条件，比如按人脸哪个区域比对（选眼睛还是鼻子）。\\n\\n经过这样分解拆分成4条协议，再结合对业务理解，可读性才勉强到可用的程度。\\n\\n再说说库相似度。有需求要求修改人脸库时可以修改相似度，最初我也觉得可以，但经人提醒意识到，为什么会有相似度，是因为人脸识别算法的不准确性需要阈值，但既然是阈值一定要结合当时的环境一起考虑，不应一概而论。环境就是视频通道，经过讲解让需求方接受了这个用法。看一个概念要理解其背后代表的含义和适用场景，否则就容易用偏。"}'));jctx.push(JSON.parse('{"id": "180129", "tag": "os", "text": "# 小鲜4刷机反思\\n\\n上周买了一个安卓机，事先查好各种资料确定可以刷机才下的订单。然后到手后足足用了5天才线刷成功。\\n\\n第一天徒劳无功地反复操作软件、装驱动各种瞎折腾没有任何收获，虽然当天快12点换了win10系统，但仍然不成功。但大概知道原因出在数字驱动签名。\\n\\n第二天查阅数字驱动的关闭方法，按照网上最多的说明通过重启方式进入，但因为系统原因找不到这个菜单，仍然是换win10可以，即使这样也没有进展。倒是知道还能通过组策略gpedit方式关闭，不过并没有任何帮助。这一天至少刷机时MTK的红色刷机条能走完，查看了资料知道是一个叫Download Agent的程序写入CPU的RAM，但是数据还是无法写入Flash。\\n\\n连续两天折腾下来也比较心累了，估摸着换win7会好一点，第三天没有刷。\\n\\n第四天找到一台win7电脑，装驱动的时候确实提示无视数字签名，感觉离成功近了一点，但最后仍然提示驱动安装失败，仍然无果。\\n\\n第五天，既然三个系统都试过，只好静下心来反思每个步骤，在安装驱动的最后失败界面，系统提示文件无法找到。以前从来不在意这个提示，走投无路之下用这个作为关键字搜索，竟有意外收获，网上有一篇很详细的介绍，还附带了两个安装包。其中一个显示是win7用，安装失败，但另一个成功了，结果到了最后一步还是提示缺少inf文件。介绍文章也用的是win8，和我的一样，有些气馁。但想想都走到这一步了，不妨再试试win10，竟然非常顺利地插上线就开始写Flash了！问题找到就是驱动不对。5分钟后刷机成功，系统得到root权限。\\n\\n反思这个问题，如果第二天结束的时候能仔细留心提示的错误信息，用搜索引擎显然是能找到正确的解法的，只怪当时没有沉下心来找原因，只想着换系统，直到山穷水尽才发现其实路早已在那里。不过可惜的是主力机win8一直都不能成功，可能和系统文件有缺失有一定关系，刷机已结束，教训也有了，就不再尝试了。\\n\\n4月补记，拿到一台xplay3s，root过程也不平坦。\\n\\n先用教程一的方式，用PC端工具写入recovery，再导入root.apk包，这个包含有su和授权管理程序。但不知道是fastboot未解锁或其它原因，recovery没有写入，可想而知用官方recovery写入root.apk遇到签名失败问题，此路不通。\\n\\n教程二提供了adb的命令行方式写入recovery方式，但执行过程遇到无法找到su错误。再看教程介绍，要先用一键root工具。结果工具root不成，反而装上了kingroot和另一个垃圾软件，而且这两个垃圾软件还不能卸载！说明安卓一定有机制允许未root设备向只读分区写文件，又有一种可能就是su被暂时写入tmp分区，从而实现apk写入只读分区。其实当时我并没有想到这个问题，只是抱着试一试的心态又点击了一次adb写recovery。重新进入recovery模式后，发现居然已经烧写成功了，而且大量的垃圾软件已删除一空，包括kingroot也没有了，但另一个附带的垃圾软件还驻留着。\\n\\n到这一步毕竟比出厂情况要好太多，接下来就是下载第三方已经集成好root的安装包，重新完整写入就获得干净的系统了。"}'));jctx.push(JSON.parse('{"id": "180209", "tag": "protocol", "text": "# 查询协议与资源回收\\n\\n遇到一个查询业务资源未回收的问题。查询的返回数量不确定，因此会有同步和异步的方式考虑有两种返回形式。如果是异步，在查询前传入一个回调函数，所有的查询结果逐步回调给调用方。如果同步方式，由查询方每次给出一个偏移量和一次查询的数量，逐步地查完。这次的问题就出在同步方式上。\\n\\n由于是个连续的过程，第一次查询会返回一个句柄号，接下来的查询每次都从这个句柄获取，查询完成后释放该句柄。暂不考虑客户端恶意查询而不释放的问题，当网络断开时，也会存在句柄未关闭从而导致资源泄露问题。原因在于定义查询接口时，和其它的业务定义在同一个类里，而所有的类要服务化，都以单件的形式存在，当网络断开时即使协议库调用了析构函数，实现侧无法做到查询句柄的回收。\\n\\n服务化和单件不是错，但对这类存在资源分配的业务，把接口都定义在单件中，就使得单件拥有了两种不同生命周期的业务，增加了维护的复杂度，这种情况要避免。"}'));jctx.push(JSON.parse('{"id": "180219", "tag": "web", "text": "# PHP的一些语言特性\\n\\n## 程序辨析\\n\\nphp包装好后，会有php和php-cgi两个很容易混淆的程序（php-fpm单开一篇讲），这和php最早就是作为web开发语言有关。其它的脚本语言，主要都是运行在cli下，通过一些库也能运行http程序，但不是程序核心部分。虽然我没有证据，但初版的php语言可以认为只有php-cgi。在这种模式下，输出要服务于html，因此所有的文字都会包裹上适当的html标签。随着php的发展，也有人把它用于终端开发，这时就有了php程序，此时的输出就是纯粹的文本。\\n\\n## ini默认配置\\n\\n启动时会读入php.ini配置文件，虽然不读也可以，但鉴于常用选项太多，最好还是配置一下。因为有些扩展，如果不在ini文件中指定是不会加载，虽然可以通过dl手动加载，但毕竟没有ini直接指定来得方便。其它语言虽然也有类似机制，但远没有像PHP这么重视启动加载文件。\\n\\n## 动态性\\n\\nPHP的动态特性让人印象深刻。\\n\\n首先是字符串可以在一定程度表示函数。比如`spl_autoload_register`函数传入的参数是string，实际对应的是同名函数。\\n另一个例子是构造一个对象$obj，再定义一个字符串变量$foo=\'bar\'，用$obj->{$foo}()的方式就可以调用$obj实例的bar方法。\\n\\n从字符串推导出函数就是反射，对动态语言来说并不是独一无二的能力，但PHP把字符串直接映射函数这个特性，结合到部分特性的上下文，做成了很好用的语法糖。\\n\\n所有语言动态能力的源头都是eval，PHP/JS/Lua都有这个函数(Lua对应load)，比如eval(\'$abc=123;\')执行后，$abc就可以使用了。JS的书中对eval的闭包有很详细的解释，eval最重要的参数是环境，不填有可能是当前环境或根环境，不同语言偏好不同。\\n\\n再说说观察者模式和语言的结合，PHP支持SplObserver和SplSubject。在Ruby中也有类似的observer模块。差异是PHP的notify时是把SplSubject整个对象传给SplObserver对象，而Ruby可以传递任意个数的参数，多少也体现了Ruby语言的灵活。\\n\\n相对路径是程序中很容易引起混淆的地方，比如`__DIR__`或`__FILE__`变量，单独执行时很容易理解，但从另一个文件载入这个文件时，值并不会变化。原因是这个变量是从属于被执行的文件，并不会随着调用方而变化。\\n\\n## 自动加载\\n\\n要使用composer生成的自动加载代码，除了在调用端和源端按规范使用命名空间外，最重要也最容易忽视的，就是要配置好composer.json和生成加载代码。\\n\\n假设项目目录是这样\\n```\\nProject\\n|__composer.json\\n|__main.php\\n|__lib/\\n    |__A.php\\n|__vendor/\\n    |__autoload.php\\n```\\n\\n假如代码在lib目录下，务必在项目顶级的composer.json加上\\n```\\n    \\"autoload\\": {\\n        \\"psr-4\\": {\\n            \\"your-namespace\\\\\\\\\\": \\"lib/\\"\\n        }\\n    }\\n```\\n之所以显得有些啰嗦，是因为还存在psr-0和files方式，所以必须在autoload节点下再嵌套一层。\\n\\n然后在main.php使用`use your-namespace\\\\A`，而在A.php中定义`namespace your-namespace`。\\n\\n到这一步还不够，必须要手动执行一次`composer dump-autoload -o/-a`，-a表示一旦找不到就不再查找，而-o还会尝试按psr4方式再找一次。至此加载器才能正常工作。说明加载器并不是全自动的，而必须要手工介入，且最顶级的命名空间，是用配置绑定，并不要求命名体现在文件系统上。\\n\\n看过vendor/autoload.php的源代码就可以知道，所有加载类的路径，都是事先在代码中保存在一个array变量classMap里，并不是运行时拼接路径加载，所以运行前执行一次dump-autoload就好理解了。\\n\\n简单解释一下autoload的源码，vendor下的autoload.php只是一个入口，先加载autoload\\\\_real.php，虽然名字带了real，并不是真正的加载函数，还要依赖ClassLoader.php和autoload\\\\_static.php，这两个类各有分工，ClassLoader负责调用spl_autoload_register，而static则提供classMap，这两个类在调用链上经过Closure::bind被绑定到一起。\\n\\n## stdClass\\n\\n用`json_decode`函数，却不能直接用[\\"name\\"]取值，原因是返回的是类型为stdClass的值，既然是对象，就要按对象的语法`->{\\"str\\"}`取值。\\n\\nstdClass有点像Java的Object味道，当然它是类不是对象。也可以new stdClass()创建一个什么都没有的空对象。\\n\\n对象和array看起来很像，能表达的内容也差不多，目前所知最大的差异就是在赋值时，array会把所有元素的值全拷贝一遍，而new得到的对象，赋值后只是一个引用，拷贝对象是几乎没有开销的。\\n\\n从语言历史来看，array在PHP4时代就出现了，而完整的对象语义直到PHP5才成形。而引用也是相对高级的特性，因此和对象关联在一起也就好理解了。\\n\\n## 源码结构与SPL\\n\\n最主要的3个目录，Zend/ext/sapi。Zend编译虚拟机，ext是标准库和常用扩展库，如PDO/XML等等，sapi则是最外层的接口。三个层次非常清晰。\\n\\nPHP的`file_get_contents/fopen`可以直接打开url，即直接获取网页内容。这些接口虽然简单，但一来灵活性低，另外只能阻塞没有超时设置标志，因此还有一种层次更基础的fsockopen，是socket的封装，且可以控制超时时间。如果要通过fsockopen来获取HTML页面，要自己封装请求，HTTP1.1需要至少3个字段，除了方法还必须Host和Connection才能取得网页。\\n\\n做C++开发的人都知道STL，对于PHP来说对应的就是SPL(Standard PHP Library)了。这是从PHP5时代开始发展并成熟起来的技术。所有SPL的函数以`spl_`开头，除了函数还有若干窗口类的接口，比如SplHeap、SplStack等，另外就是迭代器和异常。\\n\\nURL的禁则：`+`号是要转码的，但是奇怪的是form中如果输入空格，空格会转成`+`。而真正的`+`会用%转码。PHP有个函数叫parse_url，能把url拆成path和query，但是又不做转码。"}'));jctx.push(JSON.parse('{"id": "180223", "tag": "book", "text": "# 指数编制分类说明\\n\\n一，价格加权指数\\n\\n价格加权就是股票价格越高，对指数的影响越大，不计算市值。美国著名的道琼斯指数就是按照价格加权编制的，是“道氏理论”的创始人查尔斯·道编制的全球第一只指数。缺点是贵的股不一定是大的股\\n\\n二、市值加权指数\\n\\n按照市值大小分配比重，市值越大的股票涨跌对指数影响越大。\\n\\n市值加权指数的缺点：\\n\\n1.大市值股票对指数影响过大，不能完全反映市场整体情况。\\n我们经常看到的指数，绝大多数都是市值加权指数。\\n\\n三、基本面加权\\n\\n根据基本面财务指标对股票进行权重分配，财务指标显示股票越低估，给予的权重越大。如果某只股票涨幅过大，导致价格偏离基本面过多，指数则会调出该股票。\\n\\n说个实际的例子吧，基本面50指数(000925)就是基本面加权指数，该指数从营业收入、现金流、净资产、股息四个指标去考虑，选择了50家规模较大的公司，也可以理解为上证50指数的升级版本。\\n目前市场上唯一一只跟踪基本面50指数的基金是嘉实基本面50（160716），明显看出走势要稍好于上证50\\n\\n四、等权重指数\\n\\n等权重指数属于一种比较新颖的策略指数，它的成份股的权重都是一样的。比如沪深300等权指数(000984)，也就意味着中国平安与雅戈尔的权重一样，比重都是1/300.\\n\\n等权重指数中，当某只股票涨幅过大时，会被动卖出部分仓位，同时买入涨幅并不大的股票，从而实现指数成员之间的平衡。等权重指数类似于动态平衡策略，在指数编制规则中加入了低买高卖的机制。\\n\\n在等权重指数中，小盘股的话语权更大，也意味着波动会更大。\\n"}'));jctx.push(JSON.parse('{"id": "180225", "tag": "book", "text": "# 春秋故事\\n\\n夏未必有文字，商将文字用于祭祀，到春秋尤其是战国，随着吞并的加剧，大国将小国作为县来管理，始有吏治，并以文字文书作为行政手段，经秦完善成后世的律令制度。\\n\\n儒家典籍称为经，有经必有纬。所以汉代产生了谶纬之学。这些学说承担起为中国、天下、夷狄的正名之责。当这套话语体现确立后，纬书便没有那么重要了，加之纬书中加入了很多为汉王朝合法性的说明，反而不利于后世政权，自汉以后纬书便式微了。\\n\\n战国在汉代一直被称为六国之世，为了突出汉继承周的正统性，秦朝被刻意地忽略了。战国策成书于西汉末年，这个名称可能晚到清朝才确立。\\n\\n诸子学说分别有其代言人，儒家司徒之官，道家史官，阴阳家羲和之官，法家理官，名家礼官，墨家清庙之守，纵横家行人之官，杂家议官，农家农稷之官，小说家稗官。\\n"}'));jctx.push(JSON.parse('{"id": "180226", "tag": "book", "text": "# 禅宗四祖道信\\n\\n俗姓司马，河内人（今河南沁阳县）。道信禅师七岁出家。其剃度师戒行不清净，道信禅师曾多次劝谏，但是对方却听不进。没有办法，道信禅师只好洁身自好，私下地持守斋戒，时间长达五年之久，而他的老师竟然一点儿也不知道。\\n\u3000\u3000后来，道信禅师听说舒州皖公山（今安徽潜县）有二僧在隐修，便前往皈依。这二僧原来就是从北方前来避难的三祖僧璨大师和他的同学定禅师（亦说林法师）。\\n\u3000在皖公山，道信禅师跟随三祖僧璨大师学习禅法。道信禅师开悟见性，当在这期间。《五灯会元》卷一记载：\\n\u3000\u3000隋开皇十二年（592），有位沙弥，名道信，十四岁，前来礼谒三祖僧璨大师。\\n\u3000\u3000初礼三祖，道信禅师便问：“愿和尚慈悲，乞与解脱法门。”\\n\u3000\u3000三祖反问道：“谁缚汝？”\\n\u3000\u3000道信道：“无人缚。”\\n\u3000\u3000三祖道：“何更求解脱乎（既然没有人捆绑你，那你还要求解脱干什么呢？不是多此一举吗）？”\\n\u3000\u3000道信禅师闻言，当下大悟。\\n\u3000\u3000原来，吾人所感到的束缚不在外面，而在我们的内心。束缚完全来自于我们自心的颠倒妄想，也就是分别、计度、执着，如果看破了这些妄想，知道它们来无所来，去无所去，当体即空，不再被它们所转，那我们当下就解脱了。内心不解脱，到哪儿都不会自在的。因此，解脱在心，不在外。\\n\u3000\u3000道信禅师开悟之后，并没有马上离开，而是继续留在祖师的身边，一方面侍奉祖师，以报法乳之恩，另一方面，借祖师的加持，做好悟后保任的工夫。这样有八九年的时间（亦说十年）。\\n\u3000\u3000在这期间，三祖不时地点拨道信禅师，并不断地加以钳锤，直到因缘成熟，才肯把法衣托付给他。付法的时候，三祖说了一首偈子：\\n\u3000\u3000“华种虽因地，从地种华生。\\n\u3000\u3000\u3000若无人下种，华地尽无生。”\\n并说道，“昔慧可大师付吾法，后往邺都行化，三十年方终。今吾得汝，何滞此乎（当年慧可大师传法给我之后，寻即前往邺都，行游教化，时间长达三十年，一直到入灭。如今，我已经找到了你这个继承祖业的人，为什么不去广行教化而要滞留在这里呢）？”\\n\u3000\u3000于是，僧璨大师便离开了皖公山，准备南下罗浮山弘法。道信禅师当然非常希望能随师前往，继续侍奉祖师，但是没有得到祖师的同意。祖师告诉他：“汝住，当大弘益（你就住在这里，不要跟我走了，将来要大弘佛法）。”\\n\u3000\u3000僧璨大师走后，道信禅师继续留在皖公山，日夜精勤用功，“摄心无寐，胁不至席”。在皖公山居住了一段时间之后，因缘成熟了，道信禅师便离开此地，四处游化。隋大业年间（605-617），道信禅师正式得到官方的允可出家，编僧籍于吉州（今江西吉安地区）的某座寺院。\\n\u3000\u3000隋末天下大乱，道信禅师应道俗信众的邀请，离开了吉州，来到江州（九江），住在庐山大林寺。唐初武德七年（624），又应蕲州道俗信众的邀请，到江北弘法，旋即在黄梅县西的双峰山（又称破头山）造寺驻锡传禅。后称四祖寺。在这里，道信禅师居住了三十多年，道场兴盛，法音远布，“诸州学道，无远不至”，门徒最盛时多达五百余人，其中以弘忍最为著名。蕲州刺史崔义玄，闻道信禅师之名亦前来瞻礼。\\n\u3000\u3000唐贞观年间，太宗皇帝非常仰慕道信禅师的道味，想一睹禅师的风彩，于是诏令祖师赴京。但是，祖师以年迈多疾为由，上表婉言谢绝了。这样前后反复了三次。第四次下诏的时候，皇帝火了，命令使者说：“如果不起，即取首来”（这次他如果再不来，就提他的首级来见联）。使者来到山门宣读了圣旨，祖师居然引颈就刃，神色俨然。使者非常惊异，不敢动刀，便匆匆回到了京城，向皇上报告了实情。太宗皇帝听了，对祖师愈加钦慕，并赐以珍缯，以遂其志。\\n\u3000\u3000道信禅师寂于永徽二年（651）闰九月初四日，春秋七十有二。临终前，将法衣会付嘱给弘忍禅师，并垂诫门人说：“一切诸法，悉皆解脱。汝等各自护念，流化未来。”言讫，安坐而逝。后谥“大医禅师”。\\n\u3000\u3000道信禅师的开示，现存有《入道安心方便法门》，载于《楞伽师资记》。\\n"}'));jctx.push(JSON.parse('{"id": "180305", "tag": "protocol", "text": "# 行人卡口事件的思考\\n\\n## 问题是什么\\n\\n收到智能交通产品线增加行人卡口的需求，此前协议中已经有名为HumanTrait的事件，表示视频画面中出现了人。第一感觉就是行人卡口记录的也是人的出现这一事实，和HumanTrait有没有差异？\\n\\n## 思考的角度\\n\\n能否复用就要仔细地比较两者的异同。先分析HumanTrait事件，当视频画面中出现了多个人，会以每个人为单位，进行一次这个人的事件上报，并尽可能地带上脸部照片和一些分析信息。而行人卡口要求记录一个人不同时间的画面，比如走过斑马线前后的画面。虽然描述的都是人，但是HumanTrait是从同一个时间进行切入，描述在这个特定时间点某个空间内人的状态；而行人卡口描述的是同一个人，在不同时间点构造的一个序列。*HumanTrait是多人合照，行人卡口是个人短视频*。\\n\\n## 反思与推广\\n\\n做协议经常会遇到到底能不能，要不要复用的问题。如果要复用，要看这个复用协议描述的粒度。但是在定义第一版协议时，因为没有比较，描述往往不精确，会隐含了很多外部信息，直到遇到新需求，才会发现原来还可以从另一个维度看。\\n\\n像上面提到的过人事件为例，第一次看到这个需求时，的确没想到可以从时间序列去记录一个人。其实第一次分析不完整问题也不大，只要后面遇到新需求时，回过头来比较、细化已经定义好的协议也是来得及的。\\n\\n另一个悖论是倘若粒度真的太小，非常地场景特化，能被复用的可能性自然就少了。"}'));jctx.push(JSON.parse('{"id": "180316", "tag": "lang", "text": "# AndroLua记录\\n\\n一个在Android用lua开发程序的应用，利用了JNI技术。JNI的交互是在java中定义若干个native方式的接口，通过javah导出头文件。在C函数中实现这些导出头文件对应的函数。这是java调用C的流程。想从C调用java，就要借助传给C语言JNIEnv变量并保存下来，后续用这个变量找class和method，并通过JNIEnv来调用。利用lua、C、Java三者之间两两互通，最终实现lua和java的互操作。\\n\\n最初的想法来自Lua的Kepler项目中luajava这个子项目。代码分为C和Java两部分，先看C语言部分。\\n\\n1.1版本就luajava.c一个文件。前半部分定义了5个lua操作java对象的函数，new/newInstance/bindClass/createProxy/loadLib。4.0版本又增加了多个函数，为简化起见先学习这5个。\\n\\n这5个函数肯定放入lua的table，并以字符串和C函数的关系绑定。这个L保存在CPtr.java定义的private long peer;成员变量。\\n\\nlua中会以newuserdata方式创建JNIEnv类型变量，并命名为`__JNIEnv`保存到`LUA_REGISTRYINDEX`里。每当这个userdata被触发gc时，会找JNIEnv并用DeleteGlobalRef方式对jobject的引用计数减1。\\n\\nluajava.c的后半部分定义了107个JNI的C实现，注册5个函数是在LuaState.java中定义为native方式的名为`luajava_open`的函数，由于javah的转换,到了C语言中函数名会稍有不同，但还是能看出来。C语言中实现了5大函数的注册。而在java的LuaState构造函数中，实现了`luajava_open`的调用。\\n\\n如果是通过java的console方式，会在Console.java的main函数构造LuaState，实现5大函数在lua的注册，接下来就可以在lua中调用java了。\\n\\n每次在abstract的JavaFunction调用LuaState.pushJavaFunction，就会在lua中创建新的userdata，再创建一个table，并设置`__call`域，执行函数调用int execute()签名函数。所有的入参在lua栈上，出参会压入栈上，返回的int就表示出参个数。\\n\\n## 开发安卓程序\\n\\n利用布局器交互式地添加几个简单的控件，.aly文件会依次出现这些控件，然后加上id=\\"xx\\"之后，就可以在代码中操作这些控件。布局器只要一个LuaWebView，剩下的就是web开发和打包。"}'));jctx.push(JSON.parse('{"id": "180320", "tag": "os", "text": "# 安卓APK内容分析\\n\\n## 压缩包的文件构成\\n\\n最小的apk会有classes.dex/AndroidManifest.xml/resources.arsc文件和assets/META-INF(数字签名，记录了所有文件的SHA-1结果)/res目录，换句话说是由Java编译的字节码、资源文件原生库以及辅助文件(如编译说明、签名)共同打成的zip包。\\n\\n不同apk之间是依靠记录在AndroidManifest.xml的包名和数字签名共同来进行区分的。\\n\\n## 执行代码说明\\n\\nclasses.dex文件是Dalvik字节码，也是主执行代码。java把每个源文件编译成class，而apk中只有一个dex，有点jar的味道。\\n\\n用户安装在/data目录下的apk，通常都包含dex。/system目录下的apk内没有dex，替代的是外部的odex文件。在真正执行前，会将dex做进一步优化，分Dalvik或ART优化，版本4.4以前使用dexopt生成odex文件，版本5之后使用dex2oat生成用于ART的oat格式(可能也是.dex的扩展名)。dex是跨平台的，odex/oat是平台依赖的，存放odex/oat位置就是dalvik-cache。\\n\\n## 文件内容\\n\\n每个apk会在/data/data/目录下存放文件（小米会创建/data/usr/0/别名）。这个目录下的文件夹比较固定，至少有 files, shared\\\\_prefs, cache, code\\\\_cache。有些还会有databases, lib, app\\\\_XXX这样的目录。"}'));jctx.push(JSON.parse('{"id": "180321", "tag": "book", "text": "# 雷恩杰哥\\n\\n## 如何看公告\\n\\n做任何事，都要讲究方法论，应该用最短的时间做到80%，去超过大多数人，再用大量的时间去攻克剩下的20%，成为顶尖玩家。我用这篇短文，带大家做到前面的80%，剩下的20%，就靠自身的努力与智慧了。要入门做到80%其实非常简单，我把方法化繁为简，主要是以下4个步骤：\\n\\n1.      收藏这两个网址\\na)        中证网：http://ggjd.cnstock.com/gglist/search/ggkx\\nb)        巨潮资讯网：http://www.cninfo.com.cn/cninfo-new/index\\n\\n2.      学会懒人思维，公告三千，只取三瓢。每天的公告都有成百上千，该如何减少工作量，但又不落下重要的公告呢？如何能够用最短的时间筛选并分析呢？\\n\\na)        明日复牌股的公告必看\\n（在巨潮资讯网里看，把每个复牌股的原委弄清楚，再看下停牌日期，估算补跌或者补涨的幅度）\\n\\nb)        中证网的重点公告必看\\n（步骤1里我给的网址）\\n\\nc)        自选股的公告必看，自己持有的股票或者关注的股票，每天都要去看一下公告，看看会不会对基本面有较大影响\\n\\n3.      分清楚利好公告与利空公告的类型。需要注意的是，利好不一定买进能赚钱，利空不一定会让股票跌，灵活分析才是关键，灵活分析的额前提是长期的归纳总结与试错。\\n\\n利好主要有：\\n\\na)        资本举牌\\nb)        大股东增持\\nc)        更换实控人\\nd)        并购重组\\ne)        定增\\nf)         大订单\\ng)        高送转\\nh)        业绩大增\\n\\n利空公告里我主要关注的只有两类：\\n\\na)        重组终止\\nb)        收到行政处罚书\\n\\n4.     新手该如何分析一个公告。格式如下，如果一开始每个都这么分析，无需多久，就能做到80%。\\n\\n案例：\\n\\na)  公告简介（写这个公告的内容和相关数据）\\n\\nb)  公司基本面（搞清楚这个公司的基本面如何，本身的业绩如何，本身的题材是什么，公告后的业绩如何，公告后的题材是什么）\\n\\nc)  解禁与减持（解禁和减持对股票短期的影响非常明显，看复牌公告的时候，一定要排查这两项）\\n\\nd)  停牌影响（停牌多久？期间指数情况？是否需要补涨？）\\n\\ne)  总结（做出综合分析，给出预判，做好一个交易预案，然后就是总结和归纳了）\\n\\n## 关于成长股\\n\\n1. 不要买市值超过200亿的成长股，成长股小而美，200亿以上是白马股\\n2. 不要买市盈率低于40倍的成长股，高增长通常大于40一个优秀的操作系统里，仓位的管理能力远比选股能力重要。一个职业的投资者，有几十年的投资生涯，在漫漫投资路上，最重要的就是要活下去。想活下去，那就必然不是去追求天天满仓打板，而是不管在牛市还是熊市都能稳定的赚钱，特别在市场环境不利时，守住投资本金，控制利润回撤，让账户处于风险可控状态。\\n\\n## 仓位管理\\n\\n不同的交易者在同一个时段，去买卖同一只标的股票，所得到的投资盈亏都是不一样的，最主要的原因就是每个人的仓位管理的不同。投资过程中的情绪波动会影响操盘决策，散户最常犯的错误就是追涨杀跌，看见某只股票上涨就追高买入，看见下跌就低位割肉；同时还缺少仓位管理的意识，喜欢把所有资金一把梭哈地压在某一只股票上，这其实就是赌博心理。这种投资模式的背后蕴藏着巨大风险，在遇到系统性风险或“黑天鹅”事件等极端情况时，会造成致命的损失。轻则几个月或数年的收益全部回吐，一夜回到解放前；重则血本无归，亏空出局。\\n\\n因此，投资者应严格遵守仓位管理纪律，减少主观情绪影响，控制交易心态。要谋定而后动，按照原则而动，即不管震荡再剧烈，只要没触及设定的价格底线，也可淡定持有；一旦市场打破了事先设定的逻辑或价格底线，信心再充足，也不可无原则的恋战。仓位控制的背后是情绪控制，通过合理的仓位管理，建立良好的交易心态，尽量减小投资的风险，放大投资的收益，实现长期稳定盈利，从而在投资道路上走得更远。\\n\\n仓位管理的核心原则：\\n\\n不要让自己在单笔交易中亏太多的钱，也不要明明抓住一个大牛股却对总资金增加贡献太小，不能太集中也不宜太分散。仓位管理的第一步是建立自己的投资组合，以及每只股票分配多少仓位；第二步是某一只股票仓位的具体管理，包括建底仓、补仓，以及止损和止盈时机的把握，即底仓建多少，什么时候建？回撤多少补仓，获利多少加仓？下跌多少止损，赚多少止盈？确保每次在亏损放大之前，及时止损，每次盈利都能尽可能拿到最大的利润，实现组合和个股的总体收益依旧是正的。\\n\\n\\n建立投资组合是一个考虑各方面因素后的综合决策，本文侧重介绍如何通过仓位管理去操作一只股票。下面具体分析在牛市行情、熊市行情和震荡行情中的不同仓位管理策略：\\n\\n一、牛市行情中的仓位管理策略\\n\\n牛市行情市场处于上升趋势，均线多头排列，此时最大的风险就不是股价的波动，而在于踏空的风险。\\n\\n策略：\\n\\n1、不空仓，不踏空，有机动仓位资金应对盘面。\\n\\n每一次回踩和调整都是机会，应该在保有一定底仓的前提下，用适当的机动仓位做高抛低吸，以获得更大的利润。\\n\\n2、逐步建仓，越涨越买。\\n\\n首先采用这只股票仓位的1/5进行试探建仓，买入后若标的上涨，每上涨3%-5%加仓1/5，某一只股票占总仓位不超过30%；买入后若标的下跌，低于底仓买入价5%-8%的跌幅时，择机加仓2/5的仓位。如果第二次补仓后继续下跌，到达止损线即刻止损。\\n\\n注意：一般资金200万以下的投资者，持股最好控制在5只以内。\\n\\n \\n\\n二、熊市行情中的仓位管理策略\\n\\n熊市行情市场处于下降趋势，均线空头排列。最好不参与，不要轻易抢反弹，应跟随趋势轻仓操作，确保不犯原则性错误。\\n\\n策略：\\n\\n1、轻仓操作，永远不要超过七成仓位；补仓次数不易过多，一次最好，一只股票的仓位不可超过总仓位的2成。\\n\\n2、下跌达到设定止损位，应坚决止损，绝不让损失扩大。一般行业内比较认可的，是每次交易对总仓位带来的损失控制在3%左右。\\n\\n三、震荡行情中的资金管理策略。\\n\\n我们所说的震荡行情，简单描述就是股价或者指数围绕一定的中枢进行波动，而不形成趋势。一般我们可以分为顶部震荡，底部震荡，下跌中继震荡和上升中继震荡。\\n\\n震荡行情切忌追涨杀跌，总体仓位要控制在3到7成。在波动趋势不明朗的时候，最令人难受的就是频繁踏错节奏，被市场两面扇耳光。因此追涨杀跌是震荡期的大忌，只会消耗和加重资金成本，更会使投资心态和行为发生混乱。\\n\\n今年的行情不太好做，大规模的公募私募都亏钱，就是因为全年都属于震荡行情，几乎没有像模像样的行情。\\n\\n1、底部震荡\\n\\n如何判断：1、估值水平较低，整体市盈率25倍以下，甚至20倍以下。2、成交量长期萎缩低迷，突然有所放大。3技术上的底部形态（最好有资金吸筹形态）\\n\\n策略：首仓最好少于2成仓，最好选择防御性较强的业绩股，标的范围在2-4只左右。不要追涨杀跌，应该耐心持股，越跌越买。股票超过10%的跌幅可以考虑补仓。总体仓位控制在5成内。\\n\\n2、上升中继震荡\\n\\n如何判断：均线呈多头排列，高点突破受阻。\\n\\n策略：至少保持三成的底仓，灵活的仓位做T。保有之前上升趋势中的盈利头寸作为底仓，以免踏空。但要保持一定的灵活度。仓位还是保持在5成以内为佳。\\n\\n3、顶部震荡以及下跌中继震荡\\n\\n如何判断：中小创普遍资金开始出逃，重要均线死叉。\\n\\n策略：空仓，保住胜利果实。保住现金，等待下次机会。\\n"}'));jctx.push(JSON.parse('{"id": "180401", "tag": "think", "text": "# 《JS语言精粹》学习记录\\n\\n知乎上看的，融合了自己的理解。\\n\\n## 第一章 精华\\n\\nJavaScript有很多优秀的想法也有糟粕；\\n优秀的想法在于：弱类型，函数，动态对象和富有想象的对象字面量表示法。\\n糟粕在于：基于全局变量的编程模型。\\n\\nJavaScript的函数是主要基于词法作用域（lexical scoping）的顶级对象.\\n\\n原型继承是JavaScript一个有争议的特性。JavaScript有一个无类型的对象系统。在这个系统中，对象直接从其他对象继承属性。\\n始终用一个method方法定义新方法：\\n\\n```\\nFunction.prototype.method = function ( name , func){\\nthis.prototype[ name] = func ;\\nReturn this;\\n}\\n```\\n\\n## 第二章 语法\\n\\nNaN表示一个数值，是一个不能产生正常结果的运算结果。不等于任何值，包括他自己。Infinity可以表示无穷大。数字拥有方法，有一个对象Math，包含一套用于数字的方法。\\n\\n字符串：可以在” ” , ’ ‘里面。\\\\ 是转义字符。有一个length属性，表示长度。可以用 + 连接字符串，字符串也有一些方法。\\n\\n语句：每个`<script>`提供一个被编译且立即执行的编译单元。JavaScript把他们添加到一个全局的名字空间里面去。\\n\\nVar在函数内部，定义的是私有变量。代码块在{ } 中，不会创建新的作用域。\\n\\nSwitch，while，do，for允许有一个可选的标签。可以配合break;\\n\\n被判断为 假 的值：False ; null ; undifined ;空字符串 ； 数字0 ； 数字NaN\\n\\nFor in 语句枚举对象里的所有属性\\n\\n如果throw在一个try代码块中，那么控制流会跳转到catch从句中。如果throw语句在函数中，则该函数调用被放弃，控制流跳转到调用该函数的catch中。\\n\\nThrow语句的表达式通常是一个对象字面量。通常包含一个message和name。异常捕获器可以利用这些信息知道做什么。\\n\\n表达式：最简单的表达式是字面量值，变量，内置的值，new开头的表达式，delete开头提取属性，（...）,前置运算符，三元，函数调用，属性提取....\\n\\ntypeof判断类型。\\n\\n字面量：对象字面量是一种可以方便的按照指定的规格创建新对象的方法。\\n\\n函数：函数字面量定义了函数值。\\n\\n## 第三章 对象\\n\\nJavaScript简单的数据类型包括：数字，字符串，布尔类型，null，undifined。除此以外的所有类型都是对象。数字，字符串，布尔值也类似对象，他们有方法，但是他们不可变。\\n\\n对象是可变的键值对的组合。数组，函数，正则表达式都是对象。对象是属性的容器，属性都有名字和值。值不可是undifined。对象是无类型的，对象中可以包含对象。\\n\\n对象字面量：方便的创建对象。语法有点特殊，只有在等号或圆括号内的花括号才认为是创建对象。\\n\\n“||” 可以填充默认值，\\n\\n“&&”可以避免typeerror错误，由于在不存在的属性取值产生的。\\n\\n更新： 赋值语句，存在则更新；不存在则扩充。\\n\\n引用：对象通过引用传递，永远不会被复制。\\n\\n比较JS和Lua对象，两种语言的实现都有GC和union的值类型，JS会多出两个特殊的字段，properties和prototype。\\n\\n先说原型（prototype）：每个新建对象都连接到一个原型对象，并且可以从其中继承属性。所有通过字面量创建的对象都连接到Object.prototype,他是js中的标配对象。看MuJS的实现，所有的类型像Object/Array/Function/Date有prototype。七种错误Error/EvalError/RangeError/ReferenceError/SyntaxError/TypeError/URIError也有各自的prototype。\\n\\n每次构造新对象，都会把新创建的类型的prototype指向预设的原型。原型连接在更新时候不起作用，对对象改变不触及原型。\\n\\n原型链的任何属性都会产生值 typeof fight .toString -> ‘ function’\\n\\n有两种方法丢掉不需要属性：\\n\\n1. 程序检查并丢掉值为函数的属性。\\n\\n1. 使用hasOwnProperty 方法，如果对象有独立属性，返回true。它不会检查原型链。\\n\\n再说property，比Lua要丰富一些，具备一些内在属性，READONLY/DONTENUM/DONTCONF。三者可以任意组合。\\n普通的属性可以枚举：for in 遍历一个对象中非ENUM的属性名包括原型中的属性。属性出现无序，可以使用数组避免这种情况。\\n\\nCONF和Frozen相关(ES5特性)。\\n\\n删除：删除对象的属性可能会让原型链中的属性透露出来。\\n\\n减少全局变量污染：只创建一个全局变量作为容器这样都在一个名称空间下，减少与其他程序的冲突。\\n\\n## 第四章 函数\\n\\n函数对象：函数是对象。创建时连接到Function.ptototype。每个函数对象在创建的时候配一个prototype属性。其有一个constructor属性且值为函数。\\n\\n函数字面量：函数通过函数字面量来创建。\\n\\n```\\nVar add = function ( a , b ){\\nreturn a + b ;\\n}\\n```\\n\\n函数没有名字，如上就叫匿名函数。\\n\\n函数字面量可以在任何表达式可以出现的地方。也可以在函数中，就是嵌套函数。里层的函数可以调用他上一层的函数的变量。通过函数字面量创建的函数可以连接到他的外部上下文这叫，闭包。\\n\\n调用：除了函数定义的形式参数以外函数还有两个自带的参数。this 和 argument，this的值取决于调用模式：\\n\\n函数有4中调用模式：\\n\\n1. 方法调用模式：\\n\\n函数在对象中保存为属性的时候，为方法。此时this绑定到该对象。通过this可以取值或对对象进行修改。通过this取得对象上下文的方法称为公共方法。\\n\\n1. 函数调用模式：\\n\\n当函数不是属性的时候，此时当做一个函数来调用。此时this指向了全局变量。这使得函数中的内部函数不能为外部函数服务。解决的办法：在外部函数里让this赋值给一个变量。\\n\\n1. 构造器调用模式：\\n\\nJs提供一套和基于类的语言类似的对象构建语法。如果在函数前面添加new来调用，那么会在背地里创建一个连接到这个函数的prototype的新对象，this会绑定到这个新对象。一个函数，构建的目的是希望结合new来用，就是构造器函数。\\n\\n1. Apply调用模式\\n\\n函数可以拥有很多方法。Apply方法允许我们传递一个数组参数给函数。其接受两个参数，第一个为this的值，第二个就为参数数组。\\n\\n参数：参数有一个附加的对象，argument对象，类似数组，没有数组的属性。函数可以通过这个对象，访问传过来的参数列表。\\n\\n返回：return\\n\\n异常：throw语句判断函数的执行。会抛出一个exception对象，其中包含异常类型name，以及异常的描述message。一个try语句只会跟随一个捕获所有异常的catch。\\n\\n函数的闭包使得具备静态词法作用域，但this的存在又允许动态地打开作用域，兼有动态作用域的效果，很灵活很强大。# 《JS语言精粹》学习记录\\n\\n知乎上看的，融合了自己的理解。\\n\\n## 第一章 精华\\n\\nJavaScript有很多优秀的想法也有糟粕；\\n优秀的想法在于：弱类型，函数，动态对象和富有想象的对象字面量表示法。\\n糟粕在于：基于全局变量的编程模型。\\n\\nJavaScript的函数是主要基于词法作用域（lexical scoping）的顶级对象.\\n\\n原型继承是JavaScript一个有争议的特性。JavaScript有一个无类型的对象系统。在这个系统中，对象直接从其他对象继承属性。\\n始终用一个method方法定义新方法：\\n\\n```\\nFunction.prototype.method = function ( name , func){\\nthis.prototype[ name] = func ;\\nReturn this;\\n}\\n```\\n\\n## 第二章 语法\\n\\nNaN表示一个数值，是一个不能产生正常结果的运算结果。不等于任何值，包括他自己。Infinity可以表示无穷大。数字拥有方法，有一个对象Math，包含一套用于数字的方法。\\n\\n字符串：可以在” ” , ’ ‘里面。\\\\ 是转义字符。有一个length属性，表示长度。可以用 + 连接字符串，字符串也有一些方法。\\n\\n语句：每个`<script>`提供一个被编译且立即执行的编译单元。JavaScript把他们添加到一个全局的名字空间里面去。\\n\\nVar在函数内部，定义的是私有变量。代码块在{ } 中，不会创建新的作用域。\\n\\nSwitch，while，do，for允许有一个可选的标签。可以配合break;\\n\\n被判断为 假 的值：False ; null ; undifined ;空字符串 ； 数字0 ； 数字NaN\\n\\nFor in 语句枚举对象里的所有属性\\n\\n如果throw在一个try代码块中，那么控制流会跳转到catch从句中。如果throw语句在函数中，则该函数调用被放弃，控制流跳转到调用该函数的catch中。\\n\\nThrow语句的表达式通常是一个对象字面量。通常包含一个message和name。异常捕获器可以利用这些信息知道做什么。\\n\\n表达式：最简单的表达式是字面量值，变量，内置的值，new开头的表达式，delete开头提取属性，（...）,前置运算符，三元，函数调用，属性提取....\\n\\ntypeof判断类型。\\n\\n字面量：对象字面量是一种可以方便的按照指定的规格创建新对象的方法。\\n\\n函数：函数字面量定义了函数值。\\n\\n## 第三章 对象\\n\\nJavaScript简单的数据类型包括：数字，字符串，布尔类型，null，undifined。除此以外的所有类型都是对象。数字，字符串，布尔值也类似对象，他们有方法，但是他们不可变。\\n\\n对象是可变的键值对的组合。数组，函数，正则表达式都是对象。对象是属性的容器，属性都有名字和值。值不可是undifined。对象是无类型的，对象中可以包含对象。\\n\\n对象字面量：方便的创建对象。语法有点特殊，只有在等号或圆括号内的花括号才认为是创建对象。\\n\\n“||” 可以填充默认值，\\n\\n“&&”可以避免typeerror错误，由于在不存在的属性取值产生的。\\n\\n更新： 赋值语句，存在则更新；不存在则扩充。\\n\\n引用：对象通过引用传递，永远不会被复制。\\n\\n比较JS和Lua对象，两种语言的实现都有GC和union的值类型，JS会多出两个特殊的字段，properties和prototype。\\n\\n先说原型（prototype）：每个新建对象都连接到一个原型对象，并且可以从其中继承属性。所有通过字面量创建的对象都连接到Object.prototype,他是js中的标配对象。看MuJS的实现，所有的类型像Object/Array/Function/Date有prototype。七种错误Error/EvalError/RangeError/ReferenceError/SyntaxError/TypeError/URIError也有各自的prototype。\\n\\n每次构造新对象，都会把新创建的类型的prototype指向预设的原型。原型连接在更新时候不起作用，对对象改变不触及原型。\\n\\n原型链的任何属性都会产生值 typeof fight .toString -> ‘ function’\\n\\n有两种方法丢掉不需要属性：\\n\\n1. 程序检查并丢掉值为函数的属性。\\n\\n1. 使用hasOwnProperty 方法，如果对象有独立属性，返回true。它不会检查原型链。\\n\\n再说property，比Lua要丰富一些，具备一些内在属性，READONLY/DONTENUM/DONTCONF。三者可以任意组合。\\n普通的属性可以枚举：for in 遍历一个对象中非ENUM的属性名包括原型中的属性。属性出现无序，可以使用数组避免这种情况。\\n\\nCONF和Frozen相关(ES5特性)。\\n\\n删除：删除对象的属性可能会让原型链中的属性透露出来。\\n\\n减少全局变量污染：只创建一个全局变量作为容器这样都在一个名称空间下，减少与其他程序的冲突。\\n\\n## 第四章 函数\\n\\n函数对象：函数是对象。创建时连接到Function.ptototype。每个函数对象在创建的时候配一个prototype属性。其有一个constructor属性且值为函数。\\n\\n函数字面量：函数通过函数字面量来创建。\\n\\n```\\nVar add = function ( a , b ){\\nreturn a + b ;\\n}\\n```\\n\\n函数没有名字，如上就叫匿名函数。\\n\\n函数字面量可以在任何表达式可以出现的地方。也可以在函数中，就是嵌套函数。里层的函数可以调用他上一层的函数的变量。通过函数字面量创建的函数可以连接到他的外部上下文这叫，闭包。\\n\\n调用：除了函数定义的形式参数以外函数还有两个自带的参数。this 和 argument，this的值取决于调用模式：\\n\\n函数有4中调用模式：\\n\\n1. 方法调用模式：\\n\\n函数在对象中保存为属性的时候，为方法。此时this绑定到该对象。通过this可以取值或对对象进行修改。通过this取得对象上下文的方法称为公共方法。\\n\\n1. 函数调用模式：\\n\\n当函数不是属性的时候，此时当做一个函数来调用。此时this指向了全局变量。这使得函数中的内部函数不能为外部函数服务。解决的办法：在外部函数里让this赋值给一个变量。\\n\\n1. 构造器调用模式：\\n\\nJs提供一套和基于类的语言类似的对象构建语法。如果在函数前面添加new来调用，那么会在背地里创建一个连接到这个函数的prototype的新对象，this会绑定到这个新对象。一个函数，构建的目的是希望结合new来用，就是构造器函数。\\n\\n1. Apply调用模式\\n\\n函数可以拥有很多方法。Apply方法允许我们传递一个数组参数给函数。其接受两个参数，第一个为this的值，第二个就为参数数组。\\n\\n参数：参数有一个附加的对象，argument对象，类似数组，没有数组的属性。函数可以通过这个对象，访问传过来的参数列表。\\n\\n返回：return\\n\\n异常：throw语句判断函数的执行。会抛出一个exception对象，其中包含异常类型name，以及异常的描述message。一个try语句只会跟随一个捕获所有异常的catch。\\n\\n函数的闭包使得具备静态词法作用域，但this的存在又允许动态地打开作用域，兼有动态作用域的效果，很灵活很强大。"}'));jctx.push(JSON.parse('{"id": "180402", "tag": "lang", "text": "# 接口与集合论\\n\\nhttps://bartoszmilewski.com/2014/10/28/category-theory-for-programmers-the-preface/\\n\\njava 的接口是个余积（Coproduct，可以简单地看作是范畴化的不交并）。Java 里面没有能很好表达积（Product）的概念（泛型是瘸的），而这个对偶却很好用。通俗化地理解，余积通俗理解，就是C语言的联合体，把若干不相关的类型合并。\\n\\nFP 领域就正好反过来，他们很喜欢积（Forall 量化以至于 DT 的 Pi），而几乎不碰余积（Existential 量化）。在 FP 的多态里面，返回具体类型X_1,X_2,...,X_N的函数（态射）可以被改写成一个返回多态类型\\\\prod_N{X_N}的函数外加一些实例化函数\\\\pi_1, \\\\pi_2,...,\\\\pi_N的复合。类型里的积也是两种：\\n\\n* 有限的，表现为元组（Tuple）或者记录（Record）\\n* 无限的，就是参数多态（Parametric Polymorphism）\\n\\n分析历史源流的话可以发现：OOP 得以被发扬光大，糅合了大量传统命令式语言的内容。在它们眼里，类型是一个集合，无穷个子集组成的不交并（余积）比较好理解，也好实现。但无穷个子集组成的直积（范畴积）就十分令人困惑了；FP 语言则因为和逻辑学的关系，大量使用逻辑学术语，范畴积在那边是逻辑学里非常普遍的\\\\forall符号，而余积则是只有高阶逻辑中才会出现的大\\\\Sigma算符。\\n\\nOOP 语言是追随着传统工业编程语言的路径走来的 -> 发扬光大的时候才追传统语言，但是这过程没引入什么新特性。Simula Smalltalk Flavor Self CLOS(meta object protocol)这些语言都跟工业界没啥关系，但对OOP语言的发展远远比Java高\\n\\n至于interface（in general，不是对java），parametric polymorphism，我不喜欢把他们看作infinite product/coproduct，因为有特性没有被capture到（比如interface应该隐藏实现，coproduct做不到，比如parametricity）。parametricity 是那些 π 函数干的事情（从一个 product 中「取」需要的版本）；「隐藏细节」是针对惟一的 f 说的，它不依赖 X_n 的细节，只关心接口本身。\\n\\nCategorical Abstract Machine 1985, 比Haskell的monad早\\n不一定要靠monad，Dana Scott的denotational semantic paper早就有副作用的数学建模（尽管不是纯函数的）\\n带副作用的FP看两部分\\n\\n* 一部分是纯的，生成不纯的语言的代码\\n* 一部分是不纯语言的副作用-而这部分没理由必须monadic\\n"}'));jctx.push(JSON.parse('{"id": "180405", "tag": "web", "text": "# YXcms和CanPHP的结合\\n\\n以前写过一篇URL路由，提到YXcms的解析思路，分析整体代码的思路。\\n\\nCanPHP的结构很清晰，分core/lib/ext三个目录，lib是官方功能扩展，ext是第三方扩展。core的顶级只有1017行代码，算上cache和db目录的各种不同实现共2千行。lib包括鉴权、图片等常用功能共5292行。ext有邮件和IP地址共1015行。\\n\\ncore目录有如下文件，cpApp加载入口，cpModel/cpCache数据库相关，cpTemplate/cpHtmlCache页面展示，cpConfig/cpError辅助功能。对于框架来说一定要提供M和V，而C天然是应用层要做的事，CanPHP做到了。\\n\\nYXcms会在它的体系中包含这些文件，cpModel被model使用，cpCache在cpModel内部包含，不需要显式使用。cpTemplate被controller和commonController使用，cpHtmlCache被baseController使用。cpConfig和cpError直接在YXcms的入口文件core使用。cpApp的入口功能被core重写，所以没有被使用。从中可以看出，CanPHP最核心的功能一个不落地被YXcms引用了。\\n\\nYXcms具有完整的MVC，C的代表controller，构造时会创建model，其view函数会创建cpTemplate进而渲染视图。V是一堆含有待替换值的HTML页面。"}'));jctx.push(JSON.parse('{"id": "180406", "tag": "lang", "text": "# 冯东的Lua\\n\\nLua vs. Python\\n\\n在《 Programming in Lua 》系列里谈了 Lua 的 stackless 实现。说到 stackless 设计，难免和 Python 的 stackful 实现比较一下。\\n\\n以前总有一个疑惑。为什么 Python 既要采用 native thread，又要用 great-lock 将其变成实质上的协作式 thread。像 Lua 这样的 coroutine 不好么？现在知道了，非不为，不能也。既要尽量保证虚拟机的可移植性，又采用了非常依赖 CRT stack 的 stackful 设计，语言本身没有 synchronous primitive，不能应付真正的 preemptive 多线程。这种情况下，多线程加 big-lock 是唯一的折衷了。由此也知道了 Python 的 generator 为什么只允许在第一层函数中 yield，因为 stackful 设计不允许保存 call stack (说老实话，只允许在第一层函数中 yield 的 coroutine 不过是两个函数调来调去，在 C 里实现起来也不难)。Python 3.3 开始支持更宽松的 yields，不过实现的方式和 Lua 的 yields-in-C 差不多，作为基于虚拟机的语言是比较原始的手段。\\n\\n拿 Lua 和 Python 做比较令人恍惚感觉正在比较 Objective-C 和 C++。Lua/Python 和 Objective-C/C++ 都是在共同基础上发展出来：后者扩展 C 语言；前者用 C 语言实现基于 byte-code 的虚拟机。它们都有理想的「标杆」：Objective-C/C++ 的标杆是 Smalltalk/Simula 等面向对象语言先驱；Lua/Python 是 Lisp 这样的高级动态语言先驱。努力的方向都是降低「标杆」过大的性能开销和简化「标杆」过于复杂 (或者过于精简) 的概念。Python 和 C++ 相对较早的尝试，都采用了比较低级的机制：C++ 用函数指针模拟成员函数；Python 依赖 CRT stack 直接实现 byte-code stack。这些「第一次」都没能「do things right」。后来的第二次尝试才作出了更妥当的取舍。\\n\\n在《 The Art of UNIX Programming 》里指出了系统设计的「第二系统综合症 (second-system effect)」。乔布斯也提到过「第二个产品」的问题。在一个成功的系统上衍生的第二个系统有时会因为没有理解第一个系统成功的真正原因而失败。但是，如果还有机会的话，由此衍生的「第三系统」往往会做得更好。对于上面所说的语言发展来说，它们的基础 (C 语言) 和「标杆」是「第一系统」，第一次改进的尝试毁誉参半，而后来的「第三系统」更加出色。\\n\\n2013/05/13\\t Leave a reply\\nProgramming in Lua（五）－ Coroutine, Lua Stack\\n\\n在《 Programming in Lua（三）－ Yields in C 》里讨论了 Lua 虚拟机对 yields-in-C 及其 stack 的处理。当时还未读 Lua 虚拟机的实际代码，只根据语言的行为来推测，有些术语也不符合通常用法。最近从 Lua stack 的实现入手，发现了一些以前没想过的问题：为什么 resumes-in-C 从来不是问题？为什么有 lua_yieldk() 而没有对应的 lua_resumek() ？\\n\\n首先从术语的标准化说起。《 Programming in Lua（三）－ Yields in C 》里有多处这样的描述：\\n\\n「stack 上 ⋯⋯ 的执行层次」；\\n「virtual stack 上的 Lua 部分的 stack」；\\n「Lua stack 段」。\\n其中「执行层次」、「部分」、「段」这样的字眼应该替换为「stack frame」这个更常用的术语。线程运行时，stack 呈现两层意义。一是后入先出的简单线性结构；二是把此线性结构划分成与函数调用层次一一对应的若干段，这样的一段就被称为一个 stack frame。大多数语言的 runtime 或虚拟机中，stack frame 并无单独的数据结构表示。在 64-bit x86 的 C runtime (CRT) 中，每个 stack frame 的首项是上一层 stack frame 的最低地址 (base)，称为 stored frame pointer (SFP)，最顶层 stack frame base 存储在 %ebp 寄存器中 。即每次生成新的 stack frame 时，首先将 %ebp 寄存器入栈形成 SFP，然后把当前的 %esp 赋给 %ebp。通过这种方式让需要解析 stack frame 的程序 (比如 debugger) 得到所需信息。(SFP 并非一定存在，臭名昭著的 omit-frame-pointer 编译器优化会去掉 SFP，这时 debugger 只能借助额外存储的 symbols 来解析 stack frame。)\\n\\n就需求本身来说，Lua stack 要解决的问题比 C 复杂的多，甚至比同为动态语言的 Python 更复杂。基于虚拟机的语言的 call stack 有两种可能的设计：一是借用虚拟机本身的 CRT stack。Byte-code 的函数调用指令对应虚拟机本身 native 代码的函数调用，虚拟机的 CRT stack 随 byte-code 函数调用的层次增加而增长。二是由虚拟机维护额外的 call stack 数据结构。Byte-code 的函数调用指令和其它指令一样，在虚拟机的同一个循环中完成，虚拟机的 CRT stack 不体现 byte-code 函数的调用层次。后者通常被称为 stackless 方案，前者暂且对应称为 stackful 方案。\\n\\nLua 是 embedded/extension 语言，byte code 的运行总会夹杂 C 函数。这些 C 函数的 call stack 在逻辑上是 byte-code 运行状态的一部分，实际上则间杂在 Lua 虚拟机的 CRT stack 中 (在涉及 Lua 的情况下讨论 CRT stack 时，要始终说明是虚拟机的 CRT stack 还是 C 函数的 call stack)。从这个角度来说，embedded/extension 语言更倾向于选择 stackful 设计。但 stackful 设计的固有缺陷在于 stack 结构是平台相关的，很难用跨平台的方式实现诸多功能，比如协作式多任务 (cooperative multi-threading)，跟踪垃圾回收 (tracing-GC)，lexical closure。尽管不是全部原因，Python 缺少诸多高级特性与其 stackful 实现有很大关系。\\n\\n为了遵守 ANSI C 的跨平台性和更好的实现高级动态功能，Lua 采用了 stackless 实现。这给处理 C 代码的 call stack 带来了一些挑战。Lua 的 stack 存储在 struct lua_State 的 stack field 中，是一个 TValue* 的数组。其内容包括：\\n\\n函数指针。Proto* (Lua 函数) 或者 lua_CFunction (C 函数)。注意函数指针不是函数的返回地址。\\n函数的参数和返回值。包括 Lua 和 C 函数之间传递的参数和返回值。\\nLua 函数的局部变量。\\n在这个 stack 上缺少一些属于 call stack 的东西：\\n\\nC 代码本身的 call stack。\\n函数的返回地址。\\nStack frame 信息，类似 SFP。\\n这是因为 Lua 采用了双 stack 结构。对应的 stack frame 信息存储在一个 struct CallInfo 链表中，每个节点对应一个 stack frame，它对 TValue* 数组 stack 的描述如下：\\n\\nField func 表示 stack frame 在 TValue* 数组上的起始位置 (之所以用 func 作为 field 名称是因为在 TValue* 数组上这个位置永远是函数指针)，field top 表示结束位置。\\nField union u 存储和函数类型相关的信息。Lua 函数信息存储在 u.l 中，C 函数在 u.c 中。\\nu.l.savedpc 表示函数的返回地址。这个值仅当 Lua 函数作为 caller 的情况有效。C 函数作为 caller 时，返回地址在 CRT stack 中。\\n当 C 函数中发生 yield 时，CRT stack 被破坏，该 coroutine 下次被 resume 的执行地址由 u.c.k 来承担。详见《 Programming in Lua（三）－ Yields in C 》。\\n这里值得多说一句，为什么在 C 函数中执行 yield 会破坏 CRT stack？上文说过，Lua 的设计主要是 stackless 方式，其具体实现是通过 luaV_execute() 中的循环执行 byte code，通过额外数据结构 (其实是双数据结构) 而非 CRT stack 来维护 call stack。但在 resume coroutine 时，luaV_execute() 间接地递归调用自己并在 callee 的循环中执行 resumed coroutine。也就是说由 CRT stack 来维护 coroutine 上下文切换。Yields 的机制是 longjmp 回到 luaV_execute() 函数递归调用自身的下一条指令 (虚拟机的 native 指令而非 byte-code 指令)，同时把 CRT stack 恢复到 resume 前的状态。所以 yields-in-C 会破坏 C 函数的 call stack。\\n\\n尽管 coroutine 涉及了对 CRT stack 的操作，但是和 error 一样，仅限于 ANSI C 支持的 longjmp，不会破坏 Lua 虚拟机的跨平台性。问题是，为什么 Lua 要在总体的 stackless 设计中制造这个 stackful 例外？首先退一步说，即使采用 stackless 方式实现 coroutine 切换，仅仅能避免在 yields-in-byte-code 中使用 longjmp，仍然无法避免在 yields-in-C 中使用 longjmp。这是因为，虽然不再有必要 longjmp 回到最近一次 resume 之处，但是仍然需要从 yield 之处回到最近的 Lua 虚拟机代码。不仅如此，stackless 方式还要给 resumes-in-C 引入类似的 longjmp (因为不再利用 CRT stack，所以 resumes-in-C 也必须立即回到 Lua 虚拟机代码)，破坏调用 resume 的 C 函数的 call stack，给 resumes-in-C 加上同现在的 yields-in-C 一样的局限性。而现在的 stackful 方法则完全没有这方面的问题。这正是无需 lua_resumek() 的原因。Stackful coroutine 是一个非常巧妙的设计。\\n\\n2013/05/09\\t Leave a reply\\nProgramming in Lua（四）－ Nil 和 List\\n\\n粗浅地看，Lua 的 nil 很容易被等同于「无」。如下面这段代码：\\n\\nfunction r_nil()\\n    return nil\\nend\\n\\nfunction r()\\n    return\\nend\\n\\na = r_nil()\\nb = r()\\n\\nprint(a .. \\", \\" .. b)  -->  nil, nil\\n尽管函数 r_nil() 和 r() 的返回语句分别带有和不带有 nil，接受它们返回值的变量 a 和 b 的值都是 nil。另一个例子是 nil 对 table 的作用。\\n\\ntab_v = { attr1 = 1, attr2 = 2 }\\nfor k,v in pairs(tab_v) do\\n    print(k .. \\", \\" .. v)\\nend  -->  attr1, 1\\n     -->  attr2, 2\\n\\ntab_v.attr1 = nil\\nfor k,v in pairs(tab_v) do\\n    print(k .. \\", \\" .. v)\\nend  -->  attr2, 2\\n将 table 的一个 field 赋值为 nil 不仅仅改变其值，而是让这个 field 本身消失了 (这个例子中是 field attr1)。\\n\\n分析 nil 的实际含义可以从 Lua 的另一个比较特殊的概念 —— list 入手。List 的特殊性在于它不是 first-class 类型。「First-class」是动态语言中常被提及的概念。编程语言有越多的构成元素符合 first-class 标准，其概念模型就越一致、越简单。Lua 的基本数据类型 (包括 nil) 和函数都符合 first-class。满足 first-class 标准通常有四个要求：\\n\\n可以被赋值给变量；\\n可以作为参数；\\n可以作为返回值；\\n可以作为数据结构的构成部分。( 注意 nil 并不完全符合这个要求，但是可以通过某个 field 的缺失来表示 nil。)\\n在《Programming in Lua, 2ed》的第 5.1 节提到 list 只能用于四种情形：\\n\\nThese lists appear in four constructions in Lua: multiple assignments, arguments to function calls, table constructors, and return statements.\\n\\nList 有两种具体的表现形式，一种是用逗号分割的一组表达式，表示一个具体长度的 list；另一种是三个点构成的省略号 (...)，表示其长度和内容不定。第二种表示方式不能用在 multiple assignments 的等号左方，也不能创建新 list，只能从函数的形式参数列表中获得。由此可以看出，list 不符合 first-class 标准：\\n\\n它的部分内容可以赋给几个变量，但本身不能作为整体赋给变量；\\n它是参数列表的全部或一部分，但不是任何参数 (注意两者的区别)；\\n它不能作为数据结构的构成部分。注意，「...」不能作为 closure 的 upvalue。用 first-class function 存储 list 的方式行不通。\\n作为非 first-class 类型，list 无法被生命周期较长的数据结构存储。短期的完整传递 list 的内容只能利用函数调用/返回的方式：\\n\\nfunction f_outer(...) -- important: f_out() must accept\\n                      -- \\"...\\".\\nend\\n\\nf_outer(f_inner())\\n-- pass the list returned by f_inner() to\\n-- f_outer() as the latter\'s argument list\\n\\nf_outer(1, 2, f_inner())\\n-- pass f_outer() a new list, which is \\"1, 2\\" appended\\n-- by f_inner()\'s returned list\\n\\nfunction f_caller(...)\\n   f_callee(...) -- pass argument list of f_caller()\\n                 -- to f_callee()\\n\\n   return f()    -- pass list returned by f() to one\\n                 -- level up\\nend\\n另外还有一些反例：\\n\\nfunction f_caller(...)\\n   a, b = ...   -- not pass a list, \\"a, b\\" is\\n                -- a different list of two elements\\n                -- obtained by adjusting the \\"...\\",\\n                -- and this list is very short-live,\\n                -- existing in this line only\\n\\n   tab = {...}  -- not pass a list, tab won\'t\\n                -- have fields for nils in the \\"...\\"\\n\\n   local function test(a, b)\\n   end\\n   test(...)    -- not pass a list, test()\'s\\n                -- argument list accepts only the first\\n                -- two items of \\"...\\"\\n\\n   for i in ... do  -- the \\"for\\" uses only the first\\n                    -- three elements in \\"...\\"\\n                    -- (two accepted by for internally,\\n                    -- and one received by i)\\n   end\\nend\\nList 会成为 Lua 中为数不多的非 first-class 类型是因为它实际代表了 stack 上的一段数据。一般只有动态分配的数据能作为 first-class 类型，操纵 stack 上的数据则只能通过函数调用的参数和返回值等有限的方式进行 (这也是因为 stack 在一定程度上代表了程序的 continuation)。不过在其它语言中，stack 的内容并没有被抽象为类似 list 这样可以被操作 (尽管不能像 first-class 类型那样自由地操作) 的概念。因为 Lua 提供了多返回值，鼓励可变参数以及参数/返回值和 table 的互相转化，特别是它著名的 C 接口就以 stack 为中心来设计，所以它有了独特的 list 概念来操作 stack。\\n\\n如果在 Lua 中一定要将 list 和 first-class 混用怎么办呢？比如说，一个函数返回的 list 通常还是要存储在变量中，或者应用在某个表达式中。这是上面的反例代码中已经提及的机制 —— adjustment。Adjustment 并不是真的传递一个 list 的内容，而是用一个 list 的内容构建另一个新的 list。当新 list 的长度小于原 list，多余的值被丢弃，当新 list 长度大于原 list，就用 nil 补齐。\\n\\nLua 的 nil 担当了三种角色：\\n\\n一般的数据类型，通常标志某种特殊情况 (应用或算法本身的特殊情况，而非语言的特殊情况)。\\nTable field 的删除器。\\nList adjustment 的补全值。\\nLua 的 nil 不代表「无」，反而恰恰起到了「有」的作用。在应用 adjustment 的情况下，我们往往用新 list 末尾的 nil 来判断原 list 的「无」。这个做法有一个缺陷：无法辩别原 list 末尾本来就确实含有的 nil。如果需要区别对待 list 结束和 list 本身含有 nil 这两种情况，既可以自行编写 C 代码来检测 stack，也可以使用 Lua 现成的 API select()。回到第一个例子，稍加修改就可以区别两种情况：\\n\\nfunction r_nil()\\n    return nil\\nend\\n\\nfunction r()\\n    return\\nend\\n\\na = select(\\"#\\", r_nil())\\nb = select(\\"#\\", r())\\n\\nprint(a .. \\", \\" .. b)  -->  1, 0\\n下面是精确区别 list 结束的一个实际例子 —— 关于 stack 的递归终止条件。若希望一个函数对它的 argument list 中的每个参数执行 op() 操作：\\n\\nfunction map_list(op, ...)\\n    if select(\\"#\\", ...) == 0 then\\n        return\\n    else\\n        local a = ...\\n        return op(a), map_list(op,\\n                               sub_list(...))\\n    end\\nend\\n函数 sub_list() 返回的 list 是其接受的 argument list 去掉第一个元素。这个函数的实现如下 (如果用 C 语言来实现会更简单)。如果 op() 允许接受 nil 并且在此情况下返回有意义的值，或者 map_list() 接受的 list 在中间含有 nil，那么 map_list() 的递归终止条件就必须基于 select() 而不可以基于对 nil 的判断。\\n\\nfunction sub_list(...)\\n    local list_start\\n    function list_start(start, ...)\\n        if start > select(\\"#\\", ...) then\\n            return\\n        else\\n            return select(start, ...),\\n                   list_start(start + 1, ...)\\n        end\\n    end\\n    return list_start(2, ...)\\nend\\nList 是 Lua 中最不符合 first-class 的数据类型。但由于其不能作为变量但可以被函数的返回值构建的特性，List 反而可能是 Lua 中最纯粹的 functional programming  元素。放弃 table 而完全用 list 来编写 Lua 程序也许是把 Lua 转化为一种 FP 语言最简单的手段。\\n\\n2012/12/22\\t Leave a reply\\nProgramming in Lua（三）－ Yields in C\\n\\nHandling Yields in C 是 Lua 5.2 的重大改进之一，最早从 blog《Lua 5.2 如何实现 C 调用中的 Continuation》了解到。这些资料围绕新 API lua_yieldk，lua_callk，和 lua_pcallk 来介绍这个新特性，自然有很多关于新增加的 continuation 参数的讨论。其实以 continuation 参数作为切入点介绍 yields-in-C 容易混淆问题的实质。首先回顾一下《Programming in Lua, 2ed》(中文版) 中的一段话 (第 30.1 章)：\\n\\nThe only way for a C function to yield is when returning, so that it actually does not suspend itself, but its caller — which should be a Lua function.\\n\\n这段话针对 Lua 5.1 而写，当时尚无 continuation 参数。严格地说这会误导读者。根据描述本身，可以理解为 Lua 无法在 C 代码中 yield (包括被 C 代码再次调用的第二层 Lua 代码以及之后的 stack 上更深的执行层次) 是因为无法纪录这种情况下 resume 所需的信息 —— C 代码的 stack 和 program counter。这种解释的推论是，在 C 代码即将返回 Lua 前，由于 C stack 已经恢复为调用前的状态 (可以称为「空 stack」)，program counter 也处于即将进入 Lua 代码的状态，所以可以调用 lua_yield。原理上这个结论可以推广到 lua_call/lua_pcall。如果程序在 Lua 和 C  代码之间调用切换多次，整个 virtual stack 上的 Lua 部分的 stack 会被 C 代码分割成若干段。不过只要这三个 API 总是在 C 代码即将返回 Lua 前被调用，那么这些 C stack 都是空 stack，Lua VM 只需知道 C 代码在 Lua stack 段间的位置，不需要实际纪录 C stack/program counter 本身的内容。「在多于一层 C/Lua 切换的情形下 yield」应该正常工作。\\n\\n问题是 Lua 5.1 不支持「在多于一层 C/Lua 切换的情形下 yield」！\\n\\n根据上面的分析，这个限制并非 Lua 语言或 C API 本身的设计所固有，它是一个纯粹的 VM 实现问题。也就是说，即便 Lua 在 5.1 之后不引入 continuation 参数，保留「lua_yield (以及 lua_call/lua_pcall) 只能在即将返回到 Lua 之前调用」这个限制，也还是可以支持从 C 或者从第二层及以上的 Lua 代码中 yield。\\n\\nLua 5.2 实现了「在多于一层 C/Lua 切换的情形下 yield」，这是一个 VM 内部改进，仅仅为此并无必要引入 continuation 参数。 Continuation 参数解决的是另一个问题 ——「Lua 无法跟踪程序在 C 代码中的 stack 和 program counter」，但仍保留诸多限制：首先，它无法解决纪录 C stack 的问题，所以，仍然不允许在 C stack 上有多于一层 C 函数时调用新 API；其次，它也无法纪录 program counter，编写 C 代码时必须手工把可能发生 yield 之后的 C 代码 factor 到一个单独的 C 函数中，通过函数分割这种变通方式部分的模拟 yield 时的 program counter。由于没有真正的管理 C stack，充当 continuation 参数的 C 函数在运行中不能依赖 caller 的 C stack (实际上这个问题不大，因为它只能接受一个 lua_State 结构)。最后，仿照某些评测给 Lua 5.2 的新特性做一个「优雅 / 有待改进 / 丑陋」的总结：\\n\\n优雅\\n\\n实现了「在多于一层 C/Lua 切换的情形下 yield」。对于「Lua 无法跟踪程序在 C 代码中的 stack 和 program counter」这个问题的剪裁得当，既扩大了支持的应用场景，放松了对 C 代码的限制。同时避免了编程接口过分复杂化，和使用底层 C runtime 机制破坏 VM 的跨平台性。\\n\\n有待改进\\n\\n文档没有分别说明两个问题，混淆了 VM 内部实现的改进和 API 改变的原因。\\n\\n丑陋\\n\\n新 API 在 continuation 参数为 NULL 时沿袭旧 API 的限制 —— 禁止在多于一层 C/Lua 切换的情形下 yield。这是不必要的，也是混淆两个独立问题的误解最大的来源。现在，对于那些已经在「即将返回 Lua 之前」被调用的 lua_yieldk/lua_callk/lua_pcalk，也必须传入一个 no-op 的 continuation 函数。不过，Lua 5.2 的发布已经有段时日，估计这个 API 上的小问题也不会再未来更改了。\\n\\nProgramming in Lua（二）－ 异常与错误码\\n\\n我不喜欢编程语言用「异常处理 (exception handling) 」的方式处理错误。从以往经历看，先有 C++ 创造了最差的异常实现 —— 没有 GC 帮助内存管理，扰乱 C 的二进制接口 (Application Binary Interface, ABI)。为了绕过这个拖累，维护 C++ 代码往往要花费双重开销来完成没有异常的语言可以免费获得的东西：code review 必须保证代码的「异常安全 (exception-safty)」[1]，同时不写会抛出异常的新代码。\\n\\nJava 提供了 GC，解决了安全实现异常处理最大的的先决条件。不过凡事皆 checked-exception 的方式令人毫无好感 [2]。Objective-C/Cocoa 中没有跨越 block 的异常机制，基本上采取传统的返回错误码方式，让我舒了一口气。但是接下来，Lua 通过 longjmp 实现跨函数的类似异常处理。一方面，让我怀疑 Lua 以简洁著称的设计是否在这点上采取了错误方式；另一方面，longjmp 并未实际引起麻烦，让我好奇异常处理是否也有某些价值。\\n\\n异常处理和传统的返回错误码 (error code) 两种处理错误的方式是一场持久的争论。就在最近，围绕 Go 语言完全抛弃异常处理的语言特性，《Why I’m not leaving Python for Go》的作者表了极大失望。\\n\\nRuss Cox 针对上文为 Go 语言进行了辩护。其中提到了 Raymond Chen 两篇旧日的 blog：\\n\\n《Cleaner, more elegant, and wrong》\\n《Cleaner, more elegant, and harder to recognize》\\nRaymond Chen 用严密的逻辑和实例说明了编写正确异常处理的代码 [3] 非常非常困难。特别要注意 (但不限于) 以下两点：\\n\\n正确管理资源，特别是资源的回收；\\n关键数据的修改尽可能滞后。在中间可能抛出异常的步骤中，随时保证数据处于一致 (integral) 的合法状态。\\n关注第一点也许会令人假定，如果程序不涉及内存以外的资源，并有成熟的内存管理机制，就足以保证写出正确的异常处理代码。毕竟把异常处理放到 feature list 中的语言无不首先重视提供 GC 机制。由于需要根据异常的 stack unwinding 情形考虑内存回收，这些语言一般采用 root-tracing GC 而非 ref-counting [4]。但是，将资源管理局限于内存并不足以对第二条豁免，比如复杂的图结构 (graph structure)，或者更常见的情形：对象需要向多个相互关联的全局表注册自身的引用。而且话说回来，「纯」内存数据操作除了内存用尽 (out of memory) 之外又有什么值得担忧的错误需要处理呢？归根结底异常处理是一个主要面向 I/O 问题的机制。\\n\\n在「纯」内存无 I/O 的环境下，能体现异常处理价值的领域并不多，仅存的适用领域之一是语言虚拟机。这正是 Lua 采用 longjmp 类似异常处理的原因，主要用于类型检查和数组越界等语言虚拟机问题。而且这时处理的错误往往不是最终产品代码 (production code) 期待的行为，并不真正用来弥补错误，只是起一些辅助作用，比如揭示 bug 和收集诊断信息，防止应用完全退出，在多文档应用中让用户有机会保存其它信息，或者让应用以 reset 之后的状态接受其它请求。类似于 Go 中的 panic 机制和 Java 中的 runtime-exception (unchecked excpetion)。\\n\\nGC 虽然是实现安全的异常处理机制的先决条件之一，但只是朝向最终解决问题的很小一步。因为真正能体现异常处理价值的地方是 I/O 密集程序。有哪些 I/O 机制目前可以做到「关键数据的修改尽可能滞后。在中间可能抛出异常的步骤中，随时保证数据处于一致的合法状态」呢？作为 naive 的尝试，C++ 提出了 RAII。但是很遗憾，异常安全的需求明显超出了 RAII 的能力。除了关系型数据库事务处理 (RDBMS transaction) 的二步式提交 (two-phase commit)，我不知道还有什么 I/O 机制满足这个要求。也就是说，在日常需要的软件工具中包括图形化窗口化 UI，网络，打印等等常见 I/O 操作中，只有纯粹的数据库 CRUD 系统这个特殊领域适于异常处理机制。正因为如此，非数据库的 I/O API 的错误处理都应该采取返回错误码形式。特别是，以异常处理文件访问错误的 API 都是失败的设计 [5]。Java 正是被鼓吹适合数据库 CRUD 领域，所以其异常处理机制获得了一些正面评价。但是当其野心不限于此时，将仅限于数据库领域用的还不错的异常处理机制匆忙的推广到其它问题就招致了恶名。\\n\\n某些系统通过异常处理或者类似异常处理的机制来解决某些问题，而且解决得还不错。这是它们的设计者针对一些能体现异常处理价值的特定领域选择的方案。这些成功案例并不能简单地推广。保守地说，要采用异常处理，必须保证所有资源置于二步式提交的事务管理之下；或者限于虚拟机内部对类型检查等非 I/O 操作的「粗粒度」错误处理。「粗粒度」表示一旦发生错误，系统采取的应对策略是放弃整个粒度较大的操作，异常处理仅仅保证程序不退出，收集 bug 诊断信息，或者保留机会处理其它请求，而不是去弥补刚发生的错误。特别是对于 Lua，这个问题还有一层含义。Lua 允许用 C 编写扩展。这种情况下要把基于 longjmp 的异常处理部分限于开始的参数类型检查，置于触及关键数据和 I/O 操作之前，一旦 C 代码涉及了实质的数据和 I/O 操作，错误处理方式就必须变为返回错误码机制。Lua 支持多返回值特性正是为返回错误码方式的应用提供便利。显然，Lua 的可扩展性也是其基于 longjmp 的机制彰显天下的原因，对于 Java 来说，虚拟机内部的具体实现和使用它的程序员是毫不相关的。\\n\\n脚注：\\n\\nC++ 中所谓的「异常安全」也不过就是尽量使用 on-stack 对象 (以及基于 on-stack 对象的「智能」指针) 和 RAII (下文还有涉及) 而已。\\n错误处理有经常被人混淆的两个方面。一是如何保证程序员不忽略可能的错误；二是在程序员意识到可能的错误时，如何编写正确的处理代码。本文只讨论第二个方面。因为，如何「不忽略可能的错误」属于程序员掌控应用逻辑的问题，已经超出了编程语言的能力。Java 的 checked-exception 试图用语言解决这个问题，但是即便是 checked-exception，也允许程序员相当容易的把异常遗留给上层 caller。其结果是，越多的错误集中在一处处理，而且远离错误发生的地点，这段异常处理代码的正确性就越难保证 (或者这段代码除了 crash/quit 无法做任何其它有意义的工作)。也许，这正是没有任何其它语言借鉴 checked-exception 机制的原因。\\n注意这里的「异常处理的代码」指程序员用具备异常处理机制的语言编写处理实际错误的代码，不要和异常机制本身的实现混淆。\\nObjective-C/Cocoa 舍弃异常处理的可能原因之一。另一方面，如果在 stack unwinding 时进行特定的处理，也可以用 ref-counting GC 配合异常。比如 C++ 调用 destructor 以及由此衍生的「智能」指针，还有 Python 的机制。但是我不喜欢这种将 unwinding 复杂化的机制。\\n导致每行一个 try-catch block。\\n"}'));jctx.push(JSON.parse('{"id": "180410", "tag": "lang", "text": "# JS和AWK语言的new和delete\\n\\n## new\\n\\n在JavaScript中，使用new关键字后，意味着做了如下四件事情：\\n\\n1. 创建一个新的对象，这个对象的类型是object；\\n2. 设置这个新的对象的内部、可访问性和prototype属性为构造函数（指prototype.construtor所指向的构造函数）中设置的；\\n3. 执行构造函数，当this关键字被提及的时候，使用新创建的对象的属性；\\n4. 返回新创建的对象（除非构造方法中返回的是‘无原型’）。\\n在创建新对象成功之后，如果调用一个新对象没有的属性的时候，JavaScript会延原型链向止逐层查找对应的内容。这类似于传统的‘类继承’。\\n\\n注意：在第二点中所说的有关prototype属性，只有在一个对象被创建的时候起作用，比如使用new关键字、使用Object.create、基于字面意义的（函数默认为Function.prototype，数字默认为Number.prototype等）。它只能被Object.getPrototypeOf(someObject)所读取。没有其他任何方式来设置或读取这个值。\\n\\nLua也是基于原型的语言，虽然它并没有自带new关键字，但可以从第三方库看到模拟。比如loop库的实现，就执行了 `setmetatable(object or {}, class)`，使用一个现有或创建新对象，并将这个对象的元表指向另一个表，关键特性和JS一样。\\n\\n由此可以看明显看出和基于原型和基于类的构造差异。比如C\\\\+\\\\+的new，第一步类似，开辟一段新的空间存放对象，不可能有第二步设置原型指向动作，直接把这块新的空间作为this指针执行构造函数，最后返回对象相同。\\n\\n## delete\\n\\n带有垃圾回收的语言，很大的好处分配对象不需要手动考虑回收的问题。但JS和AWK的关联数组对象，允许用delete语法手动删除某个指定元素，GNU的AWK扩展还允许用delete obj;这种语法把obj内的所有key value对一次性全部删除。\\n\\n须知GC的运作要依赖对象的可达性或计数值，但不论是哪种，关联数组内的成员的生命周期都受外层变量的控制，无法单独的让GC去释放。类似的问题还出现在函数的upvalue上，只是因为upvalue是匿名的，而且和函数模拟的对象有密不可分的关系，因此只针对关联数组提供了delete语法。\\n\\n之所以会想到这个问题，是因为lua5.4的work1版有个很大争议的改动：table中nil到底是什么语义。到5.3版本为止nil是相当于delete语法的作用，但这就产生了另一个不一致，nil作为基本类型却无法放入table中。这种不一致让语言的作者觉得是个必须要解决的问题。\\n\\n比较两种语言的使用方式，这大概就是delete存在的意义吧。\\n\\n## 附：AWK语言\\n\\n在shell中诸多工具中，AWK是相对功能最丰富的工具，只有它可以创建函数。整体代码结构由复数个awk rule和可选的函数定义组成，每个rule由pattern和action两部分构成。pattern可以省略，默认捕获整行，action就是要做的动作。最常用的pattern是匹配一行中某部分的内容；另外有两个特殊的pattern，分别是BEGIN和END。如果只有BEGIN块，AWK会跳过读文件步骤，此时相当于执行脚本自身，可以利用这个特性，执行一些略复杂的逻辑。但如果除了BEGIN外还有END块，awk会默认附加一条打印输入行的行为，执行后会停留在读stdin阶段。\\n\\n整个脚本会编译两次，先找出函数定义，再编译awk rule（和JS有点类似）。所以函数块可以放在任何位置，为了不遮挡主体逻辑，建议把函数块放最后。示例如下\\n\\n```\\npattern {\\n   action\\n}\\nfunction xxx() {\\n}\\n\\npattern := BEGIN | END | /regex/\\n```\\n"}'));jctx.push(JSON.parse('{"id": "180411", "tag": "book", "text": "# 分叉者BCC\\n\\n伪装成天使的魔鬼——BCC\\n\\n详解比特币扩容/隔离见证始末，揭露BCC实质，写给小白的BCC内幕全解\\n本文将简要介绍比特币扩容/隔离见证之争始末，着重分析矿池、Core、用户团体三方的利益博弈，揭露Viabtc推出BCC的用意。作为比特币爱好者，旨在号召币圈人士着眼于比特币长远发展，反对BCC，反对任何形式的分裂。\\n\\n一、比特币扩容/隔离见证之争的背景\\n任何一个在币圈浸淫多年的比特币玩家都会有一个基本的共识，那就是比特币作为数字货币的龙头，是其他山寨币的价格标的，比特币今天的市值高度基本上决定了其他山寨数字货币的市值上限。整个币圈各类山寨币的未来发展，其实很大程度上取决于比特币的走向。即使在山寨币大行其道，成就了“区块链元年”疯牛的2017年，只要比特币下跌调整，各类山寨币几乎无一幸免。可以大胆预测，在未来近几年内，不会出现超越比特币地位而存在的山寨币种。\\n然而比特币“扩容/隔离见证”的问题悬而未决，以至于比特币涨幅，在今年大牛市的行情中，与众多后起之秀的山寨币相比，完全败下阵来，甚至于在数字货币总市值占比中让出主导地位，跌破50%。\\n为什么“扩容/隔离见证”的问题对于比特币而言尤其重要？我们说投资某标的，最重要的是要分析其内在价值，回到投资物的本质上，也就是回到基本面上。比特币虽然头顶着“区块链技术未来大趋势”的光环，但它代表不了区块链。当前来看，比特币本质的价值在于其解决了当前流动资金支付与转账的痛点，尤其是跨境跨币种结算。因比特币的匿名性、全网交易可查的安全性以及低手续费且交易便捷的基本属性，使得比特币有望突破和改变当今缓慢、繁琐的结算体系。也可以说，比特币目前真正的使用价值，实际上体现在场外交易上。\\n自从中国各大交易所受央行调查监管以及平台自身兑付问题影响，在今年年初决定暂停充提币开始，比特币的场外交易量便开始井喷式增长。一时间，比特币区块上挤压的交易量猛增，一度突破10万笔滞留交易。二级市场上的投机交易，逐步转移至场外交易。以往至多只需要半个小时的交易确认，当时需要花上超过24小时甚至更长时间的等待。为了能让交易迅速被矿工打包确认，比特币交易者不惜交付高额的手续费加速交易。至此，比特币的基本面遭到严重破坏——交易迅捷、手续费低廉的优势丧失。一定程度上促进了场外交易者寻求新币种替代比特币交易的局面。以太坊ETH等山寨币获得了发展良机。\\n而“扩容/隔离见证”就是为了解决区块拥堵和手续费暴增的问题。由此可见，“扩容/隔离见证”问题是比特币乃至整个数字货币圈最最重要也是最最紧迫的问题。妥善解决，比特币将获得新生，整个币圈也将获得前未所有的突破性发展；反之，比特币可能面临分裂，整个币圈可能开始重演2014-2015年的萧条。\\n实际上比特币“扩容/隔离见证”的问题已经在比特币圈内讨论多年，简单回顾，无非是矿池扩容派和Core团队隔离见证派的斗争。两派斗争纠缠不息，而后用户团体的代表：各大交易所以及比特币支付公司（如bitpay等面向用户的技术公司）也加入斗争，究竟改扩容还是隔离见证迟迟悬而未决，各种“BIP”、“Segwit”、“BU”等等专业词汇，也让新入币圈的小白和投机者看得是一头雾水。\\n那首先就来解释一下这些概念吧。\\n二、什么是“扩容”？什么是“隔离见证”？\\n扩容即是所谓的“硬分叉”（hard\\nfork），比特币一条区块链变成两条链，由矿工的大多数算力决定继续挖原链或是新链，绝大多数矿工若挖原链，新链死；反之，挖新链，原链就此告别历史舞台。也有可能两条链都保持一定的算力，从此二链共存，比特币正式分为两个币，新币和原有币，就像ETC分裂出ETH一样。目前扩容派为了解决交易拥堵问题，希望把原来的区块大小1M改为2M，也就是分出一条2M的链，把绝大多数的算力切换到2M的新链上来，既保证比特币不被分裂，又能使得交易拥堵获得解决。\\n隔离见证（Segwit）是所谓的“软分叉”，为Core所支持，它是将比特币的每笔交易信息切割简化，使得每一笔交易的大小降低，并且在此基础上应用闪电网络（Lightening Network），届时，小额的比特币交易将以合约的形式在闪电网络上交易，到期结算，将区块链上的交易数量减少，从此达到不分裂比特币，同时也解决拥堵的问题。\\n事实上双方都不希望比特币分裂，但两种解决拥堵的方案一直决定不下来，究竟是为什么？\\n三、“扩容派”和“隔离见证派”的利益分析\\n抛开“为了保有中本聪原有的比特币设置”、“防范比特币被某某团体把持，变为中心化货币”等等口号，其实只要做简单的利益分析就不难看出两方的需求。\\n首先是矿工/矿池这一方，矿工的利益来源在于挖矿，实际上，如果比特币区块堵塞，矿工可以获得超额手续费，短期收益是增加的。但长期来看，只有比特币价格不断上涨，挖矿的收益才会大幅提升。因而，从长远考虑，只有当比特币交易更加顺畅，入场人数增多，资金盘越来越大，矿工的收益才会获得显著增长。扩容将导致短期内手续费减少、挖矿收益降低，而隔离见证加闪电网络如果一经运作，小额的交易将不通过区块确认，矿工连少量的手续费都收不到。虽然闪电网络承诺将结算收益分利作为手续费补偿，但是如此一来，矿工将在很大程度上受制于闪电网络。因而为了更长远的利益，矿工希望扩容。\\n然后是Core/开发者这一方。Core在2015年6月份开始就不断提出各种方案，包括隔离见证与各种形式的扩容，但都没有得到广泛支持。而最近两年内Core开始坚决反对扩容，矢志不移地推行隔离见证。要分析Core的利益诉求，我们不得不提Blockstream这家公司，其创始人Pieter Wullie本是Core成员，在2015年12月提出Segwit失败后，离开Core成立这家公司，其目的在于掌握比特币的核心技术。事实上，闪电网络也是由Blockstream研究开发。不可否认闪电网络发明确实是对区块链技术的重要延展，其在莱特币上已经率先使用，决定采用隔离见证也使得莱特币在今年终于甩掉了“横盘小王子”称号。而反观Core现今的开发团队，三人话事的团体里，有两人都是属于Blockstream，着实引人遐想——Core的决策不可能不带有Blockstream的利益诉求。而这也正好解释了为什么Core一定要进行隔离见证并且应用闪电网络。因为在比特币上运行闪电网络使Blockstream极大受益。\\n除了上述两方，还有一方是用户，主要是各大交易所。他们对于无休止的斗争已经看不下去了，于是提出了“用户激活软分叉”（UASF）。意思就是你们再吵下去没有结果，8月1号我们就自行开始软分叉，并且拒绝接收原链的币，逼迫矿工只挖新链。这里要注意的是，用户团体提出的USAF与Core的软分叉稍有不同，如果与矿工不能保持一致性，有很大的风险会将比特币分裂。\\n为了应对UASF，矿池方面和Core终于能坐下好好谈谈了。\\n四、纽约共识\\n双方扯皮逾时两年，终于迎来了关键节点。所幸，矿池与Core双方为了避免比特币被分裂，在James Hilliard的提案中达成暂时的妥协，这就是BIP91方案，也就是俗称的“纽约共识”（Segwit2x）。这个协议是双方的妥协，具体分成两部分。首先让矿工发起投票，80%以上占比通过激活隔离见证的方案，然后，在隔离见证实施2个月之后再将比特币区块扩容为2M。\\n7月份，比特币行情上蹿下跳“牛转猴”，积极配合着比特币未来忽左忽右的未来走势，终于在大多数矿池的集体投票决定下，通过激活隔离见证，比特币从13000多暴涨反弹至19000人民币。比特币未来扩容与否，虽然仍不能百分百地确定，但分裂的预期已经消退。高盛也终于在长达两个月的唱多中找回一些颜面。\\n表面上看，这场风波似乎告一段落，但其实暗流涌动。与其说BIP91是Core与矿池双方之间的妥协，不如说是矿池在UASF面前被逼无奈的让步。为什么这样说呢？隔离见证是矿工除分裂外最不想见到的结果，一方面大权旁落Core和Blockstream，另一方面闪电网络一旦应用，矿工的收益也要在一定程度上与其竞争。更让人不放心的是，如果2个月后Core又提出新方案，拒绝支持扩容2M，矿工方又要受到重挫。\\nSegwit在激活之后各大论坛一片叫好，比特币爱好者们终于松了口气，庆幸比特币起码不会在年中分裂，也有非常乐观的投机者认为比特币将在下半年迎来二次牛市。更有人认为Core的阶段性胜利非常关键，纽约共识打破了矿工希望以算力把持比特币未来走向的妄想，削弱了矿池“中心化”比特币的能力。悲观者却认为，Core必定将在两个月后继续与矿池扯皮，最终使得扩容方案无疾而终，从而使得Core占据比特币的领导地位，Blockstream从此把控比特币的核心技术，反而Core会将比特币“中心化”。\\n这种表面的和谐还没持续几天，比特币又迎来了让所有人意想不到的突发事件。\\n五、BCC\\n国内矿池/交易所Viabtc突然宣布上线BCC，作为比特币的“竞争币”，以应对隔离见证实行后可能出现的变局（“用户激活硬分叉”UAHF）。从即日起，所有用户可以充值比特币到该平台，并将手里的比特币一分为二成BCC和BTC_FROZEN2，BCC作为期货交易在该平台上线交易，开盘标价3000RMB/枚。BTC_FROZEN2币冻结直至8月1号UAHF执行之时。业界预测，该矿池有可能在8月1日切换算力至BCC，直接分叉比特币。\\n这是什么意思呢？大部分人都不知道为什么Viabtc会突然跳出来唱这么一出，况且，Viabtc还签署了纽约协议。\\n先从技术上来看。BCC（Bitcoin Cash）的区块大小定为8M，并且实行新的动态难度机制，12个小时之内如果挖出的区块不足6个，则将下一难度下降25%，并且协议上BCC剥除了隔离见证的可能。所以，在技术上看，BCC既应对了拥堵问题、降低了交易手续费，而且还怼了Core一下。\\n表面上看，确实如此。先不做评论，来看看业界的反应。\\n1. 各方立场之于BCC\\n先来看看交易所。Okcoin在消息出来的随后几天里决定也上线BCC，但是要特别注意的是，Okcoin上线BCC的平台是OKEX，而非中国站抑或国际站，一方面可能是考虑到目前BCC仍然是“空气”，有名无实，只能做期货交易，另一方面可能是对BCC持有谨慎的态度，但又不想错过这个“万一”。另，火币在临近发稿前也宣布上线BCC。除此之外，其他的各大交易所保持了中立的态度，中国比特币等平台在较早时间已暂停比特币充提业务，以防范8月1号可能出现的攻击风险。\\n再来看看矿池方面。作为矿业最大的Boss，三大矿池的投资者比特大陆发表声明称，Viabtc仅仅是其投资的矿池，表明并未对Viabtc的决定形成影响，意思是Viabtc的决定与我无关。而币信在日前发表声明直接开怼，声明直指BCC可能会造成矿池“双挖”，成为“机枪池”，“……如此一来，可能会造成比特币算力剧烈波动，给比特币网络带来一定混乱，造成算力黑洞，影响比特币网络正常出块……”，并且“……呼吁广大矿池、矿工保持理智，不因短期利益改变初衷，造成长期利益的损失……”。再有莱比特矿池，年初讨论莱特币隔离见证时，江卓尔声称如果莱特币走隔离见证，将会将手里的算力进行攻击，以破败隔离见证的实行，促使莱特币扩容，态度十分强硬。而在比特币的问题上，江卓尔却站在中立方表示“尊重对方的选择”。\\n由此可见各方立场分野——多数交易所选择上线BCC，其他保持审慎中立；矿池方多保持中立，币信立场鲜明地反对。\\n为什么一个BCC会造成用户团体和矿池/矿工团体内部的不一致。打开各大论坛网站，你会发现近期很多的文章讲解BCC的时候，会将BCC作为“比特币的竞争币种”和莱特币作类比，或者是借由ETH和ETC的关系来阐述BCC和比特币的联系。这样的文章和言论这段时间屡见不鲜，还有另外一类文章说的是如何使用BCC进行短期套利，也就是将比特币充进Viabtc分割成两个币之后，在期货市场做空比特币，8月1号，白赚3500块钱。事实上都是在模糊化BCC的概念和实质，这些文章极力撇清，称BCC不是分叉币，并且言语模糊地只谈论短期的投机收益，对于中长期矿池的挖矿风险和交易风险完全避之不谈，美化BCC是“积极进取的”，可以促进比特币发展的币种，用意何在？\\n对于这个问题我们暂且不谈，先来看看投机者和小白们面对横空出世的BCC最常有的两个问题。\\n2. 两个问题\\n直接断言BCC百害无一利可能有失偏颇，那么先来看看这两个问题：\\n第一个问题：为什么扩容到2M你们矿池全部支持，扩容到8M你们要么中立、要反对了？以后2M区块堵塞了不还是要扩容吗？一次到位难道不好？\\n第二个问题：ETH和ETC都是这么过来的，你看看它们的涨幅，为什么这么反对两个币并行呢？\\n首先回答第一个问题，扩容成2M的共识得到矿池广泛同意有两个原因：\\nA.防止用户团体8月1号实行UAHF造成分裂，缓兵之计。\\nB.多数矿池已经表明态度，在Segwit2x施行两个月后，也就是10月份左右扩容2M之际，将算力全部切换到扩容后的链上，消灭原链，以保证比特币不分裂。\\n也就是说2M大概率不分裂。\\nBCC此刻上线各大平台，实际上将矿池好不容易与Core达成的一致“纽约共识”撕毁，加剧了矿业的不稳定。\\n为什么当初坚决反对分裂比特币的矿工现在又对8M的BCC保持中立或反对呢？中立的原因在于矿工可以获得短期暴利，反对的原因在于8M可能造成分裂。\\nBCC出来，理论上有三条路：\\nA. 被干掉。矿工们仍然坚持反对出现两个币，联合抵制BCC，8月1号当天对BCC进行算力攻击，没有算力支持的BCC就会胎死腹中，纽约共识会继续生效。然而矿工的算力分配，是看利润决定的，问题就出在这。\\nB. BCC和比特币“二币并行”。如果同一协议的两个币，BCC和BTC，BCC价格暴涨，作为矿工我当然会挖BCC，切换到BCC上挖矿，对矿工而言没有增加更多挖矿成本。鉴于目前BCC在Viabtc交易平台上的价格一直维持在2000-3000RMB左右，还有如此之多的交易平台上线支持，由此一来，8月1号矿工会选择挖哪个币，确实不好说。如果矿工在BCC和比特币上都分配了大量的算力，8月1号之后，可能真的会形成二币并行的局面。不论各类文章如何解释“BCC作为竞争币只会促进比特币发展”、“BCC出来是个好现象”云云，矿池因此分散算力是不可避免的，而且有可能形成“机枪池”，BCC利润高时挖BCC，比特币利润高时挖比特币，而且8M区块会导致更长的广播时间和算力浪费，与此同时，还增加了被DDOS攻击的风险……可以预见，整个矿业会不可避免地陷入混乱。除此之外，BCC与比特币“二币并行”最大的技术漏洞，也是各类吹捧BCC文章避而不谈的缺漏，在于二者代码完全一样，地址也一致。这会造成什么问题呢？以后如果我将比特币发送到你的BCC地址，我的比特币会被吞噬掉，但你也收不到比特币。严重的转账交易混乱将会产生。比特币交易将会面临严重的信任危机，持币者很有可能转而使用以太坊等其他山寨币替代比特币进行交易。\\nC. 还有一种微乎其微的可能，就是所有矿工在8月1号突然全部切换算力至BCC，比特币从此消亡，以后的比特币就是BCC，这种情况在矿圈没有形成一致意见的现状下，基本上是不可能事件，不再赘述。\\n对矿工来说，以目前BCC目前的价格而言，挖BCC虽然有风险（曾经一度算力排名第一的鱼池在比特币区块产出减半调整时，也曾挖过侧链，不幸导致亏损），但确实有利可图。所以一部分矿工保持中立甚至暗地支持8M的BCC，是因为短期内有利可图。而以币信为首的反对声音是出于反对分裂比特币的长期利益的考量。\\n其次，回答第二个问题。为什么ETH、ETC二币并行价格暴涨，而对于比特币要分成两个币就谈虎色变？换句话说，为什么要反对比特币的分裂？\\n币圈里有一句名言“了解比特币和了解比特币技术是两回事”，好像是出自江卓尔。技术是指区块链技术，Core毫无疑问应该是比特币技术的权威，延续中本聪思想是其宗旨。区块链技术势必要对未来产生深刻影响。但比特币不仅仅是代表着区块链技术，它更是一种投资品，了解比特币技术不代表了解比特币金融市场。比特币的基本面由其技术决定，但其价格波动是由市场决定的。我们看看ETH和ETC的历史，ETC从2016年中分裂出ETH，一直是横盘阶段，直到今年年初ETH才正式走上了爆发之路。而且ETH在今年取得如此重大的突破，很大程度上是因为Vitalik及其团队不遗余力地为ETH拓展业务，不断扩大合作团队，在牛市之中接连爆出各种利好，抓住ICO风口，以非常友好便捷的生态体系承接了ICO热。ETH和ETC能暴涨，根本原因不是在于分裂，而是因为其宣传与造势能力。\\n况且，比特币作为数字货币龙头，代表着整个数字货币资金盘面的信心。ETH、ETC分裂之际，ETC也只是作为小盘面的山寨币，就算分裂成8个，对整个数字货币盘面也不会造成很大的影响，对于投机者而言只是增加了投资选项。而比特币的分裂会造成整个数字货币盘面信心的丧失，投机者失去价格标的，数字货币市场会陷入混乱。所以，不能简单的将比特币和BCC与ETH、ETC做类比。比特币要想继续扩大市值，让场外的人不断加入进来，就必须要保证一个币不分裂。这对于整个数字货币投资市场而言都是至关重要的。\\n这两个问题实际上能让我们看清BCC在技术层面和市场层面上的弊端，那为什么用户团体会不顾纽约共识，铤而走险呢？\\n3. 用户团体的利益诉求\\n前文我们分析矿池/矿工和Core的利益诉求，两者殊途同归，一致反对比特币分裂，只不过是手段不同，真正的利益分歧在于交易手续费的取得，一方希望交易在区块上完成，一方希望通过闪电网络收取手续费。以交易所为代表的用户团体也是如此，只不过交易所的收入来源在于场内交易的手续费。因此交易所每天的目标就是扩大用户数量，上线潜力币种，抢占该币种的市场份额。如果我上线了这个币，而别的交易所没有，这个币火了，暴涨了，所有的交易量都会被我占有。中国比特币今年眼光独到，最早上线ETH交易，赶上了ETH疯牛行情，吸纳了大量资金和用户，一度成为世界第一大ETH交易平台，充足的用户量也使其第四大比特币交易所。对于交易所来说，占领先机就是占领了制高点。\\n于是便有了现在的局面，各大交易所轮番表示上线BCC，并出台了各种风险警示，提醒用户注意风险。但明眼人都知道，这不是因为BCC将要取比特币而代之的大势所趋，而是交易所面对8月1号分裂预期的未雨绸缪。谁都不想放弃承接比特币分叉币的机遇。\\n4. Viabtc\\n这个部分是个大胆的猜想，毕竟没有证实。很多人把Viabtc归入矿池团体，其实不然，Viabtc跳梁的做法暴露了其属于用户团体的实质。矿池大致两种，一种是自有矿机，矿池本身拥有矿场自己挖矿，另一种是通过运算力和吸引矿工投资，让矿工自有矿机挖矿，而自己不挖矿。Viabtc属于后者，其真正目的在于扩大Viabtc交易所经营。如果Viabtc本身拥有矿机，属于矿池/矿工团体一方，绝对不会这么干。\\n上线BCC，对于“矿池/交易所”双重身份的Viabtc而言是利大于弊的。首先抢占了比特币分叉币的先机，吸纳大量比特币筹码，用户量显著增加，站内分割比特币为BCC和BTC_FROZEN2冻结了用户比特币资产，不但吸筹，而且不让提走，不断扩大比特币筹码的占比；其次，如果“二币共存”，Viabtc交易所地位大大提升；再有，直接标价BCC，拉升操盘，让摸不着头脑的投机者拱手送出筹码不说，还让投机者交易“空气”，做了一波连白皮书都省略掉的ICO。如果矿池联合，8月开始算力攻击，BCC将大概率不复存在，币市小白们将血本无归。雇几个写手写写“BCC是竞争币”、“BCC是比特币的良性补充”等等避重就轻的文章，即可忽悠小散进场，空手套白狼，无成本套利。在缺乏监管的币圈环境下，交易所之于小的山寨币种拥有绝对的定价权。一家交易所要拉升一个新币种，刷出成交量，是非常容易的事情。这种不以基本面为支撑的价格都是泡沫，矿工短期切算力挖矿也仅仅是昙花一现的“伪需求”。\\n至此，BCC的各方利益诉求已经十分明晰。总结一下，做个预测。\\n5. BCC分裂比特币的结果\\n矿池/矿工团体反对分裂，反对BCC。但如果BCC分裂比特币阴谋得逞，各大交易所BCC价格被操控拉盘上涨，因短期利益，矿工也将会切算力挖BCC，至此比特币正式分裂，矿业混乱，比特币交易混乱，比特币基本面崩盘，整个数字货币盘面由此走衰。\\n用户团体无所谓分不分裂，抢占BCC先机是目前交易所首要考虑的事情。投机者见短期“捡钱”良机会将手中筹码拱手相让，最终血本无归。\\n6. 对于最后一个问题的猜想\\n还有一个问题悬而未决——为什么仅仅只有币信代表矿业发声反对BCC？\\n比特大陆作为矿业最大的Boss，旗下投资的三大矿池加起来的总算力已经足以对任何一个分叉进行算力攻击。Viabtc宣布上线BCC之际，作为矿业大佬，旋即发表声明称Viabtc仅仅是自己投资的矿池，其决定与自己无关，但也没有明确反对BCC。莱比特矿池也是站在中立的立场上说话。\\n貌似势单力薄的Viabtc背后到底有没有别的大佬支持？无从得知。但仔细想想，如果矿业大佬暗地背书Viabtc支持BCC，很难说得通。\\n首先，破坏纽约共识，信誉大损；其次，已经占据矿业主导地位大佬没有必要加速扩大自身的占比，况且风险极大；最后，长期来看，分裂的比特币，对于矿池乃至整个币圈来说都是灾难，当今最大利得者不会去冒这个险。\\n如果这个假设行得通，那么除币信外的其他矿池保持中立就有如下两个可能：\\nA.作为投资方，不好直接否决BCC，8月1号干掉BCC即可。其他矿池看大佬意见行事。\\nB.以假分裂威慑Core，防止Core在隔离见证实行两个月后再次搞破坏拒绝2M扩容。以BCC事件为筹码确保2M扩容顺利通过。\\n六、结语\\n比特币的构想非常伟大，比特币前进的道路也非常曲折。比特币的理想非常丰满，但比特币的现实非常残酷。我们希望比特币在技术上能够不断完善自我，加速推进区块链发展进程，从而解决社会上一个又一个的痛点，改变我们的世界。但作为金融市场中风险极高的投资品，比特币不可避免地，为各种利益团体所挟持。因而更需要我们看清利害，以比特币长远利益为重，反对各种形式的分裂。\\n"}'));jctx.push(JSON.parse('{"id": "180413", "tag": "lang", "text": "# C++类的访问控制符与引用\\n\\n`C++`类的public/private是范围式的，从一个声明符直到下一个声明符之间的所有变量、函数的可访问性是一样的。而Java是针对每个函数需要显式写出访问控制符。初看之下似乎两者没有大的区别，甚至`C++`的范围式控制还可以少打几个字，直到最近我才意识到`C++`的控制方式在隐藏信息上存在的缺陷。\\n\\n比如声明一个接口类，通常来说最先思考的肯定是类的对外可以提供的功能，即public区域的函数。定义好这些函数后，就开始着手实现。但是在实现的过程中，如果公开函数的语义包含的操作较多，肯定会进行拆分，这些被拆分出的函数当然是private级的。但是当你在cpp文件进行函数拆分后，却会遇到代码无法编译通过的问题，原因就是在类声明中没有定义这个private函数，于是一方面，你要切换到.h去声明这个仅仅为了可读性而提炼出来的函数，而且可能因为函数命名比较随意，直接暴露出去又不是本意。\\n\\n为什么在编译器层面，不能省略声明呢？还是由class的特性引起的。由于对OO特性的理解：封装、继承、多态，这3大特性被语言级别地支持了。封装就体现在public/private上。如果一个函数没有声明就直接实现函数体，编译器不能也不敢随意地给这个函数确定可访问性，于是这个问题被抛回给了代码编写者。因此类的每一个细节就必须在头文件中暴露出来。这也是为什么`Effective C++`这么推崇pImpl法则的原因。\\n\\n所以`C++`的访问控制只是阻止了人为的调用，但无法阻止人看到内部函数。要想完全地隐藏细节，必须先声明一个只有public的函数，然后在实现时，继承这个类，把私有函数在继承类中声明，这个继承类不公开，如此才能做到细节的隐藏。\\n\\n反观Java，由于访问性是函数级别，完全可以在实现时直接把这个被拆分的子函数声明为private。话说Java好像也没有头文件和实现分离这回事。\\n\\n## 引用\\n\\n「引用」是被 operator overload 逼出来的。在 operator overload 出现之前，Bjarne Stroustrup 从来，从来没有想过要引入「引用」。因为引用的所有用途都可以被指针代替。\\n\\n而且 Bjarne 是最烦增加新元素的。像 C++14 里那个「= delete」我以前都没想到这辈子能在 C++ 里出现。因为 Bjarne 当年死认为把 constructor 放到 private 就行了。\\n\\n「引用」也不能防止空指针。大型代码动辄传递指针引用好几层，其中完全可以有一层是空的。具体代码我就不放了。\\n\\n自从 Bjarne 铁了心要做 operator overload 之后，一个问题就是像 「=」，「+=」这样的自修改操作怎么传参。你要不要写成：\\n\\nA a;\\n&a += 1;\\n这哪行？（上面这种代码是 Bjarne 论证引用的必要性的时候自己在书里写的。）\\n\\n所以就有了引用。\\n\\n至于其它用法都是废物利用吧。"}'));jctx.push(JSON.parse('{"id": "180420", "tag": "book", "text": "# 股票市场的回购\\n\\n成立股市的动机，90年国企亏损太严重连利息都还不出，于是少量股份从民众手里换钱，又不影响国资控制权。导致彻底沦为赌场。于是开启全流通，但命脉企业是肯定不会出让的，就有少量企业开始分红，但分红按股份比例，大头仍给了大股东，小股东受益不多。美国主流玩法不是分红，而是回购。相当于买盘并锁仓，刺激股价上涨，数字货币多是这套玩法\\n\\n回购 vs. 分红:\\n\\n同样是返还现金给股东，为什么感觉回购好像比分红更普遍呢？一个主要原因是，自上世纪80年代以来，期权在公司高管薪酬里的比重越来越高。同样是返还现金，派发红利只对当前股东有利，而回购股票可以最大化地提升股价，从而让期权持有者同样获利。还有一些高管的薪酬是根据既定股数，道理相同，今天的分红分不到未来才能持有的股票上，但是提升的股价却直接增加了自己未来的收益。\\n\\n进行股票回购的最终目的是有利于增加公司的价值：\\n\\n1. 公司进行股票回购的目的之一是向市场传递股价被低估的信号。股票回购有着与股票发行相反的作用。股票发行被认为是公司股票被高估的信号，如果公司管理层认为公司的股价被低估，通过股票回购，向市场传递了积极信息。股票回购的市场反应通常是提升了股价，有利于稳定公司股票价格。如果回购以后股票仍被低估，剩余股东也可以从低价回购中获利。\\n\\n2. 当公司可支配的现金流明显超过投资项目所需的现金流时，可以用自由现金流进行股票回购，有助于增加每股盈利水平。股票回购减少了公司自由现金流，起到了降低管理层代理成本的作用。管理层通过股票回购试图使投资者相信公司的股票是具有投资吸引力的，公司没有把股东的钱浪费在收益不好的投资中。\\n\\n3. 避免股利波动带来的负面影响。当公司剩余现金是暂时的或者是不稳定的，没有把握能够长期维持高股利政策时，可以在维持一个相对稳定的股利支付率的基础上，通过股票回购发放股利。\\n\\n4. 发挥财务杠杆的作用。如果公司认为资本结构中权益资本的比例较高，可以通过股票回购提高负债比率，改变公司的资本结构，并有助于降低加权平均资本成本。虽然发放现金股利也可以减少股东权益，增加财务杠杆，但两者在收益相同情形下的每股收益不同。特别是如果是通过发行债券融资回购本公司的股票，可以快速提高负债比率。\\n\\n5. 通过股票回购，可以减少外部流通股的数量，提高了股票价格，在一定程度上降低了公司被收购的风险。\\n\\n6. 调节所有权结构。公司拥有回购的股票，可以用来交换被收购或被兼并公司的股票，也可用来满足认股权证持有人认购公司股票或可转换债券持有人转成公司普通股的需要，还可以在执行管理层与员工股票期权时使用，避免发行新股而稀释收益。\\n"}'));jctx.push(JSON.parse('{"id": "180421", "tag": "protocol", "text": "# 浏览器对文件的处理\\n\\n协议工作经常遇到Web开发问及如何处理二进制数据的问题，查了资料并记录。\\n\\n最早的HTML浏览器实现，是李在1990年实做的，IETF在93年中发布了相关草案，在95年11月24日发布的HTML2.0规范RFC1866，这份规范的内容非常简洁，只有77页。它定义了HTML的MIME类型、基本元素，紧接着在次日，发布了名为《HTML中基于表单的文件上传》的1867。后来的RFC1942又扩充了table的表示法。\\n\\n1866的HTML表单规范为INPUT元素的TYPE属性定义了八种可能的值，分别是：CHECKBOX, HIDDEN, IMAGE, PASSWORD, RADIO, RESET, SUBMIT, TEXT。另外，当表单采用POST方式的时候，表单默认的具有\\"application/x-www-form-urlencoded\\" 的ENCTYPE属性。1867则建议对HTML做出了两处修改：\\n\\n1. 为INPUT元素的TYPE属性增加了一个FILE选项。\\n2. INPUT标记可以具有ACCEPT属性，该属性能够指定可被上传的文件类型或文件格式列表。\\n\\n另外，本建议还定义了一种新的MIME类型：multipart/form-data（因为urlencoded效率太低了），以及当处理一个带有\\nENCTYPE=\\"multipart/form-data\\" 并且/或含有`<INPUT type=\\"file\\">`的标记的表单时所应该\\n采取的行为。\\n\\n由于ENCTYPE不同，每个文件都必须配备一个单独的表单。不能和文本类的form共用一个表单。\\n\\n随着HTML的发展，IETF也就是RFC的责任方决定将它交给W3C组织专门维护，也就没有RFC来记载HTML的描述了。\\n\\n## 上传\\n\\n时间来到了HTML5标准，file元素配合FileReader对象，有了更多的变化。通过getElementById拿到这个file对象后，一个files的数组(虽然我没见过支持多文件选择，也许是为了以后扩展吧)，取`files[0]`就是文件对象，这个对象可以传到FileReader.readAsXXX。由于JS的异步属性，读取到的内容惯用法是在回调函数中返回\\n\\n```\\nreader=new FileReader;\\nreader.readAsDataURL(files[0]);\\nreader.onload = function(){ this.result;// this指向reader，读取成功onload，不考虑成功失败，用onloadend也行}\\n```\\n\\n奇怪的是即使用二进制读出图片数据，再用base64转换得到的长度始终有问题，只能用DataURL获取图片，原因未知。\\n\\n## 下载\\n\\n静态方式的下载用href标签可以实现`<a href=http://www.xx.com/xx.zip>点击下载</a>`，但是问题不少，用PHP实现，核心代码\\n\\n```\\n  header(\\"Content-Type: application/octet-stream\\");\\n  header(\\"Content-Length: \\".$fsize);\\n  header(\\"Content-Disposition: attachment; filename=xx.zip\\" );\\n  @ob_clean();\\n  flush();\\n  readfile($f);\\n  exit;\\n```\\n\\n把文件类型改成octet，然后用readfile函数把文件写入标准输出流，由于PHP的stdout已经绑定到HTTP连接，客户端就能得到完整的文件。通常Content-Length是规范要求必须有的，没有的话浏览器也会兼容，但下载过程中无法显示总长度和当前进度。标准中这个字段表示传输过程中的长度，嚼字眼的话说明不是文本的原始长度，比如开启了gzip压缩，传输长度和实体长度就不一样，如果PHP外面的nginx又套了gzip，由于nginx无法事先知道要代理的内容长度，干脆全部用chunk方式传输，此时Content-Length会被chunk遮蔽，也不会有问题。"}'));jctx.push(JSON.parse('{"id": "180423", "tag": "net", "text": "# TCP的状态与nc的理解\\n\\nTCP的状态多达11个，4个连接7个关闭。之所以会这么复杂，是因为TCP作为双向全双工协议，读写端是完全独立的，建立连接的过程不区分，所以相对简洁一些，一旦连接建立后，分化出读写两个管道，要关闭这两个独立的管道，会经历不同的状态，显然复杂度会翻倍。调用close()只能主动关闭写管道，读端会被动一些。\\n\\n| 写关闭状态 | 说明 | 读关闭状态 | 说明 |\\n| --- | --- | --- | --- |\\n| FIN_WAIT1 | 发送FIN给对端，关闭写道道 | CLOSE_WAIT | 收到FIN，关闭读通道 |\\n| FIN_WAIT2 | 收到对方的ACK，但还没收到对方的FIN | LAST_ACK | 读端Only，收到FIN后自动触发close进入该状态，并等待ACK，网络中断时才会出现 |\\n| TIME_WAIT | 收到对方的FIN | | |\\n\\n还有两个状态是读写端都会有\\n\\n* CLOSING  本该收到对端ACK却收到FIN，发ACK给对方，就会进入最终的CLOSED\\n* CLOSED  收到FIN后再过2个MSL才可以彻底关闭\\n\\n说完TCP的双工性，来看看nc，从它的简述`Concatenate and redirect sockets`能看出，nc也是利用了socket的双工性再连接了shell的stdin/stdout，实现了像反弹shell这样的魔法。"}'));jctx.push(JSON.parse('{"id": "180501", "tag": "lang", "text": "# JS模块化历史\\n\\n在2009年1月，Mozilla的程序员Kevin Dangoor发起了名为ServerJS动议，这是最早的模块规范。同年8月更名为CommonJS。为了适应浏览器环境，慢慢发展出了异步加载的AMD规范，最初是被挂在CommonJS下面，后来因为两个环境差异实在太大，最终分道扬镳。Dojo库率先实现了这个规范。最晚到2011年10月中旬已经有多个库支持AMD规范。\\n\\nCommonJS定义了require和exports，而AMD定义了define。\\n\\n## node\\n\\nnode诞生于2009年5月27日，ES6的标准化则迟至2015年6月，由于node出现在前，发展出一套自己的require加载语法，不能和ES6的语法混用。\\n\\n假设Y是路径，X是文件名或目录名，当 Nodejs 遇到 require(Y+X) 时，按照下面的顺序处理：\\n\\n1. 如果 X 是核心模块（例如：require(\\"http\\"), path, buffer）\\n\\n\u3000\u3000a.返回该模块\\n\\n\u3000\u3000b.不再继续执行\\n\\n2. 如果Y是以“./”、“/”或“../”开头\\n\\n\u3000\u3000a.把X当成文件，从指定路径开始，依次查找下面文件：X、X.js、X.json、X.node，只要其中一个存在，就返回该文件，不再继续执行\\n\\n\u3000\u3000b.把X当成目录，从指定路径开始，依次查找下面文件：X/package.json(main字段)、X/index.js、X/index.json、X/index.node，只要其中一个存在，就返回该文件，不再继续执行\\n\\n3. 如果 X 不是核心模块，也没有以“./”、“/”或“../”开头，则Nodejs会从当前模块的父目录开始，尝试从它的 /node_module 目录里加载模块，如果还是没有找到，则移动到再上一层父目录，直到文件系统的根目录\\n\\n4. 抛出“not found”\\n\\n通过debug/inspect模式会发现执行文件的语句，在node内部变成一个立即函数调用，像这样\\n\\n```\\n(function (exports, require, module, __filename, __dirname) {your code}\\n```\\n\\n这就很好理解，为什么每个脚本都会有5个预定义变量了。同一个文件直接运行和被require时，module对象被解释成不同的含义。比如test.js，运行node test.js，module.parent的值是null。而node -e \\"require(./test.js)\\"，module.parent的值就指向另一个module，这个module是命令运行产生的，id是`[eval]`，如果不用-e，会打印对应的文件名。\\n\\n## ES6\\n\\n使用export(注意不是exports)和import关键字。\\n\\n## 差异\\n\\nnode的require是动态加载，用if (x>1) else可以加载不同的模块，而ES6的import则不行。\\n\\nnode加载的是值，即使模块的值变化了，不会影响node中已加载的地方。而ES6是引用加载，会受模块影响。"}'));jctx.push(JSON.parse('{"id": "180502", "tag": "book", "text": "# 朝贡与威斯特法利亚体系\\n\\n东亚和东南亚有着天然的贸易优势。他们共同沐浴在世界上最强劲的季风之下。守时的季风每年从太平洋上送来丰沛的降水和热量，滋养出这片富饶多产的土地，同时为这一地区的商船提供了远航的动力。\\n朝贡贸易只占东亚贸易极小的分量。朝贡贸易按照各个国家的地位（与中国的相似性）明确规定了朝贡次数和使团规模（尽管执行起来并不十分严格）。可以想见这种常常数年一次的朝贡贸易只能占到地区贸易微乎其微的份额。朝贡贸易之外是数量巨大的商业贸易以及非法贸易（走私和海盗）。朝贡贸易的重要性体现在它是东亚国家关系的基石，是东亚国际秩序的表现。中国对朝贡国加倍的赏赐算的也不是经济账，是中国维护朝贡体制、获取政治认可的需要。真正承担东亚贸易往来的是数量巨大的非官方的商业贸易以及走私贸易。而中国通过这些非官方贸易获取了巨额的收益。\\n东亚庞大的贸易网络以中国为中心，可以说当时的世界和现在类似，对中国商品有着难以满足的需求。国内商品经济发达，棉、丝绸、糖、茶等商品丰盈，满足国内市场之余有相当比例都用于出口。银行和企业广泛投资于纺织、陶瓷、金属以及外贸等行业。明朝重修了沟通南北的大运河，清朝修建了贯通中国东西的道路网。发达统一的国内市场通过东南沿海的贸易港口和日本、琉球、东南亚以及欧洲联系起来。\\n \\n如果只看历史上中国和日本的官方文件，的确会产生中日闭关锁国的判断。考虑到贸易与政治安全的对立性，中日两国的确都实行过严格控制对外贸易的政策。但是这一政策的出发点是维护边疆地区的政治稳定，而非杜绝对外贸易。而且在边疆稳定之后，统治者往往都会放松对外贸易的管制。比如康熙在收复台湾之后，废除了海禁政策。那之后中国每年下水的远洋船超过1000艘，船只吨位也普遍介于200—500吨之间，部分船只能达到1200吨以上。\\n实际上闭关锁国这样的描述来自于西方。西方人到达东亚之前，东亚的制度、文化、经济就高度统一和发达。处在朝贡体系下的东亚国家，贸易关系十分紧密，中国商人和日本商人都十分活跃，中国南海非现在才成为世界上最繁忙的航线。西方人来到后，发现东亚铁板一块，无处插足。同时东亚的儒家文化对基督教强大的排斥也使得西方对东亚国家产生了封闭孤立的印象。\\n\\n东亚的贸易、外交、政治秩序全都建立在明确的等级制度之下，而这些礼仪就是等级制度最明显和重要的宣示。令中国改变这些礼仪无异于改变东亚数百年稳定的朝贡体制。\\n中国是一个早熟的文明，中国（带动东亚地区）发展出世界上运行最早最成熟的政府治理机制。唐朝时，朝鲜、越南和日本都向中国派出大量遣唐使，对中国文明有着发自内心的向往。其中，朝鲜和越南的汉化程度最深，它们建立了中国式的中央集权官僚体系、推行科举制、引入中国文字，并将儒学作为官方意识形态。虽然中国的制度和文化在东亚有着独一无二的优势，但是中国也无意干涉这些邻国的内政和汉化选择。所以东亚国家对中国积极而主动效仿的同时，也都不同程度地加入了本土的实践。基于文明的认同和贸易的需要，东亚地区形成了充满活力的贸易和外交综合体系——朝贡体系。明清（1840年以前）时期，这一体系成熟而稳定，中国（东亚）政治和经济的统一达到历史的最高峰。东亚也成为世界上经济最繁荣、政治最稳定的地区。在人类社会存在增长极限的近代早期，人口数量很能说明东亚的发达。17、18世纪，东亚是世界人口密度最大的地区，中国每平方公里约37人（西藏除外），南亚约32人，欧洲只有11人，东南亚为5.5人。\\n\\n中国毫无疑问位于朝贡体系的核心，朝鲜、越南、日本、琉球都属于次级国家。**朝贡体系很大程度上基于文明的认同**，所以次级国家间根据与中国文明的相似程度排序，国家实力并不是最重要的。朝鲜是模范藩属国，排位仅次于中国。日本尽管实力超过朝鲜和越南，但汉化程度不如后者，只能靠后。朝贡体系下，国家间的正式关系是不平等的，并且有着明确的等级制度。这种不平等的制度化设计就是上级国家通过敕封的方式认可下级国家的身份、下级国家派遣使臣到上级国家以及其中严格的礼仪。不平等并不代表中国对下级国家的欺凌和剥削。事实上，中国对藩属国的敕封在一定程度上限制了中国，因为敕封就表示了中国承认藩属国的主权，便不会干涉藩属国的内政，并为藩属国提供安全保护。\\n\\n如果以国家主权平等的标尺看，朝贡体系显得专制和落后，甚至滑稽可笑。但是我们不能拿一把东亚历史上并不存在的尺子来丈量东亚。历史上东亚国家和民众对不平等毫无疑问，“生而平等”的观念反而让人觉得莫名其妙。\\n \\n中西方历史在某些时间节点上的巧合很有意思。1644年，在亚欧大陆的东端，清军进入山海关，处于朝贡体系边缘又不是儒家社会的满清部落入主中原。清朝很快打消了众番邦的疑虑，不仅接受了儒家思想，而且完全沿用了明朝的朝贡制度。同一时期，在亚欧大陆的另一端，欧洲也发生了三十年战争（1618—1648年）。与东亚不同的是，这场战争打出了完全不同的近代欧洲国际体系——威斯特伐利亚体系。\\n\\n和朝贡体系的国家间形式上不平等、存在明确的等级制度完全不同，威斯特伐利亚体系最主要的特征就是国家间形式上平等、实行均势政治。战争中欧洲各国彼此妥协、寻求均势的过程中诞生了主权国家、平等、条约等一系列国际法概念，这些概念随着后来欧洲的扩张，成为所有国家的行为准则。\\n \\n中国为中心的朝贡体系和欧洲三十年战争诞生的威斯特伐利亚体系是近代仅有的称得上国际关系的体系。而这两个几近对立的体系造成的结果也大不相同。朝贡体系下，东亚地区维持了长时间的和平稳定。在朝贡体系成熟并良好运行的近代早期（1368年明朝建立到1840年），东亚国家间的战争只发生了两场：中国出兵越南（1407—1428年）和日本侵略朝鲜（万历朝鲜战争）。\\n 中学学习历史的时候就有一个疑问，历史课本大量篇幅聚焦于中国的北部边疆（尤其是明清时期），对东南海疆的关注一直到近代西方到来之后才成为重点，李鸿章感叹为“数千年未有之变局”。明清历史中绝大多数的战事都与北部游牧民族的边境冲突（无论从伤亡人数还是征战的目的，绝大多数都不能称得上是战争）有关，讲述与某个蒙古部落的边贸马市都是十分重要的历史事件。形成鲜明对比的是，东南方向的越南、朝鲜、日本与中国却有着长时间的稳定和平。\\n\\n这绝非因为这些国家绝非没有战争能力，要知道这些国家有着比游牧部落更高级的组织方式、更成熟的国家体制，同时又是农耕民族，对粮草等军事物资的自筹能力要比游牧部族强很多。甚至强于同时期的欧洲国家。1592年的万历朝鲜战争，丰臣秀吉动员了16万日本军队，数十万的后勤人员以及700艘船，另一方是明朝的10万援军和6万朝鲜士兵组成的联军，战争持续时间了6年。发生在1588年的英国海军与西班牙无敌舰队的决战尽管当时被西方人称为“人类有史以来所集结的最大的军事力量”，它的参战人数和消耗物资却只有万历朝鲜战争的1/5—1/10。\\n\\n朝贡体系是和威斯特伐利亚体系同为国际关系体系。比较这两种国际关系体系，最大的区别在于：威斯特伐利亚体系以国家间互相平等为基础，而朝贡体制则以国家不平等为基础和前提。在朝贡体制内，中央王朝的地位是最高的，藩属国的地位低于中央王朝。他们之间，并不平等。\\n\\n但在中国人看来，正常的国际关系本来就建立在国与国不平等的关系之上。英国要想加入中国主导的朝贡国际秩序，就得先接受不平等的地位，否则，整个朝贡国际体系就面临动摇甚至解体。覆巢之下安有完卵，当整个国际关系体系被动摇之后，国际贸易也就无从谈起了。\\n\\n中国人的问题在于信息不灵通，对英国已经非常强大一无所知，但中国坚持要求维持既有的国际秩序，先明确地位，再谈具体问题的做法，并非特别荒谬。毕竟，今天的外交场合中，外交官为了维持平等的地位，在一些“虚礼”上针锋相对毫不退让，也是常有的事。\\n\\n更加引人深思的是，东亚各国在近代史上都多多少少遭受过外来侵略。但在各国恢复了独立地位以后，东亚再次出现了一个高度发达、活跃兴旺的贸易圈。所谓东亚经济奇迹，其实只发生在原中国朝贡体制圈的范围内。那么，在东亚这种历史和现实的传承中，是否存在什么尚待人们深入认识的规律呢？比如，国家到底在社会发展中应该是什么角色和地位呢？\\n"}'));jctx.push(JSON.parse('{"id": "180510", "tag": "lang", "text": "# 实战flex和lemon要点\\n\\n以前写过flex和bison的实战，这两个工具出现在70年代，bison生成的主函数入口名只能是int yyparse(),内部强制调用yylex函数，语法驱动词法，传递数据使用全局变量的形式，从代码美学角度看相当令人不快。最近学习了SQLite项目下的lemon，从语法分析上来说比bison更简洁一些。PHP开发组在10年曾发起动议用lemon替换bison，不过后来不知何故不了了之。使用lemon配合flex可以直观地解决重入问题，bison也可以，但略复杂。\\n\\n先说flex生成可重入代码的方式，使用`flex -R`或者用%option reentrant都能达到效果。生成的函数原型变为`int yylex (yyscan_t yyscanner);`。通过yyget_text(yyscanner)和yyget_leng(yyscanner)的调用方式，取代了以往全局变量yytext和yyleng的使用方式。\\n\\n在使用前后要分别调用`yylex_init`和`yylex_destroy`。如果要指定输入文件，用`yyset_in`函数(非重入版也有这个函数)。和lemon配合时，flex是驱动者，每条规则匹配的执行动作不需要return，而是在执行动作中从yyscanner提取token，处理并交给lemon进行解析。\\n\\nlemon只是生成解析函数，被词法驱动调用，函数原型如下，函数名可以自定义。\\n\\n```\\nvoid Parse(\\n  void *yyp,                   /* The parser */\\n  int yymajor,                 /* The major token code number */\\n  ParseTOKENTYPE yyminor       /* The value for the token */\\n  ParseARG_PDECL               /* Optional %extra_argument parameter */\\n)\\n```\\n\\nmajor表示符号类型，所以固定为int就够了。相应的minor是该符号的值，需要自定义union才行。minor主要用在shift和报错时用。\\n\\n用%name xyz指令可以替换Parse成你想要的函数名，一共会导出7个函数，其它都是以static约束并以`yy_`开头的内部函数。这7个函数只有主函数和Alloc及Free必须使用，Init和Finalize似乎不应该暴露，还有两个Trace和StackPeak是辅助用途。\\n\\n类似%name这样的指令共有23个\\n\\n```\\nname\\ninclude\\ncode\\ntoken_destructor\\ndefault_destructor\\ntoken_prefix\\nsyntax_error\\nparse_accept\\nparse_failure\\nstack_overflow\\nextra_argument\\ntoken_type\\ndefault_type\\nstack_size\\nstart_symbol\\nleft\\nright\\nnonassoc\\ndestructor\\ntype\\nfallback\\nwildcard\\ntoken_class\\n```\\n\\n改为可重入后，很多函数声明被改变，但工具并没有自动生成对应的接口申明，必须手工补齐，是个不足。\\n\\nflex和bison配合的时候，每当识别到一个符号动作的最后，都会return该符号对应的枚举。但和lemon配合时，如果在词法动作中执行lemon的Parse函数，就不需要return。因为lex函数内有个while循环，只要不return就会不停地找下一个符号。不考虑初始化和结束动作，只要调用yylex();Parse();就是解析的全部了。\\n\\nlemon内部也有while循环，其目的是收到新的符号后，可能会反复的shift或reduce。直到出现错误或者栈溢出结束循环。\\n\\nlemon在计算规则时会计算shift、reduce和shiftreduce的范围。shift的最小值是0，只定义最大值，另外两个既有最大也有最小值。\\n\\n解析函数根据计算的act的区间范围，调用shift(shiftreduce也算shift)或reduce。因为Parse内有循环，只要正常一定会reduce到accept状态，都不属于只能是错误。\\n\\nlemon在解析y文件时，有22种分支，包括自动机状态，出错和特殊符号的处理。\\n\\nlemon不允许开始符出现在规则右侧，因此一定要为开始符定义一条专门的规则，从生成的代码可以看到，开始符的规则在default分支，是最特殊的，这条规则通常什么也不会做。如果一条产生式有多种写法，不需要写`|`，把不同的产生式分开写出来，lemon会负责合并这些规则。因为每个语句最终都对应到一个case，这样考虑的话分开写反而更自然。\\n\\n`token_type`标识lex的终结符，而`type`标识lemon内的非终结符。\\n\\n除了用指令，有3个宏可以控制lemon的Parser结构。分别是水位警示、错误回退和栈增长控制。reduce需要用栈暂存数据，bison默认深度是200，lemon是100，但是可以定义宏为负值做到自增长，如果不定义宏，到100就报错退出了。产生式的每个符号，以最右边为0，向左依次-1并在栈上可以找到。\\n\\n## lemon阅读\\n\\nlemon生成后的代码大多数是表驱动，虽然大的结构能看懂，但怎么得到表却要看本体才能明白。\\n\\n程序有几个结构要关注，除了最大的lemon，就是rule、action、symbol最为重要。从入口来看，先确定终结符的最大个数，然后构造First集和Follow集。lemon的目的是得到一个语法分析器，但它自身又必须有词法分析，否则y文件都不能解析。\\n\\n整个流程是如下几个步骤\\n\\n1. 计算First集\\n2. 计算LR(0)状态机，次复杂\\n3. 计算Follow集（包含一个前置的FindLinks 不知道该怎么翻译）\\n4. 计算并压缩Action表，其中压缩可以通过命令行选项控制。此步已经是LALR\\n5. 生成LALR分析器，最复杂\\n\\n计算First集要考虑空规则"}'));jctx.push(JSON.parse('{"id": "180511", "tag": "book", "text": "# 两晋南北故事\\n\\n秦汉时期的政治体制是一君万民，是所有的老百姓财富均等，没有形成利益集团，层级比较扁平，但是随着汉朝400年的发展财富自发的形成了分化，并形成了大地主，大资产阶级，比如颍川荀氏，司马氏在这样的制度下，原有的制度就不再适用，出现了400年的魏晋南北朝这段时间不仅是一个政治制度的，演进和适应，还有各个民族的融合\\n\\n随着公权力的下放，汉代又推行儒学国教化，使得全国具备了庞大的官僚预备队伍，直到隋唐的科举制度，才把这些人才重又纳入体制\\n\\n## 西晋的八王之乱\\n\\n西晋灭吴之难远超想象.灭吴总大将是王濬.如果不是羊祜再三举荐,杜预的信任,加上司马炎的授权,光是贾充王浑,这场仗就打不赢。\\n\\n西晋51年的历史，重点当然在八王之乱。一共跨越15年，分为两段，都和贾南风有关。前面一段持续3个月，起因是贾南风为诛灭杨氏引三王入京，事后平稳了8年，期间社会还是比较安定的。之后贾南风为了继续把持朝政，阴死了司马遹，导致了第2段长达7年的混战。最终司马越胜出，但也掏空了中原的家底，这个时候周边的胡族已经崛起，5年后的永嘉之乱，第一次中原王朝的皇帝北掳，再下一次这样的耻辱就是更有名的靖康之耻。\\n\\n八王之乱是指死掉的8王，最后的胜利者司马越不算在其中的。8人有7人是司马懿后代，1人是司马孚一支。司马懿后代中，2人是懿的儿子，4人是司马衷的亲弟弟，还有1人是司马衷的堂兄弟。\\n\\n八王之乱最后司马越能胜出，一是因为八王之乱已经打光了中原的力量，第二是因为司马越靠着刘琨从幽州王浚处借来的5000骑兵，这个时候由于中原已经没有了训练有素的步兵军团，而骑兵在双马镫的加持下，造成了非常恐怖的破坏力，最终使得他这个远支的旁观者能够清盘。\\n\\n### 时间线\\n\\n1. 司马攸出镇: 司马炎一直想让攸出镇齐王，但高门因为有攸在，能平衡外戚杨家都表示反对。攸在司马炎持续催促下离奇病死，而一众官员比如张华都被外放，导致官位大量空缺，杨家占据三公位。此事后司马炎终是对杨家不放心，此时党争已起，也无可用之人，只能将自己的儿子分封为实权诸侯王。八王之乱才有了爆发的可能\\n2. 司马攸(炎的亲弟，但被过继给师)之死: 司马炎一直想让司马攸出镇齐王,但高门因为有攸在,能平衡外戚杨家都表示反对.攸在司马炎持续催促下离奇病死,而一众官员比如张华都被外放,导致官位大量空缺,杨家占据三公位.此事后司马炎终是对杨家不放心,此时党争已起,也无可用之人,只能将自己的儿子分封为实权诸侯王.八王之乱才有了爆发的可能.\\n3. 司马衷娶贾南风: 因为贾充的女儿先嫁司马攸。展开说句其实是贾充前妻李氏之女，李氏之父李丰参与反对司马师而被流放，所以只是一枚冷棋结交司马攸。但贾充的能量太大，司马炎一度想将贾充外放西北平叛。贾充为求自保，联络荀氏将贾南风配给司马衷。贾充是贾逵之子，虽然贾逵忠于曹魏，曹叡和曹髦都分别为其重修庙，可谓是曹魏纯臣，但到儿子辈却转投司马家。司马炎娶妻时司马师未死，娶的是弘农杨氏，这一族自杨修后一直没有在曹魏时代出头，所以司马衷其实势力不稳，于是司马炎又打破曹丕时代外戚不得为官的成例，来壮大司马衷的背景\\n4. 司马遹与贾南风(第2段起因): 司马衷太子司马遹长大后,不满贾南风,有日被召入宫后强灌酒数升,抄反书一封后被幽禁,后又被打死在厕所,死时声音传得很大.贾南风亦借其妹之子谎称有孕,引得司马家自危.司马伦(右军将军),司马肜(领军将军),司马冏(左军将军)发动宫变诛杀贾南风。司马衷无子,此役后司马允(衷弟)为第一顺位继承人,但司马伦名望低却想篡位,伦诛杀允后自己加九锡并称帝,迁衷到金墉城,为太上皇.司马伦是司马懿九子,辈分上是司马衷的爷爷,奉自己的孙辈为太上皇,天下开始乱了。伦登基后大肆封赏,官帽不够,有狗尾续貂,官印不够,有白板官,政治生态完全被破坏\\n5. 司马伦之死: 对司马伦上位后种种不满,京外藩王开始起兵.司马冏(攸子)率先发难,联同司马颖和司马颙三路军向洛阳进军.交战之初虽然不利,但人人想当皇帝所以账而不散,反观中央军却不知因何而战,即便战胜赏赐也只是空头支票.终于冏和颖取得一次胜利后,洛阳震恐再生内变,将司马伦押到金墉城换回司马衷.司马冏入洛阳,成为实际话事人.此战过后,西晋兵员损失10万人,武备不足为日后永嘉之乱埋下伏笔.\\n\\n## 东晋的建立\\n\\n司马越和司马睿的封地，前在东海，后在琅琊，挨的比较近，加上越的心腹王衍和睿的心腹王导是同族。所以才会出现这两个人明明是司马家两支比较远的支，但是司马越派司马睿江东屯住。\\n\\n在司马睿和王导渡江之前，睿的部将陈敏曾试图割据江东，并和甘宁之孙甘卓结为儿女亲家，一度也取得了江东大族顾家周家的支持。最终失败了，原因有几个：第1他不够能打，输给了陶侃，没能取得更大的地盘。第2他气量太小，任用兄弟没有重用世家，第3陈敏出身只有六品下。反观司马睿和王导不仅有名分，王敦在平叛中表现出的武功还相当了得。最后通鉴纪事本末中也评价：蹑桓王之高踪，蹈大皇之绝轨，意思是既没有孙策能打，又没有孙权的腰身柔软，失败也就是理所当然的事。\\n\\n琅琊王司马睿于307年，受当时西晋实权者东海王司马越之诏督江南军事，原先打算驻军下邳，不久由于战乱南迁到建康。同郡的王导到了江南后，由于王导高超的政治技巧，团结北方分化南方，使睿在江南站稳脚跟，西晋怀帝愍帝先后死后，于317年被推举为东晋元帝。在建康铺垫十年始得帝位。\\n\\n王导做为辅政大臣，王导在京畿，王敦因平两湖流民而坐大，守武昌。元帝为制衡王家，乃重用刘隗，刁协两人，王敦打入石头城，元帝亡。明帝即位，调祖约，苏竣镇压，王敦阵中病死。明帝在位3年亡，托孤庾亮辅政，苏竣不满庾亮严苛，与祖约又反，陶侃复压。朝中有迁都之想，王导力劝。政权初期便不稳定。整个朝廷由北府(郗鉴)和西府(陶侃)两股军事力量与贵族的妥协与平衡中维持。\\n\\n恒家是西府兵，谢安年过四十始出仕恒温，立谢玄为北府兵制衡恒家。两则轶事，谢安见谢玄爱香囊，施赌局得而烧之，玄亦明事理，从此悔过。恒温见刘琨侍女，初曰像，然细看却诸多不似，温闷闷，时人平评风盛\\n\\n北方移民到了南方，设立与原籍同名的侨县，但户籍却与江南住民的黄籍不同，另设白籍。经恒玄刘裕两次土断，方转白入黄。另侨民经几代人生衍，不再对北地有眷恋，亦有顺应民心所为。\\n\\n### 几个值得说的人物\\n\\n* 刘琨: \\n* 祖逖: \\n* 陶侃: 南方没落寒门子弟的晋升之路：陶侃的母亲年轻时应该也是有一定见识的，当时他们家乡的孝廉范逵经过他们家，侃母割其发招待他。陶侃送出百余里后，终于换来了范逵的举荐。后来陶侃到洛阳以后，又多次拜访张华，因为张华是唯一寒门出身的，并且对南人也没有偏见的人。陶侃本人的自身素质过硬，不管是清谈、政务、沟通，无师自通的军事能力，都是他成功的基础。刘弘（司马炎儿时玩伴）发现了陶侃的才能，是他真正的飞跃。陶侃丁忧后，华秩（华歆曾孙）保荐他。但是此时华秩和司马睿已经闹掰，所以陶侃和他的侄子陶臻演了出双簧戏。陶侃先是把陶臻作为人质，留在华秩那里，陶臻发现华秩和司马睿不和，托病跑回陶侃处，陶侃痛骂陶臻后令人送陶臻回华秩处，但陶臻中途跑出，并去了司马睿。被司马睿表为参军，并加封陶侃为奋威将军，陶侃借此和华秩划清界限。陶侃57岁被王敦迁至广州刺史，但每天白天仍搬百砖到屋外，天黑再搬回屋内，自述：吾方致力中原，过尔优逸，恐不堪事。看到下属游戏时，也会严厉指责。传说其幼时曾做一梦，梦中身有八翅飞向九重天，但攀登最后一重跌落，所以自知没有天命，故一生谨慎，预感寿将近时将所有权力都还给中央。可惜陶侃的数个儿子或自相残杀，或被王导的继任者庾亮和其兄诛杀，都不得全寿。由于这个关系，陶侃的孙子很多都是隐士，而他的曾孙陶渊明则是最有名的一个。\\n* 桓温: 出生时温峤评价其子不凡，所以取名温。\\n\\n## 五胡十六国\\n\\n刘渊是匈奴屠各部人，没有政治资源，他假借其父是南匈奴谱系来讲故事，成就了第一波，借势典范\\n\\n石勒只有十几岁时,卖东西的声音引起了王衍王夷甫的恐惧,王衍想派人追杀石勒,但已经晚了.十几年后,王衍随司马越去东海的路上被石勒抓住,王衍为自己开脱拍石勒马屁,石勒觉得王衍乃不忠之人,遂杀之\\n\\n## 南朝\\n\\n刘裕能击败桓玄，固然有战力原因。但桓玄作为高门代表，在皇权企图恢复的大背景下，无法得到高门的支持。高门想要的是王导谢安这种维护高门利益的人，而非自立者。刘裕经过20年才九五加身，需要时间让人心转变。\\n\\n刘裕武人立国，使皇族与近亲任北府，皇子任西府。刘裕托孤4重臣，1年后大变样。谢晦轻浮，檀道济恨毛德祖（实为王镇恶）占了北伐之攻，不救虎牢，致北境第一次丢失。徐羡之寒门出身，被将任吏部尚书所鄙，健康行政效率低下，无法感知外部压力。皇族间残害甚重，只能任用寒族，终为萧道成所代。\\n\\n货品经济极为发达，但货币不够，以前朝钱为大钱，因无铜更铸铁钱以充。\\n\\n## 北朝\\n\\n平定北凉掳回三千僧侣，始有礼佛，遂有洛阳伽蓝记。北方原为守备柔然，设六镇。孝文帝迁都洛阳致中心南移，六镇升迁无门，积蓄不满。\\n\\n张仲瑀上书清退朝中北人羽林虎贲职，引起北人火烧张宅，朝廷只治八人罪，高欢时正在洛阳，知天变遂变卖家财聚死士，后投靠尔朱荣，在战事中丰满羽翼，成东魏。\\n\\n出帝不甘为傀儡帝，西逃宇文泰，有东西魏对峙。初西弱东强，宇文以周礼治国，终于一统。\\n\\n三武一宗灭佛，因佛非汉族文化，立道教以自居，说明此时鲜卑以中华自居，奉中华文化为尊，汉人更有勤王之举，汉人也认可政权\\n"}'));jctx.push(JSON.parse('{"id": "180515", "tag": "book", "text": "# 大道随行，不忘本心10\\n\\n道生一，一生二，二生三，三生万物------ 《道德经》\\n\\n一）SAP\\n\\n大约17年前，公司里要上SAP。当时坐在我身边的，是一个生产部的女士。\\n她工作极其认真严谨，拿出了一个小本本，笔记记得密密麻麻。\\n对于200多个Form，这里是输入地址，那里是输入日期，下拉框是查库存列表。她整日眉头深锁，觉得这个系统实在是很复杂很复杂，有200多个表格要学呢。\\n相对于我的漫不经心，麻瓜女士表示十分不满：“xx桑，SAP系统对你意味着什么。难道就意味着每工作餐可以额外地吃免费水果么。而且你每次都抢最大最甜的泰国芒果，知不知道你这样形象很差耶”。\\n我白了白眼睛，那你认为该是什么呢。\\nSAP系统其实很简单。说穿了就是一个数据库查询系统。\\n无论你有多少个Form，多少个查询表单。无非就是数据库的输入/输出工作。\\n今天你下一个采购订单，是把货物输入到了系统。\\n明天你填一个生产表格，是把货物A转换成了货物B。\\n后天你填一个销售表单，就是把货物B卖了。\\nSAP很简单，无非就是一个大型的数据库。仅在生产规划环节有一些CPU计算，但也并不脱离传统的MRP系统。\\n扣除掉了生产线流水线那一些MRP算法，整个SAP就是一个超级简单，幼稚的数据库软件。其库存，运输，账本，乃至于后来画蛇添足加出来的HR，行政，总务等系统，无不是简单之极的一个二维数据库。\\n论技术含量，SAP可能还不如国内的《金蝶软件》。\\nSAP很简单。其实就是个数据库。\\n但SAP为什么在某些人眼里这么难呢。因为她们的思考方法不同。\\n在某些人眼里，SAP是200个不同的Form，每一个表格都要单独背诵和记忆。笔记记了一大本，到最后还是云里雾里多走出一步都不明白。\\n可是如果你懂得SAP的大框架，整件事就十分清晰。清晰得宛如手指上的掌纹。然后你只要关注一下一些细节就可以了。\\n\\n二）万物理论\\n\\n最近有一部电影十分热火，讲霍金的《万物理论》。\\n科学家们试图寻找出一种理论，它可以作为其他理论的“母理论”。从他开始可以推断出人世界一切的科学。\\n必需承认，这是一个很诱人的想法。人类永远在寻求更低一层的规则，T-1层的规则。\\n规则，规则是一切的力量。更底层的规格，可以帮助我们更好的描述这个世界，发现新的机器，发挥无以伦比的力量。\\n就好比说，中世界的炼金术士们不懂化学。无论他们做了多少的试验，最终他们也无法炼出金子。\\n可是等化学学科渐渐丰满，HCl和NaOH的反应渐渐普及。人类才能组合出各种各样稀奇古怪的材料。才会有塑料，铝器，汽油柴油。\\n而化学渐渐的也有瓶颈。等门捷列夫排出化学元素表，人类才看清楚 “更深”一层的规律。于是才有了Nuclear，有了核能和原子弹。2007年日本科学家第一次用激光照射纯汞，剥掉了一个中子，获得了金原子。\\n但是，原子物理仍不是最终极的科学。在原子之下，还有夸克。如果能了解夸克的奥秘，就能象《三体》小说一样，制造出无敌的战舰“水滴”。\\n其外壳的强度，将是现在所有材料的100000倍。完全不可摧毁。这靠的是强相互作用力。\\n而夸克也不是最终的粒子，夸克之下，还有弦论，至少。\\n讲这么多的闲话，和炒房有什么关系呢。请别忘了，这始终是一个俗不可耐讲钱的账号。\\n其实我们要说的是，基础理论的重要性。\\n很多人很表面，很肤浅。\\n就象那个SAP画了二百个表格的女孩子。又或者深陷题海战术的高考学子们。\\n他们看似很努力，可成绩始终上不去。\\n因为他们只是忙碌于很表层的东西。从没有想T-1层潜在的原理。其实老师出题来来回回就那几个套路。真正的学霸，学霸从来不读书。\\n\\n三）体，用，术\\n基础的理论很重要。从一些更基本的规则，可以推出上一层的规则。这样不仅更好记，更快捷，而且可以算出别人看不见的东西。\\n但是，事情也有其反面。若真如此，今天最富有的人，应该是“粒子物理”科学家，或者数学系研究“数论”的老学究们。因为他们，才是走在整个人类科学最前沿，最底层的学问。\\n可是事实并非如此。真正的科学家，往往是很穷的。问题出在哪里？\\n问题在于“体，用，术”。\\n最基础的科学，好比人类文明的大树。根基都在这里。这个方向一定要把准，绝对不能出错。\\n在基础科学之上，“用”指的是应用科学。你精通了化学，这并不能帮你赚钱。化学要转化成应用。研究出一种新型去屑洗发水，牙膏，洗衣液，奶粉配方之类的。\\n在大科学家眼里，这些应用科学自然是小儿科，不值一晒。可正是这些在“企业”里混的人，其收入往往是大科学家的二倍三倍，若能做到高管，更是幸福滋润。\\n为什么，因为“应用科学”离消费者更近，离钱更近。\\n从“理论”到产品，当中有很长的一段路要走。这段路之困难，之复杂，绝对不在基础研究之下。就好比你知道了“万物理论”，你也造不出粒子战斗机。当中还需要工程师几十年的研究。\\n“体，用，术”，在“用”之外，还有一个术。\\n术指的是完全末端的，不属于理论体系的，分散的，短期的似是而非的知识。\\n好比门口王婆卖的烧饼比较甜。\\n去坐电车可以穿过弄堂小路。\\n地铁交通卡可以互换以节省成本等等。\\n\\n四）炒楼界的体、用、术\\n花了这么大的力气来作铺垫，我们要说的是，作为一个合格的“炒楼客”，你需要怎样的学识修养。\\n首先，你需要正确的基础知识。炒楼这一行，虽然对于自然科学，物理数学要求不高。但却是对于社会科学，政治人文财经的分析要求很高。\\n人生基于“三观”，三观一定要正。先把头脑倒空，把脑子里乱七八糟的马克思主义调控等等全部倒空。\\n“体”，正确的信仰，首先你的政治经济学要对。方向要对。\\n正确的流派，目前看来是“奥地利经济学派”。在中国的代表作是铅笔社，原因以后再说。\\n可是“体”无需深究。如果你不想做个大科学家，也不想研究哲学的话，只需要大致知道“奥派”“铅笔社”是正确的就可以了。铅笔最前沿的一些学术观点也无需参与讨论。\\n“用”，指的是水库论坛。\\n我们知道了经济学上的一些大知识。譬如M2超发，譬如货币失常。\\n可是如何让他们变成商机，变成钱，变成我们赚钱。这其中仍大有学问。点点滴滴，细说起来也是宏篇巨著。一架飞机的说明书，只怕比“空气动力学”研作更厚。\\n“术”则是最外围的。譬如说，你买房，每次需要谈判下定之前。不要空手，去银行取几万元现金出来。\\n现金最好是旧钞。毛绒绒的看上去一大堆。旧钞的厚度比新钞厚。\\n等你谈判的时候，谈到关键要紧处，把钱往桌子上一堆。\\n“叔叔，我们很诚意买的。请你卖给我吧”。\\n现钞永远比银行转账或者支票更有冲击力。厚厚的一大叠堆在桌子上，有时候房东还是穷苦了一辈子的小市民，于是就被闪花了眼。\\n俗话说，“冲动是魔鬼”。房东一冲动，你就成魔鬼了。\\n用这个方式，房价至少可以多砍0.5W元下来。\\n但是这样的知识，对于系统性的理论研究有用么。对未来有指引么。\\n没用的。他是碎片化的，短暂的，散诸各方的点滴。或许过几年现金都不用了。\\n这样的知识，点点滴滴，散落在各个方面。无法用一根绳子将他们串起来。\\n而他们对赚钱却很有用。甚至一个短暂的技巧，能赚到大学教授一年的工资还要多。\\n再举个例子，但凡买房，上家总会问到一句：“你们是买来想自主还是投资啊”。\\n正确的回答，绝不是说实话，或者一半一半。而是要毫不犹豫地坚决说道：“自住”~~俺女朋友/老娘特别喜欢。\\n因为如果你回答说是“投资”，凡是投资，必然要有回报。房价就要有涨幅。房东难免心里会犯嘀咕，是不是我卖便宜了。以后交易容易产生纠纷。\\n而你回答“自住”。甚至要说“房价是贵了一点，可是她（女朋友）不知道为什么蒙了心，非得盯着这套买不可”。\\n于是房东沾沾自喜，顿时觉得是卖了一个好机会。以后的交易更配合不容易产生纠纷。\\n“体”大道理是根本，但他很少帮助我们赚钱。“术”每一条都是精灵古怪。但他们只能碎片化使用。\\n\\n## 经济学20\\n\\n经济学没有流派。世界上只有二种经济学，讲道理的，和不讲道理的。\\n\\n一）坑外有坑\\n当我读高中时，好友Magnus和我说，经济学是一门奇异的科学。是唯一的“正反双方”都可以获诺贝尔奖的学科。\\n当时觉得 “哇，好高大上啊”。\\n经济学是一门实证性科学，即他无法做实验。也不知道一些举措，譬如加息减息，刺激性财政政策，这些行为的真实效应是多少。\\n因为他只有一个输出量，就是GDP。而各项政策的效果，是无法单量的。\\n据说尼克松总统曾经想要找一个独臂的国家经济顾问。因为他的经济学家总是和他说“In one hand……in another hand……”，搞得老尼不胜其烦。最终忍不住翻脸说有没有杨过九难之类的。\\n当时很年轻，很不懂事，觉得真有道理。大学生知识份子就是不一样。\\n一直到许多年以后，才发现这样的“讲法”是有很大问题的。\\n1967年出现了学说“理性人共识”。\\n其具体的解释，指二个人，如果都是绅士，完全秉承着善意探讨的精神，没有任何偏见和不可逾越的宗教信仰。纯粹基于科学和逻辑的推论；\\n则最终二人是能达到共识的。\\n也就是说，科学是有的，真理的道路是唯一的。如果让一正一反，二个经济学诺贝尔奖得主关在同一间小黑屋里面。关上三个月，最终他们是会得出“共识”而出来的。\\n二个人中必有一个是错的。\\n那么，为什么现实生活中，克鲁格曼和哈耶克都是诺贝尔？\\n\\n二）万物理论\\n\\n世界上有没有“万物理论”，有没有一条揭语，直指本心。一语道出，云开雾散，大道破得干干净净。\\n幸运的是，这并不是一个哲学问题。而是真实发生的事。\\n据我所知，至少发生了二次。\\n一次发生在古希腊时期。欧几里得发现了“几何学公理”。\\n将当时繁杂复扰的几何学知识，通过几条简单的公理。可以象房子建筑大厦一样，一层一层垒起来。\\n给你几块地基，最终垒成摩天大楼。其简洁，精妙，千百年后仍让人赞叹不已。\\n另一次则发生在19世纪。\\n当时地理大发现，越来越多的物种被发现。都超出了《圣经》的描述。\\n生物学，一度被认为是不可归类的。\\n因为生物实在太多样化，太复杂，红尾翅蝇，巴西蜗牛，苔藓与磷虾，他们完全没有共同点和相似之处。也完全无法理解与脉络。\\n这时候，出现一个人，他只用了一句话，八个字，就将地球870万个物种解释得清清楚楚。破得干干净净。\\n这人是CR.Darwin，他说的八个字是：“物竞天择，适者生存”。\\n有了这条主线轴，寒带为什么没有常绿树，三文鱼为什么要迁徙，大猩猩为什么不会绝经，这些问题就很清楚了。\\n人类再回过头来看自然界，看得是清清楚楚。宛如公式在手，再把环境变量套上去就可以了。\\n如果把人类文明粗略地分为“自然科学”和“社会科学”。\\n那么自然科学皇冠上的宝珠，是物理学。他几乎是一切实用科学的基础。\\n而社会科学的总轴，皇冠上的宝珠，是“经济学”。\\n\\n三）政治经济学\\n\\n学术界一直有一个词，叫做“经济学帝国主义”。\\n意思就是经济学如此强横，以至于任何一个社会学科他都可以插上一手。凡事都可以用经济学解释。\\n为什么人们会闯红灯，因为经济学。\\n为什么印度要烧死寡妇，因为经济学。\\n为什么伊斯兰不吃猪肉，因为经济学。\\n为什么监狱里Gay的比例会大幅增加，还是因为经济学。\\n经济学几乎解释了人类社会的方方面面，几乎每一个宗教，习俗，道德传统，饮食烹饪，家庭亲情，婚姻恋爱，几乎每一个角落都有经济学的解释。\\n就好比“进化论”对于生物学的解释无所不在。\\n在这个时候，“经济学”产生了一场质变。变成了“政治经济学”。\\n因为经济学这件事，本身具有“大义”的名分。\\n马克思曾经说过，生产关系要适应生产力的发展。生产关系的所有调整，关键要解放生产力。\\n所以对于“最大生产力”这件事，本身就具有大义的名分。\\n哪怕对于统治者，他也是需要“生产力”越大越好的。\\n因为统治者并不是一个人，一个大哥下面跟着一群的小弟。\\n每一个小弟，都张大着嘴，渴望捞取更大的利益。有糖派，才能团结人心。没糖吃，队伍就散了。\\n在一些情况下，这可以通过掠夺其他群体来维持。但长远来看，还是要创造财富，创造更多的财富，才可以维持统治。才可以让下面的每一张嘴都开心。\\n“生产力的发展”，是一股不可阻抗的历史洪流。\\n“经济学”本身会对这个世界作出解释。但这个解释，真正有文化有思想的人，会知道哪些是对的，哪些是错的。但这就违反了统治者的利益。\\n譬如说，我们知道“武媚娘”剪胸是错误的。\\n广电总局禁止小米盒子是错误的。\\n上不了Google是错误的。\\n加油只有二桶油是错误的。\\n微信POS不允许展开业务是错误的。\\n但是知道这些错误，违背了统治者的利益。\\n“经济学”本身占据了大义的名分。统治者如果不想面对这些错误，那么他最好的选择是“阉割经济学”，或者给你一门错误的经济学。\\n所以我们这个世界，从来没有真正的“经济学”。有的都是“政治经济学”。也就是统治者塞给你的经济学。\\n在中国，我们学的是马克思主义经济学。\\n在欧洲美国，人们学的是大政府凯恩斯主义经济学。\\n其共同的特点，这二门经济学都是错误的。\\n但是政府需要这么做，他需要给人们洗脑。以获得“大义”的名分。要使人民相信，统治者目前所做的一切，都是符合理论逻辑的。生产力最大化，最治国治民的。\\n所以，诺贝尔经济学奖，出现二个相反的“经济学家”得主根本不奇怪。纵观其得奖名单，凯恩斯主义占了一大半，真正奥派只有Hayek一个。\\n诺奖基金会也是人，人有什么不可操纵的。上次日本觉得三十几年没出诺奖了，于是次年就得了一个文学奖。\\n\\n四）扭曲的世界\\n\\n好吧，本账号是一个俗不可耐讲钱的账号。各位听我嗑嗑叨叨讲了半天，到底和赚钱有什么关系。\\n“体、用、术”，在基础理论之中，我们所学到的并不是真正的科学：“奥地利经济学派”。\\n而是政府强行灌输给我们，错误的政治经济学。无论是马克思，还是市面上流行的“西方经济学”----凯恩斯主义。\\n这里面就产生了扭曲，就产生了错配。就产生了套利空间。\\n内功心法的不同，一开始就走上了不同的道路。\\n“体、用、术”知道了体基础三观已毁，具体的用法还要下篇再讲。\\n（yevon_ou@163.com,2015年2月27日午后）\\n\\n## 无风险套利30\\n\\n只要给我一个无风险套利方法，我就可以富可倾城。\\n\\n一）套利赚钱\\n\\n这个世界赚钱，一种方法是出卖劳动力。譬如下煤井搬煤，或者小白领坐办公室。坐满八个小时，老板就发你一天的工资。\\n另外一种方法，则是做生意。低买高卖。1元买进，2元卖出。\\n第二种方法来钱快，但他有二个缺点。\\n价格会移动。随着你生意做多了，买进价会逐渐涨到1.1元，卖出价会跌到1.9元。利润空间会缩小。最理想的是你背靠一个海量般的市场，比天空还宽广，比大海还辽阔，这样价格才会仅缓慢滑动。\\n会有竞争对手。加速价格滑拢。\\n对于绝大多数做生意的人，他烦恼的是a和b二个问题。所以生意也不好做。真想赚大钱也难。\\n那么，有没有一个办法，能维持价格始终不动。始终维持“1元买进，2元卖出”。我只要在其中跑来跑去，就能躺着赚大钱。\\n这种方法，学术上称为“套利”。\\n但是套利是不长久的。几乎任何一本教科书都会和你说，一旦存在套利机会，就会吸引无数的“竞争者”涌入这个市场。大家竞食这块肉。最终搞到“1.4999元买进，1.5001元卖出”。也没有多少利润。\\n如果你能发现一个长期套利机会。毫无意外，你会积累大量财富，无可限量。\\n\\n二）长期套利机会\\n\\n几乎所有的教科书，都说“长期套利机会”是不可能存在的。\\n但我们生活的是一个神奇的国度，一个神奇的时代。一个千年变革的国度，一个千年未遇的时代。\\n在我们这个时代，至少发生了一次“伪”大型套利机会，虽然不是完美的例子，却符合了大多数的特征。\\n他比天空还宽广，比大海还辽阔，饕餮盛宴，吃到盆满钵满。\\n他至少要满足几个条件；\\n1）这个市场要很大\\n2）存在严重的扭曲\\n3）99%，甚至99.99%人口是愚蠢的。他们不知道这种扭曲。\\n这其中，第三条才是最难的。\\n很多人已经猜到了，这就是中国的房地产市场。\\n房地产市场很大，这是毋庸置疑的。但很少有人承认，他是被“扭曲”的。\\n什么叫“不扭曲”。门口的煎饼果子店就是不扭曲的。你想买就买，想买几个就买几个。今天忘带了钱，让烧饼王大娘赊你几个也是可以的。\\n如果煎饼果子的利润太高，明天旁边摊贩就会出现李大娘，赵大娘。煎饼果子充分竞争，消费者可以自由选择。绝不会有人规定王大娘的烧饼只能卖3元/个。而且加鸡蛋只能加半个，不许抹沙茶酱。\\n而房地产市场不是，从购买土地，土地贷款，定价，发放许可证，户型，面积，配套比例，销售对象，消费信贷，再交易年限，税务惩罚，中介掮人，每一件事政府都要管。政府的手从来没插得这么深。\\n有干预就有扭曲。有扭曲就有落差。\\n落差就是钱。就是“2元卖出，1元买进”。\\n而有了商机还不够。关键还要看“竞争者”的多少。\\n互联网热潮一旦兴起，硅谷一个月之内就多了3000家公司。羊再多，也经不起狼多。\\n这会极大地降低你的成功几率。\\n而这时候，就牵涉到了关键第三点。中国是一个极特殊的国家。\\n其99%，甚至99.99%的国民，仍未脱离“蒙昧”状态。接受的是错误的政治经济学、洗脑教育。\\n这个才是核心点，赚钱核心点。\\n错过这样的时间段，就再没有这样的机遇。\\n内功心法不同，决定成长路线不同。\\n当2005年政府发动“宏观调控”时，对二手房交易征收5.5%的营业税。几乎所有持“正确”经济学，奥地利学派经济学的人，都会倒吸一口冷气。房价这是要大涨啊！经济学如是分析。\\n可是持有“错误”的经济学之人呢。如果我们翻翻05年的舆论媒体，几乎是一片倒的99.9999%人口都在唱:“中央出手了，房价要大跌”。\\n你说这算什么，蠢货么，白痴么，我们的同胞都是一群猪么。\\n因为他们都是文盲。虽然他们的头顶上往往都有一冠“学士”“博士”的帽子，可他们实际都是TG培养的学士。并不是真正的大学生。\\n独立思考，正确学术，这条路在中国是如此之稀少。乃至于0.0001%的人口都不足。\\n而另一方面，铅笔社那些大师，李子暘，布尔费墨，他们虽然可以正确地推断出“房价必涨”。可是他们只有“体”，没有“用、术”。\\n他们不会真正冲到购楼处，去买一套房子。他们只会书桌图纸上，写二篇结论。这样的人，也不会对我们套利赚钱构成威胁。\\n“体”是根本，你首先要有正确的科学，才能推算出价格的走向。\\n然后还要“用、术”，有实际执行力，才能冲进售楼处赚钱。\\n我们赚钱的基础，是整个时代的大格局。99.99%的国民是文盲，他们受的是洗脑教育。\\n在可预见的将来，也不见得“政治经济学”会得以放松。科学能够普及。\\n这才是长期套利的基础。\\n\\n三）正道\\n\\n经济学没有流派。世界上只有二种经济学，讲道理的和不讲道理的。\\n任何二个绅士，讲道理的理性人，都可以坐下来。细心耐心地好好商讨一下，基于理性和逻辑的科学是唯一的，不存在流派。\\n在所有的“讲道理”经济学中，奥地利系统所向无敌。哈耶克，米塞思，罗斯巴德，中国的布尔费墨……\\n他们提出的观点，他们对于社会保险，医疗保险，劳动法，最低工资，妇女童工歧视法案，垄断法，贸易保护主义，耕地红线，环保主义，新能源革命的抨击是如此犀利，让人完全心悦口服，完全无法反击。\\n如果大家坐下来讲道理，则“奥派”天下无敌。所向披靡。\\n那其他学派的经济学家怎么办呢。当他们发现心服口服，无可辩驳的时候，他们最好的办法就是不和你讲道理，而是挥舞起了拳头，“开门，抄水表”。\\n奥地利经济学派对于目前“主流”经济学家的批判几乎可以说到烂了。象李稻葵，易宪容，谢国忠之流根本不配称为经济学家。“凯恩斯学派”存在的整个基础，是政府需要他们，政府喜欢他们的论调。\\n每年政府拨款99%拨向凯恩斯经济学家。\\n秦晖有一篇《阻止极右倾向可能为时已晚》[1]，他这篇文章虽然写得乱七八糟。但标题却是取对的。\\n“科学一旦发现，就在人心中发了芽”。就象中世界无法阻止伽利略斜塔试验，现在的人也无法阻止正确的经济学传播。\\n因为人类追求真理的心态是永恒的。只有正确的理论，才能精确判断事物走势，进可以治国安邦，退也可以为个人谋财赚钱。\\n人类追求真理的心理是无可遏制的。当奥地利学派以无可争议的优势崛起，横扫，从正面战场将其他所有理论驳倒，推翻。\\n你仅仅跳起来挥舞拳头，“喝咖啡，抄水表”，那是无济于事的。没什么可以阻止人们对于科学的狂热，对于真理的信仰。\\n虽然今天，“奥地利学派”在中国仅是刚刚生根发芽，知道的人群不足0.01%，连知识份子也大多处于愚蔽状态。\\n但是，只要他一开始传播，就没什么力量阻止他在人群中的生根发芽。因为奥派完全符合科学。有什么问题，你坐下来说啊。大家坐下来，摆事实讲道理的讨论，于是你就被奥派说得心服口服。在讲道理的经济学中，奥派天下无敌。\\n当你说:“开门，抄水表”那一刻，你就已经输了。\\n \\n（2000年6月12日，美国华盛顿一家名笔专卖店举行了一个别开生面的揭幕仪式：笔与剑的较量。81岁老人持笔作战，击败身披战袍、手持利剑的彪悍武士，象征“文明战胜蛮荒”。）\\n\\n## 大纲的困扰40\\n\\n椭圆是什么，椭圆就是X2+2Y2=1\\n“伢子，这x,y是什么东西呀。还有，你画一横一竖二条直线，这是要干嘛呀”\\n一）写本书\\n我写过很多篇文章。\\n第一篇广为转载的，是2003年的《我们是怎样陷入贫穷的》。指责挪用外汇储备，忽弄百姓。\\n流传最广的，则是2004年的《人民币面临巨大的贬值风险》。转了超过1万个网站，超过2000万人次阅读。还被改了很多名字，譬如《大排面30元一碗》。\\n到了2013年时，有好事之人，将我的文章都搜集起来。整理成册。而我太太，则是温柔体贴，偷偷地找了出版社印刷成书。这就是《十年文集》第一稿。\\n坦白说，对于这本书，我是极其不满意的。\\n十年来，水平涨了是一个方面。现在再写，肯定比当年老练。更深入，还能纠正一些小瑕疵。\\n但最主要的关键，这本《十年文集》，他是散碎零落的。\\n这本旧册子，每一篇都有闪光点，每一篇都很精彩。\\n3000字一篇，任何一个单篇，取出来都足以满堂喝彩，眼前一亮。\\n但这一共约300篇文章聚在一起呢。\\n那就是狗屁不如。\\n好比我们说“体，用，术”。这一系列的文章，零零碎碎大多属于“术”的范畴。\\n这些文章，他会教你房子如何选择，笋盘如何砍价，资金如何筹措，利息如何精算，再融资盈亏平衡点在哪里，现金如何管理…………\\n其中的每一篇，拿出来都堪称经典。\\n可是你整部书看完呢，你还是不懂炒楼。\\n\\n二）框架与脉络\\n那我们缺的是什么呢。我们缺的是一根线，把这些知识点串联起来。\\n又或者说是一颗大树，有了主干，有了框架，然后再把枝枝页页挂上去。\\n如果你现在立志，大吼一声：“我要开始炒楼了”。\\n你知道你要干什么么。第一步，第二步，第三步。\\n分几个阶段，哪几个阶段该怎么走，每一步需要注意点什么。\\n这个就是框架。\\n就是“体”。\\n所以当我们回顾这本《十年文集》Ver 1.0时，我们十分不满意。因为他充满了技巧，却没有整体框架。\\n所以我们干脆下了一个决心。我们要写一本Ver 2.0，这个版本不是以前的版本上加加减减几篇文章。而是要一个全新的框架，几乎全部都重新写。\\n将原先重复的语录删去，缺失的几个节点补上，所有的文章，以2015年的水平眼界重写一遍。300篇全部都是新的。\\n箫逸的《甘十九妹》中有一段话，“她虽然只展示了水红芍三招剑法”，但因为人一个时期的水平总处于同一水准线上。水红芍的其他剑法也是类似威力。\\n同样道理，在我目前这个年龄，这个见识阅历。目前是一个大体上的平台期。在这个水平线上，将全部所学整理一下。汇集成册，告一段落，也是一件很有意义的事情。\\n当2014.8我们刚开始准备写这本《炒楼秘籍》2.0时，我们十分乐观。最初的估计，是仅仅十五天。\\n此后，我们发现这是一个不可完成的任务，于是改为三十天。\\n再之后，我们发现三十天也写不完，又改成了二个月。\\n四个月过去了，全书完成进度11%\\n为什么，卡在哪里了呢。\\n问题出在《总纲》上面。没错，就是不足500字的总纲，卡了整整四个月。\\n现在才知道，一些大师举重若轻，那是多么地不容易。\\n最初刚开始整理这本书的时候，我们心里底气很足。\\n既然这300篇都是我写的，肚子里有墨水。那我将你们都整理一遍，稍加修改润色，十五天也够了。头尾再加二篇，立即就可以成册。\\n但之后我们就发现，将炒楼这件事整理成一个“系统”，是多么地不容易。\\n从哪个角度切入，然后一层层剖开。\\n既有循序渐进，又可以面面俱到。\\n这个问题想了足足四个月。实在做不到如“庖丁解牛”一样行云流水。\\n但各方已经开始催稿，RP值已经跌得不能再跌。\\n眼看郭敬明都可以拍部电影自讽拖稿之王，永远不迈出第一步，那就永远没进步。\\n那怎么办呢。我们用《水库论坛》订阅微信号向外开始推送文章。\\n每一篇都是被人看见的。每隔3~4天必然会推一篇。\\n这样，大家都看见了。不可逆的，终有一天会写完。\\n三）大纲的结构\\n可是，这个问题还是没有解决。“从哪里切入点，然后一层层剖开，循序渐进，把整个系统讲得清清楚楚”。\\n我已经知道问题在哪了。\\n我问你，椭圆是什么形状的。\\n书本还没丢光的朋友们立即会回答：“X2+2Y2=1”。\\n你把这个答案拿给姥姥看，她一定看不懂。\\n她会问你，X是什么，平方是什么，坐标轴是什么。\\n这是怎么回事呢。这是“基础知识”的作用。\\n如今我每天有一点新的心得体悟，技巧和手法漏洞，我会贴一篇帖子在水库论坛。\\n在水库论坛(Shuiku.net)上讨论问题很容易。因为大家都懂得一些基本知识。就像X2-2Y2=1是双曲线一样。\\n在水库论坛上，你要讲砖本位，CEO盘，笋，药单，初房情节，DS流，文科生小编，航母，A8…………这些术语和单词几乎是顺手拈来，每个人都看得懂。\\n \\n\\n但是，如果我们想写一本书。你不能假设初次阅读者，懂得“2N”的道理。\\n所以我们就要花上整整一篇篇幅，解释“长颈鹿”。然后把长颈鹿的精神，溶入到每一篇文章中去。\\n我统计了一下篇幅，发现大大超出意外。\\n首先我们解释一下，炒楼分三个阶段：\\n筑基\\n明悟\\n天诛\\n这三个词本身没有多大的意义，甚至只是当时一句戏言。但他们的确代表着几个转折领。分别是第1套，第6套，第16套。在这个位置上，你会遇到瓶颈。而突破之后，整个模式都会不同。\\n如果我们简单介绍这本书。则他分5个部分。\\n基础知识，160篇\\n筑基，80篇\\n明悟，40篇\\n天诛，20篇\\n云清，10篇\\n其中，首先把所有“经济学”的专业文章全部剥去，无论是讲利率，汇率，货币关系，存款准备金率，次贷算法………任何专业的东西都剥掉。“体”全部都不讲，你只要接受公式就行了。想要问为什么，另外再起订阅号。\\n这样，剩下的篇幅，恐怕还有160篇。全部都是“基础知识”。从什么是x，什么是平方，什么是坐标轴说起。\\n但是，很多人关心的并不是“基础理论”。而是怎样帮他们赚钱，赚快钱。\\n譬如说，从微信的内部统计数据，那篇《经济学》的阅读量，就只有平时的一半。\\n人们不喜欢枯燥的学习知识，人们只喜欢八卦。\\n\\n如果你坚持写160篇“普及知识”，恐怕人都跑光了。这个微信号也没有人看。\\n所以我们还得跳着写。写几篇打基础的“用”，还得先写赚快钱的“术”。\\n按流程，下一篇应该写《经济学第一定律》。但纯学术已经没人看了。所以我们还得先写一篇应景的《降息对房价的影响》。\\n当然其水准，也足以秒杀目前绝大多数学院派大师的。\\n对于编号，我们是插着编的。基础知识是1~199，后几个阶段是200~299，300~399，400~499，500~599。\\n也就是说，《降息对房价的影响》，编号将是#3000\\n那为什么要加一个0呢，#10，#20，#30这样的编号呢。那是为了插补。\\n\\n四）最后的问题\\n最后，还有一个问题。为什么越到后面，篇幅越少呢。为什么绝世武功，往往只有寥寥几十个字呢。\\n因为一个到了“天诛”阶段的职业炒家，他对于炒房这一行已经非常熟悉了。该懂的全都懂了，再也没什么东西可教他。\\n而他对于基础知识，也已经非常的了解。若再要沟通，直接三言二语就够了。\\n这个时候，还能够百尺竿头更进一步的，往往只是一二句话，一二句突破口。\\n欧阳锋如果要练《九阴真经》，几句话一个指点就行了。\\n爱因斯坦曾经花了后半生的努力，来寻求万物理论。物理界公认，这个理论是个公式，可以写在一指长的纸条上。\\n一指长175px，狭义相对论的公式是E=MC2\\n广义相对论的公式是: Rμν-（1/2）gμνR=(8G/c4)Tμν\\n生物学的公式是八个字:“物竞天择，适者生存”。\\n现在物理学孜孜以求的公式，也是类似长度，可是爱因斯坦就是求不出来。\\n简单吧，很简单，一共十几个字符。\\n写这些话干嘛呢，因为下一步的路，我也不知道。\\n"}'));jctx.push(JSON.parse('{"id": "180520", "tag": "book", "text": "# 经济学第一定律50\\n\\n经济学第一定律是什么，dT>0，这里的T代表交易。\\n\\n一)国民财富\\n如果以1773年《国富论》出版，作为经济学科技树萌芽的标志。则亚当·斯密斯将他呈献给英王的时候，有一个问题是无论如何绕不过去的。\\n“尊敬的先生，你号称经济学能让我们的国家变得更富裕。可是纺织女工织布，农夫耕作。你一不织布、二不耕地，请问你创造的财富，从何而来？”\\n这是一个大是大非的问题。也是后世几百年国力强盛的分水岭。这么多年的歧视商人，打击投机倒把，割资本主义尾巴。乃至于今天的环保恐怖主义，人权圣母B，福利懒虫绿教泛滥。全都和他有关。这是个核心问题。\\n这个问题的正确回答：“先生，财富来自于交易”。\\n我们知道，财富，并不仅仅是简单的相加关系。\\n一个樵夫有一把小提琴，一个音乐家有一柄斧子，他们(二人）的财富，并不是简单的“小提琴+斧子”。\\n一定要非得到樵夫和音乐家见面了，二人互相“交易”。樵夫拿到斧子，音乐家拿到琴，财富才算最大化。\\n一个沙漠中的部落，可能拥有大量的石油，可却没有蔬菜水果。\\n一个桃花源中的部落，可能拥有蔬菜水果，可却没有石油。\\n二者交换。“总财富”才能最大化。为此，我们甚至不惜加点损耗，修条铁路。\\n当国王问到AdamSmith，“纺工织布，农夫耕田”时。其实“布+米”的财富，并不是国民财富的最大化。\\n“布+米+交易”，才是国民财富的最大化。\\n参考文献：铅笔社立社精神之本《铅笔的故事》[1]\\n\\n二)不动量\\n我们习惯用“不动量”来分析问题。\\nA有一个苹果，B有一个梨。无论你左看右看多少遍。其物理财富也是“一个苹果+一个梨”。\\n只有当A和B见面了。A喜欢吃梨不喜欢苹果，B喜欢苹果。二者交换。则“财富总量”才可以增加。\\n可是这个时候，财富又达到最大化了。不可能再增加。因为再也想不出“新的交易”。\\n除非这时候，再出现一个C。C喜欢吃苹果和梨，但有很多桔子。用桔子把梨苹果都换了。\\n可见，在整个系统中：\\n有了交易，财富就会增加。\\n没有交易，财富就不会增加。\\n如果广义地把上班也理解成为一种交易。是“用你的8小时”换“雇主的工资”，则人类的全部生产活动，全部财富，可以理解成一个公式：dT>0.\\n有多少交易，就有多少财富。\\n交易越多，财富越多。\\n当你再也找不出任何交易机会时。财富达到最大化。这就是帕累托极限。[2]\\n这是一条非常非常强大的定律。强大到象“能量守恒定律”一样坚不可摧。\\n因为他并不是一条宏观定律，而是一条微观定律。不仅对大社团有效，拆散到每一个环节，每一个步骤，每一个场景，他都是有效的。\\n“交易”就象小草，在任何一个不起眼的角落生长开来，都会使得我们的社会更美好。任何一个角落交易多了，全社会财富都会增加。\\n所谓宏观，无非无数个微观累加。“能量守恒定律”并非在航天宇宙飞船上有效，他在飞船的每一个零件都有效。\\n当你学会了dT>0，秉承了“经济学第一定律”的精神，你再去看看目前的教科书，包括最近40年历届的诺贝尔经济学奖。其中一大半是错的，一大半可以直接扔进垃圾堆里。\\n因为dT>0，交易产生财富，有多少交易，产生多少财富。\\n不增加交易，就不增加财富。\\n然后你再翻翻这些经济学著作，譬如去年的法国人诺奖得主“反垄断法”。你再问问前几年的工会与博弈，环保与管制。你只要简单地问他们一句：“交易增加了么”？\\n对于那些玄而又玄的计量经济学公式，洋洋洒洒的几千页论文。指手画脚的经济学高参。你只要简单地问他们一句：“先生，您既不耕地也不织布，请问您是怎样为我们的国家增加财富的”。\\n拥有了经济学第一定律：dT>0，简直就象拥有了“能量守恒定律”大杀器，然后穿越回到十五世纪。\\n你拿起来看看十五世纪的论文，永动机或者炼金术，一大半都可以直接扔进垃圾堆。擦靴子。\\n\\n三)现实的世界\\n如果哪一天你被请去了清华大学教授经济学，你只要在黑板上写一个公式:dT>0.\\n然后就可以宣布散会了。学生们都可以回家去了。经济学这门课程就讲完了，剩下的20个课时都不用上了。\\n因为经济学只要求追逐T“交易”最大化。当你把一个社会所有能交易的事情都想遍了，再也找不出任何“新”的交易。则自然国家最富，达到了帕累托最优。\\n可是，那么多经济学宏篇巨著。洋洋洒洒几千万部巨著，他们说的都是啥。\\n这说的都是啥？\\n千万部巨著，说的是，当你达不到最优时。你该想到什么补救办法。当你打了1个补丁，就要要再打100个补丁。当你打了100个补丁，你就需要再打10000个补丁。\\n举个例子。凡是发展中国家，政府都很喜欢压低汇率。以刺激出口。这就是第一个补丁。\\n当你打了第一个补丁之后，市场之上就会出现很多热钱，来冲击你的汇率。还会有地下钱庄，来偷偷汇款进出。这时候你就需要“外汇管制法”和“汇款实名制”。这是第二轮管制。\\n当有了外汇管制和存款实名，就会有各种各样的洗钱机构，BVI公司和VIE代持。为了管制这些手法，你需要建立庞大的警察机构和合规律师团体。这就是第三轮管制。\\n最终把你的政府撑得庞大不堪。1个管制带来100个管制，100个带来10000个。\\n而经济学家也顺便找到了工作。因为“外汇”“FDI”“资本流动”“法律法规”，每一个都可以展开写上NNN万字。于是“专家”们不会失业了。\\n经济学可以很简单，简单到只要一个公式：dT>0\\n顺着这个公式去做，国家就会大富。掌握了能量守恒定律，你会发现“国家财经顾问”的绝大多数建议都是谬误。\\n经济学也可以很复杂。“地心说”曾经在地球仪上套了46个光圈，来修正学说的误差。今天的情况也差不多。\\n为什么会这样？为什么人类会“不作死就不会死”，搞到生产力倒退。\\n下篇再说。\\n\\n譬如说，你知道“限购”这件事，是怎么出台的么。\\n（yevon_ou@163.com,2015年3月23日午）\\n\\n[1]《里德：铅笔的故事》http://finance.ifeng.com/opinion/xzsuibi/20111129/5161616.shtml\\n[2]插一句题外话。以前教科书上写帕累托最优是三重解。生产者最优+消费者最优+分配者最优，这纯粹是看书不甚求解。这三重解其实是一回事。是更底层同一条规则，dT=0\\n"}'));jctx.push(JSON.parse('{"id": "180601", "tag": "lang", "text": "# 继承和原型\\n\\nThe History of Object Oriented Programming\\n\\n最初，人们并不知道“继承”究竟应该是什么。对这种新生事物，要求人们一下子就在头脑里有个清晰图景显然是不可能的。\\n\\n关于面向对象，一直以来就有两个主要派别：Class-based vs prototype-based\\n\\n后来的其他各种流派，都离不开这两个派别的核心思路，只是具体细节上略有不同而已。\\n\\n其中，前者认为，面向对象就是个分类问题；既然是分类问题，那么更靠“上”更“抽象”的大类自然就更基础，它所有的东西理所当然应该被继续细化的“子”类“继承”——圆形是个图形，方形也是个图形，所以圆形和方形都应该从“图形”这个类继承。\\n\\n类似的，蝙蝠既是可以飞行的动物，也是哺乳动物，所以它就应该从“可飞行动物类”和“哺乳动物类”继承——这样才可以“既能飞行又能哺乳”。\\n\\n换句话说，Class-based这个思路很容易直接导向一个误区，那就是不假思索的引入“继承”，并且还总是把“继承”看得过重。\\n\\n但是如此一来，就不可避免的导致很多含糊不清的问题。其中表现最严重的就是多重继承。比如，蝙蝠究竟是用飞行动物的嘴吃饭呢，还是用哺乳动物的嘴吃饭？吃下的饭，是给哺乳动物的胃消化呢，还是给飞行动物的胃消化？（熟悉编程的朋友恐怕马上就要想到未初始化、未重置、访问错误的内存区域等等“恶心而又可怕”的东西了）\\n\\n有的人可能不假思索的说“没关系没关系，C++的虚继承了解下！似乎只要在语言中提供个机制，把来自飞行动物和来自哺乳动物的嘴巴、胃等等合并起来就够了。你看，现在不存在歧义了吧？\\n\\n嗯……我现在有个需求，我们知道，汽车过去都是内燃机车，后来有了电动车；但是电动车充电慢电池容量小，所以又有了混动车。请问，当我的混动车同时从内燃机车和电动车多重继承后，你会不会自作主张把两个不同的动力基类合并？你要合并了，我这程序还怎么写？我的车上的的确确有两个不同的发动机！但倘若你不合并……你看，菱形继承的二义性就又来了。\\n\\nC++和Java都是class-based派别的支持者。这是因为，乍看之下，class-based这个思路很好很解决问题；所以Object C、C++甚至后来的Java全都选择了这条路。\\n\\n但是，它“默认让派生类取得基类所有遗产”的行为还是造成了很多很多的问题——这种行为不可避免的导致派生类和基类代码产生耦合；尤其在多继承时，尤其是菱形继承这种最恶劣的情况下，你甚至都不知道它会和基类的哪段代码/哪些数据结构产生耦合！\\n\\n理所当然的，基于C系语言一贯的、对程序员的无条件信任，C++选择了支持多继承，虽然这个东西已经暴露出来很多很多的问题，但它毕竟在某些时候还是有用的；而Java则禁止了多继承——毕竟它已经暴露了太多太多的问题，禁用它至多也就是实现繁琐一些、性能差一些而已。\\n\\n长期实践下来，prototype-based派别的观点就在实践中越发显示出了它的正确性——相比之下，class-based派就有点像缺乏考虑、就着比喻做设计的一群大老粗了：只是比喻总是比学术语言更生动、更容易流行，这才让它一度占据上风而已。\\n\\nprototype-based派别认为，面向对象其实就是一组实现了特定协议（或者叫接口）的object——在它里面压根就不存在类，只有prototype和object。\\n\\n按照这一派的思路发展下去，我们真正应该关心的是“对象可以提供什么样的服务（或者说，像XXX一样的服务）”：重要的是接口！压根就不需要考虑/支持继承这种矫揉造作的东西！\\n\\n分类？呵呵，正方形是长方形吗？在想清楚前别说话！\\n\\n这就绕开了class-based需要面对的、棘手的“正方形是不是一种长方形”问题——程序语言里面的class并不是日常语言中的“类”，它的精确表述是“is-a”，和口语的“类”八竿子打不着（事实上，自从class-based派同意“类不是类而是is-a”开始，他们已经向prototype派投降了：你可以自己想想这是为什么）。\\n\\n和外行的想象相反，class-based和prototype-based并没有因此而打得头破血流。\\n\\n事实上，几乎从最初的几个版本开始，C++/Java就引入了prototype流派的思想，这就是所谓的“interface”，或者说，其实严格来说并不是继承的“接口继承”——当然，基于一贯的、对程序员的信任，C++允许你的interface里面存在实现代码甚至数据成员：只要你确切知道它会被如何使用。这种做法就使得接口继承里面的继承二字又找回了一定的存在感，然后就把多重继承之类问题又找回来了。\\n\\n不过，class-based思路真正的问题还在于继承带来的强耦合，以及“鼓吹继承”给它的程序员甚至设计者所带来的思想包袱（想想本来已经通过interface解决、但又被随意“魔改”的interface找回的菱形继承问题吧）。\\n\\n为什么prototype-based派可以绕开继承带来的诸多副作用呢？很简单，因为prototype派压根就不存在继承。它就是声明自己支持某个“协议/接口/prototype（反正就这意思，你叫它什么都可以）”，然后想办法真的去支持这个协议就完了。\\n\\n如何支持呢？你可以自己从头写；但也完全可以在自己的object中隐藏一个支持该协议的、来自系统或第三方的object，然后把相关调用转发给它（这个转发在相关语言里，常常可以通过显式声明自动完成：换句话说，继承在这种语言里不过是个语法糖而已；而且这种语法糖思路确保你不可能弄出多继承来）。\\n\\n既然prototype只是允许一个对象声明它兼容某个prototype而已，并不会越俎代庖的把这个prototype的默认实现/标准基类等等东西塞进你的代码——那么，这个prototype究竟是怎么搞出来的，当然就由你完全控制了：哪怕你往里面塞一万个同样支持这个prototype的object进去，只要你自己头脑清醒、知道什么时候应该把调用转给这一万个object中的哪一个，它就是完全合法并且井井有条的。\\n\\n换句话说，既然prototype-based放弃了自动从“父类”拿到“祖传代码”这点实惠，那么它自然就绕开了“继承父类代码”带来的诸多弊端（注意这个多余的“自动”。经常的，把一个项目搅乱、把一个问题复杂化的根本原因，就是因为有人做了看似很棒很好用然而整体上却是多余的事，导致某个局部甚至整体陷入“水多了加面面多了加水”的窘境。然后就把参与者全都带歪了）。\\n\\nprototype扔掉“通过class继承拿到的祖传代码”，这看似是个绝大的浪费；但事实上，你仍然可以通过“把拉来的订单转交给父亲/母亲开的公司”、从而不浪费可以从父母那里拿来的好处——这个转交过程是完全可控的，绝不存在任何含糊之处。\\n\\n与之相比，class based鼓吹的继承就麻烦多了——你必须理解父/母亲开的公司的运作机制，不然就很容易在“继承”时搞错；更可怕的，当你同时从父母那里继承两家公司时，你喊“会计，记账”，你并不知道哪家公司的会计会把账务记到哪本帐上。\\n\\n你说我可以虚继承，把两家公司的会计团队合并起来？\\n倘若两家都是同样性质的公司，那的确没什么问题……\\n但倘若你得到的是一家房地产公司和一家IT企业，让你搞出了个X氏企业集团，同时支持房地产业务和IT业务——两者内部管理逻辑截然不同；强行把帐做到一起给你个“统一的管理接口”？我看你还怎么管理这个混账团队！\\n\\n醒醒吧。你真正需要的，是把这两家公司当两家公司经营，并不是通过什么神秘的巫术仪式合并它们：一旦两家公司有各自使用各自基类数据的理由/特殊逻辑，合并就成了混账！\\n\\n换句话说，既然语言允许，那么子类和父类当然就可能存在深度耦合；然后，当孙类从两个子类多重继承时，它们的共同父类就可能成了某种“合并不是，不合并也不是”的尴尬存在。\\n\\n千万不要以为编程语言提供的什么东西真就那么智能。\\n除非你完全明白自己在做什么、而且也确信接手自己代码的人也知道你在做什么、或者让你接手别人代码时你也总能头脑清醒的把每一个流程的来龙去脉都搞清楚……否则，还是离这类含糊/微妙的东西越远越好。\\n否则，并不是“多重继承搞出了二义性、咱只要闭着眼睛通过算法把二义性消除了就一定能解决问题”：你真正需要思考需要解决的问题实在太多了；在这种领域，语言越“智能”，你和你的团队需要理解和理顺的规则/逻辑就越多，反而越容易出错。\\n\\n多重继承的确可以很方便的解决一些问题；但为了这个方便，付出的代价往往过于高昂。\\n\\nprototype就是“不去支持继承这种含糊不明的、多余的东西，从而把语言逻辑搞简单”的典范：这种思路使得“如何组合使用object、如何对外提供prototype抽象”等诸多细节完全由程序员控制，再不存在任何含糊之处。\\n当然，它也因此再也不能像C++那样，通过“变多重继承魔术”神奇的得到某些功能了——现在你得自己明确写出来。\\n\\n这个思想一旦被引入class-based学派，就成了“优先使用组合而不是继承”。至于晚近出现的一些语言，比如go，直接就走了prototype-based的道路。\\n\\n就这样，通过引入interface，C++/Java就允许了程序员们把这种语言变成“看似class-based，实质是一堆空壳子”的存在，从而暗地里实现语言向prototype的转化（与之同时，头脑清晰的程序员仍然可以利用“继承”带来的“自动化”能力，却不至于受“就着比喻做设计”之害——越是觉得“继承”没用的，反而越是可以从语言提供的继承相关设施上得利；而越是觉得继承无与伦比无可替代的，越是会受到继承阴暗面的伤害）。\\n\\n换句话说，一旦通过prototype规避掉“实现继承”，“实现继承”带来的坏处自然就烟消云散了：多重继承这种由“实现继承”发展而的“恶性肿瘤”，自然也就失去了存在基础。\\n\\n当然，前提是，千万不要把interface又搞得像个类一样。\\n"}'));jctx.push(JSON.parse('{"id": "180602", "tag": "book", "text": "# 日本宪制史\\n\\n我们首先要建立一个关于日本的模型。日本在东亚和世界都是非常特殊的。大体上来讲，它是一个小欧洲。简单粗暴地说，日本分为两个部分，关西和关东。直到现在，关西和关东仍然有很多不同，包括它们发电机的频率都不一样，关西和关东相互歧视、相互嘲弄的段子是非常之多的。这两个部分的差异也是从历史的黎明就开始的。我们都知道，日本在它的先史时代是经历过一次替换的。最古老的居民可能是跟东南亚和南岛血统比较接近的绳文文化的居民，以北部和东北部为中心。越往北，人口密度越高。在接近北海道的地方，尤其是接近海岸线的地方，人口密度最高。即将进入历史时期的时候，来自亚洲大陆的新一代移民，通常称为弥生文化，从西部进入日本，然后情况就颠倒过来了：西部的人口密度最高，大和和北九州的人口密度最高；北方的人口密度很低，越往北，人口密度越低。这实际上是两种不同性质的文明。我们所知道的日本，是建立在这个二元对立的基础上的。\\n\\n同时，东北和西南两者，形势上也不一样。在有历史的日本这个时期内，东北部，或者是所谓的关东，相当于是欧洲的日耳曼地区；西部，以美浓不破关为界，包括京都、奈良在内的这整个西部，是相当于拉丁欧洲的格局。如果你去寻找日本的古典文化财富，那你就会发现，除了东京以外，关东基本上没有，绝大部分历史文化遗迹都集中在关西。关东对于日本来说是一个未开发地区。日本历史的前半期，关西和朝鲜半岛南部是联系在一起的，而关东则是在种族上和文化上都非常疏远的地区。而日本的武家政体基本上是开拓者的产物，相当于是拉丁的欧洲开发日耳曼的欧洲，或者是欧洲人开发美洲一样。封建主义跟军事殖民的关系一向非常密切，也是关东开拓的自然结果。这是日本历史的第一个二元结构：北方和东方像是日耳曼；南方和西方像是拉丁欧洲或者旧欧洲，或者更确切地说，像地中海世界，因为它不仅像拉丁欧洲，还包括了北非和西亚，濑户内海就相当于是日本的地中海。日本有一个小小的地中海，这是整个亚洲大陆都不具备的形势。\\n\\n二元结构贯穿了整个日本的历史和文化。地理和地缘是一个方面，文化和结构也是一方面。跟南岛或东南亚有关系的这种文化，它的主要特点是祭祀和祭司的文化。最早的天皇就是祭司。“天皇”这个词包含的一个含义就是清净和洁净。在《古事记》（注：712年成书）这样的日本神话当中，日本最早的诸神，天照大神和她的同僚们，主要的功能就是拔除凶秽。凶秽包括腐烂的尸体、疾病和其他一切肮脏的东西。高天原是一个极度洁净的地方，诸神是洁净的来源。而天照大神那个喜欢调皮捣蛋的弟弟，就是因为把各种乱七八糟的脏东西拿来折腾，才被诸神赶出了高天原。而他的被驱逐，导致了日本民族的诞生。这个被驱逐事件在日本的文化当中的意义，差不多就像亚当和夏娃被逐出伊甸园一样。被驱逐者到下界以后，产生了大国主命和出云系的诸神。然后天照大神的子孙——所谓的天孙民族进入出云以后，征服了大国主命和他的子孙。所以日本现在的诸神也包括天孙系和出云系这两个部分。两者的差别是很明显的，甚至在德川时代产生了两种不同的神道学。\\n\\n如果把这个过程对换到历史当中，那就可以看出，日本真正最早的原住民，在文化上跟太平洋列岛和东南亚的居民非常相似的原住民，他们基本上是祭祀民族，祭祀的主要功能就是洁净。欧洲人十九世纪到太平洋群岛的时候就惊讶地发现，在他们见过的所有民族当中，太平洋群岛的居民的清洁程度是最高的，甚至比欧洲人自己还要清洁。他们是那种一天不洗澡就要觉得浑身不舒服的角色，而且认为不够清洁是宗教上和道德上的罪恶。这跟原始日本人的特征是非常相似的。而后来建立弥生文化的那些日本人，就考古学来说，是所谓古坟时代(250~538)的中期，给日本文化的风格带来了另外一种特征：以前基本上是以祭祀为主，以后则增加了很多军事上的内容，所谓的“铜利”之类的东西。古坟时代的早期，是很少有那些具有内亚风格的物品和跟军事有关的色彩的。这就是日本历史、政治和文化的第二个二元对立：祭祀的国家和军事的国家的二元对立。后期日本的历史也是围绕着这个二元对立展开的，但是一般人没有注意到，这个二元对立其实是在日本历史的最早期就已经开始了。\\n\\n天皇本人也有他自己的二元角色。一方面，他是神的嫡系。在神道学当中，所有的日本人都是一家，都是神明的后代，但是天皇是长房和嫡系，贵族是比较接近的支系，一般的老百姓就是平民了，虽然也是神的后裔，但是是神的小宗和支系。天皇的祭祀作用无疑是第一位的，但是他也是有双重作用的，就从天皇的三大宝器就可以看出，他既是祭司的领袖，又是武士的领袖，而最早的天皇是在这两个角色之间交替转换的。天皇的二元性又产生出了国家体制的二元性。日本国家体制的二元性是一个不对等二元性。所谓“不对等”是这个意思：第一，它是二元的，二元中间，一元是名，一元是实；然后名的一元当中又会产生出小的二元，这个二元当中又是有名有实，实的二元当中又会产生出另一个小的二元，这个二元又是有名有实。名和实之间不对称，但是每一个不对称都会产生出新的不对称的二元结构。这个也是从日本历史的黎明就开始的。\\n\\n我们所知道的最早的日本，就是历史的日本，不同于以虾夷人为代表的那个土族民族的日本，是在九州的北部和本州的西部首先开始的。这时候最早出现的天皇，是在两个角色中间来回转换。一般来说是会出上几代像雄略天皇（注：456~479在位）那样武功出众的天皇，然后又会出上几代非常热爱和平、以祭司和文化提倡者为特征的天皇，两者之间不断交替。这时候的天皇还没有“天皇”的称号，在推古时代（注：推古天皇，592~628在位）以后，天皇才会得到“天皇”这样的称号，而这个称号的产生就是日本国家体制正式出现的结果。日本国家体制出现的第一个结果就是，原先由天皇一人承担的两种职能，在未来的律令制国家当中一分为二了。不过现在还不用讲到这一步，我们回过头去，首先讲历史的黎明，就是对应于古坟时代。\\n\\n古坟是一个比金字塔还要巨大的建筑物。按照主流考古学家的意见，这是日本古代氏族首领埋葬的地方，也是新任氏族首领举行就职仪式的地方。当时的日本是未来天皇家族和地方豪族构成的一个类似君合国的联邦性的实体，照律令时代的说法就是天皇和部民：天皇的家族就是雄略天皇(418~479)或者神功皇后(169~269)他们的那个家族，而部民就是后来苏我家族或者物部家族的那些部民。部民不是纯粹的血统集团，因为它包含了许多渡来人，而且联结的方式也不是真实的血统。部民和天皇之间是属人的联系，而不是属地的联系。部分原因大概是因为，当时是属于人少地多的时代，要找新的土地不是很困难，但是要得到新的人口，难度就会比较大，得到新的人口是社会得以发展的一个重要因素，而要得到新的土地，相对来说就会比较容易。\\n\\n部民有土地，但是土地对他们来说可能不是最重要的财产，他们自己的礼器、法器和生产技术才是最重要的财产。有些比较小的部就是专门从事某一个行业的，比如说制造某种工具的部或者生产某种产品的部。它们可以改变它们的地理位置，也可以分到或者得到新的土地，但是不大会改变它们的职业传统。像物部氏这个在《万叶集》中有特殊地位的部，所谓“物部大臣盾，高擎号令雄”（注：《万叶集》卷1，第76首），它最早的特点可能就是为天皇和为整个社会保存那些与武器有关的资源。“物部”实际上翻译出来的意思，就大概相当于是储藏室或者说是后勤部的意思。\\n\\n"}'));jctx.push(JSON.parse('{"id": "180603", "tag": "book", "text": "# 多与空的分歧\\n\\n买方和卖方成交后，才会有成交量。成交量的本质就是多空双方的分歧。成交量大小取决于力量较小的一方。\\n\\n1. 无量涨停：多空双方分歧小，持有者（潜在的空方）不愿意卖出，多方占绝对优势。\\n\\n2. 上涨趋势中，成交量很温和，没有放量：空方不愿意卖出，多空分歧较小，未来继续上涨的可能性较大。\\n在股市中，股票的持有者是潜在的空方，而现金持有者是潜在的多方。因为你持有股票的话，你唯一能对股价产生影响的行为就是卖出，不管你看空还是看多。反之，现金持有者对股价产生影响的行为只有买入。\\n\\n3. 上涨趋势中，成交量急剧放大：随着价格抬升，多空分歧剧烈，越来越多的持有者在卖出股票。虽然多方暂时获胜，但也许股价只是强弩之末。\\n\\n4. 下跌趋势中，成交量萎缩：买方不足，而并不是卖方无力。多空分歧小，未来继续下跌可能性大。\\n\\n5. 下跌趋势的末期，出现放量:多空分歧加大，可能下跌趋势即将结束。\\n特别注意的是，下跌初期放量并不意味着将要上涨。\\n\\n看成交量的时候，我们还要关注谁和谁发生了分歧？我们需要站在特立独行的机构一方，而不是随波逐流的散户那边。\\n要分辨谁和谁发生了分歧，最简单的就是看分歧发生的位置。\\n比如，在一轮下跌趋势的初期，此时成交量很大是坏事，因为墨守成规的大多是散户。\\n\\n但如果下跌趋势已经形成，此时市场出现分歧，即成交量变大，大多是好事。因为心灰意冷的散户从来不会带领趋势的改变。\\n\\n股谚有云：市场走坏时，地量是地狱；市场走好时，地量是天堂；市场震荡时，先缩到地量再放量是向好的信号。\\n"}'));jctx.push(JSON.parse('{"id": "180609", "tag": "protocol", "text": "# 论RESTFul特性\\n\\n产生RESTFul的领域，似乎不能涵盖API风格。要求URL以名词性单词结尾，典型的比如心跳，要作为什么样的资源呢？也许可以强作令牌，但其它需求未必有适合的名词。\\n\\n再提一点很现实的问题，浏览器的GET不能携带body。RFC7231说明payload是no semantic的，XMLHttpRequest的实现会不允许发出，PUT/POST/DELETE可以。这就导致复杂的查询请求只能用POST来实现，已然破坏了获取语义。\\n\\n再说点XHR作为本地页面，会把PUT和DELETE作为OPTION发出，内容不变，这就涉及到浏览器跨域场景中额外加入的preflight特性，POST如果Content Type改了也会遇到，GET似乎不会。\\n\\n转载一个观点，带来几个问题：\\n\\n数据定制的问题：我们的应用数据现在越来越丰富，已经不是10年前可以相比的了，也就是说数据的返回可能很丰富，非常大，而我这次可能只要其中一小部分，比如说我请求一个用户的数据/user/1，我只要他的名字和头像，而并不需要他几千个好友。传统的Rest，你可以加个Mask参数，例如/user/1?friend=false 这种方式无疑增大了前后端的代码复杂度，增加了开发的强度，而且也不够灵活，难道我要给每个字段都加个Mask？后端要依赖各种可能的Mask组合来生成查询也是个麻烦事儿，这种代码写出来也是难维护。\\n\\n多次请求的问题：类似上面提到的灵活性问题，上面说我们要少要点数据，那我们这次想多要些数据。比如说我想要一个用户的所有好友，还没完，再加上每一个好友的所有好友。这在传统Rest里面，往往我们就使用多次的请求，拿到1度好友的列表，然后写个循环，依次拿到所有2度好友。这当然不够优化，于是可能你会再设计一个专门的API去一次性拿到所有2度好友。同样的问题，这增大了前后端的代码复杂度，不够灵活，万一下次我要3度好友呢？\\n\\n异常处理的问题：这个很多朋友都会有自己的办法，有些朋友会返回特定的http response code: 4XX, 5XX，有些朋友可能会返回特定的Json消息。比如说/get/user/8527, 如果这个用户不存在，你可以返回404，你也可以返回自定义消息｛msg：“user not found”｝。这很多时候也不是问题，但我觉得如果使用更结构化的异常处理方式，应该会好些。\\n\\n发出一个请求，我不知道会得到啥：结合上面几点，其实你会发现，如果你请求一个资源，例如/user/1，你并不知道结果里具体会有什么，你可能需要查阅文档，但文档可能已经过期。你可以自己实验，但你不知道是否覆盖了全部可能的情况。这是一个很痛苦的过程。\\nPUT和DELETE也是个坑：这需要前后端框架的支持，如果不支持怎么办？其实我也不知道，我这么多年一直尽量避免使用PUT和DELETE来设计API。\\n\\n每个resource都有自己的一组end point或者说URL，这会带来管理和维护的麻烦。\\n安全问题：Rest难以避免的从URL上接受各种参数（parameter），不严格的使用Get等都会造成安全的隐患。有些问题GraphQL上也有，而且我不是这方面的专家，就不细说了。"}'));jctx.push(JSON.parse('{"id": "180612", "tag": "os", "text": "# 写文件的一些特性\\n\\n先创建一个分区，方式如下\\n\\n* `dd if=/dev/zero of=./dummy count=204800` 创建一个普通文件，用file看类型是data\\n* `mkfs.ext4 ./dummy` 会提示不是个block special device，是否要继续。选Y继续。将普通文件用ext4的方式格式化，进而可以挂载。block大小1K，每个inode管理约4个block。预留5%的block给root用户，journal占4096block。文件变成了filesystem data类型\\n* `mount ./dummy /tmp/` 将block文件挂到指定目录\\n\\n磁盘满有空间满和inode用完两种情况。inode用完主要是小文件过多导致，此时空间是还有剩余的。一般跑服务器程序不会有这么多小文件，重点关注磁盘剩余空间。\\n\\n分别用fwrite和write测试连续256次写入一些数据。\\n\\n* 4K粒度，每次用3到9us，隔20次左右会突然有次达到30us，最大44us。\\n* 8K粒度，每次用5到9us，但隔10次左右就会耗时增加，大约20略大us，最大78us。\\n* 16K粒度，开始5us，到最后几次达到20us，突变时约30us，但有一次特别大，达到25ms。\\n* 32K粒度，每次最少20us，后来到达150us。突变峰值32ms。\\n\\n当空间快占满时，写4K的速度几乎没有变化，10us左右，波动仍是30us。当写完后，每次写的时间仍然差不多，但100多次才出现2、3倍的小波动。\\n\\n用df看磁盘空间，当avail显示是0时，root仍然能继续写入一定量的数据，普通用户如果是0那就真不能写了。写空间从有到没有的一瞬间，会出现写入耗时的峰值，约是10us到10ms放大1000倍，在那之后写入速度基本就是个2到3us的恒定值。\\n\\n## df和du查看磁盘区别\\n\\n这两个命令都能统计分区大小，原理不一样。df读磁盘的superblock分析空间和文件系统属性，而du是用stat系统调用遍历每个文件或目录，最后得到总和。因此速度要慢很多。"}'));jctx.push(JSON.parse('{"id": "180615", "tag": "think", "text": "# 明朝与文官集团\\n\\n对明史的一些理解，不贴史料更多是一些论述性的东西。\\n\\n明太祖立国大杀功臣集团，对官僚集团也是异常残酷，俸禄为历朝最少，剥皮实草戴枷上堂都是只在这一朝独有的特点。也许正是这种苛法，也为后来的反噬做了铺垫吧。建文帝即位，本来是对文官集团的一次修好，但是成祖起兵与燕，凭着朵颜三卫不4年打下南京，后更大杀方孝孺十族，其一朝武力强盛，文官集团自然被压得抬不起头来。\\n\\n但是武力是很难持久的，随着天下承平，后来的统治者一定会趋于文弱，所以仁宣之治一方面是皇帝本人向平均线的回归，获得治世之誉也是文人集团对历史纠正的一次行动。\\n\\n土木堡之变是明朝早期一次大的转折，皇帝对于太监的宠信原因不详，但随着兵败，皇权失去了京畿26卫（太祖上12卫，成祖增10卫，宣宗增4卫）中21卫的控制权，仅留下锦衣卫为皇帝统领、腾骧左右卫、武骧左右卫未撤，其余归兵部辖下。\\n\\n随后皇权逐渐衰落，到弘治朝更是成了文官集团最喜爱的傀儡皇帝。其子正德帝意图再染兵权，却不幸因落水而死，这落水极大可能是文官集团的反制。\\n\\n嘉靖朝大礼议，是皇权和文官集团的一次激烈冲突，本以为扶藩王入继大统可以回到隆庆朝的风气，但嘉靖是聪明人，以炼丹为名消极抵抗，在位45年算是高寿，炼丹一说真伪我是有疑问的。在位期间发生宫女试图勒杀的奇事，有言是文官集团在背后指使，证据不足且存疑。\\n\\n万历朝的张居正算是文官中的异类，非其改革王朝恐怕早50年便要终结。"}'));jctx.push(JSON.parse('{"id": "180618", "tag": "think", "text": "# 【译】Eiffel之路\\n\\n这是一篇开放式地讨论SP和OO的文章(a free ranging discussion, the reader should view it as a promenade on the border road between SP and OO)。\\n\\n作者赞成Bottom up甚于Top down设计。不该忘记程序构造的基石，对变化的适应，对复用的追求。(The main flaw of Top down,however,is that they neglect fundamental aspects of software: the need for change, and the need for reuse )。自顶向下设计得到的是对应需求的产品，而这些无法适应未来。类似的观点在On lisp的开篇也做了浓墨重彩的描述。重点是向上。与其实现一个最好的解决办法，不如实现一个好的，但适应未来的物件。\\n\\nThe particular choice of  set facilities and of their sequencing is the least committing decision of system design; because it is bound to be the first to change, it should be made last. 反映在Eiffel上就是缺少main程序概念，只是一堆class的组合，其中一个被指定为root或执行的种子。变更root则是最简单的事。\\n\\nnot to find fault with their authors, this excise is as easy as it is vain. This discussion aims to generate light than heat.\\n\\n## OO的原则和技巧\\n\\n显式重定义类\\n\\n作者认为这是OO之所以优雅的关键。a key factor behind the elegance of OO.\\n\\n多态是种开放的机制，相比起Pascal/Ada用record来固化选择which freezes the list of choices.我倒觉得两者适用场景不同，无高下之分。\\n\\n静态类型和动态绑定相结合，静态绑定保证了至少有一种选择，而动态绑定则在有多种选择时，有机会选择最好的。\\n\\n重命名机制使得多继承的接口冲突得到了解决。\\n\\nGeneralization，尚不清楚是个什么样的方式，但对于以行来计价的程序而言，泛化的价值并不大，只有长期维护的软件才值得这么做。\\n\\nlifecycle，定义cluster model，对应的就是一个目录。把整个系统级的度量，缩小到目录级别，因而更具伸缩性。由于cluster粒度更小，呼应了前文的对变化的适应和对复用的追求。\\n\\n管理者不要人为地在设计和实现中设置屏障，他应该对最关键的部分负责。"}'));jctx.push(JSON.parse('{"id": "180621", "tag": "net", "text": "# 网络协议与socket\\n\\n## IP协议族的历史\\n\\nTCP/IP这套基于包交换理念的协议族最早构思于1974年5月，并在同年12月发布了如何控制传输的RFC675（这个时期还只是一个大的单体程序，没有做分层）。到1980年1月发布了层次化的RFC760标准，82年3月美国国防部钦定用于军事系统。随后在1982年用于SATNET，紧接着在1983年1月用于ARPANET。\\n\\nTCP和UDP只支持单一特性，出现在2000年的SCTP协议，能够同时支持严格有序传输（像TCP），部分有序传输（像per-stream）和无序传输（像UDP）。贴段说明：\\n\\n> 作为一个传输层协议，SCTP兼有TCP及UDP两者的特点。SCTP可以称为是TCP的改进协议，但他们之间仍然存在着较大的差别。\\n> 首先SCTP和TCP之间的最大区别是SCTP的连接可以是多宿主连接的，TCP则一般是单地址连接的。\\n> 在进行SCTP建立连接时，双方均可声明若干IP地址（IPv4，Ipv6或主机名）通知对方本端所有的地址。\\n> 若当前连接失效，则协议可切换到另一个地址，而不需要重新建立连接。\\n> 其次SCTP是基于消息流，而TCP则是基于字节流。\\n> 所谓基于消息流，是指发送数据和应答数据的最小单位是消息包(chunk)。一个SCTP连接（Association）同时可以支持多个流(stream)，\\n> 每个流包含一系列用户所需的消息数据(chunk)。而TCP则只能支持一个流。\\n> 在网络安全方面，SCTP增加了防止恶意攻击的措施。SCTP连接采用四次握手机制，有效的防止了类似于SYN Flooding的防范拒绝服务攻击。\\n> SCTP主要的贡献是对多重联外线路的支持，一个端点可以由多于一个IP地址组成，使得传输可在主机间或网卡间做到透明的网络容错备援。\\n\\n## Socket的历史\\n\\n光有协议还不够，必须有编程接口，Berkeley socket于1983年随着BSD4.2系统发布，但直到1989年才和AT&T达成诉讼和解并真正成为众人公认的网络编程接口。\\n\\nsocket函数声明传入3个值，依次是domain/type/protocol。域最大，然后是类型，比如连接/无连接/原始等，最后是协议种类如TCP或UDP。经过这么多年的洗礼，历史上曾经繁多的domain类型，比如X25,IPX,AppleTalk,NetBEUI不能尽数，可对如今很多人来说，只知道IP。协议也只剩下TCP或UDP这两种了。网络之外，还有红外`AF_IRDA`、蓝牙`AF_BLUETOOTH`的socket可以使用。\\n\\n现在一提到连接，就是TCP，一说数据包就是UDP，一般用如下两种方式：\\n\\n* UDP socket(AF_INET, SOCK_DGRAM, IPPROTO_UDP);\\n* TPC socket(AF_INET, SOCK_STREAM, IPPROTO_TCP);\\n\\n如果DGRAM配合TCP或反之，函数返回-1，errno显示原因是`EPROTONOSUPPORT`，表示协议不支持。还有一种`IPPROTO_UDPLITE`类型，去掉了UDP的checksum，配合音视频流的时候，尤其VoIP效果更好。"}'));jctx.push(JSON.parse('{"id": "180702", "tag": "think", "text": "# Lisp文章读后感\\n\\nRethinkDB作者的理解，从XML，C语言宏等角度作了比喻。\\n\\nXML是一种数据表示，但Ant中可以表示行为。如果把尖括号和属性(只是为了少打字的节点的一种简写，非必须的特性)做变换，最终呈现的就是Lisp的多重括号。\\n\\n用C宏和元编程做比较，日常有太多的boilerplate代码要写，宏是理所当然的选择，但如果能用host语言来无缝处理显然更好。\\n\\n## Henry G Baker的实现思路\\n\\n把Scheme转成C用到CPS变换，常见的思路是trampline，但这种方式会慢2-3倍。提出了一种永远不return，不停地让栈生长，内存分配都实现在栈上，使栈堆合一简化分配。当栈达到极限，用Cheney的GC方法进行收集。\\n\\nC语言禁止嵌套函数，目的就是阻止free变量的引用。只允许toplevel函数，free变量惟一的可能只有全局变量，编译器会维护一个环境指针，可以找到这些全局变量。Pascal允许嵌套定义函数，不清楚怎么解决。\\n\\n## 自己的体会\\n\\nsymbol是为了区分函数求值和数值表示。最初存在Mexp和Sexp两种，最后以quote的形式把Mexp给去掉了。所以只能说数据和函数同构，但不是相同。在lisp体系中完整体现了外部表示->符号->值的两次转换，没有quote符号，不过是换一种语法的lua。\\n\\nsymbol不仅能表示简单的变量，也能表示list，因此具备树状结构，而string只是字符线性排列。换句话说，string能看起来无缝地表示成symbol，部分symbol变成string后就大不相同了。让我们混淆的是自表示symbol，比如数字1，当eval作用在结构的symbol上，求值就变得统一了。\\n\\n写宏的时候，\\\\`把sexp标识成数据，而`,`则起到了局部eval的效果。\\n\\n反过来想，PHP/JSP这些语言的默认标识成数据，用了`<?`就把进行求值演算。只是PHP缺少数据和程序互操作的能力，而Lisp打通了两者的边界。\\n\\n既然函数和字符串本质都是一段二进制值序列，只是类型不同，所以计算时对这个值的eval也不同。环境是若干个frame构成的list，闭包是带env的函数，而类不过是生成对象的函数模板（let over lambda）。所以说在静态作用域出现之后，闭包和对象的界限才被打破。\\n\\nR5RS中，pair和vector是两种最基本的数据结构(procedure)。hash是一种高效的实现，但本质上可以用list实现。最简单的做法是单向链表，但是红黑树一样可以用list来表示，此时就不能以car来取值，而要针对树的list结构定义专门的函数，如果要用bucket方式，则会用到vector，元素是list。\\n\\ncontinuation在1964年由Wijingaarden首次提出，有点ES6的Promise味道，到72年广为人知。Kamal Abdali在会议上发表论文，把Algol60转为untype lambda计算。提交第一届ACM符号被拒。他在74年完成他的毕设。他的推荐人提到，将语言转为\\"pure\\" lambda，比如赋值就modeled by substitution，而不是内存，地址，存取操作。\\n\\n推演时，把k代表的符合消去，就能看出在current时间点，要做的是什么，再把参数找到，因此要做两次推导，所以显得复杂。\\n"}'));jctx.push(JSON.parse('{"id": "180706", "tag": "lang", "text": "# Shell编程说明\\n\\n## 解析顺序与转义\\n\\n和函数调用类似，一条命令行的多个部分会在不同阶段解析。先判断整行是简单命令还是复合命令，每条简单命令的参数会先解析，像glob、变量替换、重定向都是参数解析阶段的重头戏，然后作为主命令参数执行。\\n\\n单双引号可以防止转义，双引号保留$和\\\\n等扩展语义，单引号完全不做转义。但是`$\'\'`语法支持有限转义。比如$\'\\\\u4f60\'会转义成汉字\'你\'，如果没有$，则原样输出。\\n\\n## 类型\\n\\n解析时默认都是字符串类型，所以不需要特意标记双引号或单引号，有两种情况要特意加引号：1-空串，2-\\\\*之类会被扩展的特殊字符。\\n\\n在值的比较上，颇有些强类型的感觉，字符串的比较和整形的比较要用不同的操作符。\\n\\n## 变量与赋值\\n\\n赋值的`=`两端一定不能有空格。因为在sh的体系里，空格并不是可有可无的，在语法解析时扮演重要的角色，因此一定要注意。用set或readonly可以看到当前已设置的变量。\\n\\n环境变量是带有特殊属性的变量，export把变量提升到环境级别，但这个变量依然是变量，可以用unset删除，之后在环境中就没有这个变量了。用env看到的变量比set会少一些，除了前面提到的提升的变量外，set还能看到函数的定义。\\n\\n位置变量是对函数调用特有的，有个很少人知道的特性，`set -- a b c`可以实现把位置参数替换成a b c这3个值（把--后面的值，赋给隐式的$@，如果--后面无参数，则$@被清空），如果想实现追加在前或后的效果，用`set -- $@ a b c`实现追加到尾部。再配合shift命令，看起来不能修改的位置参数，也能随意操控。\\n\\n除了=还有:=表示未设置才赋值，:-未设置就替换。像这样`PS1=$\'${ local e=$?\\\\n((e)) && REPLY+=\\"$e|\\"\\\\nreturn $e\\\\n}${PWD:30} \'`表示先计算上一条命令的返回值，如果有错误就赋值给REPLY，并把当前路径重新计算一次，丢弃前30个符号。重点是return，如果没有的话，显示的路径就不会变化。这句话在非bash环境，以迂回方式实现了显示当前路径。\\n\\n等号`=`和圆括号`()`与`$`三者间构成3种不同含义的功能\\n\\n* =($xx)  把带空格的字符串赋值给左侧\\n* =$(ls)  把圆括号内的内容作为命令执行，执行结果赋值给左侧\\n* =$((1+2)) 把双圆括号内的内容作为数学计算，计算结果赋值给左侧\\n\\n值的截取和替换\\n\\n* ${#var} 取变量的长度\\n\\n* ${var:=word}\\t如果变量 var 已被删除(unset)或为空，那么返回 word，并将 var 的值设置为 word。\\n* ${var:-word}\\t和=类似，区别是但不改变 var 的值，理解为-是一半的=，所以效果也只有一半。\\n* ${var:+word}\\t和-相反，如果变量 var 被定义，那么返回 word，但不改变 var 的值。\\n* ${var:?message}\\t如果变量 var 为空或已被删除(unset)，那么将消息 message 送到标准错误输出，并停止脚本的执行。用来检测 var 是否被赋值。\\n\\n以上4种替换法，可以想像成{}内的三元表达式，比如${var:=word}可以理解为`isnull(var)?word:var`。以上几种替换法，都可以省略:，区别在于isnull的判断逻辑，变量声明为空串，有:时，空串的isnull为真，无:时，空串的isnull为假。比如`A=;${A=abc}`，因为A已经定义了，值是空串，判断为真，输出前半部分，即仍是空串。\\n\\n* ${var#expr} 从变量头开始，按匹配expr的表达式删除，支持glob。比如${var#?}表示删除第一个字符，和${var:1}是一样的。如果两个#则启用贪婪匹配\\n* ${var%expr} 从变量尾开始，按匹配expr的表达式删除，类似的%%启用贪婪。记忆窍门：删除方向取决于在$的哪侧，#在$左侧，而%在$右侧。\\n* ${var/obj/rep} 把变量中obj替换成rep，obj支持glob。只替换一次，如果要想替换多次，写作`${var//obj/rep}`\\n\\n$变量的展开和命令解析有一定的顺序，比如要执行`foo 1>/dev/null`命令，但遇到问题时，希望把输出到控制台，如果用`DF=1\\\\>/dev/null`来控制，用`foo $DF`会报错，大意是`1>/dev/null`参数无法识别。猜测是因为$DF触发了替换后，就直接被当成参数来用了，而1>/dev/null重定向需要一次特殊的解析，但被$替换后，就错过了这种解析。办法是eval \\"foo $DF\\"才能既展开变量，又能触发重定向。\\n\\n## 函数\\n\\n函数定义有`function name{}`和`name() {}`两种风格，function是bash扩展的，带上后可以不写括号（function或括号都是告诉shell，现在开始定义函数了），如果是busybox的ash，只能用不带function的格式。函数内声明变量最好用declare(字符串类型)或者`-i`(整型)，相当于是内部变量，否则就会在全局空间创建这个变量，typeset是declare的同义词。也可以用declare来看已定义的变量和函数。\\n\\n函数可以返回unsigned char，但是不能直接把返回值赋值给变量，直接在`=`后带函数名，函数名会退化成字符串。必须先执行，再用$?赋值。\\n\\n函数调用不需要括号或逗号，用foo $a \\"var\\"方式将函数和参数以空格平铺开就算执行了。\\n\\n`$*`和`$#`都表示所有参数，区别是`$*`是字符串形式，`$#`是数组形式。在传参给执行程序时没区别，遍历用`$#`会方便很多，如下\\n\\n## 数组和遍历(仅bash支持)\\n\\n用圆括号和空格定义，arr=(1 2 3 4 5)，定义后可以用arr+=(6 7)向末尾追加元素。也可以这样\\n\\n```\\ndeclare -a array\\narray[0]=\\"a\\"\\narray[1]=\\"b\\"\\narray[2]=\\"c\\"\\n```\\n\\n遍历（For循环法）：\\n\\n```\\nfor var in ${arr[@]};\\ndo\\n  echo $var\\ndone\\n```\\n\\n遍历（带数组下标）：\\n\\n```\\nfor i in \\"${!arr[@]}\\"\\ndo\\n  printf \\"%s\\\\t%s\\\\n\\" \\"$i\\" \\"${arr[$i]}\\"\\ndone\\n```\\n\\n遍历（While循环法）：\\n\\n```\\ni=0\\nwhile [ $i -lt ${#array[@]} ]\\ndo\\n  echo ${array[$i]}\\n  let i++\\ndone\\n```\\n\\n获取数组的length（数组中有几个元素） ${#array[@]} 。解释一下 @ 是数组展开，#取长度，$把值取出来。对函数内的参数而言，简化成$#就是数组长度。\\n\\n## 向函数传递数组\\n\\n由于Shell对数组的支持并不好，所以这是一个比较麻烦的问题。除了全局变量外，无完美解法。提供一个变通的思路，在调用函数前，将数组转化为字符串。在函数中，读取字符串，并且分为数组，达到目的。\\n\\n```\\nfun() {\\nlocal _arr=(`echo $1 | cut -d \\" \\" --output-delimiter=\\" \\" -f 1-`)\\nlocal _n_arr=${#_arr[@]}\\nfor((i=0;i<$_n_arr;i++));\\ndo\\n  elem=${_arr[$i]}\\n  echo \\"$i : $elem\\"\\ndone;\\n}\\n\\narray=(a b c)\\nfun \\"$(echo ${array[@]})\\"\\n```\\n\\n## 条件判断\\n\\nif语句\\n\\n```\\nif [ \\"$0\\" -eq/= \\"$1\\" ]; then\\n  statement1\\nelse\\n  statement2\\nfi\\n```\\n\\n本质上讲，if 检测的是命令的退出状态，所以then前面必须有;，用;让if做完求值。\\n\\n**在 test 中使用变量用双引号包围起来**。想判断当前文件夹为空，捕获ls的输出后，一定要用[ -n \\"$out\\" ]才正确。如果没双引号判断不准，这个过程将变量 $str1 替换的细节如下：\\n\\n* 如果 $str1 是一个正常的字符串，比如 abc123，那么替换后的效果就是test -z abc123，执行形式相当于main(\\"-z abc123\\")。test 命令后面附带的所有选项和参数会被看成一个整体，并作为实参传递进函数，正常执行。\\n* 如果 $str1 是一个空字符串，那么替换后的效果就是test -z，执行形式相当于main(\\"-z \\")，这就比较奇怪了，因为-z选项没有和参数成对出现，执行时就会出现意想不到的情况(对于-n和-z的执行结果都是错误，导致if的评估结果一样)。如果给 $str1 变量加上双引号，当 $str1 是空字符串时，test -z \\"$str1\\"就会被替换为test -z \\"\\"，调用形式就是main(\\"-z \\\\\\"\\\\\\"\\")，显然这样 main() 在分析时就不会出错了。正因为此，经常会看到x = x$var的写法，也是为解决空串问题。\\n\\nswitch格式\\n\\n```\\ncase \\"$1\\" in\\n  start)\\ncommand1\\n;;\\n  stop)\\ncommand2\\n;;\\n  *)\\ncommand\\n;;\\nesac\\n```\\n\\n前面提到过，默认的类型是变量，在条件间断时有一些有趣的现象，比如[ \\"x\\" = x$empty ]的结果是true($empty是空串)。case后的条件建议加双引号，原因同前，分支语句有没有双引号都没关系，反而想同时捕获error或errors时，必须用不加引号的error\\\\*才行，加上引号会适得其反。\\n\\n## heredoc\\n\\n第一行可以跟参数，说明EOF代表文件名\\n\\n## 执行子命令\\n\\n$()与 backquote(反引号)效果是一样的，优劣如下\\n\\n* $() bash扩展命令，可以嵌套，似乎busybox也能支持，由于带了$，可以放在=的右侧，命令的运行结果可以赋值到=左边\\n* backquote是posix规范，嵌套时内部的反引号要加转义\\n\\n另外$(())是用于整数计算，同样可以放在=右侧，不要和$()搞混了。\\n\\n## 字面值还是文件名\\n\\n严格来说，这并不是shell的特性，而是各个程序的特点，比如echo的参数当作字面量，而cat或ls的值则作为文件名来解析。有一个操作符`<()`，会把执行的结果作为文件内容，<()作为一个文件的占位符，等效于匿名文件，有点类似lambda的感觉。\\n"}'));jctx.push(JSON.parse('{"id": "180714", "tag": "lang", "text": "# Lisp的宏\\n\\n都说Lisp的宏很强大，其最大的特征仍然是字符串展开和替换，只是在替换的过程中，可以结合环境进行适合的绑定，加之程序和数据的同构，才使它异常强大。本文以s7的传统宏实现来理解宏。\\n\\n我最初最大的困惑，在一个宏定义的开始，要不要加\\\\`？以一个最简单的宏来做实验。\\n\\n```\\n1. (define-macro (print arg) (display arg))\\n2. (define-macro (print arg) `(display ,arg))\\n3. (define-macro (print arg) `(display arg))\\n```\\n\\n* 情况1，不加\\\\`。在宏展开后，就进行运算，并得到最终结果。展开的结果类型是表达式的返回值。没有\\\\`也就不能用\\\\,，参数无法求值，即使是未绑定的值，只是作为一个symbol来用，未绑定的值并不会报错。比如(print ar)会输出ar，甚至ar有定义时，也只是输出ar。这种宏展开，只是最单纯的展开，没有求值替换，和C的宏能力等价。\\n\\n* 情况2，加\\\\`。宏展开的类型就固定是pair，仅仅宏展开并不求得最终值。只有把宏展开的结果，再用于eval才能得到宏最终的结果。宏变量也会成为宏展开时环境的一部分，再传入无意义的变量会报错。\\n\\n* 情况3，加\\\\`但忘记用,求值。宏展开期间参数没有用，eval时只能从当时的全局环境找绑定，不确定性很大，有点类似动态作用域的效果，不建议用。\\n\\n所以调用宏，相当于展开宏并把展开结果绑定到一个匿名变量，展开前会把参数作为新的frame插入环境中，如果出现求值，再用eval对这个匿名绑定求值两个步骤。有时看起来加\\\\`和不加效果相同，是因为不加\\\\`相当于宏展开后已经是个self evaluating值，再做eval看不出变化罢了。要注意：加了\\\\`但没有把参数用,进行求值，则这个参数就会在eval阶段引用全局的同名参数。\\n\\n由于scheme是strict语言，只要遇到表达式就求值(但set!的第一个参数和宏的参数在宏展开前是不求值的)。"}'));jctx.push(JSON.parse('{"id": "180801", "tag": "protocol", "text": "# 电话协议的发展\\n\\n写这篇的起因，是确定了SIP协议更直观的翻译应该叫电话初始化协议。Session在IT领域是个很宽泛的词，只表示两者之间持续的一段互动。而话音业务却有很多的特殊性：\\n\\n1. 双向交互。光这一条就干趴下当前互联网界最常用的HTTP/1.1，一个只能单向通信的协议。\\n2. 兼具信令和媒体流，而且媒体流非常在意实时性。\\n\\n很多业务虽然非常复杂，难于拆解，但承载的协议却非常简单，往往HTTP就足够。但话音业务却是业务非常容易理解，也不复杂，但对协议的要求却非常得高。\\n\\n贝尔(AT&T成立的贝尔实验室就是纪念他)在1876年发明了电话，从此话音业务就渐渐成为了很大的市场。从模拟线路时代以来，以1975年为分界点，之前是In-Band协议，最后一代是SS5(Signaling System 5)，在那之后发展出了Out-Band，并最终进化并定格在SS7。直到IP时代到来，SIP协议产生于1996年。也是沿着Out-Band的脉络发展。\\n\\nIn-Band时代，只有一条承载话音的模拟线路，为了解决在语音通道上发送号码，贝尔实验室在二战后发明了MF多频技术，定义5个频率，每次同时发出两种频率，一共能组成10种组合对应十个数字。基于MF，在1963年发展出了DTMF，至今仍在使用。在那之前的电话都是转盘式拨号，之后就是现在常见的按键式拨号。MF包括R2 Signaling，R1(仅北美)，SS5。由于把控制信号在语音通道上传输，1960年代，phone phreaking发明了blue box，最大的好处可以免费打长途电话。为了防御这种攻击，加上数字技术的成熟，Out-Band开始登上历史舞台。\\n\\nSIP使用了很多HTTP和SMTP的元素，形式上也非常相似。SIP首先从Internet发展起来，并被IETF承认，H.323系也是话音业务。两者从大的功能上都服务于电话，但设计思路却并不同，且H323兼容电信网络更好，所以ITU更偏好。"}'));jctx.push(JSON.parse('{"id": "180809", "tag": "os", "text": "# 操作系统启动器的故事\\n\\n看看几大主流操作系统的启动区别。\\n\\n## 启动顺序的差异\\n\\nWindows是先认硬盘，再从硬盘分辨分区，其中系统分区中找到ntldr并引导。\\n\\nLinux要先有根文件系统，由于还没有读硬盘，必然在内存中建立根目录，有了根目录硬盘才能挂载。抛开硬盘后，有UBoot(BIOS)、内核、内存文件系统和init进程等关键元素。如果用mount命令查看，`/`的类型并不是rootfs，像我的Cent7虚拟机是xfs，Alpine则是ext4。看不到rootfs不代表没有，它确实存在过，只因为rootfs是ramfs的一个空实例，挂载后大部分系统会把硬盘上真正的文件系统替代rootfs，所以用mount就看不到了。但是在硬盘被挂载前，rootfs基于的ramfs使内核有栖身之处，显然是有意义的。\\n\\nLinux启动的三大部分，boot/kernel/rootfs，常见组合是BIOS把控制权交给grub，grub显示启动菜单，并把用户选择的kernel即vmlinuz文件加载到内存。内核自带虚拟文件系统，由于只管调度并提供调用接口，要让用户使用，必须在内存中安装根目录，initramfs.img就负责干这个。它的前身叫initrd，两者的区别是initrd把内存模拟成硬盘，制作时要关联到loop back device，再mount后才能找到init。而ramfs方案直接把内存模拟成文件系统，一步到位。把initramfs.img解压到根目录（又叫rootfs），这个initramfs.img其实是个`gzip+cpio`的文件，用gunzip加cpio -idv <file的方式能看到内容，包含/bin/,/usr/这些文件夹。开始是只读，只要挂载完校验完整性通过，才会改成可写方式。加载完并有了init后，就可以彻底进入用户态加载各种服务了。\\n\\n## Unix系的init\\n\\n### Linux\\n\\ninit是最初启动的程序，必然是静态程序，用ldd不会看到有关联的动态库。其它的程序都是由它fork之后运行的。Linux的0号进程是Idle，不过ps不会显示它。传统Unix系PID为1的程序是/sbin/init，也可以是个指向其它程序的软链接，到了Linux则支持向内核传参来改变启动程序。随着开机启动服务越来越多，出于对速度的追求,init也演化出了很多派别（我的cent7启动耗时为2.098s kernel + 7.568s initrd + 15.753s userspace 总计 25.420s）。wiki把归于Service Management，有两大类：\\n\\n1. 可移植实现：目前还活跃开发的只有OpenRC（Gentoo主导），其它runit和initng似乎已经停止很久了。\\n2. 系统专属实现：Linux有Systemd和Upstart，Mac是lauchd\\n\\nVoid使用runit\\n\\ninit指向runit-init，负责启动器，还自带简单的一套sv/runsv服务管理程序。\\n\\nAlpine 使用OpenRC\\n\\n> init是指向busybox的软链接，而后由openrc-run程序引导，可见两者是分离的，是为可移植。/etc/init.d/目录下平铺着所有的服务，3.7版的AlpineLinux，会偶现启动时chrony非常耗时问题，要禁止chronyd，直接把文件移走就可以了。程序运行稳定后，用pgrep无法找出openrc相关的进程，不确定是不是运行完就退出了。\\n\\nCentOS 7.x 使用Systemd。（6.x及以前使用传统的/sbin/init）\\n\\n> init指向/usr/lib/systemd/systemd，同时也控制启动服务的顺序和依赖关系，是结合式的。而/etc/init.d/目录指向rc.d/init.d，又根据runlevel分了数个目录，要复杂得多。\\n\\nPID从2开始的前几个程序都是kthreadd/ksoftirqd/kworker/migration/md/watchdog/crypto等，都是Linux必须要启动的服务。\\n\\nLinux和FreeBSD的ps都会把无法获取args的进程（通常是内核线程）标记上方括号，用ps auxfc可以看到这些进程间的父子关系。而OpenBSD不会显示带括号的进程。\\n\\n### OpenBSD\\n\\nBSD系的init都是独立的可执行程序，大小分别是1M和300K，启动脚本都在/etc/rc.d，没看到init.d。但也有不同，比如FreeBSD，PID为0的进程叫kernel，Idle是11号，2之后的进程名也是内核进程，而OpenBSD却看不到2之后的进程。\\n\\nBSD风格的init和传统的Unix风格或者叫SysV不一样，最显式的差异在于读的文件是/etc/rc文件，传统的SysV读取/etc/inittab文件，现在Linux中用的比较多的是systemd方式，不过这个程序使用了cgroup和fanotify方式，导致无法迁移到BSD系统。\\n\\n程序只有一个C语言文件，非常干净。真正业务开始是个非常有趣的循环\\n\\n```\\ntransition(state_t s)\\n{\\n\\tfor (;;)\\n\\t\\ts = (*state_funcs[s])();\\n}\\n```\\n\\n通过给定一个s的初始值，确定一个初始函数，通过这个函数返回下一个状态，又会进入下一个函数，如果反复恰如完整的状态机在运转。\\n\\n默认的循环共有三重，`runcom->read_ttys->multi_user`，第一个runcom就是读入/etc/rc脚本，这也是rc这个文件名的由来。\\n\\n最后一个multiuser阶段就是做了waitpid操作,对每个waitpid返回的进程号，会尝试从RB树中找对应的session，因为unix有远程登陆概念，登陆的上岸点则是tty，每次的登陆就是一个session。如果没有就结束了，如果还有session需要清空会话的日志并从RB树中去掉这个节点。login/logout是BSD的系统函数，会操作/var/log/wtmp和var/run/utmp文件，并记录登陆的用户名。还会用到utmp.h的头文件，根据man的描述，是用于login record。正因为有这些文件，用who命令才能实现。\\n\\ninit的程序体现了很多login/logout/tty的概念，因为Unix在出现的时代就是用于远程访问的，只是当时访问的介质不是网线，而是电传打字的设备。因为只是介质不同，和网络访问的概念是相通的。程序本身是静态的，一旦运行起来就要归属到session，通过login/logout来创建和销毁session。常规的login一定是由物理硬件发起，这个硬件就被抽象成tty。除了远程登陆的session，也存在fork出的程序，这些程序可以在同一个session，也可以另起一个会话，如果要新建会话，就用setsid()函数。init程序所属的会话，并没有谁主动来login，只能通过setlogin(\\"root\\")方式手动指定会话所属用户。每个会话只能有一个login name。"}'));jctx.push(JSON.parse('{"id": "180813", "tag": "net", "text": "# UDP和相关操作\\n\\nTCP属于有连接协议，所以一定需要有bind操作。服务端显式bind，客户端在connect时会内OS隐式bind。一直不确定UDP要不要bind，正好有同事问起组播和单播如果监听同一个端口，如何区分。查看代码才知道UDP的bind在这种场景就有意义了。\\n\\n先说广播，把0xFFFFFFFF通过bind和UDP的socket绑定，最好再用setsockopt(SOL_SOCKET, SO_BROADCAST)配置。\\n\\n如果是组播的D类地址段，范围是[0xE0000000, 0xF0000000)，在这个区间内，绑定后用setsockopt(IPPROTO_IP, IP_ADD_MEMBERSHIP)方式加到组播组。\\n\\n单播的socket和网卡的IP地址用bind关联。\\n\\n如果是一张网卡要同时收UDP的单播和组播，对这两个socket都做一次setsockopt(SOL_SOCKET, SO_BINDTODEVICE)。把地址和eth0这样的网卡名关联上。\\n\\n顺便再谈谈选项分类。可以看到有SOL_XXX和IPPROTO_XXX这两大分类。上面没有列出的，还有SOL_IP、IPPROTO_TCP等。SOL的层级比IP和TCP都高，广播数据直到UDP才会被处理，和在IP层处理的组播不同，因此选项前缀也不一样。\\n\\n广播的地址有4种，工作中我只用到了全为1的受限广播，只有主机号全为1的广播地址没有接触过。"}'));jctx.push(JSON.parse('{"id": "180819", "tag": "tool", "text": "# 消息队列理解\\n\\n为了实现观察者模式提供的一种中间件，串接起生产者和消费者两端。不同的场景要选择合适的实现。RabbitMQ有6种工作模式，也有Exchange,Binding,Queue,RouteKey等很多概念，适用于业务复杂场景。Kafka只有topic和partition，因此吞吐量大，但业务就需要使用者手动处理。\\n\\n## RabbitMQ的模式\\n\\n6种模式分别为Hello world、Work queues（工作队列）、Publish/Subscribe（发布订阅）、Routing（路由）、Topics（主题）、RPC（远程调用）。除了RPC模式外，其余的模式都是从简单的使用到更为灵活的使用。\\n\\nHello world和Work queues比较简。消费者声明一个队列（Queue）才能收消息，增加队列一方面可以把多个消费者合并，另外能多些特性，比如消息要不要持久化，要不要做排它性。\\n\\n最简单的投递，有了Queue消息就能贯通了。这种模式的Q和设备侧的事件定义很像，生产者指明要发给这个Q，不关心谁来收，需要这个Q的消费者去响应并做逻辑就行。\\n\\nPublish/Subscribe、Routing、Topics这几个模式都依赖Exchange，源于RabbitMQ遵循的AMQP规范不允许直接向Q投递，而引入的概念。Exchange有3种类型fanout,direct,topic,header，很像UDP的广播，单播，组播。\\n\\n* Publish/Subscribe模式: 对应fanout型exchange。最粗暴，全发送\\n* Routing模式: 对应direct型exchange，必须严格匹配，简单的分类器\\n* Topics模式: 对应topic型exchange，可以用通配符模糊地表示关联关系\\n\\n前两种直接发给Q的模式，用了名字是空串\\"\\"的一个特殊Exchange，后三种则必须指定Exchange名字。\\n\\nBinding是很简单的，虽然存在但很无脑。只有通配匹配，绑定的算法才变得重要起来。绑定是Exchange给消费者的提示，生产者需要给出RouteKey。所以即使同一个Exchange，投递的消费者可以千差万别，它的数量级也是最少的。\\n\\n## RabbitMQ使用\\n\\n默认启动会有epmd监听4369端口和beam的25672。启用web插件后，只能用guest用户，再添加admin后，就能用15672端口进入web控制台。\\n\\n```\\nrabbitmq-plugins enable rabbitmq_management\\nrabbitmq-server\\nrabbitmqctl add_user admin admin\\nrabbitmqctl set_user_tags admin administrator\\nrabbitmqctl set_permissions -p \\"/\\" admin \\".*\\" \\".*\\" \\".*\\"\\nrabbitmqctl shutdown\\n```\\n\\n## RabbitMQ和Kafka的比较\\n\\nRabbitMQ的劣势\\n\\n1. 在消息投递时必须由客户端指明IP，这就给无感横向扩展带来不便。\\n2. 默认没有分区机制，虽然官方有个sharding插件，但似乎用得不多\\n3. 只有主备，类似副本机制\\n\\nKafka的劣势\\n\\n1. 由于Kafka每条消息都会写磁盘，当topic数量变多后，并发多进程的随机写入会导致性能会急剧下降，RabbitMQ大多数情况把消息保存在内存，不会有此问题\\n\\n为了从MQ迁移到kafka，在MQ协议中引入了分区概念。\\n"}'));jctx.push(JSON.parse('{"id": "180829", "tag": "tool", "text": "# 一次反汇编的崩溃定位\\n\\n将设备搜索功能从子节点迁移到管理节点，虽然程序没有变动，但会出现启动就崩溃问题，重启后不会崩溃。\\n\\nGDB跟踪发现是死在第三方的so库，直观的解释是free的内存被破坏。可是重启后没问题，开始就没往这方面去想。第二天，同事说怀疑是否网卡数量过多引起，原来子节点没有很多网卡，重启是因为主备切换导致虚网卡消失，所以就不会重启了。加上这个第三方库做设备搜索工作，确实很有可能在绑定网卡时出了什么问题。\\n\\n于是开始研究反汇编代码，发现存在一个大循环，跳转前有`addw 0x01, -2(%rbp);cmpq 0x00 -10(%rbp);`。后一句cmpq还原成代码，是`p==NULL`，前一句则是计数，等循环结束就能知道一共有多少张网卡。看来很可能是由于没有控制好网卡上限，导致内存溢出。\\n\\n再回到函数开头，查阅了x64的汇编调用规则，第一个参数在rdi，第二个参数在rsi，第三个参数rdx（展开说一下，这个规则随着位数、编译器不同，VC用的寄存器就不同，而32位默认全放在堆栈，除非开启fastcall模式才会用寄存器传参）。可以看到rdi被放了一段内存。之后又高了另一个so的库也分配了内存，去掉malloc在分配前的16字节cookie（取决于实现），发现刚好是挨着的。在最后执行free的时候，cookie部分被前面所写坏，导致free时abort退出。最后又找到了进入函数前的hardcode的分配0x75C内存的new操作，基本可以定论不换so的情况下，只能依赖限制网卡数来规避问题了。\\n\\n限于汇编能力不足，具体是哪一行写坏内存仍不可考，但利用这些点，算是把问题给交代了。"}'));jctx.push(JSON.parse('{"id": "180901", "tag": "protocol", "text": "# GB28181理解\\n\\n全称由3个词组合，安全防范，视频监控，联网系统。视频监控领域的通用标准，用了信令SIP和媒体RTP/RTCP的模型。选用SIP是有多重原因\\n\\n1. 视频监控有大量的视频数据要传输，而建立起这样一个视频会话，最现成的就是RTSP或者电话的SIP协议。\\n2. RTSP虽然是专为视频业务设计的协议，却基于一个前提，必须知道流源的地址。在中心化分发场景，多个客户端向一个流源请求视频是非常合适的。但是视频监控反过来，往往只有很少的客户端，却有大量潜在的摄像头，因此RTSP出局。\\n3. 要收集散落在各处的摄像头，需要向一个中心节点主动报备，恰巧SIP就有这个功能。\\n\\n综上三点，SIP就奠定了在整个体系中的基础地位。\\n\\n核心的SIP指令只有6条，INVITE、BYE、REGISTER、CANCEL、ACK、OPTIONS，相比H323简单很多。但SIP毕竟是用于建立电话的协议，视频监控还有很多的需求，好在有INFO和MESSAGE两个扩展，有了信令控制的基础，INFO具备改变会话的能力，典型应用是DTMF，即在电话中点击数字，所以用于回放控制是很自然的。而MESSAGE并不构成一次SIP的dialog，所以用在设备控制上，类似短连接语义。\\n\\n除了请求应答模型，SIP还支持SUBSCRIBE/NOTIFY/PUBLISH模型，可以推送消息，甚至还有基于SIP的IM协议。\\n\\n控制协议分请求和应答，请求有3种，Control, Query, Notify。应答是Response。体现在XML的最外层结构。\\n\\n统一编码有A和B两种规范，前者20位，后者18位。我只见过A。编码即能表示设备又能表示用户。存储设备被称为前端主设备，而相机被称为前端外围设备。\\n\\n目录概念解释\\n\\n分设备目录和文件目录。设备目录包含3种:设备，区域，系统。文件只有1种:录像。每种都用一个complexType定义对象语义。业务上经常会订阅目录，发生变化后下级推送。\\n\\n查录像协议很有特点，一个请求会有若干次的返回。一方面，MESSAGE请求本身就有应答，另外UDP受限于MTU无法携带大量消息，必须要分段传输。大华网关实现查目录，默认一次返回1条，可以配置一次返回5条。"}'));jctx.push(JSON.parse('{"id": "180902", "tag": "think", "text": "# 伊斯兰国家的传承\\n\\n世说穆罕默德雄才伟略，不得观。但死后四大哈里发不得善终者二，并不稳固。按时间线共有3个大的王朝分别是：\\n\\n1. 倭马亚王朝，白衣大食，逊尼派，661-750。\\n2. 阿拔斯王朝，黑衣大食，750-1258。都巴格达。\\n3. 奥斯曼帝国，1299-1922。都伊斯坦布尔\\n\\n另有两个支线王朝：\\n\\n1. 法蒂玛王朝，绿衣大食，什叶派，909-1171。都开罗\\n2. 阿尤布王朝，1171-1250。都开罗\\n\\n倭马亚立足叙利亚享国近百年，却幅员辽阔。有名的普瓦捷之战便在此朝，此战后扩张也被终止了。由于朝内反对势力太盛，终被被阿拔斯朝取代，地处伊朗，官僚集团大量波斯化。稍晚一点有法蒂玛王朝，但只是一方割据，未能占据正朔。至元朝阿拔斯为旭烈兀(拖雷子)所灭，稍后就进入了最强盛的奥斯曼帝国。\\n\\n从蒙古灭亡阿拔斯王朝后，传统上的阿拉伯帝国就不复存在了。奥斯曼和其它几个阿拉伯帝国不同，它是消灭了东罗马帝国后，定都于君士坦丁堡，且以东罗马帝国的继承人自居。随后突厥人更是在文件上融合了伊斯兰教，但仍以教徒自居。"}'));jctx.push(JSON.parse('{"id": "180905", "tag": "lang", "text": "# 词法语法之后\\n\\n以前写过3篇词法语法工具使用的记录，对完整的编译过程来说，后面的代码生成和执行却一直忽略了。\\n\\n如果只是写计算器，到语法生成勉强还够用。但要想支持分支，函数定义、调用等，\\n复杂性就真正体现出来了。\\n\\n为了引入函数，必须把解析分为定义态和执行态。从函数定义开始到结束，要做代码生成。其它情况则取指令执行，是两个完全不同的处理，可以加标志位控制，也可以决定是否允许嵌套函数定义，简单起见可以先禁止。\\n\\n要保存函数定义，就要有一套指令码和虚拟机来执行。指令可以不必多，但基本的Load/Save/Cmp/Jmp/Call是不可少的。从Load/Save又可以分为基于栈和基于寄存器两大流派。\\n\\n构建指令集，先确定用定长或变长，基于栈还是寄存器。以定长寄存器为例：将若干bit位解码为指令，指令一旦确定，剩下bit位的操作数的解析方式就随之确定了。不同指令需要的数是不同的，1到3个都有可能，所以操作数的解析并不固定。使用拉掩码方式分别提取对应位数构成数据。\\n\\n指令集除了表示做什么外，寄存器和立即数都是用索引号代替，所有的寄存器用栈形式分配，立即数要有常量池来存储和索引。如果不允许函数内嵌套定义函数，指令集+常量池这种模式就足以表示了。如果允许嵌套定义，要函数原型内递归地存储，难的是要处理upvalue。反观C语言，既不允许嵌套定义，最外层只能是main函数为入口，实现就相对简单而纯粹了。\\n\\n有了指令集，还必须记住当前的指令执行位置，IP指针，在Lua中用savedpc变量保存。取指令用`*(savedpc++)`，执行当前指令时，IP指针已经向前走了一步。IP指针和函数在全局栈上的位置共同构成一个函数的必备元素。\\n\\n指令通常顺序执行，加上比较和跳转后，就能实现分支和循环，跳转步数需要一些技巧获得。\\n\\n指令，变量环境，常量环境，这3者构成函数原型的全部，运行时再将常量加载到变量。也可以将常量全部做成伪变量，只是写代码会非常繁琐。"}'));jctx.push(JSON.parse('{"id": "180910", "tag": "design", "text": "# 用数组实现链表\\n\\n为每个链表元素分配一次空间对有洁癖的我来说太过累赘，更倾向用数组的连续性来得到这个特性。\\n\\n直到看到s9的实现，才明白该其中决窍，引入一个和真实元素等长的标记可用数组，我称之为canuse，下标表示当前数组已使用或分配了多少个，再用一个整型值记录当前used个数。多出的canuse数组，类型选项uin8的话，可以将空间占用压到最少，代价就是每个块只有255，如果不够换uint16绰绰有余了。\\n\\n初始化用canuse[i]=i。每次增加元素，只要used没到上限，自增后从对应canuse位置取得真正可用块。释放则反过来，把分配块的下标，放在canuse[used]位置，再将used减1，不需要释放内存。\\n\\n上面的释放过程结束后，canuse数组元素内容从初始的顺序变乱序，但元素不会重复。这也要求决不允许同一个元素释放两次，目前没有做内部保护，要在外面清理。\\n\\n另一点稍微不方便的是，分配出去的块，必须要记住在数组的什么位置，否则归还时无法建立正确的映射。"}'));jctx.push(JSON.parse('{"id": "180920", "tag": "lang", "text": "# 指针的三种面貌\\n\\n起因是同事发了一段C语言的汇编代码，理解不透，代码如下\\n\\n```\\nifAddrSt = ifAddrSt->ifa_next;\\n\\n0x00000000004006a5 <+221>:  mov  -0x10(%rbp),%rax\\n0x00000000004006a9 <+225>:  mov  (%rax),%rax\\n0x00000000004006ac <+228>:  mov  %rax,-0x10(%rbp)\\n```\\n\\n能看出把rbp-10位置上的值做了一通操作后赋值回自身，但是为什么是两次取地址非常迷惑。\\n\\n在分析汇编之前，先想明白指针的几种表示和对应的汇编形式。先说普通的变量，比如最简单的`int i=1;`这条语句，i就有两种形式，i和&i。&i是i这个变量的地址，对应rbp加减一定的偏移量。实际代码中很少会用到&i，大多数时候都是用i，也就是&i地址存放的值，这个值对应的汇编就是(%rbp)。\\n\\n说完普通变量，再看指针。指针除了上述两种形式，还多了提领`*`操作。因此对于`char* p;`，rbp就对应&p，(rbp)才是p。`p->next`的操作可以等价为`*p.next`，因此才有了刚才汇编中的前两句，对rbp做了两次取址操作就好理解了。\\n\\n1. 第一句(%rbp)将ifAddrSt放到%rax寄存器\\n2. 第二句等效的C语言是`*ifAddrSt->offset 0`，所以(%rax)就够了，不需要偏移\\n3. 第三句将值重新写回ifAddrSt，此时不用提领%rax，值写入(%rbp)。"}'));jctx.push(JSON.parse('{"id": "180923", "tag": "lang", "text": "# 自制编程语言的历程\\n\\n尽管还存在缺陷，即便如此从9月16号开始重新启程，已经比过往强得太多。大约从2009年便有实现一门语言的想法，如今看到希望，虽然很简陋，却也算原型完备，令心结解开，不再纠结于要不要学习新的语言。\\n\\n词法和语法都是工具生成，不在此文罗列，主要从归约出生成语法后的事。\\n\\n## 转译到字节码\\n\\n除了从源码执行，还可以从字节码执行，而源码又能输出成字节码（反之也可以，但那更多是破解用）。字节码通常不能无脑序列化，会有个非常简单的重组过程，三者构成如下关系。\\n\\n```\\nSource-----|\\n         VM(IR)---Run\\nSerial-----|\\n```\\n\\n最初是雄心勃勃想按二进制定长方式指令，但发现融合常量池的实现周期太长，为了验证可行性，还是全部用可打印字符，便于调试。格式很简洁，一字节指令加上用逗号分割的指令数，最后用分号结尾。如果是顺序指令，将每条连在一起就构成完整指令。\\n\\n顺序其实不值一提，函数、分支、循环才是三个最难的部分。理论上循环可以由分支和尾调用替代，从字节码实现看，确有相似性。\\n\\n先说函数，这是十年前最让我头疼的难关，甚至在想明白用字节码做为间接层后，仍为返回值该放哪里思考良久。函数必不可少的成分有二，指令和环境。指令永远不变而环境可链表，递归处理时要做好保护和复原。指令可以持久化而环境不需要，这两个阶段用不同的结构会更好，而在传递中指令最好能做到所有权转移。\\n\\n环境除了保存局部变量，还要保存入参。每次调用相当于两个环境间的数据复制。我现在的做法，得到指令码还捆绑一个环境的做法是错误的。\\n\\n## 转译到另一种语言\\n\\n业界对此有专门的叫法transpiler，比较难的点是对嵌套结构的处理，自然地统一用cons/car/cdr方式来表达，在实现时为求简单，把值也保存在cons。cons看似简单，其实可以表示树和链表结构（不使用car就是单链表）。\\n\\nC语言在表示链表移动时，要分配内存和链表移动放一起，否则很容易引起内存分配了，但链表没有指向新分配的内存。"}'));jctx.push(JSON.parse('{"id": "181021", "tag": "web", "text": "# 【转】对PHP的分析\\n\\n我不考虑可以用封装库解决的问题，比如不考虑 JSON api，in_array 默认 == 等等\\n我不考虑各种 VM 实现的问题，比如 C 扩展常驻内存\\n\\n我不考虑 PHP 文档的问题，不考虑 PHP 历史上的问题，比如 5.3 中不能 parse $cb()()\\n我不考虑 parser 的报错信息难读问题\\n\\n文章内容目录：\\n\\n* FP：set! 和 defun 是不一样的，但是 PHP 连 set! 都不如\\n* MP: MP 不是 toString 或者 any -> String， 而是 Expr -> Expr 和 Expr -> Q\\n* OO: The big idea is messaging.\\n\\neechen 说我们可以使用 $func来在 PHP 中实现 FP，但是这是不可行的。让我们考虑最简单的 fib\\n```\\n$fib = function ($x) use ($fib) {\\n  if ($x == 0) {\\n    return 1;\\n  }\\n  return $x* call_user_func_array($fib, [$x-1]);\\n};\\nvar_dump($fibs(10));\\n或者\\n\\n$fib = function ($x) {\\n  if ($x == 0) {\\n    return 1;\\n  }\\n  return $x* call_user_func_array($fib, [$x-1]);\\n};\\nvar_dump($fibs(10));\\n```\\n二者皆会报错，第一个说找不到 $fib，第二个说 $fib 是没有定义的 NULL。\\n\\n继而我们猜测这只是 PHP 解释器的一个小 bug，我们只需要把 closure 的位置在 AST 往下压一层之后 use 就能找到了，比如\\n```\\nfunction id($x) {return $x;)\\n$fib = id(function ($x) use ($fib) {\\n  if ($x == 0) {\\n    return 1;\\n  }\\n  return $x* call_user_func_array($fib, [$x-1]);\\n});\\nvar_dump($fibs(10));\\n```\\n依然是找不到 $fib。\\n\\n\\n可能这时候我们只是认为 use 之前需要声明，只是一个 php 解释器上实现的一个小 bug，比如\\n```\\n$fib = NULL;\\n$fib = function ($x) use ($fib) {\\n  if ($x == 0) {\\n    return 1;\\n  }\\n  return $x* call_user_func_array($fib, [$x-1]);\\n};\\nvar_dump($fibs(10));\\n```\\n结果是 $fib 在 closure 中对应的值 NULL，无法被访问。\\n\\n这就是我们说 PHP 既不支持函数作为第一成员又没有 scope 的原因。scope 是作用域内 symbol 和 value 的绑定。PHP 并不存在一个正常的讲上层 scope 的某个 symbol 映射放到 closure 中的方法，PHP 的所谓的 use 只是即时地在 closure 中插入一个 $fib = NULL ，而并非是将对 $fib 的访问转移到上层 scope 的访问中。\\n\\n简单来讲，**PHP 所谓的 scope 不是 scope，而只是一个解释求值的 barrier，你不可能访问上层 scope 的 symbol。而 php 的 closure 也不是 closure，php 的 closure 只能绑定 value 而不能绑定 symbol。**\\n\\n如果说要强行 $func 来实现自指递归或者互指递归也不是不可以，那么你需要这么写\\n```\\n$scope = [];\\n$scope[\'fib\'] = function ($x) use ($scope) {\\n  if ($x == 0) {\\n    return 1;\\n  }\\n  return $x* call_user_func_array($scope[\'fib\'], [$x-1]);\\n};\\n$fib = $scope[\'fib\'];\\n\\n或者更加规范的，默认使用的 scope 入口和 defun\\n\\nfunction createDefun($scope) {\\n   return function($fname, $definition) use ($scope) {\\n       $scope[$fname] = function () use ($scope, $fname, $definition) {\\n          $args = func_get_args();\\n          $scope[$fname] = call_user_func_array($definition, array_merge([$scope], $args));\\n       };\\n   };\\n};\\n\\n$sp = [];\\n$defun = createDefun($sp);\\n$defun(\'fib\', function($scope, $x) {\\n  if ($x == 0) {\\n    return 1;\\n  }\\n  return $x* call_user_func_array($scope[\'fib\'], [$x-1]);\\n});\\n$fib = $sp[\'fib\'];\\n```\\n我只是觉得，「一个语言支持 FP 范式」和「一个语言需要自行实现 scope 然后就可以通过手动注入 scope 然后就可以 FP 了」应该是完全不同的两个意思吧？\\n\\n这也是我们说 「PHP 不是一门支持 FP 的语言」时和说「JS，Py 等等可以写 FP，但是毕竟不是一门 FP 语言」的不同。如果我们有其他语言的经验，（无论这语言是 Py2/Py3，JS，Perl5，还是利用 operation() 当作 function 的旧 CPP，甚至是他喵的 MatLab），我们可以看到他们访问上层 scope 中的 symbol 是自然而然的；而 PHP 我们要么自己实现一个 scope 和 defun，要么就是使用 array(__NAMESPACE__ . \'\\\\\' . $className, $funcName) 和 static 这种并非设计为 FP 的 ugly hack。所以我们可以安全地宣称，PHP 是不支持 FP 的。\\n\\nPS：在本节末尾指出来一下， eechen 原文误以为「PHP 变量可以绑定类」，实际上 PHP 变量只能被赋值为类的实例而不能绑定类。这种不能绑定类特性的缺乏导致了没法实现 immutable-js BaseRecord = Record({...}) 之类的基于函数的类派生，也对实现利用 cache 来加速 immutable 变量的生成增添了很多不必要的 boilerplate code\\n\\nMP: MP 不是 toString 或者 any -> String， 而是 Expr -> Expr 和 Expr -> Q\\n\\n一个语言是否具有 MP 的能力并不是其是否有一个叫做 XXXRefection 的方法，实际上 PHP 的 reflection 只是一系列拿到源码的 toString；这类方法在其他语言中也是常见，比如 ES3 时代就有了 Function.prototype.toString这样的方法\\n```\\nfunction hasContent() {/*\\n    Line 1\\n    Line 2\\n    Line 3\\n  */}\\nvar content = hasContent.toString.split(\'\\\\n\').slice(1, -1).join(\'\\\\n\')\\n```\\n如果我说 ES3 时代就实现了 MP，我觉得我会被 JSer 打死。甚至 ES5 时代 styled-component 通过了 Tagged templates 实现了 JS 中解析运行 CSS，JSers 也没有吹什么 「JS 是一个支持了 MP」的语言（虽然我明年准备看看能不能借用 tagged template 可以访问 js obj 的特性来实现一些简单的可访问 JS 变量的 DSL，当然这只能说能有一点 MP 技巧；和真正利用 MP 做 code gen 离得很远）\\n\\n\\nMP 是利用已知代码进行 code generaation 的手段。比如 Julia 如果不想多次写 dimension 可以（免责声明：自转行后大概有一年没写 Julia 了，所以下面可能会有简单的语法错误或者漏写 global 或者 quote）\\n\\nconst c = @cmm( squeeze(sum(mean(a,3),2))) ## cmm stands for common math macros\\n\\n扩展成如下代码以避免写两次 dimension\\n\\nconst c = squeeze(sum(mean(a,3),2)), (2,3))\\n\\n同样我们可以轻松地在处理 NaN 的时候利用 macro 来做替换\\n\\nconst c = @cmm( periodic(mean(x,2, isNaN=false)))\\n\\n替换成这样的形式，也就是我们在没有提供 isNaN 接口的时候，一定程度上可以类似用写 R 的方式处理数据\\n\\nconst c =  periodic(nonNaNMean(x,2))\\n\\n甚至可以模拟一下 typeclass，下面是利用 MP 将 svd, eof, 等等方法从 Array{Float, 2} 扩展到 Array{Float64, n} 的一种 macro 示例\\n\\n```\\nconst (eofs, pcs) = fuck2D(\\n  quote\\n    global SST // SST is a 3D array of lat * lon * time\\n    describe(SST, 3) // 3 is the timal dimension;\\n    return svd(SST)\\n  end\\n)\\n这将扩展成现将 SST 转成 2D array， 然后将 分析后的 1D array 转回 2D 的方法\\n\\nconst (eofs, pcs) = do\\n   global SST\\n   SST_config_#1 = create_Dconfig({timal_dims: 3})\\n   (SST2D_#1, from_1D_to_sp, from_1D_to_timal) = decompose(SST, SST_config_#1);\\n   (eofs1D_#1,pc1D_#1) = svd(SST2D_#1)\\n   eofs_#1 = intercept_1D(eofs1D_#1, from_1D_to_sp)\\n   pcs_#1  = intercept_1D(pcs1D_#1, from_1D_to_timal)\\n   return (eofs_#1, pcs_#1)\\nend\\n```\\n\\n这类宏生成代码节省了大量手动写 adapter 的时间，实现了类似 type class 的效果。另外一类常用的 MP 做法是将任何一个需要埋点的函数\\n```\\nfunction func(a,b,c) {\\n     return func(a\', b\', c\')\\n}\\n这类代码转换成类似\\n\\nfunction func_effect(f, a, b, c) {\\n      call_effect(f, a\', b\', c\')\\n}\\n```\\n这样我们可以在 call_effect 中使用统一的 effect 处理和上下文传递等等。\\n\\n首先PHPer 看不懂 MP 但是又说 PHP 支持 MP 难道是我的错么？\\n这里只是展现一下为什么 MP 的实践需要 AST；在这类需求中，文本替换然后 eval 显然是不安全而且不够灵活的。不在 AST 上 walk 一下还能怎么办呢，难道拿头锤 regex 做替换？\\n\\n一个 PHPer 可能会争论说其实这类 MP 实践在 PHP 中是可以做到的；然后他可能会举出类似于 Roave/BetterReflection这样的库；显然，在看过这种库之后，即使不懂 MP 也能发现很明显的风险：\\n\\n其 parser 库并非是 php 解释器自己的 parser，而是另一种 PHP 实现的 https://github.com/nikic/PHP-Parser ；也就是任何 PHP-Parser 和 php 解释器 parser 的不一致都会影响到结果 （而且难以 debug）\\nPHP 并没有 eval(Expr) 的手段，对于变换后的 AST，需要使用 PHP-Parser 来 write string，然后执行转写的 string。这不仅仅依赖于 PHP-parser 的正确性，而且任何 php 的报错都会在 eval 这一行，eval（string） 永远是危险的呀\\n\\n而且不可避免的，这样的 parser 实践还会导致所有含有副作用的语言中 MP 共同要面对的问题：副作用跟踪。考虑到我们在某个文件中元编程两次\\n\\neval(AST2String(expr1))\\n\\neval(AST2String(expr2))\\n\\n如果在 expr1 中含有了\\n\\nfunction foo {...}\\nbar_effect = ...；\\n然后 expr2 含有了\\n\\nfunction foo {...}\\nbar_effect = ...;\\n然后 expr1 的部分结果就有被 expr2 覆盖的风险。\\n\\n在 Julia 中，macroexpand 直接会分析上下文并且在变量后面加上 `_#number` 这样的后缀防止覆写变量；而且很多 lisp 系语言中，eval 本身是 lexical scope 下在一个新的 scope 进行的。\\n\\nOOP：三原则或者四圣谛只是 90 年代类似 Java 语言对于 OOP 的一种实现手段而已\\n\\n本来我以为我这里不需要解释一下 extends 的问题，可以直接讨论层次复杂度和静态检查的关系。我发现我还是必须引用一下 Alan Kay 的名言 [The big idea is \\"messaging\\"](http://wiki.c2.com/?AlanKayOnMessaging)\\n\\n只要我们能够实现层次划分和父子 components 之间的 messaging 传递，那么 OOP 所需要的 divide and conquer 是自然而然的，而且会便利实现 testable module （类似于为了测试方便， database 仅仅被实现为获得值和更新值的一种特例，而非必要的 backend）。\\n\\n而旧时代的 java 以及其所代码的三原则，实际上很容易出现两个很讨厌的事情，一者是子类对父类的副作用污染，另外一种是只要一个香蕉但是拿到了香蕉加猴子加森林。\\n\\n当然 data class 和 sub typing 本身就是很讨厌的强行 binding 数据和方法的手段，但是如果不得不这么做了，实际上我们更常委托的方式而非 extends 的方式处理父类和子类的关系。当然，把大部分所需要的方法重新写一遍是很讨厌的 repeat yourself 行为。所以对于动态语言，我们常常依赖约定自动推导 b -> f a -> f b 或者 (a-> b) -> f a -> f b 来压缩类的层次。Java 等等静态语言虽然不能使用这种方法，但是静态分析可以保证在使用工厂或者其他委托方法时候代码的正确性。\\n\\n然后 PHP 学 Java 了，但是问题是 PHP 能够用静态分析保证委托足够复杂时的正确性，PHP 行么？没有静态分析学 java 就像猪学鸟跳出飞机一样。\\n\\n尾声\\n\\n如果你不会 FP，不懂 FP，也没写过 FP，那么就不要说别人「无脑黑 PHP 不支持 FP」\\n如果你不会 MP，不懂 MP，也没写过 MP，那么就不要说别人「无脑黑 PHP 不支持 MP」\\n如果你对 OO 的理解只停留在三原则上....算了，对于这种 ill-defined 的东西你开心就好\\n如果你只会 PHP，或者只会用 PHP 的方式写很多副作用满天飞的语言... 就不要讲什么「好的程序只和程序员有关，和程序语言无关」；这类编程经验不能教人「什么是好的程序」\\n\\n其实说句实话，作者还真不是了解 php，起码一些基础不行，简单的问题复杂化了，或者是 JavaScript 给你了一些固定的思维方式。明显就是作用域问题，至于为什么 use 继承不了，考虑考虑操作符优先级。\\n\\n```\\n$fib = function ($x) { \\n  global $fib;\\n if ($x == 0) { return 1; }\\n return $x * $fib($x-1);\\n};\\n```\\nvar_dump($fib(10))"}'));jctx.push(JSON.parse('{"id": "181025", "tag": "tool", "text": "# Graphviz使用说明\\n\\n## 命令说明\\n\\ndot(官方命名gv格式)是最核心的语法格式，渲染引擎有多种，比如dot/neato/fdp/twopi，暂时来看dot画的图最符合直觉，其它没有想到应用场景。\\n\\n除渲染命令外，还有一些和dot配合的检测或统计工具。\\n\\n* acyclic: 计算是否存在循环图\\n* gc: 类似wc，统计dot图的点、边、子图数量\\n* edgepaint: 有交叉边时增加色彩区分\\n* gvgen: 生成内置的若干形状，作为画图的参考\\n* nop: 格式化dot源文件，试用后发现会丢弃注释，且排列顺序也不符合预期\\n* unflatten: 调整图的比例，适用于一些孤立点很多的图\\n\\n## 包含常用元素的示例\\n\\n中文用UTF8编码，但不能首字母用中文，前缀用空格规避。\\n\\n```\\ndigraph abc {\\n  rankdir=LR\\n  graph [bgcolor=\\"gray\\"]\\n  node [shape=box, fontname=\\"simsun\\"]\\n  edge [color=\\"darkgreen\\", fontname=\\"Microsoft YaHei\\"];\\n\\n  box1 [shape=record, label=\\" 中文1\\", fontname=\\"simhei\\"]\\n  box2 [shape=record, label=\\"abc | def\\", color=\\"gold1\\", fontname=\\"simhei\\"]\\n  box3 [label=\\"{json | {bson|cpkg} }\\"]\\n\\n  box1 -> box2 [weight=10]\\n  box2 -> box3 [label=eval, color=deeppink]\\n\\n  subgraph {}\\n}\\n```\\n"}'));jctx.push(JSON.parse('{"id": "181027", "tag": "web", "text": "# 跨域和同源策略\\n\\n浏览器的三大线程\\n\\n1. javascript引擎线程(GUI渲染也在这个线程)\\n2. 浏览器事件触发线程\\n3. HTTP请求线程\\n\\n问题是这样：在localhost页面用XHR发起请求，始终回调error函数。\\n\\n原因：首先这是个跨域的请求，而规范定义XHR不允许跨域请求。出于安全考虑，所有的JS请求都不能跨域，但为了使用CDN的多个源加载机制，对script或img标签的src属性开了个口子，允许跨域，但为了防止被滥用，只支持GET方式，对于CDN分发来说已经足够了。所以就有人基于此开发了JSONP机制。\\n\\n我需要POST，所以JSONP不通。为求简单用了同步方式，同步请求规定withCredentials属性必须false，跨域却必须是true。因此要想跨域，只能用异步方式。\\n```\\nxhr.withCredentials = true;\\nxhr.open(method, dst, true);\\n```\\nJS不能跨域展开一下，浏览器并不会拦截跨域请求(不严谨，如果content-type有值还是会会改动，下述)，抓包能看到浏览器发出了数据，但是在收数据后，会对数据做校验，不符合规范就不把收到的数据给JS。\\n\\n网上很多说通过响应header增加`Access-Control-Allow-Origin: *`来解决，但都没有细说是在哪个server端增加。来分析一下跨域定义：访问A页面，这其中有一段JS脚本向B页面请求数据，虽然跨域，浏览器还是会向B请求数据，请求的头中会加上来自A站的标识`Origin: http://localhost` 。直到发现有刚才那段申明，才把数据给JS，否则就不给JS。从字面意思也好理解，对B来说，Origin指的是A。只有B允许A（或`*`所有人）来请求数据，浏览器看到既然B都特地声明数据开放给A了，才会把给JS。如果B没有说这句话，默认是不给JS的。\\n\\n再说说跨域的高级变化，又称为preflight机制。只有简单请求能够直接发出去，而复杂请求浏览器会修改XHR发出的请求。简单请求包括HEAD/GET/POST，且不允许设置Content-Type等若干头部。一旦发现违反，就会把方法改成Options向服务器探探路，只有应答带了`Access-Control-Allow-Origin: *`等若干字段，才允许重发真正的请求，且即使这样，仍有些头是不允许带的。\\n\\n如果HTTP的请求头中有特殊字段，同样会触发浏览的preflight机制，必须在响应端增加`Access-Control-Allow-Headers: *`，否则浏览器也会不予显示。\\n\\n而表单不受同源限制，因为表单一旦发出，整个页面就切换了，原页面拿不到新页面的内容。所以说同源策略的本质是，一个域名的 JS ，在未经允许的情况下，不得读取另一个域名的内容。但浏览器并不阻止你向另一个域名发送请求。\\n\\n用异步就一定会涉及回调，看看MDN上关于回调的写法\\n```\\nvar xhr = XMLHttpRequest();\\nxhr.onreadystatechange = function () {\\n    switch(xhr.readyState){\\n      case 1://OPENED\\n        break;\\n      case 2://HEADERS_RECEIVED\\n        break;\\n      case 3://LOADING\\n        break;\\n      case 4://DONE\\n        xhr.response; //do something\\n        break;\\n    }}\\n```\\n我最疑惑的就是function中的xhr表示谁？函数无参也无定义，xhr只能链式地向上查找，回调这个函数的主体是xhr，所以向上找的时候，一定能找到xhr变量。但我觉得更好的写法还是`switch(this.readyState)`，引入一个同名变量太容易引起混淆。\\n\\n上述写法是早期xhr的推荐做法，现在新的浏览器还可以用onload和onerror方法，看起来更简洁\\n```\\nreturn new Promise(function (resolve, reject) {\\n    var xhr = new XMLHttpRequest();\\n    xhr.open(method, url);\\n    xhr.onload = resolve;\\n    xhr.onerror = reject;\\n    xhr.send(...)  // POST has string body\\n}\\n```\\n\\n这两个方法回调时的惟一参数是ProgressEvent类型，target.response就是对端返回的内容。target是其父事件Event的属性，ProgressEvent继承得到target属性，表示这个事件被分派的对象，此处代表XHR对象。"}'));jctx.push(JSON.parse('{"id": "181028", "tag": "protocol", "text": "# 视频的封装格式\\n\\nES（Elementary Stream）流是基本码流，包含音频、视频、数据的连续码流。编码器输出的都是这种类型。\\n\\nPES（Packet Elementary Stream）流是打包的基本码流，是将ES根据需要打包成长度不等的数据包并加上包头就形成了打包的基本码流PES。\\n\\nTS（Transport Stream）流，也叫传输流。是由固定长度的188字节的包组成。含有独立是一个或者多个program,一个program又可以包含多个视频，音频和文字信息的ES流。每个ES流会有不同的PID标示。为了分析这些ES流，TS有些固定的PID来间隔发送Program和ES信息表格：PAT表和PMT表。\\n\\n(在MPEG-2系统中,由视频, 音频的ES流和辅助数据复接生成的用于实际传输的标准信息流称为MPEG-2传送流)\\n\\n封装 : 就是捆绑打包, 将画面视频文件和音轨文件打包在一起, 并按照一定规则建立排序和索引, 便于播放器或播放软件来索引播放. 包括AVI / PS(Program Stream)/ TS（Transport Stream）/ MKV（Matroska）等.\\n\\nPS是节目流编码器出来的是TS流，传输接口为asi口，编码器整个作用过程是把模拟信号变成ES，再打包成PES，再打包成TS流输出。\\n复用器是把多路单节目或多节目TS流合称1路多节目TS流，再给调制器。\\n数字卫星接收机出来的是TS流，也是asi接口，可能包含一路或多路节目，有的还同时有一路模拟信号视音频输出。\\n模拟卫星接收机出来的是模拟视音频信号。，PS流与TS流的区别在于，PS流的包结构是可变长度的，而TS流的包结构是固定长度的.\\n\\nTS流的解码过程-ES-PES-DTS-PTS-PCR\\n\\nTS 流解码过程:\\n\\n1. 获取TS中的PAT\\n\\n2. 获取TS中的PMT\\n\\n3. 根据PMT可以知道当前网络中传输的视频（音频）类型（H264），相应的PID，PCR的PID等信息。\\n\\n4. 设置demux 模块的视频Filter 为相应视频的PID和stream type等。\\n\\n5. 从视频Demux Filter 后得到的TS数据包中的payload 数据就是 one piece of PES，在TS header中有一些关于此 payload属于哪个 PES的 第多少个数据包。 因此软件中应该将此payload中的数据copy到PES的buffer中，用于拼接一个PES包。\\n\\n6. 拼接好的PES包的包头会有 PTS，DTS信息，去掉PES的header就是 ES。\\n\\n7. 直接将 被拔掉 PES包头的ES包送给decoder就可以进行解码。解码出来的数据就是一帧一帧的视频数据，这些数据至少应当与PES中的PTS关联一下，以便进行视音频同步。\\n\\n8. I，B，B，P 信息是在ES中的。\\n\\nES 是直接从编码器出来的数据流，可以是编码过的视频数据流，音频数据流，或其他编码数据流的统称。 ES 流经过 PES 打包器之后，被转换成 PES 包。 PES 包由包头和 payload 组成.\\n\\n在 PES 层，主要是在 PES 包头信息中加入 PTS( 显示时间标签 ) 和 DTS （解码时间标签）用于视频、音频同步。 其实， Mpeg-2 用于视音频同步以及系统时钟恢复的时间标签分别在 ES ， PES 和 TS 这 3 个层次中。在 ES 层，与同步有关的主要是视频缓冲验证 VBV （ Video Buffer Verifier ），用以防止解码器的缓冲器出现上溢或下溢；在 PES 层，主要是在 PES 头信息里出现的显示时间标签 PTS （ Presentation Time Stamp ）和解码时间标签 DTS （ Decoding Time Stamp ）；在 TS 层中， TS 头信息包含了节目时钟参考 PCR （ Program Clock Reference ），用于恢复出与编码端一致的系统时序时钟 STC （ System Time Clock ）。\\n\\n基本流程如下：首先 MPEG-2 压缩编码得到的 ES 基本流，这个数据流很大，并且只是 I ， P ， B 的这些视频帧或音频取样信息，然后加入一些同步信息，打包成长度可变长度的数据包 PES ，原来是流的格式，现在成了数据包的分割形式。同时要注意的是， ES 是只包含一种内容的数据流，如只含视频，或只含音频等，打包之后的 PES 也是只含一种性质的 ES, 如只含视频 ES 的 PES, 只含音频 ES 的 PES 等。可以知道， ES 是编码视频数据流或音频数据流，每个 ES 都由若干个存取单元（ AU ）组成，每个视频 AU 或音频 AU 都是由头部和编码数据两部分组成， 1 个 AU 相当于编码的 1 幅视频图像或 1 个音频帧，也可以说，每个 AU 实际上是编码数据流的显示单元，即相当于解码的 1 幅视频图像或 1 个音频帧的取样。 MPEG-2 对视频的压缩产生 I 帧、 P 帧、 B 帧。把帧顺序 I1,P4,B2,B3,P7,B5,B6 帧的编码 ES ，通过打包并在每个帧中插入 PTS/DTS 标志，变成 PES 。在插入 PTS/DTS 标志时，由于在 B 帧 PTS 和 DTS 相等，所以无须在 B 帧多插入 DTS 。而对于 I 帧 和 P 帧，由于经过复用后数据包的顺序会发生变化，显示前一定要存储于视频解码器的重新排序缓存器中，经过从新排序后再显示，所以一定要同时插入 PTS 和 DTS 作为重新排序的依据。\\n\\n其中，有否 PTS/DTS 标志，是解决视音频同步显示、防止解码器输入缓存器上溢或下溢的关键所在。 PTS 表明显示单元出现在系统目标解码器（ STD- System Target Decoder ）的时间 , DTS 表明将存取单元全部字节从 STD 的 ES 解码缓存器移走的时刻。 视频编码图像帧次序为 I1,P4,B2,B3,P7,B5,B6,I10,B8,B9 的 ES ，加入 PTS/DTS 后，打包成一个个视频 PES 包。每个 PES 包都有一个包头，用于定义 PES 内的数据内容，提供定时资料。每个 I 、 P 、 B帧的包头都有一个 PTS 和 DTS ，但 PTS 与 DTS 对 B 帧都是一样的，无须标出 B 帧的 DTS 。对 I 帧和 P 帧，显示前一定要存储于视频解码器的重新排序缓存器中，经过延迟（重新排序）后再显示，一定要分别标明 PTS 和 DTS 。例如，解码器输入的图像帧次序为 I1,P4,B2,B3,P7,B5,B6,I10,B8,B9 ，依解码器输出的帧次序，应该 P4 比 B2 、 B3 在先，但显示时 P4 一定要比 B2 、 B3 在后，即 P4 要在提前插入数据流中的时间标志指引下，经过缓存器重新排序，以重建编码前视频帧次序 I1,B2,B3,P4,B5,B6,P7,B8,B9,I10 。显然， PTS/DTS 标志表明对确定事件或确定信息解码的专用时标的存在，依靠专用时标解码器，可知道该确定事件或确定信息开始解码或显示的时刻。例如， PTS/DTS 标志可用于确定编码、多路复用、解码、重建的时间。\\n\\nPCR\\n\\nPCR 是 TS 里面的，即 TS packet 的 header 里面可能会有，他用来指定所期望的该 ts packet 到达 decoder 的时间，他的作用于 SCR 类似。\\n\\nDTS, PTS\\n\\n对于一个 ES 来说，比如视频，他有许多 I,P,B 帧，而 P, B 帧都是以 I ， P 帧作为参考。由于 B 帧是前向后向参考，因此要对 B 帧作 decode 的话，就必须先 decode 该 B 帧后面的 帧（ P, 或者 I 帧），于是， decode 的时间与帧的真正的 present 的时间就不一致了，按照 DTS 一次对各个帧进行 decode ，然后再按照 PTS 对各个帧进行展现。\\n\\n有时候 PES 包头里面也会有 DTS ， PTS ，对于 PTS 来说，他代表了这个 PES 包得 payload 里面的第一个完整地 audio access unit 或者 video access unit 的 PTS 时间（并不是每个 audio/video access unit 都带有 PTS/DTS ，因此，你可以在 PES 里面指定一个，作为开始）。\\n\\nPES 包头的 DTS 也是这个原理，需要注意的是：对于 video 来说他的 DTS 和 PTS 是可以不一样的，因为 B 帧的存在使其顺序可以倒置。而对于 audio 来说， audio 没有双向的预测，他的 DTS 和 PTS 可以看成是一个顺序的，因此可一直采用一个，即只用 PTS。"}'));jctx.push(JSON.parse('{"id": "181101", "tag": "web", "text": "# Web单页和跳转\\n\\n思考开放平台的网页呈现方式，基于已经有若干md文件，怎么去呈现。基本的想法是目录中放html文件，以静态方式来获取，完全不需要一行代码，但是开发似乎已经不知道还有上古技术了。单页配合后台按路径读数据也足够简单，定下大致思路。期间想到文档间需要跳转，如果按md内相对路径的写法，编译成chm没有任何障碍，但到了单页应用就会面临被跳转到其它页面的问题。\\n\\n经前端开发提醒，href除了绝对路径和相对路径外，还支持哈希方式，就是以#为记号的页面内跳转。简单测了下，规则大致是这样\\n\\n1. 如果发现是`scheme://`开头，且scheme可以识别，就直接向外发起链接，页面也转移走了。\\n2. 如果首字母是`#`，进行页面内定位，仍留在当前页。\\n3. 除以上情况外，就以这个页面为根，在服务器的目录进行间接寻址。比如当前页面请求的路径是`/www`，如果name是ha，就向/www/ha发请求同时页面会跳转。\\n\\n可以看出，只有#路径的点击可以驻留，可以说是SPA的最佳搭档，同时会回调onhashchange函数，只要能进入JS，拿到#后面的数据，重新请求数据就是自然而然的事情，接下来就是编码的工作了。\\n\\n再看图片。如果用img标签，src是不会触发JS的(可以跨域的属性，当然不能随便加载JS)。这就要求必须能定位到这个SPA页面的根地址，再以跟地址进行相对路径的编写，理论上也是可以找到图片的。还没验证，先记录一下。\\n\\n最坏情况下，还能把图片先base64编码再嵌入页面，像这样`<img src=\\"data:image/png;base64,agEna13==\\">`。"}'));jctx.push(JSON.parse('{"id": "181103", "tag": "design", "text": "# 字符编码与字体映射\\n\\n早期计算机的字符编码基本上都是6位。所以早期计算机的整形的字长一般是6的倍数，如18位、24位、36位等。1963年公布的ASCII码是第一个得到广泛采用的7位字符编码。这时的通信领域的协议采用了第8位做校验纠错用途。但是对于计算机内存来说，校验纠错变得不是必要。因此8位字符编码逐渐出现，用来表示比ASCII码更多的字符。为此，1971年公布的ECMA-35标准，用来规定各种7位或8位字符编码应当遵从的共同规则。随后ECMA-35被采纳为ISO 2022。\\n\\n\\n字符编码追求的是\\n\\n1. 表示的字符足够多\\n2. 表示常用意思时占用内存足够小\\n\\n汉字有GB2312和Unicode编码，字符编码是字符的数字表示，一套字符集相当于一个命名空间，空间里的每一个元素代表一个唯一的字符。不同字符编码方式对应同一个字符的字面值不同。区位码的「区位」即「row-cell」，日语称「区点」\\n\\nGB2312釆用94x94的区位码，顺带一句日语的JIS0208也是94x94。符合ISO2022定义的用7位双字节编码（共128*128），为了避开ASCII编码中的控制字符（0~31和127DEL）以及空格符（32），最后只剩下94位可用。至于0x9A~0xFF这些空间是国标码变形后得来的。设计时采用的是区位码，有了区位码才会在编码空间上作映射。区位定义：\\n\\n* 01-09区为特殊符号。\\n* 16-55区为一级汉字，按拼音排序。\\n* 56-87区为二级汉字，按部首/笔画排序。\\n* 10-15区及88-94区则未有编码。\\n\\n共计72区的汉字，在区码为215，位码为250-254之间共五个编码没有汉字编码，所以一共72x94-5=6763个汉字。\\n\\n不管选哪种，最终用黑体字比如simhei.ttf都能正确渲染，原理如下。\\n\\n首先字体内部是有一个自己的编码号的，用于索引图元（Glyph），但是外界不会知道它。字体内部的各种数据比如 GSUB 和 GPOS 都是用这个索引号编的。\\n\\n将图元和文字关联起来的东西是 cmap 表，这表的格式十分多，用来支持不同的外部编码：最常用的 UCS-2 外部编码（FontForge 里面称 UnicodeBMP）使用 Format 4，UCS-4 外部编码（FontForge 称 UnicodeFull）使用 Format 8、Format 12 等。\\n\\n然后是绘图的时候，WINAPI 或者其他的 API 会对文字编码进行转换。Windows 是默认把其他编码转换成 UTF16LE ，兼容早前版本API用的UCS2格式。"}'));jctx.push(JSON.parse('{"id": "181110", "tag": "web", "text": "# 论为什么CSS难学\\n\\n很多人以为CSS是给DOM元素设置属性（attribute），其实CSS规定的并不是属性，而是行为（behavior），DOM里的每个元素都可以看成是一个独立的物体，按照CSS规定的方式运动，最后稳定下来的结果就是最终布局的结果。所以有人说CSS不正交，它当然不是正交的，因为它的设计就是要求协变，要求在其他元素做出调整的时候，即便本元素的样式没有发生任何变化，也可以跟着调整位置和大小，以适应新的内容，维持设计风格。\\n\\n为什么CSS要设计成基于选择器和多种各异的behavior，而不像其他框架那样直接将显示样式绑定到每个元素呢？恰恰是因为正交性，因为CSS和DOM是正交的，这样DOM内容变化时，CSS可以规定一组不变的特性，从而以灵活的方式适应内容的改变。传统的GUI通常每个元素都有固定的位置和大小，要实现根据内容动态调整，就必须针对各种情况（如视口大小改变，内容改变）专门编写代码；WPF则有网格、流式、绝对三种不同的定位方式，与CSS有不少共同点，但是自适应的功能少了不少，也没有选择器的功能，这样动态生成的内容就需要更多的代码来调整。而CSS只要将DOM组织成特定的格式，就会自动启用相应的样式。WPF制作的界面毕竟变化比较少，大部分元素仍然是固定的，而网页通常要求更高的灵活性。\\n\\n前期准备：首先理解 HTML的一些常用的基本元素和常用样式属性的约束定义\\n\\n基本元素\\ndiv, span, a, p, input, textarea, select, ul, li, h1-h6, hr\\n\\n常用样式\\ndisplay\\nmargin\\npadding\\nborder\\nbackground\\ncolor\\nwidth\\nheight\\nposition\\nfloat\\n\\n基础：把以下几个常用的CSS样式，记熟\\n\\n1. 固定长宽的圆角有边框的头像\\n2. 三角形， span (这个前端面试特别喜欢考\\n3. 横向的导航条，像知乎网页版导航条\\n4. 竖的的菜单栏，比如gitbook章节列表\\n5. 同时纵向和横向都居中对齐（暂时没想到其他的\\n6. 进阶：前端排版布局练习\\n\\nhttps://github.com/dodoru/40LayoutExercise\\n专门做的40个排版练习的演练，前端排版布局都还挺轻松。主要训练，float display position"}'));jctx.push(JSON.parse('{"id": "181111", "tag": "tool", "text": "# 字体名\\n\\nAdobe 有一份文档就是专门讲这个的: 5149.OTFname_Tutorial.pdf\\n\\n字库中有关于字体信息的数据都储存在 name table 中, 每条数据有 4 个标识符:\\nnameID,platformID,platEncID,langID - 名称,平台,编码,语言\\n(其中 platformID 将会影响后两项的取值).\\n\\n其中, 与字库名称有关的 nameID 如下, 以 Adobe 黑体中的对应名称作为参照:\\n```\\n1. Family - Adobe Heiti Std R\\n2. Style - Regular\\n4. Full - Adobe Heiti Std R\\n6. PostScript - AdobeHeitiStd-Regular\\n16. Preferred Family - Adobe Heiti Std\\n17. Preferred Subfamily - R\\n18. Mac Compatible Full - (无)\\n20. (未命名) - AdobeHeitiStd-Regular-GBpc-EUC-H\\n```\\n\\n通过 4 个标识符, 可以组合出不同平台不同语言下的不同名称, 如:\\n1,1,0,0 - Family,Macintosh,Roman,English\\n(如果不特意指定除 nameID 外的其它 3 个标识符, 将默认为 \\"1,0,0\\", 即西文字体大都如此).\\n1,1,2,19 - Family,Macintosh,Big5,繁体中文\\n1,3,1,2052 - Family,Microsoft,Unicode,简体中文\\n\\n现在常用的 Opentype 字体的命名是通过里面的 name 表组成。name 表项由语言、名称类型以及名称值组成。在名称类型里有 Family、Style 和 Preferred Family、Preferred Style 两组。因为历史原因，Family+Style 不能支持超过四个 Style（而很多字体，比如 Adobe 的那些经常 6 个宽度），Preferred Family+Preferred Style 则可以支持很多的小 style 甚至是非标准的 Style（比如 Hiranigo 里面就用 W3、W6），而这就产生了问题。\\n\\nWindows 的字体预览会采用你目前的系统语言对应的 Preferred Family 作为命名，如果此项缺失则会用系统语言 Family、英语 Preferred Family、英语 Family。\\n\\n对浏览器来说不同浏览器的处理策略是不一样的，比如 IE9 和 FF4 支持按照 Preferred Family 选字而 Chrome 只按照 Family（Opentype 规范里的 [name] 表项目）搜索。\\n\\n下面是「Adobe 黑体」的名称表：\\n\\n[name] 表：\\n2052（中文）Fullname：Adobe 黑体 Std R\\n2052 Preferred Family：Adobe 黑体 Std\\n2052 Preferred Style：R\\n1033（英语）Family：Adobe Heiti Std\\n1033 Subfamily(style)：Regular\\n1033 Fullname：AdobeHeitiStd-Regular\\n1033 Preferred Family：Adobe Heiti Std\\n1033 Preferred Style：R\\n65536 CID findfont Name：AdobeHeitiStd-Regular-GBpc-EUC-H\\n\\nPostscript 特有名称（仅限 CFF OTF）：\\nPostscript Name：AdobeHeitiStd-Regular\\nPostscript Family：Adobe Heiti Standard Opentype\\nPostscript Name For Humans：Adobe Heiti Standard Opentype Regular\\n"}'));jctx.push(JSON.parse('{"id": "181115", "tag": "book", "text": "# 交出思考的权利\\n\\n现成的思想背后往往隐藏着谋划已久的目的，要不要交出自己思考的权利，确实不是一个愚蠢的问题\\n\\n1905年，是平常的一年。摇摇欲坠的大清国国事依旧羁縻。前一年爆发了日俄之间的战争，战场却设在了中国，还是清王朝的龙兴之地；大清国却只能饬令吉林将军“厚集兵力，严守中立。”祖宗的龙兴之地，领主从毛熊换成了鬼子；努尔哈赤的后代们却只争来了一纸《关于清国人入学之公私立学校之规程》的取缔清国留学生规程。1905年也是不平常的一年，这一年两位对中国影响深远的年轻人献出了他们年轻的生命。一位是年仅20岁的邹容；一位是才入而立之年的陈天华。一位死在了英租界的大狱中，一位跳入了碧波荡漾的日本海。\\n\\n出身富户的邹容善造风潮、创办《苏报》、暗结英日为后劲、每以“杀尽满人”自勉；其文章语言跳朗搏跃，情绪高亢激烈。“虽玩懦之夫，目睹其事，耳闻其语，无不面赤耳热，心跳肺张。” 其宣传煽动，渲染夸张可见一斑。观其成名作《革命军》也无甚史德史识，也无独立思考，专以诉诸情绪、诗意表述、鼓动民众向某些特定的人交出自己本不自觉的思考权利为职事；近代维新派诗人蒋智由称之为“热的文章”。家境贫寒的陈天华则性情恰恰相反，他常怀悲苦，眼冷心热。在亲眼目睹革命团体内部的推诿与倾轧后，他从《猛回头》、《警世钟》的热切转向了《绝命书》的冷静；并试图以死亡这种决绝的姿态提醒与告诫同道“坚韧奉公，力学爱国”。极易动情、动辄流泪的他，写出了“凡做一事，须远瞩百年，不可徒任一时感触而一切不顾”、“一哄之政策，以后再不宜于中国矣”的自省与告诫。经过对革命本身的审视与反思，他以自己的生命为代价劝革命同道们独立思考，刻苦学习，徐以养成实力，丕兴国家。\\n\\n性情激越，倡言杀人的邹容去世后哀荣备至，发现其利用价值的革命家们对他大肆吹捧；辛亥事成后，孙中山即以大总统的名义追赠邹容大将军；劝人冷静、以死劝世的陈天华投海后，他的同志们将他称为烈士，并为他在岳麓山举行了盛大的安葬仪式。唯独对于他生前留下的那份充满自省与告诫的“切要之言”却无一人听取。甚至他的自杀也被革命的同志解释为对政府的抗议。至于他所深为忧虑的那些“不顾一切”的行为，“理直气壮”的发难，脱离实际的“一哄之政策”，更是史不绝书。\\n\\n## 1\\n\\n1936年8月5日夜，鲁迅先生拖着久病的身体写了一篇题为《答徐懋庸并关于抗日统一战线问题》的文章。25日之后，仍不解恨的鲁迅先后写信给欧阳山、杨霁云、台静农等人说：“真不懂徐懋庸为什么竟如此昏蛋，忽以文坛皇帝自居，明知我病到不能读写，却骂上门来，大有抄家之意。”\\n\\n被骂的徐懋庸是“左联”的常委和秘书长，专门负责联系鲁迅的。鲁迅的这份公开信算是对左联的“革命家”们的彻底决裂和强烈反击。“左联”之于鲁迅，犹如儿子之于父亲；这个组织是他一手看着组建起来的，同时也为这个组织倾注了大量的心血。1929年，中共征得鲁迅的同意后组建了这个以鲁迅为领袖，以一些左翼作家和鲁迅身边的青年作家为核心的组织。\\n\\n可能因着“铸剑复仇”的战士性格与审美意识；对论敌向来以“死也不放过一个”的睚眦必报著称的鲁迅，对这些年轻人出奇的宽容。虽然他对革命的后果包括共产党掌权后他的命运一直都不乏警惕，但他依然热情的提倡和向往着革命，并且全力以赴的支持革命和那些献身革命的年轻人。对现状的极端失望导致了他对一场摧枯拉朽、涤荡污浊；能够迅速改变现状的暴风雨的满怀期待。越来越倾向于暴力革命的他把希望寄托在了共产党和红军一边。\\n\\n然而，在他生命的最后几年里，这种希望在他的心里可以说彻底破灭了。1933年，共产党给“左联”委任了一位党团书记，主持“左联”的工作。这位党团书记后来有一个天下闻名的绰号：文艺沙皇。诨名文艺沙皇的周扬以政治才干见长。他充分利用了这种组织的行政化的有效性，在极短的时间内，把“左联”甚至整个“文委”都变得清一色；一批青年知识者忠诚地围绕在他的周围，随时为他所用。\\n\\n周扬初期还能对鲁迅保持表面上的尊重，但很快事情就发生了变化。随着他与宣传部长胡风在工作上的分歧越来越大，志在统一思想的周扬对信任胡风的鲁迅也越来越不尊重。从1934年开始，“左联”有关人士对鲁迅的批驳文章越来越多，说他“懒”，“不做事”，“不写文章”等等，后来甚至散布一种空气，说他“破坏统一战线”；甚至后来做出“左联”解散的决定也没有征询“精神领袖”鲁迅的意思。\\n\\n直至徐懋庸以书信致鲁迅，提醒鲁迅不要相信胡风，并隐晦的劝鲁迅从思想和组织上服从周扬的领导，彻底激怒了鲁迅。“我憎恶那些拿了鞭子专门鞭扑别人的人们。”“有些手执皮鞭，乱打苦工的背脊，自以为是革命的大人物，我深恶之，他其实是取了工头的立场而已。” “唱高调就是官僚主义”这样的反击喷薄而出。毫无疑问，鲁迅并不屑于跟这种以组织自居，志在统一文坛，做“文坛皇帝”的做派，自己不做事，却专责以别人不做事，役使别人，监督别人的行为；对于不听指挥者，则动辄加以罪名，以至以“实际解决”相威胁的人和组织完全契合的。\\n\\n吊诡的是鲁迅去世后，并不尊重他的周扬却做了很多年鲁迅研究会的会长，而且每逢鲁迅研讨会都要讲话，以正统自居；官方史料也有意无意的将二人之间的矛盾，解释为一种工作中的误解。而鲁迅所喜欢的胡风则在历次运动中脱尽了皮。\\n\\n在这种似有似无的掩盖中人们也逐渐忽略了鲁迅与周扬矛盾中更深刻的原因：鲁迅认同某一战略目标，但不愿交出独立思考的权利，无意成为某个庞大的政治集团或国家机器的“螺丝钉”。\\n\\n## 2\\n\\n1957年，教员前往上海小住。依照惯例在上海中苏友好大厦接见了周谷成、罗稷南等几位老友。时值反右，文化界风声鹤唳，性情直率的罗稷南老先生抽了个空隙，向教员提出了一个大胆的设想疑问：要是今天鲁迅还活着，他可能会怎样？教员对这样一个设想的问题十分认真的沉思了片刻，回答说：以我的估计，（鲁迅）要么是关在牢里还是要写，要么他识大体不做声。罗稷南先生顿时惊出一身冷汗，不敢再做声。\\n\\n很多讨论反右的文章和书籍里都提到这次座谈会中教员对罗老先生设问的这番回答，以此说明教员生性一贯的冷峻。受这些材料的影响，大多数人也都这么认为；跟教员打发儿子去朝鲜是为了接班的说法一样在社会上大有市场，即使在对教员充满敬意的人中间这种说法也并不鲜见。\\n\\n其实教员的这句话应该跟他的另一句话联系起来看。文革前夕，决意跟党的机器决裂的教员给江青回了一封信。这封有点政治遗嘱性质的信里有一句话：“我和鲁迅的心是相通的。”教员和鲁迅都是少数派，都不愿意向一些人和一些组织交出自己思考的权利，哪怕这些人、这些组织是自己寄予厚望的青年，是自己一手创建的政党。\\n\\n很多党史爱好者们，对于早期共产党的探索和教员彼时的处境都知之甚少也并不感冒。但是这段经历深深的影响了教员；也正是这段历史更反应了教员如炬的目光和坚毅的性情；而不是后来那个被不断书写，不断解读的教员。考察这段历史，不能不注意两个问题：一个是中国的共产主义运动及其内部关系的历史与克里姆林宫之间关系的历史；一个是思想与实际之间的演进关系。能回答这两个问题也就能体会到教员的不易与伟大。\\n\\n众所周知，早期的共产主义运动跟克里姆林宫的关系非常密切；克里姆林宫的一封信甚至都可以改变党的领导。而教员关注农民运动的战略并不是莫斯科所欣赏和预先计划的战略；教员的领导也不是莫斯科所主动选择的。直到遵义会议前，教员在党内的发言权也是非常有限的。\\n\\n克里姆林宫为了显示自己对周围环境的了如指掌，加强对仰望者的精神主宰，做了大量的政治断言；不断预言中国工人阶级运动的高潮已经来到。为维护这些断言的正确性，他们不惜一次次把断言失败的原因归咎于忠实执行自己路线的领导人；从陈独秀到瞿秋白，从李立三到王明；领导换了一茬又一茬，工人运动的高潮硬是没有来到。而在井冈山偷偷摸摸打游击的教员却不断胜利，现实迫使他们不得不想起1927年就写了《湖南农民运动考察报告》的这位教书先生。\\n\\n在他们对农民运动不屑一顾，醉心于发动大城市里的工人进行暴动时，教员选择了坚持自己的判断。他在很长一段时间都是少数派，被讥为“山沟里的马克思主义”、“流寇习气”。从他多年后以国家领导人的身份会见斯大林时那句恨意难平的抱怨就可看出他当年的坚持并不容易。\\n\\n正因为教员知道坚持独立判断的不易，他才在徐懋庸到延安后向他汇报“左联”与鲁迅的情况时对左联的领导作了严厉的批评，这中间包括对他认可的“有一点组织才干”的周扬的批评。长久以来，我们总是宣传或者强调抑或是认定领袖人物的无所不能，一厢情愿的相信他们如戏剧中的那样口授机宜，沉思踱步，激情演说，计上心头，妙语博笑，指挥千军万马，接受万众欢呼；似乎他们动动手指就能拨转历史；而忽略了他们也是人，他们也会被掣肘、被裹胁、被引导、被影响、被代理、被推动、被造就的事实，忽略了聚光圈外的体制条件和环境制约。那双看不见的历史之手始终无处不在，即使睿智的教员也不可能逃脱这样的境况。\\n\\n1957年在反右扩大化的情况下，当他的“温和”，他对鸣放的鼓励，对“人民内部矛盾”提法的固守，还有“恳求宽大”和“阻挡对右派的全面政治迫害”面对彭真、陆定一、总设计师、高个子领导等反右“强硬派”的愤怒时，他的这些认识和建议显得那么的无济于事。在他最终选择迁就这些强硬派，与各方磨合与“妥协”的时候，教员一定想到了1934-1936年的鲁迅。生命的最后日子里，鲁迅被周扬派去的人站在病床前逼着他在别人替他拟好的稿件上签上自己的名字。1957年的周扬正在热火朝天的领导文艺界的反右运动；教员心心念念的“百花齐放百家争鸣”因着这些人的努力变成了所谓引蛇出洞的“阳谋”，而他不能分辩，必须认账，必须加以圆说；如鲁迅一样，教员不得不在这些人做的这篇“文章”上签上了自己的名字。\\n\\n选择在那样一个相对正式的场合，以那样凝重的话语回答罗老先生的设问，我想教员的目的不应该仅仅是吓罗老先生一身冷汗，其中应该更有自己的无奈，对自己的坚持和对那些人的反感。\\n\\n## 3\\n\\n1933年3月23日，已经率领纳粹党完成组阁并初步实现了独裁统治的希特勒为德意志人民颁布了一项法律。这项法律的名字叫《消除人民和国家痛苦法》，他告诉人民独立思考和判断选择是产生痛苦的根源，为了消除人民和国家的痛苦，人民应该自觉出让思考和选择的权利，让领袖替人民痛苦。人民欢欣鼓舞着交出了可怜的权利，以为遇到了救世主。未料到六年后他不但给德国人民也给世界人民带来了一场更深的痛苦。\\n\\n在考察历史，思虑未来时，比起独立的思考，理性的判断往往更喜欢属意于标签的不仅仅有接受纳粹的德国人民。这个世界上关心本质，远瞩百年的人远远没有情绪摇摆，活在当下的人多。对于那些意图在思想和现实上对别人进行谋划、迎合、引导和控制的人，大众从来都缺乏足够的警惕。\\n\\n远的不说，近代以来日本人在中国思想界的谋划迄今为止都鲜为人知。各种光明正大的口号和史实为何如此发展从无人追究。邹容的《革命军》为何做于日本？同盟会为何创于日本？护国、护法战争中为何有日本政界、军界人士忙碌的身影？几乎无人研究。\\n\\n第一次世界大战后的巴黎和会上，中国的外交官们做了极大的努力，他们在和会上的表现可以说是可圈可点，可咏可叹；顾维钧、颜惠庆等人的据理力争也赢得了与会代表的尊敬。最后列强们迁就日本，牺牲中国导致交涉失败，不能归罪于他们。消息传回国内，国人却将卖国的矛头指向了他们。英国人的喉舌《字林西报》刊出分析时局，指出为防止中国学生由和会而对英法美三国产生恶感而应该将学生运动的矛头指向中国政府，从而为他们谋取最大的利益。结果上海爱国社将这篇文章的标题翻译为“西人痛斥卖国贼”，在国内广泛传播。狡猾与糊涂形成鲜明的对比。\\n\\n人民和国家一次又一次为自己的轻信付出沉重的代价。先是外国势力介入，国家四分五裂，军阀拥兵自重，人民流离失所；接着是思想定于一尊，以一人之是非为天下之是非；改革之所以在初期吸引人，就在于他解开了束缚每个人的枷锁，各个阶层甚至每个个体只要愿意都能在建设的大潮中寻找到机会。如今，改革到一定的阶段出现了困难不是因为大家自由发展的机会太多，而是少部分人的机会太多，大家的机会太少；解决问题的办法应该是建立规则，捆住乱动的手，给大家以机会而不是思想定于一尊，捆住大家的手，给寻租的人以权力。\\n\\n1913年，面对国家失去统治基础，有效的管理机能渺不可求，激进党人互相倾轧，版图大大缩小，主权大大削弱的状况；一位杰出人士感叹道，少数豪暴狡狯者在所谓的民政、民权中得利，广大人民则不得安居，刀兵水火，天灾人祸。“共和自共和，幸福何有于吾民也！”\\n\\n说这句话的，不是“不幸而言中”的康有为，而是年轻的李大钊。年轻的共产党人能够成功靠的也不是不要规则想怎么管就怎么管的粗暴干部，而是像教员一样为工农打开思考问题的大门；未来国家的复兴，人民的安乐也不能靠指路的舵手，伟大的灯塔，反腐的英雄而应该靠解放每个人的思想。\\n\\n英国牛津大学著名的思想史家、政治哲学家以赛亚·伯林在与贾汉贝格鲁的谈话中评价马克思主义时有过这么一句：“对于各种观点、社会运动、人们的所作所为，不管出于什么动机，应该考虑他们对谁有利，谁获益最多，这些并非愚蠢的问题。”他自己不是马克思主义者，却对这些问题极为敏感。也是因着这份敏感，他和他的朋友们以思想和学术为武器，把大国政治的博弈引向了有利于犹太人和以色列的一边。\\n\\n现成的思想背后往往隐藏着谋划已久的目的，要不要交出自己思考的权利，这确实不是一个愚蠢的问题！\\n\\n参考文献：\\n\\n罗德里克·麦克法夸尔 《文化大革命的起源》第1卷，香港新世纪出版社，2012年\\n"}'));jctx.push(JSON.parse('{"id": "181116", "tag": "net", "text": "# C语言的HTTP请求\\n\\n在windows上写HTTP请求，遇到问题很多。\\n\\n头文件要用winsock2.h，且必须调用WSAStartup，另外还要链接`ws2_32`库。\\n\\nPHP Server会分两次发送头和payload。\\n\\n收到的数据，win7似乎是1013，大于这个数量，puts或printf的输入就会被截断。但win10至少在2200左右无问题。更大未知。\\n\\n发送的接口要把数据拆成3块，否则很难灵活组合。\\n\\n遇到过对端不断连接，导致流程下不去，变通办法是对recv加超时参数。奇怪的是用`SO_RCVTIMEO`在某些情况下导致程序异常中止，命令行无法打印，GUI直接崩溃。\\n\\n换用select，返回有3种情况，>0表示事件发生，0表示超时，<0是select函数本身有问题。这3种状态即使在跨平台上也依然适用。\\n\\n读写集`fd_set`在win10配64位gcc的大小是520字节。第一个字节，所有的手册都说是最大的fd+1，看到一种说法是OS要给监听fd分配连续的内存，最小的fd是0，为了容纳从0到最大fd的范围，因此填值是fd+1。而windows上这个参数是无意义的，因为windows的fd并不是从3开始，而且连续两个fd的差也不是1，所以最大值+1规则不适用。当fd数量过多，超过`FD_SETSIZE`，其实就是超过`fd_set`容纳的范围时，就不能再用select。换句话说select不能应对海量连接。\\n\\nreadset表示可读，或者说read操作不会堵塞，这时进行recv一定有数据或者EOF，对于socekt就是连接被断开。\\n\\n超时虽然有秒和微秒两个值，但实测windows下必须在秒以上，少于1秒的值会破坏堆栈导致崩溃。\\n\\n使用HTTP/1.0短连接，关闭联接时又遇到语义不一致的坑，由于是服务端主动断开，主动断开方会变成`TIME_WAIT`。这个socket在windows客户端用close会被置成`CLOSE_WAIT`状态。说明windows的close函数只是释放句柄，不处理TCP协议，必须先调用shutdown或换成closesocket(对TCP/UDP都适用)才行。除非要半关闭，通常用closesocket就行。\\n\\n语义不一致的原因，猜测大概是由于，fd的维护和socket状态是分开的，windows没有把这二者绑定。\\n\\nTCP状态机有5个标识过渡到CLOSED的中间状态，超过所有状况的一半。要仔细理解。\\n\\nhttp库和国标网关调试时，会遇上登陆流程卡住不往下走的问题，才分析出原因。\\n\\n代码中用recv收数据，之前遇到过和某些服务器请求，对端会在1分钟后才关连接，所以recv就会阻塞1分钟，所以把请求改为HTTP/1.0且显式声明是close，期待对端来关闭连接。但是国标网关的程序并不理会close指示，不会断开连接，所以就一直停在recv不往下走。查询手册知道用setsockopt设置fd的超时时间，recv就不会永远等待，先这样规避该问题。\\n\\nuv的多线程。只提供了4个线程接口，没有cancel这种语义复杂的接口，对我来说够用。多线程同时从tty读入，是否会抢占？从实验来看，两个线程如果都调用scanf，先被触发的会锁住tty，直到输入完成才会放开tty，让另一个线程去读，因此是安全的。但是在读的过程中，似乎可以输出。"}'));jctx.push(JSON.parse('{"id": "181117", "tag": "tool", "text": "# FLTK编译历程\\n\\n为了跨平台，Windows用了GDI，Mac用Quartz，Unix用X11。Fl::scheme可以简单地设置风格，效果一般。\\n\\n要想编译后的程序没有背景的cmd窗口，编译选项要增加`-Wl,--subsystem,windows -mwindows`。\\n\\n> the effect of -mwindows is to\\nadd -lgdi32 and -lcomdlg32 to the list of default libraries (the uwin\\ntarget also adds -luser32), and to pass --subsystem windows to the linker.\\n\\n说明subsystem是无用的，以防万一记录在此。按带cmd方式编译出来的程序，不论是从命令行启动还是界面点击，都会有IO输出。而按windows编译，即使从命令行启动，也不会有输出。\\n\\n链接时，除了fltk和mwindows附带的两个库，还要额外的库`-lole32 -lcomctl32 -luuid`，所以一共是5个windows库。第一个对应dnd，第二个对应TrackMouseMove，网上很多人说user32，可惜是错的，uuid是IUnknown需要的库。\\n\\n窗口函数的运行一定基于事件，风格就是main函数的最后return Fl::run();锁住。实现很简单，判断如果有窗口widget，就开启无尽wait，否则直接结束。windows版实现wait时，会从`ws2_32`库找select函数并等待，具体时间还没看懂，似乎是0.5秒？一旦被唤醒，执行PeekMessageW寻找是否有窗口事件或超时发生。\\n\\n如果要搭配libuv，可以再启动一个线程比如叫`run_layout`，在layout线程中画出布局并Fl::run，layout线程会一直阻塞。主线程join这个layout线线程，就能结合了。\\n\\nGUI必然依赖回调，为避免代码太长显得混乱，套路化的做法是将布局函数layout放在main文件，结构体放在cbfunc.h，回调定义放在cbfunc.cpp。\\n\\n```\\ncbfunc.h\\nstruct stXXX {\\n};\\n\\ncbfunc.cpp\\nstatic void gf_cbdosth(Fl_Widget* fw, void* w){}\\n\\nmain.cpp\\nstatic stXXX sv_xxx;\\n在layout()中对sv_xxx赋值并作为参入传给gf_cbdosth\\n```\\n\\n在布局创建控件后，`widget->callback(sf_dosth, &sv_xxx);`\\n\\n既然是图形程序，配上图标会好看得多，图标等资源的源文件后缀是rc，猜测是resource compile，再用`windres -i xx.rc -o xx.res -O coff`编译成res后缀文件，不指定COFF格式的话无法链接。最后用gcc把res和o文件一起链接成可执行程序。rc是文本文件，格式如下，因为只有一个图标，nameID这栏随便指定没关系。还可以通过rc加上版本号和其它附加信息。\\n\\n```\\nnameID BITMAP filename\\n2  ICON  xx.ico\\n1  VERSIONINFO\\n\\tFILEVERSION     2,3,3,3\\n\\tPRODUCTVERSION  2,3,3,3\\n\\tFILEOS 0x4L\\n\\tBEGIN\\n\\tBLOCK \\"StringFileInfo\\"\\n\\tBEGIN\\n\\t\\tBLOCK \\"080404E4\\"\\n\\t\\tBEGIN\\n\\t\\tVALUE \\"CompanyName\\", \\"NKUCodingCat Co.Ltd\\"\\n\\t\\tVALUE \\"FileDescription\\", \\"NKU-SSS-in-One Project General Launcher\\"\\n\\t\\tVALUE \\"FileVersion\\", \\"1.0\\"\\n\\t\\tVALUE \\"InternalName\\", \\"Launcher on Windows\\"\\n\\t\\tVALUE \\"LegalCopyright\\", \\"GPLv2\\"\\n\\t\\tVALUE \\"OriginalFilename\\", \\"小心使用，谨防水表\\"\\n\\t\\tVALUE \\"ProductName\\", \\"NKU-SSS-in-One\\"\\n\\t\\tVALUE \\"ProductVersion\\", \\"2.3.3 build 42\\"\\n\\t\\tVALUE \\"Comments\\", \\"一群渣渣\\"\\n\\t\\tEND\\n\\tEND\\n\\n\\tBLOCK \\"VarFileInfo\\"\\n\\tBEGIN\\n\\t\\tVALUE \\"Translation\\", 0x0804, 1252\\n\\tEND\\n\\tEND\\n```\\n\\n整体布局会用到Double Window这个类，是Window类的子类，有onscreen和offscreen两个buffer，flush的时候把offscreen copy出来。\\n\\n如果想更灵活地回调，就要继承widget并覆写handle方法"}'));jctx.push(JSON.parse('{"id": "181120", "tag": "tool", "text": "# 音视频解码器的特性\\n\\n音频解码有指标\\n\\n* 比特率范围\\n* 输入通道\\n\\n比特率范围，典型如MP3是8k到320k，FLAC会有1到2^31全覆盖。\\n\\n通道数大抵越低端，用于通信的越少，音乐则多。AMRNB, G711是1个，MP3是2，AAC是6可以5.1声道，Vorbis是8可以7.1声道。FLAC某实现是30(但另一个实现编码只有2通道)。\\n\\n视频解码指标\\n\\n* 帧速率\\n* 比特率范围\\n* 对齐宽高\\n* 支持宽高\\n\\n帧速率大多是1到240全覆盖，也有mpeg4只有12到60。VP8和9是0到960。\\n\\n对齐宽高不论编解绝大多都是2，H263是解4(编码是16)\\n\\n别名3gpp的音频是AMRNB，视频是H263。mp3是mpeg，mpeg4是mp4v-es，aac是mp4a-latm。"}'));jctx.push(JSON.parse('{"id": "181201", "tag": "book", "text": "# 赵括的长平\\n\\n战国人肉磨盘。 \\n\\n 一）\\n\\n韩上党郡守冯亭居然选择投降赵国！\\n\\n受降，不受降？前262年，这道极其棘手但又不能不答的选择题，一下子摆在赵孝成王面前。\\n\\n天上不会掉馅饼。冯亭献地归赵，是绝境奇招，但对赵国来说，却是烫手山芋。 \\n\\n3年前，秦军大举攻韩，先后占领了少曲、高平和野王等地，把狭长的韩国从中截断，一分为二。\\n\\n\\n\\n冯亭辖下的韩上党郡，一下子成了韩国飞地，与本土通路被彻底断绝。 \\n\\n韩桓惠王无计可施，决定把上党献给秦国，以求偏安自保。结果，冯亭宁死不降秦，献上党于赵。 \\n\\n这里面的逻辑，好比当年的联合国军准备明天越过\\"三八线\\"，但是朝鲜今晚居然宣布：自愿成为中国的一个省。\\n\\n二）\\n\\n对于从天而降的上党郡，要，还是不要？这是一个严重的问题。\\n\\n赵国的朝堂上乱成一团，各方激辩。 平阳君赵豹认为不能要，这是“嫁其祸于赵”；平原君赵胜却说，“此大利，不可失”，必须要。\\n\\n上党，战略位置太重要了！ \\n\\n它位于晋东南，涵盖今天长治、晋城两市，太行山、太岳山环绕，山地丘陵纵横，地势险要。\\n\\n\\n\\n古老而神秘的上党，号称天下之脊，“俯瞰中州，肘臂河东、并州，则谓晋国咽喉也”。\\n\\n三家分晋后，上党成为必争之地，最终也被一分为三，韩上党、赵上党和魏上党同时并存。\\n\\n前453年到前280年，170多年里，这个韩赵魏“金三角”，纠纷、冲突、战乱不断，成为当时名副其实的“火药桶”。\\n\\n这里，对内是三晋势均力衡的博弈场，对外是三晋稳固坚实的后盾，也是秦国东向的最大绊脚石。\\n\\n它不单关系着三晋存亡，同时也是秦灭三晋统一中国的最大障碍。\\n\\n三）\\n\\n现在，韩上党面对秦军血盆大口，要把自己的17个县、16万多人口，全部献给赵国。\\n\\n经过反复争论，赵国君臣最终作出痛苦决策：明知这是“嫁其祸于赵”，明知这是虎口夺食，但不能不接受韩上党的投降。\\n\\n因为，韩上党靠西，有太行山天然屏障，是真正的战略要冲，易守难攻。而靠东的赵上党，却是一马平川，无险可守。\\n\\n这说明，韩上党一旦被秦所占，赵上党必将失守；赵上党一旦失守，赵国重镇晋阳和国都邯郸必将不保，面临灭国。\\n\\n不接受，必死；接受吧，起码还有一线生机。痛苦的是，接受之后，能不能守得住，赵国君臣心里无底。\\n\\n顾不了那么多了。赵孝成王终于拍板，进军韩上党长平。就这样，秦赵两军终于要短兵相接了。\\n\\n当时，赵军兵力不过50多万，为了守住长平，赵国陆续出兵20多万，由老将廉颇任主帅。\\n\\n四）\\n\\n一方是综合实力极强的超级大国，一方是国力虽弱但军力不容小觑的地区大国，一场影响历史进程的大战，拉开了帷幕。\\n\\n秦强赵弱，是当时两国实力的客观现实。商鞅变法，郡县之制，奖励耕战，短短几十年，秦国一跃成为强国。\\n\\n秦国拥有巴蜀和汉中两大粮仓，总兵力150多万。相反，地处北方四战之地的赵国，国力远弱于秦。\\n\\n赵国北有匈奴，东有强齐，南有悍魏，西有虎秦，常年战事不断，无法安心搞经济建设，但锻造了赵人彪悍风气。\\n\\n赵武灵王时代，“胡服骑射”，实行“先军战略”，经济一般般，但组建了实力强大的骑兵部队。\\n\\n战国中后期，赵国基本国策是：力求避战，万不得已真打起来，也要速战速决，以胜求和，切忌拖成消耗战。\\n\\n\\n五）\\n\\n这个基本国策，就是“完璧归赵”、“渑池相会”、“负荆请罪”等赵国众多精彩典故背后的逻辑。\\n\\n但是，廉颇老矣，在贯彻基本国策上，并没有取得如期效果。两军相接，赵军数战不胜，“亡一裨将、四尉”。\\n\\n山川河流遍布的上党，不利强于骑兵的赵军。老成持重的廉颇，被迫逐渐依靠深沟高垒，偏向固守。\\n\\n一旦固守，赵国必输。赵国只得展开“以败求和”的外交斗争：秘密地既向魏楚求救，又向秦国求和。\\n\\n秦国“远交近攻”的外交策略更狡猾：高调接待赵使，营造双方正在议和假象。魏楚等国听到消息，中止了援赵念头。\\n\\n外交斗争失败了。一年多时间又过去，上党地区的相持，正在一天一天变成赵国最为害怕的消耗战。\\n\\n六）\\n\\n终于，赵国的后勤开始出现危机，“赵人乏食，请栗与齐，齐王弗许”。国力吃撑不起，不能再拖下去了。\\n\\n “赵王以颇失亡多而更怯不战，数让之”。赵孝成王严厉批评廉颇的固守消磨，他决心换将。\\n\\n问题是，换谁？ 强敌、无粮，无援，无盟友，必死之战。\\n\\n临危有命，无人敢应战：李牧要防范匈奴，乐毅年老多病，田单初来乍到…… \\n\\n赵王焦灼的目光，停留在赵括身上。\\n\\n这个年轻人是将门之后，从小接受严格军事训练，是当时赵军最杰出的少壮派将领。\\n\\n国难当头，赵括毫不犹豫，挺身而出，愿意出战。\\n\\n但是，他妈妈死活不答应，跑到赵王面前抹黑儿子，说他自大贪钱，只会空谈，“愿王勿遣”。\\n\\n这只是一个可怜老母亲的私心，她在用尽办法保护自己的儿子。\\n\\n七）\\n\\n赵括匆匆来到前线，立刻“悉更约束，易置军吏”，谋求与秦军决战。\\n\\n但是，历史并无奇迹，他的运气也太差，唯一的战机稍纵即逝，粮草耗尽。\\n\\n他指挥主力准备渡丹水撤退，在此生死关头，恰逢丹水涨潮，无法徒步涉水，大军陷入重围。\\n\\n肥肉到嘴边，秦国当然不会放过，不惜血本增兵：“秦王闻赵食道绝，王自之河内，赐民爵各一级，发年十五以上悉诣长平。”\\n\\n断粮多日的赵军杀光战马，甚至到了杀老弱病残为食，但赵括保持着镇定，想尽办法突围。\\n\\n他派刺客去刺杀秦军主将白起。可惜，仅刺伤；他找了个替身，冒充自己带队往北突围，掩护主力回撤。\\n\\n秦军杀死假赵括后，以为赵括已死，便对真赵括招降。赵括将计就计诈降，亲自带领剩余的敢死队精锐，冲入秦军。\\n\\n想象一下吧，秦赵两国近60万人厮杀拼命，最终有20多万年轻生命在此消逝。\\n\\n长平，成为“战国人肉磨盘”。\\n\\n这些年轻的生命里，包括赵括。惜墨如金的史书，我们读到了这么不经意但极其悲壮的一笔：\\n\\n“赵括出锐卒自博战，秦军射杀赵括。” \\n\\n不像廉颇那样保守消磨，不像李牧、乐毅那样明哲保身，赵括奔赴国难，英勇地冲锋到最后一刻。\\n\\n “赵卒不得食四十六日”，在赵括指挥下，奇迹般没有崩溃，殊死战斗使秦军死伤极惨重，“秦卒死者过半，国内空”。\\n\\n正是这一战，秦国国力过度损耗和军队巨大伤亡，吃到嘴里的上党终究吞不下去，上党又回到三晋手中。\\n\\n正是这一战，使得魏韩楚等国极为恐慌，唇亡齿寒的阴影迫在眉睫，不得不摒弃前嫌，结成联军，彼此救援。\\n\\n直到三十多年后，前 236 年，秦军才终于彻底占据整个上党。至此，前230年，韩亡；前 228 年，赵亡；前 225 年，魏亡。\\n\\n是的，年轻的赵括，长平一战，为三晋续命长达四十年。他，尽力了！\\n\\n## 长平之战，悲壮的赵括，到底有多少兵？\\n\\n我在前文《长平之战》说了4个数字：长平会战，秦军40万，赵军20万；两国可动员总兵力，秦150万，赵50万。\\n\\n然后，收到很多回复，有些人信心爆棚说我“张嘴就来”、“弱智没跑”，如图： \\n\\n二）\\n\\n长平之战两军兵力，主要史书记述很多，特别是赵军数量，如下： \\n\\n白起……又越韩、魏攻强赵，北坑马服，诛屠四十余万之众。——《战国策•秦策三•蔡泽见逐于赵》\\n\\n秦使武安君白起击，大破赵于长平，四十余万尽杀之。——《史记•秦本纪》\\n\\n白起破赵长平，杀卒四十五万。——《史记•六国年表》\\n\\n秦拔赵上党，杀马服子卒四十余万于长平。——《史记•韩世家》\\n\\n廉颇免而赵括代将。秦人围赵括，赵括军降，卒四十余万皆阬之。——《史记•赵世家》\\n\\n括军败，数十万之众遂降秦，秦悉阬之。赵前后所亡凡四十五万。——《史记•廉颇蔺相如列传》附《赵奢传》\\n\\n括军败，卒四十万人降武安君。武安君计曰：“前秦已拔上党，上党民不乐为秦而归赵。赵卒反覆，非尽杀之，恐为乱。”乃挟诈而尽阬之，遗其小者二百四十人归赵。前后斩首虏四十五万人，赵人大震。——《史记•白起王翦列传》\\n\\n赵师大败，卒四十万人皆降。武安君曰：“秦已拔上党，上党民不乐为秦而归赵。赵卒反覆，非尽杀之，恐为乱。”乃挟诈而尽坑杀之，遗其小者二百四十人归赵。前后斩首虏四十五万人，赵人大震。——《资治通鉴》卷五\\n\\n或“诛屠”，或“尽杀之”，或“悉阬之”，用词各有不同，但一致地认定白起杀光赵国降卒“四十余万”、“四十五万”。 \\n\\n扪心自问，这个数字你信吗？很早就有人表示怀疑，认为是夸大了的，不可信的，例如：\\n\\n“长平坑杀四十万人，史言不足信。败则有之，若谓之尽坑四十万人，将几多所在！又赵卒都是百战之士，岂有四十万人肯束手就死？决不可信。”——朱熹《朱子语类》\\n\\n学习无止境。就我目前所见的有限资料，我赞同这种怀疑，这个数字应该是不准确的。\\n\\n三）\\n\\n战国中后期，七国总共有多少人口？史料中无此数字。据杨宽《战国史》分析：战国末年，总人口2000万左右。\\n\\n但具体到各国，也无资料，但可以合理推断：其中，秦国“秦地天下三分之一，而人众不过什三”，占了30%，大约600万人。\\n\\n汉平帝元始二年，公元2年，按《汉书•地理志》，在原秦朝疆域内人口5755万。即，从秦统一到西汉末两百年间，相同地区人口， 自然增长188%。\\n\\n据此，原赵国极盛时代疆域的人口，元始二年约有643万余，减去188%自然增长数，赵国在战国最高人口在220万左右，占10%多一点。 \\n\\n1）秦赵军力\\n\\n各国征兵，凡年满16至60男子都应服兵役；总人口剔除一半女性，男性剔除40%-50%官僚贵族和15岁以下、60岁以上的老小弱病残。\\n\\n长平之战前，赵国兵员潜力最大约为50万；秦国约为150万。这就是两国拥有可动员的最大限度总兵力。\\n\\n但是，可动员总兵力不等于实际拥有的兵力。一个国家，不可能每个成年男子都去打仗，否则，没人种田，没人搞后勤，国家停摆。\\n\\n一般二丁抽一，那么，赵国实际拥有的常备军应该是30万左右，秦国大概75万。\\n\\n战国中期起，各国战争规模日益扩大，一些大国逐渐能够出动10万、20万人参战。\\n\\n秦统一前夕，前223年，灭楚大决战，“空秦国甲士”，王翦统兵60万，为战国用兵最高纪录。\\n\\n时间更早的长平之战，虽然也是秦赵大战，但毕竟不是生死存亡的灭国决战，两国不可能倾全国之兵去打。 \\n\\n2）长平兵力\\n\\n韩上党归赵，到口肥肉被夺，前260年，秦将王龁击上党，赵将廉颇军长平。一开始，只是一场争城夺地战。\\n\\n赵国方面，长平之战前几年，赵军打大仗，往往“必负10万、20万之众”，相国田单曾颇有微词，认为出兵太多“使民不得耕作”。\\n\\n另外，赵国是“四战之国”，边防不能空，都城邯郸要拱卫，长平之战赵国没理由倾国出动，把全部兵力都押出来。\\n\\n合理推断，按赵国惯例，投入长平的军队，撑死了也就20万左右，国家常备军的三分之二。\\n\\n秦国方面，战争初期，主将是王龁，他的官职是左庶长，爵位只有十等，类同今天副军级。\\n\\n那时他又无显赫战功，也没有什么名气，一贯精明的秦国王室，肯定不会轻易派过多军队由他指挥。\\n\\n前225年，两套灭楚方案，王翦用兵60万，李信用兵20万。结果，秦王采纳了李信方案，只肯出兵20万。\\n\\n考虑到王龁与名将廉颇对抗，几次打赢，可见他的兵力一定多于赵军，合理推测在30万左右，秦军的二分之一。\\n\\n3）秦军增兵\\n\\n战争过程中，赵军并无增兵行动。\\n\\n起初，赵军失利，赵王确实想“卷甲而趋之”，增派军队，不料遭到大臣楼昌、虞卿反对而作罢。\\n\\n后来，赵括代替廉颇为将，“括至军，悉更约束，易置军火，出兵击秦师”，也没说他带来援兵。\\n\\n当赵括被彻底包围时，赵和楚齐都发出紧急援军，可惜，都被秦军阻挡，未能进入核心战场。\\n\\n秦国，前期不曾增兵，更换主将白起，“令军中有敢泄武安君将者斩”，采取秘密易帅行动，更不可能增兵。\\n\\n直到白起分割包围赵军，秦王才亲自到达附近河内郡，大张旗鼓征发15岁以上丁壮组成援军，以“遮绝赵救兵及粮食”。\\n\\n秦汉河内郡地域相同，元始二年该郡人口106万，188%增长率，当时人口应在35万左右，能征发新兵约10万。\\n\\n长平会战，赵括的兵不过20万，秦军加上增兵，最多40万。这两个数字，已是往大了算。\\n\\n\\n四）\\n\\n反过来看，所谓秦军“杀赵卒45万”，或者说“活埋”，是无法让人相信的。\\n\\n1）技术难题\\n\\n兵法有“十则围之，五则攻之”原则，如果赵军真有45万，还被包围长让46天，秦军不得有450万人？就算打个四折，也得180万人。\\n\\n显然，这是不现实的。\\n\\n如果不是全国所有成年男子出动，白起再能打仗，就算75万常备军都用上，包围45万赵兵，并将降俘全部杀死，也是不可能的。\\n\\n南京大屠杀，屠杀30 多万人，据说持续长达六周。冷兵器时代，杀40万人，或者活埋，技术上怎么解决？\\n\\n需要多少人执行？需要多少时间？斩杀？射杀？活埋？深坑怎么挖？土方怎么来？赵卒会不会反抗？是否捆绑？绳子怎么来？……\\n\\n2）时人记载\\n\\n总人口只有2000万的时代，短短几天40万人同时死亡，对时人得造成多大的心理冲击呢，“赵人大震”！\\n\\n但是，长平之战同时代的人，绝大多数都无提到过“杀赵卒45万”之事。\\n\\n当事人如白起、范睢、廉颇、赵胜、虞卿等人，在先秦史料记载里，只写到“大收赵师”，“赵军大破”、“死者十之七八”，等等，强调的是赵国吃了个大败仗。\\n\\n荀子、吕不韦、韩非等同时期的大学者，他们的著作，不只一次谈到长平之战，但也无“坑赵卒40万”的描述。\\n\\n荀子本身是赵人，50岁后才离开赵国，《荀子》里只讲到长平之战韩上党地方数百里被秦国夺取，并无提到赵军伤亡人数。\\n\\n长平僵持期间，荀子一度受命去秦国展开外交谈判，他由此见识了“强秦之风”，这段文字极有意思，全文照录：\\n\\n“应侯问孙卿子曰：‘入秦何见？’孙卿子曰：‘入境，观其风俗，其百姓朴，其声乐不流污，其服不挑，甚畏有司而顺，古之民也。及都邑官府，其百吏肃然，莫不恭俭、敦敬、忠信而不楛，古之吏也。入其国，观其士大夫，出于其门，入于公门；出于公门，归于其家，无有私事也；不比周，不朋党，倜然莫不明通而公也，古之士大夫也。观其朝廷，其朝闲，听决百事不留，恬然如无治者，古之朝也。故四世有胜，非幸也，数也。是所见也。故曰：佚而治，约而详，不烦而功，治之至也，秦类之矣。虽然，则有其諰矣。兼是数具者而尽有之，然而县之以王者之功名，则倜倜然其不及远矣！’‘是何也？’‘则其殆无儒邪！故曰粹而王，驳而霸，无一焉而亡。此亦秦之所短也。’”——《荀子·强国篇》\\n\\n他一路所见，秦国民风简朴守法，社会充满活力朝气，官僚机器高效廉洁。更重要的是，秦国剑宗治国，朝野普遍对儒家不感兴趣，“无儒”。\\n\\n荀子是儒家气宗高手，德治派大师，他那一套高大上理论在秦国根本找不到共鸣，外交使命失败，只好酸溜溜说“此亦秦之所短也”。\\n\\n先秦史料里，唯一的孤证，是《战国策•秦策三•蔡泽见逐于赵》里，蔡泽说的话：白起“北坑马服，诛屠四十余万之众”。\\n\\n蔡泽是什么人？说客一个，被赵国驱逐出境，屁颠屁颠跑到秦国求官，这样的人说的话，能有多少可信度？\\n\\n3）战后局势\\n\\n长平之战后不久，秦国又大举伐赵，用兵规模超过长平，“三军之俸，有倍于前”，军队数量也“倍其前”。\\n\\n秦军一度进围邯郸。但是，赵军顽强抵抗，又得到楚魏支援，打得秦军“弃甲负弩，战悚而归”。\\n\\n可见，如果长平之战，赵军真的损失45万，已超出常备军数量、占全国丁壮十分之七八，在几年内，赵国怎能神奇般地再有足够兵员抗敌？\\n\\n五）\\n\\n《史记•白起传》白起自己说，长平之战秦军虽大获全胜，但也付出了“秦卒死者过半”的惨重代价。\\n\\n号称“虎狼之师”的秦军付出“死者过半”代价，40万人只剩20万，作为败方的赵军，伤亡只会更多。\\n\\n经过廉颇、赵括与秦军多次搏杀，再加上被围中饿死、被“阴相食”、溃逃的，决战阶段，20万赵军，可能只剩不到6、7万人。\\n\\n当赵括冒险突袭，他亲率的敢死队不会超过1万人。因此，白起才能只用2.5万人就能将赵军后路切断并形成包围圈，另用5千骑兵将赵括主阵地穿插突破、并实行围歼。\\n\\n赵括死后，战役结束，最后活下来投降并被杀死的赵卒，也许也就3、4万人。 \\n\\n近年来，山西长平古战场考古陆续发现尸骨坑，如典型的“长平之战遗址永录 1号尸骨坑”。\\n\\n\\n\\n1996年第6期文物杂志《长平之战遗址永录 1 号尸骨坑发掘简报》，坑内百余具尸骨，经鉴定，为“赵军亡卒”，死亡原因并不是“活埋”：\\n\\n“坑内人骨皆为男性；30 岁左右的最多，20岁 以下者甚少，但 45 岁以上的士卒占有一定比例，平均身高约 170 厘米。根据骨骼排列和创伤观察，死者绝大部分为被杀后乱葬的，未发现大量被活埋的证据，这种现象有别于史书关于四十万降卒被阬杀的载述。”\\n\\n历史求诸野，最好的历史，在田野里。感谢考古的发现，让我们有机会瞻仰一下，2200多年前这些英勇无畏的“赵括的兵”：\\n\\n\\n\\n六）\\n\\n《战国策》里蔡泽夸大说辞，是为了大拍秦国马屁，以便求官。司马迁《史记》，为什么也要夸大秦杀赵降卒数量？\\n\\n合理的解释，应该有二：\\n\\n首先，中国古代战争，夸大战场杀伤数，往往是一种难以根治、也无法根治的通病。\\n\\n《三国志•魏书•国渊传》明确指出其中奥秘，军中惯例就是“破贼文书，旧以一为十”，千百年来相沿成习。\\n\\n这种“夸大”，战胜方用来邀功请赏；咳咳，战败方也可用来宣传己方“惨重牺牲”，既可将敌方置于不义地位，又可激励自己，团结民众。\\n\\n其次，秦末汉初，因为反秦的政治需要，普遍存在极力抹黑、夸大前朝残暴、黑暗的行为，咳咳，以证明自己造反夺权的合法性。\\n\\n另据考，司马迁六世祖司马靳曾作为白起副将参加了长平之战，后因秦王猜忌白起而和白起一起被赐死。\\n\\n国仇家恨，集于一身，通过“夸大”长平之战“杀赵降卒”强化对“暴秦恶政”的定性，反衬大汉代秦是历史必然，人民选择，不亦可乎？\\n\\n长平之战，赵括惨败，根源在于秦强赵弱。外无援国，内无援兵，外交失败，就算仍让廉颇主军，或换了别的谁，结局估计也好不到哪里去。\\n\\n无非，一是继续困守，坐以待毙；一是组织一次成功突围，挽救部分赵卒生命。两种结局，终归是败。 \\n\\n秦军虎狼之师的背后，是剑宗治国，是赫赫武功，是强大综合国力。\\n\\n没有实力和铁拳的保障，天天喊破喉咙“厉害了我的赵”，赵括和赵括的兵们再英勇无畏，留下的也只能是悲壮的身影。\\n\\n## 赵括之为将也，壮哉！\\n\\n一）\\n\\n从赵国一贯的国策出发，廉颇领命之时，肩负的战略使命，肯定本来就是：主动攻击、速战速决。\\n\\n “赵使廉颇将攻秦。”——《史记•廉颇蔺相如列传》\\n\\n “四十七年，秦攻韩上党，上党降赵，秦因攻赵，赵发兵击秦。”——《史记•秦本纪》\\n\\n“四月，龁因攻赵。赵使廉颇将。赵军士卒犯秦斥兵，秦斥兵斩赵裨将茄。六月，陷赵军，取二鄣四尉。七月，赵军筑垒壁而守之。秦又攻其垒，取二尉，败其阵，夺西垒壁。”——《史记·白起王翦列传》》\\n\\n你看，两军一接触，“攻”、“击”、“犯”，首先主动进攻的，不正是赵军吗？\\n\\n可惜，在廉颇指挥下，4到7月战况，连失两道防线，损一裨将六尉，开局不利，丧失战场主动权。\\n\\n老成持重的廉颇，根据实际战况，擅自把战略方针调整为持久防御，“廉颇坚壁以待秦，秦数挑战，赵兵不出。赵王数以为让。” \\n\\n\\n\\n从纯军事角度看，这种调整，或许是可取的。遗憾的是，打仗从来不是纯军事问题。\\n\\n赵国领导层反复督促廉颇恢复主动攻击战略，但是，廉颇始终不听，赵王只好临阵换将。\\n\\n这情形，与朝鲜战争中美国撤换麦克阿瑟相似：国家领导层与前线指挥员在军事战略上根本分歧，不换思想就换人。\\n\\n廉颇打仗一向谨慎，不擅长打势均力敌的硬仗。此前，他只成功指挥过对齐、魏的战争，从无打赢秦军的记录。\\n\\n前270年，阏与之战，赵王本想请廉颇或乐乘出征，但两人认为打不赢，拒绝了；最后，是赵括之父赵奢挺身而出。\\n\\n同样是“道远险狭”，廉颇、乐乘看到的是失败，而赵奢看到的是胜利。他说出了一句极具英雄气概的话：“狭路相逢勇者胜！”\\n\\n秦伐韩，军于阏与。王召廉颇而问曰：“可救不？”对曰：“道远险狭，难救。”又召乐乘而问焉，乐乘对如廉颇言。又召问赵奢，奢对曰：“其道远险狭，譬之犹两鼠斗于穴中，将勇者胜。”王乃令赵奢将，救之。——《史记·廉颇蔺相如列传》\\n\\n显然，捐躯赴国难，是老赵家一贯的家风、家教。阏与之战是父亲，长平之战是儿子。\\n\\n二）\\n\\n前266年，秦昭王的“权威人士”范雎正式出任秦相，他主要干了三件大事：\\n\\n一是帮助秦昭王从宣太后手中夺回君权：二是提出“远交近攻”方针；三是以报私仇为名，试探各国战略底线。\\n\\n“远交近攻”非常高明：“毋独攻其地，而攻其人” ，战争重在削弱敌有生力量；“得寸则王之寸, 得尺则王之尺”，一旦夺地，务在巩固。\\n\\n范雎公开复仇，追杀魏相魏齐。魏齐逃亡，只有赵国平原君赵胜留他在府中暂避一时，各国均不敢收留。\\n\\n赵胜为什么胆敢收留魏齐？仰仗阏与之战的余威，认为赵国能与秦人一拼。嗯，极力劝说赵王接受韩上党的，正是他。\\n\\n的确，当时除赵国外，关东各国均受重创，各国都把抗秦希望寄托在赵国，“天下之士合纵，相聚于赵，而欲攻秦” 。\\n\\n\\n\\n秦国东进，须击破赵。秦赵争强，是秦国兼并战争中最为棘手的。阏与之战，赵国先胜一场。\\n\\n但是，随着范雎主掌秦政，充分进行军事、外交全面准备，秦国重新启动“东进战略”，咄咄逼人。\\n\\n魏国首先屈服，与秦人结盟。长平之战、邯郸之战中，魏国始终作壁上观，甚至力劝赵国投降。\\n\\n至于韩国，与秦国地形相错，自身难保。长平之战前，无力应战，宁愿割让韩上党领土。\\n\\n可以说，长平之战前，秦人已经彻底打开通向赵国的门户，失去“合纵”支撑的赵人，被迫单独正面应战。\\n\\n\\n三）\\n\\n单独应战的赵国，输在综合国力。须知，“秦富十倍天下”，秦之富强，首在粮食。\\n\\n战前，秦以“耕战”立国，拥关中、成都、江汉和河东四大产粮基地，耕地总面积和粮食产量远超各国。\\n\\n反观赵国，粮食产区仅有以晋阳、邯郸为中心的太原-漳滏区域，耕地面积、土地肥沃程度，与秦国没法比。\\n\\n且赵国长期执行重商轻农政策，赵烈侯、赵武灵王变法都无涉及农业，相反，商业极发达，邯郸是当时最著名的商业之都：\\n\\n“商家错于道，诸侯交于路。然民淫好末，侈靡而不务本。田畴不修，家无斗筲。”——《盐铁论》\\n\\n技术上，秦国已普遍掌握农业“先进核心技术”，嗯，牛耕。平阳君赵豹反对接受韩上党时就说：“且秦以牛田，水通粮。”\\n\\n物资运输上，秦河东向长平运粮，距离不足200公里，与邯郸到长平距离相当，且水陆交通状况要好很多。\\n\\n战国秦汉之际，中原陆战，早已从战车集群形式进化为以步兵为主的鏖战。战车对地形要求太高，且造价贵，战国时已退居辅助角色。\\n\\n战国七雄逐步建立君主集权政体，世袭贵族退场，农民中征发的步兵成为战场主力，列国争战的规模越来越大。 \\n\\n别以为赵军“胡服骑射”很牛逼，当时马镫、马鞍等“杀手锏”装备尚未发明，骑兵难以担当高速冲杀肉搏主战任务，只能进行配合性任务。\\n\\n步兵数量多，行动缓慢，作战旷日持久，军粮消耗量大，后勤运输成为维持战争、赢得战争的关键要素。\\n\\n这个关键因素，正是赵国的短板。果然，长平之战开打三年多，赵国粮食储备开始严重不足，“赵无食，请粟于齐，齐不听。”\\n\\n与魏韩不同，齐国见死不救，楚国也毫无动静，除了害怕秦人，更多是因为两国领导人恰好更替，处于新旧内政过渡期。\\n\\n其实，赵国接收韩上党，一开始得到齐楚支援的允诺。《赵国策·齐策二》：“秦攻赵长平，齐、楚救之。秦计曰：齐楚救赵，亲，则将退兵；不亲，则且遂攻之。” \\n\\n可见，秦国几乎要退兵。随着外交威慑、收买的进行，加上齐楚国君变换，齐楚“不亲”，秦军彻底解除后顾之忧。\\n\\n前 264 年，无能的齐王田建继位；前263年，楚考烈王返国接班，嗯，他一直在秦国做质子，与秦相范雎是铁杆。\\n\\n赵国实力不如，内政外交备受挫折：赵惠文王 、赵奢、蔺相如等一批成熟政治家相继去世；完全失去魏、韩、齐、楚的支援。\\n\\n是的，这就是赵括匆匆走马上任时面对的绝境。如果他拒绝，相信也没有人会强迫他，但是，他没有。\\n\\n四）\\n\\n前260年7月，对赵国而言，和平的希望已彻底破灭，接下来该怎么办？\\n\\n撤军吧，意味着失去太行山以西大片领土，包含赵氏发祥地赵城和经济重镇晋阳，战败结果也不过如此。\\n\\n持久防御吧，粮食储备无力支撑，如僵持到粮食消耗一空，前线大军也会不战自溃、全军覆没。\\n\\n综合衡量国情、军情、敌情，继续执行既定的“主动攻击”战略，已是当时所能作出的最佳抉择。\\n\\n\\n\\n主动攻击，狭路相逢，或有一线胜机，就算最终战败也可大量消耗敌人有生力量，总好过不战自败。\\n\\n赵括带着“速战速决”的命令上任，根本没有足够时间从容运筹，一抵达前线就“悉更约束”，立刻展开战斗。\\n\\n赵国领导层从众多文武大臣中挑选赵括，毅然将国家命运和二十万将士性命托付于他，你真相信是秦人反间计？\\n\\n你想过没有，如果赵括只是夸夸其谈的废柴一个，秦国何必临时派出他们的“大杀器”白起过来指挥呢？\\n\\n白起是什么人？战国绝世名将，前后指挥秦军击败楚、韩、魏、赵等强敌，拓土数千里，为秦国一统天下奠定基础。 \\n\\n当时，他率军驻扎在秦楚边界，威慑防范楚国。直到长平决战开始时，才暗中连夜赶往长平前线。\\n\\n后来惨烈的战况证明，赵括之为将，率军20万，如果秦军不是由白起指挥，或许胜负未可知。\\n\\n五）\\n\\n战后，40万秦军伤亡大半，白起明确讲：“今秦虽破长平军，而秦卒死者过半，国内空”。\\n\\n王龁指挥时，秦军屡战屡胜，阵亡人数不会太多，绝大部分伤亡是与赵括拼死决战造成的。\\n\\n“发现8例头部有砸痕或钝器致伤的标本。D2.1号个体颈骨前有砂石块，长13厘米、宽7厘米、厚7厘米，类似大小的砾石1号坑内已发现10余件。”——《长平之战遗址永录 1 号尸骨坑发掘简报》\\n\\n啥意思？说明两军中很多将士曾用石块等近身肉搏，可见战斗之惨烈。\\n\\n另外，丹河两岸流传至今的地名，如血泊、血山、血昏河、骨头坡等，也间接佐证了这一点。\\n\\n白起作为主将，先后指挥了新城之战、伊阙之战、鄢郢之战、华阳之战、陉城之战、垣城之战等所有重大战事。\\n\\n你仔细分析可发现，长平之战是他指挥的所有战事中损失最惨重的，也是战国时期秦国所有战事中损失最惨重的。\\n\\n正是长平之战中，秦军损耗巨大，导致此后邯郸之战、河外之战、新中之战连遭惨败，“秦军退回河西”。\\n\\n是的，在与白起交手的所有将领中，年轻的赵括，表现是最出色的。\\n\\n须知伊阙、鄢郢、华阳之战，暴鸢、公孙喜、芒卯与楚顷襄王指挥的韩、魏、楚虽被白起杀死、淹死数十万，却无一能给秦军造成重大损伤。\\n\\n鄢郢之战，白起以几万人攻陷楚国数十万大军防守的核心城市鄢和郢，淹杀楚人数十万，夺取楚国经营数百年的基业江汉平原，楚国从此一蹶不振。\\n\\n两相对比，面对“战神”白起和兵力多一倍的虎狼之师，赵括指挥大军在野战中鏖战两个月，杀敌大半，给予秦军战国时代最高记录的死伤。\\n\\n况且，在无粮、无援的绝境之中，他指挥的20万大军，始终坚持鏖战，没有崩溃，直到主帅身死那一刻才放弃抵抗。\\n\\n同样的一批兵，廉颇指挥时屡战屡败，赵括指挥时却能予秦军前所未有的巨大杀伤，这是一个嘴炮能做得到的事吗？\\n\\n赵括之为将也，不亦壮哉？\\n"}'));jctx.push(JSON.parse('{"id": "181202", "tag": "book", "text": "# 天启的另一面\\n\\n## 帝国的木工\\n\\n一）\\n\\n在腾讯视频看了电影《绣春刀2·修罗战场》，拍得可以，故事的编排也很有意思。\\n\\n片中，北斋先生，东林党人，要杀魏忠贤，要换皇帝，弟弟朱由检\\"谋害\\"皇兄朱由校，在龙船上做手脚。\\n\\n最后，床上病恹恹的哥哥对弟弟说：“来，我弟要做尧舜。”就这样，弟弟赢了，东林党赢了。\\n\\n这个小情节，正史有记载。1627年，兄终弟及，朱由检从哥哥手中接过帝位，成为明朝崇祯皇帝。\\n\\n他上台3个月，在东林文官簇拥下，将魏公公“阉党”一网打尽。东林党弹冠相庆，变天了，好日子到了！\\n\\n极具讽刺意味的是，弟弟信东林，杀“阉党”，用文官，大明并没有实现中兴，反而一步一步走向灭亡。\\n\\n17年后，李自成杀入北京，弟弟上吊自杀，身边没有一个东林官僚，陪伴他的却是一个阉党王承恩。\\n\\n二）\\n\\n哥哥朱由校，是帝国的第15个皇帝，年号“天启”，庙号“熹宗”，1620年九月初六登基，1627年八月十一日病亡。\\n\\n哥哥只活了23岁，只做了不到7年的皇帝。在明末时期写就的大量文章里，哥哥常被讥笑，人送外号“木匠皇帝”。\\n\\n他们讥笑他痴迷木工，不务正业。“圣性又好盖房，凡自操斧锯凿削”，“每营造得意”，忘记吃饭，忘记寒暑。\\n\\n他们讥笑他傻不拉叽上了魏公公的当，大肆用贪财的“阉党”，而不用“爱国”的东林读书人，贻误江山，云云。\\n\\n文章都是读书人写的。当时，东林党是最大的读书人，以江南士大夫为主的官商集团。哥哥信公公，用公公，深深得罪了那帮文臣官僚。\\n\\n哥哥是聪明人，就是死得太早。在位短短七年，他和他信任的公公执政团队，领导军民打赢了几场大仗。\\n\\n这些仗，对内对外都有，例如，平息山东白莲教、在澎湖打败荷兰，辽东“宁远大捷”，原本艰难的朝局焕然一新。\\n\\n三）\\n\\n我们把目光放“木匠皇帝”四个字。这个用来讽刺哥哥的外号，背后隐藏的却是另一番宏大故事。\\n\\n时间往前推移，1597年，明神宗万历二十五年六月十九日，皇宫又突起大火，把皇宫“三殿”烧个净光。\\n\\n“三殿”在当时名叫皇极殿、中极殿和建极殿，即今天故宫太和殿、中和殿和保和殿。这是帝国最高级别的政治建筑。\\n\\n三殿，是帝国脸面、国家象征。三殿尽毁，如同美国白宫、国会大厦、自由女神像一夜之间被恐怖分子炸掉。\\n\\n这场大火对帝国政治生活的严重冲击，要有多大就有多大。正常情况下，三殿需要马上重建，刻不容缓。\\n\\n但是，如此重大而紧迫的国家头等大事、超级工程，朱由校的爷爷明神宗，终其余生，都没有重建起来。\\n\\n整整23年过去，在紫禁城里，光秃秃的三殿遗址，犹如帝国面上的三块癞疤，成为无言的耻辱！\\n\\n\\n四）\\n\\n三殿建不起来，不是不想建，而是“没法建”。火灾过后，惊魂未定的明神宗要求文官内阁“即议修复”。\\n \\n工部很快提交“大工”预算：白银3000万两。把神宗吓呆了。天啊，这可是户部10年的财政盈余！\\n\\n当时，帝国财政已捉襟见肘。户部太仓每年额收税银不过300万两，而“九边”一年军费就超过此数。\\n\\n边军年年缺饷，户部时时告穷。用神宗的话说，“官民两竭”。工部提出的这个天量预算，怎么拿得出来？\\n\\n为了筹钱，文臣内阁提出了很多办法，诸如开征矿税、复征罚脏银两、汇积各省财政结余、发动官民捐献，等等。\\n\\n可惜，这些政策，一如既往在庞大官僚系统手里变了样，成了层层经办人中饱私囊的绝佳机会。\\n\\n几年下来，筹钱不到百万，连预算零头都不够，反而造成民怨四起。神宗放弃治疗了，在剩余的23年皇帝生涯，他龟缩偏殿办公。\\n\\n五）\\n\\n这时，哥哥朱由校匆匆上台。他刚满16岁，身边有个53岁的老太监，不是别人，魏忠贤公公。\\n\\n出身贫穷的魏公公，入宫30年，头发熬白了，才从底层倒马桶太监，晋升为东宫太子一个才人的伙食管理员。\\n\\n命运很奇妙。这个才人，恰好为太子生了一个长子。公公伺候才人，自然而然也连带伺候这个小皇孙。\\n\\n煎熬了那么多年，公公极度珍惜这份工作，对才人和小皇孙有种说不出的忠诚与依恋，伺候主人一丝不苟，全力以赴。\\n\\n公公手把手将小皇孙带大。想象一下，400多年前，夕阳从紫禁城头落下，公公抱着小皇孙，絮絮讲故事、哼歌曲。\\n\\n在那十几年的岁月里，公公一定会讲到皇宫里三殿遗址的耻辱，讲到重建预算大到离谱，讲到征税过程中官员的贪墨。\\n\\n这个小皇孙，就是哥哥朱由校。因这层关系，他与公公的感情，他对公公的信任，异乎寻常的不一般。\\n\\n六）\\n\\n朱由校决心重修三殿。他即位之初，马上下诏：“传起建皇极门殿，择日兴工。”\\n\\n对于工部的天量预算，他怀疑，他不信。他用了最笨但也是最好的办法：自己学木工，钻技术，分贤愚，辨忠奸。\\n\\n哥哥真的沉下心去学。他聪明，学得快，“自操斧锯凿削，巧工所不能及”，他成了建筑工程专家。\\n\\n哥哥的任职日志《明熹宗实录》，记载了他掌控三殿重修的各个关键施工环节：兴工礼、立金柱、升金梁、竣工典……\\n\\n天启六年九月，“皇极殿成”。次年，“中极、建极殿成”。作为帝国权力象征的三殿，终于再次屹立在紫禁城里。\\n\\n哥哥重建三殿，实际上花了多少钱？睁大眼，看清楚，一共是白银5957519.7684161两。\\n\\n你并没有看错，就是这么变态，精确到小数点后7位。这个数字不是我编的，是明朝的官方文告：\\n\\n“工部奏，三殿大工……报竣，……所费银计五百九十五万七千五百一十九两七钱六分八厘四毫一丝六忽一微。”——《明熹宗实录》\\n\\n七）\\n\\n以前，每逢为内廷兴建或修葺工程，工部官僚冒领工料价款、贪污中饱已成惯例。何况修三殿属于大工，更是机会难得。\\n\\n现在，他们遇到“木匠皇帝”，真正的内行，专家中的专家。\\n\\n工程的猫腻，官员的伎俩，逃不过他法眼。竣工决算精确到小数点后7位。\\n\\n600万两与3000万两，差距达2400万两，文臣官僚虚报工价高达5倍之多。\\n\\n胆敢联合起来蒙骗朕！太黑了，这才是真正的祸国殃民。\\n\\n东林党文官在皇帝眼里一文不值，公公们得到极大重用。天启五年，皇帝诏令烧毁全国书院。\\n\\n魏公公也贪，但是，他所有的赃款加起来，也很难超过2400万两。而且，公公们忠心，人少，办事高效，远比当时的文臣官僚强。\\n\\n信任，才是要害。有明一代，层出不穷的“宦官专权”现象，骨子里揭示的正是皇帝对文臣官僚系统的不信任。\\n\\n极其诡异的是，三殿刚完工，哥哥莫名其妙从龙船上“落水”，很快病亡。弟弟是亲王，没受过系统的、真正的帝王之术教育。\\n\\n他接班后，东林党日夜在他耳边忽悠，“太监都是奸臣，是卖国贼”，“东林党个个是圣人君子，是爱国英雄”。\\n\\n志大才疏、刚愎自用的弟弟真信了。上台后立刻铲除“阉党”。崇祯二年，为东林党恢复名誉，大加重用。\\n\\n就这样，哥哥苦心经营、原本有很大起色的国事政局，逐步好转势头被彻底破坏，重走回头路。\\n\\n自私自利、内斗误国的东林党空前膨胀，这帮家伙，一贯擅长文宣，标榜人间楷模，口口声声为大明，说的比唱的好听，就是不干人事。\\n\\n弟弟心中的“大明梦”，最终彻底幻灭。\\n\\n1644年，崇祯十七年四月三十日，李自成撤出北京，一把火将紫禁城焚毁，哥哥亲手重建的三殿复为灰烬。\\n\\n## 东林为政\\n\\n 一）\\n \\n1620年九月初六，哥哥朱由校登基，一开始他重用的人，其实还不是魏公公，相反，是东林党人。\\n\\n那时，哥哥对满口子“爱大明”的东林党抱有期望。东林党人得以主掌内阁、都察院及六部，杨涟、左光斗等众多大佬身居要职。\\n\\n当家了，朱由校拿来财政报表一看，登时傻眼：除内库尚余七百万两，外库居然已经枯竭很久了。\\n\\n内库，供皇室日常御用，属于皇帝私房钱；外库，也叫太仓，属于户部国库，“专供军国”。\\n\\n当时，帝国总收入折合白银约1500万两，其中入内库600余万两，入外库400余万两，剩下的大多为实物。\\n \\n蛋糕远远不够分。外库枯竭，财政赤字好几年了。当时，单是“九边”兵饷一年就要380余万两，几乎用尽外库岁入。\\n \\n除正常边饷经费，还有战事的临时专项军费。随着辽东抗清战事频起，战费开支骤然锐增。\\n\\n哥哥让户部作了统计，他上台前3年里，1618年—1620年，共计发辽事银2018万余两，平均每年超过600万两！\\n\\n二）\\n\\n仅以辽事开支计，外库每年赤字200余万两。这盘烂帐，哥哥算不过来了。他要求执政的东林党想办法。\\n\\n“风声雨声读书声，声声入耳；家事国事天下事，事事关心。”这是挂在东林书院门口的一副对联，你们肯定听过吧。\\n\\n在《明史》里，东林党被赞美成了一朵花：正人君子，正气凛然，可歌可泣，人间楷模，“众正盈朝”。\\n\\n当然，这些赞美的话语，还有那些臭骂“阉党”的篇章，看看就好。这些文字，大多是东林党所在的江南士人所写。\\n\\n看一个人，不要只听他说了什么，而要看他到底干了什么。\\n\\n东林党的老巢是无锡东林书院，书院的背后是江南大土豪大财阀。金钱滋养下，书院培养出来的人才，做官后自然以维护财阀利益为己任。\\n\\n东林党很像嘴炮党，不干事的文青圣母。他们的政纲有两条：税收得越少越好，特别是商税；皇帝管的越少越好，事情由我们来管就好了嘛。\\n\\n面对内忧外患的朝局，面对外库可怕的财政赤字，东林党首先提出了他们的第一套解决方案：发内帑。\\n\\n啥意思？陛下，外库虽然没钱了，您的内库里不是还有几百万两白花花的银子嘛，先拿出来用呗。\\n\\n是的，东林党提出要用皇宫内库的钱，为了抗清，为了国家，哥哥毫不犹豫答应了。\\n\\n史载，哥哥上台后，朝廷先后5次发内帑“劳边”，共花白银500万两。后来，重修“三殿”的费用还得东拼西凑，内库很快枯竭。\\n\\n\\n三）\\n\\n内库虽然花光，但东林文官把持下的辽东战局，毫无起色，边饷还是一刻不能停。怎么办？东林党又提出第二套方案：造钱。\\n\\n开动印钞机，天启二年七月，东林党内阁在北京和南京正式开铸“天启通宝”。\\n\\n造钱不是重点，关键在于纪值：看清楚，是“折十大钱”。一枚小小的破钱，被强制要求价值“十两”，津巴布韦货币1后面多少个0？\\n\\n结果，大财阀乘机买田买房买物，把货币换成实物资产，享受通胀升值。而广大草民蚁族购买力极大被剥削，陷入更为困难境地。\\n\\n还有比这更黑的吗？毫无意外，这个赤裸裸的货币超发抢钱计划，实在是太狠了，很快就不得不流于失败。\\n\\n一计不成，一计又起。“有道德，有理想”的东林党又从工具箱里拿出了第三套方案：加税。\\n\\n从他们一贯的政纲出发，这个加税计划其实很有意思，很好玩：\\n\\n只加田赋，不加商税；商税不但不加，还要减税；只在农民身上割肉，把丝织业等非农税赋减为原来的33%。\\n\\n咳咳，江南地区是全国最大的丝织产业基地，懂了吧。\\n\\n很多东林党大佬，家族都有庞大的工商业，有的甚至经营着垄断企业。他们是大官商集团，怎么可能在自己身上割肉？\\n\\n四）\\n\\n东林党执政三年，花光了内库积蓄，割了小农的肉，肥了官商自己的腰包，败坏了辽东战局。\\n\\n聪明的哥哥，杰出的建筑工程专家，逐渐看清了一切。再也不能这样子下去了。魏公公正式登场。\\n\\n天启四年六月以后，“内外大权一归忠贤”。事情很快立竿见影，就在当年，帝国税收构成发生了180度转变：商税突然占据了大头。\\n\\n天启四年，帝国商税从上一年的322万两猛增至548万两，净增226万两，增幅达70%。\\n\\n天启四年，主要针对工商业的杂项银从上一年的60万两猛增至220万两，净增160万两，增幅达270%。\\n\\n这样的增幅，接下来的两年都得到了保持。更为重要的是，天启四年后，帝国基本没有针对农民的加赋。\\n\\n短短一年，帝国多收入的400万两白银，全部来自江浙地区工商业。你说，把持工商业的东林党，能不恨公公入骨吗？\\n\\n东林党对“阉党”发起猛烈攻击。可惜，公公们不是吃素的。在刺刀见红的斗争中，东林败下阵，一个个被陆续收拾。\\n\\n400多万商税，每一两都是魏公公真刀真枪从东南大官商集团手里抢出来的。你以为轻描淡写约谈一下，他们就肯乖乖补交几亿税款？天真！\\n\\n\\n\\n《五人墓碑记》记得吧？这篇“奇文”的作者，是东林大文人张溥。文中，他用生花妙笔，歌颂五人为“反抗暴政”的大英雄。\\n\\n朝廷派人到江南收商税，有税官在苏州被人打死，魏公公准备坚决镇压，江南大财阀吓坏了，只好交出五个带头人，这五人被押往北京处死。\\n\\n《五人墓碑志》就是写来纪念他们的。国家风雨飘摇，他们也没有吃不上饭，相反还挺有钱，却大肆逃税、抗税，居然带头打死朝廷税官，这是英雄吗？\\n\\n五）\\n\\n有钱好办事。帝国形势有所好转。“三殿大工”如火如荼进行，河南灾民得到赈济，辽东抗清捷报频传。\\n\\n天启6年，明军取得宁远大捷，大炮轰伤努尔哈赤。次年，宁锦大捷又重创皇太极。这背后，就是钱在起作用。\\n\\n魏公公为人也贪，也干了很多令人发指的坏事。但在他掌权的几年，国事确实大有改观。当时，有很多人开始给他修生祠。\\n\\n后来的结局，大家很熟悉。天真的崇祯上台，灭掉魏公公，重新起用文官，帝国锋利的“搂钱之刀”，再次割向农民。\\n\\n1630年，崇祯三年，第4次加派“辽饷”，每亩加一分二厘，共增田赋银685万余两。\\n \\n1637年，崇祯十年，“不集兵无以平贼，不增赋无以饷兵”，加增田赋银280万两，称为“剿饷”。\\n \\n1639年，崇祯十二年，朝廷宣布练兵73万，“因练兵必用饷”，又每亩加“练饷”银一分，共征730万两。\\n \\n10年里，帝国在农民身上割肉1695万余两，并以此作为岁额向全国派征。这可是正赋以外的加派！\\n\\n当时，“民田一亩值银七八两者，纳饷至十两”。土地成了负资产。农民活不下去了，只好当流寇，“明之亡亡于流贼”。\\n\\n崇祯再傻，后来也发现事情不对劲，但世上已无魏公公，他无力彻底摆脱文官集团，只好靠不断撤换内阁首辅来发泄心中不满。\\n\\n当然，帝国文官系统和东南豪商中饱私囊，发了大财，但是，他们赢了所有政治对手，却输给了整个时代。\\n\\n终于，帝国暴力保护壳彻底崩溃。\\n\\n李自成破京，对大明官僚实行残酷逼捐。你猜，共逼捐出多少钱？白银2000万两！李自成不由惊叹：“以此破敌，何敌不破？”\\n\\n清兵入关，东南遭受一连串大屠杀，“扬州十日”、“嘉定三屠”…… ，豪强们拼了命都不愿意拿来交税的财富被洗劫一空，全家老小的命也搭上了。\\n\\n不过，握有生花妙笔的东林文人们，投降满清后，带头编书写文，痛骂\u202a明朝\u202c皇帝昏庸误国、魏忠贤等人贪墨殃民，导致明朝灭亡……\\n\\n## 决算的数目字\\n\\n没有正确的“三观”，历史读得越多越傻，中毒越深。\\n\\n一）\\n\\n“史实考证”这种费脑筋的事，我担心你应付不来啊。\\n\\n今天，我们“史料考证”，看看天启皇帝留下的一份工程决算报告。这份报告，缘于天启末年对故宫“三殿”的集中重建。\\n\\n“三殿”的具体故事，当然要看本号的这两篇文章：\\n\\n《谁是帝国大忽悠》\\n\\n《利害相磨笔如刀》\\n\\n坦白说，我第一次看到这份工程决算，刹那间，我是怀疑的，直到静下心深挖，我才深深被震撼：\\n\\n居然精确到小数点后7位，对整个工程要细致掌控到什么程度才能算出如此恐怖的数字！\\n\\n人们称天启为“木匠皇帝”，原本应该是想污蔑抹黑他，但是，我却觉得，这个称呼，简直就是对他无上的赞美。\\n\\n闲话少说，我们先欣赏一下这份决算报告，看看天启皇帝的利害手段：\\n\\n“工部奏，三殿大工开工自天启五年二月二十三日起，至七年八月初二日报竣，总算钱粮给与领状者，共五百七十八万八千一百三十五两八钱三分八厘二毫二丝八忽六微，应找者共三十万零一百三十三两八钱九分四厘七毫五微，透支者一十三万零七百四十九两九钱四分四厘二毫二丝外，兑者共一十三万九千一百五十三两三钱八分一厘六毫九丝，所费银计五百九十五万七千五百一十九两七钱六分八厘四毫一丝六忽一微。虽前朝册籍无可稽考，而工倍费省未有如斯举者也。\\n得旨，览奏‘三殿鼎建，两载告成，工大费省皆赖厂臣心计经营，力效鸠庀，以故顶石之运，\\t楠杉之采，节省金钱数百万，而禁苛恤力,\\t子来胥悦，劳勤独高’。 说得是。这截算钱粮，\\t自开工迄工竣，计五百九十五万七千五百两有奇，具见稽核详恪，还宜以册案宣付史局，用彰实录。\\n其夫匠铺车等役，给银未完的，\\t须外解补还，著行各省直严催，题过助工银两，星速内解，\\t以完工局。”\\n——《明熹宗实录》卷78，天启七年八月乙酉\\n\\n这份决算，载明了“三殿”大工的工程时间、总费用、皇帝批语、后续工程款项支付和厂臣功劳等内容。\\n\\n二）\\n\\n“三殿”主体工程，从天启五年二月二十三至七年八月初二报竣，仅仅用了两年半时间。\\n\\n这个速度快不快？你肯定轻飘飘的一扫而过，心中无感。\\n\\n但是，你去故宫实地看看吧，“三殿”极为庞大恢弘的建筑规模、精密复杂的工程结构，你想过吗？\\n\\n没有现代施工机械，没有水泥钢筋，一砖一瓦，一草一木，全靠成千上万个人的双手！\\n\\n史载，“三殿”大工的施工人员主要是国家的工程部队，三都司班军，超过20000人。\\n\\n如此繁杂的超级基建，短短的30个月工期，庞大的施工队伍，怎能不惊叹天启政府强大的组织力和高效的执行力？\\n\\n三）\\n\\n工程总费用，我们都知道了：白银5957519.7684161两。\\n\\n这笔钱，虽然远比文臣内阁的预算少了好几倍，但对帝国财政收入来说，仍是天量开支。\\n\\n当时帝国中央政府内外库口径的岁入约1500万两左右，这笔钱已占39.7%。啥概念？\\n\\n世界超级工程港珠澳大桥造价1269亿，仅占2017年全国一般公共预算收入172567亿的0.73%。\\n\\n1）\\n\\n实数已如此巨大，万历龟缩偏殿办公二十余年，想破脑袋都无法筹足文臣内阁预算中的那个虚数，也就情有可原了。\\n\\n“三殿”焚毁时，帝国财政已入不敷出，皇室、官俸、军费等日常开支相当庞大，而战争支出，更是如流水一般。\\n\\n为修复国家权力运行象征的“三殿”，万历皇帝甚至新增了一项工业税：矿税：\\n\\n“迨两宫三殿灾，营建费不赀，始开矿增税……中官遍天下，非领税即领矿。”\\n——《明史·食货五》\\n\\n矿税原本丰厚，但遭到工商业主抵制，再加上层层贪墨，收到中央手里后，攒下来的钱连预算零头都不够。\\n\\n万历一死，泰昌、天启即位，政治得势的东林党内阁，趁机立刻废除了矿税。\\n\\n“罢天下矿税令旨。先年开矿抽税，为三殿两宫未建，帑藏空虚，权宜采用。近因辽东奴酋叛逆，户部已加派地亩钱粮，今将矿税尽行停止。”\\n——《明光宗实录》卷2，万历四十八年七月丁酉\\n\\n请注意蓝色那句话，活画出东林党的核心政纲：辽东用兵缺钱，在田亩加派钱粮，而废止专门损害工商业利益的矿税。\\n\\n2）\\n\\n天启四年六月，东林党垮台，魏忠贤用事，朝政为之一新。\\n\\n八个月后，“三殿”重建就动工了。工程预算真正做实之后，筹起钱来心里有数，甚至边筹钱边动工也是有底气的。\\n\\n天启皇帝和魏公公是怎么解决钱的问题呢？并不是靠加派田赋！\\n\\n首先，内库私房钱。天启登基后，要求立即启动“三殿”大工，拨出内帑200万两：\\n\\n“传起建皇极门殿，择日兴工，……。时辽饷愈急，大工起建，有司莫措。乃以工部请发内帑二百万，刻日起工。”\\n——《明光宗实录》卷3，泰昌元年八月戊申\\n\\n其次，户部、工部、兵部等中央机关分摊费用。其中，兵部负担较重，既要出人，还要出钱。\\n\\n明中后期，中都、河南、山东的三都司京操班军，实际上已转型为国家专业基建工程部队。\\n\\n“又有中都、山东、河南班军轮操谓之更番军，总称三大营军，故凡有兴作，辄役班军。”\\n——《明神宗实录》卷425，万历三十四年九月乙未\\n\\n“三殿”基建，也是由班军负责，部队的劳务费、修筑费由“户七兵三”分摊，户部出七成，兵部出三成。\\n\\n再次，朝廷号召全国文武官员、士民工商献爱心，嗯，“劝捐”。\\n\\n“大工繁费，物力不赀，内外大小文武百官，通行捐俸。”\\n——《明熹宗实录》卷71，天启五年六月庚戌\\n\\n“今中宫等官、诸王公主，并司礼监等衙门、各监局司库掌印管事牌子，及内外私家闲住太监等官，恭进助工银共四十万两，俱发公所贮收。”\\n——《明熹宗实录》卷58，天启五年四月丙午\\n\\n你看，后宫诸王公主、太监都踊跃捐款“助工银”40万两，内外百官的捐献一定只多不少。\\n\\n这一幕，你想到什么？对了，李自成兵临城下，亡国关头，崇祯政府“劝捐”兵饷，居然死活“劝”不出钱来！\\n\\n两相对比，你还会觉得天启皇帝是傻瓜笨蛋、魏公公是无能阉党吗？\\n\\n四）\\n\\n焚毁多年的“三殿”终于建成，这对当时的明帝国来说是几十年来难得一见的盛事！\\n\\n“天启六年九月，皇极殿成。七年八月，中极、建极殿成。”\\n——赵翼《廿二史札记》卷32，《明宫殿凡数次被灾》\\n\\n对此，天启批示：“工大费省皆赖厂臣心计经营”；工部总结：“虽前朝册籍无可稽考，而工倍费省，未有如斯举者也”。 \\n\\n君臣一致都提到“工大费省”这四个字，确实，太不容易了！\\n\\n天启皇帝把功劳归结于“厂臣心计经营”，这就太谦虚了。他本人是顶级土木建筑工程专家，“三殿”重建的所有关键环节，他全程参加核验。\\n\\n“三殿”重建，都在天启皇帝的牢牢掌控之下，任何猫腻都瞒不过他。\\n\\n天启七年八月乙未，三大殿重建工作完成。十天后，八月甲寅，朝廷正式宣布：“殿工告成。”\\n\\n历史就是这么诡异。就在宣布“三殿”竣工的第二日，帝国的命运骤然发生重大转折，天启皇帝就驾崩了！\\n\\n“上崩于乾清宫。”\\n——《明熹宗实录》卷87，天启七年八月\\n\\n天启只有短短的七年，“三殿”重建伴随皇帝在位七年的始终。天启一朝，是大工的一朝。\\n\\n五）\\n\\n工程决算报告书中，还专门对工程尾款的支付作出明确规定：\\n\\n“其夫匠铺车等役，给银未完的，\\t须外解补还，著行各省直严催，题过助工银两，星速内解，\\t以完工局。”\\n\\n做工给钱，天经地义。朝廷明文要求，“给银未完的”，必须“外解补还”，“以完工局”，绝对不能拖欠工程款！\\n\\n不是说魏公公贪得无厌、为所欲为、十恶不赦吗？怎么对一点工程尾款都要交代按时支付不拖欠？\\n\\n看来，天启皇帝和魏公公办事是有规有矩的，哪怕是国家最高级别的政治建筑，完工后该给钱的就给钱，不打白条。\\n\\n天启皇帝批语中的“厂臣”，正是魏忠贤。“厂臣”，意为东厂、西厂主官。\\n\\n“三殿”完工，“工大费省”，在天启皇帝领导下，魏忠贤亲自负责，具体抓，抓具体。\\n\\n当时，各部官员上表称贺，都不约而同认可魏公公主持“三殿”大工的功劳：\\n\\n“三朝旷典，久需运会，才余两载，煥复旧规，实赖厂臣魏忠贤，生符名世，精禀扶舆，真有与国家共休戚之心，卓尔肩天下系安危之望？”\\n——《明熹宗实录》卷87，工部尚书薛凤翔“题叙殿工”\\n\\n“臣仰见三殿告成，……为大典克襄省财节费，地方受福，此皆厂臣干国，宏猷匡时伟略所以臻此。”\\n——《明熹宗实录》卷87，吏科右给事中陈尔翼奏表\\n\\n皇帝、朝臣都交口称赞魏忠贤的功劳，这难道都是为了拍魏忠贤的马屁吗？显然不是。\\n\\n万历、泰昌两朝，折腾了二十多年，“三殿”大工始终无法动工。\\n\\n天启皇帝继位初，国事艰难，内忧外患；等他离世时，帝国财政较为充足，形势有了很大好转。\\n\\n对外，相继取得“宁远之战”和“锦州之战”大捷，迫使后金转为防御；对内，河南灾民得到赈济，社会基本趋于稳定。\\n\\n就算天灾人祸频发，辽东天天打仗，东林党拼命捣乱，但是耗资惊人、工程浩大、二十多年想建而始终建不起来的“三殿”竟然得以顺利竣工。 \\n\\n六百万两的大工支出顺利筹措，并不是靠横征暴敛，对农民加派赋税而来的；三都司班军以完整的队伍、近两万人的规模照常上班，按期完工。\\n\\n你想过没有，这难道真的是偶然的吗？\\n\\n六）\\n\\n从决算书看出，天启皇帝和魏公公团队对人力、物力和财力的有效控制和组织，活生生的摆在哪里，并不靠文宣吹嘘。\\n\\n“集中力量办大事”说得好听，问题是，你能不能集中得起来？你有没有能力去集中？\\n\\n天启短短几年，确实处理了好多长期想处理而没有处理的难题，干成了好多过去想干而没有干成的大事。\\n\\n这些，靠东林嘴炮党，靠公知文青圣母心，能做到吗？\\n\\n随着天启皇帝诡异早死，魏公公被崇祯和东林党清算，帝国重走回头路，一切又变回了老样子。\\n\\n天启朝的改革和商税政策全部被废除，中央财政又一次穷得叮当响。随之而来的，是辽东局势日衰，是流民暴动峰起。\\n\\n当然，这一切，东林党得势后，他们掌控了历史的书写，自然有着另一番截然相反的结论：\\n\\n“圣性又好盖房，凡自操斧锯凿削，即巧工不能及也。……先帝每营造得意，即膳饮可忘，寒暑罔觉，可惜玉体之心思精力，尽费于此。然皇极等三殿落成于天启之年，肯堂肯构，先帝之好土木，岂亦天启其朕兆耶？……，至皇极等等三殿告成，逆贤等只图荫赍为己荣耳！\\n——刘若愚《酌中志》卷1，《客魏始末纪略》\\n\\n“木匠皇帝”贻误国政，“阉党专权”胡作非为，“三殿告成”是公公想邀功请赏，大明江山几乎被他们搞垮了……\\n\\n题外话，揭露这段“黑历史”的作者刘若愚，曾是魏忠贤团队的重要成员。咳咳，这种“反戈一击”，是不是更有一种特殊的说服力？\\n\\n其实，刘若愚是在牢狱中写出这本《酌中志》的，写完崇祯君臣审阅后觉得很满意，就赦免了他的死罪。\\n"}'));jctx.push(JSON.parse('{"id": "181210", "tag": "book", "text": "# 明清的回治与回乱\\n\\n中国是世界上穆斯林人口较多的国家之一。\\n\\n作为一个古老的世俗国家，穆斯林的治理始终是一个不可回避的问题。近年来，随着宗教激进主义在世界范围内的蔓延，以及中国西北穆斯林问题的复杂化，研究中国历史上对穆斯林的治理无疑具有相当的现实价值。\\n\\n蒙古时代：回回的兴起\\n\\n穆斯林在中国境内的大量定居，源于蒙元时期。\\n\\n13世纪初,蒙古军兴起于漠北,成吉思汗及其继承者征服了中亚、西亚地区的大量伊斯兰国家，蒙古军每攻占一处,往往将当地穆斯林青壮年男子征入军队。如不花刺人投降后,“适于服役的青壮年和成年人被强征人军”（《世界征服者史》）;在撒麻耳干“从青壮年中挑出同样的（三万）人,编为一支签军”，工匠也是征调的对象,蒙古人仅在撒麻耳干就掳掠了三万工匠。这些部队被蒙古用于征讨金、南宋和大理的战争中，就这样，大批穆斯林士兵被滞留在中国陕甘、云南地区。\\n\\n为了低成本安顿这些军人，元朝政府乃鼓励其在当地定居，并多次颁布优待政策：\\n\\n至元十六年(公元1279)正月,“立河西屯田,给耕具,遣官领之”（《元史》卷十,《世祖纪》七）；至元二十五年(公元1288年),“以忽撒马丁为管领甘肃、陕西等处屯田等户达鲁花赤,督斡端、可失合儿工匠千五十户屯田”；至治二年(公元1322年),诏“免回回人户屯戍河西者银税”。鉴于来华的穆斯林人口数量巨大，穆斯林族群在文化、习俗、政治和经济上亦有别于中国土著，元朝政府于是设立了“回回户”，将其纳入封建国家的特定户籍之中。\\n\\n就这样，在元政府的鼓励和支持下，这些曾经服役于蒙古军的穆斯林士兵，从此逐渐在中国云南和大西北地区定居下来。是故《明史·西域传》称:“元时回回遍天下,及是居甘肃者尚多。”\\n\\n明代的同化、繁衍\\n\\n蒙元灭亡后，明廷建立。以“驱逐鞑虏，恢复中华”自命的明朝统治者在处置回回的问题上，在尊重穆斯林信仰的同时，也采取了一系列带有明显“同化”色彩的政策。\\n\\n一方面，明朝政府强制回回与汉人通婚。《明会典》卷141刑部十六《律令•婚姻》规定： “蒙古色目人婚姻：凡蒙古色目人，听与中国人为婚姻，务要两相情愿，不许本类自相嫁娶，违者杖八十，男女入官为奴。另一方面，明廷在内地禁止“胡服、胡语、胡姓”，结果使得回回都变胡姓为汉姓，并改变了很多服饰、语言等方面的习俗。《明太祖实录》卷26洪武元年二月壬子条文称，“其辫发、胡服、胡语、胡姓一切禁止，甚酌损益，绵断自圣心，于是百年有余胡俗，悉复中国之旧矣。”正是基于这一系列政策，后来的大陆回族才呈现出汉化的面貌。\\n\\n不过，明廷的同化政策，并未对回族人口的繁衍产生影响。1528年兵部尚书王琼到甘肃平凉府,就惊讶地发现东关地区居住着大量穆斯林；兵部侍郎张海则奏称:“甘肃即古河西五郡之地……人民奔溃,诸夷熟羌来归,在边安插,积聚数年,蕃育日多”。\\n\\n实际上，西北地区回回人口的急剧增加,也引起了明朝的注意和不安。巡抚甘肃都御史朱英对此表示,“欲将甘州等处久住夷人迁徙河南、陕西地方,庶免交通漏泄……欲将先年哈密残破夷人随土鲁番使臣入境者分寄甘肃一带者,暂送腹里陕西、河南地方”。兵科给事中章镒亦称:“哈密遗种,寄附我边,日增月益,在在有之。”\\n\\n事实上，明廷强制回回与汉人通婚的初衷在于限制其人口增长，明法典原注中“夫本类（蒙古、色目）嫁娶有禁者，恐其种类日滋也”即是如此。然而，事实却表明，明朝政府的限制措施效果相当有限，回回人口反而借助通婚大幅增长。\\n\\n\\n\\n明代回族地区政治稳定的根源\\n\\n不过，需要指出的是，尽管回回人口在明代出现了剧增，但明廷在回回地区的统治依然是稳定的。终明之世，西北回回地区基本没有出现过大规模的穆斯林动荡和叛乱。那么，明朝为何能够在回回地区维系稳定的统治？\\n\\n这是因为，相比于后世，明代的回回宗教结构与宗教观念有着很大的不同。\\n\\n明代的闭关锁国和强烈的儒家文化氛围，使得伊斯兰教不仅缺乏传教人才，而且出现了儒家化的现象。明代中叶的海禁和西北边疆的隔绝，使抵达中国的伊斯兰学者、中国穆斯林到圣地的朝觐都越来越少，中国伊斯兰社会与世界伊斯兰社会逐渐呈现出隔绝的状态，并不得不走向本土化。到了明朝中后期，大批自幼习儒的回回知识分子开始通过儒家理论解构伊斯兰教典，如陕西回回儒生胡登洲办理经堂伊斯兰教育，回教传播呈现出“经政兼通，回而兼儒”的特性。在这种情况下，回汉社会的观念分歧急剧缩小，儒家立国的明廷能够相对适应当时回教社会的观念需求，从而实现有效治理。\\n\\n同样由于明代时期中国和伊斯兰世界的宗教交流匮乏，回回社会缺乏具有强大影响力的教典诠释者，中国伊斯兰学者既无法研读经典和教义，也难以到其他地方传播其认知，各地只能依靠“祖习、风俗、自性”家传口授。\\n\\n就这样，明代回回社会的伊斯兰教呈现出教坊式的村落分散结构：凡有十几户、几十户或几百户穆斯林居民的村落，便可以建造一座清真寺，择聘一位阿訇任教长，这一区域便形成一个独立的教坊，且与其他教坊没有任何隶属关系。教坊制的宗教结构使得回回社会的宗教组织结构极为松散，宗教的动员能力非常有限。明代基于士绅治理的统治机器，可以轻而易举地对回回社会实现有效治理。\\n\\n与这些现实相应的是，明朝政府对回族教坊的教长采取了收买扶植的政策，形成了共同的利益联盟，使伊斯兰教成为明廷统治回回社会的利器。按照明朝制度，凡清真寺的掌教，均须领得明廷发给的札副作为凭据，其中更有“敕赐札副”者，被称作“冠带住持”，即所谓“冠带荣身”，一切差役徭役，概在蠲免之列。弘治年间正式领取札副的北京东四清真寺掌教马颙，就是一位“冠带住持”；另外，明廷统治者与回回社会宗教领袖的结合还表现在掌教的世袭制上，如北京东四清真寺掌教马氏，自明弘治年间给予札副，住持是寺，绵绵延延。这种特权加身和世袭罔替的掌教制度，乃是明朝统治者在回回社会的统治手段。\\n\\n正是基于以上现实和政策，明朝才得以在回回地区建立廉价、稳定、有序的统治——这是后世统治者很难做到的。\\n\\n清朝前中期的治理思维\\n\\n明朝灭亡后，清廷入主中原。由于满清来自关外，对伊斯兰教和回族缺乏了解，再加上明代回回社会的本土化，故而清朝统治者并未意识到回回与汉族的区别。\\n\\n实际上，尽管清朝统治者在与蒙古、藏族、维吾尔族以及西南少数民族打交道的过程中，采取了相当灵活的政策，通过与各个少数民族上层达成权力联盟，形成了稳定的统治联盟，但在回族问题上，清廷则完全不同。\\n\\n清朝统治者并不认为回族有什么特殊性。当有官员提出回族的特殊性时，清政府则刻意强调“一体同视”的原则。\\n\\n1648年，甘肃河西爆发了以米喇印、丁国栋为首的回族大起义，起义军拥立故明延长王朱识穿，并打出“反清复明”的口号。清廷经过五年的时间，镇压了这场叛乱。叛乱后，清陕甘总督孟乔芳上奏清帝顺治，“（回回）从来叵测……习俗不一，终为疑二……（战后应）另行安置，勿令养马，勿藏兵器”。顺治皇帝对此不以为然，而是采取了与汉族类似的统一抚恤治理政策。\\n\\n1729年四月，针对多位大臣对回民的猜忌，雍正帝下谕内阁，称“（回民）其人既为国家之编氓，即俱为国家之赤子，原不容以异视也……朕思回民之有教，乃其先代留遗，家风土俗，犹中国人之籍贯不同，嗜好方言亦逐各异。”乾隆帝也曾表示“不以回民异视，而以治众者（汉人）治回民;为回民者亦不以回民自异,即以习回教者习善教。则赏善罚恶,上之令自无不行,悔过迁善;下之俗自无不厚”（《清高宗实录》卷八）。\\n\\n从三代满清帝王的表述中可以看出，清廷固然要求地方官员不得歧视回族,但也绝不承认回族的特殊性,坚持对回族的直接统治，正所谓“（回民）自其祖先以来,食毛践土,蒙国家豢养深恩者已百数十年,与民人同隶编氓,毫无区别”（《石峰堡纪略》卷十四）。这即是清廷前中期在回回社会实行直接统治的政治原则。即清朝以等同于汉地的郡县制统治回回社会。\\n\\n回教的变化：从教坊到门宦\\n\\n尽管清廷的统治手法依然延续了明朝的经验，但回回社会则随着时代的变革，发生了相应的变化。\\n\\n清朝平定台湾后，明廷“片板不许入海”（《明史》卷二百五《朱纨传》）的严苛禁海政策被废除，清廷取之以有所限制的“开海”政策，这就使得中国与世界的交流急剧增加。在这种情况下，伊斯兰世界的“正统”伊斯兰教传入中国，并对中国的回教社会产生了巨大影响。\\n\\n海禁的开放后，回回社会与伊斯兰世界的交流变得相对便利，使得一大批更具权威的传教大师得以涌现。\\n\\n他们中的一部分是中国穆斯林到伊斯兰世界学习，习得“真经”，回国后确立宗教影响力。如甘肃临夏穆斯林马来迟1728年到中东朝觐，通过师从一些中东苏菲派大师（中国版记录马来迟从广州航行到阿拉伯半岛，并在那儿向一个著名的伊斯兰学者学习3个月）；甘肃陇南穆斯林马明心随叔父赴麦加朝觐，被当地沙孜林耶道堂收为门徒，习经修道。这种源于伊斯兰圣地的宗教学习，使得回乡后的马来迟和马明心在回教社区的宗教权威性远远超过传统的儒式解读，成为当时著名的传教大师。\\n\\n传教大师中的另一部分则是亲自来华传教的伊斯兰世界传教者。明末海禁废弛之后，伊斯兰世界的传教者穆哈伊丁先后三次来华传教，第一次在广东、广西传教，第二次在湖南、湖北传教，第三次到甘肃传教，最后于定居于河州东乡大湾头，成为当地影响力极大的宗教领袖；而另一位伊斯兰世界学者和卓·阿卜杜拉则在传教时启迪了大拱门宦的创建者祁静一。\\n\\n海禁废弛之后的传教大师涌现，最直接的影响就是，以往回回社会孤立分散的教坊宗教社会结构被打破，转而代之以跨省连县式的门宦体系。传统的经堂传教和狭小村落式的孤立教坊传教无力抵挡伊斯兰世界的“真经”对信众的影响力，纷纷拜倒在那些传教大师面前。\\n\\n据马来迟的追随者记载，“马来迟朝觐回来后，声望很高，远近群众都来探望他这位有名的‘哈智’，他乘此机会宣传伊斯兰教和朝觐收获”，远近无不悦服，马来迟由此创建了著名的“华寺门宦”，当时就号令了四十多万人；而另一位传教大师马明心在归乡之后，“全国各地来此拜师求教者不计其数，有青海循化的苏四十三阿訇，平凉的穆大阿訇，宁夏海原的田五阿訇，同心的米爷，河州的高三阿訇，洪乐府的甘南旦若阿訇，伏羌（甘谷）银拐子的丁阿訇，巩昌（陇西）的三阿訇、李阿訇，安定（定西）关川的关里二阿訇（即哲赫忍耶第一部《热什哈尔》经的作者），礼县盐关的刘满拉，云南古城（今寻甸）的马三爷阿訇，贵州（今贵州省）的金氏弟兄，山东的金阿訇，陕西的陈阿訇、买阿訇、白乡老，新疆的没胡子阿訇等，还有灵州（今宁夏灵武）的马七巴巴者（马化龙之曾祖）挈其子马达天同学于马明心门下，一时传为佳话。经过这些学生的再次传播，追随者不断增多，遂形成了一个较大派别，被称为关川道堂（亦称哲赫忍耶门宦、关川门宦）。马明心也被称为‘关川阿齐兹’（即尊贵者）”\\n\\n最终，原本分散孤立的回回教坊社区最终在传教大师的影响下形成了强大统一的门宦整体，这是回回社会历史上所不曾有过的情况，就像大陆宁夏历史学会会长霍维洮所言“回族一开始就超越了部落阶段，其民族整合只能以宗教的方式展开”（《近代西北回族社会组织化进程研究》）。这种现实的转变，对于清廷的统治来说，是一个巨大的挑战。\\n\\n历史经验总结：跨区连片地传教可以极大提升宗教的动员能力，同时削弱统治者的管制能力，对于统治者来说，跨区传教即是威胁。\\n\\n清廷治回的新挑战\\n\\n回回宗教社会结构的变化，使得原本平静的回回社会出现了巨大的变化因素，进而影响到清朝地方政府在回回社会统治的稳定性。\\n\\n首先，对于传教者来说，信徒不仅仅意味着宗教影响力，也代表着真实的财富和现实利益。因此，当传教大师打破原有的孤立教坊之界限，跨区传教时，也就带来了回回社会新传教者与老传教者、新传教者与新传教者之间的剧烈斗争，这是清朝地方政府所难以应对的新问题。1747年，河州格底木回民马应焕向官府控诉华寺门宦创始人马来迟“邪教惑众”，聚众“至二三千人”，两者之间的分歧在于斋月里“开斋、礼拜”先后顺序不同，这是典型的老式传教者与新传教者之间的冲突。对此，甘肃巡抚黄廷桂要求新老教各方应自守其约，力避冲突，“前开、后开各遵祖教，遇有丧事，不许一起延请两造念经，致滋事端”。\\n\\n而哲合忍耶门宦的创建者马明心归国后在河州地区的传教也遭到了马来迟华寺门宦的阻挠，被迫到循化地区传教，随着传教者的不断扩张，哲合忍耶与华寺门宦之间的矛盾和冲突也日趋激烈，作为直接统治者的清政府不得不介入其中。在1769年的两门宦冲突中，清政府判处哲合忍耶的阿訇贺麻路乎发乌鲁木齐为奴，华寺门宦的阿訇韩五充军三千里。\\n\\n其次，伊斯兰世界的新教传入和普及，使得回回社会呈现出去儒家化的现象，加剧了回回社会与清廷儒家官僚阶层的观念隔阂，不利于双方的沟通。这种观念导致的误解，在清代中期政府官员的奏疏中体现得极为明显。\\n\\n1724年九月，山东巡抚陈世倌上疏称“如回教不敬天地、不祀神祗,另立宗主,自为岁年;党羽众盛,济恶害民”；陕西总督岳钟琪也有同样的看法，他在奏折中表示“查编户之中,有回民一种,其寺皆名礼拜,其人自号教门,饮食衣冠,异于常俗”；而安徽署理按察司鲁国华更在奏折中宣称“回民居住内地……自宜凛遵历度，仍伊不分大小建……又平日尚白，早晚皆戴白帽，设立礼拜、清真等寺名色。不知供奉何神，妄立把斋名目，违制惑众。”（见《清真释疑补辑》）”。\\n\\n清廷官员与回民之间的隔阂加深，实际上加剧了清廷官员对回民的蔑视，使得清廷在处置回教事务中的粗暴和蛮横不可避免。\\n\\n更为重要的是，门宦宗教体系极大的强化了回回社会的政治动员力，使得清廷地方政府在回回社会的统治面临巨大的抵抗。\\n\\n门宦的建立，使得回回社会原本孤立的教坊得以统一起来,各教坊所属的回民通过教坊、教区、道堂,实现了有机联系。尽管，回民与门宦之间的联系是比较自由的，但回民对门宦教主的宗教虔诚弥补了门宦组织的松散性,或者说由于教民有了坚韧的宗教信仰,门宦根本不需要对教民实施明显的组织控制，即可形成强大的动员能量。\\n\\n事实上，在门宦组织中，教主所属的教区和教坊,无论在心理上还是组织上，都是门宦组织确定无疑的领导核心。\\n\\n清廷大臣那彦成长期任职西北,他对门宦领袖的威望和动员力深感触目，在向朝廷报告的中，这位官员这样写道:“回俗阿浑为掌教之人,凡回子家务及口角争讼事件,全凭阿浑一言剖断,回子无不遵依” （《那文毅公筹划善后事宜奏议》卷七七）；而大陆宁夏伊斯兰教研究会会长勉维霖亦在其《中国回族伊斯兰宗教制度概论》中，则详尽阐述了当时门宦领袖的政治权威，“门宦谢赫,一般驻于他的传教中心地道堂,以领导和统辖各地的信众。门宦谢赫既是寻道者穆里德的导师和引路人,也是全体信众的精神领袖和世俗首领,具有至高的权威,受到信众的特殊尊崇,他的指示和命令称为\'口唤\',不论精神问题还是世俗问题,教众都要竭诚遵从。”\\n\\n就这样，清廷在回回社区的直接统治对象由类似于宗族的回坊个体，逐渐演变成庞大的门宦组织，也有能力做出规模更大的反抗，这是清廷脆弱的地方政府所无力面对的。\\n\\n新教回变\\n\\n由上可知，随着宗教冲突的加剧、官民隔阂的加深，以及门宦组织的形成，使得清廷地方政府与回民宗教力量之间的大规模对抗难以避免。双方的第一次剧烈碰撞恰恰源于这三种因素的叠加。\\n\\n1781年元年，马明心的弟子、哲合忍耶派阿訇苏四十三率领教徒千人围攻华寺门宦信徒的村庄，双方械斗“一日不绝”，清朝当地县府无力镇压，“游击胡松阿差弁带兵往来弹压而不能禁止”（《循化志》卷八）。\\n\\n在这情况下，陕甘总督勒尔谨委派兰州知府杨士玑，会同河州协副将新柱、皋司福菘等，带兵到该地区查办。苏四十三等装作华寺门宦的教徒前来迎接清政府的查办官员，清廷官员对其诳语道：“新教（哲合忍耶派）若不遵法，我当为汝老教（华寺门宦）作主，尽洗之”（《循化志》卷八）。“苏四十三等闻是言，反志益急。”夜晚，苏四十三率信徒千人，围攻清军所驻之白庄，尽杀新柱所属之清军，次日晨又赴旗台堡杀知府杨士玑、守备徐彦登、外委陈伏得、土司韩成嶙等。回民与清廷的直接冲突正式爆发。\\n\\n广告\\n去逛逛\\n清总督勒尔谨闻讯将哲合忍耶派创始人马明心逮捕，由官川解押兰州。苏四十三听闻恩师马明心被捕，遂率领哲合忍耶反抗军进逼兰州，要求清政府释放马明心，当时兰州只有清标兵800名，城中空虚。兰州布政使王廷瓒见状乃将马明心的随从先行释放麻痹反抗军，然后杀害之。马明心的死激起了哲合忍耶派的更大反抗，苏四十三反抗军被镇压后，到了1784年，马明心弟子田五又发动了对清廷的反抗。\\n\\n在这场哲合忍耶派（后来的哲合忍耶门宦）的反抗浪潮中，新式宗教政治动员力体现得极为明显。苏四十三和田五的反抗斗争显示，阿訇有能力成为大规模武装反抗运动的组织者，而宗教领袖的号召力可以通过信奉其的阿訇得到极大的拓展。\\n\\n据《钦定石峰堡纪略》记载，“田五于今年正月内至靖远掌教哈得成、头人哈彦家商同谋逆，复立新教，令哈得成、哈彦转约城内回民，俟起事后攻打靖远，勾通内应……勾令临期内应，众回民均属知情。”安定一带的反抗军亦由当地阿訇领导。“安定县属沙马沟、马家河地方俱有新教，马营街尽系新教。现在领头打仗头人名叫马阿不都、马之光、沙之玉、马世雄，此四人都是三掌教头目。”\\n\\n这次反抗的主要领导人或为马明心弟子，或为其亲属，或在宗教师从上属马明心一系，号令所及，无所不动。“至贼匪煽诱起事，系盐茶、靖远、安定、会宁、伏羌、通渭、固原、静宁、隆德、秦安、华亭各州县所属之小山、海城、官川、糜子滩、马营街、白马庄、马家堡、底店、乌家坪、鹰窝石、白杨岭、蔡家堡等处”（《钦定石峰堡纪略》）\\n\\n清廷的应对\\n\\n宗教力量的壮大和反抗，使得清廷在西北的统治变得软弱无力，这种现实迫使清廷做出一定的政策调整。\\n\\n在门派冲突恶化之前，清廷的政策是以增强驻军和强化地方政府组织为主。\\n\\n1729年,撒拉土司韩炳呈文说:“撒拉土广人稠,回民桀骜不驯,微末土目,委难约束,请设兵驻防,以期安”，次年,清廷设循化营,驻兵五百于草滩坝，1762年又设循化厅；1731年,甘肃巡抚许容要求在回族中强化保甲制度:“回民居住之处,嗣后请令地方官备造册籍,印给门牌,以十户为一牌,十牌为一甲,十甲为一保,除设立牌头、甲长、保正外,选本地殷实老诚者充为掌教。如人户多者,再选一人为副,不时稽查”；这是在西北回族中实行保甲制的开始,目的在于使官府统治进一步深入回族乡村,建立乡村政治网络,掌教之选则寓有把宗教势力亦纳于官府之用意；到了1738年,清廷议准川陕总督查郎阿奏议,在西宁城旁建土城一座,设游击、千总各一员,驻兵四百，并在贵德厅、甘都堂、河州城以西、西固城等处,或添兵把守,或增建墩台。\\n\\n经过几十年来对驻军的强化,到了乾隆时期，为了维持当地的稳定，清廷在甘肃的驻军已得到了极大的加强，故《清高宗实录》有云“故甘肃兵视天下为最多”，可见西北回民维稳压力之大。\\n\\n到了哲合忍耶派回变之后，清廷除了继续强化对回教地区的军事存在之外，也设法利用了门宦矛盾，并努力削弱掌教的影响力，以维持其在当地的统治。\\n\\n当回变发生后，乾隆帝表示“此案用旧教（华寺门宦）而除新教（哲合忍耶派）最为吃紧关键”，他反复指示清廷地方官员要充分利用回民内部的门宦之争，“即应明切晓谕旧教之人，赦其互相争杀之罪，作为前驱，令其杀贼自效。如此以贼攻贼，彼等本系宿仇，自必踊跃争先，既壮声势，又省兵力，则贼势益分”。变乱发生后，凡是参加反清行动的新教回民一律被镇压，祸及家属。更重要的是，清廷在经历回变之后，意识到门宦掌教的巨大政治动员力，因此不论新教老教，其掌教均令革除。\\n\\n就这样，通过花费巨大的庞大驻军和对回民内部矛盾的利用离间，清廷在回回社会的统治总算维持了大约七十年的大致稳定。\\n\\n清末大西北统治的真空化\\n\\n到了清朝晚期，随着官僚风气的腐化，清廷在大西北的统治能力逐渐衰朽，使得清廷在该地区的统治出现了真空。\\n\\n到了道光咸丰年间，清廷在大西北的官僚队伍已经退化得相当严重。在同治以前,清廷所署的甘肃巡抚共有四十人,其中满人倒有三十四人。由于享有政治特权的满族官员相对缺乏儒家政治理想，再加上西北地处偏远，缺乏来自上峰的监督，当地官员大多不仅疏于公务，而且贪污之风尤甚。道光时青海办事大臣哈勒吉那“素不识字,惮于用心,所管本署通丁,半通番匪”,“希图坐地分赃”；咸丰时陕甘总督乐斌“性爱听戏宴会,彻夜不休,同人深以为苦;酒量食量极大,舆夫走卒所不及” ，“属员相率效尤,俱尚浮靡。而督、臬两署笙歌,竟无虚月。”官员“恩麟、和祥、明绪并督幕彭沛霖,结拜兄弟,酒食征逐,醉后谩骂,毫无局面” ,甘肃官场“一堂鬼魊,暗无天日,不仅政由贿成也” 。\\n\\n与此同时，清廷在当地的驻军也失去了军事威慑力。当时的清军士兵缺乏纪律,借故滋事者极多。1850年(道光三十年),固原裁汰老兵,引起士兵闹事,“平庆泾道范懋德闻之大恐,亲赴教场向众兵磕头求散” ； 1856年,“胜保奏西宁、宁夏等处兵丁因请饷滋闹,兰州省城复有兵众围绕总督衙署,打碎藩司段大章、知府刘仲海肩舆之事;并汉回匪党于关内外抢劫,或假冒野番,或勾结番匪,行旅为之裹足,甚至饷粮、奏折均被抢掠……”军队哗变频发，不仅仅显示军事纪律的废弛，也表明维系清廷统治的暴力机器已经丧失了战斗力。\\n\\n税收的剧增和“回勇”的建立\\n\\n到了1853年，随着太平天国扫荡江南，清廷丧失了自己最大的财源，财政压力就被转移到了北方各省，而1860年，英法军队入侵直隶，捻军扫荡华北，四方扰攘，更使得财政压力集中在了西北各省。陕西是当时完好省份中最为富庶的地区，被视为饷源所在，成为清政府以镇压太平天国的人力、物力和财力的主要基地之一。《清实录》记载：“此时京饷及各军饷粮，均赖山、陕西省接济。”湖北巡抚严树森表示：“陕西为财赋之邦，西、同、凤三府又为精华荟萃，近年用兵各省，皆借陕西协饷聊以支持，即京饷巨款亦多取盈于此。”在这种情况下，陕甘地区回民的税负徭役压力和怨愤情绪可想而知。\\n\\n更为糟糕的是，清廷为了抵挡太平军而盲目扩编的“回勇”团练，使得事态开始失控。\\n\\n1860年清廷根据湖广总督官文的建议，在甘肃、陕西推行团练。在团练筹办之初，清廷组织了大批相对武勇的回民加入团练，试图以此编练精锐抵御太平军，却不曾想使得陕西地区的强大的回族武装迅速建立起来。\\n\\n以陕西凤翔地区为例，“初团练章程不分回、汉，在局中者千总铁九霄、监生麻生瑞，皆回子也……而有为之游说者……可得二千劲勇，将来御贼，较乡勇倍强。余商诸唐宰，从之，遂调看其技艺。从此回方市军器，缝旗帜，白布号头，踊跃用兵，莫能禁也。讹言四起，一日数惊。”（郑士范著《旧雨集》）\\n\\n回汉团练的组建，使得陕西过去的回汉冲突演变为武装斗争。团练之前，陕西回汉屡有争讼和斗争，但双方只是分散疏离的普通民众，造成的破坏和影响都非常有限。回汉团练组成，无论是汉民，还是回民，都变成了有组织的队伍，回汉矛盾极易转化为武装斗争。\\n\\n对于当时的场景，前江西巡抚、陕西士绅张芾在写给清廷的奏折中这样写道：\\n\\n“近日渭南地方……该处回众将汉民村庄焚毁杀戮甚惨；大荔县一带，回民亦纠众助斗，两县汉回，各怀不平，愈斗愈狠。并据华州知州禀称：渭南赵姓招募回勇在华州峪口滋事，华阴县汉民复将秦家村等处回庄焚毁；（渭）河北大荔、渭南所属汉、回各庄，亦互相烧杀，日来尚在相持；又据同官县知县禀称：耀州、富平等处汉回突至耀州所属之富沟堡，杀毙回民数十人，焚毁礼拜寺，复至同官县属之韩家原，开放枪驳，围攻搈杀。”\\n\\n清廷当时的谕旨也记录了类似的场景：“从前寻仇械斗尚不过在一村一镇之间……近因粤、捻各匪窜人陕境,西、同两府属汉回同时并起,纷纷烧杀,沿河一带村镇俱成焦土”（《清廷于同治元年六月初九日明发谕旨》）\\n\\n曾在陕西华阴县办理团练的士绅李启讷，目睹团练带来的灾难之后，在他的《愤忧疾书》中表示:“团练之设,名曰弥乱,实为乱阶。推原其由,善良者畏事,绝不与闻;刁猾者喜事,争先恐后。迨至充为团练头目,吓诈乡邻,借端索求,又有无赖游民,每日支得口粮,百十为群,抢劫成风,此风一炽,天下多事矣。如今岁关中回汉相杀,虽属回民滋事,实由汉人有以激之也”。\\n\\n所以,倡建“回勇”，致使回汉冲突失控，乃是清政府的严重政治失误。当庞大的回汉武装建立之后，清廷官府已无能力仲裁双方矛盾，维持社会秩序了。再加上政府的横征暴敛，一场大规模的毁灭性冲突，不可避免了。正如时人所言，“地方官亦右汉而左回,大变之兴有自来”（《壬戌华州回变记》）\\n\\n此时，干柴烈火早就就绪，只需一个导火索即可。\\n\\n历史经验总结：普法战争时，法国政府武装巴黎市民，形成了革命军的基础，且不受政府控制，导致了巴黎公社革命；俄国革命的后备军，法国大革命中的国民自卫队，都是如此。\\n\\n谣言、回变与蔓延\\n\\n当时，云南爆发了杜文秀、马如龙、马德新等领导的回变，陕西回民与之多有交结。在回汉杀戮渐乎失控的情形下，陕西士绅、前江西巡抚张芾亲自到回民中间调解冲突，声称“汝等皆良回，起衅者任老五（任武，回民头目）耳。只诛渠魁，胁从罔治”，任武之所以不被赦免，是因为他参与了云南的反清回变。\\n\\n然而，当任武听闻清廷必不恕己的时候，便设法挟持张芾，并声称在张的轿子中发现“秦（陕西）不留回”的传单，鼓动回民将张芾以极其惨烈的方式处死，从而以杀害朝廷大员的既成事实逼迫陕西回民叛乱。\\n\\n陕西回变发生后，回汉攻杀愈发惨烈。清廷害怕甘肃回民起来响应，试图争取甘肃境内的强大宗教门宦，以稳定局面。陕西回变之初，1862年7月，灵州知州张瑞珍曾召见哲合忍耶门宦领袖马化龙，马化龙当时力保灵州回众不参与叛乱；张家川地区回民领袖马伏瑞也声明将约束回众。然而，陕西回汉相互残杀和清廷大肆镇压陕回的事实，大大激发了甘肃回汉、回清之间疑惧，使得双方的信任荡然无存。\\n\\n1862年8月，宁夏同心平远所回族把总马兆元散发谣言，声称“称奉上司檄，官兵刻期歼除回类”，甘肃回民深信其言，“各庄回民纷纷惊惧，投往附和”。随后，哲合忍耶门宦领袖马化龙在金积堡举兵。回变蔓延至甘肃境内。\\n\\n陕甘回变使得内地通往新疆的道路阻绝，新疆清廷统治机构无力维持局面，变乱频发。1864年4月，回教阿訇热西丁在反叛者的支持下，控制了库车；白山派宗教领袖托合提·爱来姆控制了喀什；1864年5月，寓居在乌鲁木齐的甘肃河州阿訇妥得璘在回族将领索焕章的支持下，发动变乱，自称“清真王”；1865年9月，浩罕军人阿古柏奉“大和卓”后裔布素鲁克入侵新疆。\\n\\n从此，云南、陕西、甘肃、青海、宁夏、新疆皆被回变所席卷，可谓全盘糜烂。\\n\\n清末回变领袖一览表\\n姓名\\n身份\\n起兵\\n结局\\n杜文秀\\n大商人、秀才、意见领袖，通晓回教经典\\n1856年起兵云南蒙化(今巍山)\\n1872年服毒后投清营，被杀害\\n马德新\\n云南著名回教领袖\\n1856年号召云南东南起义，响应杜文秀\\n1862年投降清政府后豁免，1874年被清政府杀害\\n马如龙\\n武生、官宦家庭\\n1856年起兵云南红河\\n1862年投降清政府，获署总兵衔，后为云南提督\\n马兆元\\n盐茶厅属平远所把总\\n1862年起兵宁夏同心\\n1863年被其他回变军诱杀\\n马桂源\\n华寺门宦创始人马来迟四世孙，华寺门宦宗教领袖\\n1862年起兵甘肃西宁\\n1873年被清政府处死\\n禹得彦\\n陕川地区的大地主和大商人\\n1862年起兵陕西渭南\\n1872年投降清政府后豁免\\n白彦虎\\n陕西“回勇”头领\\n1862年起兵陕西渭南\\n逃亡俄国幸免\\n任武\\n陕西回变领袖\\n1862年起兵陕西渭南\\n1863年被盟友禹得彦所杀\\n马化龙\\n哲合忍耶学派第五代穆勒师德（传教人），大阿訇\\n1862年起兵甘肃金积堡（今属宁夏）\\n1871年被清政府处死\\n \\n马占鳌\\n莫泥沟清真寺和大河家清真寺之开学阿訇\\n1863年起兵甘肃河州\\n1872年投降清政府后豁免\\n马永琳\\n苏菲主义虎夫耶派领袖\\n1863年起兵甘肃河州，被招降\\n1895年河湟起义后被清政府杀害\\n艾拉汗\\n低阶军官家庭\\n1864年起兵新疆伊犁\\n流亡俄国\\n妥得璘\\n河州回民阿訇\\n1864年起兵新疆乌鲁木齐\\n1872年被阿古柏所杀\\n热西丁\\n额什丁麻札清真寺教长\\n1864年起兵新疆库车\\n1867年被阿古柏所杀\\n阿古柏\\n浩罕汗国高级官吏\\n1864年奉布素鲁克入侵南疆\\n1877年去世，死因不明\\n布素鲁克\\n大和卓木曾孙，南疆宗教领袖\\n1864年随阿古柏入侵南疆\\n1869年去世，死因不明\\n马文禄\\n甘州（今张掖）提督索文部下军官\\n1865年在肃州（今酒泉）起兵\\n1873年战败被杀\\n\\n\\n清廷的应对与结局\\n\\n尽管回变涤荡半个中国，但当时的清政府最关键的敌人依然是与之争夺天下的太平天国和捻军，在太平天国和捻军被消灭之前，清廷对于各个回变军的政策是有以招抚为主的针对性遏制。\\n\\n在陕西地区，清军兵力集结较为便利，且变乱威胁中原腹地，危害较大，清廷乃以武力消灭为主。1862年五月，清廷命令名将多隆阿督办陕西军务，1863年二月，多隆阿攻占回军在同州的两个重要据点羌白镇和王阁村，九月攻占苏家沟和渭城湾，杀死回变军一万七、八千人，陕回基本被驱逐出陕西境内。\\n\\n在云南、甘肃、青海、宁夏地区，由于地方偏远，清军集结不利，且回变军实力雄厚，而当地回变军领袖马桂源、马化龙等人也志在追求独立自治权（马化龙甚至改名为“马朝清”），清廷乃通过承认回变军统帅的兵权、管辖权，并赠送官职，通过拉拢分化这些回变军，防止局势恶化。\\n\\n在云南，清廷多次招抚回变军统帅马如龙和马德新等人，任命马如龙为云南提督，任命马德新为“二级伯克”，“云南回回总掌教”；在甘肃，清廷置回变军叛乱事实不顾，设法拉拢回变军领袖，先后任命金积堡回变军领袖马化龙为记名提督，西宁回变军领袖马桂源为西宁府知府，肃州马文禄为镇标都司，承认其军事和行政自治权，并利用回变军的内部矛盾，诱杀了回变军领袖马兆元，勉强维持了清廷对这几个省份的名义统治。至于新疆地区，清廷则无暇顾及。\\n\\n不过，到了1868年，清廷平定太平天国和捻军之后，有了足够的军事力量，便改变了对以上各省回变军的安抚政策。\\n\\n1867年2月，左宗棠被任命为钦差大臣，都督陕甘军务，他一改此前宁夏将军穆图善的安抚政策，拒绝承认受抚回变军的官衔，致力于武力镇压回变军。1869年9月，左宗棠率军进攻灵州回变军马化龙所部，1871年1月，马化龙军被打垮，3月，马化龙被杀；1872年6月，左宗棠迫使河州马占鳌回变军投降；1872年11月，打垮了西宁回变军马桂源所部；1873年11月，肃州马文禄回变军战败投降。陕甘平定之后的1876年，左宗棠出兵新疆，历时一年多，平定新疆回变。\\n\\n同样的情形发生在云南，1867年之前，云南回变军领袖杜文秀控制了半个云南，并率领大军围攻昆明，清军直到1869年之后，方才腾出军力反攻云南，到了1872年底，最终攻克大理，并在1874年重新恢复了对云南的统治。\\n\\n人口损失与历史教训\\n\\n清末回变是中国历史上规模最大的宗教战争，在战争中，回汉相互攻杀，备极惨毒，战争也极大地陕甘两省的民族分布。\\n\\n据《中国人口史》一书的统计，回变战争中，甘肃（此时的甘肃包括今宁夏回族自治区和青海省西宁市海东地区）全省人口损失约1400万人，人口损失比例为74.5%；陕西人口损失总数高达622万，大约占战前人口总数的44.6%。其中，陕西省因战争杀戮死亡的人口为520.8万，占全部损失人口的比例高达83.7%，而因灾荒损失的人口不过101.2余万。战乱过后，原有约200万回民的陕西省最后仅存于西安城内和陕南。而甘肃回民在战争中损失超过十分之八，汉民损失近十分之七。\\n\\n总之，同治回变是一次历史上罕见的浩劫，在宗教极端主义和极右翼浪潮愈来愈烈的今天，中国历代的回教治理与回变，无疑是历史留给现代人的宝贵经验。\\n"}'));jctx.push(JSON.parse('{"id": "181222", "tag": "book", "text": "# 司马代魏\\n\\n因为失败者没有人权。自正始十年（249）高平陵之变到景元五年（264）司马昭称晋王加九锡，司马家两代三人用了15年的时间巩固统治，经历高平陵之变、淮南三叛等事件已经扑灭了所有的明面的和潜在的反对者。那些曹魏的忠诚者、支持者、甚至同情者们，都已经被从肉体毁灭到升迁打压，最终消失于历史里了，他们可能心向曹魏，但在司马氏一次又一次的血腥屠刀下，这些人不投靠司马氏，也就成为了粉末。同时因为这些人没能赶上魏晋换代的机会，无法成为西晋开国功臣，自然也就没人记得乃至知道他们了——毕竟正面造反还能留下个名，被打压排挤到没官可做，可是连个名都留不下来。\\n\\n至于司马氏篡权的最开端高平陵之变的时候，因为曹爽那十年干的太出色了，所以曹魏元老们都是站在司马懿一边的。司马懿强大的政治号召力使他表现出来的不是被目为阴谋篡权的乱臣贼子形象，而是出来匡正朝纲的功勋太傅。政变时，司马懿称高柔“君为周勃”，意即此举在曹魏元老心中是昔日陈平、周勃诛除诸吕安定刘氏一样的行为。也因此他们觉得曹爽才是乱臣，老太傅是出来安定局面，重新维护他们这些曹魏功勋元老的利益、安定曹魏的，他们认为司马懿在做的才是护卫帝室。曹爽所任命的大多是姻亲同郡，这才是损害了曹魏老臣们的切身利益。像历仕四代的蒋济、高柔，孙资、刘放，这些人都信任司马懿，再加上与司马懿关系密切的司马孚、王肃（也就是王司徒儿子）、陈泰、荀顗、郑袤，与曹爽集团闹翻的北地傅氏傅嘏、范阳卢氏卢毓、陈郡何氏何曾、颍川钟氏钟毓，此外还有孙礼、王观等人，这些人都是司马懿的盟友。\\n\\n高平陵之变里曹爽亲信——他们的身份更准确是司马懿等曹魏元老的政敌，既然站在司马懿对立面，姑且算是忠于曹魏的吧。毕竟他们肯定拥护曹魏统治，不可能支持司马氏营立家门的行为。\\n\\n曹爽兄弟：曹真子\\n\\n何晏：曹操养子、娶公主\\n\\n邓飏：南阳邓氏\\n\\n丁谧：曹操同乡亲信丁斐之子，可能是丁夫人族人\\n\\n李胜：上党、钜鹿二郡太守李休之子\\n\\n毕轨：东平毕氏，明帝亲信，曹操早年别驾毕湛之子，子娶公主\\n\\n桓范：龙亢桓氏，曹操乡里老宿\\n\\n以上人物下场：夷三族\\n\\n高平陵之变里司马懿的两位主要盟友太尉蒋济和司徒高柔。蒋济反对将曹爽诸人灭族，是曹魏政权的同情者，于是后世无闻，子孙无仕宦记录，五等封爵时获得一个子爵而已。相比之下高柔的后代就显赫多了，长子高俊大将军掾；次子高诞，历任三州刺史、太仆；三子高光，廷尉、尚书令，赠司空。这就是差距。\\n\\n高平陵之变里支持司马懿的士族代表是尚书陈泰和侍中许允，他们劝服了曹爽投降。陈泰是颍川陈氏司马懿密友陈群之子，高平陵之变时站在司马懿一边非常正常，但高贵乡公之事时，陈泰要司马昭诛贾充以谢天下，司马昭拒绝，于是颍川陈氏陈纪支名位遂微，不复汉魏两朝并有重名的景象了。许允是河北冠族，与夏侯玄、李丰为密友，两人被司马师诛杀后，许允也走到了司马家对立面，准备趁阅兵时做掉司马昭，然后再攻司马师，事泄被流放乐浪，半路被追杀。\\n\\n此外可能被牵连的还有尚书左仆射徐宣之子徐钦（桓范牵连）\\n\\n淮南一叛\\n\\n淮南一叛有既有忠于曹魏的因素，也有权臣争权的内质，我个人觉得王凌更想当权臣。王凌是王允的侄子，虽然以主弱受制于强臣为理由，但他的行为不太像匡正。王凌之所以敢与司马懿对抗，所依仗的就是曹魏四征三方与自己关系匪浅。王凌自己为假节钺、太尉、征东将军，外甥令狐愚为兖州刺史，专东南之重；征南为族弟王昶，都督荆州豫州军事，征西为郭淮，是王凌妹夫。不过王凌想的太多，做的太少，被司马懿亲征迅速平定。\\n\\n淮南一叛的影响扩散不大，一是因为司马懿之前杀的人太多了，二是王昶、郭淮都是司马懿提拔过的亲信，所以仅太原王氏祁县王凌支夷三族，太原王氏晋阳支、太原郭氏、太原令狐氏都安然无恙。\\n\\n可能被牵连的人大司农梁习之子梁施（王凌牵连）\\n\\n淮南二叛\\n\\n司马懿死后，司马师继续执政，这引起了魏帝曹芳的不满。因为司马懿自身是四朝元老、又受两代皇帝托孤，本身功勋卓著，所以由他辅政从皇帝到朝野并无异议。至于司马师就名位差很多了，凭什么可以掌控军政大权？\\n\\n魏嘉平四年春正月，（司马师）迁大将军，加侍中，持节、都督中外诸军、录尚书事。命百官举贤才，明少长，恤穷独，理废滞。诸葛诞、毌丘俭、王昶、陈泰、胡遵都督四方，王基、州泰、邓艾、石苞典州郡，卢毓、李丰掌选举，傅嘏、虞松参计谋，钟会、夏侯玄、王肃、陈本、孟康、赵酆、张缉预朝议，四海倾注，朝野肃然。\\n注意这些名字，全部与司马氏关系亲密，不是司马懿提拔的亲信，就是曾经在司马懿麾下效力，或者是司马师兄弟的通家之好。这里面大部分日后依然是司马氏的心腹重臣，小部分因为心向曹魏被司马家夷三族。\\n\\n中书令李丰、太常夏侯玄、光禄大夫张缉等准备发动政变，做掉司马师。计划泄露，李丰被司马师亲手锤死，夏侯玄被斩，张缉被赐死狱中。李丰是卫尉李义之子，魏明帝曹叡亲信，很可能和毌丘俭是早年密友，子娶公主联姻魏室；夏侯玄，曹魏宗室，征南大将军夏侯尚之子、曹爽表弟；张缉，凉州刺史张既之子，女为曹芳皇后。这次在中央的未遂政变，有很深的曹魏皇室背景，连皇帝曹芳都因此被废。受牵连者苏铄、乐敦、刘贤，都是小角色，不过待遇相同，全部夷三族。\\n\\n司马师废曹芳后，都督扬州的镇南将军毌丘俭与扬州刺史文钦起兵，司马师亲征淮南。毌丘俭是魏明帝曹叡亲旧，铁杆曹魏粉丝。文钦，曹操同乡部将文稷之子，曹爽亲信，忠诚度不如毌丘俭，但起吗也是曹魏支持者。事败后，毌丘俭夷三族，文钦逃亡入吴。\\n\\n除了二人外，受到牵连的还有刘陶。刘陶，大鸿胪刘晔之子，曹爽亲信。同为曹爽亲信的毌丘俭起兵后，司马师问计于刘陶，刘陶不肯多说，激怒了司马师，出刘陶为平原太守，路上被司马师派人砍了。\\n\\n淮南三叛\\n\\n诸葛诞并不是什么曹魏忠臣，只不过被司马昭逼反了。他的好友邓飏、夏侯玄已经提前一步夷三族了，之前都督淮南的王凌、毌丘俭也已经夷三族了，于是诸葛诞再接再厉，据要地，拥强兵，外联孙吴，准备割据了。这次是司马昭带着太后、皇帝，都督中外二十六万大军倾国之力亲征诸葛诞，激战十个月，诸葛诞传首，夷三族。此战过后，司马氏举国上下再无敌手。\\n\\n高贵乡公\\n\\n至司马昭执政时，朝中和外镇的反对势力基本已经被肃清，所以才有了高贵乡公奋力一搏，不愧为曹操子孙。高贵乡公平日为其讲经的是太保郑冲、司空王祥，与他讨论经学的是中护军司马望、侍中王沈、散骑常侍裴秀、黄门侍郎钟会，这些人全数出自高门大族，但已经全是司马氏的心腹了，没人心向曹魏了。郑冲荥阳郑氏、王祥琅琊王氏、司马望河内司马氏司马懿之侄，王沈太原王氏、裴秀河东裴氏、钟会颍川钟氏，而且这批人最后全部成为了司马氏的重臣。当然，钟会本身就是个野心家，最后玩脱了，把自己玩死了。\\n\\n不过高贵乡公一事事发突然，受影响的除了想让司马昭杀贾充的陈泰外，还有太尉满宠之孙满长武，他是司马家姻亲，照样被司马昭拷问杖死。\\n"}'));jctx.push(JSON.parse('{"id": "181230", "tag": "design", "text": "# 并不神秘的深度优先搜索\\n\\n在图中搜索到某个点的路径，把图映射成一张二维数组，每个坐标的值，区分障碍物，未走过，已走过等状态。\\n\\n深度优先的核心思路还是递归的应用，先确定下一步的寻路方向，然后把下一步的坐标点直接以递归的方式调用，虽然看起来只是一次函数调用，但已经穷举了这个坐标点后所有的可能。但是穷举这个方向不一定会有结果，所以当函数结束后，要回退这一步的尝试，换一种寻路的方向，再次递归尝试。如果是数组，只要单方向前进就够了，如果是地图寻路，可以在4个方向上做尝试，4个方向都尝试过，所有寻路的可能就穷举尽了。\\n\\n深度优先也属于穷举，只是用了递归的方式让代码看上去比较简洁。\\n\\n```\\n#include <stdio.h>\\n#include <stdlib.h>\\n\\nint gmap[6][5] = {\\n  0,0,0,1,0,\\n  0,0,1,0,0,\\n  0,0,1,0,0,\\n  0,0,0,1,0,\\n  0,1,0,0,0,\\n  0,0,0,0,0,\\n};\\nint move[4][2] = {1,0,  0,1,  -1,0,  0,-1};\\n\\nint gshort = 100000;\\nint gall = 0;\\nint gway[100] = {0};\\n\\nvoid printway(int cnt){\\n  int i = 0;\\n  for (; i<=cnt; i++) {\\n    printf(\\"%02d \\", gway[i]);\\n  }\\n}\\n\\n#define ISREACH(x, y) ((x==4)&&(y==0))\\nint sf_step(int x, int y, int cnt){\\n  int eps;\\n  int i=0;\\n  printf(\\"EPS:%p\\\\n\\", &eps);\\n  gway[cnt] = 10*y+x;\\n  gall++;\\n\\n  if (!ISREACH(x,y) ) {\\n    for (; i<4; i++) {\\n      if ( (x+move[i][0]<5) && (x+move[i][0]>=0)\\n        && (y+move[i][1]<6) && (y+move[i][1]>=0)\\n        && (gmap[y+move[i][1]][x+move[i][0]]==0) ) {\\n        gmap[y+move[i][1]][x+move[i][0]]=2;/*reach this slot*/\\n        if (1==sf_step(x+move[i][0], y+move[i][1], cnt+1)) {\\n          cnt+1<gshort? gshort=cnt+1: 0;\\n          return 1;\\n        }\\n        gmap[y+move[i][1]][x+move[i][0]]=0;\\n      } else {\\n        continue;\\n      }\\n    }\\n   } else {\\n      printway(cnt);puts(\\";\\");\\n      return 1;\\n    }\\n    return 0;\\n}\\n\\nint main(int argc, char** argv) {\\n  int x,y;\\n  x = atoi(argv[1]);\\n  y = atoi(argv[2]);\\n  printf(\\"%d,%d\\\\n\\", gall, sf_step(x, y, 0));\\n  return 0;\\n}\\n\\n```"}'));jctx.push(JSON.parse('{"id": "190103", "tag": "net", "text": "# 网络层的交换与路由\\n\\n## 网段定义\\n\\n对于私网地址的规范，在RFC 1918 - Address Allocation for Private Internets里有完整的规范定义。其中A类，B类，C类网段各取了一部分：\\n\\n* 10.0.0.0/8 (255.0.0.0)\\n* 172.16.0.0/12 (255.240.0.0)\\n* 192.168.0.0/16 (255.255.0.0)\\n\\n192的私有网段只能放下255^2即6万多台主机，家庭当然够用，但大企业可能就不够。所以大公司内网会用10或172网段。\\n\\n可能最早的路由是用192.168.0.1，从最小的0开始合理，后来随着小区有了网络，为了避免和外级网络冲突，用了192.168.1.1，好比现在的无线网络用192.168.2.1，原理是类似的。\\n\\n最后一位不能用0。原理大概是这样，0和255都是广播地址，**关于0到底是广播还是主机号，此处存疑，但不用肯定没错**。0不能被主机使用，255可以。但如果用255会被用作广播的收端，尽量避免。有些特殊会用254，所以也有路由器用253地址。\\n\\n倒数第二位用0虽然理论上很正确，在早期的路由器中，0段子网在没有子网掩码的情况下会与它的网络号相同而产生路由上的混乱，古老的路由协议RIP在路由时就不考虑子网掩码的问题，所以在cisco的设备上才有 ip subnet-zero这个命令来打开对 0段子网的支持。可能出于规避目的，用192.168.1.1。当然现代的路由器应该不需要考虑这些问题了。\\n\\n## 交换和路由的区别\\n\\n简单的说，同一个网段内叫交换（二层），不同网段之间叫路由（三层）。现实中也有三层交换，属于特例。\\n\\n早于IP网络的电话交换机，可以理解为一层交换。对电话来说独占一条物理电线，不存在IP分包的概念，直接对物理介质做交换控制，所以是一层。\\n\\n路由路径在二层和三层的路径是不同的。二层用ARP协议，从IP反查MAC直接物理层就找过去了。三层就全是IP寻路，通过网关出去，并由网关往后一级的网关传递，最终找到目的地。\\n\\n有两个常被忽略的属性，dev和scope。dev相对于对gateway的一个更小的约束。同样起到约束作用的还有scope。Scope是一个更小程度的约束，指明了该路由在什么场景下才有效。也是用于约束目的地址的。例如不指定网关的二层路由，通常对应的scope类型是scope link。scope link的意义就是说明在同一个二层。这个意义与网关不指定的效果是呼应的。\\n\\n四种scope\\n\\n1. global是在任何的场景下都有效，link是在链路上才有效，这个链路是指同一个端口，也就是说接收和发送都是走的同一个端口的时候，这条路由才会生效（也就是说在同一个二层）。Global则可以转发，例如从一个端口收到的包，可以查询global的路由条目，如果目的地址在另外一个网卡，那么该路由条目可以匹配转发的要求，进行路由转发。\\n2. link的scope路由条目是不会转发任何匹配的数据包到其他的硬件网口的。\\n3. host表示这是一条本地路由，典型的是回环端口，loopback设备使用这种路由条目，该路由条目比link类型的还要严格，约定了都是本机内部的转发，不可能转发到外部。\\n4. site是ipv6专用的路由scope。\\n\\n## route命令\\n\\nWindows和Linux的参数不完全一样，网上找文章时要注意。route命令除了添加了删除，还能屏蔽某种路由路径。route命令除了支持inet协议，还能支持ax25、ipx、netrom等数种二层协议，不过由于/proc/net/下没有对应的文件，所以没有使用。\\n\\n## 路由协议和preference\\n\\n到某主机有多条路可选，会挑选优先级高的。比较方式先匹配掩码长度，再比较管理距离(比如metric)。掩码长的高于掩码短的，所以3种路由顺序如下\\n\\n1. 主机路由，直接指明某台主机，/etc/hosts\\n2. 网络路由，指明某类网络怎么走\\n3. 默认路由，也叫默认网关，一般是目标地址为0.0.0.0的那条\\n\\n路由器往往支持多路由协议，这就有一个多种路由的选择和配合问题。为了解决这个问题，在路由的参数中引入了优先级（preference）的概念。各路由协议一般来说都定一个固定的preference值，preference值越小，协议对应的路由的优先级越高。以下是业务标准的路由协议：\\n\\n* 直接路由  0\\n* OSPF路由  10\\n* IS-IS的level 1的路由  15\\n* IS-IS的level 2的路由  18\\n* RIP路由（Berkeley）  100\\n* BGP路由 170\\n* EGP路由（已被BGP淘汰） 200\\n\\nRIP是最简单的协议，只告诉近邻，距离目标有几跳，且当目标之间距离变长后，并不会更新，因此网络收敛非常慢。RIP协议规定跳数上限是16，因此17可以认为是目标不可达。\\n\\nOSPF/ISIS比RIP高明的地方，RIP只知道邻居选择告诉自己的消息。OSPF/ISIS邻居不会隐瞒任何消息，会毫不保留地将消息传递给整个参与OSPF/ISIS网络里的任何一台路由器。因为信息同步是OSPF/ISIS能够正常工作的前提。如果不同步，OSPF/ISIS有网络环路的可能。OSPF内划分一个或多个Area，规模小的话只要一个Area0就行。由于OSPF/ISIS分享的信息过多，只适合运行在一个AS（Autonomous system 自治系统）内部，自治系统可以是一个公司，或一个校园网，也可以是一家运营商。每个AS会有个独立编号，公安网内部号段6xxxx和7xxxx。\\n\\nRIP、OSFP都属于内网路由，但规模不能太大，如果是非常大的AS，或者AS之间，就要引入BGP协议。\\n\\nBGP路由最复杂，主要用作不同AS间的边界网关，也是互联网惟一的协议。可以配置路由的颗粒度。颗粒度是由路由前缀的长短决定的，比如17.0.0.0/8的颗粒度很粗，17.1.0.0/16就会稍细，当然17.1.1.0/24颗粒度会更细。但是颗粒度太细，又会造成路由表的臃肿不堪。当前对颗粒度的要求是，路由前缀的长度，要≤21。\\n\\nBGP是唯一使用TCP作为传输层的路由协议（端口179），其他的路由协议可能都还到不了传输层。TCP连接的窗口是65K字节，也就是说TCP连接允许在没有确认包的情况下，连续发送65K的数据。而其他的路由协议，例如EIGRP和OSPF的窗口只有一个数据包，也就是说前一个数据包收到确认包之后，才会发送下一个数据包。当网络规模巨大时，需要传输的数据也相应变大，这样效率是非常低的。这也是它们不适合大规模网络的原因。而正是由于TCP可以可靠的传输大量数据，使得BGP适合大规模网络环境。\\n\\nBGP不同算法对收敛速度影响不同，比较快的有BFD，FRR算法。\\n\\n## 路由metric的含义\\n\\n需要区别的是路由开销（metric）和路由优先级（preference）这两个概念。metric是针对同一种路由协议而言，对不同的协议，由于代表的含义不同，比较不同协议的metric是无意义的，所以要在两条不同协议的同信宿路由中作出选择，只能比较路由的优先级。相反，preference是针对不同协议而言，同协议的路由的优先级是一般情况下一样的，metric这时是在两条同信宿路由中作出选择的标准。"}'));jctx.push(JSON.parse('{"id": "190108", "tag": "os", "text": "# 环境变量的继承\\n\\n操作系统有一片空间保存环境变量，我猜测这只是一片只读空间，每次用户登陆会创建一个会话，这个会话首先继承了全局的全局变量，如果脚本中export了某些环境变量，会作用到这个环境，但是其它用户登陆后，完全不受影响。\\n\\n典型的同一个账号，先export A=123，另一个会话也指定export A=456，不会影响前一个会话，这是两个完全隔离的会话。export的效力仅及于该此登陆操作。\\n\\n再看看同一个会话中启动一个shell进程会如何。每个shell创建的进程，除了argc, argv 就是env了，父子间的env到底能不能打通呢？事实表示，父改了，子会受影响；但子改了，父是感知不到的。\\n\\n如果不考虑fork子进程，仅仅当前环境使用的话，不需要export，仅使用 A=123 就会在当前环境创建变量，只是子进程无法看到这个变量罢了。\\n\\n综上export不是定义环境变量必须的语法，只是为了让子shell能感知到，将环境变量**提升**到可被子shell感知到的区域。\\n\\n说了shell顺便说说tty和terminal这两个概念。远古时代的计算机需要穿孔打印机和纸带进行操作，自从有了电传打字机，打字机输入，输出会打到纸上，虽然有些费纸，但已经比纸带有了巨大的进步。大型机体积巨大，但多人需要使用，所以每个人看到的就是terminal，tty算是最原始的终端形态。\\n\\n打印到纸上也勉强能算，毕竟不方便，随着70年代末出现的CRT显示器，terminal更多地被用于video terminal的简写。至于现在的软tty，包括各种stdin, stdout只是保留这个概念，形式上已经差别很大了。"}'));jctx.push(JSON.parse('{"id": "190110", "tag": "protocol", "text": "# 视频取流协议\\n\\n## RTSP\\n\\nRTSP支持RTP/AVP, RTP/AVP/TCP两种传输模式的，前者也可以写作RTP/AVP/UDP，这种模式因为是UDP传输，客户端会携带自己的端口，通常是两个，音频和视频。而TCP是RTP over RTSP over TCP方式，复用连接并不需要传递端口。\\n\\nVLC向StreamApp请求，发送SETUP时指定RTP/AVP。由于库本身的问题，只能支持TCP，回复455表示不支持，于是VLC发起OPTION尝试，但响应中又携带了SETUP，于是VLC就不知道该如何执行下去。\\n\\n看起来似乎RTSP缺少一种更灵活的协商机制，但是考虑到TCP和UPD特性对视频的影响，如果协商变成由服务端来决定，显然并不符合客户的本意，这个SSL的协商在业务领域是不同的。虽说也可以做成SETUP时交换能力，在PLAY时指定方式，似乎和SDP的阶段又有冲突，也许是它的不足吧。\\n\\n## 浏览器无插件视频播放\\n\\n看了IPC的浏览器播放，速度很快体验很好，抓包看实现，网络协议用 RTSP over WebSocket，用HTTP的upgrade部分切换，要注意的是必须先F12打开开发工具，再进入视频页面，这样才能在Network页签看到网络数据。\\n\\n可以看H265视频，组合了多种技术\\n\\n首先解码部分单独跑在worker里，音频和视频各一个，解码部分用了FFMpeg，这块估计是用了WebAssembly实现的，但不能实证。既然播放H265那就肯定不是用video标签，用的是canvas呈现，将视频解码并转成图片画上去的。虽然能播放H265，但是码流太高还是非常卡，实测在3M码流时已经掉帧严重，几秒后自动切入辅码流模式。\\n\\n## HLS\\n\\nHLS是HTTP Streaming传输视频的一种，由Apple提出，另外3GPP，微软和Adobe也有类似的技术，由于iPhone太强势，使得HLS几乎无人不知。\\n\\nURL对应的索引文件，就是M3U8，8代表UTF8。格式像这样\\n\\n```\\n#EXTM3U\\n#EXT-X-VERSION:3\\n#EXT-X-ALLOW-CACHE:YES\\n#EXT-X-MEDIA-SEQUENCE:0\\n#EXT-X-TARGETDURATION:1\\n#EXTINF:0.998, no desc\\nhttp://media.com/seg1.ts\\n#EXT-X-ENDLIST\\n```\\n\\nhtml5的video标签本来只支持3种封装格式，mp4/ogg/webm，这几种格式似乎都偏向点播。而Apple在safari的实现中额外支持了ts，为什么要用 TS 而不是 MP4，这是因为两个 TS 片段可以无缝拼接，播放器能连续播放，而 MP4 文件由于编码方式的原因，两段 MP4 不能无缝拼接，播放器连续播放两个 MP4 文件会出现破音和画面间断，影响用户体验。这就是Living的意思。最简单的方式是video.src"}'));jctx.push(JSON.parse('{"id": "190111", "tag": "lang", "text": "# Lisp与静态类型\\n\\n别的不说罢，你跟我说 Common Lisp 的类型系统是宏？没有融入语言核心？SBCL 等实现的 static type declaration 不需要编译器层面的支持？可去您的罢。SBCL 这种还不够静态？没办法 OOP 这玩意总归得用些动态类型特性，那我们限制在一个比较小的语言标准， barak/stalin 能通过分析整个程序推导静态类型直接免除运行时的动态分发，用的就是标准的 R4RS，不需要任何额外的类型声明。\\n\\n啥，要的是那种 type as specification 的类型系统，那种 tc 过后就 strip 掉的东西不用 preprocessing 实现还能用啥？\\n\\n啥，要 Lisp semantic 的支持，讲道理本质上是 untyped lambda/predict logic 的玩意要怎么加。\\n\\n用 ADT 有啥问题么，搞得和 Lisp 就不是 ADT 了一样\\n\\n```\\ndata Lisp = Symbol String\\n          | Nil\\n          | Cons Lisp Lisp\\n\\nexample :: Lisp\\nexample = (Cons (Symbol \\"defun\\")\\n           (Cons (Symbol \\"id\\")\\n            (Cons (Cons (Symbol \\"x\\") Nil)\\n              (Cons (Symbol \\"x\\") Nil))))\\n```\\n\\n还 list 换 lazy stream，lazy stream 本质上就是个给定上一个输出给出下一个输出的函数，有啥花头的，CLtL2 Appendix A 就有 Series 了，Appendix B 就是 Generator 了。\\n\\nReferences\\n\\nCLtL2 by Guy Steele 顺便一说，81-86讨论语言方向，86到94年才最终定稿。\\n\\nInterpreting Lisp by Gary Knott\\n\\n这里应该有一本用 ML/Haskell 写 Lisp 解释器的书，然而我忘了具体哪本了\\n\\nProgramming Languages and Lambda Calculi by Matthias Felleisen & Matthew Flatt\\n"}'));jctx.push(JSON.parse('{"id": "190120", "tag": "book", "text": "# 梁山排名解\\n\\n关于几个点，第一个，鲁智深确实是天下第一的好男子，但评价好坏，要论品行，打死镇关西虽是无心，但却是一个黑点，且改为上中人品；第二个，青州虽有错在先，但百姓无辜，所以宋江、花荣洗不白，可他们又和普通杀人魔不同，所以花荣列为中下；第三个，秦明认花荣作大舅哥，也是身不由己，但确实凉薄，对于一个没有恶行的人，不该是中下，所以是中品，张清列为中品，也是因为对妻子不地道，林冲不一样，他是完全没有担当，看着老婆进火坑，所以是中下；第四点，当时朝廷无德，权臣窃国，所以占山为王、取生辰纲、军官投降非梁山人物之过错。\\n\\n\\n话分两头，这个山头在招安之前，是邪恶的，看似杀了不少贪官，实则是为了粮草。打东昌府那次，结尾说，太守清廉，饶了不杀。如果真的是替天行道，为什么要打东昌府，为什么要连累当地百姓？打大名府，军民死伤半数。每除去一个贪官，都要满门抄斩，包括妇女、小孩、丫鬟、仆人，说实话，在《封神演义》中纣王自焚的一段，作者尚有怜惜无辜宫人的情感，虽然封神只是二流小说，但可取之处不少。\\n\\n此外，畸形的侠义。男人喜欢女人是可耻的。亲密度决定立场，如施恩、蒋门神都不是什么好东西，但施恩和武松亲密；孔家兄弟行凶杀人，占据白虎山、落难于官府，按道义，不该相助，但武松、梁山还是帮了。道德绑架，李忠的二两银子，史进和李睡兰。随意行凶闹事，就连鲁智深都有不让李忠卖药，打掉小二牙齿的黑点。为了所谓的义气，视家人如无物，汤隆和徐宁就不说了，讲义气的乐和为了救二解，联合孙新坑姐夫孙立，想过姐姐吗？\\n\\n\\n另一头，说梁山人：\\n\\n七领袖：宋江，给晁盖报信是义气，还是目无王法，暂且不论，因为朝廷不咋地；为人有可取之处，识英雄，对武松、李逵是真心相帮；情商高，百两黄金，取一条，既顾全兄弟情义，又没让梁山乱花钱；热心肠，得到一条金子，马上想到帮助老人家；知廉耻，救刘高妻子于清风山。但此人可同富贵，不能共患难；平常的时候，是个君子，紧要关头，暴露凶心；而且贪婪、野心极大。清风山陷害秦明，说实话，刘高事件是青州官府的错，还是花荣、宋江的错？宋江好心救人，被反咬一口；兄弟无辜被抓，花荣挺身相助，花宋并无理亏之处，反倒是青州官府不察，宋江虽然害了秦明，但彼此为敌，本来就是你死我活。是青州先捉拿的宋江，宋江后烧的民居，错不在宋江，而在官府，只是可怜的还是无辜百姓。此后，杀黄蜂、灭高廉，打祝家庄、曾头市、芒砀山，都是对方自找。可是对李逵、对朱仝、对晁盖、对林冲、对大名府、东昌府的百姓，宋江做的如何？可谓狠心。宋江有优柔寡断之处，四大奸臣，三个带亲，高俅只是个外人，梁山打了杨戬，杀了高廉，杀了蔡京门生，差点害了蔡京的女儿女婿，此仇已经不能解，反倒杀了高俅，倒有敲山震虎的作用，而且可以通过贪生怕死的高俅，引来高衙内，杀此贼父子。结果呢，放了！又想打个大仗，又畏首畏尾。但此人，大义不亏；纵是朝廷排挤，坚决不降辽国；面对辽国贿赂，痛斥之，不辱国威；为官时，兢兢业业；身死时，不忘忠心。所以宋江表面忠厚，内心狠辣，又颇有气节，为人中品。\\n\\n卢俊义，心地善良，救李固、抚养燕青；面对混江龙水淹太原城，不因战胜而喜，反为百姓而悲。善。\\n\\n吴用，为人歹毒(不用多说)。\\n\\n公孙胜，道德之士。\\n\\n朱武，占据少华山，只为谋生(只看到少华山为了生存打劫粮草，未见害人举动)；为陈达，甘冒风险；为了少华山，情愿将首领之实位让于史进(为保一山，而将一山之富尽托付于外人，此等胸襟，王伦难比)；兄弟死后，洒泪祭奠，朱武者，国之栋梁，人中君子。\\n\\n柴进，就凭他姓柴，他养士人、留囚徒就合理合法，未有害人之举，善。\\n\\n李应，先是祝家庄负李应，后是李应置身事外。未有害人之举。善。\\n\\n七个领袖，一个知大义(宋江)，三个君子(卢俊义、朱武、公孙胜)，两个好人(柴、李)，只有一个小人(吴用)。\\n\\n五虎：关胜，重情重义。虽降梁山，而宋非季汉，宋徽宗不是刘备，蔡京也不是诸葛亮，且关胜先服宋江为人，后上的梁山，不愧祖宗。是个英雄。\\n\\n林冲，欺软怕硬，为人怯懦，有点智障(比刀、当董超和校霸的面夸鲁智深)。杀王伦是污点，虽是柴进举荐，但梁山毕竟姓王，但个人认为林冲是一时兴起，非有意如此，情有可原之处。为人中下。\\n\\n呼延灼，高手有两种，一种是一生无敌、所向睥睨，一种是被更厉害的高手打败，呼延灼是唯一没被其他高手打败且鲜有胜绩的高手——鲁迅。这哥们挺逗，骂了上梁山的凌振，自己也上了梁山；有一个黑点就是，走投无路的时候是慕容帮了他，结果他反倒领梁山军马攻打青州，看在身不由己的份上，理解一下。人品中下。\\n\\n秦明，这个太惨了。人品中等。\\n\\n董平，人渣，最坑的是程万里不想得罪梁山，是他得罪的梁山；结果带着梁山杀了程万里。\\n\\n五虎之中，一个人渣。\\n\\n八彪：朱仝，重情重义，善。\\n\\n花荣，宋江铁粉，人品中下(毕竟有青州事件)。\\n\\n张清，这哥们最逗的是，和老婆亲热完才说，我叫张清。人品中等。\\n\\n索超，愣头青，人品算中等吧，脾气不好。\\n\\n杨志，有些怕事、脾气差；但杀牛二，主动自首；生辰纲被劫，没有补刀杀了几个坑货，人品中上。\\n\\n穆弘，横行霸道、无视人命，恶。\\n\\n徐宁，惨，算是个好人。\\n\\n史进，水浒传中的黄天化，品格高尚，做事糊涂。被王进打败，马上认错，为人大气坦荡；苦留王进、为父守丧，知恩图报，有孝心；大战陈达，保卫乡里，有勇气、担当；义释三人，有情有义；少华山派人半夜送礼，没有推辞，为人豪爽，知道体谅他人；还礼的时候，只送衣物用品，不送金银珠宝，可知史进是真心待人，并非表面形式；大战华阴县，有血性；尊敬李忠这个半吊子师父，念旧情，知感恩；救王义，闯华州，侠肝义胆。缺点也明显：不务正业，败家子，有孝心没孝行；不会说话，好得罪人；没有心眼(相比宋江只拿一条，史进的来者不拒就太稚嫩，毕竟人心隔肚皮)，也就是坦诚大劲了，题外话，这也是鲁智深和史进最好的原因，瓦宫寺，鲁智深知道史进需要钱，让他先挑，史进也不客气，捡好金银包了一包，要是所有兄弟都像这二人，生活将轻松不少；太稚嫩，做事少考虑，一时兴起烧了庄子，当时不肯落草，等到走投无路了回去，那差别就很大了；好色，结果坑了一个无辜妓女。不知如何评价，说是上品人物，却多是混账行径；说是下品人物，却是个响当当的英雄，故评为中品。\\n\\n八骠之中，只有一个恶人。\\n\\n十步：鲁智深：梁山里面，唯一一个尊重女人，还和别人讲道理的好汉，桃花庄里，庄客骂他找死，他还据理力争，挺可爱的。但镇关西，罪不至死；杀人之后畏罪潜逃；随便动手打人店小二(本来就手重)，这些都是过失，虽然我非常尊敬鲁智深(假如我是梁山一员，一定反对招安，因为鲁智深反对招安)，但过错明显，人品就列为上中品。\\n\\n武松：前期打人未伤人命，暂且不提；对施恩，也算是照顾小弟，也不提；血溅鸳鸯楼，虽杀无辜，但愤恨所致，可以理解。但是蜈蚣岭杀小道童，白虎山下行凶，若是不上二龙山，不知道要害多少人，还好迷途知返，皈依佛门，人品中品吧。\\n\\n石秀，之所以杀人，非为杨雄，乃为私愤，性情残忍，虽有智慧，仍为恶人。\\n\\n杨雄，兢兢业业好干部，努力工作好丈夫，善待石秀好兄弟，虽然杀人犯法，一来妻子有过，二来石秀引诱，再者心中愤懑。故应该是个好人。\\n\\n二解，本本分分的可怜孩子，好人。\\n\\n雷横、刘唐，人品只能是中下。\\n\\n李逵，十恶不赦。\\n\\n燕青，有智慧，不滥杀无辜，坦坦荡荡(从见李师师后，和戴宗的对话看出)，真真的君子。\\n\\n好的极好，坏的极坏。\\n\\n一个情报官：戴宗，酷吏，而世风如此，故戴宗非是恶人，人品中等。\\n\\n八水军：李俊，揭阳岭上，只有他不做人命的生意，虽水淹太原城，乃是为国效力；侠肝义胆，重情重义，二童为助手，也是重情重义，三个都是上品人品。\\n\\n二张都不是好东西，而张顺清白些，张横手里，不知多少人命。\\n\\n三阮，容易被利用，但没什么大过失。\\n\\n水军一个恶人(张横)。\\n\\n三十六天罡加上三个地煞，步军恶人最多，步军之外，吴用、董平、穆弘、张横是恶人，宋江、张顺不算好人，林冲、呼延灼、花荣有些污点。\\n\\n十六小骠：黄信戏份不算多，人品算中等。\\n\\n孙立先被兄弟坑，迫不得已，又坑兄弟，且彼此敌国，此为兵不厌诈；如果孙立单枪匹马，找栾廷玉劝降，栾廷玉、祝彪会放了他吗？所以并不能说是孙立的过错，非是孙立人品差。\\n\\n关胜的两个副手、水火二将，都是有情有义的人。\\n\\n呼延灼的两个副手，人品也没什么不好。(朝廷军官的素质是真高)\\n\\n陈达、阳春，我相信少华山上都是君子。\\n\\n欧鹏，武功不错，人品不知；邓飞，疾恶如仇，颇有侠气(救裴宣、让位)。\\n\\n杨林，有些英勇之处；马麟，这个出场太少。\\n\\n周通，一个有礼貌的强盗，但不是好东西，人品中下。\\n\\n燕顺，食人恶魔，恶人。\\n\\n小骠有两个坏东西。\\n\\n十七小校，芒砀三侠，皆是好汉；鲍旭，听名号就是心狠手辣之辈。其他十三个， 施恩、穆春，横行一方(施恩还好一些)，李忠，有过谋财害命的行径；龚旺、丁得孙、薛永、宋万、杜迁、郑天寿、焦挺、石勇，普通人物；邹家叔侄，有情有义。\\n\\n五个好汉，八个寻常人物，一个不怎么样(施恩)，三个坏人。\\n\\n此外三十六人：\\n\\n六健将：孔明、孔亮，杀人的暴徒；王英，淫贼；扈三娘，可怜之人；吕方、郭盛，还算不错。\\n\\n三个恶人。\\n\\n十二个情报人员：张青、孙二娘、李立，人中恶鬼；王定六，平庸无奇；朱贵，平庸无奇，但过去梁山酒店的作风和十字坡相比，好不到哪里；杜兴，算是有情有义；顾大嫂、孙新，坑哥哥。\\n\\n白胜，也算是好汉了，在晁盖已经暴露的情况下，忍了许多刑罚才招供的；乐和，坑姐夫；时迁、段景住，盗贼。\\n\\n梁山情报人员普遍不咋地。\\n\\n六个斯文人士：神医、伯乐、书生、匠人、孔目、神算子都不错。\\n\\n两个行刑头领：蔡家兄弟，也算酷吏了，但危机之时，还知道救城里百姓，是两个好汉。\\n\\n一个炮手：凌振没什么黑点，还是那句话，军官素质普遍高。\\n\\n九个打杂的：汤隆，坑兄弟，恶人。\\n\\n朱富，下药杀人，虽然是为了救李逵，但也挺狠的，算是坏人。\\n\\n孟康，行凶杀人(不能算是军官，和被抓上山的不同)，坏人。\\n\\n曹正，颇有谋略，人品算中上吧。\\n\\n陶宗旺，好像连台词都没有。\\n\\n李云、郁保四、侯健、宋清，都不是什么坏人。\\n\\n十八个非武斗派，有三个坏人。\\n\\n这三十六人，算是好坏参半吧。\\n\\n总体上来说，梁山龙蛇混杂，好汉多，人渣也不少。\\n\\n\\n此外，还在这里更两篇和《水浒传》有关的文章吧！\\n\\n浅谈梁山排名：\\n\\n我的观点是除孙立改为天罡24，穆弘改为第38位，黄信改为第39位，其余皆不变。\\n\\n梁山排名四要素：\\n\\n第一，星位与人物命运对应；\\n\\n第二，组合不可破坏，多交错分布，一般情况下搭档多是奇偶排列，而水浒传多是偶奇排列(解珍34解宝35)；例外的是朱仝、雷横，花荣、徐宁，前者实力差距大，后者徐宁(金)没办法排花荣(银)前面\\n\\n第三，在其位谋其职，排名一般和职位有关(几乎没有猫腻)\\n\\n第四，特殊星位，燕青为天罡之末，但地位很高(相当戴宗)；朱武虽在第37位，却是地煞之首。\\n\\n先更天罡，我的观点是把孙立改为第24位，穆弘改为第38位，黄信改为第39位。\\n\\n天罡前四位没有争议，第五、第六位虽只差一位，但地位相差很多，第五位是群将之首、第六只是群将之一， 第五位是天勇星、第六位是天雄星，关胜、林冲皆配得上雄字，而林冲却当不起勇字，只因此人太过隐忍。\\n\\n秦明、呼延灼谁在前，谁在后都可以， 猛字最配秦明脾气；花荣箭术、武功皆一流，配得上英字，排在第九位恰到好处，对于梁山，五虎重于八骠，八骠重于步军，而五虎之末不如八骠之首，八骠之末亦不如步军之首，若先把五虎排完了，再排八骠，八骠排完了，再排步军，反而不尽人意，所以先排好四个主力(勇雄猛威)，之后紧接着是八骠之首，再好不过。\\n\\n五虎已有四位，关键是第五位的人选，有资格进入五虎的有杨志(林鲁杨本领相当)、孙立(梁山一流武将之间差距不大，但兼具智勇胆及应变能力的只有孙立)、董平(双枪绝技)、徐宁(金枪绝技)；张清武艺不太高、史进和索超性子太急躁，排除在外；朱仝按下不表(朱仝、雷横一对，没办法在九宫八卦阵中守八方，而五虎第五必须是四个方位中的一个)。再看兵器，关胜的刀，林冲的矛，秦明的棒，呼延灼的鞭，还差一样兵器：杨志使刀，与关胜重复；孙立使鞭，与呼延灼重复；董平、徐宁相比，董平双枪更出彩一些，所以董平进入五虎。\\n\\n正因为董平这个虎将并不太出色，所以不能排第十位。第十位的柴进对应贵字，十一位的李应对应富字；且看前十一天罡，先是首领，再是调兵遣将的军师，再是大将，再是掌管钱粮的头领，排得不要太好。第十二位的朱仝，打仗也是一绝，林冲爆发力超强，关胜越战越勇，朱仝速战速决；且朱仝名望极高，又是梁山两代首领的恩人，排在第十二位不错。\\n\\n朱仝这个骠将之后，是步军的两个大神(老大)。大佬级别排好了，就是最后的虎将董平。论本事，张清极为重要，董张cp排15、16位，之后是八骠中的三个杨志、徐宁、索超(性格短板)，确实按本事排的。再之后，是情报部长戴宗，财政部长在五虎快排完的时候出现，情报部长在八骠快要排完时出现，也是恰到好处。\\n\\n之后老规矩，再插两个步军大将，李逵本事自不必说，刘唐和石秀武艺难分高下，但刘唐属于创立家业的那一批头领，所以做了步军第三，排在李逵前面。插入两个步军大将之后，就是最后两个骠将，史进本事不必说，但孙立和穆弘二人，确实不好安排。\\n\\n论本事，孙立进入五虎都可以，穆弘不行；论地位，穆弘是一方霸主，孙立虽不如五虎八骠中几个朝廷大将、山头大王，却也是一系首领，不逊色于穆弘。难点在于职位，在九宫八卦阵之中，孙立等十六小骠负责守八方，穆弘、刘唐一马一步各带一个偏将负责守两侧，且穆弘、穆春兄弟正好是一正一副组合；但这个难点不是没有解决的办法：第一，孙立太强，使九宫八卦阵的西方气势过盛，换成穆弘更好；第二，一侧的刘唐和陶宗旺不是兄弟，所以另一侧的一对将领也可以不是兄弟，可以把穆春换成同样打杂的曹正，与孙立组成一正一副。关于命运，天究星，究者，极也，更符合孙立的智勇；关于组合，史进、穆弘cp感不强。孙立排在地煞，属于连降两级(五虎—八骠—小骠)，穆弘只是降了一级(八骠—小骠)。而且，有些星位是特殊的，可以把穆弘排在第38位地煞星，地魁、地煞对应天魁、天罡，正好是其余七十副将的首领，也不委屈这个一方霸主。\\n\\n八骠之后，排第五个步军头领，雷横既与朱仝一对，不宜太后，且剩下的天罡都是最后几个，排名前后也没那么重要了。步军排了一半之后，就是没有争议的水军六大头领，李俊为首，其余交叉；再之后是两对兄弟，二解武艺虽不如小骠前几个，但佐将易有，异人难得，这对兄弟是不可多得的特种兵，该在天罡之中。燕青压轴。\\n\\n地煞之首是副军师朱武，正如吴用是三十四正将之首，朱武为七十二副将之首，一正一副相对应，这就是所谓的特殊星位。朱武之后是地煞星穆弘，穆弘之后是地勇星黄信(莫非作者把孙立排在地勇星的位置是想表达孙立是地煞中的关胜)。\\n\\n再更地煞：\\n\\n地煞差不多原则：如果某个地煞比理想中的排名只差了几位，则视为排名合理。\\n\\n理由如下，第一：反正都是副将，没必要较真；第二：自作聪明有时候会适得其反，比如想让某些人的排名提前，可能其中一人前进两位、但他后面的四个人跑到他前面去了，排名反而退后了。\\n\\n首先强调一点：\\n\\n宋万、杜迁、朱贵几个老头领完全凭个人本事排名，不会受特殊照顾，这是晁盖时期定下来的规矩。\\n\\n接下来讨论原著排名的合理性：\\n\\n(一)先说三个特殊人物(前两个有资格超越穆弘、黄信)：\\n\\n第一个：裴宣，权限很大，精神天罡。天罡的排名是先军师，后大将；所以理论上地煞的排名最好是执军令者在前，诸副将在后，即裴宣紧随朱武居地煞星，效仿吴用、公孙胜。但提到裴宣，必须提萧让，两人在职务上是一对，萧让的职务是行文走檄调兵遣将，裴宣的职务是定功赏罚军政司，按职务，排名应是萧让在前，裴宣在后；但论职务，萧让是秘书官，不适合太高的排名，所以原著中朱武之后，先是四虎的八个副将，再是萧让、裴宣的这种排法是合理的。\\n\\n与萧让、裴宣相关的梁山五大技术人员金大坚、安道全、皇甫端、凌振、蒋敬，他们具体的排名不重要(骨干人物职位有时候并不高)，只要满足几个条件：排名不宜过高、亦不宜太低，不打乱其他组合、安皇cp，怎么排都说得过去。故原著凌振(地煞16)、蒋敬(地煞17)、安道全(地煞20)、皇甫端(地煞21)、金大坚(地煞30)五人的排名是合理的。\\n\\n第二个：樊瑞，是具有中等天罡实力的地煞。论势力，部下三千人马，在各山之中，仅次于梁山，碾压史进部下的七八百人；论根基，芒砀山之名不逊色少华山之名；论行军用兵，一战灭了史进一半人马，需要梁山总寨亲自出马才能降服。为何史进是天罡，樊瑞却是地煞，且排名不算高？樊瑞排入地煞唯一的原因就是个人战力问题，他不像二解、燕青那样可以搞情报工作，武力上又不如其他七个步军头领，所以只能是步军副将先锋，而非步军大将，故樊瑞只能居地煞之位。那为什么樊瑞不能排在第二位的地煞星，居地煞众武将之首？因为梁山坐次是按照职位功能排序的，步军不如马军，若樊瑞排在地煞众武将之首，那其对应的步军将校整体排名也该在马军偏将之上，此事关乎三军，不可因一人变动；所以樊瑞的排名要低于一部分马军偏将。至于排名的合理性，和扈三娘放在一起讨论。\\n\\n第三个：扈三娘，地煞之才有余，天罡之才不足。马军偏将，以扈三娘实力最强(孙立是天罡)。所以在穆弘、黄信之后(二元老)，就是扈三娘，这种排法理论上是可取的。但为将不只看武功，副将之中，关胜二副将、呼延灼二副将、水火二将懂得行军用兵之法，武艺又不输扈三娘多少，排在扈三娘前面也是合理，而且王英、扈三娘是一对，扈三娘的排名要考虑王英的排名，所以扈三娘的排名没有办法高于宣郝韩彭单魏。\\n\\n现在要同时分析樊瑞、扈三娘在原著排名的合理性，在此之前，必须要分析排在二人之前的十二个小骠：\\n\\n四虎的八个副将排在樊瑞、扈三娘前面是合理的：这八个人是一个整体，如关林秦呼不可分割，既然樊瑞要排在一部分马军偏将之后，那八副将理所应当居于樊瑞之前；扈三娘排在八人之后的理由不用再说。\\n\\n燕顺排名必须在欧鹏、邓飞之后，王英及其他小骠之前：欧鹏、邓飞武功高强，不逊色扈三娘及前八小骠，又是一山之主，兼具实力、地位，所以排在后八小骠最前，成为第五个虎将的副将；燕顺武功不高，但为一山之主，且清风山名声很高(大闹青州)，所以在后八小骠之中排第三位，居欧邓后，其他人前。\\n\\n小骠排名总论对，燕顺还需要一个搭档：陈达、杨春一对不可分，周通和李忠必须一对，所以要从马麟、杨林之中选一个做搭档，二人都是各自山寨副头领之一，但杨林是梁山和饮马川的牵线人，重要程度高于马麟；所以决定杨林是燕顺的搭档。\\n\\n因为燕顺的原因，所以决定了扈三娘必须排在前十二小骠之后。\\n\\n扈三娘王英、吕郭、二孔是守护中军的重要六健将，樊瑞、鲍旭、项充、李衮是步军小校中最重要的四个先锋，前者地位如同中等小骠，后者属于步军小校的佼佼者，两者地位相近，又因为马军重于步军，所以扈三娘等四个马军排名高于樊瑞等六个步军是合理的。至此，可以认为原著中，朱武、前八小骠、萧让、裴宣、中四小骠、扈樊十将和五个技术人员相互穿插的排列方式是合理的。\\n\\n樊瑞、鲍旭高于二孔、项李没有问题，二孔和项李谁前谁后都可以；但是吕郭高于扈三娘，鲍旭高于樊瑞确实有问题，考虑到樊瑞、扈三娘排名都不高，所以遵循地煞差不多原则，默认原著的排名。\\n\\n(二)讨论完三个特殊人物，再讨论位于地煞武力顶点的前八小骠：\\n\\n个人认为宣赞、郝思文是十六小骠中实力最强的两个，但穆弘、黄信两个作为元老，有资格排在二将之前；个人认为单廷珪、魏定国的武功及军事才能高于韩滔、彭玘，但由于原著中“林冲排名低于关胜，林冲副将的排名高于关胜副将的排名，呼延灼排名低于秦明，呼延灼副将的排名高于秦明副将的排名”这一迷之规则，所以不改变四人排名，前八小骠排名遵循原著。\\n\\n至此前三十地煞分析完了，除穆弘、黄信，其余排名皆与原著相同。\\n\\n(三)水军二童排名应为地煞中游水平，理由有二：水军地位不太高，二童是地煞之中难得的水军人才。所以二童(地煞32，地煞33)的排名是合理的。\\n\\n(四)最后分析其余四十人：\\n\\n先将这四十人分为四类：\\n\\n马军九人：一阶陈达、杨春、汤隆、马麟、孙新、顾大嫂\\n\\n二阶周通、张青、孙二娘(注：桃花山实力太弱，故将周通归于二阶)\\n\\n步军十六人(最杂的一类人)：一阶龚旺、丁得孙(二前哨)，李云、焦挺、曹正、薛永(步校四勇)\\n\\n二阶宋万、杜迁、李忠、郑天寿、陶宗旺、施恩、穆春\\n\\n三阶邹渊、邹润、石勇(二三阶这十个都没什么大本事)\\n\\n情报八人：时迁、乐和(金牌情报员)\\n\\n朱贵、杜兴、段景住(老江湖)\\n\\n李立、白胜、王定六(普通情报员)\\n\\n杂役七人：孟康、侯健、蔡福、蔡庆(有一定作用)\\n\\n宋清、朱富、郁保四(几乎没用)\\n\\n故个人认为的排名如下：\\n\\n一阶：陈达、杨春、汤隆，龚旺、丁得孙、李云、焦挺、马麟，宋清(地位最高的小弟)，时迁段景住(时段是一对)—乐和—孙新顾大嫂—曹正—薛永\\n\\n二阶：宋万杜迁—李忠周通—郑天寿陶宗旺(龙套兄弟)\\n\\n三阶：孟康与侯健—施恩与穆春、朱贵朱富—杜兴—蔡福蔡庆—张青孙二娘—邹渊邹润\\n\\n四阶：石勇，李立、白胜、王定六、郁保四\\n\\n注：—这个符号表示两个人并列(排名可以互换)，加黑的人物与原著排名出入较大(12个)\\n\\n与原著排名比较(排除了李云、焦挺、孙新、顾大嫂、时迁、段景住六个变动很大的人物)：\\n\\n1.(前二十个的原著排名)马麟、孟康、侯健、陈达、杨春、郑天寿、陶宗旺、宋清、乐和、龚旺、丁得孙、穆春、曹正、宋万、杜迁、薛永、施恩、李忠、周通、汤隆(我的排名：陈达、杨春、汤隆、龚旺、丁得孙、马麟、宋清、乐和—曹正—薛永、宋万杜迁—李忠周通—郑天寿陶宗旺、孟康与侯健—施恩与穆春)\\n\\n①因为二童的排名遵循原著，所以地煞31的位置需要一个人，小骠马麟比铁匠汤隆更适合(马麟与陈达兄弟排名的差距很小，三人地位对等)；②孟康、侯健在作者心中的重要程度与其在我心中的重要程度不同，故排名有较大差异，在此尊重原著；③龚旺、丁得孙两个前哨在作者心中没有那么重要，对此不能说作者错了，且二人原著排名与我的排名只有几名的偏差，选择尊重原著；④穆春在原著的排名有点偏高，但对于这种无关痛痒的人物，偏高几名或偏低几名，并无太大影响(可能与江州派对梁山的重要性有关，由此看，穆春的排名反而合理)；⑤汤隆的排名太低，其实力(后期屡立战功)及重要程度(造兵器)完全被低估。除此之外，其他人的排名出入不大。\\n\\n2.(后二十个的原著排名)杜兴、邹渊、邹润、朱贵、朱富、蔡福、蔡庆、李立、李云、焦挺、石勇、孙新、顾大嫂、张青、孙二娘、王定六、郁保四、白胜、时迁、段景住(我的排名：朱贵朱富—杜兴—蔡福蔡庆—邹渊邹润—张青孙二娘、石勇、李立、白胜、王定六、郁保四)\\n\\n与原著出入不大，情报人员及其他人员排名普遍很低(职务重要性决定)。\\n\\n3.李云、焦挺、孙新、顾大嫂、时迁、段景住六人：\\n\\n李云、焦挺虽然武艺高强，但李云的职位太低，排名不高没有办法；焦挺没有一点名声，实际作用同样不大，排名不高也是合理；\\n\\n时段二人最符合其星位，排名不可变更；\\n\\n孙新顾大嫂夫妻的实力完全被低估了，排名太低。\\n\\n(五)得出结论：\\n\\n七十二地煞，除孙立之外，汤隆、孙新、顾大嫂排名不合理，李云的职务安排很迷(不敢妄加猜测)，其余的倒也合乎情理，宋江似乎有意针对登州系和汤隆。\\n\\n(六)地煞排名改动问题：\\n\\n扈三娘、樊瑞不变(只差一两名而已)；李云职务不好改变，也不做改动。\\n\\n汤隆原为地煞52位，建议改为地煞38位(杨春之后)；孙新(原地煞64位)、顾大嫂(原地煞65位)，建议改为地煞45位、地煞46位(丁得孙之后)。但可行性为零，若变动此三人的排名，将有大批地煞的星位随之变动，导致整个地煞排名混乱，且这三人的排名没到非改变不可的地步。\\n\\n所以我的观点是除孙立改为天罡24，穆弘改为第38位，黄信改为第39位，其余皆不变。\\n\\n——————————————————————————\\n\\n梁山人物出身：\\n\\n天罡(排除七个骨干)二十九将：朝廷三人+一元老，宋江心腹，宋江老乡，二龙山系二首领，朝廷四将夹一个二龙山系头领，梁山元老，宋江心腹，二龙山系头领，宋江心腹，宋江老乡，水军六人，草根四人，卢俊义心腹\\n\\n七十二地煞：\\n\\n二龙山系军师、宋江心腹、登州系首领、朝廷六将\\n\\n名士、饮马川、黄门山、饮马川、清风山、饮马川、朝廷将领、黄门山\\n\\n宋江心腹二人、名士二人、宋江心腹二人、李逵心腹、芒砀山、宋江心腹二人\\n\\n芒砀山二人、名士、黄门山、水军二人、饮马川、草根、二龙山系二人\\n\\n清风山、黄门山、宋江兄弟、名士、朝廷二偏将、宋江小弟、二龙山系\\n\\n梁山旧派二人、草根、二龙山系三人、草根、李应心腹、登州系二人\\n\\n梁山旧派兄弟二人、草根二人、地方势力二人、草根二人\\n\\n登州系二人、二龙山系二人、草根五人\\n\\n01010101010101010101010101010101010101\\n\\n水浒之遗：\\n\\n与梁山好汉关系紧密的九个人：和武松有缘的头陀、史进之师王进、杨雄丈人潘公、孙立师兄栾廷玉、孙立的师父、郭盛师父嘉陵张提辖、扈三娘哥哥扈成、曹正妻舅、王定六的父亲，此外还有张青手下的阿二、阿三、四个捣子(或许还有其他火家)以及李立的几个火家这些杀人无数的恶人。\\n\\n关于水浒传的七个疑问：林冲、杨志的两把宝刀的去向(林冲的宝刀也许就是高俅那把)；\\n\\n紫金山、伞盖山、白沙坞、野云渡究竟存在哪些势力；\\n\\n韩伯龙死后，他手下两三个火家的去向；\\n\\n戴宗、乔道清、樊瑞、马灵，高廉、贺重宝、毒焰鬼王寇烕、包道乙师承何处；\\n\\n在晁盖之前夺取过生辰纲的人是谁；\\n\\n和李忠、周通打斗的那群客人的身份；\\n\\n好汉党世雄的去向。\\n\\n\\n九大奸贼：蔡京、童贯、高俅、杨戬、蔡攸、王黼、朱勔、梁师成、李邦彦(书中提到七个)\\n\\n与四大贼臣有关的十个梁山仇人：高衙内、高府老都管、沧州管营、卖刀的人、欺骗林冲的两个承局、大名府张孔目、拟写招安草诏的翰林待诏、蔡太师府张干办、高殿帅府李虞候，高三郎、童贳、高俅提拔的寇州知府三个不知是不是奸佞之徒，梁山的仇人不包括与杨志一同护送生辰纲的那群人。\\n\\n与梁山好汉有关但没有下文的十七人：法华寺二僧(晁盖因之而死)、何涛、何清、唐牛儿、洪教头、周谨、大名府首将王定、截江鬼张旺(应该死了)、踢杀羊张保、祝家庄被偷鸡的店小二、剪径被燕青射伤的汉子、安定州的歪学究何才、范权、龚正、锦鳞龙翟源、冲波龙乔正\\n\\n\\n辽国下落不明的二人：驸马太真胥、皇侄耶律得忠\\n\\n三寇部下幸存二十六将(不包括与梁山好汉交好的几个)：于玉麟、陆辉、云宗武、冯玘、刘赟、许定、卫忠、家余庆、段恺，苏吉、方顺、卢元、费珍、薛灿、翁奎、杨春、蔡泽、傅祥、寇琛、管琰、吕振、吉文炳、安士隆、武顺、程胜祖、薛斗南\\n"}'));jctx.push(JSON.parse('{"id": "190121", "tag": "data", "text": "# SQLite分析\\n\\nSQLite指针是个很大的结构，包含vfs和Db结构。允许attach特性，可以同时有多个数据库，因此DB成员是数组，每个DB的最关键结构是BTree，最终读写OS上的磁盘页。\\n\\n使用Btree是针对磁盘的惯用法，m阶B树表示每个节点最多有m个出度，又叫分叉。因为m很大所以深度就浅了，相当于用内存多查几次换磁盘IO。B树另一个特点是至少有m/2个出度，原因同样是保持树尽可能浅，让树每一级承载的信息多一些。不取更高是考虑到有插入，太满的话旋转次数过多，因此要折衷。作者曾试图换成LSM Tree开发v4版，但最终停掉这个计划，大概是因为LSM太占内存，而在小型化场景一方面没有这么多内存，另外保障数据尽可能快地写入磁盘也是很重要的，结合来看B-Tree仍是最好的选择。\\n\\n管理每个存储数据的是pager，每个节点称为page，page大小一致，新数据库可设置，一旦持久化就不能改变。一定是2的幂，界于512到65536之间（在17和18字节表示，1表示65536）。\\n\\n第一页比较特殊，前100字节格式包含Magic Number，页大小，版本等。创建一个只有表定义，但没有数据的库，占2K，共2页，第一页是`sqlite_master`。\\n\\n表用B+树，数据只存在叶子上。索引用B树，所有页都有数据。展开一下，如果数据用B树保存，在条件检索时，结果数据会分布在不同层级，这就导致很多的磁盘随机访问，对机械硬盘非常不友好，SSD稍好，但仍然是连续访问优于随机访问。因此最终选择了B+树。页内最小单元是cell，每页头部是指针，尾部是内容，中间全为0，添加数据直接用中间区域，速度很快。\\n\\n## 扩展机制\\n\\nSQLite的基本单元是table及配套的view和index，如果要扩展功能就要使用virtual table机制，常见的有Full Text Search，Json和CSV等。virtual table只是概念，要实现需要module，看`sqlite3_create_module_v2`函数实现。通过`sqlite3_compileoption_get`函数可以看到使用版本中被编译了的模块。\\n\\n要关注的类型就int64,double,text,blob这4种，还有个null类型，但是以前看过一本书强烈地批判了SQL规范中纳入null这种不严谨类型的坏处，所以我想还是尽量少用为妙。\\n\\nSQLite最晚在3.15版引入了json扩展函数，但至少3.6版是没有的，也许SQLite的演化就是加入这种新功能吧。不过虽然代码有，默认是不编译的，需要定义宏才能把这些特性编译进来。创建一张表的时候，可以在最后用\\n`primary key(a_key, b_key)`这种方式指定两列为联合主键。\\n\\n如果就用gcc sqlite.c编译，通过`sqlite3_compileoption_get`只能看到3个选项：\\nCOMPILER、SYSTEM_MALLOC和THREADSAFE=1。其它高级特性都需要定制宏打开。\\n看的方法很简单，打开SQLite输入`select sqlite_compileoption_get(n)`就能看到。\\n\\n### 全文检索机制\\n\\n`CREATE VIRTUAL TABLE memo USING fts5(col1, col2, tokenize = \'porter ascii\');`fts5是module名，被创建的虚表用USING来继承一个已经实现的module，\\n这个virtual table就有了fts5这个module的全文检索能力，使用MATCH关键词的匹配速度快很多。\\n\\n全文检索最核心的要素是分词器，即tokenize指定的值，不指定则默认simple，不过至少要用icu才能处理中文。这种方式创建出的表，如果用.schema去看，会对应另外3到5张普通的table，3张是fts3和fts4共有，加了content、segdir、segments后缀的表。fts4则多两张start和docsize表，称之为Shadow Table。可惜中文分词必须引入ICU，这个库在windows并不具备，不实用。\\n\\n全文检索表除了用like，更多的是match，由于是全文检索，所以match前面通常是表名，不用列名。支持几种语法，但必须记得开头。fts5用倒排索引构建`full-text index`，支持prefix match，所以只能后面跟`*`，不能用在前面。\\n\\n1. match \'abc*\' 搜索abc开头的分词，但不能搜索12abcd(因为不是独立的词)\\n2. match \'ab* + cd*\' 搜索ab开头后面跟cd开头的词\\n3. neargroup: match NEAR(ab cd) 注意NEAR必须大写，ab和cd顺序随意，只要中间间隔词数量少于默认10，如果想更长，match \'NEAR(\\"a b\\", 20)\'\\n4. 支持 AND OR NOT，用\\"a b\\"指定a和b严格排序\\n\\n全文检索使用前缀索引，所以不能用`*a`语法。\\n\\n## lua与sqlite整合\\n\\n依赖userdata，因此一定配合newmetatable函数，元表关联ud实现在lua中无缝使用的体验。引申一句，通过newmetatable创建的表内部仍是通过newtable创建，只是这个表一定有名字，且名字会被保存在表的`__name`字段。另外元表也会记录在C的`LUA_REGISTRYINDEX`大表中。\\n\\n动态库入口创建4个元表，分别是对db的操作，对prepare产生的vm的操作，对context的操作，以及backup操作(需要两个db实例)。然后用`register_lib`创建动态库，这个库除了查版本外，就是创建db。\\n\\n## 不同语言的封装比较\\n\\npy和lua在执行DML操作时，py默认不会提交，需要手动执行commit，可以在connect时加上`isolation_level=None`。而lua的封装只有自动commit一种模式。大概是py要考虑多种DB的兼容性吧。\\n\\n## 测试数据\\n\\n* 5万条: 查整数的耗时只有5毫秒左右，定长31字符串的LIKE查询在15毫秒上下。\\n* 10万条: 查整数不超过15毫秒，字符串LIKE查询30毫秒。\\n* 30万条: 查整数不过30毫秒，字符串LIKE查询80毫秒。\\n* 150万条: 查整数140毫秒，字符串540毫秒。一旦开启索引，查整数5毫秒。\\n\\n索引占空间的大小取决于类型，150万条100M左右的库，整数索引增加16%，字符串索引增加95%（由于数据主体是字符串，可以认为翻倍）。\\n\\n即使做了字符串索引，似乎效果也不好，完全匹配的速度并没有提升，一旦用LIKE的后置%，速度降低到1/10。如果前后都有%，**索引完全不起作用**，耗时变为2.5倍。\\n\\n字符串建索引，对第一次不生效，但似乎会对结果做缓存，第一次查字符串，会耗时300毫秒，同样条件再查询不再耗时。作为对比，不开索引的库，始终耗时200毫秒。\\n\\n无索引查字符串，第1条0毫秒，中间第75万100毫秒，最后的150万200毫秒，非常严格地符合线性关系（要加limit 1，否则会全遍历耗时是一样的）。"}'));jctx.push(JSON.parse('{"id": "190202", "tag": "book", "text": "# 唯为-难产的帝国大朝会\\n\\n原创： 唯为  唯为  今天\\n\\n“我来问道无馀说，云在青天水在瓶。”\\n\\n一）\\n\\n从四月份新皇帝即位起，1521年，大明正德十六年，接下来整整八个月，早该举行的大朝会，迟迟无法举行。\\n\\n为什么呢？原因就是在某些核心问题上，新皇帝始终无法与他的同事们达成一致。\\n\\n围绕着帝国的意识形态——“大礼仪”——的争论与冲突，君臣对立和博弈愈演愈烈，气氛和态势越来越尖锐。\\n\\n决策层难以统一思想、形成共识，大朝会的举行遥遥无期。\\n\\n新皇帝与同事们的纷争，看起来纷纭复杂，归根结底其实就是一点：\\n\\n继嗣，还是继统？\\n\\n当初进京，朝臣一致认为他要按照皇太子的身份即位礼仪；他却坚持按皇帝身份登基：“遗诏以我嗣皇帝位，非皇子也。”\\n\\n是皇太子接班，还是新皇帝登基？是坚持原定礼法礼制政策不动摇，还是可以另起炉灶、新搞一套？\\n\\n分歧不解决就开不了团结胜利的大会。这是帝国政治的常态，也是定期举行的大朝会的实质：\\n\\n大朝会只是为了表达君臣和谐、上下同心、形势一片大好的信号，所有分歧和冲突都必须在大朝会之前妥善解决。\\n\\n故事，还得从一个来自遥远偏僻的湖北钟祥安陆王府的青年藩王讲起。\\n\\n二）\\n\\n正德十六年四月二十二日，北京，他在奉天殿即皇帝位。\\n\\n坐上龙椅之后，天生政治敏感的他立刻发现，自己不是一个真皇帝，朝政大小事务，自己说的话不好使。\\n\\n在他这个皇帝之上，还有一张无形的巨网，将他紧密笼罩，让他感到窒息，却又难以摆脱。\\n\\n这张巨网，就是以内阁大学士杨廷和为代表的文官群体。而杨廷和的背后，隐隐约约还有深宫中的那个可敬长者——伯母张太后。\\n\\n初来乍到，初登大位，他想说的话没有一句可以随心所欲地说出来，他想办的事情没有一件能够顺顺当当得以办成。\\n\\n这让他很不爽，让围绕在他身边的来自兴献王府的小兄弟们很不爽。从进京的那一天起，他们逐渐试图改变这一切。\\n\\n1）封赏\\n\\n他大力封赏从湖北钟祥带来的藩邸旧臣小兄弟，进行“掺沙子”活动：\\n\\n先把人安插到吏部，兴王府时的秘书长袁宗皋，被任命为吏部左侍郎，组织部常务副部长；\\n\\n接着在宫中提拨心腹，随驾来京的贴身太监谷大用等人受到提拔重用。\\n\\n他的这番行为，马上受到他的同事——文臣们的反对。\\n\\n三天后，吏科给事中阎闳上书，直言他“滥赏”太过分：\\n\\n“伏闻陛下赐扈驾太监谷大用等人……臣窃以为过矣。观历代以来藩王入继大统者，序援立之功则主威弱，私扈从之人则侍卫骄，弛戚倖之禁则请托行。”——《明世宗实录》卷一，正德十六年四月丁未\\n\\n第二天，兵科给事中夏言轮番上阵，居然对他定规矩，划红线，限行为：\\n\\n“时召内阁大臣相与论议裁决，或事关大体，众论不同者，则敕下廷臣集议，不宜谋及亵近，径由内批，……圣意有所予夺，亦必经由内阁议而后行事”。——《实录》卷一，正德十六年四月戊申\\n\\n处理朝政必须要和内阁大臣讨论，有必要甚至在廷臣中公开征求意见，集体研究后再实施，最高决策不能只出自皇帝身边不为人知的内廷小圈子。\\n\\n看完这两份刺耳的奏本，他的心情如何？史书无载，但记录了他的批复意见：前者，“嘉纳之”，接受批评；后者，留中，搁置，不作任何表态。\\n\\n2）看客\\n\\n即位的第六天，四月二十八日，他见证了自己执政后的第一场政治攻讦，紧接着见证了一个极其重要的人事变动。\\n\\n是的，这一切，坐在龙椅上的他，真的仅仅只是见证，犹如看戏的观众，对局势的发展毫无影响力。\\n\\n当日，给事中张九叙弹劾大学士梁储及吏部尚书王琼。王琼呢？直捣黄龙，直接抨击杨廷和“窃揽乾纲，事多专擅”。\\n\\n很快，堂堂的吏部尚书组织部长，王琼被立案审查，撤职下狱。腾出来的空缺，五月五日，由杨廷和的亲信、原礼部尚书石瑶接任。\\n\\n对这场朝堂风波，从《明世宗实录》来看，朱厚熜唯一能做的，就是按照杨廷和等人的意思办，签字同意。\\n\\n但是，在他的内心，是否隐藏着深深的不快呢？王琼指控杨廷和的那八个字，是否隐然拨动了他的神经呢？ \\n\\n3）双亲\\n\\n后来，我们都知道，他是大明帝国出了名的大孝子。\\n\\n登基后三日，他下令奉迎老母亲来京；登基后五日，他要求礼部尽快研究确定他刚去世不久的父亲的身份定位，“诏议兴献王封号”。\\n\\na）父亲\\n\\n不出所料，朝臣们一如既往从“继嗣论”出发，坚持帝国的既定路线方针不变。\\n\\n五月七日，新的礼部尚书毛澄提出他父亲兴献王封号初步意见：\\n\\n“皇上宜称孝宗为皇考，改称兴献王为皇叔父兴献大王，兴献王妃为皇叔母兴献王妃。”——《实录》卷二，正德十六年五月戊午\\n\\n啥意思？你要叫自己的伯父明孝宗弘治皇帝为爹，而自己的亲身父母，只能称为叔父、叔母。\\n\\n有的事可顺从，有的事可留中，有的事可忍隐，唯独此事，他铁了心不退让。他要求“再议”：“藩府主祀及称号，事重大，再会议以闻。”\\n\\n毛澄等人也很硬，毫不妥协，五月十八日回奏：我们提出的这个方案已经很好了“尊崇之典可谓至矣。臣等不敢复议。”\\n\\n他耐着性子，再次把报告打回去，要求多翻翻前代档案资料，继续“详议”：“博考前代典礼，再会官详议，务求至当以闻。”\\n\\n嗣还是统？左还是右？年轻新皇帝与同事们互不妥协，各不迁就，陷入了长时间的僵持。\\n\\n此时，朝廷中新生代瞄准时机冲了出来，为势单力孤的新皇帝摇旗呐喊，冲锋陷阵。七月初三，新科进士张璁公开上书：\\n\\n“则陛下之兴，实所以承祖宗之统，而顺天下之心。”——《实录》卷四，正德十六年七月壬子\\n\\n皇帝继承的是祖宗的大事业，而不是明孝宗一脉的香火，怎能让皇帝改称伯父为爹？\\n\\n他看了这份有理有据的扎实的论证报告，感动得一塌糊涂：“及得璁奏，喜曰：‘此论一出，吾父子必终可完也。’”\\n\\n但是，张璁的报告犹如捅了马蜂窝，受到中央和地方大小臣工的一致反对和抨击。\\n\\n地方派的压力来了。七月十二日，皇帝藩邸所在的湖广道御史上疏，明确认为“兴献王称号宜如礼官议”。\\n\\n藩邸老家的父母官都不帮自己，他气得说不出话来，批了两个字，“报闻”，已阅。\\n\\n中央的压力更大。七月十三日，杨廷和等人带头上奏，指责张璁的主张是“邪说”，坚持要求皇帝接受“继嗣”理论：\\n\\n“国家典礼，关系甚重，臣等实不敢阿谀顺旨。”——《实录》卷四，正德十六年七月甲子。\\n\\n紧接着，汹涌浪潮随之而来。朝臣们纷纷上疏，请求皇帝接受礼部所拟定的方案，重提皇帝行事须守规矩：\\n\\n“事必咨于辅臣，宠勿启于近习，割恩正义以定礼，稽古准今以崇孝。”——《实录》卷四，正德十六年七月庚午、丙子，邓继曾奏疏\\n\\n八月初一，礼部尚书毛澄第三次将原封不动的“皇叔父兴献大王”称号方案提交皇帝。\\n\\n但是，这一切压力，他顶住了，咬紧牙关，反复批示就是一句话：“命再会官详议。”\\n\\nb）母亲\\n\\n\\n不过，有了张璁等朝臣支持，有了锦衣卫人事布局的展开，逐渐增强了他对皇权的信心。\\n\\n请参阅本号《唯为 | “皇帝，是太阳，是雷霆#c530”》\\n\\n他开始尝试运用身上的大义名分和手中的最高权力。\\n\\n毕竟现在天下皆知他是一国之君，不管如何，处于决策最顶层的他，越来越体味到专制体制的奥妙：\\n\\n任何一件朝政大事，如果没有自己的同意，是无法得以顺利执行的！\\n\\n意识到这一点之后，他更加地渴望做一个“真皇帝”，而不愿意完全被文官政府所束缚、所操控。\\n\\n在个别不得已的问题上，他开始敢于对大臣们说“不”，以贯彻自己的意图和维护自己的利益。\\n\\n其中，首先就是他的老母亲“进京礼仪”的问题。\\n\\n父亲去世后，他对老母亲的感情极为深厚。离开钟祥王府时，他想念母亲，一路哭个不停：“不忍遽离圣母，呜咽涕泣者久之”。\\n\\n故世父亲的身份定位问题，尚可暂且搁置争议：老母亲一天比一天临近北京，用什么样礼仪来接待，是一个非常迫切的现实问题。\\n\\n这个问题，同样有“嗣统”的争论、左右的分别：按“继嗣论”，用王妃之礼；按“继统论”，用母后之礼。\\n\\n不出所料，礼部提出按王妃礼仪迎接：“豫遣文武大臣各一员于通州境外奉迎。至日，母妃由崇文门入东安门。”\\n\\n派人在通州迎接，再从侧门进宫。对此，想用母后礼仪的皇帝同样退件，要求“再议以闻”。\\n\\n这次，朝臣们作了一点让步。复议中，礼部提出新建议——“由正阳左门入宫”。不料，皇帝仍不满足。\\n\\n面对新皇帝的得寸进尺，礼部非常不满，在第三次复议时忍不住说出了一番情绪化的气话：\\n\\n“臣等初议由崇文门进东安门；再议由正阳左门进大明等门东门，而皇上仍令集议以闻。……自通州至朝阳门，路直且顺，从此进东安门便。”——《实录》卷六，正德十六年九月丁巳\\n\\n你爱让你妈从哪个门进就从哪个门进吧，我们不管这点破事了。\\n\\n4）甜头\\n\\n结果，文官们耍的小性子，反而激起了新皇帝的反抗勇气。\\n\\n他立刻下诏，直接否决礼部“用王妃凤轿仪仗”，改为“用母后仪驾”；走宫城正门，“从正阳门由大道行”。\\n\\n在迎接老母亲礼仪的问题上，他第一次使用皇权“独断”，没想到挺顺利，文官们就算不满也无可奈何。\\n\\n这种感觉太爽了！初尝最高权力的甜头，他食髓知味，试图用同样方式解决父亲的问题。\\n\\n十月初一，他借口钦奉“伯母张太后之命”，直接颁诏：\\n\\n“钦奉慈寿皇太后之命，以朕既承大统，父兴献王宜称兴献帝，母兴献后、宪庙贵妃邵氏为皇太后。朕辞之再三，不容逊避，特谕卿等知之。”——《实录》卷七，正德十六年十月己卯\\n\\n我的老父亲是“帝”，我的老母亲是“后”，我就这么定了，爱咋咋地！\\n\\n于是，礼部尚书毛澄等大臣们纷纷以辞职抗议。他呢，“优诏不允”，抚慰，优待。\\n\\n大军师之三国群龙录\\n广告\\n查看详情\\n\\n\\n三）\\n\\n短短半年，他已不再是涉世未深的地方藩王，对权力有了更多的理解。他积极介入或主动设置政治议题。\\n\\n他介入司法，多次直接更改刑狱审判结果。这一点，也令大臣们很感失望。\\n\\n“何近日以来事或少变，如法司奏上大狱，某等已经多官会审明白，拟以重典。臣等依票旨，未蒙愈允，往复执论数次，既而径从中改？”——正德十六年十月，毛纪奏疏\\n\\n他不断刷存在感，文官们觉得这个新皇帝越来越难操控，感叹皇帝在四方面渐渐变了：\\n\\n“信大臣渐不及始、广听纳渐不及始、 勤圣学渐不及始，明赏罚渐不及始。”——《实录》卷八，正德十六年十一月甲寅\\n\\n他用“内旨”的方式，想在父母“帝、后”尊号上加多一个“皇”字。对此，以杨廷和为首的文官政府，“封还御批”，拒绝办文。\\n\\n如果再加“皇”字，他的父母就和明孝宗、张太后等真正的皇帝、皇后并列，朱家祖庙的谱系排序就会大乱。\\n\\n“正统大义，惟赖一皇字以明。若加于本生之亲，则与正统混而无别。揆之天理则不合，验之人心有未安。”——《实录》卷八，正德十六年十二月\\n\\n明代权力结构，皇帝的诏旨、御批，要经过六科审核；六科若认为不妥，有“封还执奏”的权力。这是文官政府对于皇权的一种约束。\\n\\n不过，他故伎重演，又搬出深宫之中张太后这个长者来敷衍搪塞，“慈寿皇太后谕旨有谕”，“朕不敢辞，尔群臣其承命”。\\n\\n这一次，附和他的官员，除张璁等人外，还多了不少人。但是，绝大多数官员仍持强烈反对立场。\\n\\n世事就是这么奇妙。就在这期间，皇宫内发生了一连串火灾，文官们纷纷拿出生花妙笔，大加渲染：\\n\\n“禁中失火，密迩青宫。变不虚生，宜应之以实：法成汤之自责，效周宣之侧身；思礼乐教化之或愆，念庆赏刑威之有失；充其惧灾忧患之心，而致夫顺天悦亲之实上。”——正德十六年十二月，毛澄奏疏\\n\\n“今月二日长安榜廊灾，及今郊祀日，内廷小房又灾。天有五行，火实主礼。人有五事，火实主言。名不正则言不顺，言不顺则礼不兴。今岁未期而灾者三，废礼失言之郊也。”——正德十六年十二月，邓继曾奏疏\\n\\n“上天示戒，朕心警愓”，几场大火，他终于让步，同意不加“皇”字。1522年，嘉靖元年三月，他正式定议父母尊号为“兴献帝、兴国太后”。\\n\\n虽未能实现尊奉父母为“皇帝、皇太后”，但相比一开始的“皇叔父兴献大王、皇叔母兴献王妃”，他已在胜利路上迈进了大大的一步。\\n\\n更重要的是，从中他学到了很多，尝到权力美味，塑造了自己的强势姿态。不过，他也切身感受到那班文官对于皇权的束缚。\\n\\n四）\\n\\n一年多来，与文官政府的博弈，各色人物的表现及其行为背后所表露出的人性弱点，让他对权力的理解越来越通透。\\n\\n文官的固执、中庸、投机，乃至彼此争斗、攻讦，让他认识到这班士大夫不过如此，内心的极权欲望越来越膨胀。\\n\\n当然，他也知道：在文官没有出现重大分歧时，除了依靠目前这批大臣之外，他所能依靠的人毕竟还是太少、太弱。\\n\\n随着对厂卫等监察力量的掌控，他，慢慢地开始享受专制皇权的优越性，一步一个脚印地推行自己的意志。\\n\\n在尊崇自己父母的事情上，他有条不紊地继续进行着各种动作，以争取“继统论”彻底胜利，一举确立自己的治国新规则。\\n\\n八月，他在湖北钟祥县设置国家级的祭祀管理局，“命安陆添设祠祭署”，按照帝王的规格祭自己的父亲。\\n\\n十二月，他指示礼部为其刚刚去世的奶奶上“徽号”，即“尊号”，还要在明宪宗成化皇帝的寝宫旁选择安葬地。\\n\\n嘉靖二年四月，他要求制定“兴献帝家庙享祀”标准，四次“下廷臣会议”均被文官否决，他悍然“特旨”，“竟用八佾”，天子规格。\\n\\n如果说之前他尝试专权，还半遮半掩打着那个长者张太后的旗号，此时已完全熟练运用“个人独断”的专制权力了。\\n\\n五）\\n\\n愈演愈烈的专权态势，咄咄逼人的威权氛围，文官集团终于顶不住了，开始进一步分化、分裂。\\n\\n如果文官们的立场能始终保持一致，他或许还有所忌惮。但是，文官内部出现了分歧乃至纷争，正中他的下怀：\\n\\n你们争得越厉害，就越便于我大刀阔斧调整干部；通过人事任免，不听话的滚蛋，听话的上台。\\n\\n开始有人攻击杨廷和。说他在正德皇帝面前屁都不敢放一个，现在却敢于天天给新皇帝使脸色，简直是欺负人：\\n\\n“先帝自称威武大将军，廷和未尝力争，今于兴献帝一‘皇’字、‘考’字，乃欲以去就争之，实为欺罔。” ——嘉靖元年十二月，史道奏疏\\n\\n开始有更多的人悄悄转变立场，变换腔调，认真学习贯彻皇帝所主张的“继统论”的精神实质和丰富内涵。\\n\\n而张璁等人呢，气势越来越壮，言论越来越激进，不断公开表态，坚决拥护皇帝尊奉本生父母的英明决定。\\n\\n开始不断有人提出辞职。这次，皇帝基本对谁也没有再作挽留，所有辞呈，马上签批。\\n\\n终于，嘉靖三年二月，65岁的杨廷和请求退休。他很爽快，遂“许之”，“言官交章请留”，其他官员要求挽留，“上不听”。\\n\\n旧人走了，新人排队进京。皇帝下令，张璁、桂萼等一批官员从南京调入北京。\\n\\n请参阅本号《唯为 | 一个寒门老学渣之逆袭#c550》\\n\\n对于这场人事大地震，四月初四，吏部尚书乔宇联合九卿共同上疏，提出最严正的抗议，请求皇帝收回成命：\\n\\n“顷罢汪俊，召席书，取桂萼、张璁、霍韬，黜谪马明衡、李本、陈遁等，举措异常，中外骇愕。……且书不与廷推，时出内降，升为尚书，百余年来所未有者，请收回成命，令俊与书各守职如故……止召萼、璁。”——《实录》卷三十八，嘉靖三年四月戊戌\\n\\n文官们的任何骇愕都已无济于事。他们并未意识到，此时的大明帝国，已悄然进入了一个全新阶段。\\n\\n大军师之三国志名将令\\n广告\\n查看详情\\n\\n\\n六）\\n\\n事情继续在发展。皇帝距离确立自己至高无上的绝对权威，还差最后的“关键一步”：见血！\\n\\n五月二十四，张璁等一班大礼新贵来到北京，继续火上浇油，悍然提议去掉“本生皇考恭穆献皇帝”谥号中的“本生”二字，让皇帝的生父成为完全意义上的“皇帝”。\\n\\n六月十三，皇帝无视数十名官员的强烈反对，分别授予张璁等人为翰林学士：同时，严厉惩治了一些攻击张璁的官员。\\n\\n七月初六，吏部尚书乔宇提出辞职回老家，皇帝爽快批示，“给驿以归”，车费倒可以报销。\\n\\n这样，他逐步构建了效忠于自己的小圈子和基本盘，不听话的人通通被清退、清理、清查。\\n\\n对帝国这种政治局势的深刻转向，《明史》用了11个字作了精准概述：\\n\\n“三年，帝渐疏大臣，政率内决。”\\n\\n时间指针走到1524年，嘉靖三年七月十五日，皇帝终于召开了久违的大朝会。历史已永远记住了这一刻。\\n\\n大朝会结束后，一班文官聚集到左顺门，黑压压跪在一起，“或高呼太祖高皇帝，或呼孝宗皇帝，声彻于内”，要求保留兴献王谥号中的“本生”二字。\\n\\n到了中午，群臣仍然伏地不起。皇帝派人“录诸臣姓名”，将带头的八人下诏狱。结果，“群臣皆哭，声震阙庭”。\\n\\n皇帝龙颜大怒，又将五品以下官员“悉下诏狱拷讯，四品以及司务等官姑令待罪”。\\n\\n第二天，大学士毛纪紧急上奏，哀求皇帝希望挽救众臣：\\n\\n“昨日伏睹天威，将部院等衙门各言事官并下锦衣狱。臣等不胜悚惧。缘各官伏阙谕奏，继以号泣，诚为有罪。但区区一念，皆出于忠恳，其情可矜，况各衙门缺官办事，加以天气炎热，万一病惫不测，亦伤国体。伏望圣明少霁天威，严令各回衙门办理事务，亦足以示惩戒而无累于圣德矣。臣等不胜惓惓之至。”\\n\\n皇帝不听。十天后，毛纪辞职。又过了两天，七月二十八，皇帝“诏锦衣卫”，对左顺门事件作出最终处理结果：\\n\\n“杨慎辈倡率叫哭，期慢召上，震惊阙廷，大肆逆，其各杖于廷。于是，原状死，慎、元正、济充戍，磐、汉卿、时柯俱削籍为民。“——《实录》卷四十一，嘉靖三年七月辛卯\\n\\n或当场杖毙，或入狱充军，或撤职双开，他用一场骇人听闻的血淋淋暴力事件，宣告了自己绝对权威的最终形成。\\n\\n此后，大礼议相关议题以及他作出的所有指示，不论如何不合传统礼法礼制礼仪，如何背离原有的方针政策，再也无人敢有一丝一毫置喙。\\n\\n在帝国的每一个角落，他的话真正成为一言九鼎的金口玉言。在他至高无上的个人威权之下，整个嘉靖朝的文官群体，噤若寒蝉，鸦雀无声\\n\\n从一个谦逊少年成长为玩弄权术的极权主义信徒；从一个地方藩王转变为拥有绝对权威的最高统治者。\\n\\n他，只用了短短的三年又三个月时间，迅速，彻底，且不可逆转。\\n\\n大明帝国“两京十三省”，迎来了只属于他的长达四十多年的时代。历史册页里到处都是他的名字：\\n\\n朱厚熜。\\n"}'));jctx.push(JSON.parse('{"id": "190203", "tag": "book", "text": "# 守夜人总司令结构学\\n\\n## F1：见大行远\\n\\n原创： 觉悟者  守夜人总司令  2018-07-27\\n\\n生命是一种结构，它能自己从外界攫取能量以维持自身的存在。生命是基因的载体，只要有利于基因传递，任何一种延续的方式都可能被选择。在甲骨文中，上古先民们崇拜能够像青蛙一样大规模繁衍的女性，这是脆弱的生命应对灭绝最有效的形式——同一时期，相互隔绝的各古老文明都不约而同的崇拜繁殖，这绝不是一个巧合！\\n\\n如果一个人的儿女遭受绑架，会本能的愿意牺牲自己去交换。如果绑架的是丈夫或者妻子，则要看感情的深浅；如果是父母那就更要看关系的亲疏程度了——几千年的孝道浸染依然抵不过护犊子的本能！为什么会这样？\\n\\n盗墓行业最终进化成这样的形态：父子组队，儿子下去拿墓里的珍宝，父亲在上面拉着绳子。别的模型在漫长的行业进化中都被淘汰了——甚至儿子在上面拉绳子，父亲下去拿宝物都被淘汰了。因为儿子拿到父亲递上来的宝物后会斩断绳索，只有父亲拿到儿子递上来的宝物之后依然会拉儿子上来!\\n\\n\\n那些刻在基因里的本能行为，往往蕴藏着某种关于整个人类的秘密…\\n\\n中国古代最恶毒的惩罚不是车裂、腰斩或者凌迟，最残酷的惩罚是：株连九族！断绝基因的传递是对生命最高的绝罚，足以让所有人匍匐在地心惊胆颤！罗马人最终打败并毁灭了迦太基，还在他们的土地上撒了盐——让它永远寸草不生！为罗马一雪前耻的统帅西匹阿没有任何胜利者的喜悦，他的心头涌起无比的悲凉和恐惧——罗马会遭遇同样的命运吗？是否有一天也会消失在历史的长河中，无影无踪……\\n\\n生命无时无刻不处在生存的竞争之中，所有温情脉脉的装饰下面都藏着那个无法回避的终极命题：生存还是死亡！你可以回避竞争，但无法回避死亡。物竞天择的源动力来自基因对能量的无限需求——基因需要不断的进化，所有载体都不过是它进化路上的工具！\\n\\n## 生存策略\\n\\n生存环境是一种结构，处于结构中的生命为了基因的延续进行着残酷的竞争，如果缺乏打破结构的力量，结构本身就是一个角斗场。人类历史上所有对外行为都是为族群的延续争夺生存资源，所有的内部行为都是为对外竞争做好准备——它们彼此交织，相互支撑。\\n\\n能够摧毁结构的关键支点，并制造坍塌的内部力量只有两种：\\n\\n1. 科技树升级 \\n\\n2. 组织度跃升\\n\\n这二者往往相伴相生，彼此促进形成一种变革的合力！在这种结构性的变革中，原结构中占据资源的群体会整体溢出，这个占据资源又高度组织化的群体必定趁机借势制造各种内外纷争，其它芸芸众生都跟在后面追涨杀跌沦为炮灰。当这个群体在斗争中消亡或成为新的稳定结构中的一部分之后，秩序就会得以重建，并对内外生存结构都进行重塑。\\n\\n摧毁结构的外部力量主要依靠落差——技术落差，组织度落差，资金落差都能形成强大的势能，并降维攻击摧毁落后一方的原有内部结构。当年的洋务运动和今天的改革开放都基于此！\\n\\n人的器官中存在各式各样的细菌，它们在争夺有限的养分并相互攻伐逐渐达到一种微妙的平衡。自以为是的医生用药物把绝大多数的细菌都杀死了，那唯一没有被杀死的细菌瞬间占有了所有的养分，并以意想不到的疯狂，加速繁殖——很快它就占据了整个器官，并造成无法挽回的病变！\\n\\n即便拥有某种落差优势，富有远见的人也不会轻易的摧毁落后一方原有的结构——经过千百年博弈所形成的精密结构并不像表面看起来那样简陋——无论是行业生态还是政治经济都是如此！\\n\\n如果你正走在一片空旷的草地上，突然倾盆大雨，你会下意识的拼命奔跑——其实，你知道没有躲雨的地方，奔跑也无济于事；然而，你还是会本能的这样做！这种本能由久远的生存环境塑造而成，并被藏在基因里代代相传。生存竞争不仅仅塑造外在的结构，也雕塑内在的结构。群体外在的一致行为被称之为：“文化特征”，群体内在的相同思维被叫做：“文化心理”。所谓文化，就是生存结中群体共同的生存策略！生存环境决定生存策略。在生存环境改变之后，生存策略往往延续之前的惯性——这是许多悲剧的根源所在！\\n\\n在生存竞争的历史长河中，参与博弈的各方发明了一堆让人眼花缭乱的名词，还把它们写在各自的旗帜上用力的挥舞，试图吸引对方入套…有真知灼见的人一眼就看穿这些鬼把戏，虽虚以委蛇，却并不当真——其生存策略只会矢志不渝的遵循真实世界的底层逻辑！\\n\\n## 结构力量\\n\\n力量通过结构来聚集，也通过结构来释放。结构性的崩溃所造成的毁灭是一种让人痴迷的力量：地震、海啸、山崩地裂，皆因为地壳板块发生结构性的坍塌——所有能模拟大自然那种瞬间灭绝无数生命的力量都被赋予无上的权威！\\n\\n如同雪花的每一片都呈现它整体的形状一样，许多事物的最小组成单元与它的整体结构存在惊人的雷同。在数学中，这一形态被称之为递归。你能按图索骥找到那个原点，也可以清晰的预见它在更大时空中的边界。如果那个原子结构是不稳定的，规模越大，整体的崩溃系数就会指数增长。如果原子结构的力量呈盈余状态，规模越大潜力也就越大！\\n\\n识别结构，洞察原子结构所蕴含的力量和存在的缺陷，充分借用时间的杠杆——在毁灭性的力量面前，一切腾挪的技巧都是多余的……\\n\\n摧毁结构的内外两种力量：内部的力量源自科技树的升级和组织度的提升，外部的力量源自于落差的挤压——后续会展开很多经典的案例，此时此刻先阐述原理。摧毁结构是为了构建新的生存结构，那么，搭建结构并通过结构聚集和释放力量的方法又是什么呢？\\n\\n## 制造工具\\n\\n马克思说：“人与动物的最大区别就是制造和使用工具”。但他没明说：天子驭官，州牧牧民，事实上，你也只能算是动物！统治工具是人为构建的结构，人也是一种资源，被嵌入各种各样的结构之中，结构自身具有内在的约束力：一个金字塔型的结构会把人向上挤压——这种竞争结构不断强化内部的一致性，让归属感和荣誉感的含金量持续升高，最终形成：同一个目标，同一种主张，同一个套规范！为了进一步强化内部成员的自我约束，还会人为增加等级，并按等级分配利益——它不仅仅强化各层级对组织结构的忠诚，同时刺激成员自下而上的竞争愿望！无论天子还是州牧都是通过各种结构驾驭庞大的组织并把资源组织起来发挥着整体性的作用——搭建结构就是制造和使用工具！\\n\\n\\n\\n可怕的力量不是权力，也不是资本，甚至不是人心，一切都是工具！只有拥有了目标，才会需要工具！驱动一切的力量，潜伏在更底层的暗处。\\n\\n## F2：底层逻辑\\n\\n原创： 觉悟者  守夜人总司令  2018-09-18\\n\\n凡是能大量制造死亡的力量都会被顶礼膜拜！\\n\\n共识与仲裁\\n\\n死亡\\n\\n所有生命体都会最大限度的占据资源以追求多样性和保障自身的存续，生命体处于不同的生存结构中会采用不同的生存策略，一切行为的目的都是为了生存和延续。生存策略的终极共识是关于面对死亡的选择。\\n\\n用拳头捶击膝盖引发的弹跳不过是一种应急的条件反射，被毒蛇咬伤之后的断臂求生，则源于生命在面对死亡时所形成的共识：执行舍弃局部来保护整体的系统性调度！\\n\\n人类进化出感情和探讨生命的意义都是为了在生命体遭遇生死选择的时候，让取舍最有利于基因的传递。\\n\\n共识\\n\\n在史前的生存竞争中，人类并非最强壮的物种，但最终胜出并成为地球的统治者。这源于人脑中会相信某种在现实世界中并不存在的东西，还会为之一致行动，甚至牺牲自我。个体按照某种一致性的目的构建起一个更复杂的结构来发挥整体的合力，是人类战胜其它物种的关键所在——搭建的结构越庞大，越精密，所汇聚的力量也就越大。\\n\\n能最大限度凝聚个体的共识源于对存亡绝续的同样抉择。让生命处于死亡的威胁之下，是凝聚共识最有效的方式。共识是你愿意为自己的选择付出多大的代价。因此，共识必定是超越个体的，同时又有利于个体的终极目标。\\n\\n仲裁\\n\\n《F1：见大行远》里说：凡是能大量制造死亡的力量都会被顶礼膜拜。暴力能够终结生命，造成死亡，所有生命都面对死亡的威胁，所以暴力能够成为裁决的终极力量。\\n\\n仲裁其实就是通过死亡来做出抉择。因此，仲裁的最初形式就是暴力对决，其它一切的仲裁机制都是在模拟暴力对决。随着社会结构复杂度的跃升，需要暴力做出仲裁的需求量成爆炸式增长。原始暴力不足以供给越来越多的需求者，于是，它转变为公共暴力并被虚拟化——购买力是对公共暴力的第一次虚拟，它把暴力的使用群体由少数拥有领地和武装的贵族扩展到拥有资产的新兴人群。他们通过拥有这种模拟的暴力来获得事务的仲裁权。\\n\\n各领主的私人武装变成了社会的公共暴力，拥有购买力的群体通过国家机器来控制公共暴力，暴力被虚拟化后，为更大规模的群体所共享。基于这样的路径依赖，暴力将来会被第二次虚拟化：随着科技的进步和互通互联的密度越来越高，资金可以瞬间聚集于一点，也可以瞬间撤离。确立目标和调动资金的能力将优于占有资源的能力——凭借远见能确立目标并搭建结构调动巨量资金的认知力，将会是继购买力之后，暴力的第二次虚拟化。如果说购买力是通过消费来确立护城河，那么，认知力会通过教育来建立门槛。\\n\\n建造与交易\\n\\n渔猎游牧社会违背誓约必然要被处死，因为动态的稳定建立在约定成俗的契约之上，而农耕社会以欺诈为智慧，因为零和博弈的生存资源争夺必然不择手段——身处不同生存结构之中的生命体，生存策略自然各不相同。\\n\\n\\n渔猎游牧民族的辉煌存在于口口相传的传说之中，开拓、连接和征服的英雄故事激励着一代又一代的人走向更远处。农耕文明的辉煌留在建筑里，通过向上层层累积的方式搭建起恢宏而稳定的结构，以彰显生存竞争中优胜者的辉煌和传承。\\n\\n人类因交易而变得精致，因建造而变得富强。\\n\\n建造\\n\\n农耕文明的生存以土地为根本，认为包括自己在内的所有一切都只是临时的过客——世事无常，又周而复始；一岁一枯，又生生不息——所以，既能立足长远克制隐忍，又会画地为牢相互倾扎。在周而复始的预期之下，一切都依赖时间的沉淀。千百年来，都是通过不断的向上累积和持续接力，建造出精密又恢弘的结构并传之后世——愚公移山不是一种精神，而是一种生存方式！在农耕文明中，富贵不表现为金玉满堂的奢华，而体现为深宅大院中盘根错节遮天蔽日的古树——那是一个家族持续兴旺繁荣的象征。\\n\\n\\n建造者关注秩序，因为秩序的崩溃会毁掉的不仅仅是自己的努力。一切的荣辱都沉淀于层级之中，名次和位置不仅仅关乎利益的多寡，还暗示着基因的优劣。 聚族而居的人抬头不见低头见，所以不能撕破脸；但内心的波诡云涌和利益纷争又无法避免。因此，明面上的假模假式和暗地里的咬牙切齿会被完美的融合在一起，并进化出精湛的为人处世技巧。\\n\\n在建造者眼中，自己不过是一个临时的看守者，获得的一切都要继续传之后世，还必须叠加上自己的痕迹：朝廷的丹书青史，民间的家族谱系，都在为千百年后的子孙，提供评估自己一生价值的依据！这种超越时空的恐惧，连接着久远的过去和遥远的未来。如同一副千钧重担压的人举步维艰！\\n\\n土地足以让附着其上的生命自给自足时，所有的生存斗争仅限于方寸之间，它们对外部的世界就会漠不关心，甚至人为设置障碍进行自我封闭。\\n\\n\\n交易\\n\\n如果方寸之间的资源无法保障生命的自给自足，除了通过杀戮将生命的规模降低到与资源相匹配的程度，就必须利用科技树和组织度的提升，来提高资源的利用效率，从而能攫取更多的能量以维持生命的存续。如若科技树和组织度都无法获得跃升，生命就必须从新的地方攫取资源来维系自己的存在。如此一来，方寸之间的斗争就变得不那么紧迫，团结一致反而有利于对外开拓。对外开拓最初的形式是劫掠，劫掠的成本太高才会变成交易。\\n\\n生命会以不同的形式搭建出更大规模的生命体来实现自己的生存目的。如果没有足够的力量建立稳固的静态秩序，就会以契约的方式构建动态的平衡。交易会提升分工和协作的密度，从而让资源得到最充分的配置——资源的利用率越高，所能攫取的能量就越多，从而搭建起更大规模的结构，形成一种正向循环，直至遭遇增长的极限。\\n\\n\\n\\n交易者的价值并不取决于自身，而取决于自己所置身的交易结构及其权重。因此，利益和安全都建立在契约之上，通过维护整体的安全和整体的利益来获得个体的安全，保护个体的利益。所以，会比较热衷于公共事务。搭建交易结构能够通过纠正资源的错配达到小博大的效果，并获得巨大的回报——价值源于失衡，利润源于扭曲——结构性的扭曲正是快速增长和巨大利润的源泉。\\n\\n破碎的爱琴海沿岸，村镇级的邦国林立，任何一个城邦都无法单独应对来自东方的威胁，斯巴达和雅典这样的死敌，面临死亡威胁的时候，也会携起手来共同对敌。与农耕文明的东方君主不同，西方的英雄大多是协调者、沟通者、连接者。他们善于与敌人达成共识，也善于与世仇结成联盟。狭小的国土散落在群山之，任何一个城邦都必须依赖与他人互通有无才能存续下去。于是，他们把自己与别人深度的捆绑在一起，通过对契约的坚守实现一种斗而不破的动态平衡。这种底层状况所雕塑出来的生存策略，同样决定了其语言的特征——必须要根据上下文才能确定某个单词的在当下语境中的确切意思。\\n\\n转化\\n\\n任何社会的一切组织形式都根植于其底层逻辑。《F1: 见大行远》中说过：所谓文化就是一个群体应对其生存环境的共同生存策略。无论东方还是西方的文化，都是一套关于底层逻辑的自我解释——以自己族群的理解方式和熟悉的语言来表述而已。\\n\\n\\n\\n无论是交易还是建造，都是生命应对存亡绝续的生存策略。一个社会的方方面面都深深的扎根于它最初的生存策略，即便底层结构已经改变，生存策略的惯性依然具有很强大的裹挟力。如果底层结构并没有实现升级，任何形式的沙中建塔都会坍塌！\\n\\n\\n\\n结构的特征\\n\\n结构的动态稳定依赖契约，结构的静态稳定依赖秩序。如果统治结构的维系成本无法支撑，关键节点之间经过博弈会形成某种契约。开始由静态的平衡转变为动态的平衡——秩序逐步瓦解，交易成为主流。一旦交易链条无法打通，交易成本持续升高，交易结构就会瓦解，处于无序状况的结构会释放它所聚集的能量，一旦某种低成本聚集力量的方式出现，暴力，或被虚拟化的暴力，就会在混沌中重建静态的统治秩序。\\n\\n统治结构\\n\\n统治结构将所有的利益与层级节点深度捆绑，通过营造封闭的层级结构来构建静态的稳定秩序。统治结构需要选择一种能强化秩序的道义覆盖其上，以降低维持统治的成本。在统治结构中，所有的道义之争都是权力之争；所有的权力之争都是利益之争；所有的利益之争，都是位置之争。\\n\\n无论自上而下，还是自下而上的内部信息传递，各层级都会根据自身的利弊进行伪造、筛选、屏蔽之后再逐级传递，因此，统治结构内部的信息传递严重失真。身处其中的人，更愿意通过外部信息来判断当前形势和自身所处的状态。统治结构越严密就越对小道消息和暗箱操作缺乏免疫力。\\n\\n\\n统治结构致力于让任何深陷其中的人变成依附型的寄生者。深陷其中的人被各种无形的内在制约力所裹挟，裹挟力越强，就越缺乏独立生存能力。因此，除了维系成本过高之外，流动性也是瓦解统治结构的巨大威胁。一旦成员有了迁徙的能力，封闭的结构就会被打破，单向的控制力就逐渐下降，从而变成一种双向的交易。\\n\\n\\n\\n交易结构\\n\\n在交易结构中，为了建立信任，必要时需要增加中间层级，以搭建供需双方的信任链条。信任链条的维系依赖于交易结构中各参与方对契约的坚守。遵守契约的程度决定着交易成本。换而言之，只需要反复的违背契约，就能轻易的提升交易成本。交易结构的最大威胁是交易成本，一旦交易成本过高，交易结构随即瓦解。\\n\\n在交易结构中，效率是整体的效率，不是单点的效率。由上下游编织而成的竞争协作关系网决定了整条交易链条的效率。单点效率的提升不足以改变原有交易结构。要替代任何一个环节必须能以更低的成本和更高的效率承担起此环节在整个交易结构中扮演的角色，否则无法替代。\\n\\n一旦退出就足以让交易结构面临死亡威胁的参与方，是交易结构的关键支点，拥有最高权重的博弈筹码。无论显性还是隐形的关键支点都不仅仅能决定交易当下的生死，也决定业务未来发展的边界和瓶颈。\\n\\n注：防失联，备用公众号：交易成本  \\n\\n## F3：结构力量\\n\\n结构学是解决现实问题的认知工具。结构学研究：生命体在其生存结构中的求存之道！它源于“基因延续对能量的无限需求和其载体对能量的有限转化之间的终极矛盾”。结构学并非个人技能，它一直就在那里。我只是碰巧发现了它，并试图将它描述出来，以便应用于生活、商业及投资的判断和取舍！\\n\\n生命体是一种能够从外部攫取能量维持自生存续的有序结构。它是基因的载体，基因的延续是生命体存在的终极目标。因此，只要有利于基因的传递，生命体这个结构既会自我进化也会接受改造。无论是自我进化还是外力改造都需要摧毁原有结构并完成重构。进化需要内部力量摧毁结构并完成重建，改造则需要外部力量摧毁结构并完成重建。无论摧毁还是重建，起决定作用的都是结构的关键支点。结构的关键支点及其相互之间的约束条件构建起结构内部相互支撑又相互制约的秩序——这种相互制约能够避免结构内部的损耗，从而最大限度的聚集力量作用于结构所导向的目标。\\n\\n所有的设计和进化都是为了解决某个问题，结构为目的而存在——结构力量的聚集和释放都是为了它的终极目标。不管是统治结构还是交易结构都是一种有序的稳定形态——这种有序需要能量来维持，构建这种稳定的秩序同样需要消耗能量。当能量不足时，结构就必然会坍塌和瓦解；如果能量不够，结构就无法搭建起来！\\n\\n结构力量三要素 \\n\\n科技是将遥远的资源用于解决眼前的冲突，金融是将未来的资源用于解决眼前的冲突。情绪是把不存在的资源用于解决眼前的冲突——这里的“遥远”不仅仅是距离遥远，也包括资源转化的中间环节的长度和转化条件的复杂度。这里的“未来”是一个没有精确刻度的时间概念。这里的“不存在”是以产生情绪的载体为参照！无论是科技、金融还是情绪，三者都能形成递归循环，持续叠加，自我强化的结构力量。释放和阻断结构力量都取决于结构的关键支点——结构力量的关键支点包括以下三要素：\\n\\n\\n面对存亡所形成的共识和仲裁机制\\n\\n能形成自我强化的内在驱动力机制\\n\\n执行生存策略的高性价比传导体系\\n\\n仲裁和共识 \\n\\n生命体是基因的载体，个体生命按照一定方式构建起更大的生命体是为了控制更多的资源，提高能量转化的能力，降低基因传递断绝的概率，增强基因延续的多样性和适应性——所以，生命体会最大限度的占据资源以追求多样性和保障自身的存续，生命体处于不同的生存结构中会采用不同的生存策略，生命体的一切行为都是为了存续！\\n\\n所有的个体行为都受其内在精神结构的驱使，精神结构中的判断基于自我视角的抽象。这种自我抽象的差异性必然形成各不相同的生存策略，从而驱使各自采取符合自己生存策略的求存行为。作为一个整体，这势必造成混乱和内耗并制约结构力量的形成，继而危及整体求存策略的贯彻。共识必定是超越个体的，同时又有利于个体的终极目标。共识为求存确立目标，仲裁则针对目标做出取舍。仲裁的判断和取舍为个体的行为确立边界和规则，并形成一种结构力量驱使所有个体贯彻执行整体的生存策略。\\n\\n共识赋予仲裁机制做出判断和取舍的权力，形成一种约束来确保个体遵循规则并做出牺牲。如果说共识是一部宪法，那么仲裁机制就是宪法的执行机构——没有执行机构的宪法就是一纸空文。这个执行机构之所以能够建立的根本原因是什么呢？\\n\\n所有生命都需要面对死亡的威胁，暴力能够终结生命，造成死亡，所以暴力能够成为仲裁力量。正因为如此，凡是能大量制造死亡的力量都会被生命顶礼膜拜。将生命体置于死亡的威胁之中是迅速形成共识的最佳方式！仲裁其实就是通过死亡来做出抉择。因此，仲裁的最初形式就是暴力对决，其它一切的仲裁力量都是在模拟暴力对决。随着社会结构复杂度的跃升，对仲裁权的需求量成爆炸式增长。原始暴力不足以供给越来越多的需求者，于是，它转变为公共暴力，从而把仲裁权由少数拥有领地和武装的贵族扩展到拥有资产的广大群体——他们通过购买力来获得公共事务的仲裁权。\\n\\n领主的私人武装演变成国家机器的公共暴力，拥有购买力的群体通过国家机器来控制公共暴力。所有并发的压力都源于共享的规模——社会密度的持续提高，个体对仲裁的需求会更频繁。随着科技和金融的发展，一切都会被加速证券化并交易，资产的波动幅度会持续增加，保值将越来越难，因此，拥有让资产增值能力的认知力将会是继购买力之后的仲裁力量。购买力通过消费来确立护城河，认知力将通过教育来建立门槛！未来让人难以其及的不是奢侈品而是顶级的教育——它不仅仅贵，还逆人性，对绝大多数人而言，后者会是更大的门槛。\\n\\n仲裁所确立的规则个体虽然会遵从，但任何秩序的维持都需要消耗能量。如果迫使个体遵守规则所消耗的能量大于能从中获得的能量，结构力量就无法聚集起来，更无法形成自我强化的叠加。\\n\\n内在驱动力\\n\\n精神结构是内在驱动力的源头，包括三点： \\n\\n对自我的判断；\\n\\n对自我与外部资源关系的判断；\\n\\n基于以上的判断形成求存策略。\\n\\n\\n生存策略是生命体求存的指引，也是生命体在其生存结构中一切行为的原始驱动力。这个驱动力是如何自我强化，又是如何作用于现实的呢？生命体对自我及自我与外部资源的关系所做出的判断并非基于客观事实，而是基于自我感知的一种筛选和抽象。生存结构既包括所处的生存环境，也包括生命体对所处生存环境的自我抽象！在阐述结构力量三要素的时候，提到过情绪之所以能够循环叠加并自我强化，是因为情绪具备一个特征，那就是可以用“不存在”的资源来解决当下的冲突。这个“不存在”并非指客观不存在，而是相对于生命体而言。既然生命体的精神结构对自我判断及对自我与外部资源关系的判断都是基于一种自我抽象。这里就提供了一种“做假”的可能——自身的状况和资源的匮乏或富足都不再取决于现实，而取决于生命体的自我抽象！\\n\\n所有能够形成循环叠加自我强化的元素都具备一个显著特征：能突破现有条件的限制并持续的提供能量。情绪是能不断的让“不存在”的资源成为形成生存策略的依据；金融是能不断的透支未来；科技是不断构建更复杂的工具去转化能量。但是，都存在一个边界，那就是能量守恒！\\n\\n精神结构在依据自我抽象的判断形成生存策略之时，其目的都是围绕在其生存结构中求得存续。越是关乎生死存亡，判断、决策、执行和反馈就会加速运转——生命体不断的根据反馈重新对自我及自我与外部资源的关系进行判断，并以此形成新的生存策略，再驱使生命体执行策略并重复以上的循环。情绪是一种将生存策略转化为行为的指示信号，情绪的叠加其实是上面那个循环在加速运转，这种运转需要消耗能量，只不过常人无法理解，就认为是情绪在持续消耗能量。\\n\\n鉴于精神结构的特征，如果生命体的自我抽象造成了错误的判断，这个循环叠加就会造成偏离——无论是对生存环境的感知、过滤、判断都将失真，继而会在目标设定、约束条件和检测标准上，越来越偏离事实。欲壑难填其实是一种内在判断的失真，正是这种错误的自我强化在不断的驱动着生命体去采取行动执行错误的生存策略——外部的一切都是它的工具！\\n\\n激励机制之所以能发挥作用，本质上并非源于外部的奖惩，而是源于个体精神结构的扭曲：所有金融机构在招募人员的时候都会故意挑选野心勃勃的人，并热衷于激发内心的恐惧和欲望，制造人与人之间的竞争，形成相互刺激、彼此驱赶的氛围。\\n\\n\\n生命体的认知、判断和行为都会延续某种惯性，这惯性有的来自于所处生存环境中的制约，更多的是源于内心的某种缺失——在面对选择的时候，无论方案多么的完美，最终起决定作用的是当事人内心的恐惧——人会不惜代价的逃避内心的恐惧，去满足对安全感的需要。\\n\\n正因为生命体的对外行为是为了满足内心的需求——不是被恐惧所驱使，就是被贪婪所引诱。情绪的冲突源于生命体的精神结构——正是这种失真持续造成的扭曲产生了驱动力！生命体的所有行为都是由内部驱动的——所有的外交都是内政的延续！\\n\\n一个国家的内外政策亦是被内部各种结构性扭曲造成的问题所驱动——错误的策略经过传导体系的放大必然造成结构性的扭曲，一旦相互叠加就会形成多米诺骨牌一样的坍塌——人必自侮，然后人侮之；家必自毁，而后人毁之；国必自伐，而后人伐之！常人畏果，贤者畏因。因为贤者看到了结构力量会自我叠加的内在驱动力。\\n\\n\\n一个社会、一个国家、一个组织都是由个体构建而成的更大生命体。生命体的结构特征具有普遍适应性。生命体的一切行为都受其精神结构所驱使。在由个体构建而成的更大生命体的生存策略也就是我们所谓的文化！个体的精神结构会对自我和自我与外部资源的关系进行抽象，再根据这种抽象和判断形成生存策略。无论个体还是整体，形成生存策略的基础都是基于自我视角的抽象而非现实——这既是个体自卑和自负的源头，也是文化具有自我遮蔽特征的源头！文化天然具备自我遮蔽性——因为它不仅仅源自于个体生命体精神结构对所处生存环境的自我抽象，而且是个体自我抽象所形成的共识。不仅会产生一种机制约束所有个体执行这一共识所形成的生存策略，还会衍生出一套机制去清除质疑者，从而实现内部的自我约束和自我强化。（会有一堆C系列来详细阐述）\\n\\n传导体系\\n\\n力量通过结构来聚集也通过结构来释放，结构力量的形成依赖于：一个能够凝聚共识的道义，一套能自我强化的激励机制，一个捆绑了利益的传导体系。所谓的道义其实就是生存策略。任何道义拆开来看，都是关于对自我判断的解释，以及对生存环境和自我与之关系的解释。生命体的精神结构特征决定了外部的奖励无论是对生命体造成正向的循环刺激还是反向的循环刺激都会形成自我强化。所以，奖励的核心是持续的刺激，而最有效的持续刺激就是设计一套规则去制造相互之间的优劣之争。生命体作为基因传递的载体，淘汰就意为着死亡。竞争的胜负会唤醒生命体对死亡的强烈恐惧，从而改变其对生存结构的判断，继而形成自我强化的驱动力，利用外部的一切工具去执行生存策略。\\n\\n生存策略的执行效果取决于传导体系。传导体系所能控制的资源决定了生存策略能在多大范围内产生影响。传导体系的构建也是一种秩序的构建，任何秩序的建立和维护都需要消耗能量。因此，成本决定着所搭建的传导体系的规模和控制力。\\n\\n共识所形成的生存策略之所以能得以贯彻是因为仲裁力量的作用。然而，仲裁力量不是凭空产生的，无论是原始暴力，还是购买力，或者认知力，都需要高昂的成本。所以，这种依靠外在约束确立规则并维持秩序所构建起来的传导体系，会有一个临界点，那个成本的临界点决定了它的规模和控制力。因此，搭建传导体系需要最大限度的追求性价比。\\n\\n通过外部约束来避免内耗，源于个体对生存环境和置身其中的自我抽象各不相同。各不相同的判断势必驱使各自执行自己的求存策略，从而造成混乱。因此，除了通过仲裁力量维持秩序之外，还会通过统一各体的自我抽象和判断来避免混乱——所有的教育和训练都是为了统一判断，从而降低成本，搭建性价比更高的传导体系。规模更大和控制力更强的传导体系不仅意味着生存策略能作用于更大的范围，还意味着整个生命体能控制更多的资源去提升转化能量的能力，并有利于终极目的。\\n\\n在搭建传导结构中，通过对各种工具内在驱动力的洞察和底层逻辑的理解，就能充分利用外部的各种工具，将搭建传导体系的成本转嫁出去，从而达到持续放杠杆的效果，以更低的成本建立更大规模，渗透力更大，控制力更强的传导体系——所有的四两拨千斤都是充分的利用规则去转嫁成本。\\n\\n结构学：https://t.zsxq.com/NNNvzVF\\n\\nE1：精神结构\\n\\nF2：底层逻辑\\n\\nF1：见大行远\\n\\nC1：他们到底怕什么？\\n\\nC2：宗教是统治工具吗？\\n\\nC3：梳理流程也没用！\\n\\n"}'));jctx.push(JSON.parse('{"id": "190209", "tag": "tool", "text": "# vim的概念和配置\\n\\n## 编译遇到的问题\\n\\n在cent6上遇到Python无法编译出动态库，只有.a库，这时编译vim的选项 ./configure --with-features=huge  --enable-python3interp=yes --enable-luainterp --enable-multibyte --enable-sniff --enable-fontset\\n\\n如果能编译出Python的so库，可以--enable-python3interp=dynamic，这种情况下vim的版本会显示python3/dyn，vim也会去找so库，对提高加载速度有一定帮助。虽然编译出来，但运行中还是报错undefine symbol `PyByteArray_Type`，网上找到解决方法export LDFLAGS=\\"-rdynamic\\"方式解决的。\\n\\n## 模式\\n\\nvim最大的特色就是模式，也是和emacs比较时不能直接对比的地方。基础模式有7种，只不过像Select/Ex模式很少会用，最常用的有normal、insert、command。插入模式没什么特别，normal模式堪称移动的最佳实践，而command模式（或者说ex模式）则是真正进阶vim高手的必经之路，一切高级的批量处理，或是函数与脚本都是这个模式的扩展，至于快捷键，只不过是把ex模式的动作做了映射。在配置键绑定或命令时，要区分不同的模式。部分模式还有子模式，insert模式有Ctrl-X的自动补全子模式。\\n\\nnormal模式下有一种特殊的operator，包括原生的cdy和自定义命令，后面必须跟motion（更高级的叫法是文本对象，同样可以定制），使我们可以对文本进行任意操作。\\n\\nvim启动会依赖$VIM、$VIMRUNTIME、$HOME变量，其中$VIMRUNTIME默认是$VIM/vim{version}，而$VIM在unix是share/目录，在windows则是安装vim的目录。然后按某个顺序从这些变量指定的目录寻找.vimrc，这个文件可以不直接写内容，而是加载.vimrc.before和.vimrc.bundles脚本将不同用途脚本归类。\\n\\n## 目录作用\\n\\nVIM的行为，受配置参数的调整。或者统称为plugin(Vim script file)。整个plugin体系的入口，就是.vimrc相当于C语言的main函数，或者脚本的主文件，.vim目录下的各个子目录，可以认为在一定条件下，通过require方式导入的。遇到比较多的目录有\\n\\n* plugin 相当于全局的加载，只要有文件就会加载\\n* ftplugin 和文件类型相关的加载方式，需要filetype命令来打开\\n* syntax 和语法相关的加载，需要syntax命令来打开\\n* indent 缩进相关，也可以放在ftplugin，单独放只是为了更清晰\\n\\n这样看下来，这些目录的分类并不是vim强制要求，更像是社区的一种自发行为。对Vim来说就像个脚本解析器，以.vimrc为入口不断地导入关联的其它脚本，并运行在全局空间或Local Buffer上，进而达到高效编辑的效果。所以要相深入理解就必须明白Vim的脚本语法和内置规则。\\n\\n## 概念和区别\\n\\nVIM的概念很多，要能清楚这些概念的使用场景和区分。\\n\\n值类型的概念\\n\\n* 变量: 有10种类型，用let/unlet定义和删除变量，*弱类型、强作用域、无块作用域*。有多个命名空间控制变量的作用域，通过前缀来区分。比如脚本的静态变量用s:name，VIM自定义的变量用v:name，局部缓冲用b:name，窗口用w:name，全局用g:name，函数参数用a:name引用等等。而函数的变长参数更可以用a:1，a:2的方式表示第一个和第二个参数。如果在函数scope外用l:varible会报错。由于源出ex，和shell类似，变量没有块作用域，意味着在条件判断中创建的变量，出了判断块依赖可以使用。\\n* 选项: 有3种类型，VIM内置的一类特殊内部变量，刚学习的用户从修改选项开始。8.1版本的帮助手册显示有403个选项，不过有些选项如果编译时没有打开开关，是不能访问的，比如编译时用的python是3.6版本，而你电脑上是3.8版，就可以修改pythondll选项来适配。用set修改，用set filetype?/set syntax?查看，set syntax&恢复默认。也能用let &syntax=c方式来修改。\\n\\n动作类型的概念\\n\\n* 函数: 用function定义的一段功能，执行需要用call或eval方式调用，主要是作为插件的组成部分，如果要映射到按键，要用:call <funcname>。\\n* 命令: 用command定义并可以在Ex模式下直接触发，通用是插件开放给用户的接口形式，可以用map映射到按键，最终还是调用函数。\\n\\n其它\\n\\n* 事件: 还不了解\\n* 组: 还不了解\\n\\n如果在终端显示乱码，可以尝试将lang目录改名甚至删除，将只显示英文不会有显示乱码的问题。\\n\\n## 帮助系统\\n\\n有时某个查询的关键字会在多个分类下出现，比如@@既是一种操作，也是一个变量，直接:h @@只会出现操作的含义，这时就要:h variables再从这页单独查找。类似的options和内建函数也是类似做法。\\n\\n## 缓存和窗口\\n\\n两者相近却大不相同，buf是真正具备文字内容的对象，而window只是展示buf的容器。所以两者的属性也不一样，比如localdir是挂在窗口，而非缓存，两者也不绑定，用:ls看到的是缓存列表，其中有隐藏的缓存，需要的时候开个窗口并用b<buf-number>来关联这个缓存；也有些虽然只是一个缓存，却在多个窗口同时打开时。\\n\\n缓存有多种类型，默认是文件，不保存甚至不能正常退出，很多时候我们打开一个临时缓存只是作为展示，所以需要设置属性成nofile，除此之外还有很多别的有趣的类型。\\n\\n窗口同样有多种类型，不同类型的窗口可以同时存在，不同类型窗口在打开新内容时，会替换成新的buf。\\n\\n* 常规编辑窗口\\n* 帮助窗口 :h命令显示内容的窗口\\n* quickfix窗口 :copen打开的用于显示错误的窗口"}'));jctx.push(JSON.parse('{"id": "190210", "tag": "book", "text": "# 晚清沧海事\\n\\n太平天国和湘军之战，曾国荃利用先进火器，取得胜势。由于火药和铜帽全靠进口，曾国藩开始并不舍得，后来意识到优势，也改用火器。\\n\\n英王陈玉成和藩在合肥对峙，派其叔陈得才和赖文光北上陕西寻找穆斯林援兵，使兵力分散，曾联合多隆阿将其击败。玉成投靠苗沛林，苗却将其送给胜保。\\n\\n咸丰和慈禧的儿子是同治，后来的光绪是其表弟。二人的父亲是兄弟，母亲是姐妹。\\n\\n晚清名臣曾左李胡(也有把胡林翼换成张之洞)，曾是1811年而左是1812年，李比曾小一轮1823年也最长寿。李帐下的刘铭传最能打，提议修4条铁路，可惜被翁同龢否定，最后在台湾才得以施展并铺上铁路。\\n\\n曾国藩的翻译容闳，耶鲁毕业，是第一个受美国文化影响的汉人。受他影响，曾提出留美幼童计划。原定持续15年最终仅4年，饶是如此依然成果颇丰。\\n\\n左先平定陕甘回乱，再定新疆。平回后借马占鳌之手杀花门宦寺教主马桂源，使其统治合法性只能来自中央权力，宗教势力从此不复存在。马的后人即灭红军西路军的马步青马步芳。为平定边患长治久安立大功。\\n"}'));jctx.push(JSON.parse('{"id": "190215", "tag": "os", "text": "# Android安装Linux环境\\n\\n15年时试用过kbox，毕竟是个半成品，到2019年2月，安卓跑终端已经很成熟了。和Linux比，安卓的模拟环境是单用户且用户名已预置，在4.2以前，用户名就是个序号，4.2之后扩充形成类似`u0_a99`的命名方式，但本质还是单用户，且没有密码。home目录下不会再有子目录，自然不能创建新用户。\\n\\n已经root可以用linux deploy。这个软件会在/dev/block/loop0（或loop1）块设备上创建rootfs，并安装完整操作系统，因此，从体验上最接近完整系统。\\n\\n没有root的机器，根据安卓不同版本，选择不同的软件。\\n\\n* 安卓5.0及以上，用Termux或UbuntuForAndroid\\n* 安卓4.4及以下，用GNURoot\\n\\n## Termux\\n\\n由于文件系统无法遵循FHS规范，加上依赖的C库是bionic，所以不能直接拿其它发行版的二进制程序来用，需要单独编译。除了基础的库依赖/system/lib/下的libc.so、libm.so、libdl.so之外，其它动态库都在Termux的lib目录内，因此也可以说不是个自完备的系统。相比bionic的libc.so，glibc则命名为lib-2.32.so，再用libc.so.6软链接过去。\\n\\n包管理器是dpkg和apt，又用shell封装了简单的pkg前端。初始化安装后有大约65个包，ca-certificates包只有一个文件，记录了可信任的CA，提供者是curl的作者，可见CA的基础性。在一次升级过程中遇到依赖的libandroid-support无法升级，甚至用`-o APT::Force-LoopBreak=yes install libxxx` 命令还导致所有程序全部被清空的惨剧。据说是用了改版的apt，使升级策略变成了滚动升级。重装之后提示仓库版本和本地不同，我选择D看差异却导致再也无法继续，只能再次重装时只敢选N(保留我的配置)，折腾3次才重新装上。\\n\\n如果更换源，要先执行`apt-get update`更新缓存才能执行进一步操作。\\n\\n默认bash，用chsh可以换sh，原理是把默认shell写入$HOME/.termux/shell。login不能作为默认shell。bash有700多K，而dash仅130K。bash提供了很多交互上方便的特性，典型的像通过改变PS1变量更换提示符，还有个内建钩子函数`command_not_found_handle`，当执行一个不存在的命令，会用一个外部程序给出更好的提示，比如用pkg安装某个对应包。\\n\\n用atilo可以安装完整的linux，原理是先启动基于proot打了patch后的termux-chroot构造假的root环境，从lxc-images下载基础镜像，再以proot方式启动。包括取消LD\\\\_PRELOAD环境变量，用`env -i`加载空的环境，设置PROOT_NO_SECCOMP=1关闭可信计算。同时也说明这类镜像只依赖内核的syscall，辅以合适的根目录，就能运行。\\n\\n在termux上编译软件要注意，因为默认的/usr/local路径不可用，必须用 ./configure --prefix=$PREFIX/stow/xx-1.0 方式显示指定安装路径。安装后，进入stow目录，执行stow xx-1.0就能用了，执行stow -D xx-1.0则删除该软件。\\n\\n## UbuntuForAndroid\\n\\n自带ssh，装上就能用。源比debian要少太多，先安装software-properties-common再用add-apt-repository ppa:添加相应的源才能安装。在换国内源时遇到若干问题\\n\\n1. 先确保安装了*ca-certificates*\\n2. 网上换源的文章都只适用于x86系，如果是arm的话，要把url的ubuntu换成ubuntu-ports\\n3. apt-get update会提示签名不通过，改成`deb [trusted=yes] http:...`。注意如果没有装第1步提到的包，即使加了trusted也没用\\n\\n## GNURoot Gentoo\\n\\n可以安装debian jessie，理论上可以换源逐步升级到最新版本。不过在5.0不让装。\\n\\n又试了Gentoo，依然遇到sshd问题。首先是没有公私钥对，用`ssh-keygen -t rsa -f ssh_host_rsa_key`生成，还是会断开，通过修改配置项`UsePrivilegeSeparation no`后能登陆。这个选项在7.5版本后废弃，强制yes，但在安卓系统下，可能是exec机制不同，必须no才能连接。如果sshd不管怎么配置都不能用，可以换dropbear，因为只用一个进程，免去了exec的麻烦。默认没有公钥的话，用dropbearkey -t rsa  -f dropbear_rsa_host_key。由于Gentoo的portage机制导致小文过多，同步后直接把inode用完（至少13万个），导致系统无法使用。这可能也和手机版本4.2，默认只有19万inode，而另一台6.0上的inode有64万多，可惜无法尝试了。\\n\\n由于ebuild不能用，只能源码编译，没有自带解压zip的软件，网上找到的unzip源码竟然是2010年最后更新的6.0版本，看起来也不会再更新了。支持非常多的操作系统，以致于根目录下没有Makefile，看了帮助才知道要自己从相应的目录复制Makefile，在那个操作系统百花齐放年代的软件，风格和如今大为不同。可能是太常用也太古老的关系，busybox也整合了unzip功能，倒不一定非得使用原始的unzip。顺便说下unzip和zip分属两个包，版本号也完全不同，有点难以想象。\\n\\n应用市场能下载和GNURoot配套的镜像都比较旧，可用lxc制作的发行包(https://images.linuxcontainers.org/images/), arch或alpine也有独立发布的arm包(选armhf，不支持aarch64)。下载发行包后，按以下顺序操作\\n\\n1. 进入/host-rootfs/data/data/champion.gnuroot/app_install目录，有roots/support/versions 共3个文件夹。versions不用管，在roots和support下创建同名文件，名字随便取以后会显示在下拉框。roots包含的是发行版的rootfs，support是proot和busybox。由此看出GNURoot的流程大概就是busybox内用proot加载rootfs，达到模拟操作系统的目的。\\n2. 创建host-rootfs目录，如果没有/etc/resolv.conf也复制一份。\\n\\n做完以上两步，再打开GNURoot的下拉框，就可以看到刚安装的发行版了。\\n\\n* 不成功案例1: 先安装GNURoot的aboriginal包，然后不另建目录，直接把发行版的rootfs覆盖上去，再次打开会退出，可见必须另建新目录。在覆盖时遇到一个有趣的问题，原有的bin/目录是指向usr/bin/的软链接，这时一定要用`rm -rf bin`，不可以在bin后面加/，否则会把指向的目录删掉。因为软链接是文件，不加末尾的/，rm只删除这个软链，而加了/的话，会被作为目录删除导致悲剧。\\n* 不成功案例2: 在安卓5上可以安装GNURoot，但安装dropbear后，ssh输入密码成功后，提示`client_loop: send disconnect: Broken pipe`，然后断开。可见终究还是不能用。\\n\\n## GNURoot Aboriginal\\n\\n有台配置极差的老机只能装这个版本，sshd也不能用，好在上传busybox1.31通过telnetd可以使用。只能挂个http服务，别的也不指望了。\\n\\n## GNURoot Debian Jessie\\n\\n可以逐个版本地滚动升级上来\\n\\n```\\napt-get update\\napt-get upgrade\\napt-get dist-upgrade\\nsed -i \'s/jessie/stretch/g\' /etc/apt/sources.list\\n```\\n\\n之后再重复以上3升级步骤，此时要多一条\\n\\n```\\napt-get autoremove\\n```\\n\\n这样就彻底向上跳了一个版本，后续版本的更新类似。不过在一台未root的手机上操作，最终却因为libc无法更新停在了half-install状态，此时尝试装file，会提示需要libc >= 1.20，但是jessie的版本是1.19，只有stretch是1.24，无法安装新的软件，导致这个版本等于是废了。"}'));jctx.push(JSON.parse('{"id": "190216", "tag": "book", "text": "# 《精通比特币》知笔墨\\n\\n钱包、密钥\\n私钥衍生家族----适用于各种树形权限分配，比如企业钱包\\n\\n交易\\n交易费按交易数据字节大小计算，交易费市场定价，与币值无关。矿工可按交易费排序优先级进行处理。\\n比特币以UTXO记录，UTXO如同金额不同的一张张支票，金额最小单位为“聪”\\n交易输入减输出即付给矿工的交易费，交易订单一般由钱包创建，手动创建时应避免付出天价交易费。（贪心算法挑选输入UTXO，解决背包问题常用的还有动态规划）\\n交易链条和孤立交易：父、子、孙订单在比特网络中传输可能出现不同时序。孤立交易会被放入一个大小有限的等待池。\\n类Forth脚本语言编写的脚本验证比特币交易：解锁脚本解锁输入UTXO集，锁定脚本指定输出UTXO集的解锁条件。脚本可表达出多到数不尽的条件变种。这也是比特币作为一种“可编程的货币”所拥有的权力。\\n并非所有解锁脚本都一定会包含签名。 有哪些特殊情形？？？\\n解锁脚本&锁定脚本，拼接执行\\n图灵非完备性，去除脚本复杂性，减少漏洞可能\\n标准交易：五大标准脚本分别为P2PKH、P2PK、MS（限15个密钥）、P2SH和OP_Return\\n多重签名，多个密钥联合管理资金，多重签名机制能为公司治理提供管控便利，同时也能有效防范盗窃、挪用和遗失。\\nOP_RETURN的定义即显示不能赎回；请记住OP_RETURN不涉及可用于支付的解锁脚本的特点，OP_RETURN不能使用其输出中所锁定的资金，因此它也就没有必要记录在蕴含潜在成本的UTXO集中，所以OP_RETURN实际是没有成本的。\\n\\n比特币网络\\n每个比特币节点都是路由、区块链数据库、挖矿、钱包服务的功能集合\\n对待节点区块数据同步，获取区块hash列表，再获取区块数据\\nBloom过滤器：增加SPV隐私性\\n交易池：节点们利用这个池来追踪记录那些被网络所知晓、但还未被区块链所包含的交易。\\nUTXO池\\n\\n区块链\\n区块头：1.引用父区块哈希值的数据，连接前一区块。 2.难度、时间戳和nonce，与挖矿竞争相关。3. merkle树根（一种用来有效地总结区块中所有交易的数据结构）\\n区块标识符：区块头哈希值和区块高度\\n\\nMerkle 树\\nMerkle树被用来归纳一个区块中的所有交易，同时生成整个交易集合的数字指纹，且提供了一种校验区块是否存在某交易的高效途径。\\n- 生成一棵完整的Merkle树需要递归地对哈希节点对进行哈希，并将新生成的哈希节点插入到Merkle树中，直到只剩一个哈希节点，该节点就是Merkle树的根。在比特币的Merkle树中两次使用到了SHA256算法，因此其加密哈希算法也被称为double-SHA256。\\n- 当N个数据元素经过加密后插入Merkle树时，你至多计算2*log2(N)次就能检查出任意某数据元素是否在该树中，这使得该数据结构非常高效。 （为了证明区块中存在某个特定的交易，一个节点只需要计算log2(N)个32字节的哈希值，形成一条从特定交易到树根的认证路径或者Merkle路径即可。）\\n- Merkle树和简单支付验证（SPV）：减少数据传输\\n\\n挖矿与共识\\n矿工提供算力，矿工们在挖矿过程中会得到两种类型的奖励：创建新区块的新币奖励，以及区块中所含交易的交易费\\n去中心化共识\\n* 每个全节点依据综合标准对每个交易进行独立验证\\n* 通过完成工作量证明算法的验算，挖矿节点将交易记录独立打包进新区块，\\n* 每个节点独立的对新区块进行校验并组装进区块链\\n* 每个节点对区块链进行独立选择，在工作量证明机制下选择累计工作量最大的区块链\\n\\n交易的独立校验\\n每一个节点在校验每一笔交易时，都需要对照一个长长的标准列表\\n在收到交易后，，每一个节点都会在全网广播前对这些交易进行校验，并以接收时的相应顺序，为有效的新交易建立一个池（交易池）。\\n\\n挖矿节点\\n矿工间的竞争以新区块的传播而结束，如同宣布谁是最后的赢家。也是下一个区块竞赛的发令枪。\\n整合交易至区块\\n交易块龄，矿工费和优先级\\n交易的优先级是通过输入值和输入的“块龄”乘积之和除以交易的总长度得到的： Priority = Sum (Value of input * Input Age) / Transaction Size\\nUTXO的“块龄”是自该UTXO被记录到区块链为止所经历过的区块数，即这个UTXO在区块链中的深度。交易记录的大小由字节来表示。\\n区块中用来存储交易的前50K字节是保留给较高优先级交易的。\\n\\n创币交易\\nCoinbase奖励与矿工费\\n\\n创币交易的结构\\n表8-1 “普通“交易输入的结构\\n长度 字段 描述\\n32 字节 交易哈希 指向包含有将要被花费UTXO的交易\\n4 字节 交易输出索引 UTXO在交易中的索引，0 从0开始计数\\n1-9 字节 解锁脚本长度 解锁脚本的长度\\n(VarInt) 可变长度 Unlocking-Script 一段脚本，用来解锁UTXO锁定脚本中的条件\\n4 bytes 顺序号 当前未启用的TX替换功能，设置为0xFFFFFFFF\\n\\n表8-2 生成交易输入的结构\\n长度 字段 描述\\n32 字节 交易哈希 不引用任何一个交易，值全部为0\\n4 字节 交易输出索引 值全部为1\\n1-9 字节 Coinbase数据长度 coinbase数据长度\\n(VarInt) 可变长度 Coinbase数据 在v2版本的区块中，除了需要以区块高度开始外，其他数据可以任意填写，用于extra nonce和挖矿标签\\n4 bytes 顺序号 值全部为1，0xFFFFFFFF\\n\\n构造区块头\\n表8-3 区块头的结构\\n长度 字段 描述\\n4 字节 版本 版本号，用来跟踪软件或协议的升级\\n32 字节 前区块哈希 链中前一个区块（父区块）的哈希值\\n32 字节 Merkle根 一个哈希值，表示这个区块中全部交易构成的merkle树的根\\n4 字节 时间戳 以Unix纪元开始到当下秒数记录的区块生成的时刻\\n4 bytes 难度目标 该区块的工作量证明算法难度目标\\n4 bytes Nonce 一个用于工作量证明算法的计数器\\n\\nProof Of Work\\n通过迭代 nonce 来生成不同哈希值的输出\\n目标阀值\\n难度表示\\n表示：系数/指数格式，前两位十六进制数字为幂，接下来得六位为系数。（如0x1903a30c，0x19为幂，而0x03a30c为系数）\\n计算难度目标的公式为： target = coefficient * 28 * (exponent – 3)\\n难度目标与难度调整\\n比特币的区块平均每10分钟生成一个。这就是比特币的心跳，是货币发行速率和交易达成速度的基础。难度被动态设定在，无论挖矿总算力如何变化，新区块产生速率都保持在10分钟一个。\\n难度的调整是在每个完整节点中独立自动发生的。每2,016个区块中的所有节点都会调整难度。难度的调整公式是由最新2,016个区块的花费时长与20,160分钟（两周，即这些区块以10分钟一个速率所期望花费的时长）比较得出的。难度是根据实际时长与期望时长的比值进行相应调整的（或变难或变易）。简单来说，如果网络发现区块产生速率比10分钟要快时会增加难度。如果发现比10分钟慢时则降低难度。\\nNew Difficulty = Old Difficulty * (Actual Time of Last 2016 Blocks / 20160 minutes)\\n工作量证明的难度调整 源文件 pow.cpp 第43行函数 GetNextWorkRequired()\\n为了防止难度的变化过快，每个周期的调整幅度必须小于一个因子（值为4）。如果要调整的幅度大于4倍，则按4倍调整。\\n挖矿成功后立即进行扩散传播\\n校验新区块\\n行为不诚实的矿工所产生的区块将被拒绝\\n* 区块的数据结构语法上有效\\n* 区块头的哈希值小于目标难度（确认包含足够的工作量证明）\\n* 区块时间戳早于验证时刻未来两个小时（允许时间错误）\\n* 区块大小在长度限制之内\\n* 第一个交易（且只有第一个）是coinbase交易\\n* 使用检查清单验证区块内的交易并确保它们的有效性\\n* “交易的独立校验”一节已经讨论过这个清单。\\n\\n区块链的组装与选择\\n比特币去中心化的共识机制的最后一步是将区块集合至有最大工作量证明的链中。一旦一个节点验证了一个新的区块，它将尝试将新的区块连接到到现存的区块链，将它们组装起来。\\n任何时候，主链都是累计了最多难度的区块链。在一般情况下，主链也是包含最多区块的那个链，除非有两个等长的链并且其中一个有更多的工作量证明。\\n节点维护三种区块：第一种是连接到主链上的，第二种是从主链上产生分支的（备用链），最后一种是在已知链中没有找到已知父区块的。在验证过程中，一旦发现有不符合标准的地方，验证就会失败，这样区块会被节点拒绝，所以也不会加入到任何一条链中。\\n选择了最大难度的区块链后，所有的节点最终在全网范围内达成共识。随着更多的工作量证明被添加到链中，链的暂时性差异最终会得到解决。挖矿节点通过“投票”来选择它们想要延长的区块链，当它们挖出一个新块并且延长了一个链，新块本身就代表它们的投票。\\n区块链分叉\\n链的重新共识\\n单区块分叉每周都会发生，而双块分叉则非常罕见。\\n挖矿和算力竞赛\\n下表表示了比特币网络开始运行后最初五年的总算力：\\n2009\\n0.5 MH/秒–8 MH/秒 (16倍增长)\\n2010\\n8 MH/秒–116 GH/秒 (14,500倍增长)\\n2011\\n16 GH/秒–9 TH/秒 (562倍增长)\\n2012\\n9 TH/秒–23 TH/秒 (2.5倍增长)\\n2013\\n23 TH/秒–10 PH/秒 (450倍增长)\\n2014\\n10 PH/秒–150 PH/秒 到8月为止 (15倍增长)\\n\\n随机值升位方案\\n算力增加，难度增加，会导致随机数不够用（全部随机数尝试过还是不能获得满足难度的hash）\\n随机数升位扩展方案衍化：\\n- Nonce随机数\\n- Nonce + 时间戳延后（空间有限，如果把它移动得太远，会导致区块变为无效）\\n- Nonce + coinbase脚本变化（coinbase脚本可以储存2-100字节的数据，其变化导致merkle树根值变化，导致区块头变化，进行扩展随机区域）\\n如果未来矿工希望可以尝试更多的可能性，他们还可以通过修改时间戳来解决。同样，coinbase脚本中也有更多额外的空间可以为将来随机数的扩展做准备。\\n\\n矿池：有趣，份额统计，工作量证明设计\\n让我们回到骰子游戏的比喻。如果骰子玩家的目标是扔骰子结果都小于4（整体网络难度），一个矿池可以设置一个更容易的目标，统计有多少次池中的玩家扔出的结果小于8。当池中的玩家扔出的结果小于8（矿池份额目标），他们得到份额，但他们没有赢得游戏，因为没有完成游戏目标（小于4）。但池中的玩家会更经常的达到较容易的矿池份额目标，规律地赚取他们的份额，尽管他们没有完成更难的赢得比赛的目标。\\n时不时地，池中的一个成员有可能会扔出一个小于4的结果，矿池获胜。然后，收益可以在池中玩家获得的份额基础上分配。尽管目标设置为8或更少并没有赢得游戏，但是这是一个衡量玩家们扔出的点数的公平方法，同时它偶尔会产生一个小于4的结果。\\n同样的，一个矿池会将矿池难度设置在保证一个单独的矿工能够频繁地找到一个符合矿池难度的区块头hash来赢取份额。时不时的，某次尝试会产生一个符合比特币网络目标的区块头hash，产生一个有效块，然后整个矿池获胜。\\n\\n托管矿池\\n矿工连接到矿池服务器使用一个采矿协议比如Stratum (STM)或者 GetBlockTemplate (GBT)\\nSTM和GBT协议都创建包含候选区块头模板的区块模板。矿池服务器通过聚集交易，添加coinbase交易（和额外的随机值空间），计算MERKLE根，并连接到上一个块hash来建立一个候选区块。这个候选区块的头部作为模板分发给每个矿工。矿工用这个区块模板在低于比特币网络的难度下采矿，并发送成功的结果返回矿池服务器赚取份额。\\n\\nP2P矿池\\nP2Pool是一个点对点的矿池，没有中心管理人。\\nP2Pool通过将矿池服务器的功能去中心化，实现一个并行的类似区块链的系统，名叫份额链。\\n本质上说，比起用一个矿池服务器记录矿工的份额和奖励，份额链允许所有矿工通过类似比特币区块链系统的去中心化的共识机制跟踪所有份额。\\n\\n共识攻击\\n比特币的共识机制依赖于这样一个前提，那就是绝大多数的矿工，出于自己利益最大化的考虑，都会通过诚实地挖矿来维持整个比特币系统。\\n共识攻击只能影响整个区块链未来的共识，或者说，最多能影响不久的过去几个区块的共识（最多影响过去10个块）。而且随着时间的推移，整个比特币块链被篡改的可能性越来越低。\\n区块链分叉/双重支付攻击指的是攻击者通过不承认最近的某个交易，并在这个交易之前重构新的块，从而生成新的分叉，继而实现双重支付。有了充足算力的保证，一个攻击者可以一次性篡改最近的6个或者更多的区块，从而使得这些区块包含的本应无法篡改的交易消失。值得注意的是，双重支付只能在攻击者拥有的钱包所发生的交易上进行，因为只有钱包的拥有者才能生成一个合法的签名用于双重支付交易。攻击者只能在自己的交易上进行双重支付攻击，但当这笔交易对应的是不可逆转的购买行为的时候，这种攻击就是有利可图的。\\n双重支付可以有两种方式：要么是在交易被确认之前，要么攻击者通过块链分叉来完成。进行51%攻击的人，可以取消在旧分叉上的交易记录，然后在新分叉上重新生成一个同样金额的交易，从而实现双重支付。\\n共识攻击中除了“双重支付”攻击，还有一种攻击场景就是拒绝对某个特定的比特币地址提供服务。 本质上来看，共识攻击，就像是系统中所有矿工的算力被分成了两组，一组为诚实算力，一组为攻击者算力，两组人都在争先恐后地计算块链上的新块，只是攻击者算力算出来的是精心构造的、包含或者剔除了某些交易的块。因此，攻击者拥有的算力越少，在这场决逐中获胜的可能性就越小。从另一个角度讲，一个攻击者拥有的算力越多，其故意创造的分叉块链就可能越长，可能被篡改的最近的块或者或者受其控制的未来的块就会越多。一些安全研究组织利用统计模型得出的结论是，算力达到全网的30%就足以发动51%攻击了。\\n竞争币和竞争块链的分类\\n元币平台\\n染色币:添加附加信息的币中币\\n万事达币\\n合约币\\n竞争币/山寨币\\n下面所列出的就是这些竞争币区别于比特币的三点主要不同：\\n* 货币策略不同\\n* 基于工作量证明的一致性机制不同\\n* 一些特殊的功能，比如更强的匿名性等等\\n\\n多目的挖矿创新：Primecoin, Curecoin, Gridcoin\\n致力于匿名性的竞争币：CryptoNote, Bytecoin, Monero, Zerocash/Zerocoin, Darkcoin\\n非货币型竞争区块链\\n域名币\\n"}'));jctx.push(JSON.parse('{"id": "190220", "tag": "lang", "text": "# 程序语言的依赖包管理\\n\\n没有人可以写从到尾写完一个程序，除了内核这种项目，多都需要依赖其它库或源码，解决依赖也成了各种语言的基本功。又细分了两个需求：全局的包管理和项目级的包管理，不同的语言支持程度各不相同。\\n\\n## JS\\n\\nnpm是Node.js的首选模块依赖管理工具，仓库npm config get/set registry修改成国内的镜像http://registry.npm.taobao.org/。有本地和全局两种安装模式。\\n\\n* 本地模式: 在当前目录创建 package.json 文件来描述模块的依赖，在这个文件里你可以定义你的应用名称( name )、应用描述( description )、关键字( keywords )、版本号( version )等。npm会下载当前项目依赖模块到项目中一个叫做node_modules的文件夹内。\\n* 全局模式: 惟一的区别就是 install 命令后多了 -g 选项。安装到 prefix 目录的node_modules文件夹。但有一点不同，全局安装的依赖在主入口目录内，而本地则是平铺开。举个例子\\n\\nnpm的2.x版本采用嵌套式依赖方案，适合某个依赖在一个项目中多版本并存的问题，比如node；而3.x则换成扁平化的方式，更适合前端。npm的依赖可以指定版本区间，锁定，任意版本都支持。\\n\\n安装A库，A依赖B。如果是本地安装，node_modules下有 A 和 B 两个目录。但是如果是全局安装，node_modules只有A目录，A目录内又有node_modules，在这个嵌套子目录内会有B目录。\\n\\n对node来说，require的参数如果是核心模块，不会搜索磁盘目录直接加载核心模块，如果不在核心列表内，就会在路径后依次用找package.json的main字段/.js/.json/.node方式寻找，找到第一个文件停止搜索，且npm还有缓存机制，如果在缓存中就不会重复加载。\\n\\n与maven/gradle不同的是，maven最终会分析依赖树，把相同的软件默认扁平化取最高版本。而npm支持nested dependency tree。nested dependency tree是每个模块依赖自己目录下node_modules中的模块，这样能避免了依赖冲突, 但耗费了更多的空间和时间。由于Javascript是源码发布，所以开发态与运行态的依赖都是基于npm，优先从自己的node_modules搜索依赖的模块。\\n\\n## Lua\\n\\nrocks安装时要指定属于全局、个人或项目。\\n\\n## Python\\n\\npip只有全局模式，不支持项目级别定制包。默认放在python的lib/site-package目录，两个目录或是一个文件加一个目录（一个是执行模块或包，一个是描述元数据）。比如安装jedi包，成功后会有一个名为jedi的目录，还有一个jedi-0.16.0.dist-info目录。jedi目录放py代码，而带版本号的目录则放requires.txt、SOURCE.txt、PKG-INFO等元数据文件，依赖关系就记录在requires.txt里。将这两个文件以zip方式压缩，就是wheel包。\\n\\n## PHP\\n\\n出现较早的pear只支持全局下载包，后出现composer称自己是依赖管理器（也支持pear的包模式），可以在全局或项目中管理包更新，另外还自带PSR4的加载规范。\\n\\n## Java\\n\\n没有全局包的概念，只能在项目层面用pom.xml来控制版本，指定的版本号必须精确匹配，又走到了另一个极端。如果仓库没有想要的版本，就失败了不能模糊匹配。\\n\\n开发态，可以通过maven和gradle工具编辑依赖清单列表/脚本，指定依赖库的位置/版本等信息，这些可以帮助你在合适的时间将项目固化到一个可随时随地重复编译发布的状态。这些工具对我来说已经足够优雅有效。但maven中也有不同依赖库的内部依赖版本冲突等令人心烦的问题。尤其是在大型项目中的依赖传递问题，若团队成员对maven机制没有足够了解下，依赖scope的滥用，会让整个项目工程的依赖树变得特别的巨大而每次编译效率低下。运行态，目前Java也没有很好的依赖管理机制，虽有classloader可以做一定的隔离，但像OSGi那种严格的版本管理，会让使用者陷入多版本相互冲突的泥潭。\\n\\n展开说说maven，可以理解为Makefile的网络版，得益于java原生的网络支持，远程仓库的jar包和本地/lib下的so在软件层面等效。lifecycle由多个阶段(插件)构成，类似的也有clean, test, compile等目标，不同的是只能输出一种目标，package输出到当前工程，install进一步写入本地仓库，可以给其它工程链接，deploy多一步发布到远程仓库，给其他人用。\\n\\n## C语言\\n\\n最多的还是Makefile，但和其它语言比，只能说是半残。接口头文件和库之间没法校验匹配性，也不容易指定库的版本。链接时通常是指定库名称，到底指向哪个库，只能听由操作系统的软链接。所以现在的发行版在.so后面还会跟一个数字，形成类似.so.2这样的文件名，如果出现重大不兼容，可以指定大版本。\\n\\n## 语义化semver\\n\\n开源产品的迭代难免引入不兼容修改，通过目前社区都认同的语义化版本方案，依赖时必须要限定版本号，否则大版本升级就无可挽回了。npm有`~`和`^`两种标识符，比较体现版本依赖的思想。\\n\\n* `~`，tilde range。只接收bugfix，不会改功能版本，可以理解为约等号。比如`~1.2.0`，即使上游开发了1.3或1.4，仍停留在1.2.z的最后一个版本。是早期npm的默认策略，也是比较稳健的策略。\\n* `^`，caret range。只要保证兼容性，尽量往新了更，会保证左侧第一个非零值不动。比如`^1.2.0`会追踪上游的1.3.x，但是`^0.2.0`则会停留在0.2.x，因为左侧第一个非零是2，必须保证不变。这大概是语义化版本对0的理解有不稳定的意思，所以稳妥起见遇到0选择跳过。\\n\\n我倒觉得都用`1.*`这种方式表达依赖，更少学习成本，也更直观。"}'));jctx.push(JSON.parse('{"id": "190221", "tag": "lang", "text": "# Lisp与Haskel比较\\n\\n这两门语言从不同的角度去解决了一个共同的问题：如何减少重复代码，如何提高抽象。\\n\\n首先两门语言都是建立在lamdba演算之上，都提供了first class的函数支持，所以在这两门语言里函数都是构建计算的基本单元，而不是c系语言的statement。\\n\\n但是即使是书写函数，人们依然希望获得更加高级的抽象，来减少重复，举几个具体的例子：\\n\\n解析文本这个过程，前进buffer >> 判断是否符合当前的语法结构 >> 失败了？报错 >> 成功了继续重复（重复的代码：判断）\\n渲染模版的过程，计算一个模版片段 >> 计算下一个模版片段 >> 把模版片段相连 >> 继续重复 （重复的代码：相连）\\n设计一个状态机的过程，拿到上一个计算之后的状态值 >> 基于这个值运行状态机，产生新的状态和可能的计算结果 >> 继续重复 （重复的过程：状态传递）\\n我们看到这个时候依赖人工书写这些代码会出现大量重复的情况，LISP的思路基于语法结构，LISP巧妙的利用lamdba的基本书写形式 (lamapp variables)，构建了模版(marco)，这意味着只要是一段代码具有相同的语法结构，比如重复地进行判断，你都可以把它抽象为模版，由编译器或者解释器来替你做语法层面的替换，自动生产重复的代码。需要注意的是LISP的模版抽象是基于语法树(AST)而不是字符串的，同时LISP的AST非常简单，这意味着书写构建AST的模版也非常简单。\\n\\n\\n而Haskell的思路是建立在类型类多态的基础上的，haskell里构建大规模计算的类型类是Monad，它定义了一个多态的连接函数bind，aka. >>= 。 这个函数的作用是连接上下两段相同类型的运算。在这个连接的过程中，你可以通过定义判断，或者相连，或者传递状态等等，来实现不同的计算语义，这个类型类是haskell减少代码重复的关键。而这个构建计算的框架和haskell的强类型系统非常契合。\\n\\n\\n当然LISP也可以实现一个untyped的monad模版，haskell也支持template haskell，所以在LISP里monad这是众多模版中的一个，而在Haskell中，LISP的AST也只是众多语法结构里比较底层的一个。但是这些并不意味着谁比谁更加强大，这只是两个语言解决问题的思路不同。\\n\\n\\n所以无论如何，如果可以，请把这两门语言都认真的学习一番，即使你可能不在实践中使用它们，它们都会给你带去很不一样的编程思路。\\n"}'));jctx.push(JSON.parse('{"id": "190223", "tag": "protocol", "text": "# Unicode的若干概念\\n\\n可以把Unicode想成一本字典，规定了每个文字的映射(严格的说有些带声调的文字是组合出来的)。ASCII的删除键DEL编码是0x7F，在打孔机时代把字母全部重置，如果没见过纸带怕是理解不了的。\\n\\n欧洲文字ISO8859定义了16个分部，但是要混打德文和俄文就不行了，于是2022规范引入了ESC转义规则，这套规则后来也被用在JIS和GB上。\\n\\n截止1999年前，CJK统一汉字的范围是4E00-9FA5，用了基本面的20901个符号。后来又补充了若干编码，大多在基本面，少量在0x20000面，都是很少见的字。不严谨地说，用4E00-9FA5是足够用的。\\n\\n首先每个字符是不是等宽，于是就有了宽字节和多字节的区分。宽字节的好处是查找统计反转方便，而多字节由于是变长，保存拉丁字母会省空间。因此宽内存多用于内存中的计算，而多字节用于存储或传输。Windows的API就是宽字节版。\\n\\nBMP之前的宽字节方案，就称为UCS2，多字节编码是UTF8。随着UCS2不得换为更大集合，出现了UCS4方案，Windows为了保持和UCS2的兼容性，于是有了UTF16编码。它选取了UCS2一段不用的编码段来标识。而这个段的范围是1024x1024。这个范围等于17x65536，也就是现在字符集范围的来历。\\n\\n## 正则匹配\\n\\npcre库为适应Unicode，加入了`\\\\p`选项，支持pUnicode类名和p{Unicode}文字名两种模式。比如想匹配广义的数字，用`/\\\\pN+/`，想匹配中文，用`\\\\p{Han}`不用指定编码区间，全部交给底层文字引擎就可以了。\\n\\n## 代理项对sorrogate pair\\n\\n最初的1.0版本定义65536的集合大小，称为BMP。但是2006年中国要求所有软件支持GB18030，这个范围就不够了。这时就从BMP中把D800~DFFF这段区间保留下来不单独表示任何字符，专门用于转义扩展。这个区间又叫S区，共2048个字符。\\n\\n转义时，D800到DBFF表示高10bit，DC00到DFFF表示低10bit，于是又能多表示16x65536个字符，再加上BMP。整个Unicode范围17个位面就是这么来的。"}'));jctx.push(JSON.parse('{"id": "190301", "tag": "os", "text": "# 多线程中锁的介绍\\n\\n自旋锁（spinlock）很好理解。对自旋锁加锁的操作，你可以认为是类似这样的：\\n\\n```\\nwhile (抢锁(lock) == 没抢到) {\\n}\\n```\\n只要没有锁上，就不断重试。显然，如果别的线程长期持有该锁，那么你这个线程就一直在 while while while 地检查是否能够加锁，浪费 CPU 做无用功。\\n\\n仔细想想，其实没有必要一直去尝试加锁，因为只要锁的持有状态没有改变，加锁操作就肯定是失败的。所以，抢锁失败后只要锁的持有状态一直没有改变，那就让出 CPU 给别的线程先执行好了。这就是互斥器（mutex）也就是题目里的互斥锁（不过个人觉得既然英语里本来就不带 lock，就不要称作锁了吧）。对互斥器加锁的操作你可以认为是类似这样的：\\n\\n```\\nwhile (抢锁(lock) == 没抢到) {\\n    本线程先去睡了请在这把锁的状态发生改变时再唤醒(lock);\\n}\\n```\\n\\n操作系统负责线程调度，为了实现「锁的状态发生改变时再唤醒」就需要把锁也交给操作系统管理。所以互斥器的加锁操作通常都需要涉及到上下文切换，操作花销也就会比自旋锁要大。\\n\\n以上两者的作用是加锁互斥，保证能够排它地访问被锁保护的资源。\\n\\n不过并不是所有场景下我们都希望能够独占某个资源，很快你可能就会不得不写出这样的代码：\\n\\n```\\n// 这是「生产者消费者问题」中的消费者的部分逻辑\\n// 等待队列非空，再从队列中取走元素进行处理\\n\\n加锁(lock);  // lock 保护对 queue 的操作\\nwhile (queue.isEmpty()) {  // 队列为空时等待\\n    解锁(lock);\\n    // 这里让出锁，让生产者有机会往 queue 里安放数据\\n    加锁(lock);\\n}\\ndata = queue.pop();  // 至此肯定非空，所以能对资源进行操作\\n解锁(lock);\\n消费(data);  // 在临界区外做其它处理\\n```\\n\\n你看那个 while，这不就是自己又搞了一个自旋锁么？区别在于这次你不是在 while 一个抽象资源是否可用，而是在 while 某个被锁保护的具体的条件是否达成。\\n\\n有了前面自旋锁、互斥器的经验就不难想到：「只要条件没有发生改变，while 里就没有必要再去加锁、判断、条件不成立、解锁，完全可以让出 CPU 给别的线程」。不过由于「条件是否达成」属于业务逻辑，操作系统没法管理，需要让能够作出这一改变的代码来手动「通知」，比如上面的例子里就需要在生产者往 queue 里 push 后「通知」!queue.isEmpty() 成立。\\n\\n也就是说，我们希望把上面例子中的 while 循环变成这样：\\n\\n```\\nwhile (queue.isEmpty()) {\\n    解锁后等待通知唤醒再加锁(用来收发通知的东西, lock);\\n}\\n```\\n\\n生产者只需在往 queue 中 push 数据后这样，就可以完成协作：\\n\\n触发通知(用来收发通知的东西);\\n\\n// 一般有两种方式：\\n//   通知所有在等待的（notifyAll / broadcast）\\n//   通知一个在等待的（notifyOne / signal）\\n```\\n这就是条件变量（condition variable），也就是问题里的条件锁。它解决的问题不是「互斥」，而是「等待」。\\n\\n至于读写锁（readers-writer lock），看英文可以顾名思义，在执行加锁操作时需要额外表明读写意图，复数读者之间并不互斥，而写者则要求与任何人互斥。读写锁不需要特殊支持就可以直接用之前提到的几个东西实现，比如可以直接用两个 spinlock 或者两个 mutex 实现：\\n\\n```\\nvoid 以读者身份加锁(rwlock) {\\n    加锁(rwlock.保护当前读者数量的锁);\\n    rwlock.当前读者数量 += 1;\\n    if (rwlock.当前读者数量 == 1) {\\n        加锁(rwlock.保护写操作的锁);\\n    }\\n    解锁(rwlock.保护当前读者数量的锁);\\n}\\n\\nvoid 以读者身份解锁(rwlock) {\\n    加锁(rwlock.保护当前读者数量的锁);\\n    rwlock.当前读者数量 -= 1;\\n    if (rwlock.当前读者数量 == 0) {\\n        解锁(rwlock.保护写操作的锁);\\n    }\\n    解锁(rwlock.保护当前读者数量的锁);\\n}\\n\\nvoid 以写者身份加锁(rwlock) {\\n    加锁(rwlock.保护写操作的锁);\\n}\\n\\nvoid 以写者身份解锁(rwlock) {\\n    解锁(rwlock.保护写操作的锁);\\n}\\n```\\n\\n如果整个场景中只有一个读者、一个写者，那么其实可以等价于直接使用互斥器。不过由于读写锁需要额外记录读者数量，花销要大一点。\\n\\n你可以认为读写锁是针对某种特定情景的「优化」。但个人还是建议忘掉读写锁，直接用互斥器。\\n\\n额外补充\\n\\nspinlock 不涉及操作系统，就是等价于 while 的俩汇编指令。mutex 虽然经典实现会引起 context switch，但是现在的具体实现不一定，比如 Linux 下可以利用用户空间的 futex。回答里的那个「本线程先去睡了请在这把锁的状态发生改变时再唤醒」不涉及条件变量，可以认为是个系统调用。\\n\\n读写锁内部是至少需要用一把锁来保护当前读者数的，所以，如果你的临界区很小，读写锁相比一般的锁并不能带来很大的优势，甚至可能性能更低。\\n\\n\\n另一方面，读写锁要真正发挥效能，条件也比较麻烦。比如实际的读写锁通常不用例子里两把锁的实现，而是用一把锁、一个条件变量来实现，好处是可以缓解写者饥饿的情况（一旦有写者在等锁，后续读者都需要等写者离开后才能继续），但这样一来，如果读者的临界区没有明显小于写者的临界区，阻塞情况可能会变得比较不理想……\\n\\n\\n不是说不要用读写锁，而是读写锁往往没有看上去那么理想。个人建议是可以优先用 mutex，如果遇到瓶颈后可以选择替换为读写锁，看看能否带来性能提升。\\n\\n通常是用信号量（semaphore）来实现锁，而不是用锁来实现信号量。至于如何保证线程安全，可以理解为有专门的机器指令来保证原子操作。\\n\\n请教一下，为什么“以读者身份加锁”那里，加写锁的条件为什么是“rwlock.当前读者数量 == 1”？\\n\\n第一个到达的读者负责抢写锁，确保写者等待；最后一个离开的读者负责归还。如果你把把所有读者看成一个整体的写者，可能更方便理解为什么这么抢。\\n\\n一个进程获得锁资源进入临界区后，很可能在锁没有释放前被调度走，而其他进程在等待锁资源，这样就会发生死锁。我知道通常spinlock会关中断，所以用spinlock锁定后进程不会被调度走。那么其他几种锁会允许获得锁后被调度吗？\\n\\n如果我的理解没错的话，你说得这种情况是正常情况，还是可以调度回来的，不是死锁。如果是两把及以上的锁，各个线程上锁顺序不一致，才会出现你说的死锁问题。\\n\\n答主，请教下 前两个例子： 我感觉自旋锁和互斥锁都会引起上下文切换，假设一个单核cpu 分配时间片给多个线程竞争相同自旋锁，其中只有一个拿到锁，然后时间片结束切换到其他线程但它还持有锁，那么其他线程获得cpu 分片但没获得锁进入自旋，cpu 分片结束还是会引起上下文切换，这样跟互斥锁的主动上下文切换似乎是一样的。那它自旋的意义何在呢？因为从这里看起来你进入自旋一定获取不了锁。\\n\\n单核「进入自旋一定获取不了锁」是不对的，因为还会被操作系统切换回来，只不过是浪费时间片。自旋锁本意是给多核/处理器场景用的，除了你举的例子里浪费时间片的问题，如果是在单核非抢占式上用经典自旋锁，那么铁定死锁。多核/处理器的场景下，自旋锁的意义在于优化一些短时间的锁（比如一些自旋等待的时间几乎始终会比互斥锁让线程睡眠&唤醒操作的时间要短的情况）。现代操作系统在实现自旋锁、互斥锁时，一般都会做优化，比如可能会让互斥锁先自旋一小会儿；可能会在自旋锁自旋超过一定时间后强制切换上下文；也可能会在单核非抢占式上让自旋锁什么都不干……不过这些「优化」我们编程时通常都不需要了解，按照经典实现去理解就足够了。\\n\\n您好，问一个问题， mutex 的lock后，unlock应该是要同一个线程才能执行的，但像上面的读写锁， 解锁（rwlock.保护写操作的锁） 的时候不一定是加锁的那个线程怎么办啊....\\n\\n如果你真的想要用两个 mutex 实现的话，需要看你用的 mutex 接口的具体情况，比如 C++17 的 std::shared_mutex 是支持不同线程解锁的。当然你也可以把 mutex 换成 semaphore。\\n"}'));jctx.push(JSON.parse('{"id": "190310", "tag": "os", "text": "# Preempt机制\\n\\nPreempt是一个32位的整数，每一个CPU有一个。虽然是一个简单的整数，但是作用非常大。一个当前运行的线程能不能被抢占，全靠判断这个整数是否是0。这里的线程包括了用户空间的进程的概念，在内核中对应的也是一个线程。当这个整数为0的时候，当前线程就能被抢占，否则不能。\\n\\n软中断是一个普通的内核线程，与其他的内核线程一样，都参与内核线程的统一调度。软中断的实现是每一个CPU对应一个内核线程ksoftirqd，所以，有多少个CPU就会有多少个ksoftirqd内核线程。\\n\\nSoftirq依赖一个softirq_vec数组执行软中断。每一个数组内容对应一个Action，相当于一个中断向量（仿照硬中断进行的设计）。虽然所有的核共享这个数组，但不是每个核都要执行这个数组里的所有任务，每个核都有一个本地数据，用来指明当前核所需要承担的软中断任务。由于是共享一个softirq_vec，理论同一个任务都可以被所有的核对应的ksoftirq内核线程所执行。\\n\\n由于软中断的内部是用户可以注册的任意的软中断函数，在这内部用户的行为一定程度是不可控的。所以软中断系统在调用每一个软中断的action的时候，都会保存preempt的值，在执行结束后复原这个值。这个值的作用很大，一个CPU一个值，如果非0，就代表这个CPU不能发生抢占，只有这个值是0的时候，当前的线程才能被抢占。也就是说，当我不希望被别人抢占的时候，只需要将这个数设置为非0即可。一般调用一下preempt_count_inc就可以将这个数自增1来达到目的。设置的就是当前CPU的计数器。对其他CPU并不影响。\\n\\nTasklet是基于Softirq功能进行实现的，实现的方法就是在一个特定的数组位置定义了一个action，仅此而已。但是由于Tasklet在内部进行了中断和抢占的设置，会显然Tasklet与其他的Softirq行为上不太一样。Tasklet相当于在Softirq之上多了一层保证，两个相同的Tasklet不会同时执行。也就是说不存在软中断上下文重入的问题。除此之外，Tasklet就是个普通的软中断的一个action而已。内核中的Timer也是软中断的一种。同一个软中断是可以在不同的核上同时执行的（但是不能在同一个核上重入），而同一个tasklet不可以同时在不同的核上执行，显然也不能在一个核上重入。\\n\\n由于一个软中断只是一个普通的内核线程，所以它和其他的内核线程一样参与内核的进程调度。只是软中断的内部动不动就会操作抢占和软中断的使能函数，所以显得软中断会比较特殊。更特殊的是，软中断的入口函数是__do_softirq，这个函数在一开始就会把本核的preempt关掉，也就是说，软中断在执行的过程中，不允许在本核被抢占。那么带来的结果就是，如果在软中断里面阻塞了，将永远阻塞。就是完全死锁。这也是软中断的难度之一。\\n\\n假设有一个软中断的函数和一个用户上下文的函数操作同一个自旋锁（这在内核模块的编程中很常见），用户空间锁了这个自旋锁之后，软中断打断了用户空间对应的内核模块函数的执行，软中断继续来加锁，就会导致用户空间的锁永远不能释放，软中断就会永久死锁。所以一般在这种情况的用户上下文需要先把软中断关掉才能进行加锁。这个情况最典型的是用户空间上下文和软中断上下文要操作同一个自旋锁的时候。也正是因为软中断在进入的时候关闭了preempt，禁止了抢占，所以在软中断内部禁止调用可以阻塞或者睡眠的函数，因为这会导致软中断被调度出当前的CPU，其他的内核线程被调度来执行。而这个时候，preempt已经关闭，这样就相当于了所有的内核线程都是在禁止抢占的环境下执行的，这显然会带来严重的问题。所以软中断是绝对禁止调用阻塞式的函数的。\\n\\n另外，软中断和preempt计数器的关系是很巧妙的设计。每一个CPU核对应的preempt计数器都是一个32位的整数。软中断和硬中断在进入的时候都会禁止抢占，而他们禁止的时候设置的位是不一样的。我们知道这个整数只要是非0就不可以被抢占。内核为了区分当前到底是谁在禁止抢占，在这32位的整数上做了很多文章。对这个整数进行了位空间的划分。不同类型的抢占对应不同的位。这样就可以区分不同的专用抢占了。所以软中断和硬中断在禁止抢占的时候，并不是简单的调用自增，而是调用一个增加函数，增加的值就是他们对应的位。例如软中断是__local_bh_disable_ip(_RET_IP_, SOFTIRQ_OFFSET); 这个SOFTIRQ_OFFSET对应的就是软中断的位偏移。\\n\\n如果需要local_bh_disable()来保护进程的临界区。比如，进程A和某个tasklet都会访问一个共享数据结构，semaphore和mutex不行，因为tasklet有可能运行中中断上下文。 spinlock也不行。\\n\\n如果进程A先获得spinlock, 然后被tasklet打断，在tasklet也去获取同义把spinlock, 就会死锁。这时就需要在进程A中调local_bh_disable()，在临界区结束时调local_bh_enable()。这样保证在临界区中，不会被tasklet所打断。\\n\\n实际代码中，一般都是spin_lock_bh()，相当于local_bh_disable()加spin_lock()。关键的代码是软中断的入口处的代码，如下：\\n\\n```\\nasmlinkage __visible void do_softirq(void)\\n{\\n__u32 pending;\\nunsigned long flags;\\nif (in_interrupt())\\nreturn;\\nlocal_irq_save(flags);\\npending = local_softirq_pending(); \\nif (pending && !ksoftirqd_running())\\ndo_softirq_own_stack();\\nlocal_irq_restore(flags);\\n}\\n```\\n\\n实际的软中断的执行之前，都会调用一个in_interrupt的判断，字面意义是如果发现自己已经在软中断内部了，就不再执行软中断。所以，同一个CPU的软中断是不可能被另外一个软中断抢占的。in_interrupt函数仅仅是一个查看当前preempt整数对应的中断的位有没有被设置的判断（包括硬中断和软中断），所以关闭软中断的操作就会很简单：\\n\\n```\\nstatic __always_inline void __local_bh_disable_ip(unsigned long ip, unsigned int cnt) \\n{ \\npreempt_count_add(cnt); \\nbarrier(); \\n}\\n\\nstatic inline void local_bh_disable(void) \\n{ \\n__local_bh_disable_ip(_THIS_IP_, SOFTIRQ_DISABLE_OFFSET); \\n}\\n```\\n\\n只是是一个简单的设置这个preempt整数的操作，使得当前CPU处于一个中断上下文中。而，这个函数不止是中断处理程序才会调用，用户自己写的模块也可以调用。\\n\\n也就是说，用户的内核模块，在用户进程上下文的时候，想要与软中断上下文争夺一个自旋锁的时候，就需要在用户进程上下文对应的内核模块函数中将软中断关掉。关闭软中断在软中断本身看来就是有其他的软中断在运行。所以实际上，这个操作是欺骗软中断系统有其他的软中断在运行了，你就不能运行了。这也是软中断不能同时运行抢占的原因。\\n\\n由于用户在这个CPU上调用 local_bh_disable的时候，一定是一轮的软中断已经运行结束的时候，所以当前关闭软中断就不会和ksoftirqd冲突。一轮的软中断执行会遍历当前CPU pending的所有软中断，直到执行结束，软中断才会让出CPU。出现pending就一定是硬中断的干的，因为硬中断才是负责源源不断的给软中断输出内容的机制。也就只有硬中断能够抢占软中断。\\n\\n这里面就有一个尴尬的问题。如果硬中断可以打断软中断，那么在硬中断退出的时候，怎么保证CPU的上下文是交还给软中断，而不是被调度引擎调度给用户进程了？如果这个得不到保证，软中断的所有不可被抢占的保证都白费了，因为这就相当于间接的允许被抢占。\\n\\n为了解决这个问题，硬中断退出的时候有一个专门的操作：\\n\\n```\\nvoid irq_exit(void) \\n{ \\n#ifndef __ARCH_IRQ_EXIT_IRQS_DISABLED \\nlocal_irq_disable(); \\n#else \\nWARN_ON_ONCE(!irqs_disabled()); \\n#endif \\naccount_irq_exit_time(current); \\npreempt_count_sub(HARDIRQ_OFFSET); \\nif (!in_interrupt() && local_softirq_pending()) \\ninvoke_softirq(); \\ntick_irq_exit(); \\nrcu_irq_exit(); \\ntrace_hardirq_exit(); /* must be last! */ \\n}\\n```\\n\\n可以看到，在硬中断结束的时候，会检查当前CPU的软中断是否被挂起，如果挂起了，就主动的调度软中断。这一步是不把调度交给调度引擎的，而是直接在硬中断中强制调度。也就是说，虽然硬中断可以打断当前的软中断的执行，但是当硬中断执行结束的时候，必须要把CPU交还给被硬中断挂起的软中断。从而就解决了这个可能被间接抢占的问题。\\n\\n这个把preempt按位区分功能的做法有一个很特殊的效果，就是有的功能是可以同时设置多个功能对应的位的。例如NMI也对应preempt整数的一些位，但是当进入NMI硬件中断的时候，它会同时设置NMI对应的位和硬件中断对应的位。\\n\\n```\\n#define nmi_enter() \\\\\\ndo { \\\\\\nprintk_nmi_enter(); \\\\\\nlockdep_off(); \\\\ \\nftrace_nmi_enter(); \\\\ \\nBUG_ON(in_nmi()); \\\\\\npreempt_count_add(NMI_OFFSET + HARDIRQ_OFFSET); \\\\\\nrcu_nmi_enter(); \\\\\\ntrace_hardirq_enter(); \\\\\\n} while (0)\\n```\\n\\n设置的位越多，从效果上看，也就意味着权限越高。因为首先硬件中断对应的抢占位是只能由硬件中断来恢复的，NMI这种硬件中断做到了，即使其他的硬件中断恢复了硬件中断抢占位，其他人还是不能抢占当前的NMI上下文。因为还有一个NMI_OFFSET对应的抢占位没有被清0，而只要这个值不是零，就不能被抢占。这就意味着当发生NMI的时候，任何其他的硬件中断都不能将其抢占。这也就奠定了NMI在硬件中断中的最高优先级的地位。所以，NMI的全称叫做：NMI(non-maskable interrupt)，不可屏蔽中断。这从另外一个层面说明了屏蔽硬件中断的操作是将preempt的 HARDIRQ_OFFSET置位，而不会去操作NMI_OFFSET 。也就是说明了NMI的实现原理还是在这个32位整数上做文章，就是规定了硬件中断以外的位来作为抢占的开关。\\n\\n在硬中断快要结束的时候，硬中断会在硬中断的函数栈内调用一次软中断的执行函数。这个时候，硬中断已经打开了硬中断，所以允许被抢占。这个上下文属于中断的BH，但是还不属于ksoftirqd的软中断内核线程的上下文。\\n\\n由于硬中断进入这个BH的条件是当前没有处于中断中，这个中断包括了软中断，硬中断和不可屏蔽中断三种情况，处于任何一种情况下，这个硬中断BH下都不会进入软中断的处理逻辑。所以这部分的软中断逻辑运行是不会同时允许多个的。只要该CPU当当前有在这个BH逻辑中，其他的硬中断就不会进入。\\n\\n这个逻辑的设计使得同一个软中断同时具备两个执行的环境。一个是在硬中断执行结束退出的时候，直接调用软中断执行，这个时候已经将硬中断打开。另外一个是在ksoftirqd中运行一个软中断，这个软中断执行的时候，是处于内核线程的上下文，接受内核线程调度的过程。一个简单的区别是，如果在ksoftirq中写一个死循环，该CPU是仍然可以执行其他的逻辑的，只是该CPU上的软中断逻辑会被永远卡住。但是如果在硬中断的BH执行了软中断，那么硬中断只可以被硬中断打断，但是打断之后又会回来软中断的执行，所以该CPU将会永久阻塞。\\n\\n硬中断结束的时候调用软中断这个设计，使得当系统负载很低的时候，大部分的软中断都可以直接在硬中断结束的时候完成，而不需要进入ksoftirqd的软中断内核线程进行执行。省去了软中断的内核线程运行开销就节省了一定的性能。\\n\\n但是有个矛盾的问题是，这种硬中断直接能处理玩的软中断的情况只会发生在资源占用率很低的情况。但是这种情况下，对资源的这点程度的节省又意义不大。所以在涉及到中断的性能的时候，仍然是需要关注ksoftirqd的性能，而是BH的性能。\\n\\n内核对于这个preempt一个小小的整数所设计的复杂的机制，可谓精妙绝伦。\\n\\n## 链接原理\\n\\n符号重定位是编译过程和运行过程都要发生的动作。在编译的过程中，如果所有的代码都写到一个单独的文件，由于编译器以文件为单位进行编译，所以可以一次性的拿到所有的函数，那么就可以就地处理所有的符号。显然这样是编译器最喜闻乐见的事情。但是由于有外部库和工程组织的需要，不可能所有的代码都在一个文件中，编译器是用来满足开发人员的需要的，不是反过来。所以编译器就要想办法解决不同文件之间的链接问题。\\n\\n编译器在编译一个文件的时候，会生成一个段的划分。这个划分通常名字大同小异（当然可以通过写link脚本改变段的命名和排布），但是.text, .data这种常用的代码段和数据段基本没有人会有其他想法。每个文件编译的时候生成了同样的.text段，链接器用来处理多个编译单元的（也就是.o文件），将这些文件链接在一起的时候，链接器的主要工作就是将同样的段进行合并。这个操作看起来简单，但是不断.o文件互相调用的情况该怎么解决呢？例如A文件调用了B文件的test函数，在编译A的时候看不到B中test函数的定义，那么这个A里面的B的test函数的地址该如何填充？链接器在进行链接的时候又该如何修正？\\n\\n首先可以确定的是A里面在链接发生之前是肯定不能知道B中test的地址的，但是A里面的汇编结果的call指令的目的地址总需要填充个值。这个值就是0，就是在编译A的时候，发现A调用了别人的test函数，编译器会直接在call的A函数的位置填call 0地址，然后同时，在A的目标文件的一个.rel.text和.rel.data。这两个表叫做重定向表，用于在链接的时候组装不同的目标文件，一个是函数重定向，一个是数据重定向。里面存储的信息就是在A的某某偏移位置调用了test函数。当链接发生的时候，链接器查看A的重定向标发现A需要test的地址，然后在B的函数定义中查找test的定义和地址（是A和B的.text合并之后的地址），然后用这个地址去修改A对应的偏移里面的call指令。这样就完成了链接时的重定位。\\n\\n这个重定位发生在所有的静态链接的时候，包括静态链接库的时候和链接自己的代码文件的时候。\\n\\n但是我们知道还有一个很常见的应用是动态链接。动态链接的时候，符号的位置要在运行的过程中才会解析。编译的时候分为PIC的编译方式和非PIC的传统编译方式（现在大部分库都是使用PIC的方式）。两个的区别在于能不能在内存中重用库的代码。非PIC的传统编译方式需要在加载库的时候就重新设置所有的符号。例如liba.so里面调用了libb.so里面的一个函数test，那么按照静态链接的思路liba.so需要暴露一个段里面存放需要重定位的符号（也就是 call test的偏移），在加载libb.so的时候就要立刻解析条虫liba.so里面的call指令对应的test函数的地址。这种情况相当于liba.so的.text段的内容在加载的时候被修改了。也就是说liba.so的.text的位置在不同的程序里面是不一样的（因为libb.so在不同的进程不一定在同样的位置）。所以liba.so在内存中不能复用，也就是每个进程都要在内存中加载一份liba.so的.text，liba.so使用了多少次就需要加载多少份。\\n\\n这样有问题吗？除了内存里有多份liba.so外，并没有什么问题。有一个特点是加载的时候需要解析全部的符号，即使没有用到的，这样加载的速度相对慢一些。\\n\\n动态链接用到了.rel.dyn和.rel.plt（PLT：过程链接表）。前者是数据重定向，后者是函数重定向。两个段的功能与静态链接的重定向表是一样的。这一切都显得那么轻松。\\n\\n但是毕竟程序员是追求完美的，针对这两个问题，追求完美的程序员想出了PIC模式。所谓的PIC模式就是位置无关，就是想办法让liba.so的.text在所有使用liba.so的进程之间复用。这样只依赖.rel.dyn和.rel.plt可能就做不到了。因为使用这两个表是需要修改.text段的内容的。所以又添加了.got和.got.plt两个表，同样的，前者对应数据，后者对应函数。这两个段就是PIC的实现方法了。\\n\\n所谓的PIC就是在编译liba.so的call test函数的时候，不是在test函数的地址位置填充0，而是填充liba.so的.got.plt段的test地址。在编译的时候.got.plt中的test的地址是空的，显然是不能寻址的，但是call test指令却是直接固定的调用.got.plt的表的test函数的（虽然这个函数还不知道在哪定义）。.got.plt相当于一个桩子，call test就是调用了这里的桩子函数。由于.got.plt不是位于.text里面，所以在解析的时候只需要修改.got.plt里面的test的定义地址就可以找到真实的定义，无论libb.so加载到内存的什么位置，都是只需要找到它，然后填充liba.so的.got.plt的test函数条目即可。如此.text就可以实现复用了。第一个问题解决。\\n\\n第二个问题就是延迟绑定的技术。这个技术是为了防止加载的时候解析所有的符号，而是让用的时候才解析。所需要的技术在应用了PIC之后几乎是现成的。就是.got.plt中的内容不是加载的时候填充，而是用到的时候填充。这一切由运行时的链接器完成（interpreter）。\\n"}'));jctx.push(JSON.parse('{"id": "190326", "tag": "lang", "text": "# Java程序的演变\\n\\n编译后的class类似lua的luac文件，jvm去加载并从指定的类开始跑。不过从一开始，java就支持导入和打包，尤其是打包，引申出很多内容。\\n\\n最早出现的jar包，把多个class集中到一起，作为库或执行程序来发布。jar包的顶层目录结构包含META-INF目录，其中有MANIFEST.mf文件，如果是可执行程序，就要指定Main-Class作为入口。后来sun出了servlet规范，类似python的WSGI，都是语言专属规范，按servlet写好的类，不用考虑底层的网络处理。当年不选择CGI，是因为它和HTTP强绑定，而Java想做通用网络规范。HttpServlet就是语言专属的特化规范。\\n\\n为了配合tomcat这个网络层的运行时，显然需要配置文件，类似于nginx的location语句，这些配置文件一起被打到jar包，为了体现差异，就把后缀改成war。多了一个和META-INF并列的WEB-INF目录，后来的springboot则用BOOT-INF命名目录。\\n\\nwar包流行了至少十多年，慢慢地微服务的概念起来，服务变小再用tomcat加载就很啰嗦，于是springboot把所有的库和资源，包括嵌入式tomcat打到一个包，拿着1个文件，随便往哪一丢，连命令行参数都不用指定就跑起来了，于是war又回归了flat jar(实质是jar in jar的二重封装)。这种包的Main-Class是org.springframework.boot.loader.JarLauncher，Start-Class才是你写的类。\\n\\n顺带说句tomcat实现servlet规范，比较适合阻塞式的模型，追求非阻塞的服务，网络层甚至都不再用tomcat了。\\n\\nflat太大，依赖的lib通常不会更新，可以瘦身。先正常编译，并把BOOT-INF/lib解压出来。修改pom.xml，在configuration、ZIP后加入\\n```\\n<includes>\\n    <include>\\n          <groupId>nothing</groupId>\\n          <artifactId>nothing</artifactId>\\n     </include>\\n</includes>\\n```\\n就能打出没有lib的包。用java -Dloader.path=/path/to/lib -jar /path/to/springboot.jar 运行。\\n\\n## bean\\n\\n最早为了配合IDE开发GUI出现的概念，变成了大家共同遵守的约定，随着加入越来越多的需求，变成EJB，事情过了头又被spring的bean替代，解决的问题，无非是数据的包装和生命周期管理，惟此GC才能正常工作。\\n\\n## maven\\n\\n既然上面给了配置片断，就展开讲讲pom要怎么理解。每个project由groupId(推荐用域名)和artifactId(对应jar名)标识出来，另外vertion当然是必备的。\\n\\n## 组织和标准委员会\\n\\n1998年成立的JCP组织，community process是运作委员会，而每个提案则以JSR，specification request经过多轮讨论，只有到final阶段才算发布。\\n\\n## 使用体会\\n\\n以HTTP发送JSON为例子。解析和序列化是个很繁复的工作，每种JSON都必须先定义一个类，运行中由反射出来的信息，根据类的scheme进行解析，完全不是随心所欲地写节点。要用这种重器，必须先想清楚结构，才能下笔。于是登陆就拆成3个类，1个行为加2个结构类。倘若换在C里，也是如此拆分，但不可能为结构体单开一个文件。\\n\\n再说异常，这恐怕和C的差别就更大，似乎风气导向，出现问题抛异常并在最后统一处理，往好了说是把正常和异常代码各划各片，但新语言如go仍反对异常，只能说语言倾向和手法不同。\\n\\n说说编译，稍微有点功能的程序，依赖包必不可少，`-classpath .;../lib/xx.jar`非常重要。其中的点号一定要有，每个用到的jar包都要写进来，编译和运行都如是。\\n\\n## 远程调试\\n\\n支持多种connector，不过最常用的还是socket。shmem仅局限于windiws，不看也罢。\\n\\n客户端用 jdb -connect com.sun.jdi.SocketAttach:hostname=192.168.101.72,port=8899\\n\\n服务端启动脚本：\\n\\nJAVA_OPTS=\\"$JAVA_OPTS -agentlib:transport=dt_socket,address=127.0.0.1:8000,suspend=y,server=y\\"\\n如果是调试jar包，指令：\\n\\njava -Xdebug -Xrunjdwp:transport=dt_socket,address=127.0.0.1:8000,suspend=y -jar remoting-debug.jar"}'));jctx.push(JSON.parse('{"id": "190401", "tag": "book", "text": "# 山寨舆论背后的政治意图\\n\\n    今天我们继续聊《水浒》。\\n\\n    大家都知道《水浒》是一本讲反抗的书，里面兄弟情义讲得多，计谋韬略讲的少；多叙兄弟之间的出生入死，鲜及政治层面的钢铁无情。但是讲的少，并不是没有讲。上篇文章提到的招安一事宋江就颇费心机，其间很多政治操作。\\n\\n    今天我们就接着这个话头讲一讲这山寨舆论背后的政治意图。\\n\\n1\\n\\n    折腾死人，是我们这个民族的传统。\\n\\n    事业越宏伟，生前闹腾的越大的人，死后越容易被折腾。这种事情千百年来屡屡上演，一代代的政治家，社会活动家，宣传家们前赴后继，乐此不疲。这种折腾有的是以抬举、戴高帽子的办法，有的是以抨击、树靶子的办法；手法不一，效果不同。\\n\\n    我是个读闲书的，不知有汉，无论魏晋。咱们言归正传，聊聊《水浒》。\\n\\n    《水浒》在关键的第七十一回“忠义堂石碣受天文，梁山泊英雄排座次”一节中有这样一段描述：忠义堂后建筑雁台一座，顶上正面大厅一所，东西各设两房。正厅供养晁天王灵位，等于给晁天王弄了一座纪念堂。造反的强梁，也逃不脱死后被折腾的命运。\\n\\n    这是晁天王曾头市中箭以后在书中不多的几次出现之一。\\n\\n    这次的出现有个背景：在这之前经历了东平、东昌之战，收服了体制内部分力量，梁山进入全盛期。晁天王没有看到这样的全盛；他在曾头市中箭临终之际交代谁能活捉史文恭谁就接替他做梁山之主。\\n\\n    带领弟兄们创建了梁山盛世的宋江没有听他的话，他不但没让活捉史文恭的玉麒麟卢俊义做山寨之主；而且为大家指了一条投降的出路。但是宋江同志毕竟还是很讲政治的，虽然他违背了晁天王的遗言，但是面子上的功夫还是做足了。\\n\\n2\\n\\n    面子上的功夫主要有这样几个。\\n\\n    一是，打完曾头市，活捉史文恭以后，作势要遵从天王遗愿，把头把交椅让与卢俊义。后来在李逵，吴用等人的运作之下，以另一种方式解决了遵从天王遗愿和宋江做山寨之主之间的矛盾，维护了梁山的稳定。这中间也有许多关节，我们日后再聊；总的来说，虽然没有遵从天王遗愿，但还是在表面上维护了天王的权威，哪怕这个权威和事实上的晁盖已经无关了。\\n\\n    二是，在梁山英雄排座次的建醮大会上有一句这样关于晁天王的话。原话是这么说的：“三则上荐晁天王，早升仙界，世世生生，再得相见。”跟宋江前面提起晁盖来时的恭敬相比，这句话虽说得客气，背后的意思却不怎么客气。首先，上荐仙界的意思，肯定不是已经在天界了，而是需要上荐才能早升仙界；其次，我们看看需要用罗天大醮来上荐仙界的人都是什么人？书中说的明白：“横亡恶死，火烧水溺，不得善果之人”。晁天王是领兵打仗的，死于战争，按理说并不在此列。宋江这么说，是想告诉大家什么？是不是有点一面大搞揭秘史学，一面高喊维护领袖威望那种高级黑的感觉。\\n\\n    第三，就是前面提到的在这次建醮之后给晁天王修了一座纪念堂。修纪念堂这种事情比较复杂，有的是继承人想强调自己的的合法性，有的是想借着死人替自己说话。但一般都不是单纯的为了纪念逝者。就拿晁盖这座纪念堂来说吧，纪念晁盖的成分就很小。不信你看书中写宋江围攻大名府遇阻，心生忧闷，梦中见晁天王显圣；见晁盖显灵后宋江的表现书中原文是这样写的：先是“宋江吃了一惊”，接着是“急起身问道：‘前者一向不曾致祭，以此显灵，必有见责’。”若是时常挂念怎会吃了一惊？又怎会说出后面“一向不曾致祭，必有见责”这番话来？时时思虑，纪念又何必纪念堂？纪念堂之非为纪念，于此中可见一二。\\n\\n3\\n\\n    晁天王这个人从本质上来说是个粗人，他的愿望和感情都比较朴素。这从中箭弥留之际所留的遗言就能看出来，他说谁捉住了射他的史文恭谁就做山寨之主；将山寨视为私囊，谁能与他雪恨，就馈赠与谁。再反观他当初做出智取生辰纲的决定时，理由也是生辰纲“一套不义之财，取之何碍？”，朴素且简单。\\n\\n    跟作为庄园主的晁盖相比，宋江就显得复杂多了。宋江在公门之中有些身份，押司在皇权不下县的年月虽是小吏，搁现在至少也是个县委办主任，从书中两个主管公安的都头都受他节制的情况看他这个押司的职务弄不好还是个主管公安的县委常委的身份呢。\\n\\n    宋江人在公门，政治敏感性自然比晁盖强。他瞒着朝廷私通晁盖，但是他的意识形态里对于上梁山还是排斥的。秦腔里面有一出戏叫《宋江投朋》，其中有一句唱词：“手指梁山怒晁盖，你不该差人下书来。”这出戏在西宁快板中叫《沧州投朋》；它对宋江的心理描摹应该说是比较准确的。\\n\\n    书中交代他私放晁盖后再次见到刘唐时，先是：\\n\\n听了大惊，说道：“贤弟，你好大胆！早是没做公的看见！险些儿惹出事来！”\\n\\n《水浒传·郓城县月夜走刘唐》\\n    然后拒收金条，并“我不敢留你去家中住”；后面更有分付“贤弟保重，再不可来。此间做公的多，不是耍处。我更不远送，至此相别。”\\n\\n    跟刘唐相别后，更是：\\n\\n一头走，一面肚里寻思道：“早是没做公的看见，险些惹出一场大事来！”一头想：“那晁盖倒去落了草！直如此大弄！”\\n\\n《水浒传·郓城县月夜走刘唐》\\n    这前前后后的表现和心理活动倒是跟戏文呼应，妥妥的一种保护伞想和黑社会切割关系的既视感。\\n\\n4\\n\\n    宋江是有组织的人，是县委的领导；晁盖是草莽财主，是涉黑企业家。没事的时候，晁盖发晁盖的财，宋江干宋江的事；晁盖给宋江供奉，宋江给晁盖摆平诸如夺了西溪村的宝塔之类的事情。政商关系不说清清爽爽吧；也是正正常常。\\n\\n    可是如今晁盖劫了生辰纲，夺的那是当朝太师的富贵。担下这等干系，宋江即使有心也没胆跟他来往了。二人日后的路线差别其实在这里已经埋下了。遇到刘唐这等人时，晁盖是领着干，想的是取了这套富贵；宋江是礼送出境，想的是险些惹出大事来。\\n\\n    晁盖认为宋江担着这天大的干系，提前给他通风报信，将他从官军的虎口中救出，是在江湖义气和皇权体制之间选择了江湖义气；因此他一到梁山落草就冒着被抓的风险打发刘唐拿着书信，黄金来酬谢救命之恩；但是宋江多半不这么看。“老子冒着风险，担着干系让你走人，你却打发人跑来又是书信又是黄金的，这不是给老子惹事么。”这多半是宋江的心里话。\\n\\n    晁盖本以为宋公明也是个革命者；结果搞了半天，人家只是同情革命的同路人。\\n\\n    宋江的这种思想一直延续到做了山寨之主以后，“权居水泊，专等招安”不仅仅是他挂在口上的说辞，也是他积极践行的政治实践。在他的意识中这种“权居水泊”的“犯上作乱”其实是“替天行道”的“忠君之行”，他要做的只是将江湖的力量纳入皇权的轨道，替腐朽的皇权补罅葺漏。\\n\\n    鲁迅说《水浒传》是“国政废弛，转思草泽”。鲁迅确实扭住了根本；以草泽的力量倒逼国家机器的革故鼎新这是宋江式的忠君。在官员/皇权的二元结构中，他并不想抛弃对作为权利意志象征的皇帝的忠诚，但是又不满作为国家机器的一系列官员的作为；只能转思草泽，替天行道去了。\\n\\n5\\n\\n    教员说《水浒》这本书好就好在投降，老人家几次三番说宋江搞修正主义，是投降派。教员是修辞学的大师，熟读《水浒》的他，对于书中种种关节洞若观火。宋江这种将聚义变为忠义的政治正确，将造反纳入皇权格局的大方向，将重建国家政治伦理秩序的政治诉求引入草泽社会的努力，在作为革命者的教员看来确实和投降庶几等之。\\n\\n    宋江说自己“自幼熟读经史，长成亦有权谋”，他上梁山以后通过大量吸纳官军降将来改造原本以蒙冤者和不法者为主的队伍，通过设置纪念堂将自己的政治目标和作为一个晁天王的遗志继承者二者之间的矛盾调和了，引导、教育、督促众家兄弟在忠君的道路上越走越远。\\n\\n    教员是靠边站过的人，也是对教育群众充满责任感和迫切感的人。终其一生，都对各种隐藏起来的政治意图充满警惕。他自己选出来的接班人跟群众说听教员的话不是虚无的，而是落实在行动中的，这个行动就是听各级党委领导的话；各级党委又听接班人的；最后他的讲话被印发的多多的，他的思想被总结的全全的；但是他的话没人听，他的事没人办。\\n\\n    随着他经历的党内斗争越多，越对宋江这种将晁盖高高的贡在纪念堂，动不动就说自己梦见晁天王，但是对晁盖生前那些愿望则一概摒弃的行为警惕。接班人，副统帅一个个都没逃过法眼。然而，即使警惕也改变不了他身后被人更多的请进课本，请进纪念堂，请进各种场合，而实践却更多远离他的情况。\\n\\n    当然，要受这种宋江/晁盖式摆布的不止教员一个人。摆布过他的人，也免不了被人摆布的结局；甚至于一个企业家去世了，也免不了被有的人捧成盖世英雄，被有的人基为犯罪分子；唯一不同的是有的人像教员一样激烈的反抗过这些摆布，有的人却对这摆布甘之如饴。\\n\\n    人民的思想总是从一个极端走向另一个极端；历史长河中，政治家如宋江一般“熟读经史，长通权谋”的是多数，如教员一般“百家注我，恣肆汪洋”的是极少数；如果看不透隐藏在一座座纪念堂，一篇篇颂扬文字后面的政治意图，那“反抗—绝望”的《水浒》模式，将在现实中不断上演；国人也就只能在一轮轮的聚散交替中上演轮回。\\n"}'));jctx.push(JSON.parse('{"id": "190408", "tag": "web", "text": "# 网站项目教训\\n\\n## MySQL\\n\\n用service 启动MySQL后，会发现进程有两个，mysqld_save和mysqld，save是个shell脚本，做些资源守护。记得开binlog，\\n\\n遇到启动不了updating without PID的情况，居然简单地mv /etc/my.cnf /etc/my.cnf.old就解决了。原因是支持无配置文件的启动，用mysqld --verbose --help |grep -A 1 \'Default options\'察看读取的配置文件。\\n\\n本地无法连接，先改配置skip-grant-tables并重启，update mysql.user  set authentication_string=password(\'newpasswd\') where user=\'root\'更新密码。事后发现是密码置空所以登陆不进。\\n\\n远程无法连接，可能是限制了root的来源，use mysql; select host from user;看是否为localhost，并改为%。改完如果不想重启mysql，执行 flush privileges;相当于刷新权限表。\\n\\n## nginx\\n\\n命令行参数很简洁，修改配置后用-t验证，重启用-s，而启动前可以用-p, -c, -g指定预加载路径、配置名称和额外的全局变量。\\n\\n重定位原理，如果是root配合index指令，浏览器的请求一定要以/结尾，这样才能配合index指令找到文件。可以理解为访问站页，用的就是`/`路径，返回index.html。\\n\\n`location ~* /js/.*/\\\\.js`\\n\\n* 以 = 开头，表示精确匹配；如只匹配根目录结尾的请求，后面不能带任何字符串。\\n* 以^~ 开头，表示uri以某个常规字符串开头，不是正则匹配\\n* 以~ 开头，表示区分大小写的正则匹配;\\n* 以~* 开头，表示不区分大小写的正则匹配\\n* 以/ 开头，通用匹配, 如果没有其它匹配,任何请求都会匹配到\\n\\nlocation和proxy_pass配合有个奇怪的特性，路径如果最后带/与否对结果影响很大，比如location /openeco，请求/openeco/user的话，转发后会剥掉匹配部分，实体只会收到/user请求，而location /openeco/，转发就会收到完整的/openeco/user。\\n\\n再举个例子，想达到访问首页跳转到某个子文件夹，利用rewrite指令，这条指令的格式是这样\\n\\n* rewrite  capture-regex  dst-path  flag;  flag可选，但我试了不填效果不确定，建议填上\\n\\n对flag的选择不同会有少许区别。一种是用redirect或permanent返回给浏览器新地址，由浏览器重新请求，另一种用last或break由nginx在内部完成地址重写。前者适合网站域名迁移，通过HTTP 301/302通知搜索引擎进行域名更新。如果只是网站内的地址重写，最好还是用last或break。要理解这两者的区别，要明白地址重写后，并不会立刻进入下一阶段，而是把重写后的地址，作为源，继续匹配别的location，直到没有可以匹配的时候，才进入下一阶段。break的作用，就是提前终止并立刻进入下一阶段，而last会继续匹配location。感觉last这个叫法不够直观。\\n\\n如果是首页重定向，匹配式必须写成`^/$`，完整匹配根路径，这样下次重新匹配时才不会又匹配上。\\n\\n访问限制\\n\\n使用allow和deny指令，要注意的是如果只想限制某些IP可以访问，用allow列举了所有可以访问的IP后，要加一句deny all;才行。另外deny all;和allow all;都加上的话，生效的还是deny。"}'));jctx.push(JSON.parse('{"id": "190410", "tag": "design", "text": "# 微服务的理解和实践\\n\\n大型系统由于业务复杂，理论上通过合理的约定，一个服务没问题，就像linux至今仍是宏内核。但大部分的团队没有自制力，只好强制拆分，使每个功能变小，互相之间通过消息传递，不再也无法知道其它服务的细节。\\n\\n在做两个网站项目，虽然规模不大，还是借公司项目尝试拆分，想以下原则\\n\\n1. 变动和不变分离，比如第三方依赖库和包装类单独建一个工程，部署后要能做到lib/不改动。更新只替换jar\\n2. 同类型业务不拆分，打包进一个jar。如果要读写分离应该是一个服务内两个数据库连接来分离。具体一个jar放多少个业务，视情况而定\\n3. 服务间通过网络交互，不要共享数据库。原因依赖接口而不是依赖实现。服务间的地址通过独立服务共享，现阶段可以用nginx实现"}'));jctx.push(JSON.parse('{"id": "190413", "tag": "web", "text": "# 网站性能测试\\n\\n14年5月我用PHP做了个公司网页，查询协议文档。今天用ab测了性能简直掉了下巴。\\n\\nlinux配置4核4G，Xeon E5-2680v3 2.5G。windows配置4核4G，i5-6500 3.2G。\\n\\n* 首页\\n\\n| 命令 | linux-qps | windows-qps |\\n| ---- | ---- | ---- |\\n|ab -n500 -c5 | 1340 | 194 |\\n|ab -n500 -c1 | 381 | 111 |\\n\\n* 单表查询一条关键字\\n\\n| 命令 | linux-qps | windows-qps |\\n| ---- | ---- | ---- |\\n|ab -n500 -c5| 802 | 69 |\\n|ab -n500 -c1| 155 | 46 |\\n\\n* 多表查询一条关键字\\n\\n| 命令 | linux-qps | windows-qps |\\n| ---- | ---- | ---- |\\n|ab -n500 -c5| 117 | 15 |\\n|ab -n500 -c1| 31 | 14 |\\n\\n从上表数据看，先不谈语言或OS，讨论qps如果不说并发数是不严谨的。不过即使再上量，对这台linux的极限无法超过1500。"}'));jctx.push(JSON.parse('{"id": "190420", "tag": "web", "text": "# 浏览器的网络请求发展史\\n\\n偶然间推论出的历史脉络\\n\\nHTTP0.9版只有GET，加上当时浏览器最初的定位就是互相看文档，初代只是个能在地址栏发起GET的图形程序。\\n\\n慢慢地应用开始丰富起来，估计和CGI同时代，要从浏览器提交数据到后台，于是出现了form表单。这时表单传输数据的格式和GET一样，后来者总会借鉴前面的标准。随着上传文件功能被纳入标准，表单加入了multipart格式，具有独立的特性，至少从数据支撑来说，已经是完整了。\\n\\n但表单数据会导致整页刷新，并不适用所有场合，微软开发了XHR的前身，各厂商发现这是个好东西，标准化之后有人整出了AJAX概念。到这时既然可以更新数据无跳转，那就干脆更进一步，整个应用都驻留在一个页面，SPA和前后端分离的理念才发扬光大。\\n\\n网络层面的问题解决了，但响应数据如何与视图层绑定仍是大问题，直接操作DOM便产生了jq这样的面条代码，于是三大框架响应人心，不约而同地实现了双向绑定。\\n\\n后人看来很自然的开发方式，其实是由多个独立的节点渐渐地串起来。"}'));jctx.push(JSON.parse('{"id": "190421", "tag": "design", "text": "# 负载均衡介绍\\n\\n在架构系统的时候，通常会涉及到分布式，而处分布式里面最前端的是负载均衡器(当然还有cdn)。在网上搜寻一份，对目前常见的负载均衡器做一些介绍和常见组合，不涉及具体配置。\\n\\n第一种是常见的硬件有比较昂贵的NetScaler、F5、Radware和Array等商用的负载均衡器，它的优点就是有专业的维护团队来对这些服务进行维护、缺点就是花销太大，所以对于规模较小的网络服务来说暂时还没有需要使用；\\n\\n第二种是类似于LVS/HAProxy、Nginx的基于Linux的开源免费的负载均衡软件策略,这些都是通过软件级别来实现，所以费用非常低廉，所以我个也比较推荐大家采用第二种方案来实施自己网站的负载均衡需求。除了这些还有：Lighttpd、Apache-mod_proxy、Squid、Socks、TIS FWTK、Delegate。\\n\\nLVS的特点是：\\n\\n1. 抗负载能力强、是工作在网络4层之上仅作分发之用，没有流量的产生，这个特点也决定了它在负载均衡软件里的性能最强的； \\n2. 配置性比较低，这是一个缺点也是一个优点，因为没有可太多配置的东西，所以并不需要太多接触，大大减少了人为出错的几率； \\n3. 工作稳定，自身有完整的双机热备方案，如LVS+Keepalived和LVS+Heartbeat，不过我们在项目实施中用得最多的还是LVS/DR+Keepalived； \\n4. 无流量，保证了均衡器IO的性能不会收到大流量的影响； \\n5. 应用范围比较广，可以对所有应用做负载均衡； \\n6. 软件本身不支持正则处理，不能做动静分离，这个就比较遗憾了；其实现在许多网站在这方面都有较强的需求，这个是Nginx/HAProxy+Keepalived的优势所在。如果是网站应用比较庞大的话，实施LVS/DR+Keepalived起来就比较复杂了，特别后面有Windows Server应用的机器的话，如果实施及配置还有维护过程就比较复杂了，相对而言，Nginx/HAProxy+Keepalived就简单多了。\\n\\nNginx的特点是：\\n\\n1. 工作在网络的7层之上，可以针对http应用做一些分流的策略，比如针对域名、目录结构，它的正则规则比HAProxy更为强大和灵活，这也是许多朋友喜欢它的原因之一； \\n2. Nginx对网络的依赖非常小，理论上能ping通就就能进行负载功能，这个也是它的优势所在； \\n3. Nginx安装和配置比较简单，测试起来比较方便； \\n4. 可以承担高的负载压力且稳定，一般能支撑超过几万次的并发量； \\n5. Nginx可以通过端口检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点，不过其中缺点就是不支持url来检测； \\n6. Nginx仅能支持http和Email，这样就在适用范围上面小很多，这个它的弱势； \\n7. Nginx不仅仅是一款优秀的负载均衡器/反向代理软件，它同时也是功能强大的Web应用服务器。LNMP现在也是非常流行的web架构，大有和以前最流行的LAMP架构分庭抗争之势，在高流量的环境中也有很好的效果。 \\n8. Nginx现在作为Web反向加速缓存越来越成熟了，很多朋友都已在生产环境下投入生产了，而且反映效果不错，速度比传统的Squid服务器更快，有兴趣的朋友可以考虑用其作为反向代理加速器。\\n\\nHAProxy的特点是：\\n\\n1. HAProxy是支持虚拟主机的。 \\n2. 能够补充Nginx的一些缺点比如Session的保持，Cookie的引导等工作。 \\n3. 支持url检测后端的服务器出问题的检测会有很好的帮助。 \\n4. 它跟LVS一样，本身仅仅就只是一款负载均衡软件；单纯从效率上来讲HAProxy更会比Nginx有更出色的负载均衡速度，在并发处理上也是优于Nginx的。 \\n5. HAProxy可以对Mysql读进行负载均衡，对后端的MySQL节点进行检测和负载均衡，不过在后端的MySQL slaves数量超过10台时性能不如LVS，所以我向大家推荐LVS+Keepalived。\\n6. HAProxy的算法现在也越来越多了，具体有如下8种： \\n① roundrobin，表示简单的轮询，这个不多说，这个是负载均衡基本都具备的； \\n② static-rr，表示根据权重，建议关注； \\n③ leastconn，表示最少连接者先处理，建议关注； \\n④ source，表示根据请求源IP，这个跟Nginx的IP_hash机制类似，我们用其作为解决session问题的一种方法，建议关注； \\n⑤ ri，表示根据请求的URI； \\n⑥ rl_param，表示根据请求的URl参数\'balance url_param\' requires an URL parameter name； \\n⑦ hdr(name)，表示根据HTTP请求头来锁定每一次HTTP请求； \\n⑧ rdp-cookie(name)，表示根据据cookie(name)来锁定并哈希每一次TCP请求。 \\n\\nNginx和LVS作对比的结果\\n\\n1. Nginx工作在网络的7层，所以它可以针对http应用本身来做分流策略，比如针对域名、目录结构等，相比之下LVS并不具备这样的功能，所 以 Nginx单凭这点可利用的场合就远多于LVS了；但Nginx有用的这些功能使其可调整度要高于LVS，所以经常要去触碰触碰，由LVS的第2条优点 看，触碰多了，人为出问题的几率也就会大。 \\n2. Nginx对网络的依赖较小，理论上只要ping得通，网页访问正常，Nginx就能连得通，Nginx同时还能区分内外网，如果是同时拥有内外网的 节点，就相当于单机拥有了备份线路；LVS就比较依赖于网络环境，目前来看服务器在同一网段内并且LVS使用direct方式分流，效果较能得到保证。另 外注意，LVS需要向托管商至少申请多一个ip来做Visual IP，貌似是不能用本身的IP来做VIP的。要做好LVS管理员，确实得跟进学习很多有关网络通信方面的知识，就不再是一个HTTP那么简单了。站长教学网 eduyo.com \\n3. Nginx安装和配置比较简单，测试起来也很方便，因为它基本能把错误用日志打印出来。LVS的安装和配置、测试就要花比较长的时间了，因为同上所述，LVS对网络依赖比较大，很多时候不能配置成功都是因为网络问题而不是配置问题，出了问题要解决也相应的会麻烦得多。 \\n4. Nginx也同样能承受很高负载且稳定，但负载度和稳定度差LVS还有几个等级：Nginx处理所有流量所以受限于机器IO和配置；本身的bug也还是难以避免的；Nginx没有现成的双机热备方案，所以跑在单机上还是风险较大，单机上的事情全都很难说。 \\n5. Nginx可以检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点。目前LVS中 ldirectd也能支持针对服务器内部的情况来监控，但LVS的原理使其不能重发请求。重发请求这点，譬如用户正在上传一个文件，而处理该上传的节点刚 好在上传过程中出现故障，Nginx会把上传切到另一台服务器重新处理，而LVS就直接断掉了，如果是上传一个很大的文件或者很重要的文件的话，用户可能 会因此而恼火。 \\n6. Nginx对请求的异步处理可以帮助节点服务器减轻负载，假如使用apache直接对外服务，那么出现很多的窄带链接时apache服务器将会占用大 量内存而不能释放，使用多一个Nginx做apache代理的话，这些窄带链接会被Nginx挡住，apache上就不会堆积过多的请求，这样就减少了相 当多的内存占用。这点使用squid也有相同的作用，即使squid本身配置为不缓存，对apache还是有很大帮助的。LVS没有这些功能，也就无法能 比较。 \\n7. Nginx能支持http和email（email的功能估计比较少人用），LVS所支持的应用在这点上会比Nginx更多。在使用上，一般最前端所 采取的策略应是LVS，也就是DNS的指向应为LVS均衡器，LVS的优点令它非常适合做这个任务。重要的ip地址，最好交由LVS托管，比如数据库的 ip、webservice服务器的ip等等，这些ip地址随着时间推移，使用面会越来越大，如果更换ip则故障会接踵而至。所以将这些重要ip交给 LVS托管是最为稳妥的，这样做的唯一缺点是需要的VIP数量会比较多。Nginx可作为LVS节点机器使用，一是可以利用Nginx的功能，二是可以利 用Nginx的性能。当然这一层面也可以直接使用squid，squid的功能方面就比Nginx弱不少了，性能上也有所逊色于Nginx。Nginx也 可作为中层代理使用，这一层面Nginx基本上无对手，唯一可以撼动Nginx的就只有lighttpd了，不过lighttpd目前还没有能做到 Nginx完全的功能，配置也不那么清晰易读。另外，中层代理的IP也是重要的，所以中层代理也拥有一个VIP和LVS是最完美的方案了。具体的应用还得 具体分析，如果是比较小的网站（日PV<1000万），用Nginx就完全可以了，如果机器也不少，可以用DNS轮询，LVS所耗费的机器还是比较 多的；大型网站或者重要的服务，机器不发愁的时候，要多多考虑利用LVS \\n\\n反向代理从传输上分可以分为2种：\\n\\n1. 同步模式(apache-mod_proxy和squid)\\n2. 异步模式(lighttpd 和 nginx)\\n\\n在nginx的文档说明中，提到了异步传输模式并提到它可以减少后端连接数和压力，这是为何？\\n\\n下面就来讲解下传统的代理（apache/squid）的同步传输和lighttpd,nginx的异步传输的差异。\\n\\n同步传输：浏览器发起请求，而后请求会立刻被转到后台，于是在浏览器和后台之间就建立了一个通道。在请求发起直到请求完成，这条通道都是一直存在的。\\n\\n异步传输：浏览器发起请求，请求不会立刻转到后台，而是将请求数据（header）先收到nginx上，然后nginx再把这个请求发到后端，后端处理完之后把数据返回到nginx上，nginx将数据流发到浏览器，这点和lighttpd有点不同，lighttpd是将后端数据完全接收后才发送到浏览器。\\n\\nSquid作为网页服务器的前置cache服务器，可以代理用户向web服务器请求数据并进行缓存，也可以用在局域网中，使局域网用户通过代理上网。Squid与Linux下其它的代理软件如Apache、Socks、TIS FWTK和delegate相比，下载安装简单，配置简单灵活，支持缓存和多种协议。用ipchains+Squid的解决方案，就可以获得通过缓存高性能的同时能够无缝的访问Internet。\\n\\n小结：apache和squid的反向会增加后端web的负担，因为每个用户请求都会在proxy上与后端server建立的长久链接，知道数据取完前，连接都不会消失。因为wan速度与lan速度的不同，虽然lan之间的速度是极度快的，但是用户的wan连接决定了这个时间长。而lighttpd和nginx的异步模式，是不管你用户要求的数据有多大，都是先收下来，再与后端联系，这是非常迅速的速度，所以proxy与后端连接时间也会很短，几十M的东西也是几秒内。后端不需要维护这么多连接。而lighttpd也和nginx不同的异步，lighttpd是先收完再转向客户浏览器，而nginx是边收数据边转向用户浏览器。\\n\\n那么这到底有什么好处呢？\\n\\n1. 假设用户执行一个上传文件操作，因为用户网速又比较慢，因此需要花半个小时才能把文件传到服务器。squid的同步代理在用户开始上传后就和后台建立了连接，半小时后文件上传结束，由此可见，后台服务器连接保持了半个小时；而nginx异步代理就是先将此文件收到nginx上，因此仅仅是nginx和用户保持了半小时连接，后台服务器在这半小时内没有为这个请求开启连接，半小时后用户上传结束，nginx才将上传内容发到后台，nginx和后台之间的带宽是很充裕的，所以只花了一秒钟就将请求发送到了后台，由此可见，后台服务器连接保持了一秒。同步传输花了后台服务器半个小时，异步传输只花一秒，可见优化程度很大。\\n2. 在上面这个例子中，假如后台服务器因为种种原因重启了，上传文件就自然中断了，这对用户来说是非常恼火的一件事情，想必各位也有上传文件传到一半被中断的经历。用nginx代理之后，后台服务器的重启对用户上传的影响减少到了极点，而nginx是非常稳定的并不需要常去重启它，即使需要重启，利用kill -HUP就可以做到不间断重启nginx。\\n3. 异步传输可以令负载均衡器更有保障，为什么这么说呢？在其它的均衡器（lvs/haproxy/apache等）里，每个请求都是只有一次机会的，假如用户发起一个请求，结果该请求分到的后台服务器刚好挂掉了，那么这个请求就失败了；而nginx因为是异步的，所以这个请求可以重新发往下一个后台，下一个后台返回了正常的数据，于是这个请求就能成功了。还是用用户上传文件这个例子，假如不但用了nginx代理，而且用了负载均衡，nginx把上传文件发往其中一台后台，但这台服务器突然重启了，nginx收到错误后，会将这个上传文件发到另一台后台，于是用户就不用再花半小时上传一遍。\\n4. 假如用户上传一个10GB大小的文件，而后台服务器没有考虑到这个情况，那么后台服务器岂不要崩溃了。用nginx就可以把这些东西都拦在nginx上，通过nginx的上传文件大小限制功能来限制，另外nginx性能非常有保障，就放心的让互联网上那些另类的用户和nginx对抗去吧。\\n\\n用异步传输会造成问题：\\n\\n后台服务器有提供上传进度的功能的话，用了nginx代理就无法取得进度，这个需要使用nginx的一个第三方模块来实现。\\n\\n针对高可用（HA）通常做是主备或者集群，也是分布式集群的中的很重要一环，直接避免单点故障。目前使用较多的HA软件有：Keepalived、Heartbeat、 Piranha、Pacemaker；\\n\\nKeepalived和Heartbeat对比：\\n\\nKeepalived使用的vrrp协议方式，虚拟路由冗余协议 (Virtual Router Redundancy Protocol，简称VRRP)。Heartbeat是基于主机或网络的服务的高可用方式； \\nkeepalived的目的是模拟路由器的双机。heartbeat的目的是用户service的双机； \\nlvs的高可用建议用keepavlived。业务的高可用用heartbeat\\n\\nPiranha 提供了一套解决方案，包括对服务状态的监控、业务服务器的监控和负载服务器本身热备。\\n\\nPacemaker 是一个集群资源管理器。它利用你喜欢的集群基础构件（OpenAIS 或heartbeat）提供的消息和成员管理能力来探测并从节点或资源级别的故障中恢复，以实现群集服务（亦称资源）的最大可用性。 \\n它可以做几乎任何规模的集群，并带有一个强大的依赖模式，让管理员能够准确地表达的群集资源之间的关系（包括顺序和位置）。几乎任何可以编写的脚本，都可以作为管理起搏器集群的一部分。尤为重要的是Pacemaker不是一个heartbeat的工具，可能有人存在这样的误解。Pacemaker是一个延续CRM（亦称V2资源管理器）的项目。最初开发的项目是heartbeat，已经成为该项目的子项目。\\n"}'));jctx.push(JSON.parse('{"id": "190422", "tag": "book", "text": "# 西门庆的情\\n\\n李瓶儿死后，西门庆在她灵前收用了奶妈如意儿。许多人大叫这一段辣眼，我看了却心里难受。\\n\\n面对着你的灵位，把别人当成你，哪怕是这样，都感到欣慰。\\n\\n这不是乖张荒淫，这是深切的哀寂。一个人思念另一个人，到达了这样的程度。\\n\\n李瓶儿死后大半本书，我只读一遍，就不太再读得下去。满纸荒唐言，都是辛酸泪。\\n\\n西门庆对王六儿潘金莲，只是用钱梳拢，每日想尽办法，寻欢作乐。\\n\\n那不是正常的情感。正常的情感，一定会有沟通的愿望，和对未来的期待。想要从对方那里，得到对自我的终极认同。\\n\\n他只是在麻醉自己，也许不敢独处一夜，怕瓶儿夜半入梦来。\\n\\n他再没有人可以爱，没有人可以托付。\\n\\n没有人可以诉说衷肠，没有人能令他再对未来生出美好期待。\\n\\n也许他心里早就暗暗盼望着，死亡带来的终极解脱。为了那阵鬼风，他已经等了太久。\\n\\n西门庆，其实是很怕寂寞的人。他绕树三匝，无枝可依。\\n\\n这个人的情感依赖，到了这样的程度，明知是潘金莲害死官哥儿，他都离不开她。\\n"}'));jctx.push(JSON.parse('{"id": "190429", "tag": "os", "text": "# 网络文件系统机制\\n\\n几种常见的NAS协议，FTP无法挂载到路径，AFS只有Apple用，几乎遇不到，只有Samba(smb又叫CIFS)和nfs方式好用\\n\\n## Samba\\n\\n有1和2两个版本，在win10上比较方便，但win7怎么都试不出来。win10要用smb版本2，需要注意。\\n命令是sudo mount -t cifs -o username=\\"administrator\\",password=\\"1\\" //winip/code/ /mnt/win -o vers=2.0\\n\\n如果linux当服务端，要用`smbpasswd`另外设置密码才能访问。\\n\\n## nfs\\n\\n有1~4版本，前3个版本是Sun设计，4是IETF主导，机制上改动很大。目前多见的是3和4版本，v3监听UDP的111端口，但真正RPC通信端口是后续协商出来的，而v4则只监听TCP/UDP的2049，配置防火墙更简单。\\n\\nwindow作为服务端，linux作客户端时，高版本windows带了v4版本，或者用第三方hane nfs server开启服务，配置 `D:\\\\code -public`就可以共享指定目录了。linux端下载nfs-utils。用 showmount -e ip 查看开放的共享目录，用 sudo mount -t nfs ip:/d/code /mnt/win 就可以挂载目录了。默认用UDP可能不太稳定，可以在mount加上 -o proto=tcp -o nolock。如果用v4版，mount命令改为-t nfs4。\\n\\n如果linux作服务端，步骤稍多一些，必须root身份\\n\\n1. 安装nfs-utils和rpcbind（也叫portmap）\\n2. 编辑/etc/exports文件，执行`exportfs -rv`，启用nfs目录共享\\n3. 启动rpcbind，也叫portmapper服务，在cent上的包叫rpcbind\\n4. 启动rpc.mountd和rpc.nfsd服务\\n\\nv3和v4版本都要用 exportfs 命令设置 NFS 导出目录。exportfs 有两种操作模式：\\n\\n1. 读取 /etc/exports 以及 /etc/exports.d/\\\\*\\n2. 从命令行参数获得导出目录设置\\n\\n两种模式下，exportfs 都会通过 /proc/net/rpc/nfsd.export/channel 往 Linux 内核写一份（很像 Plan 9），并且更新 /var/lib/nfs/etab 文件。\\n\\nnfs采用了 C/S 架构，但是NFS的Client/Server只负责和文件系统交互，而不提供任何 TCP/IP 数据传输功能，需要配合RPC服务器才能实现数据传输（其实也好理解，Sun利用RPC开发了很多服务，NFS只是其中的一个应用，从分层角度看，自然不会包含网络协议）。因此nfs的v3版共有4个服务才能完成完整的功能\\n\\n1. rpcbind服务(portmapper)，监听111端口，有点像 DNS server，它把 PROGRAM ID 翻译成服务真正的 IP 和 PORT(不知道 IP 是否可以是其它机器），每个 RPC service 启动时都要向  注册自己的 PROGRAM ID。可以用rpcinfo -p ip来查看注册了哪些服务。注意这个命令是查注册命令，不一定运行，所以netstat可能看不到这些端口\\n2. rpc.mountd服务，监听20048端口，应该是负责文件系统交互的服务\\n3. rpc.statd服务，有IN和OUT端口要监听\\n4. rpc.nfsd服务，监听2049端口，如果没启动，客户端在mount时会提示RPC程序未注册\\n\\nv4版简化了上述流程，只需要nfsd监听2049就可以了，简化了防火墙的配置难度，但需要额外向/proc/fs/写内容。"}'));jctx.push(JSON.parse('{"id": "190430", "tag": "design", "text": "# 依赖注入和控制反转\\n\\n各个components自己的逻辑\\n怎么把多个小components组合起来形成高一层组件的组合逻辑(也就是控制组合流，你可以手动DI，或者用任何类型的controller，或者用DI Framework，或者你使用的语言直接支持，或者利用隐式环境，关键是单独来完成这件事，别把怎么组合自己和自己的dependency这件事情，让自己来决定；也就是别把components的逻辑和components怎么和别人的实例组合的逻辑放在一起)\\n做到这点需要component不能把自己的依赖写死(不能自己去创建自己需要的dependency的实例)，而是只是声明自己需要的spec(一般是interface；如果只存这个spec/interface的一种实例，那么懒得定义interface用实例的类型做依赖声明也可以，需要存在不同实例的时候再重构抽出interface就行了，但是别自己create自己的依赖。比如sort的实现把要sort的compareTo的实例固定，那么sort就只能sort一种T）这就是广义的DI。 无法把广义DI和DI framework分开思考的人就别评论了。\\n\\n只有很少几种情况components可以直接决定自己的依赖，比如这个依赖绝对不会更改(这意味着你想连UT都把这个components和依赖必须一起测，因为写死了)，或者这个实例在世界上只存在一种(比如你依赖于一些数学函数，Math.abs) 这些东西只存在一种实现，绝对不会变，即使放在UT里。\\n\\n注意：如果需要component控制dependency生成的时机timing，可以inject进来dependency的factory。那么component虽然控制dependency instance生成的时机，但是不知道生成的具体实例类型，同样松耦合了各个Components\\n\\n再次注意：我个人不喜欢DI Framework，是手动DI，或者用Reader Monad一派的，友军请别乱开枪。\\n\\n看了很多答案，感觉都没提到依赖注入对系统设计的重要性，所以其实我更想说一下依赖倒置原则和系统设计\\n\\n因为依赖注入也可以手动完成，而根本不需要DI framework。所以任何支持subtyping或者first class function的语言都完全可以做dependency injection；甚至在C里也可以用函数指针做DI。\\n\\n问：这世上有一离开“依赖注入”就玩不转的项目吗？\\n我想就这个问题讲一下依赖注入，依赖倒置，和系统设计。\\n\\n依赖注入的一般应用\\n\\n依赖注入可以让让“提供功能类A”和“使用功能类B”解耦合；A注入在B里，那么如果A有subtyping的变换A_x，A_y...时，而整体系统调整(比如新feature，测试环境和prod环境)需要B在不同的场景/时间注入其他具体功能实现类A_x...时； B都不需要改，且系统可以通过不同的配置轻松实现在不同场景的多版本系统。最常见的就是业务类使用Dao类，不要在业务类里new具体Dao类，这样就绑死了关系，而注入Dao类，这样则任何Dao的subtyping，业务类都可以接受。\\n\\n## 依赖注入与依赖倒置DI\\n\\n其实依赖注入最重要的作用之一是实现依赖倒置；（控制反转和依赖倒置不同，最后说）\\n\\n让任何B调A的关系，不都产生B必须绑死依赖于A的效果。\\n\\n当B必须用到A的功能的时候，控制流是从B到A，A不需要知道B(最直观的proof A不需要import B)，而B必须知道A，或者说B直接依赖于A(直观proof就是B需要import A才能用A)，依赖关系箭头从B到A；这样会导致类依赖图甚至包依赖图(如果A和B在不同包)是从B指向(依赖)A。\\n\\n但是如果有一个interface类C在B的包里(甚至自已的一个interface包里)，让A实现C(注意这样A import C依赖于C)，让B使用C的interface(B也依赖C)来间接使用C的implementation A，A的实例通过依赖注入到B里供B使用；这样依赖关系就变成了A依赖C，而如果C在B的包里(为什么C放在B的包里合理请往下看)，依赖关系就变成了A所在的包依赖于B所在的包(注意本来是B包依赖A包)。从而实现了依赖的倒置。\\n\\n\\n依赖倒置原则与系统设计\\n\\n为什么要这么麻烦做依赖倒置？如果你看过我写的这篇关于系统分层的文章：用谁都能看懂的方式来解释系统设计中的分层，那么应该明白一个稳定易拓展的系统应该让底层依赖高层，而不是相反(高层依赖底层)，一个合理的系统，应该由高层按照自己的需求，指定底层应该满足的specification(比如B包是一个高层业务包，那么B里的interface C就是B对于底层的命令式的Specification，然后B里的所有逻辑都应该基于这个specification来写，因为B和B的Specification, 也就是interface C都是在高层抽象讨论问题，所以B和Interface C放在一个高层包里是一种合理设计)，底层应该想方设法来满足这个specification(也就是底层类A需要实现interface C)；而不应该让业务类扭曲自己来迎合底层类的需要(非依赖倒置的情况)；最终实现整个系统的高层底层配合；\\n\\n用DDD的话来说就是，业务决定技术实现， 而不是相反。\\n\\n不使用依赖反转的系统构架，控制流和依赖关系流的依赖箭头是一个方向的，由高层指向底层，也就是高层依赖底层，最明显的特点就是高层包需要import很多底层包里的类，这样的话任何的底层小改动，都可能产生影响高层业务逻辑类的改动的蝴蝶效应；这样的系统耦合严重，维护，模拟，测试，实验和拓展都很困难(想想你一个业务类绑死了数据库类，你怎么做UT？怎么在Continuous Delivery的pipeline里模拟数据库做integration test？怎么能简单的把业务数据写替换成写到SQS里，换成写到S3里，写到Kinesis里？ 或者能同时都写)，可能动不动就要重构和re-architecture；让程序员苦不堪言。而使用依赖倒置，使得底层包服从高层包规定的spec。高层包里不会import任何一个底层类。只要interface设计的好，底层的任何变动，都不会影响高层一行code。**即控制流向和依赖方向是反的**。\\n\\n严重注意：一个系统绝不仅仅只有高层和底层2层，而是可以有很多层，业务类也可以并需要分为多层，同时保证依赖倒置！\\n\\n## 关于控制反转IoC\\n\\n顺便提一下控制反转，比较容易和依赖倒置原则弄混(太早学的这些，我在开始写这个答案的时候也弄混了这些名词。。。)，控制反转是EJB，Spring这种框架平台兴起的时候提起的一个概念。相对于Lib来说，我们总是自己application的逻辑调用Lib的逻辑，控制流由我们的application规定，EJB，Spring是让Framework调用我们的逻辑。在这个控制流的方向上，体现了控制反转。这个原则也称为Hollywood Principle - \\"Don\'t call us, we\'ll call you\\"。\\n\\n其实Template Method这个设计模式也体现了控制反转，父类实现一些框架方法并定义控制流如何走，控制流会按照定义好的顺序调用一些abstract方法，然后留给子类去实现这些abstract方法。JUnit框架就是一个好例子。\\n\\n控制反转是当系统的很多东西都能够模版化的时候，而业务逻辑只是其中的某一步或者几步，那么framework一般需要DI的方式来管理你的领域(业务)类，来inject到自己的控制流里，成为framework规定的控制流的一部分，而你的业务类则不需要关心控制流。可以看出，当控制流可以framework化和模版化的时候，控制反转相当重要（EJB，Spring，JUnit都是例子）。\\n\\nDI Framework\\n\\nDependency Framework, 就是Spring，GoogleGuice，MacWire(一个scala DI framework), 这种通过config file或者annotation等标记来帮助你自动DI的框架，那么到底是手动wire手动DI好，还是用DI framework好呢？\\n\\n要评价这个就不免带个人意见色彩了。。。 我个人不是很喜欢DI framework，因为我喜欢函数风格的程序，**DI对于函数式来说不过是high order function罢了**。我个人更倾向于MacWire的作者的意见, In today’s post-OO world, is dependency injection still relevant? 就是DI以后可能会设计为语言自己的功能，由语言来提供一个隐式“environmental” parameter。\\n\\nJava，Scala里的DI framework有两个好处：\\n\\n可以把wiring各个组件，类的code变成config，这样严格区分了“组件功能逻辑”和“控制组合逻辑”，降低了功能逻辑 泄漏到“控制组合逻辑”的类里的风险(其实这很经常发生，我review code就经常看到新手SDE在组合逻辑里放业务逻辑...) 而使用DI framework，比如Spring配置文件，根本就没办法写逻辑，只能老老实实指定谁怎么实例化和谁跟谁组合，所以避开了这些风险。\\n可以用反射等实例化非public可见，而是包可见，甚至private的类，而手动wire则需要所有需要实例化的类是public可见的。比如我们的例子里底层的功能类A必须是public可见，我们的手动wire所有高层底层组件的逻辑才能够实例化A。使用DI framework使得我们可以把A设为包可见甚至private，这样除了DI的wire logic，没有任何类能够实例化A，保证了A不被滥用。当然，如果你上了java9，你就可以用modular功能指定A只能被wire logic所在的包看到，所以上了java9的项目，在这点上DI framework就毫无优势了。\\n\\n依赖注入，可说是任何程序员必掌握的技巧之一，系统设计入门基础技能之一。而依赖倒置原则作为一条原则，自从被人发现以来，从来都没被颠覆过，可以算得上软件设计艺术的真理之一。\\n\\n最后推荐Clean Architecture这本书。\\n"}'));jctx.push(JSON.parse('{"id": "190431", "tag": "design", "text": "# DI续\\n\\n为什么 AngularJS 抛弃了 DI 而换回 import 了呢? 因为这些用着用着发现 JS 中 require \\"com/bar/foo\\" 和 Java 的 import .Foo 有两个本质的不同: 第一在 JS 里, 你可以在打包工具中把 \\"com/bar/foo\\" resolve 成不同的目标, 第二是 JS 没有 Java 类这种非对象的语法上碰不着的东西, require/import 进来就是实例, 那直接用 require/import 就好了, 本来通过大量代码实现的复杂的依赖注入框架瞬间就变得一无是处了... 等到 Angular 2 抛弃这些糟粕简化回 require/import, 市场早就被后来的框架占领了. 当初使用 DI 的错误决策是因为思维没转变过来: require/import 表达依赖更简单容易理解, 没有了限制的简洁表达, 才更接近本质.\\n\\n\\n为什么 Ruby 实现依赖注入不需要 1 行代码? Martin Fowler 也说过, 依赖注入和所谓的 Service Locator 模式是等价的. 而啥是 \\"Service Locator\\" 模式? 无非就是动态语言的运行时等价于一堆 service instance 的数据库, 然后你取哪个对象不用做编译期类型检查, 你运行时想往里边放什么对象也没有任何障碍, 其实这根本就没有依赖啊摔... 还搞依赖注入就是程序员灭火法: 先把火点着, 再打水灭火...\\n\\n\\n然后既然你用过 Haskell/Scala, 那你该知道, 它们支持 Structural Typing. Structural Typing 也不是什么很新鲜的东西, C 有 Go 也有. 只要两个东西的成员声明都一样, 那就可以搭配上. 这样模块间就解依赖了. \\n\\n解依赖的错误方法是: 先作死搞这么多依赖, 然后再用复杂的依赖注入解决\\n\\n正确方法是: 别作死, 用动态语言的思维去架构, 约定的界面尽量用 Structural Typing 搭配上就好了http://com.bar\\n\\n要倒置并不是依赖被程序员搞反了，而是当系统分为不同层级的时候；必然是控制流是从高层call向低层（比如业务逻辑调用数据库，而不是数据库逻辑调用业务逻辑），这个和使用什么语言无关。如果依赖箭头和控制流方向相同，那么必然造成高层业务紧紧依赖底层实现。 所以必须在构架上达到“依赖倒置”，做到依赖箭头与控制流的反转。\\n"}'));jctx.push(JSON.parse('{"id": "190501", "tag": "os", "text": "# Linux的软件包管理软件说明\\n\\n不同发行版有独特的包管理软件，分为打包软件和包管理两块，相对来说打包软件定义包的格式，而包管理要解决的问题要复杂得多。\\n\\n1. 添加软件时，要记录所有依赖的库和执行程序，且依赖项的引用计数要加1\\n2. 删除库时，所有依赖这个库的执行程序都要连带删除\\n3. 删除执行程序时，对其依赖的库的引用计数要减1，如果减到0了，要提醒用户，但并不删除，比如apt autoremove就是用于删除引用计数为0的库和执行程序\\n4. 更新软件时，对依赖项有变动的，要更新引用计数，并按上面提到的策略给用户以提示\\n5. 列举已安装软件时，apt做得很清晰。如果是被连带安装，会标注automatic，如果引用计数到0了，会提示auto-removable。对被连带安装的软件，如果手动安装一次，其auto标记会被清除，以后就不再提示auto-removable了。\\n\\n## CentOS\\n\\n可以更新系统内核版本。\\n\\n* yum clean all\\n* yum update\\n\\n时间取决于和最新版本的差距，我从7.3到7.6约用了10分钟。为了让新安装的内核成为默认启动选项，你需要如下修改 GRUB 配置,打开并编辑 /etc/default/grub 并设置 GRUB_DEFAULT=0.意思是 GRUB 初始化页面的第一个内核将作为默认内核。不过这条我没用到。\\n\\n升级后不同版本会遗留很多的垃圾，要清理。先找出冗余内核\\n\\nrpm -qa | grep kernel\\n\\n对不是当前在用的，复制名字并删除。\\n\\nyum remove xxx  yyy\\n\\nyum不会升级内核版本，elrepo.org 专门负责有内核升级需求的人。命令如下\\n\\n* rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org\\n* rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm  //适当调整\\n\\n仓库启用后，你可以使用下面的命令列出可用的系统内核相关包:\\n* yum --disablerepo=\\"*\\" --enablerepo=\\"elrepo-kernel\\" list available\\n\\n接下来，安装最新的主线稳定内核:\\n* yum --enablerepo=elrepo-kernel install kernel-ml\\n\\n外番：rpm的命令围绕-q, -i, -e展开，选项不能随意搭配，但顺序随意。有些只用于-q查询，有些只用于-i安装。奇怪的是-R只在man能看到，帮助没有显示。\\n\\n## AlpineLinux\\n\\n首先编辑/etc/apk/repository，到你想要的版本号，执行\\n\\n* apk update   ; 更新repo的index\\n* apk upgrade  ; 更新程序实体\\n* sync;reboot  ; 保证落盘重启生效\\n\\n## Debian\\n\\n版本7(wheezy)以前是apt-get和apt-cache分离，版本8(jessie)增加了统一入口apt。apt-get负责下载软件和仓库索引，而apt-cache是查询，初始干净的版本是没有仓库索引的，这时用apt-cache搜索没有结果，是正常现象，apt-get update后就能正常使用了。\\n\\n## Gentoo\\n\\n衍生自BSD系的portage，全部由python/bash构成。和其它二进制方式管理包不同，仓库同保存的各种软件的元信息，以目录形式保存描述，倾向于源码编译。\\n\\n所有的命令都以e开头，核心命令是emerge，支持5种安装格式。意寓把某个软件合并到portage树，最常用的world是一个set的别名。另外还有ebuild，emaint等。\\n\\n由于从源码编译，有几个很独特的概念\\n\\n* USE: 类似编译开关，选择是否取消某些连带项，而arch就做不到，只能取决于维护者的个人喜好\\n* mask: 对包做的标记，如果前提不满足，无法安装\\n* EAPI: ebuild的格式版本，隔一段时间会更新，如果达不到上游的要求不能安装软件\\n\\n## Arch\\n\\npacman的命令风格格式全部以`-[DQRSU]`开头，接下来是选项，如果是单字选项可以直接跟在命令后面。比如-Qv命令显示同步源和所有已安装的包，比如我的版本有5个文件，大小从4K到5M不等，每个文件是gz压缩的纯文本。所有已安装的包也以独立目录的形式存在，每个包的描述、文件详情都能很方便得看到。\\n\\npacman的包没有.deb或.rpm这样特殊的后缀，而是很朴实地用了.tar.xz名（也可以配置为.tar.gz）。包的内容通常是建立在/usr目录下的各个文件，还有.BUILDINFO, .MTREE, .PKGINFO三个元数据文件。制作包也很朴实，写好PKGBUILD文件，再用makepkg就能打包。\\n\\n### pacman在其它发行版上的尝试\\n\\n起因是装了Gentoo但是磁盘空间不够，第一步emerg-webrsync就失败了，无法下载软件的系统是没有意义，于是想既然Linux的内核一致，能否从别的发行版移植包管理器来用。\\n\\n最流行的当然是apt，但这几天刚好在用ArchLinux的pacman，而且从不足2小时的了解来看，pacman非常简明，且源码只有3M，感觉比较容易，这是我第一次尝试编译包管理系统。pacman依赖并不多，在这个2015年左右的Gentoo上，只缺少libarchive的3.0版本，另外bash版本稍低，最终决定编译pacman的5.1.3。(5.2版本要求bash版本4.4以上)。遇到`clock_gettime`函数不存在，好在代码里用宏给了另一种实现，把相关3行代码换一下手动编译过。配置通过/etc/pacman.conf就够了，可以配置repo位置、arch、哪些包不更新、使用curl/wget下载等。\\n\\npacman的思路，所有的软件信息保存在本地的sync和local两个目录，sync是全部软件的索引，local是已安装的软件。-S操作sync，-Q操作local。所以搜索也区分全部搜索的-Ss和本地搜索的-Qs。一旦理解其设计思路，命令就能说通了。\\n\\n安装和配置完成后，先尝试安装locate包(几乎没有依赖)，然后提示需要更新filesystem、glibc、tzdata等若干个包，但是下载后又提示glibc:  exists in filesystem并拒绝安装。我猜原因是这些包不在pacman的记录中，且对应位置已经有文件，为防止潜在的冲突，就停止安装。加了--overwrite \\\\*选项后大部分错误都屏蔽了(这个选项正常情况下尽量避免)，只有filesystem提示一些目录无法覆盖。于是我尝试把另一个版本DB Path下local目录的filesystem内容复制过来，果然骗过了pacman更新了glibc等库并装上了locate。但是悲剧的是执行ls会提示glibc相关的错误，而且ssh也连接不上。\\n\\n分析挂掉的原因，对每个发行版来说，最根本的rootfs一定包含基础工具(哪怕是busybox)和libc，而我只更新libc却瞒过filesystem，导致两者不能配套，最终使得整个系统挂掉。可以至少对pacman来说，由于它管理了rootfs，当安装到其它发行版时，会出现不配套问题。\\n\\nArch没有固定版本(但是filesystem的日期勉强可以算版本)，因此不可能有锚定的rootfs，基础库和工具一定是不停更新的，这也是和debian/cent系最大的区别。"}'));jctx.push(JSON.parse('{"id": "190502", "tag": "think", "text": "# 蒙古帝国\\n\\n成吉思汗传位给窝阔台再传给贵由后，却不能守，被拖雷之子蒙哥抢了帝位，最终传于忽必烈改为元朝。\\n\\n蒙哥、忽必烈、旭烈兀、阿里不哥是拖雷的4个儿子，蒙哥升为汗后，忽必烈为建立军功，38岁始终大理并最终攻克，得以对南宋形成犄角的攻势。由于一路过于险峻，记过一处险径时，46名随从最后只有2名平安，其余都坠落悬崖。而旭烈兀向西进发，打下了巴格达并终结了阿拔斯王朝、顺道进攻阿勒坡、大马士革。就在此是传来了蒙哥的列讯，不得不返程，留下1万名士兵守卫，但这些士兵不久就全军覆没，蒙古的控制终究没能在中东根植。\\n\\n旭烈兀建立伊尔汗国、另有金帐汗国(钦察汗)、察合台汗。忽必烈号称天下共主，但其实不过是名义上的。也有说法把窝阔台汗国也算作其中之一，其规模较小也灭亡最早。"}'));jctx.push(JSON.parse('{"id": "190504", "tag": "web", "text": "# 博客网站功能扩展记录\\n\\n## 调试\\n\\n一直以来对Web开发调试都没有好的办法，知道了`error_log`函数可以记日志。记录的文件名通过php.ini来设置`error_log = php_errors.log`\\n\\n这种相对路径的方式把日志保存到index.php同一个目录下。除了写文件还支持发邮件等格式，对网管来说很实用。如果是php-fpm还支持slowlog，在php-fpm.conf加上\\n\\n```\\nrequest_slowlog_timeout = 5s\\nslowlog = /var/log/php-fpm-slowlog.log\\nrequest_terminate_timeout = 10s\\n```\\n\\n## 账号切换\\n\\n账号就是对session和cookie的控制，通过增加切换账号的页面，让同一个cookie在不同时间段对应不同的session。原有的auth机制没有做成通用，最初的修改甚至直接导致鉴权之后回到主页，而主页又鉴权的死循环。cookie保存的是PHP计算的哈希值，持久化的session文件记录的是数据库名，并不会记录密码，不过目前版本还没有做切换账号时的密码加密，也没有做cookie防劫持。\\n\\n账号切换按钮做了个简单的隐藏，只有登陆过或者芝麻开门方式才会显现出来，不算很高明。\\n\\n随着多账号的实现，以文件方式缓存首页也调整为数据库方式，却因SQL语句少了右括号浪费了半个小时才看错误，PDO错误通过errorInfo方式返回数组，错误码由ANSI定义。另一个缺陷是原来以文件方式保存，用include导入即完成代码到变量执行，换成数据库后要显示执行eval，无法避免失败的情况，需要继续想办法。\\n\\n将鉴权函数从全局函数修改为类的static函数，好处就是可以利用类的自动加载机制，省去了显式加载auth文件的步骤，另外将密码映射表移到类内部，减少暴露的数据。\\n\\n## 单页化\\n\\n在安卓上写程序久了，渐渐萌生了把博客网站也做成前后分离，不再依赖后台模板的想法。\\n\\n改为SPA后，有以下几个点很不同\\n\\n1. 首页会变大。因为用后台模板时，需要切换页面时才会请求，并进入新的页面。而用SPA方式只有数据流，所有的布局在一开始就已全部加载到浏览器上，如果页面很多，首页加载速度多少会有点影响。\\n2. css样式写法变化。原来多个页面时，每个页面对应的css是直接写body、p的样式，显然要合并成一个，并用都按类的方式重写。\\n3. 所有的表单请求，换成用ajax并将内容绑定到DOM\\n4. 生成DOM树的元素，手写`<br/>`，真正到了浏览器却变成了`<br>`，难怪都说前端坑多。\\n\\n分离后JS得到的都是JSON数据，除了把静态内容渲染到DOM，还有一块就是要构造带有交互功能的按钮。\\n\\n## 支持标签\\n\\n首先数据库要支持增加列，使用`alter table blog add column tag text default \'\';`语句增加一列。\\n\\n由于数据从一列变为两列，返回到页面的格式就不能再用字符串，比如用json。在PHP侧把array用`json_encode`转换输出，虽然是json但网络传输的还是字符串，所以js得到的数据不能按json操作，好像版本3的时候还没有纳入规范，直到版本5才正式成为规范。有个通用的技巧直接用eval(string)就可以转成对象，还有种说法是用eval(\'(\'+str+\')\')格式，似乎前面简单的做法就够了，不清楚两者的差异。\\n\\n总的来看多个数据在浏览器和服务器之间的交互格式是不同的，请求要按照URL规范，因为也只有这个规范，加上PHP天然就很好地支持这种格式，所以是最佳选择，回复因为是给js解析，所以用json无疑就是最好的格式。\\n\\n还有个问题，在赋值时究竟用innerText/innerHTML/value的哪一种？\\n\\n1. innerText是id为object的闭合标签内的文本,输入输出的是转义文本(字符串);(label控件用innerText有效)\\n2. innerHtml是`<div>`标签内的文本,输入输出到该DOM内部纯HTML代码(流);(获得td、div等html元素时候,它们是没有value或是text属性,只能用innerHtml)\\n3. value是表单元素特有的属性,输入输出的是转义文本(字符串);(Button、CheckBox、Radio)随表单一起发送的值;(Reset、Submit)标签;(Text、Hidden)默认值;(File、Password)(注: Text控件用value有效)\\n\\n其实对textarea标签，也就是多行文本编辑框，innerHTML和value还有更大的区别\\n\\n1. innerHTML 仅在 textarea 初始化的时候对 value 有影响，value 的内容就是从 innerHTML 来的；除此之外，innerHTML 和 value 没有任何关系，修改 value 不影响 innerHTML，修改innerHTML 不影响 value；\\n2. 界面上呈现的永远是 value 的值，而不是 innerHTML，比如通过代码修改 innerHTML 之后，界面上 textarea 里面的内容还是 value 的值；\\n获取文本框的内容，自始至终都应该读取 value；\\n3. value 获取的是原始内容，innerHTML 获取的内容会自动将 `<` 和 `>` 这2个符号转义；\\n4. 初始化 textarea 的内容只能写在 `<textarea>` 和 `</textarea>` 的中间，不能像 input 那样写在 value 属性上面；\\n\\n所以 value 一般用于一些表单元素的获取值，input，select 等，textarea 也算表单元素，而 innerHTML 用于 div, span, td 等其他元素。总之切记 表单元素别用 innerHTML！\\n\\n## 回归静态与CGI by23.01\\n\\n因为外网穿透失灵兼PHP程序不知为何不能用，从22年10月断断续续改了多次，开始用sdf提供的web服务，做成用lua动态渲染markdown，但访问速度实在太慢。后来知道了frp还是决定用回自己的主机，但免费的frp偶尔会断，加上lua渲染不支持表格，干脆用python预生成HTML回归纯静态展示，还能部署到github page，对主机没有要求。动态部分只保留CGI编辑，支持电脑和手机端多端同步。\\n\\n## 纯静态且支持搜索 by24.05\\n\\n最近玩客云硬件不能用，迁移的手机功能非常受限，编辑后的文件上传sdf非常痛苦。又怀念起全静态部署的好处来。加上以前曾开发过mytid但过于忧虑流量没有用起来。\\n\\n前提和假设\\n\\n1. 公开的博客，纯静态html部署（不一定是单文件）\\n2. 私有的笔记，基于数据库的CGI接口，通过电脑或手机编辑\\n3. 依赖尽可能少\\n\\n实现路径\\n\\n1. 博客内容基于md维护，通过mytid脚本转html，同步到公开的代码仓库\\n2. 闪念笔记，保存在1个数据库，通过电脑或CGI编辑\\n3. 静态服务： frp+busybox 尽可能低门槛；CGI：pb 只要有编译器，依赖也比较少；生产端： python3+markdown\\n"}'));jctx.push(JSON.parse('{"id": "190506", "tag": "security", "text": "# 对称加密实践\\n\\n所有对称加密的核心是XOR运算，因为XOR运算有一个非常神奇的特性A\\\\*B\\\\*B=A。也就是说A与B进行XOR运算之后的结果再和B运算就能复原A。A是明文，B是密钥，就是所有对称加密的基础。主流的AES采用块式加密，每次固定加密128位，密钥不能短于块长度（奇怪的是DES的密钥比块要短），当原文比块要长时，显然要迭代进行，如何迭代就分化出ECB，CBC，GCM等众多模式，而AES我的理解是如何把加密块和密钥进行XOR的方式，两者的阶段不同，所以合称AES-GCM。\\n\\n## AES填充\\n\\n* PKCS5 : java原生和PHP的默认行为\\n* PKCS7 : java需要导入bouncy包，PHP的`OPENSSL_RAW_DATA`\\n\\n这两种按文档说明是没有差别的，实测下来不同的pad的输出大部分一样，但有差异。而且解密时如果选错pad会解密失败。\\n\\n## AEAD\\n\\n全称Authenticated Encryption with Associated Data。是一种同时具备保密性，完整性和可认证性的加密形式。\\n\\nAEAD 产生的原因很简单，单纯的对称加密算法，其解密步骤是无法确认密钥是否正确的。也就是说，加密后的数据可以用任何密钥执行解密运算，得到一组疑似原始数据，而不知道密钥是否是正确的，也不知道解密出来的原始数据是否正确。因此，需要在单纯的加密算法之上，加上一层验证手段，来确认解密步骤是否正确。\\n\\nAEAD的实现方式可以是单纯的CBC和SHA1组合而成，也可以是AES-GCM，AES-CCM，chacha20-poly1305（chacha对称加密，poly是MAC验证）等直接完成。TLS1.2引入AEAD后，1.3就只允许这种算法了，可见安全界的认可。\\n\\nGCM本质上是AES的CTR模式加上GMAC（又叫GHASH）进行哈希计算的一种组合模式。GCM来自于AES的CTR模式，CTR是指计数器模式。GCM是利用GMAC（基于伽罗华域的MAC）和AES的CTR模式的组合。GMAC比普通的MAC算法快（毕竟冠以伽罗华之名），GCM模式与CBC的一个最大的区别是GCM模式不再把上一个数据块的计算结果输入到下一个数据块的计算，而是在分好的数据块中任意位置开始计算，由一个计数器和一个不变的IV值（nounce）来控制每一次计算的随机性。由于下一次的计算并不依赖于上一次的结果，所以GCM模式可以实现大规模的并行化，并且Intel还专门推出了clmul指令用于加速GCM的运算速度，可见其应用之广。纯软实现的chacha比aes有4倍的优势，但随着硬件指令加持AES-GCM有一统天下的趋势，也确定了AEAD的演进方向。\\n\\nGCM是一种加密范式，不是一种特定的加密算法，在AES中可以应用GCM范式，在Camellia中也可以。除了这种范式外，CCM是另一种广泛应用在Wi-Fi上的范式。"}'));jctx.push(JSON.parse('{"id": "190510", "tag": "book", "text": "# 黎塞留的反面\\n\\n黎塞留这个人今天有点被神化了，神化他的原因我就不说了。我想谈谈黎塞留这个人。\\n\\n黎塞留这个人能够成功一大半功劳应该归路易十三。他和他的国王之间其实是一种非常独特的“君臣相得”的关系。说它特殊就在于黎塞留干的所有的事，都是符合国王利益的。他参加三十年战争也好，对贵族大开杀戒也好，其实都是国王乐见其成的。但是贵族跟国王的关系盘根错节，波旁王朝已经两代了，贵族造反国王镇压，但是除了少数，比如挡了国王道的孔契尼一家，没有谁是国王真的杀掉的。不但不杀国王还会派人跟你谈谈心，你没事造什么反呢？是不是生活上有困难啊？我给你点钱或者给你个官吧！都是自己人下次别闹了啊。这是好不容易爬上王位，而且还有新教徒的黑历史的波旁王朝的一种特殊的“待人以宽”和“收买人心”。\\n\\n所以杀贵族这种事国王想不想干，肯定想！舍不舍得杀么？多半也真舍得杀。但国王不想背锅，那谁合适呢？黎塞留咯！路易十三一看到他杀人就痛心疾首，就说“你怎么这么残忍？”“你还是不是人？”说完国王该吃吃该喝喝。旁观的人恨透了黎塞留，去找国王说我们想干死黎塞留，国王就表示好啊！去吧朕支持你们！然后黎塞留把这些人的头送给国王，国王依然该吃吃该喝喝。\\n\\n比如浪漫派的作家维尼写过一本小说叫《桑马尔斯》，讲的就是这个离开宠臣就活不下去的国王，鼓励他的宠臣桑马尔斯去反对黎塞留，结果黎塞留派人用银盘子把桑马尔斯的头送给路易十三。路易十三看完之后说了一句话“我们的朋友今天看起来是多么苍白啊！”如果你联系到国王和他的红衣主教之间亦敌亦友的关系，这句话就更操蛋了。\\n\\n路易十三很希望有黎塞留这样的人替他干脏活，但黎塞留干的脏活有时候也确实让路易十三接受不了，所以路易十三很愿意看到另一个更有能耐的黎塞留替他把红公爵给干死。可假如大家都玩不过红公爵，那红公爵也不错，脏活终究得有人干。\\n\\n法国近代政治的真正游戏规则，不是政治学，不是料事如神，而是君主的喜怒。路易十三看你胡闹哈哈大笑，你就十足的道德。国王把你一脚踢出去，或者坐在宝座上喊“卫兵”，不管你干了什么你都十足的罪该万死。这是黎塞留和塔列朗这一系列人和他们的欧洲同行尤其是俾斯麦之间的本质区别。俾斯麦面对的是一个已经老了的威廉一世，他背后还有一个议会和一个内阁，普鲁士是一个多少讲点法的地方。所以俾斯麦不用担心推开国王的门就被人十几个国王的小哥们乱刀捅死。\\n\\n但黎塞留每次独身一人去见国王的时候恐怕都会默默的想想吉斯公爵。因为吉斯公爵就是在自己又有钱又有枪还有人民的支持的时候被国王的哥们们捅死的。而且捅吉斯公爵这事跟黎塞留他爸爸就有关系。他爸爸就是亨利三世的宠臣，肯定对这事完全知情。伴君如伴虎这话在法国真不是闹着玩的。\\n\\n所以法国旧制度时期的政治家往往都有近代政治下身上所没有的一种亡命徒的特质。或者说是一种发自内心的男子气概。黎塞留穿着小丑衣服去跳萨拉班德舞这种事，俾斯麦是干不出来的。原因在于俾斯麦不需要这么干。而黎塞留和瘸子塔列朗就需要这么干。\\n\\n国王的宫廷是一个舞台，国王是政治的核心，政治利益的算计和取舍人人都会。换句话说如果俾斯麦这样的政治家出现在路易十三的宫廷里他活不过第一季就得完蛋。因为他会的东西人人都会。但是黎塞留会的俾斯麦不会。黎塞留自己就是亡命徒的儿子，他杀人如麻树敌无数，但为什么他不怕？因为他是替国王办事？错了因为国王明白他在干什么，但是除了国王人人都觉得是他在杀人，而不是他替国王在杀人。\\n\\n所以黎塞留知道自己是不可替代的，但这还不够。黎塞留要在宫廷这个舞台上保持曝光率，必须始终让国王对自己有新鲜感。这是他成功的真正秘诀。他是一个真正的演员，能够让国王时刻得到新鲜感。在黎塞留这个人身上体现的就是16世纪、17世纪宫廷的游戏规则。\\n\\n一个人会办事懂政治是必要的，但光会这些还不够，他还要学会怎么让国王一方面把权力交到自己手里一方面又不用害怕自己会威胁到他。同时还不能让国王对自己感到厌烦，否则总有一天国王会把他一脚踢进巴士底狱，然后给他杀生下的贵族一个大团圆结局。\\n\\n跟这个复杂的工作相比，三十年战争、围攻拉罗歇尔这些都是小儿科。黎塞留其实并不是什么能掐会算的半仙。相反黎塞留这个人身上最突出的就是法国西部地区穷贵族身上的那种亡命徒气息。“不服就干！”有点像今天的“大金链子哥”。从这个意义上说其实亨利四世、黎塞留、瘸子塔列朗都是这样的人，他们都有崇高的出身，有机会有门路，但没什么钱。所以必须干一票，成就成了，不成就算。\\n\\n这是每一个试图坐在办公桌后边去理解黎塞留的人都理解不了的一面。因为黎塞留就不是带套袖的那种人。黎塞留是拿生命玩宫廷的那种人。这也是为什么黎塞留其实已经对我们没有什么借鉴意义了的原因。因为黎塞留的行为的基础是法国和欧洲的绝对君主制。梅特涅那个时代还可以把外交概括为“你们的皇帝，我们的皇帝和咱俩！”四个人就把事给定了，但是今天已经没有任何一个外交大臣敢这么干了，其实连外交大臣也没有几个了。\\n"}'));jctx.push(JSON.parse('{"id": "190520", "tag": "net", "text": "# 域名和DNS的事\\n\\n自从2016年5月注册免费的DDNS域名，一直用却从未深究过其中原理。网上提供免费域名的服务商不少，几个知名的直接在路由器内嵌支持，如果不支持，通常服务商会提供客户端程序和DDNS服务器通信来达到解析效果，客户端有些从C语言编译，有些就是一行脚本。如果有一台低功率主机，也方便。\\n\\n以公云3322.org为例，不充钱的账号只能开通一个账号。而且登陆管理员的账号密码和域名保活的密码并不相同，一定要分开。\\n\\n域名的完整名称是Fully Qualified Domain Name,(FQDN)，由hostname+domain name组合而成。域名服务器并不限制FQDN，有些局域网只输入hostname也能找到服务器，这个hostname又称Partially qualified domain name。域名只能包含数字，字母和连字符(减号)。域名有顶级域名和壳域名，顶级域名有组织管理，个人要用必须要购买，而免费域名一定是壳域名，通常是公司买下顶级域名，并开放了其二级域名吸引用户去用，所以才会免费。如果有域名和静态IP，可以用dnspod.cn配置绑定。\\n\\nDNS是1985年出现的，在那之前ARPANET就有了host.txt方式记录IP和名字的对应关系，随着主机数量日渐增多，文本方式成为辅助，但仍在操作系统中存在。\\n\\n## 域名解析\\n\\n查域名函数是gethostbyname，无论是宿主机或是k8s集群，DNS解析会依赖 /etc/host.conf 、 /etc/hosts 和 /etc/resolv.conf 这三个文件，查询顺序通过/etc/nsswtich.conf控制，由solaris发明，被linux继承，以libnss库的形式存在。简单讲解一下/etc/resolv.conf配置，每行都会以一个关键字开头，然后跟配置参数。在k8s集群中主要用到的关键词有3个。\\n\\n* nameserver   #定义 DNS 服务器的 IP 地址\\n* search       #定义域名的搜索列表，当查询的域名中包含的 . 的数量少于 options.ndots 的值时，会依次匹配列表中的每个值\\n* options      #定义域名查找时的配置信息\\n\\n## DNS记录\\n\\n称为Resource Record(RR)，有如下几种类型\\n\\n* NS记录：Name Server，表示这个域名由谁来解析，通常买域名的厂商就是NS，当然也可以改成dnspod或cloudflare之类。\\n* A记录： 域名到IP的映射关系，A表示Address。如果要映射到IPv6，称为AAAA记录\\n* CNAME： 域名到域名的映射\\n* MX记录：邮件交换记录，邮件服务器会用到\\n* PTR：和A记录相反，从IP获取域名\\n\\nDNS是一棵庞大无比的树，具体实现时某一段子树往往归为一个DNS Zone。\\n\\n一个域名可以对应多条A记录，使用场景一是IP的负载均衡，二是不同运营商间智能匹配最佳线路。不过DNS不会检测IP存活，需要额外的检测和更新机制配合。\\n\\n## CNAME绑定\\n\\n比如阿里云的域名指定了CNAME到3322，就行了。但想转到github pages却不能成功，必须在pages的repo增加CNAME文件，里面写上阿里云的域名，才能实现域名跳转。\\n\\n上述虽然要双向配置，但毕竟能在浏览器直接打开。而冰雪提供的绑定CNAME只能用于绑定，直接打开显示的永远是同一个首页。可能是虚机的缘故，靠入口域名做映射，这种情况显然单向绑定是不够的。\\n\\n## WHOIS和IANA\\n\\n通过whois可以查到域名在哪个分销商注册的。全球的域名分销商都会向IANA机构注册，并被分配一个IANA数字编号，见过292-1479范围的。每个分销商通常会有多个域名解析服务器地址，数量在2-8个不等。\\n\\nWHOIS只能查到一级分销商，看不到个人或企业的详细信息。"}'));jctx.push(JSON.parse('{"id": "190524", "tag": "tool", "text": "# 远程文件传输说明\\n\\n由于安全性的关系，很多新系统默认不提供FTP功能，要交互文件就需要别的方式，好在SSH整合了SFTP子系统。不用额外启动守护，只要`sshd_config`配置中增加一项`Subsystem  sftp  /bin/sftp-server`，就能使用了。要注意的是，有些发行版把sshd和sftp分成两个包，如果出现校验密码成功但连接被断开的错误，很可能要单独安装sftp。\\n\\nsftp利用SSH加密通道进行文件传输，它借用了FTP的指令，但基础是SSH加密，严格地说并不算FTP协议。\\n\\n另一种叫FTPS，类似HTTPS，本质是FTP over TLS的方式，使用的指令和FTP完全相同，不过支持的软件（服务端和客户端）都比较少。\\n\\n除了FTP模式，用scp传输文件更通用，出现过winscp用FTP和SFTP始终无法连接上，但用scp模式成功的情况。scp本身不常驻后台，监听的还是sshd，但是当外部连接到来后，sshd会调用scp完成文件传输，所以当SFTP不可用但ssh可以连上时，不妨用scp来传文件。\\n\\nscp和ssh同属一个包，但scp是基于rcp程序改写的，因此选项风格很不一样。比如指定远程端口，ssh是-p而scp是-P(大小写是反的)。指定远程用户，ssh用-l，而scp却是username@hostname:fileposition这种格式。另外scp不仅要求本机有scp，对端也必须有scp才能完成传输，否则在验证结束后，会报`sh: scp: not found`错误，之后连接就断开了(lost connection)。\\n\\n如果没有装scp，winscp可以浏览文件夹但不能复制，说明scp没有浏览命令，必须和ssh配合使用，从复制文件的角度看，scp更纯粹，当然功能也更弱，不支持断点续传。而sftp是完整的文件传输方案。有独立的浏览命令，支持断点续传。openssh实现的scp，从8.8版本开始，默认使用sftp协议，但是如果服务端不支持，也可以用`scp -O`回退到scp协议复制文件。\\n\\n如果连scp也没有，rsync -e \\"ssh -l user\\"能达到相同效果(未验证)。\\n\\n## rsync使用说明\\n\\n作为远程同步工具，支持ssh和rsync两种协议，如果是rsync协议，客户端使用`rsync -av ip::archive/img/ img`，值得一说的是`::archive`这段，::表示使用rsync协议，archive则指代服务端的一个module，可以用`rsync ip::`查看远端所有的module列表，如果有module，使用`rsync ip::modname`查看，并可递归查看mod下的文件夹。服务端先配置好/etc/rsyncd.conf后，再rsync --daemon会监听873端口。配置rsyncd.conf的module时，除了path外，如果遇到无权限问题，再加上uid=0和gid=0就可以解决。\\n\\n如果对端机器不是默认22端口的话，同步时候要加上 -e \\"ssh -p port\\"，rsync -avzP -s \\"ssh -p 22\\" /tmp/ itv@ip:/home/itv/"}'));jctx.push(JSON.parse('{"id": "190526", "tag": "protocol", "text": "# HTTP的认证方式\\n\\nHTTP初衷是定义为无状态协议，但随着使用日渐广泛，认证也纳入了RFC7235的定义。客户端如果请求一个不被允许的资源，服务端返回401或407，消息头带上WWW-Authenticate，并告知认证算法和域信息。客户端再根据这些信息，计算出一个签名，填到Authorization字段，后面用一个词表示认证算法，申请新的算法要向IANA提交申请并经IETF审核，已入标准的有Basic、Digest、Bearer、HOBA约10种。也可以是私有扩展，后面必须有一个空格，然后是签名值。如此这样交互下来，服务器才会认可这次访问是合法的。\\n\\n示例\\n\\nServer\\n\\n```\\nWWW-Authenticate: Basic Realm=XYZ\\n```\\n\\nClient\\n\\n```\\nAuthorization: Basic ABC=\\n```\\n\\n上述是服务端对客户端要求的单向认证，另外还有RFC8121双向认证，使用了离散对数或椭圆曲线算法的Key Agreement Mechanism 3机制。\\n\\n为解决SSO问题，HTTP扩展了 Negotiation 认证，也叫SPNEGO(Simple and Protected GSSAPI Negotiation Mechanism)。 Windows 支持两种 Negotiation认证方案：NTLM和Kerberos。Linux上的实现一般不支持NTLM，只支持Kerberos。\\n\\n## OAuth流程\\n\\n每个带统计或权限的应用系统，肯定会希望有用户体系，但现实是用户往往不愿意注册，这种场景下，就要依赖向另一个管理帐号的系统(简称U)请求认证，并依赖U的校验结果去鉴定用户。\\n\\n要解决的第一个问题，不能触碰用户输入密码的环节，所以U一定要提供一个完全的登陆框，但这就安全固然解决，可是登陆后要去干什么呢？所以这个登陆页的参数一定要有个callback，如果登陆成功，把cb的值用302方式回复浏览器，这时还要带一个code，表示登陆成功，这个code在一段时间内，就可以证明，用户在U系统上是存在的。\\n\\n到此，用户是否存在(真实性)的问题就解决了，如果还想知道到用户是谁，要做进一步动作。用code再一次向U的网页发起请求，用户在页面上选同意的话，返回token，最终用token去请求资源，也只有token换资源这一步，不会弹出网页。"}'));jctx.push(JSON.parse('{"id": "190528", "tag": "lang", "text": "# 批处理的用法\\n\\n## 语法篇\\n\\n### 条件判断\\n\\n字符串比较，一定要两侧加双引号。\\n\\n```\\nif \\"%1\\" == \\"\\" (\\n  command\\n) else if %1 equ 5 (\\n  command\\n)\\n```\\n\\n批处理似乎没有参数个数`$#`语法，可以用`\\"%*\\" == \\"\\"`区分没有参数的情况，但无法判断更复杂的场景\\n\\n变量捕获\\n\\n网上说通过重定向到文件再`set /P a=<xx` 方式读取回来，一则看上去不优雅，更麻烦的是前一步写入的文件在此时经常会读不到，原因不明。最好的方式还是用`for /f`语句。\\n\\n```\\nfor /f \\"delims=#\\" %%A in (\'your commad %*\') do (\\n  set VAR=%%A\\n)\\n```\\n\\n只有for的/f选项才能在SET中执行命令，否则只会当作字面量或文件名来解析，其次command要用单引号包围，其中的%参数会正常解析，最后变量一定要写两个%（只有在cmd直接输入允许一个%）。/f后面的选项可以为空，默认会按空格会Tab对内容进行切分，如果希望不切分，找一个不会在内容中出现的字符作为切分键，但无法用\\\\n，因为会被识别为\\\\和n两个字符。另外for语句支持嵌套。整个语句看下来，将输出先按行切分，再进行行内切分，值赋给一个变量，接下来用这个变量，用法有一点像awk的getline函数，甚至连选项名f都和awk一样。\\n\\n### 函数用法\\n\\n```\\ncall :add1 1 ret\\necho %ret%\\ngoto :eof\\n\\n:add1\\nset /a ret = %~1 + 1\\nset \\"%~2=%ret%\\"\\ngoto :eof\\n```\\n\\n用标签来模拟函数，但毕竟算不上函数，所以在第一个函数定义前，用goto方式结束。这也说明批处理是先编译再执行。\\n\\n这种看起来古怪的语法，原因是批处理只能按规定执行(顺序或跳转)，不具备全局哈希表，无法把一个块从执行流中摘出来。所以一定要把所有函数定义放在最后，主执行流程写在开头。\\n\\n这种做法能行得通，多亏批处理有call机制，函数执行完，能接着上一句call继续走下去。\\n\\n从中可以得知，函数最朴素的实现，便是开始标记、结束标记、执行后的返回地址。和汇编指令没有区别。\\n\\n从命令行交互使用set /p var=[prompt]方式，之后用%var%就能得到用户输入。\\n\\n### 特殊命令\\n\\n* cd /d xx: 如果不带/d，切换路径不能换盘\\n* start: 类似fork，会新开窗口，不阻塞当前脚本继续执行。也可以用/wait选项等待\\n* exit /b: 退出函数，但不关闭cmd窗口\\n\\n### 误区\\n\\n* echo后面的双引号和单引号，也会被输出，所以不要写\\n* sed对中文处理有异常，但也可能是sed版本原因\\n* 批处理内调另一个批处理命令，必须用call，不能直接调\\n\\n### 嵌入其它脚本\\n\\n通用法\\n\\n1. @more +1 %~f0 | script_engine & exit /b   # 一行代码，利用more打印第2行以后内容，缺点是不能传参，但可以交互式\\n\\n适用于python\\n\\n1. @SETLOCAL ENABLEDELAYEDEXPANSION & python -x \\"%~f0\\" %*  # 利用了-x选项来跳过第1行，如果语言支持同样功能也可以。甚至我感觉前面的SETLOCAL都没用\\n1. 不是一行式，且比较难懂，由于这段代码同时符合bat和py，技巧上很高明，但实用价值没有上一条高\\n\\n```\\n1>2# : ^\\n\'\'\'\\n@echo off\\npython \\"%~f0\\" %*\\nexit /b\\nrem ^\\n\'\'\'\\nimport os\\nimport sys\\n1. python code to compute the time elapsed\\nprint(sys.argv)\\n```\\n\\n## 用法示例\\n\\nruby的gem.bat写成这样 `ruby.bat \\"%~dpn0\\" %*`\\n\\n%在windows批处理中相当于shell中的$表示变量，\\\\~是必要的前缀否则会把后面的dpn当成变量名，有了\\\\~以后dpn就可以各自表示对应的意思。有一系列的修饰符，d表示盘符，p表示路径，n表示文件名，x表示扩展名，详细文档可以用for /?看到。还原到上面这个例子%~dp指向gem所在的路径，n就对应了gem(没有扩展名，也不需要)。整句话解释下来，就是ruby.bat gem %*。而gem刚好是ruby的源文件，因此gem就被执行到了。\\n\\n`%~dp0`符号分开解读。最初的原型是函数参数引用语法，`%~0`的%后面\\\\~符加数字，表示对变量参照进行扩展替换，等于$0，代表执行命令本身。利用`%~dp0`可以实现一个小技巧，一个文件夹下有a.exe文件，想利用批处理调用它，又想这个批处理能做到可迁移，写作`%~dp0\\\\a.exe`就能达到此效果。\\n\\n## 与Windows上其它功能的联动\\n\\n### WSH和COM\\n\\nWSH的全称是Windows Script Host，win95时代研发，win98起成为标配的自动化工具。对应cscript.exe和wscript.exe两个Host程序，但这俩只是壳，最终要根据脚本的后缀加载不同的dll。比如.js就加载jscript.dll，官方只有vbs和js，如果安装了ActivePerl这类包可以加载perl.dll并用perl语法写脚本。\\n\\n随着微软自身的演进，WSH还封装了COM技术，从OLE1.0 -> COM OLE2.0 ActiveX。比如在js中用new ActiveXObject可以获取COM对像，进而操作宿主中的Office对象，这也体现了COM底座的价值。\\n\\nWSH环境自带了14个对象，而Wscript则是root对象，其它对象都要通过Wscript.CreateObject()才能实例化。有4个一级对象\\n\\n* WshShell: 主要负责程序的本地运行, 处理注册表项, 创建快捷方式, 获取系统文件夹信息, 处理环境变量等，存在wshom.ocx文件，通过CreateObject(\\"Wscript.Shell\\")得到，该对象的Run方法可以执行命令\\n* WshArguments: 作用是获取全部的命令行变量\\n* WshNetwork: 作用是开放或关闭网络共享, 连接或断开网络打印机, 映射或取消网络中的共享, 获取当前登陆用户的信息\\n* WshController: 创建一个远程脚本对象\\n\\n### 图形化\\n\\n利用hta方式，实现所有平台的图形化开发一致。加上hta可以利用WScript，于是就打通了和批处理的双向调用，示例如下\\n\\n```\\n// bat_file: 和hta同目录的批处理文件，返回运行结果\\nfunction popen(bat_file){\\n\\tvar ws = new ActiveXObject(\\"WScript.Shell\\");\\n\\tvar s_name = document.location.pathname;\\n\\tvar pos = s_name.lastIndexOf(\\"\\\\\\\\\\")\\n\\tvar ro = ws.exec(s_name.substring(0, pos+1)+bat_file);\\n\\treturn ro.stdout.readall()\\n}\\n```"}'));jctx.push(JSON.parse('{"id": "190601", "tag": "lang", "text": "# Lisp的语法真的是括号吗\\n\\n1. Common Lisp 己经有 package 和 gensym 两个机制防变量捕捉，除了麻煩点并无硬伤，且有向旧的 Lisp Machine Lisp 等兼容的考量。\\n\\n2. 提 hygienic macro 的，无非说的是这个，也是 Scheme 用的那个 sytanx\\n\\nThe original algorithm (KFFD algorithm) for a hygienic macro system was presented by Kohlbecker\\n\\n先加点私货说 Scheme，先学 Scheme 的大多有个通病，老是想著用 list，因為 R6RS 里并沒有 struct 嘛，毕竟搞理论的人用的。用 struct 有什么好的呢？或者说以实用标榜自已的 CL 有什么高见吗？ Lisp Machine Manual 有讲：\\n\\n*The contract from ship to its callers only speaks about what happens if the caller calls these functions. The contract makes no guarantees at all about what would happen if the caller were to start poking around on his own using aref. A caller who does so is in error;*\\n\\nCL 的核心是 CLOS，在 OOP 中，object 是有 contract 的，尽管一个 object 本质可能是个 array or list，但还是要用 contract 提供的 accessor，用 nth or aref 就是 violation。这就是 CL 和 Scheme 的思想区別了。\\n\\n学 Lisp，尤其 CL 要有一个概念牢記，我们写的 (defun foo (x) ...) 等等，都不是表达式，而是由 reader 读成名为 list 的数据结构，编绎器直接 compile 的是数据结构。实际上数据结构是不是真的 list 都不重要，只要 hack 下 eval，用 array 以致 class 表示代码都可以。CL macro 的思想，就是直接通过语言自身处理因为灵活性可能出現的各种数据结构。可能这个只有熟練 CL 了以后才能体会，但我以為，這就是 CL 所代表的 Lisp 本貭。在进一步，以後写 CL 都不需要用文本，代码項目直接保存为数据结构。\\n\\n而 Scheme 的 syntax，就有了个 assumption，就是代碼只能是 List，只能限于 S-exp，不然就要 heavily hack 它的 syntax 的系統，而在 CL 中一用 defstruct 各種 handler 就定义好了，不用特別为用 macro 实現个什麼東西。同理其他比如 Rust Clojure 的 hygienic macro，都用的是 pattern match，包括 Scheme 在內，它們在设计時都还停留把代碼當表达式的层次。\\n"}'));jctx.push(JSON.parse('{"id": "190607", "tag": "tool", "text": "# 网页链接\\n\\nOCaml和SML比较\\nhttp://adam.chlipala.net/mlcomp/\\n\\n目前还在使用中的 Standard ML 实现有4个：经典的 SML/NJ（只有32位版本）、Moscow ML、Poly/ML 和 MLton。其中 SML/NJ 的地位相当于参考实现和标准库，其他所有实现都向它看齐。Moscow ML 的性能比较差，但功能丰富；Poly/ML 性能高，主要用来编译定理证明器；MLton 性能最高但没有交互界面。 \u200b\u200b\u200b\\n\\nPython字节码\\nhttp://knuth.luther.edu/~leekent/CoCo/\\n\\nLispMachineManual\\nhttp://hanshuebner.github.io/lmman/frontpage.html\\n\\n从错误提示学Rust\\nhttps://rust-unofficial.github.io/too-many-lists/index.html\\n\\n编译器课程\\nhttps://www.cis.upenn.edu/~cis341/current/\\n\\nhttp://existentialtype.wordpress.com/2011/03/19/dynamic-languages-are-static-languages/\\n\\n## 收藏夹\\n\\n[vim教程](https://github.com/vim-china/hello-vim)\\n\\nhttp://tushare.org/\\n\\nhttps://plfa.github.io/\\n\\nhttps://coq-zh.github.io/SF-zh/plf-current/toc.html\\n\\nhttps://bartoszmilewski.com/2014/10/28/category-theory-for-programmers-the-preface/\\n\\n2017学区 https://www.19lou.com/forum-263-thread-6631457491565752-1-1.html\\n\\n初中学区 https://www.19lou.com/forum-15-thread-7011427707348977-1-1.html\\n\\nhttp://weakyon.com/"}'));jctx.push(JSON.parse('{"id": "190613", "tag": "tool", "text": "# TeX学习笔记\\n\\n到现在TeX还有价值的至少有3块\\n\\n1. box-and-glue model\\n1. hyphenation algorithm\\n1. line-breaking algorithm\\n\\n要分清几个概念\\n\\n* 引擎: 执行程序，用得最多的是 pdftex(越南人写的)，最近比较新的有 xetex, luatex，这些都符合TeX标准。\\n* 格式: 后缀 .fmt，是一组经常用的宏包，往往编译后把内存的dump出来，下次直接加载减少启动时间\\n* 宏包: 文本格式的宏指令集，没到通用的程度，但各种类型的文档多少会用到\\n* 编辑器: 比如WinEdt之类包装引擎的输入工具\\n\\ntexlive包含的文件至少8000个以上，为了快速寻找文件，引入kpathsearch库，依赖 texmf.cnf 文件。\\n\\nTeX本身很基础，所有的功能都依赖宏包。文件分为三类：run files, doc files, src files。其中 run files 是编译时使用的文件（包括宏包的 .sty, .cls 等，字体的 .tfm, .pfb 等）；doc files 是说明文档；src files 是源代码（如宏包的 .dtx-生成文档, .ins-真正的代码 等，字体的 .mf 文件等）。文档和源代码部分在安装 TeX Live 的时候是可以选择不安装以节省空间的。\\n\\n记录一个网上看到的问题，常见于「插图」，一些宏包（比如 hyperref 和 geometry）也有影响。不同的生成 PDF 文件的路径，会用到不同的工具（我们称之为「驱动」）。这里给一个简单的列表：\\n\\n* DVI - PS - PDF：LaTeX -> dvips -> ps2pdf，要用到 dvips 这个驱动\\n* DVI - PDF: LaTeX -> DVIPDFMx，要用到 DVIPDFMx 这个驱动PDF (Directly): \\n* pdfLaTeX，驱动就是它自己（pdfTeX）\\n* xDV - PDF: XeLaTeX -> xDVIPDFMx，驱动是 xDVIPDFMx（默认自动调用）\\n\\n常见的编译方式，至少涉及到 dvips、DVIPDFMx、pdfTeX、xDVIPDFMx 四种驱动。这四种驱动对插图、PDF 书签、页面纸张大小等内容进行处理的时候，语法有细微的差别。为了让驱动正常工作，在 (pdf/Xe)LaTeX 编译的时候，就必须让相应的宏包按照驱动的要求工作。\\n\\n现在的问题是，宏包怎么知道应当怎么工作？如果你有注意到，就会发现，对于 pdfLaTeX 和 XeLaTeX 来说，能使用的驱动就只有一种情况；但是对于 LaTeX 来说，可以选择 dvips 和 DVIPDFMx 两种驱动。因此，如果用户选择 pdfLaTeX 或者 XeLaTeX 编译，那么宏包是可以自己检测到的，此时不需要进行特别的设置。但是，如果用户选择 LaTeX 编译，那么宏包就不知道应该怎么工作了。为了简化代码（也由于历史原因），这些宏包在用户使用 LaTeX 编译的时候，「默认使用」dvips 这个驱动；而如果希望使用 DVIPDFMx 的话，就需要在加载宏包的时候以宏包选项的方式给出说明。\\n\\n总结一下：LaTeX - dvips：默认情况，可以不给驱动选项，也可以给驱动选项 dvipsLaTeX - DVIPDFMx：无法自动检测，必须手工给出驱动选项 dvipdfm 或者 dvipdfmx （详情查阅相应宏包文档）pdfLaTeX：可以自动检测，因此可以不给驱动选项，也可以给驱动选项 pdftexXeLaTeX：可以自动检测，因此可以不给驱动选项，也可以给驱动选项 xetex4那么什么时候会出错呢？其实很简单：当实际使用的驱动和宏包的工作模式（取决于驱动选项）不一致的时候，就会出错。比如，如果使用 \\\\usepackage[pdftex]{graphicx} 载入 graphicx 宏包，那么就只能使用 pdfLaTeX 编译。此时使用 LaTeX 或者 XeLaTeX 都会报错。又比如，如果使用 \\\\usepackage[dvipdfmx]{hyperref} 载入 hyperref 宏包，那么就只能使用 LaTeX - DVIPDFMx 的方式编译。此时使用 pdfLaTeX、XeLaTeX 或者 LaTeX - dvips 的话就会报错。更有甚者，如果是这样子：\\\\usepackage[pdftex]{graphicx}\\n\\\\usepackage[dvipdfmx]{hyperref}两个宏包使用的驱动选项不一致，那么不管怎么编译，都会报错。\\n\\n喜欢「抄代码」的新手，经常遇到这样的问题：东抄抄西抄抄，结果两个作者没商量好，写出来的代码一个需要 pdfLaTeX 编译，另一个需要 LaTeX - DVIPDFMx 编译，于是就坑死了新手。所以：代码自己写，不要抄代码。题主说 LaTeX - DVIPDFMx 方式可以正确编译。这也就是说，启用了宏包选项 dvipdfmx。这时候题主尝试用 LaTeX - dvips - ps2pdf 的方式编译，自然就会报错了。\\n"}'));jctx.push(JSON.parse('{"id": "190615", "tag": "web", "text": "# nginx工作流与模块\\n\\n## 工作流\\n\\nmaster-worker的流程如下\\n\\n![flow](/img/ngx-master-worker.jpg)\\n\\n当worker被意外终止时，master会启动一个新的，且work-id不变，保持逻辑一贯性。即使master挂掉，worker会正常工作，这也是resty的工作原理。只是worker再挂掉就没有进程拉起了。\\n\\n每次的请求都会随机分配给一个worker处理，通过 accept_mutex 指令防止惊群。这是一个加在accept上的一把互斥锁。即每个 worker 进程在执行 accept 之前都需要先获取锁，获取不到就放弃执行 accept()。有了这把锁之后，同一时刻，就只会有一个进程去 accpet()，这样就不会有惊群问题了。accept_mutex 是一个可控选项，默认打开，可以显示地关掉。\\n\\n解决这个问题还有一种办法，1.9.1版本引入套接字共享选项，listen 80 reuseport; 这种方式和accept_mutex互斥，所有worker都在监听，但不需要worker抢锁，而是由内核来分配，但需要Linux在3.9以上才支持。\\n\\n## 模块\\n\\n要对Nginx做扩展，都是在nginx.conf里通过命令调用来完成的。这些命令是归属到某个module中的。命令本身不会显式支持命名空间，\\n还是要写扩展的人按照良好的习惯对命令命名，Nginx的风格是C式的蛇式命名。但是也不一定。比如echo命令就是echo这个module，但是`content_by_lua`又属于`ngx_lua`模块，我猜大概是Nginx的作者在设计之初并没有想过有一天会这么受欢迎吧。\\n\\n从语法上看，模块至少要包含context和directives两个最核心的定义(其余版本、类型简单)。\\n比如`ngx_module_t`的context对应`ngx_http_module_t`，directives则对应`ngx_command_t`。\\n\\n以上是针对Nginx module的定义包含context和directives，还有一种http module定义，\\n主要定义的是create/init main/server/location configuration的函数定义。\\n因为每个command在运行前势必要得到其所在的上下文，对应就是上面说的configuration的创建。如果命令所在的阶段不同，定义也不一样。这些定义都是嵌套在`ngx_module_t`里的。\\n\\n## 问题排查记录\\n\\n1. 访问报403无权限: 检查目标目录权限755，nginx的启动用户root都没有问题。网页文件在root目录下，尝试移到/var目录，保持权限755终于可以访问（644仍提示无权限）\\n"}'));jctx.push(JSON.parse('{"id": "190618", "tag": "os", "text": "# 性能监测工具选项备忘\\n\\n## top\\n\\n默认显示Task数量，用 top -H 切换到线程模式，显示Thread的数量。也可以 top -H -p xxx 仅显示某进程的线程。top -a按内存使用排序。\\n\\n## ps\\n\\n-T或-L 看到线程，又叫 lwp 或 spid 或 tid。默认不建议启用，只在确定某个进程有问题，且存在多个线程时，再打开线程观察，要注意的是打开线程时，内存占用是一样的（因为共享），CPU占用要加总。默认查看/proc目录时，用getdents(2)，并不显示线程。 -o %cpu= 只看cpu占用\\n\\n## pstree\\n\\n-p才显示进程号，似乎内容也会变多\\n\\n## strace\\n\\nstrace的原理是先给目标进程发暂停信号，attach上去后再发SIGCONT信号，所以开始时会显示 `restart_syscall(< resuming interrupted nanosleep >)`\\n\\n系统级别的进程用strace观察多线程的始末是个很好的方式，trace内容定向到stderr，大概是不想影响被观察程序的正常输出吧。多线程的主线程join的系统调用对应的是futex，这个动作会提示unfinished，直到所有子线程退出，退出时子线程会调用futex(FUTEX_WAKE_PRIVATE)，主线程的futex才会resume。\\n\\nLinux x86_64的ABI要求系统调用至多只能接受6个参数，strace跟踪的参数列表是有限的。\\n\\n同步的进程间通过mmap共享一段内存，futex变量就位于这段共享 的内存中且操作是原子的，当进程尝试进入互斥区或者退出互斥区的时候，先去查看共享内存中的futex变量，如果没有竞争发生，则只修改futex,而不用再执行系统调用了。如果futex变量告诉进程有竞争发生，则执行系统调用去完成相应的处理(wait 或者 wake up)。\\n\\n所有逻辑结束后，主线程会close 012三个默认句柄，munmap内存，最终exit_group退出进程组结束整个程序。\\n\\n常用选项\\n\\n* -c : 以统计形式(理解为Group By)显示哪个系统调用耗时，一般用于排查一次性任务，还可以和-S配合结果显示时的顺序\\n* -s 128 : 默认打印输出字符串的前32个字符（文件名不属于字符串），此选项打印更多字符\\n* -vT : v打印环境变量和结构体等更多信息，T打印syscall的耗时\\n* -f : 默认只跟踪进程，此选项追踪线程\\n* -t : 显示每条调用的发生时刻，可以tt甚至ttt，提升精度\\n* -e expr : -e trace=!file,process,network,signal,ipc,memory 只跟踪某类系统调用，反向时记得用backslash修饰!\\n\\n## ltrace\\n\\n跟踪动态库调用，默认输出很少，可以用-S打印系统调用，不过速度比strace慢\\n\\n## pidstat\\n\\n* -u显示的%wait表示 得不到运行的时长/期望运行的时长。比如2核机器运行8个任务，等待率是75%\\n* -w显示上下文切换，包括自愿和非自愿。说明内存或CPU存在瓶颈\\n\\n## time\\n\\n既有bash内建也有独立命令，一般用bash内建的time -p输出POSIX格式时间。real包括CPU和IO的所有耗时，等于秒表计时时间，而user和sys都只代表CPU时间且多核会一并计入，所以对多核优化得好的程序，会出现`real<user+sys`的情况。在`/proc/<pid>/stat`文件的14和15列分别表示进程运行在用户态和内核态的tick周期数，tick代表多少时间不是固定，大多数是10ms，可以用以下程序测出来。\\n\\n```\\n#include <signal.h>\\n#include <unistd.h>\\n#include <stdio.h>\\n#include <stdlib.h>\\n#include <string.h>\\n#include <sys/time.h>\\n\\n#define USECREQ 100000\\n#define LOOPS 3\\n\\nchar cmd[64];\\n\\nvoid event_handler(int signum)\\n{\\n    static unsigned long cnt = 0;\\n    cnt++;\\n    if (cnt >= LOOPS)\\n    {\\n        system(cmd);\\n        exit(0);\\n    }\\n}\\n\\nint main(int argc, char **argv)\\n{\\n    struct sigaction sa;\\n    struct itimerval timer;\\n    int pid;\\n    pid = getpid();\\n    sprintf(cmd, \\"cat /proc/%d/stat\\", pid);\\n    memset(&sa, 0, sizeof(sa));\\n    sa.sa_handler = &event_handler;\\n    sigaction(SIGVTALRM, &sa, NULL);//SIGALRM\\n    timer.it_value.tv_sec = 0;\\n    timer.it_value.tv_usec = USECREQ;  // timer can\'t precise to 1us, let it be normal\\n    timer.it_interval.tv_sec = 0;\\n    timer.it_interval.tv_usec = USECREQ;\\n    setitimer(ITIMER_VIRTUAL , &timer, NULL);//REAL\\n    while (1) ;\\n}\\n```\\n\\n原理就是利用while(1)让进程跑满用户态，同时再用setitimer机制让程序在固定时间后退出，计算用户态运行时间除以tick，就能得出tick代表的真实值。但是有一点要注意，定时周期似乎不能小于tick本身，否则程序运行时间会比期望时间长，可能是itimer定时器的精度问题，计算得到的tick值误差也会更大，但大体还是准的。\\n"}'));jctx.push(JSON.parse('{"id": "190620", "tag": "tool", "text": "# 编辑器的扩展机制\\n\\n如今的编辑器没有插件机制都不好意思出来见人，像Emacs，所有的操作都可以对应函数，再用Elisp把已有的函数和数据结合起来，本体和扩展混然一体，非常流畅。什么是真正好的机制？\\n\\n## notepad++的插件机制\\n\\nnotepad++插件很多，执行程序集成了scintilla库，另外还有个独立的SciLexer.dll库，做词法分析。原理是dll开发，一定要实现5个函数，另外有个isUnicode选择实现，一般是返回TRUE就好。这5个函数说明如下\\n\\n1. getName : 给插件选个好名字，不需要和dll名相同，在插件菜单就靠这个名字找插件\\n1. setInfo : 初始化阶段会被npp调用，传入3个句柄，分别是npp本身，scintilla的main和second handle(分别对应编辑区的两个视图)\\n1. getFuncsArray : 在setInfo之后被npp调用，获取这个插件的条目，因为功能可能依赖setInfo传入的句柄，所以时序上严格晚于setInfo，返回条目数量和函数指针\\n1. beNotified : 产生npp专属事件时会回调\\n1. messageProc : 通用的windows消息回调\\n\\n通过记录宏发现端倪。npp的操作对应的是消息，利用记录宏保存在shortcut.xml文件的信息，就可以反窥出这个动作要怎么表示，再在插件中发起这个消息，也可以达到融合的效果。这是一个宏的记录\\n\\n```\\n<Macro name=\\"Trim Trailing and save\\" Ctrl=\\"no\\" Alt=\\"yes\\" Shift=\\"yes\\" Key=\\"83\\">\\n    <Action type=\\"1\\" message=\\"2170\\" wParam=\\"0\\" lParam=\\"0\\" sParam=\\" \\" />\\n</Macro>\\n```\\n\\n猜测action type 0 is for Scintilla commands with numerical params, type 1 is for commands with string parameter, 2 is for Notepad++ commands.\\n\\n### npp的脚本化插件\\n\\n如果只能开发dll插件成本还是太高，LuaScript提供SendEditor/MenuCommand等函数，可以发送所有的SCI消息给编辑器，消息的枚举要查看scintilla.iface。或者执行菜单命令，具备了相当程度的整合能力。\\n\\n## EditPlus的扩展机制\\n\\n不提供内嵌语言方式的扩展，只能通过filter钩子来实现一些基于文本的动作，可以替换也可以执行一些其它指令，但不能获取到编辑器的内部状态，因此觉得算不上插件，但也算是一种很简便的和外部程序的协同。\\n\\nfilter的原理是逐行从stdin读入，处理后写到stdout，写出的内容按指令替换或打开新的文本。\\n\\n## 一些小众编辑器\\n\\n也许工作中不会用到这些编辑器，但是看到有趣就记录下来。\\n\\njed，取名是作者名字的3个字母，扩展语言称为SLang。快捷键默认和emacs一样，记住ctrl X ctrl C退出，Alt X执行命令。如果在site.sl中加载vi.sl插件，再执行`command_mode`命令，就能用反引号（注意不是ESC键）进入vi模式。\\n\\njasppa，一个MicroEmacs的发布版。\\n\\nvile，全名是vi like emacs，非常轻量似乎也有扩展模式。\\n\\n要具备IDE功能的编辑器是越来越难，具备语义的自动补全，跳转和跳回，和编译链的结合性。只有深厚积淀的编辑器才能承载前行。"}'));jctx.push(JSON.parse('{"id": "190621", "tag": "tool", "text": "# 编辑器内部细节\\n\\n大致分为源代码编辑器和富文本两种.\\n\\n源代码编辑器为了省事可以设置相同的行高方便计算, 不过现在多数支持变化行高了可以从富文本编辑器开始做.\\n\\n首先, 挑一个 GUI 框架\\n\\n跨平台的 GUI 通常很吸引人, 例如 Fox, FLTK, Tk, GTK+, Qt, WxWidgets 等, 大部分都有一个编辑源代码的控件, 而这个控件基本是 Scintilla 之上的包装 (再研究 Scintilla 你会发现其实各种 GUI 框架的编程模型包装都不需要, 按照 Scintilla 的设计去用就可以了). 学习下来你会发现各个 GUI 框架都自带一个特别的观感: Fox 的光标是个不可改变的巨型铁轨截面, wxWidgets 尽量模仿原生组件 (E-texteditor 就是用 wxWidgets 做的), GTK 就尽量自己画... 其编程模式实质差异并不大, 因为都是 C 和 C++ ... 最惨的是在 Windows 看着还可以, 一放到 Mac 就觉得丑爆了. 做了其他语言的绑定还是感觉在写 C 和 C++. 当然也有做得不一样的:\\nTcl/Tk 最简洁\\nREBOL view 最 fancy\\nPaul Graham 最推崇 Arc\\n\\n另一大类 GUI 框架是 XUL. 写个 XML 界面, 然后在 XML 界面上画东西. XHTML+JavaScript 就是一种 XUL 方案. Sun, 很小很柔软, 摸斯拉 等等大公司都推过自家的 XUL 方案. 然而 XML 根本就不适合人类编写, 作为 model 格式也过于巨大不好维护. 最初魔兽世界的插件也是推荐 XML 写界面然后绑定 lua 的动作, 但由于太不灵活也没有一个拖控件的界面, 所以玩家开发了 Ace 系列的 UI lib, 完全不用 XML 纯用 lua 写了. 拖拽式画界面只能骗骗小朋友, PaintCode 也比 XML 解释器性能更好, 所以现在 XUL 基本绝迹, 连直接用 HTML 写界面都不时髦了.\\n\\n如果不跨平台, 用图形操作系统的 GUI 框架会更能解决很多实际问题, 性能也有保证. Win32API, MFC, ATL, WinForms, WPF, Carbon, Cocoa, CGContext, CoreText ... 就是操作系统商人心狠手辣变幻无常, 一心搞个大新闻还处处夹带私货, 一路学来也是挺累人的. 另一方面嘛 X11 这种更难学, 我就卡在了 motif ...\\n\\n虽然跨平台的 GUI 框架在慢慢衰亡, 但 OpenGL 这类更接近底层硬件的图形库给人类提供了新的希望. 利用 OpenGL 的成功案例就有 Sublime Text. 我觉得 Cairo, SDL 这种半 GUI 框架的高性能图形库是比较适合的, 就是用的人少了点.\\n\\n鉴于图形化界面的巨坑... 何不写个纯命令行的编辑器呢? 这时候我们有各种行编辑库可以用: readline, libedit, termcap, Antirez 的轻量 linenoise ... 再用脚本语言的话, 由于内建正则语法和一些字符串处理函数, 很容易在一两万行内写个功能齐全的编辑器解决战斗, 例如 Daikonos.\\n\\n就算用 C, 如果只实现最简单的功能, 1024 行以内也是可以的: Writing an editor in less than 1000 lines of code, just for fun\\n\\n纯字符界面缺点也很多, 平滑滚动没有, 动画高亮没有, 文字显示揪细点想调个 kerning 啊 ligature 啊也没办法. 那就自己做一个图形框架? Eclipse 就自掘巨坑组合 C++ 和 Awt 搞出个 SWT. 其实 Awt 和 Swing (NetBeans, IntJ 都是基于 Swing) 处理 Unicode 都有大量的坑, 我都不喜欢... 曾经有个我关注的编辑器 Redcar, 最初用 GTK 编写, 后来转成了 Swing, 然后逐渐就做不动了... jEdit 作者弃编辑器坑, 后来挖了个基于栈的语言新坑 Factor. 后来? 后来也不搞了...\\n\\n现在 GUI 基本被 ES 的大流统治. 用 Web 做编辑器可以做出一些非常棒的用户体验, 现在浏览器引擎也优化得比几年前好太多. Atom, Monaco Code Editor 都是在 Web 上做的成功案例. 为了容易上手估计 ES 是首选. 缺点是某些细的 UX 不好实现, 正经的优化会花掉更多时间 (例如 Monaco 为了分析性能点连 IR Hydra 都用上了).\\n\\n介绍两个 Helloworld, GUI 框架 + Scintilla 实现常见一个编辑框\\n基于 FxRuby 的:\\n\\nrequire \'fox16\'\\n\\ninclude Fox\\n\\napp = FXApp.new\\nwindow = FXMainWindow.new app,\\n  \\"My Editor\\",\\n  nil, nil, DECOR_ALL, 100, 100, 710, 550\\n\\nsci = FXScintilla.new window,\\n  nil, 0, LAYOUT_FILL_X|LAYOUT_FILL_Y\\n\\napp.create\\nwindow.show\\napp.run\\n\\n基于我自己写的 GUI 框架的就更简单了 (谁不年少轻狂造过几个 GUI 框架轮子?)\\n\\nrequire \'cici\'\\napp = Cici.app \'scintilla\'\\nc = app.paint [600, 600], Cici::ZoomLayout\\nc.scintilla [500, 500]\\napp.message_loop\\n\\n其实还有各种 GUI 框架的编辑器 hello world 都差不多, 但用框架就是跟着别人走, 很难做出更好的用户体验.\\n\\n如果从更底层点的地方开始, 例如 Win32API 和 Carbon, 站稳脚跟学习图形界面编程, 前面的道路会... 更狭窄 (公司刚裁了很多桌面程序员并对 Web 产品加大投入...). 不过你理解事件模型的实现和常见优化手段以后, 就算编辑器不成功, 也可以自己写个游戏引擎玩玩嘛.\\n\\n然后, 挑一个 text storage 数据结构\\n\\n例如 Cocoa 就自己提供了一个 NSTextStorage, 自己造大约有几个主流选项:\\n\\nGap buffer: 例子有 Emacs. 很简单的数据结构, 光标前一个 buffer, 光标后一个 buffer. 能极大的减少 buffer 重新分配次数. 扩展一下变成 multi-gap buffer, 多光标编辑也很流畅.\\nChain of lines: 例子有 TextMate. 每行一个 buffer, 一行不拆散. 对压缩的文件高亮时会比较卡. 但是可以和功能强大的正则引擎 Oniguruma 完美集成.\\nCell buffer: 例子有 Scintilla. Cell 大小固定, 如果一行超出 Cell 的固定大小, 就分拆成多个 Cell. 用过 Scite 或者 Code::Blocks 或者 Notepad++ 等会发现, 打开大文件, 高亮都还流畅, 因为 Scintilla 的 Cell buffer 和重绘计算的效率很高. 但由于拆行, 只能集成 input driven 的功能较弱的正则引擎或者 lexer, 而这会对实现很多功能带来麻烦.\\nZipper: Immutable 的数据结构, 如果用 Haskell 做后端会非常适合. 同时还能顺便实现树形历史.\\n"}'));jctx.push(JSON.parse('{"id": "190623", "tag": "os", "text": "# perf使用\\n\\n包含二十多个命令的合集入口\\n\\n序号\\t命令\\t作用\\n1.\\tannotate\\t解析perf record生成的perf.data文件，显示被注释的代码。\\n2.\\tarchive\\t根据数据文件记录的build-id，将所有被采样到的elf文件打包。利用此压缩包，可以再任何机器上分析数据文件中记录的采样数据。\\n3.\\tbench\\tperf中内置的benchmark，目前包括两套针对调度器和内存管理子系统的benchmark。\\n4.\\tbuildid-cache\\t管理perf的buildid缓存，每个elf文件都有一个独一无二的buildid。buildid被perf用来关联性能数据与elf文件。\\n5.\\tbuildid-list\\t列出数据文件中记录的所有buildid。\\n6.\\tdiff\\t对比两个数据文件的差异。能够给出每个符号（函数）在热点分析上的具体差异。\\n7.\\tevlist\\t列出数据文件perf.data中所有性能事件。\\n8.\\tinject\\t该工具读取perf record工具记录的事件流，并将其定向到标准输出。在被分析代码中的任何一点，都可以向事件流中注入其它事件。\\n9.\\tkmem\\t针对内核内存（slab）子系统进行追踪测量的工具\\n10.\\tkvm\\t用来追踪测试运行在KVM虚拟机上的Guest OS。\\n11.\\tlist\\t列出当前系统支持的所有性能事件。包括硬件性能事件、软件性能事件以及检查点。\\n12.\\tlock\\t分析内核中的锁信息，包括锁的争用情况，等待延迟等。\\n13.\\tmem\\t内存存取情况\\n14.\\trecord\\t收集采样信息，并将其记录在数据文件中。随后可通过其它工具对数据文件进行分析。\\n15.\\treport\\t读取perf record创建的数据文件，并给出热点分析结果。\\n16.\\tsched\\t针对调度器子系统的分析工具。\\n17.\\tscript\\t执行perl或python写的功能扩展脚本、生成脚本框架、读取数据文件中的数据信息等。\\n18.\\tstat\\t执行某个命令，收集特定进程的性能概况，包括CPI、Cache丢失率等。\\n19.\\ttest\\tperf对当前软硬件平台进行健全性测试，可用此工具测试当前的软硬件平台是否能支持perf的所有功能。\\n20.\\ttimechart\\t针对测试期间系统行为进行可视化的工具\\n21.\\ttop\\t类似于linux的top命令，对系统性能进行实时分析。\\n22.\\ttrace\\t关于syscall的工具。\\n23.\\tprobe\\t用于定义动态检查点。\\n\\n全局性概况：\\n\\n* perf list查看当前系统支持的性能事件；\\n* perf bench对系统性能进行摸底；\\n* perf test对系统进行健全性测试；\\n* perf stat对全局性能进行统计；\\n\\n全局细节：\\n\\n* perf top可以实时查看当前系统进程函数占用率情况；\\n* perf probe可以自定义动态事件；\\n\\n特定功能分析：\\n\\n* perf kmem针对slab子系统性能分析；\\n* perf kvm针对kvm虚拟化分析；\\n* perf lock分析锁性能；\\n* perf mem分析内存slab性能；\\n* perf sched分析内核调度器性能；\\n* perf trace记录系统调用轨迹；\\n\\n最常用功能perf stat/record，先定性地看一个进程问题在哪，再详细记录调用情况。尤其stat结果的第一条task-clock能很明确地告诉你CPU占用率是多少，比如写一个无聊的lua脚本只做个打印，发现整个程序的CPU占用率是39%，即打印操作占了61%，还是IO占的时间更多。（越接近1表明CPU Bounded）\\n\\n* pref record记录信息到perf.data；\\n* perf report生成报告；\\n* perf diff对两个记录进行diff；\\n* perf evlist列出记录的性能事件；\\n* perf annotate显示perf.data函数代码；\\n* perf archive将相关符号打包，方便在其它机器进行分析；\\n* perf script将perf.data输出可读性文本；\\n\\n可视化工具perf timechart\\n\\n* perf timechart record记录事件；\\n* perf timechart生成output.svg文档；\\n\\n比如要监听某后台程序的性能，先用ps获取pid。这里我犯了个错误，其实ps出来的第一列就是pid，我却错找成后面的数字了，要注意。然后这样输\\n\\n* perf record -e cs -a -g -p xxx\\n\\n-e表示记录所有cs事件(事件名从perf list获取),-a表示记录所有CPU行为,-g表示记录call graph，而最后的-p就是指明pid。\\n然后perf就开始监听直到按下Ctrl-C才会停止。停止后会自动生成perf.data文件，\\n再用perf script(用于显示跟踪输出，而perf report命令也会自动读取perf.data并生成profile，火焰图需要的是跟踪输出，所以是script命令)。命令如下\\n\\n* perf script | stackcollapse-perf.pl | flamegraph.pl >perf.svg\\n\\n中间两个perl脚本从[这里](https://github.com/brendangregg/FlameGraph)下载。最早版本的stackcollapse是从DTrace来的，后来发展出各种工具的适配版，perf是其中之一。\\n\\n不仅用户态有线程和栈，内核的调度也以线程为单位，同样线程也有栈。硬件中断的处理就很典型，中断程序分为上下两个半部分，上半部分响应很及时，但是此时处理器处在中断禁止模式，所以必须尽快地完成重新开放中断。如果业务太多处理不完，只有交给下半部分，下半部分就和应用态类似tasklet，由线程管理器统一调度。\\n\\n像nodejs也追加了对perf的支持(V8支持)，像这样运行`node --perf-basic-prof xxx.js`就会生成/tmp/perf-pid.map文件，用`perf record -F 99 -p \\\\`pgrep -n node\\\\` -g -- sleep 30`记录运行数据就可以了。但是生成的map文件会不停增长，可以用`--perf-basic-prof-only-functions`来延缓map文件增长速度。java据说8u60版本后，打开`-XX:+PreserveFramePointer`也能和perf协同。"}'));jctx.push(JSON.parse('{"id": "190625", "tag": "tool", "text": "# 如何学习emacs\\n\\n## 写在前面\\n\\narm版的emacs的安装包35M，vim是20M，虽然大一些但还是同一量级，执行体emacs约4.7M，而vim约2.2M。之所以emacs给人感觉很大是其自带3K多个el文件，而vim自带插件数量远没有这么多。runemacs是专为图形界面做的外可覆程序(不会出现控制台)，支持emacs所有的命令行选项，还可以通过修改环境变量比如HOME来调整加载文件。配置文件全部放到.emacs.d/目录，原来的.emacs文件建议转移到.emacs.d/init.el，只有一个目录会比较整洁。\\n\\n## 概念\\n\\n由于没有像vim般众多的模式，emacs的概念比较纯粹，所有的行为都是elisp函数，加上(interactive)的函数又被称为命令，可以通过M-x调用。而快捷键就是对函数的绑定。没有行的概念，就是把文本放到buffer并显示出来，通过fill-column变量还控制在屏幕上的折行位置。\\n\\n## 帮助系统\\n\\n除了退出`C-x C-c`和取消`C-g`外，最需要熟练运用的就是帮助系统，\\n\\n* C-h f 查看函数的帮助信息， F 查看命令的帮助\\n* C-h v 查看变量的帮助信息，包含当前值和默认值\\n* C-h k 查看快捷键对应的函数名称和功能，c在minibuffer展示摘要\\n* C-h w 在minibuffer展示命令摘要及是否有快捷键， a功能类似支持正则\\n\\n写elisp时候想要验证某个函数，有时C-x C-e会不管用，可以换成M-x ielm 打开elisp的REPL试验。\\n\\n## 插件\\n\\n用spaceemacs如果觉得速度慢，改成国内镜像，到 .spacemacs 的 dotspacemacs/user-init() 添加\\n\\n```\\n(setq configuration-layer--elpa-archives\\n    \'((\\"melpa-cn\\" . \\"http://elpa.emacs-china.org/melpa/\\")\\n      (\\"org-cn\\"   . \\"http://elpa.emacs-china.org/org/\\")\\n      (\\"gnu-cn\\"   . \\"http://elpa.emacs-china.org/gnu/\\")))\\n```\\n\\n## Elsip\\n\\nquote和list的区别，用quote创造的对象，只要值一样，永远是同一个引用；而list是每次都创建一个新的对象并返回这个对象的引用。"}'));jctx.push(JSON.parse('{"id": "190703", "tag": "os", "text": "# Linux上的虚拟化\\n\\n## 容器化\\n\\n为了实现弹性计算和灵活迁移，把一台机器跑出尽可能多的实例，且实例间做到隔离，容器化相比虚拟机，省去了kernel的模拟，没有驱动方面的困扰，启动也更快。由于不能更换kernel，容器环境很可能没有/boot/目录(取决于chroot时有没有屏蔽)，容器环境的rootfs会额外挂载，比如在debian上启动cent的环境。\\n\\n容器化通过四个主要组件工作：名称空间（namespaces），控制组（cgroups），映像（images）和用户空间工具例如Docker或Podman。它们都基于内核的namespace，cgroup，unionFS机制，剩下的images和用户空间工具为了更好的封装。\\n\\n## namespace\\n\\nnamespace有多种类型 (mnt, net, ipc, user, pid, uts, cgroup, time)，没有namespace之前，所有`task_struct`共享一些全局属性，引入namespace特性后，task结构中增加了struct nsproxy *nsproxy;指针，以下是稍早期版本的结构体，没有user和time两种类型。\\n\\n```\\nstruct nsproxy {\\n  atomic_t count;\\n  struct uts_namespace *uts_ns;\\n  struct ipc_namespace *ipc_ns;\\n  struct mnt_namespace *mnt_ns;\\n  struct pid_namespace *pid_ns_for_children;\\n  struct net       *net_ns;\\n  struct cgroup_namespace *cgroup_ns;\\n};\\n```\\n\\n这些变量在/proc/pid/ns/目录下都有对应的文件。\\n\\nuts来源于uname(2)依赖的结构体 struct utsname，而这个结构体的名字源自于\\"UNIX Time-sharing System\\"。似乎只影响hostname和domainname。\\n\\n网络namespace包括网卡，回环设备，路由表，iptables规则。\\n\\n总的来说，namespace的本质就是把原来所有进程全局共享的资源拆分成了很多个一组一组进程共享的资源\\n\\n* 当一个namespace里面的所有进程都退出时，namespace也会被销毁，所以抛开进程谈namespace没有意义\\n* UTS namespace就是进程的一个属性，属性值相同的一组进程就属于同一个namespace，跟这组进程之间有没有亲戚关系无关\\n* clone和unshare都有创建并加入新的namespace的功能，他们的主要区别是：\\n\\n> unshare是使当前进程加入新创建的namespace\\n\\n> clone是创建一个新的子进程，然后让子进程加入新的namespace\\n\\n* UTS namespace没有嵌套关系，即不存在说一个namespace是另一个namespace的父namespace\\n\\n## cgroup\\n\\ngoogle工程师为了解决系统资源无法隔离的问题，于2006年提出此方案，并最终合并到2.6内核。\\n\\n物理机或虚拟机享有全部的资源，查看 /proc/[pid]/cgroup 列出的内容没有值，而容器的话会随着不同的实现方式输出不同，有kubepods/docker/machine-rkt等多种。利用这个特性，也可以检测到是否在容器环境。\\n\\n## unionFS\\n\\n在一台宿主机上跑几十上百个容器时，这些容器镜像的基础层往往是一样的，如果使用传统的chroot方式，势必造成极大的空间浪费，因此就有了多个容器共用一些基础目录的需求。每个容器又各自有其特有的内容，这些目录要和基础目录共同构建成应用看来统一的目录结构。\\n\\n为实现这个目的，把不同的目录的内容，联合放到同一目录内（如果有同名文件，只会看到一个），这便是unionFS技术。严格讲不能算虚拟化技术，因为早在使用CD作为Linux发行版介质时，就有类似的需求，union mount point的理念更是在1995就出现在BSD系统。随着容器技术的发展，人们发现uinonFS非常匹配，于是这种文件系统被更多的人所知。\\n\\nunionFS有多种实现，Docker最初使用的AUFS是2006年基于unionFS全新开发的，RedHat觉得AUFS基于文件的机制性能不好，开发了DeviceMapper。随着这个需求越来越普遍，2010年开发并被用在OpenWRT上的OverlayFS，在经过4年的讨论后，终于被合并入Linux内核的3.18版本。OverlayFS的思路和AUFS类似且又做了很多优化，目前已成为容器文件系统的主流。\\n\\n## QEMU虚拟机\\n\\n过程是将目标机的体系翻译成中间语言，再将中间语言翻译成宿主机的过程。主启动程序是qemu-system-xxx，支持x86、arm、mips等多种架构，不同架构有不同的执行程序。虽然都是一套软件，但支持力度却不同，X86(包括X64)最方便，只要配置好硬盘和内存参数就可以启动，而arm就要-M指定模拟的机器，-bios指定启动器（甚至还要自己上网找bios），这和arm只规定指令集，不包含外围引导也有关系。\\n\\nQEMU是纯软实现，不会利用硬件本身的虚拟化特性，速度非常慢。但支持-enable-kvm加速，可惜我用的是手机，无法体验kvm的效果。\\n\\narm版本启动后，无法进入引导，可能是bios没有选择正确。默认会开vnc，但对arm版来说，只会进入qemu的控制台，没什么用。相反x64的问题就少很多。但x64也存在只认某些ISO镜像的问题。\\n\\n除了虚拟机执行器本身，还有些外围程序，最常用的是qemu-image，用于创建、查看、管理虚拟机镜像。推荐用qcow2格式的镜像，支持把其它虚拟机的镜像格式转换，还能查看已有镜像的大小和其它属性。"}'));jctx.push(JSON.parse('{"id": "190705", "tag": "lang", "text": "# Go语言学习笔记\\n\\n## 语言特性\\n\\nGOROOT指定了Go的工具、库和源码的存放路径。\\n\\nJSON库要求struct的成员必须是大写字母开头，否则无法导出，可见性渗透到很多地方。\\n\\nstring和[]byte在二进制层面是一样的数据，但类型不同，原因是string被设计为不可变，保证多线程安全，而[]byte就是一块内存区域。当函数需要的参数和实际类型不匹配时，二者间要做类型转换，不可避免地会引入内存复制开销，如果想避免开销，就一定要自己保证内存安全。\\n\\ngo可以认为是启动了新线程（较创建原生线程开销较小），goroutine是不可控的线程操作，原生带了channel用于通信，对channel的读写是阻塞的（否则执行序不可控的多个go程就无法协作了）。而coroutine其实是严格串行执行，基于共享内存通信无妨，并不需要channel，用yield和resume显示控制。\\n\\n每个包可以定义init函数，会先于main执行，多个包的init顺序不可控。\\n\\n严格地说go的函数参数传递只有一种：**值传递**。因此对复杂struct变量，用指针方式减少复制的开销。但有一种说法，在特定的场合值会比指针开销少，原因是逃逸分析。\\n\\n## 编译与构建\\n\\n在工程源码的根目录执行go build即可。仔细看build过程，先生成一个中间过程的importcfg.link文件，内容是用packagefile指定了若干运行相关的参数，比如cpu、字节运算方式、math/sys库，并用go的link工具加载这些参数生成可执行文件a.out，然后改名成包相同的名字。\\n\\nimport时指定的是目录名称，导入同时会解析目录下的包名称，所以真正调用的时候以包名称引用（目录名和包名称不强制一样，但目录内的package包必须统一）。另外包名只有一级，不支持点号，所以不管import的目录名有多长，但真正起作用的，就是最后一个目录内实际的包名，而且当包名重复时，编译也会报错。所以在命名时，可以在package名中加入下划线适当增加长度，但也不需要太过冗长。导入包重命名机制一定程度上解决命名空间只有一层的简陋。\\n\\ngo build -tags \\"abc xyz\\"会启动条件编译，只有代码首行指定了`//+build abc`的文件会被编译。似乎充斥着这种打补丁似的语法，大约是实际的需求和理想化简约之间的冲突吧。\\n\\nrun指令可以带多个文件列表，顺序可以任意，甚至用\\\\*.go，否则main函数调用的其它文件没有被引入会报错，不需要像C语言把被依赖的文件放在最前面。main包平铺拆成多个文件也是最简单的项目拆分方式，如果想形成多目录，就要用replace指令，对新手来说难度会大很多。\\n\\n### 代码目录结构的变迁（go.mod）\\n\\n以下仅仅是历史，了解就行\\n\\n>  Go的1.11版本以前，代码必须在GOPATH环境变量指定的目录，背后的原因可能是Google所有的代码在同一个repo下，微缩后变成了GOPATH。固定 bin/pkg/src 三个目录，在src下建立目录比如xyz，进入这个目录下编写代码，最后用go build就会自动编译。强行指定文件名固然可以，但并不推荐。\\n\\n1.11引入Module机制，可以不限制在GOPATH路径。从1.13开始module成为默认行为，不再要求在GOPATH目录编译，而是鼓励在当前或父目录添加go.mod文件使这个目录成为go的模块，同时也不再限制必须有src目录。配置 `go env -w GOPROXY=https://goproxy.cn,direct` ，下载依赖包也变得非常方便。\\n\\n以一个简单的go.mod示例来解释构建过程\\n\\n```\\nmodule me.local/user/tdi\\ngo 1.19\\n```\\n\\n第二行版本限定并不是必须的，其实可以精简到只有module一行。后面的模块名必须以域名开头，不用担心域名是否存在，只要遵循规范就好。最后一段会默认作为go build的结果文件名。\\n\\n稍微复杂的工程肯定会导入本地目录，如果有个lib目录，import时写成me.local/user/tdi/lib（module名后跟目录名），就会在源码目录找包。\\n\\n以前还记了一种方法，似乎也用不上了。在go.mod中添加require xxx v0.0.0和replace xxx v0.0.0 => ./xxx，关键是用replace指向本地目录，go就不会去网上找这个包了。\\n\\n### 包和模块\\n\\n一个目录就是一个包package，通过这个目录下的每个源文件开头申明相同的package xx表示属于一个包。取名为main的包比较特殊，通常会定义main函数作为总的入口。同一个包内的函数和类型可以互相引用，不需要申明为大写。多个包构成一个模块，通过在顶级目录添加go.mod声明是一个module。\\n\\ngo get下载的包会放在GOMODCACHE环境变量指向的目录。\\n\\n包可以被编译成.a库。解压后虽然也是.o，但和C语言不同，是混合了字符和二进制的特定形式。不过Go提倡按源文件编译，即使提供了.a库机制，似乎用处不大。\\n\\n### GUI程序\\n\\nwindows平台的图形化程序，链接过程必须有.syso文件才行。可以用rsrc编译manifest，或windres编译rc（内部要有RT_MANIFEST指令）都可以。go build -ldflags=\\"-H windowsgui\\"就不会带命令行小窗口。\\n\\n## 测试与调试\\n\\n单元测试要函数名以 `Test[A-Z]` 方式开头，如果是小写字母则不会运行。在GOPATH下直接运行go test package，虽然能运行用例，但正常的例子不会输出到stdout，而进到package的目录直接运行go test，会输出stdout。Example开头的函数，要增加 `//output:` 才会输出。\\n\\n用GDB调试，build命令可以加两个参数\\n\\n1. 使用go build -ldflags \\"-s -w\\"减少生成文件的体积。-s: 去掉符号信息，-w: 去掉DWARF调试信息。\\n2. 传递-gcflags \\"-N -l\\" 参数，这样可以忽略Go内部做的一些优化，聚合变量和函数等优化，这样对于GDB调试来说非常困难，所以在编译的时候加入这两个参数避免这些优化。另外-m会在编译期打印逃逸分析结果。\\n"}'));jctx.push(JSON.parse('{"id": "190708", "tag": "design", "text": "# 感悟项目开发和问题分解\\n\\n最近做完两个网站类项目，流程还是很有必要的。一个功能从产品经理构思，到UE/UI设计交互，到程序员编码，到最后测试反馈是一个完整的闭环，谁先谁后，哪个时间点做什么都有讲究。\\n\\n立项初期，往往是产品经理和系分先讨论大致思路和技术可行性和选型，等思路确定后，就将交互告知UE，UE/UI具象化后提供给开发，开发听完后再给项目经理/系分做反串讲，同时测试要在场，确保实现和测试验收依据不会偏离，整个开发过程由项目经理跟踪进度。\\n\\n一个需求从诞生到验收，大约经历以下步骤\\n\\n1. 产品经理构思，并在纸上给出交互，系分确保技术可行性（所以产品经理通常要会Axure）\\n2. 产品经理把想法告知UE，UE给出更完整的交互作品，并知会UI，确保风格一致\\n3. UE评审交互流程，开发介入并理解需求。后端构思接口，前端确保交互可行性，UI出素材\\n4. 开发反串讲，和测试确保理解一致，技术问题找系分确认\\n5. 开发编码实现自测\\n6. 转测试验证、提单修改或裁决\\n\\n## 问题决策经过\\n\\n讨论两个平台功能，不仅给答案，还给出整个解决思路的做法，看起来简单，但并不是人人都会的，尽管看来很平凡，却需要多年反复实践。比如一个变量名优先级取舍，看起来是策略问题，其后确是程序设计领域有指导性的理论在指引，甚至最后结束，突然想到输出变量的命名空间归属，并不容易想到这件事"}'));jctx.push(JSON.parse('{"id": "190710", "tag": "book", "text": "# 后汉的恒灵少献四帝\\n\\n出师表中恒灵之后，千载之下仍是昏君的代名词。恒帝时的党锢之祸，致士人不得重用而任宦官。恒帝无子，灵帝是外藩入继大统，初继位无权，朝政由扶立之功的窦武把持，加之陈藩，二人欲清除宦官却做事不细致，被宦官所杀，于是灵帝仍重用宦官，甚至呼为父母。灵帝朝更开卖官之先河，吏治败坏。\\n\\n灵帝成年，立何妃为皇后，何进因而掌握朝政。灵帝为分权设立西园八尉节制何进，其中就有袁绍和曹操。灵帝184年黄巾起义，但数月即平定，因此改元中平。黄巾之事为防止党人被拉拢，灵帝重新启用党人，又为提高行政执行速度，在中平5年接受刘焉的建议重置州牧，史称\\"废史立牧\\"。刘焉也因此出任益州牧，随后地方割据就越发不受控制。\\n\\n何皇后之子刘辩即为汉少帝。但灵帝素来不喜刘辩，想立王美人子刘协为帝（此处奇怪在于既然立何氏为后，为何又不喜刘辩？）。汉灵帝驾崩，蹇硕计划在何进入宫时杀之，但在蹇硕司马潘隐的暗示下，何进称病不入。由于没有除掉何进，刘辩被立为少帝，何进辅政。何进欲杀宦官，但何皇后要借助宦官之力，加之何苗不同意，何进犹豫最后反被宦官杀。\\n\\n刘辩在位仅4月余，因宫内争斗被宦官挟持出逃，被董卓迎回，其应对不及刘协，被废。一年后被李儒以毒酒死。\\n"}'));jctx.push(JSON.parse('{"id": "190720", "tag": "lang", "text": "# LispMachine\\n\\n1. Lisp Machine 用 Lisp 做汇编指令纯属误传，虽然编译器能将 Lisp 编译成机器指令，也可以将机器转回人可读的 Lisp 代码，从某种角度来说，Lisp 处于直接和机器指令之间转换的层次，和现在常见的计算机的汇编是类似的。但说 Lisp Machin 用 Lisp 做汇编是不严谨的，因为 Lisp Machine 也有自己的汇编语言。\\n\\n2. Lisp Machine 出现的背景是 16 位处理器向 32 位的迁移，主流 32 位处理器上运行的 Lisp 实现性能不理想，才有了 Lisp Machine 这一构想。当时的 Lisp Machine 有两大派系，MIT 和 Xerox ，分别对应当时两大主流方言 MacLisp 和 INTERLISP。我对 Xerox Lisp Machin 了解不多，以下主要基于 MIT Lisp Machine 的设计。\\n\\n3. (MIT) Lisp Machine 的处理器实际就是个栈机器，Lisp 代码依次转化为栈操作执行：参数先依次压入栈，供计算指令调用，执行结果输出到返回栈。函数内部的函数调用就是建立一个新的栈帧，压入参数，输出结果到返回栈。一些特殊的函数直接实现成机器指令，从 destination 接受参数直接输出到返回栈。\\n\\n4. Lisp Machine 设计成熟时期，用 Lisp Machine 做数值运算比在当时 32 位处理器上的 Fortran 还快。最大的特色其实是支持大屏图形界面和鼠标。\\n\\n5. 很显然这种微处理器是复杂指令集设计，在现代已经过气了。后来基本等于免费分发的 Unix 配合摩托罗拉之类的廉价硬件平台很快取代了几十万美元一台的 Lisp Machine，导致本就经营不善的最大 Lisp Machine 公司之一 Symbolics 挂了，对业界又造成了打击。\\n\\n6. 说 Lisp Machine 没有进程，Lisp 不适合用来描述操作系统云云，至少对于后期的 Lisp Machin 来说是错误的。Symbolics Lisp Machine 用物件导向设计操作系统，包括进程在内几乎所有系统构建抽象成物件，Lisp Machine Manual 的原句就是进程相当于虚拟 CPU。Unix 的一切皆文件就是一种弱层次的物件导向设计，Mach 微内核更是大量采用了物件导向设计，就连 Linux 都不可避免引入了 C艹，明显同时具有高级抽象和底层硬件的 Lisp Machin Lisp 是很合适的，而内核态和用户态的访问直接由定义方法来控制，这些问题在 Lisp Machine 还没过气之前都已经解决了。\\n\\n7. 两个时代硬件的比较，Lisp Machine 晚期在 DEC Alpha 工作站上用虚拟机运行 Lisp Machine，做一次内存整理花费约 40 分钟，将同样的虚拟机移植到 Linux 后在 Core i7 四核上运行做相同操作，只要不到一分钟。\\n\\nReferences:\\n\\n[1] Guy Steele and Richard Gabriel, The Evolution of Lisp\\n\\n[2] Richard Stallman, Daniel Weinreb and David Moon, Lisp Machine Manual, 6th Edition\\n"}'));jctx.push(JSON.parse('{"id": "190801", "tag": "data", "text": "# 数据库和数仓的历史\\n\\n数据库是计算机最早的应用系统，阿波罗计划时就有了数据库原型，这便是1968年的IBM ICS系统，69年改名为IMS/360（层次型数据库）。70年，IBM的研究员Codd提出了关系型模型，虽然关系型理论是IBM提出的，但出于产品惯性IBM没有及时跟进，反而是1983年Oracle率先向市场推广，虽然同年稍晚IBM也发布了DB2产品，但在市场上显然是Oracle胜了。\\n\\n和数据库相关但又有区别的数据仓库（Data Warehouse），概念早在1970年代就有探讨，Inmon在Kimball分别在1992和1996年出版关于数仓的专著，可以认为数仓正式成型。Inmon定义数仓是一个面向主题的（Subject Oriented）、集成的（Integrate）、相对稳定的（Non-Volatile）、反映历史变化（Time Variant）的数据集合，用于支持管理决策。或者说就是建立围绕主题，并最终要挖掘出主题间关系的库。落地到具体行业，一定要对行业关心的主题建立好模型。支持构建完整数仓的技术有：清洗、集成、OLAP。\\n\\n* OLTP: 联机事务处理， 关系型数据库(Oracle、MySQL)多属于此类，擅长记录发生的业务内容，多小批量写入，要保证事务性。设计时强调三范式，表结构紧凑，避免冗余\\n* OLAP: 联机分析处理，随着OLTP的数据越来越多，如何快速地分析这些数据就变得重要起来，这个概念是Codd在1993年提出的，在设计上和OLTP不同，往往把多张表JOIN成宽表，保留一定的冗余，来提升分析和处理速度，并不在意事务能力。分析使用的技术，多为统计学或机器学习方法。\\n\\n数据仓库的来源分为非结构化和结构化数据。非结构化数据要先经NLP提取变为结构化，结构化数据可以用机器学习的方式做分类、聚类，又或者按统计学的方式进行提取。\\n\\n数仓的建模方式有多种，国内主流的是阿里推崇的维度建模(kimball)，有星形模型(一个事实表和多个维表，没有二级维表)和雪花模型(在星形基础上允许二级甚至更多级维表)。\\n\\n## MPP与SQL on Hadoop\\n\\n支撑数仓的软件有很多，其中一个大类统称MPP，比较商业的产品是金融领域的TeraData，但价格太贵，多见的是GreenPlum，是基于Postgre开发的主从式分布数据库，master负责调度segment负责执行。引申一句GP最初是EMC开发的，买存储送GP，配合EMC的存储和售后，在银行领域很有竞争力。\\n\\nMPP的代表产品有：Vertica/Redshift(Paracel，被Amazon买下了源码的license后变成Redshift)/Greenplum。仔细观察不难发现，这三者其实有非常很多相同点：\\n\\n1. 全部基于PostgreSQL\\n2. 都是基于列的存储(Columnar Storage)\\n3. 操作都是以Scan为基础，依赖Compression来提供性能的优化\\n\\nMPP为了速度，需要将数据导入做一定处理，整理成优化的格式以便加速。这样做的后果就是，它们的存储类似一个黑盒，数据进去之后很难被别的系统直接读取。\\n\\n还有另一类统称SQL on Hadoop，实现有Impala，Hive，SparkSQL，Presto等。这类方案不负责存储，或者说是存算分离，计算基于MapReduce/RDD机制，水平扩展性很强。但是这种方案是多种系统共用一个HDFS存储空间，不可能做非常彻底的优化时优化，典型的就是CBO优化程度会弱一些。\\n\\nSQL-on-Hadoop架构可以分为两类：\\n\\n1. SQL over Processing Framework：例如SparkSQL，Drill/Datameer，Presto，Impala\\n2. OLAP over Hadoop：例如Kylin，Druid，AtScale，Kyvos\\n\\nSQL over Processing Framework系统的共同特点是“Hadoop通用计算框架+SQL解析引擎”，存储层、执行引擎层、SQL解析层三者分离，可以方便替换执行引擎，对使用者而言，同一份数据可以采用不同并行执行引擎来分析。优点是灵活性高，支持细粒度容错，集群扩展性好，缺点是效率无法保证。\\n\\nOLAP over Hadoop系统的共同特点是预计算，即数据都以时间序列的方式进入系统并经过数据预聚合和建立索引，因为是预计算，所以应对多维查询时速度非常快（计算时间复杂度O(1)）且稳定，支持高并发，支持集群扩展。缺点是灵活性较差。\\n\\nMPP原理朴素上说就是分治思想，均分task。\\n然后每个worker/segment上做的都是同样的sub-task，pipeline方式执行，理想情况下性能是非常优异的。\\n但是很容易受到慢worker（它是最长路径）和interconnect的影响，所以scalability不佳，集群规模在十几个节点后就没有性能提升了（甚至还可能下降）。\\n\\nHADOOP原理更类似batch processing，更细粒度切分task，worker能者多劳（每个worker上执行的任务可以是不平均，不一致的）。\\n单独worker看，性能不及MPP，但是胜在scalability优异，几百个节点是没问题的，在集群性上远胜MPP。\\n\\nMPP和SQL on Hadoop的最大区别在于，MPP架构是Full-SQL compatiable的，实现不局限于将Query分解为一连串的job去执行。并且由于每一列的数据类型进行了特定的压缩和编码(比如run-length/delta/bytecoding)，能做的优化要比单纯的MapReduce多很多，效率自然也要高不少。相较于SQL on Hadoop，MPP更适合做interactive ad-hoc analysis，前者则更适用于对于海量数据做批处理或者需要使用UDF(自定义函数)的场景。"}'));jctx.push(JSON.parse('{"id": "190808", "tag": "data", "text": "# SQL语言梳理\\n\\n## 历史脉络\\n\\n首先说一下这帮人当时都在IBM，大概因为大规模的数据应用主要的受众是商业公司，刚好和IBM主业匹配。Codd在1970年发表了关系代数论文，引发IBM在1973年立项System R来研究可行性，然后Donald Chamberlin和Raymond Boyce于1974年发表了SEQUEL语言，但因命名重复所以改名为SQL，Boyce在发表论文后不久死于动脉瘤，后来的荣誉都给了Chamberlin。在这期间Jim Gray确立了事务机制、粒度锁系统和隔离级别。差不多时间，Berkeley的Stonebraker开发的Ingres系统用的是QUEL语言，直到后来他的学生开发Postgres后才换成SQL语言。以上这些人中，除了SQL论文的成色稍次，其他3人都获得了图灵奖。在之后的1975年，台湾的Peter陈品山，发表了虽然不是基于关系模型，但对业界影响很大的ER模型论文。\\n\\n## 理论依据\\n\\nSQL背后的理论支撑是集合论、关系代数和一阶谓词逻辑（Codd的原始论文曾设想二阶谓词，因太复杂放弃了）。操作的结果是封闭的，即输入和输出都是关系，这也是查询的结果可以作为插入动作的输入的原因。在时间的发展上，关系是在层次模型和网络模型之后提出的，它的目标就是避免出现地址概念，达到彻底的逻辑和物理分离。因此SQL语言没有变量（地址）的概念，AS只能表达不可变引用。\\n\\n由于关系代数是三值逻辑，SQL继承三值逻辑后，计算中就必然会存在NULL（严格地说是NULL有未知和不适用两种含义，最原始的也是四值逻辑，但后来被合并，所以仍是三值）。NULL并不是值，只是一个用于填充的标记，所以对它做比较是无意义的，只能IS NULL判断。NULL在计算时会引发propagate，甚至NULL/0也是NULL。AND和OR等短路运算时，NULL的优先级介于TRUE和FALSE中间，即TRUE OR NULL = TRUE；FALSE AND NULL = FALSE。\\n\\n虽然很多时候都提倡用NOT NULL，但由于NULL的概念根植于SQL的底层，在外连接或CUBE/ROLLUP的GROUP BY时，还是会不经意间引入NULL。\\n\\nSQL基于的关系代数，严格的说是Relation Bag Algebra，并不是Codd最原始的Set定义，差异在于Bag允许关系数据重复，而Set的数据必须唯一，所以有DISTINCT和ALL这类关键词来指定结果要set或bag。但是SQL和关系代数有几个很不一致的地方，比如SQL的SELECT对应的关系代数是PROJECT，SQL的WHERE和HAVING才对应关系代数的SELECT。\\n\\n关系代数的核心操作只有5种，分别是并、差、积、选择、投影，操作的都是元组。所有的SQL语句最后都能用这5种操作组合完成。比如一个嵌套子查询可以等价转换成一个连接（join）操作。UPDATE操作看起来是对字段(Attribute)的修改，但严格来说，是用一条记录替换掉原来的记录，本质还是行级。\\n\\n## 功能分类\\n\\nSQL规范定义了几种不同领域的操作，使用的指令不同。虽然最常见的是增删改查，但从完整的BNF方法列表来看，其它几种分类占的比重更大。\\n\\n* DDL - 数据定义语言(CREATE，ALTER，DROP，DECLARE)\\n* DML - 数据操纵语言(SELECT，DELETE，UPDATE，INSERT)\\n* DCL - 数据控制语言(GRANT，REVOKE，COMMIT，ROLLBACK)\\n\\n对语法有疑问时，查BNF定义是最好的，比如查询语句后面如果是子查询必须有别名，但如果是关联就不需要别名，似乎也没什么理由，就是文法这么规定的。\\n\\n## 表达式类型\\n\\n* 表表达式：对表的操作，FROM、WHERE、GROUP BY、HAVING\\n* 条件表达式：专门用在WHERE表达式，有AND、OR、IN、LIKE\\n* 标题表达式：如各种算术运算符、CASE\\n\\n## 值语法和类型\\n\\n所有的值都是用圆括号`()`包起，可以出现在很多位置，比如VALUES后的字面量，或是FROM后的子查询，甚至在SELECT、WHERE等出现变量名的位置。值有两种类型，标量和集合。\\n\\n## 查询的顺序\\n\\nSELECT查询涉及众多关键字，最核心的有3个：JOIN、WHERE、GROUP BY。执行顺序并不是从前到后，正确的顺序如下\\n\\n* 7 SELECT 8 DISTINCT 10 TOP NUMBER\\n* 1 FROM 3 JOIN\\n* 2 ON 4 WHERE\\n* 5 GROUP BY 6 HAVING\\n* 9 ORDER BY\\n\\n在不影响结果的前提下，优化器对顺序会做微调，比如 FROM a LEFT JOIN b ON a.x=b.x WHERE a.name=x and b.age=x，WHERE的a语句会先执行，再做JOIN，最后再做WHERE的b语句，术语叫Predicate Pushdown Filter。因为对LEFT JOIN来说，将右表的过滤放到JOIN前，不会影响JOIN的条数，这就和WHERE原始的后置语义不同，因此不会被优化；如果想优化也很简单，将WHERE中对右表的过滤，放到ON条件来做。\\n\\n## 横向与纵向操作\\n\\nSQL是对关系的操作，这种操作有两个方向，横向的代表是JOIN，而纵向的代表是GROUP BY。JOIN内容太多，单开一篇讲。\\n\\n## GROUP BY 层级和阶\\n\\n引入了谓词逻辑中阶(order)的概念，最明显体现在GROUP BY上。一但用了GROUP BY，操作对象就由0阶的行，变为1阶的集合，不同的阶需要用不同的谓词去操作。典型的WHERE操作0阶的行，而HAVING操作1阶的集合，其背后是有严格的理论支撑的。\\n\\nGROUP BY后可跟一到多个关键字，将集合按这些关键字形成子集，每个子集内只含一种这些关键字值的组合，此时其它值也在，但因为阶变了，不能显示地查看其它值明细（换句话说，其它值都在子集内，但不能直接查看），但是部分数据库提供了`group_concat`函数，将所有明细值表示成一个字符串，相当于把明细值做了聚合。\\n\\n### 高级分组cube和rollup\\n\\n先看这个语句`GROUP BY a,b GROUPING SETS ( (a,b),a)`，怎么理解？相当于`GROUP BY a,b UNION GROUP BY a`。在这个基础上，再来看cube和rollup。\\n\\n`GROUP BY a,b WITH CUBE`等效于GROUPING SETS( (a,b), a, b, ())，会严重膨胀。\\n\\n`GROUP BY a,b WITH ROLLUP`等效于GROUPING SETS( (a,b), a, ())，从左向右下钻。\\n\\n## NULL的比较与排序\\n\\n排序时如果有多个字段，可以为每个字段分别指定ASC或DESC，默认升序ASC。原理上NULL是不能排序的，在max/min函数也会忽视NULL值（除非数据全部是NULL），甚至count如果指定列名，而这里面如果有NULL值，也不会计入总数。但是ORDER BY的时候，NULL值会在结果里显示出来。排序的结果是实现相关，主流的几种数据库行为分为两派\\n\\n* NULL比任何值都小： 包括MySQL、SQLServer、SQLite，表现出的行为是，ASC时，NULL值最前，DESC时NULL值最后\\n* NULL比任何值都大： 包括Oracle和PostgresQL\\n\\n为弥补未定义NULL排序的缺失，SQL规范增补了NULLS FIRST或NULLS LAST关键字，通过放在ASC或DESC后来改变行为，遗憾的是只有Oracle、PG以及3.30版本后的SQLite支持。\\n\\n## 索引\\n\\nwhere条件如果是OR，索引不起作用。联合索引符合最左原则，即索引是A,B,C时，支持A或AB或ABC，其它没有作用。\\n\\n## 窗口函数\\n\\nSQL99规范定义了窗口函数，反而最常见的MySQL直到8.0版本才支持。窗口函数有点类似GROUP BY，但由于它是函数，并不会改变结果的阶，因此可以作用在每一行上。\\n\\n窗口函数有两大类：聚合函数和排序函数，聚合函数和GROUP BY类似，也是SUM、MAX这些，但可以添加到每一行上。\\n\\n排序函数用得比较多，有ROW_NUMBER、RANK、DENSE_RANK，结合分组能知道在每个分组内的顺序，进而做一些分析操作，这是GROUP BY不具备的。\\n\\n## UDTF与侧视\\n\\nSQL处理二维表，意味着列只能是标量。但如果列就是矢量，或者想作为向量用，就引入了UDTF和与之配套的LATERAL VIEW语法。\\n\\n设想一条记录，主键是身份证，接着一列手机号，该列的定义是逗号隔开的字符串，怎么转换成每行一个手机号呢？\\n\\n首先用split把逗号拼接的字符串向量化成array，但这时还是在一行里，要进一步用explode把这行炸开，但是UDTF炸开后的值是个Table，不能用select，所以就要用如下语法\\n\\n```\\nfrom t\\nlateral view explode(split(col1, \';\')) table_identify as col11\\nlateral view explode(split(col2, \',\')) table_identify as col22\\n```\\n\\n直观解释一下，对一张表t，选择其中若干行炸开，所以取名lateral横向view关键字，紧接着跟一个UDTF函数产生的临时表，带一个临时表别名，这个表别名的可见范围只在lateral view这行，多行可以取一样的别名，因为最终要的还是列，所以要as一个列名，给最外层的SELECT用。每次炸开都会触发一次行级别的笛卡尔积，炸开列越多性能越差。\\n"}'));jctx.push(JSON.parse('{"id": "190817", "tag": "os", "text": "# 协程剖析\\n\\n一句话定义：协程是可以被中止和恢复的函数。协程的历史很早，随着非阻塞(NonBlock)操作的日渐普遍，每一次非阻塞指令都配套回调，代码可读性很差，于是协程就重新被人捡起。\\n\\n协程可以从有栈/无栈，以及对称/非对称角度划分为四象限\\n\\n* 有栈/无栈: 区别在于是否有自己的调用栈来进行函数调用等操作，一般来说无栈性能好，有栈易用\\n* 对称/非对称: 区别在于是否能自由的转换控制权。非对称易理解、好用，对称灵活但心智负担会高一些\\n\\n## 有栈和无栈\\n\\n有栈协程可以随意的切换, 因为所有状态都在协程内部, 并且可以并行 , 存在中间状态比如寄存器的计算结果啥的, 切换要很小心, 但是粒度更细。无栈协程只能手动切换, 不过效率要高, 不用管复杂的寄存器状态, 切换的控制权也在用户手中\\n\\ncoroutine是个很宽泛的概念，async/await也属于coroutine的一种。但是问题是拿async/await和stackful coroutine比较。所谓stackful是指每个coroutine有独立的运行栈，比如每个goroutine会分配一个4k的内存来做为运行栈，切换goroutine的时候运行栈也会切换。stackful的好处在于这种coroutine是完整的，coroutine可以嵌套、循环。\\n\\n与stackful对应的是stackless coroutine，比如generator,continuation，这类coroutine不需要分配单独的栈空间，coroutine状态保存在闭包里，但缺点是功能比较弱，不能被嵌套调用，也没办法和异步函数配合使用进行控制流的调度，所以基本上没办法跟stackful coroutine做比较。\\n\\n但是async/await的出现，实现了基于stackless coroutine的完整coroutine。在特性上已经非常接近stackful coroutine了，不但可以嵌套使用也可以支持try catch。所以是不是可以认为async/await是一个更好的方案？\\n\\n有个匿名用户在纠结并发需要多线程，这里我统一做个回复。很多人是从多核时代入行的，看到的异步框架都是使用了线程池，所以想当然的认为并发必须依赖多线程去处理，更有人连[[并发和并行]]的概念都搞混，认为单核CPU就不能并发了。实际上并发这个概念在没有多核CPU甚至没有线程的年代（早期的Linux是没有线程的）就有了。并发经常与IO联用，IO是独立于CPU的设备，IO设备通常远远慢于CPU，所以引入了并发的概念，让CPU可以一次性发起多个IO操作而不用等待IO设备做完一个操作再做令一个。怎么实现呢？原理就是非阻塞操作+事件通知，在核心态非阻塞操作对应的是读写端口和DMA，而事件通知则有专门的术语叫中断响应。过程有2种\\n\\n1. IO设备发起中断，告诉CPU现在可以进行IO操作，然后CPU进行相应的操作\\n1. CPU先发起IO操作，然后IO设备完成处理后发起中断告诉CPU操作完成\\n\\n核心态是不存在多线程这种概念的，一切都是异步的事件驱动（中断响应），线程是核心给用户态提供的高层概念，线程本身也依赖中断来进行调度。早期的用户态IO并发处理是用poll(select)模型去轮询IO状态，然后发起相应的IO操作，称之为事件响应式的异步模型，这种方式并不容易使用，所以又发展出了阻塞式IO操作，让逻辑挂起并等待IO完成，为了让阻塞式IO能够并发就必须依赖多线程或者多进程模型来实现。但是线程的开销是非常大的，当遇到大规模并发的时候多线程模型就无法胜任了。所以大规模并发时我们又退回去使用事件响应，epoll在本质上还是poll模型，只是在算法上优化了实现，此时只用单线程就可以处理上万的并发请求了。\\n\\n直到多核CPU的出现，我们发现只用一个线程无法发挥多核CPU的威力，所以再次引入线程池来分摊IO操作的CPU消耗，甚至CPU的中断响应也可以由多个核来分摊执行，此时的线程数量是大致等于CPU的核心数而远小于并发IO数的（这时CPU能处理百万级的并发），线程的引入完全是为了负载均衡而跟并发没有关系。所以不管是用select/epoll/iocp在逻辑层都绕不开基于事件响应的异步操作，面对异步逻辑本身的复杂性，我们才引入了async/await以及coroutine来降低复杂性。\\n\\n### 有栈协程\\n\\n有栈协程要保存堆栈, 一般来说有俩种做法:\\n\\n1. 采用操作系统提供的api 类似 ucontext 或者 setjump longjump\\n1. 用汇编操控寄存器保存状态\\n\\n从上面例子看出，用了OS自带函数做所有寄存器(EIP)和栈上变量的保存恢复，故名有栈协议。 下面给一个C语言实现的模拟操作\\n\\n```\\nvoid coro_func(int& step) {\\n  switch (step) {\\n    case -1:\\n      if (step) {\\n      terminate_coroutine:\\n        step = -1;\\n        goto bail_out_of_coroutine;\\n      bail_out_of_coroutine:\\n        break;\\n      }\\n      else\\n    case 0:\\n      worker(1);\\n      for (step = 1; ;) {\\n        if (step == 0) {\\n    case 1:\\n      break;\\n        }\\n        goto bail_out_of_coroutine;\\n      }\\n      worker(2);\\n      for (step = 2; ;) {\\n        if (step == 0) {\\n    case 2:\\n      break;\\n        }\\n        goto bail_out_of_coroutine;\\n      }\\n  }\\n}\\n```\\n\\n可以看出，把阻塞操作拆成两步，在执行完NonBlock后更新步进值并退出，下次自然就能回到上次的点继续。不依赖系统调用。\\n\\n### 无栈协程\\n\\n无栈协程的实现, 要几个条件:\\n\\n1. 栈帧内保存的不是状态而是指向状态的指针\\n1. 所有帧的状态保存在堆上\\n\\n为什么说第二点比较重要, 因为理解了第二点就发现, 其实根本不需要上下文切换, 因为全局的上下文就没变过, 改变他们的调用关系就行(栈)\\n\\n## 对称和非对称\\n\\n用yield/resume风格实现流程切换，叫非对称协程。在让出运行权后并不知道接下来是谁运行。\\n\\n对称协程，类似 `f() { core.transfer(g) }`，在函数f运行过程中直接切换到函数g上，但是这种方式写出的代码破坏了模块性，要关心外部的运行流程很难维护。因此目前能见到的协程实现都是非对称。\\n\\n最后可以比较下[[进程线程和协程的切换开销]]"}'));jctx.push(JSON.parse('{"id": "190820", "tag": "lang", "text": "# 类型理论\\n\\n## 变量类型\\n\\n对变量来说有几个属性：类型，可变性，作用域\\n\\n1. 类型，动态语言不需要事先声明，所以这一点是没有的。C或Java需要，(C++11的auto看似做了简化，其实只是给编译器的一个提示，还是会转变成真实的类型再编译)\\n\\n2. 可变性，纯函数式比如Haskell是不可变的，也就不需要这个修饰。但大量其它语言还是需要的，比较多见的是const/volatile关键字，ES6也引入const了，Lua5.4引入const，Scala是用var和val来区分变量是可更改还是恒定性\\n\\n3. 作用域，Lua语言在声明一个变量时，是可以指定local的，表示这是一个位于当前chunk的变量，如果没有，则变量被声明到了全局空间，语义上对应js中的var关键字。\\n\\nlocal和当前函数的作用域在一起，因此访问速度也最快，全局变量则要依次向上查询，速度显然要慢一些。所以很多Lua代码，都会在开始处用local方式把全局重新定义一遍，目的就是为了提高速度。对于默认声明变量都不在局部域这点，我很不理解，为什么可以在一个函数内部声明一个外部的变量？而且显示调用local声明变量的方式，还可以声明一个变量但不使用。因为这本质上只是预留了一块空间，无非是空间的位置在哪里而已。\\n\\nRnRS中有这样一句：对变量的每一次使用都对应于该变量在词法上的一个明显的绑定，因此只声明变量而不使用的行为，在Scheme中是不允许的。\\n\\n纯函数式理论上是不是需要声明变量的，一切都在计算中传递。但冯诺依曼的计算机模型却让变量成为了计算的基础。另外全部做成在计算中传递也比较难以书写，于是Scheme中也保留了局部的变量绑定语法，就是let系。它的作用域就是局部的，可以认为是必须放在函数开头处，且必须显示声明绑定关系的local语句。个人以为这种规定比js中随意放置var声明要严谨得多。\\n\\n再提一点RnRS对define的定义是Top Level Definition，而let系是Internal Definition。我用TinyScheme测试，是可以在lambda内部使用define语句，但kawa就通不过。考虑到Tiny毕竟是一个极小的实现，对一些限制也不严格，因此对define的使用还是在全局较好。\\n\\nnull最好是提升到类型级别，而不是作为特殊值，编译器会推导保证类型正确，而值只能在runtime时直接崩溃。\\n\\nRust 错误处理本质上还是基于返回值的，很多基于返回值做错误处理的语言是将错误直接硬编码到正确值上，或者返回两个值，前者例如 C 在很多时候都是直接把正常情况永远不会出现的值作为错误值，后者例如 Go 同时返回两个值来进行错误处理。而 Rust 则将两个可能的值用 enum 类型表示，enum 是和类型(sum type)，表示两个可能的值一次只能取一个。\\n\\n## ADT\\n\\n函数式语言的代数数据类型ADT(algebraic data type)，简单的说就是组合类型。不要和抽象类型abstract data type混淆。\\n\\nsum type是tagged union(值域是每种field的sum)，product type典型例子是tuple或struct(值域是每种field的cartesian product)。\\n\\ntuple强调不可变，python用tuple作为函数的出入参，利用的就是immutable，而且因为不可变，一定程度上就具备hashable特质。\\n\\n拓展:思考元组、函数参数、函数返回值，命名参数和 Record 以及 list 的关系(比如像 SML 那样设计)\\n\\n## symbol和string\\n\\n在lisp中符号的历史比字符串更加久远，在LISP 1.5中SYMBOL 和 CONS是最重要的数据类型。\\n\\n> 数字是一种特殊的符号。——摘自《LISP 1.5 Programmer\'s Manual》\\n\\n而字符串是后来加上的。用来表示字符序列的概念，至此，再用SYMBOL的NAME来表示字符序列已然成为不好的行为了。\\n\\n举个例子`\'abc`作为一个原子（atom），不可以拆开；而`\\"abc\\"`是复合数据，可以提取出\\"a\\"。因此symbol的存在大大扩充了原子世界，以便于写符号计算和元编程。\\n\\n字符串是无结构的，符号是有结构的，符号中的数字类型也不是以字符串形式储存的而是单纯的数字，原子的符号受到标识符规则的限制而字符串没有。\\n\\n换句话来说不是任意一段字符串都可以找到相对应的符号。"}'));jctx.push(JSON.parse('{"id": "190821", "tag": "os", "text": "# BIOS启动地址0x7C00的来源\\n\\n这要追溯到1981年的IBM PC 5150，这货的内存是32KB。\\n\\n那个年代，内存是个金贵的东西，要省着用，当时的程序员，可比今天的码农牛逼，为了省点儿资源，各种奇技淫巧。我一直觉得，那个年代的程序员，才有资格叫程序员。\\n\\n0x7C00其实就是32K内存的倒数1024个字节。\\n\\nMBR大小是硬盘的一个扇区，也就是512字节，从0x7C00开始的1024个字节中，前512字节就是用来供BIOS加载MBR的，剩下的后512字节，用来存放MBR执行时产生的数据。\\n\\n等于是MBR的专属内存。\\n\\n为什么要放在最后，这是为了减少内存碎片，给操作系统留下更多空间。\\n\\n偷偷告诉你，其实最后这1024字节，在系统启动后，还是会被操作系统用到的。\\n\\n为什么？因为MBR加载完操作系统后，就再也用不到了。\\n"}'));jctx.push(JSON.parse('{"id": "190901", "tag": "net", "text": "# traceroute原理和ICMP\\n\\n项目中遇到ping返回time to live exceeded，即TTL超出，展开讲讲。\\n\\nping是基于ICMP协议，它是附在IP协议的数据段的一种应用协议，可以类比为HTTP之于TCP，由于是二层协议所以没有端口。IP协议共20字节，专门留了1个字节表示TTL，源端在发出时会预设一个值，比如64或128，每过一跳就减1，归零时如果还没到dst就会报ICMP错（不管请求的是TCP或UPD甚至就是ICMP协议）。目的是防止IP在路由的过程中遇到环，通过这种方式阻断循环路由。\\n\\nIP层的典型协议编码\\n\\n* ICMP: 1\\n* TCP:  6\\n* UDP:  17\\n\\nICMP有8字节头，如果是request再多32(windows)或48(android)字节的无意义数据。\\n\\n利用IP的TTL特性，可以检测到dst的所有节点。原理就是依次从源端向dst发出TTL只有1、2、3...的ICMP包，TTL为1的包在第一个转发节点会回复ICMP错，TTL为2的包在第二个转发节点回复ICMP错，直到最后一个成功到达的包，通过这种方式就能得到dst的完整链路。\\n\\n额外说下，正常要发送ICMP要用`SOCK_RAW`，但apple的系统要用`socket(AF_INET, SOCK_DGRAM, IPPROTO_ICMP);`。\\n\\n## 实战连接github\\n\\n在Alpine的虚拟机中，git clone失败，问题分析后记录如下。\\n\\n最开始怀疑是路由错误，但包可以下载说明不是这个问题。又尝试ping 163仍然失败，看来是DNS问题，虚拟机的路由 /etc/resolv.conf 改为家中路由的地址，可以ping通163，但github仍失败。\\n\\n浏览器可以上github，说明没被墙，用独立的域名解析网站分析，对应多个IP，逐个尝试发现部分可以部分会超时。说明浏览器会尝试多次，而命令行只试第一个。\\n\\n在/etc/hosts手动加入条目解决。"}'));jctx.push(JSON.parse('{"id": "190902", "tag": "os", "text": "# Fushsia：一次对操作系统的重构\\n\\nFushsia是对Windows操作系统的一次重构。\\n\\nObject的组织方式已经深深的刻进了Windows的骨髓里，同为微内核设计的Fushsia毫不避讳的继承了这个设计。\\n\\n操作系统的发展过程就是Windows和Linux不断的从不同的角度发现自己的局限性，并且从各自的角度出发来试图解决这些局限性的过程。在这个发展的过程，无数的弥补措施和新机制被发明，但是Windows和Linux都要兼容老的东西。Windows演进的过程积累下来的最重要的经验就是微内核应该怎么设计，Linux演进的过程积累下来的主要是稳定性和隔离行等容器化的要求，这一方面Windows也在不断的跟进。Android在内核之外设计了一个大型的操作系统组件，Android与Linux的配合是如此的丑陋，因为Android相当于想在应用层做掉一个内核不该做的事情。\\n\\n每一个操作系统都在痛苦的迭代，各自面临着自己的痛点。Linux的世界对于权限和隔离性非常重视，但是apparmor，selinux，cgroup等后来逐渐添加的机制又与最初的设计那么的不相符。安全方面既然发现ACL的优势，为何还要用户的权限概念？隔离性记性不同的资源可以分组隔离，为什么还要统一的fork继承？Windows以图形见长，窗口和游戏性是Windows的公认优势，那他的优势又是如何塑造的？又如何打造一个类似的呢？简单的说是因为驱动闭源，但是深层原因还是比较复杂。\\n\\nAndroid像是一个试验性系统，他希望达到Windows在图形方面（宽泛的说是硬件支持）上的优势，同时又羡慕Linux的富功能集。他从一开始就知道自己不会长期依赖Linux，否则java这种架构就不会被采纳。如果我要评价Android，就是Android更多的是一个架构层面的DEMO，验证的是操作系统的架构设计思想。至于实现，差不多能支撑这个架构设计就好了。验证这个过程，他的内核只能采用Linux，没有更好的选择。但是谷歌一直认为Linux做了太多不该他做的事情了（很多人都这么认为），其实根本原因还是认为过度的开源协议妨碍其他人赚钱了。\\n\\nFushsia一出手就是一个Android的下层替换。但是这个替换并不是代码上的，而是架构层面的。谷歌在战略方向比较少走废棋，他希望能在各个领域进行推进的同时，大家都尽可能的朝向同一个大目标前进。这个目标，就是一个开源形式的垄断Windows。在整个开源世界里，谷歌希望上下游通吃。这种做法必须要各个细分领域都要有谷歌的拳头开源产品，互相依促，互相借鉴，互相帮扶，共同前进。\\n\\n首选第一个选择是微内核还是宏内核。这个基本没有任何争议。作为一个公司之间的玩具，互相解耦是第一位的。想要快速产业化，允许参与者独立变更，微内核几乎是唯一选择。宏内核在Linus之前，没有人敢想到能成功。直到今天，这个宏内核能走多远，也没有人能把握。宏内核需要一个独裁者，他提纲挈领，乾纲独断。在你走偏的时候，能直接把你的路封掉。整个Linux世界，离开Linus本身，没有任何人有这种威信（想象一下皇帝驾崩三个儿子怎么治理国家）。\\n\\n部门之间，公司之间，都是微内核更合理。微内核是一种社会性的内核，宏内核是一个技术性的内核。要说性能，微内核无论如何也不可能击败宏内核，因为宏内核相当于任何一个细分变更都需要整合测试。任何一个细分都在整体的框架内变更，包括架构风格甚至编码风格。\\n\\n所以很容易想到的理想操作系统的样子是Android的设计架构+微内核。这个微内核就直接借鉴Windows的成功经验就好，Windows的设计代表目前商业操作系统的最高水平，没有产品层面经久不衰的成功经验的任何团队，都不会敢在微内核的设计上抛弃Windows的设计，最多是先学习，后想办法超越。包括现在的鸿蒙，其微内核的架构也一定是类似的。\\n\\nWindows的典型微内核架构是Object设计。内核管理的资源都是一个一个的Object，打开每个Object都有对应的Handle。微内核中还必须要组织进程线程之类的调度单元，这种操作系统一路发展下来沉淀出来的架构不可能被一个新系统直接抛弃，除非他想像IBM 360一样的下场。安全性是附加在Object上的。微内核包括的要保证是必须要包括并且只能被包括的，典型的是ring 3的特权代码。为了达到所有ring3代码在微内核运行的目标，很多周边架构就必须要设计进内核。比如进程线程等是CPU的直接资源使用单元，调度这个事情到底是设计到用户空间还是内核空间？这个并不一定有确定的答案，但是Fushsia选择了放在内核，那么就代表了进程间的通信机制也必须要在内核里面。Windows已经增加用户空间的调度接口，但是也并不意味着微内核就撒手不管了。操作系统是一个在安全性，易用性和符合社会组织方式的发展过程中一起动态变化的一个过程。\\n\\nWindows下一个非常精彩的设计是Event，Linux下类似的设计是signal。两个可以说完全不一样，但是从哲学层面又有很多相似的地方。谷歌经过深入的思考和实践，认为两者是可以结合的。状态，事件，信号这三个东西，本身可以抽象为Object和Signal，Event三种互相结合的模型。每个Object都有32个信号集，Event也是一个Object，可以说是最简单的Object，他里面只有32个信号集。所以的Object的信号集的变化就代表他们状态的变化。也就是说，信号与状态协调成一个概念，就是一个Object所持有的信号集，信号的发生就可以是事件的发生，几个不同的设计被谷歌经过精简和联动设计，提取他们的核心本质，保留他们的各自优点，就形成了Fushsia的Object和Signal模型。\\n\\nWindows下的安全也是Object的属性，Fushsia在微内核层次完全抛弃了Linux的用户权限概念，改为了Windows的Object权限。甚至更激进的让整个虚拟化建立在Object权限之上（更确切的说是Object对应的HANDLE）。Linux下的最大抽象是一切皆文件，微内核的经验是一切皆Object，包括进程这个单位。很多Fushsia的系统调用都要传入一个进程的HANDLE，这个HANDLE就决定了这个系统调用有没有权限继续下去。Windows最新的成果是虚拟化和沙箱技术的重度迭代，Fushsia从设计层面就直接做到了。所以说Fushsia更像是一个没有包袱的Windows系统的重构，保留了Windows的大部分优点。\\n\\nFushsia在很多地方有不同的想法。例如Windows中饱受诟病的进程间互写内核成为很多安全问题的摇篮。但是进程间互相传递HANDLE又是Windows下一个很好用的资源传递的功能。在Linux下一个被打开的资源想要传递给另外一个进程，早期除了fork是没有方法的，后面出现了SCM技术，就是通过Unix Domain Socket来直接传递fd。因为你不能默认需要传递资源的环境都是父子进程关系。Linux一个很大的设计问题就是太过依赖父子关系，Windows的问题又是因为太过不依赖父子关系，导致进程间缺乏有效的组织。近期的Windows版本已经很注重进程间关系的组织，或多或少的引入Linux下的进程关系树模型。双方在靠拢的过程中，都有一些逐渐的对原生设计的一些违背。导致整个操作系统看起来不太和谐。这个问题在Android系统中被谷歌刻意的放大了。因为Android系统重度的依赖Binder，Binder是一个试图让各个进程可以很方便的通信交换资源的设计，这个设计对Linux来说是强人所难。对Linux的要求有点过于激烈。Linux对于资源的进程隔离一直是一个很重要的发展方向，Android反其道而行，要求进程之间大门敞开。阅读Binder的代码就能很容易的知道这个系统做的是多么的艰难。反而Binder在Windows上就很容易实现，LPC是如此的高效，进程间可以方便的把自己的HANDLE写入到另外一个进程的内存，资源的传递几乎是没有什么成本的。但是直接写对面进程的内核对于权限和并发又带来了复杂性。所以Fushsia既然是Android架构的落地，自然重度的依赖这个特点。于是Fushsia直接将Golang中成功实践的Channel的思想在Fushsia中落地。传递HANDLE，只需要把HANDLE放进Channel中，原进程自动失去该资源，Channel对面的进程自动获得该资源。\\n\\n这里面就有一个问题，就是内核块本身也是资源，也是可以有HANDLE的。Linux下这种哲学几乎没有体现，Android为了落实他的架构，非常艰难的设计了ashmem，用内存文件系统生硬的设计了带有handle的内核块。Windows的底层内存管理是带有HANDLE的，叫做Section，一个Section是64KB的大块。但是Windows在往上层暴露的时候，仍然没有选择直接把section直接给用户用，而是进行了封装。但是微内核中就是section和其对应的HANDLE的方式。该方式被证明了可以同时管理内存块和文件映射，还可以向上提供更高层的内存分配机制。对于Android对HANDLE资源转移的渴求，没有理由不去学习Windows的Section机制。Fushsia比Windows走的还远，并没有直接采用Windows的section，而是创造性的设计了pager和VMO，VMAR这几种对象。同样是基于对象的，将连续内存和页更灵活的进行了对象的抽象，克服了Windows下的granulary固定的问题（默认64KB）。正是因为更机制化的对象化，整个设计中没有添加策略属性，所以就可以把策略上升到微内核之外。也就是说，操作系统的服务部分应该去负责整个的内存管理，但是内存的颗粒度对应的是内核中的硬件Object。这又是一个对于Windows下内存问题的一个巨大的改善设计。\\n\\nWindows下对任务的组织采用job，进程，线程，纤程四个维度。这一点也是完胜Linux下绕口的Session组，进程组，线程对应内核进程等一大堆看起来非常别扭的添砖加瓦。Fushsia同样是在Windows的基础上进行增强。进程组织成job，进程下有线程。\\n\\nWindows下还有一个让人印象深刻的设计，就是Completion Port。当有大量的事件发生的时候，Completion Port将其抽象为对一个HANDLE的发送数据包消息。对比Linux，类似的事情使用epoll，ppoll等事件集合机制，Completion Port在设计上非常的干净。同样的思想直接被Fushsia采用，并且进行了“本土化”实现。\\n\\n在锁这件事情上，从Linux环境工作久了再切换到Windows，会明显的感觉Windows的设计非常差。Linux作为一个服务端市场占有率第一的操作系统，其对并发问题的处理是非常好的。这里是指技术层面，而不是架构层面。一个最大的优势是Linux把所有的锁实现都抽象成一个对futex系统调用的依赖。Futex的实际意义其实跟锁没有任何关系，只是一个等待条件并且唤醒对应的线程的机制，也就是一个单纯的线程的同步机制。Linux成功的做到让各种各样的锁都依赖一个简单的同步机制来达到实现目的。如此好的抽象正式Fushsia要学习和借鉴的。而Windows下，Mutex，CriticalSection，RWLOCK等使用过程，跨进程还是进程内，不同的性能表现，全部是黑盒并且各自独立的。这显然不是一个微内核该有的样子。但是Windows的微内核是否提供类似futex的机制支撑上层锁的实现，这个我不清楚，没有逆向看过。反正我对Windows下的锁设计是不太喜欢的。\\n\\n调度算法上，操作系统产业界都逐渐的往Fair Scheduling过度，尤其是Linux。Fushsia不能参考Windows的，因为细节没人知道，Linux长期的工程实践已经证明可行性。要知道，早期的Linux调度是动不动就被挨骂的。走到现在积累下来的经验不容易。\\n\\n隔离，是现在Windows和Linux都在面临的一个问题，服务端先对隔离性发起重度需求，需求来的猛烈程度，可以用革命性需求来形容。一时间，Linux虚拟化技术雨后春笋，蓬勃发展。因为Linux先于Windows几年支持了这件事情。一切竟然归因为机缘巧合下Linux一个一度被认为没有什么意义的LXC虚拟化技术的产品化创意。你可以说出一大堆的Linux发展虚拟化的优势，但是没有LXC这种被嫌弃的技术作为铺垫，很可能第一个Docker都没有勇气发布，也就没有之后的春天。Windows近年来奋起直追，试图追赶并超越Linux在虚拟化上的优势，同时伴随自己的UWP技术对隔离性的强烈需求，Windows创造了属于自己的隔离化，并且试图侵蚀Linux的阵地。WSL技术的发展也不遗余力。Fushsia看到了虚拟化的威力，Android的经验已经告诉了谷歌，不但是服务端，客户端对隔离性的要求指挥更强，因为Fushsia的隔离性是一个深入骨髓的设计，体现的非常彻底的整个架构的隔离性重构。典型的，连我们熟知的操作系统级别的文件系统都没有，没有根目录，每个进程为单位只能看到自己的私有目录。完整的去掉了Fork，这一点连Windows都要对之敬畏。Windows还是允许Object在进程创造之间进行继承的，所以说Windows是对fork概念的选择性支持，但是远远没有Linux的全量继承那么过分。Linux下的子进程要对父进程进行减法，一些变动会导致减法经常的没有减到位，就会有很多的安全问题。Fork的设计就不是为了隔离性而设计的，相反，他是完全共享数据甚至逻辑通道的。是一个完全的反隔离设计。Fushsia对此进行了完全的重新设计，新建的进程是干干静静的容器。类似Windows的新技术UWP，完全的沙箱，从底层杜绝了逃逸的可能。Windows也会非常羡慕Fushsia可以没有历史包袱直接进行非常激进纯粹的沙箱设计。\\n\\n其他的类似的领域还有TLS，DMA，日志，中断等。都在在以Linux和Windows，Android使用过程中的一系列需求和他们蹩脚的满足方式找到一个使用和架构的最佳平衡进行的重新设计。可以说Fushsia的Zircon微内核是一个最能匹配当前所有场景应用的架构设计。系统调用数量非常少，Linux一直在精简，但是历史包袱严重，Windows的微内核让人无法区别系统调用的层次，导致API非常混乱。Zircon开了一个好头，提供了系统调用集，但是又把大量的工作交给了服务。服务也是Windows上落地非常好的一个概念，是微内核的必备的匹配组件。Android的架构设计了大量的服务，例如SurfaceFlinger，Zygo等，Linux下缺乏对服务的有效表达。因为宏内核的很多本应该是服务的逻辑单位被做成了内核线程，但是又做的不全。Linux的宏内核自己做了大量的服务，但是又做的不够全，也不可能全，还是需要用户空间的服务来补全。例如systemd等试图统一的把Linux的服务组织起来，但是各种target和启动流程，服务管理，依赖关系，把整个系统搞的无比复杂。我个人对Linux的服务面的设计一直是嗤之以鼻，因为一直有个Windows的对比在。不过Windows的服务也不能说没有问题。很多流氓软件利用服务做了很多影响体验的事情，苹果在这一方面就控制的非常好。可以说Windows是一个设计和实现在架构层面都非常优秀的系统，但是反应速度太慢，远不如Linux的适应性。而且微软公司本身对这个系统的控制性不强，导致有时候用户被流氓软件控制了。而苹果就太强，所有人都感觉被苹果控制了。Android的设计是一个平衡，隔离性，控制性都刚刚好。它可以由一个OEM进行强控制，也可以通用性的完全不控制。是一个很灵活的社会化设计。反观Windows类似概念的企业版，组织能控制的东西非常有限，并且基本上应用也只是公司的内部。类似的组织交付能力，微软不愿意给任何人，所以过度开放。不过近期有所收紧。苹果也是不愿意给任何人，所以采取了过度收紧。\\n\\n谷歌畅想的，是一个能屈能伸，能开源，能赚钱，能让自己赚钱，能让别人赚钱的大社会型架构。谷歌非常深刻的知道开源模式的力量，也知道闭源世界的强大影响力。更多的社会属性是让谷歌脱颖而出的最重要因素。因为他“接地气”。\\n\\n在驱动层面，Zircon甚至开放了用户程序中断处理的系统调用，内核层面相当于直接对驱动进行应用层委派，但是又不是给应用程序，而是给DDK，一个专门的允许闭源闭源驱动存在的框架。Android给谷歌带来的一个最大的收益，是对驱动世界的深入了解。DDK就是这种提取升华，然后重新落地的设计。我一直认为Windows是Zircon的架构学习对象，Linux是一个很好的验证算法逻辑的对象，也是一个不错的教材。Android则是一次尝试，一次架构设计的验证和社会性的学习积累。目标都是最后的大一统设计。整个Fushsia的核心IPC调用接口是FIDL (or \\"Fuchsia Interface Definition Language\\") ，这种描述性的IPC表达方式简直与binder如出一辙。Component，capbility和manifest的概念也正是Android验证的开发模式（capbility这个说不清楚有没有参考Linux）。随着Flutter的逐步推广，Fushsia的模型有效性正在由Android和Windows一步一步的验证。文件系统这个点是Linux和Windows都称不上是做好的。Fushsia有自己的设计，但是是否足够好，我无法评价。恐怕要等实际的落地才能知道。IO这个点，Windows无数败笔，Linux的电梯和缓存设计也称不上是优良，Fushsia一定可以做得更好，毕竟重新设计，完整参考。但是能好到哪里去，我觉得得后面再看。比如Android用到的ashmem，在Windows下同样功能要模拟会痛不欲生，在Linux下也是依赖已有的tmp文件系统来的。Fushsia就直接出现了MemFS这种量身打造的文件系统。Volume Manager这个在Linux上实现的非常好，但是在Windows上又惨不忍睹。Fushsia也进行了重新设计。Mount的挂载概念是Linux上的一个基本功能，这个设计是如此的优秀，现在的Windows也开始学习，Windows在进入虚拟化领域的时候发现把一个文件系统挂载到别的磁盘的目录的必要性，也产生的对应的技术。这种被一个系统发明（也不能说是Linux发明的），被Windows都采纳了的设计，Fushsia自然也不会错过。网络文件系统在Linux和Windows中实现的都不算好，但是又各有千秋，WSL中对9P协议的应用被谷歌注意到了，但是9P的落地又变成了一个延迟很高的纸上谈兵。Fushsia类似的发展路线，用了现在Windows和Android都有的描述性接口和建立连接的概念进行IO设计，效果如何有待评价。我是十分担忧会重走9P的覆辙。Windows和谷歌内部有很多过于重视架构完备性的理想主义工程师，已经做出来很多“神奇的”作品了。其架构水准之高很多时候都可以掩盖实现之丑陋。但是在性能层面，却是掩盖不了的。性能过程，大部分情况下，就是一个不断破坏架构优美的破坏性过程。我是做性能的，这句话我是真的深有体会。\\n\\n显示是Linux领域的一个最大败笔，好在有Android挽回一些，但是也是付出了巨大的努力。Windows引以为傲的显示是从Directx到驱动，从软件到硬件的深度定制合作产生的。这种通常都有非常大的商业动机。Linux本身不具备这种动机，手机具备。Fushsia对于这种决定生死的领域自然是非常看重，在Android积累的大量渲染经验，让Fushsia充分意识到渲染部分的独立性。Android对SurfaceFlinger的设计和游戏本体渲染的隔离，让传统的单线程渲染非常笨重。这种架构天然是过渡期的产品，Vulkan和Directx12本身就是对这种架构的抛弃。渲染子系统本身就要负责任务的调度和内存的管理，这是现代渲染架构都已经认清的问题了。从架构层面或者操作系统过多的干预渲染过程，坏处远远大于好处，因为渲染是一个性能第一的领域，你的架构再优美，在性能面前也有强烈的放弃动机。在Vulkan和Directx12这种命令队列缓存和任务调度，内存管理高度策略化的发展浪潮下，Fushsia作为一个新时代的操作系统自觉的对渲染作出让步。让渲染子系统能够承担越来越多的自主性工作。不但如此，Direct Compute等显卡计算技术，已经让CPU调度层面认识到计算方面的不足，计算在未来也会可以预见的更多的交给渲染管线。CPU本身和GPU之争，在软件层面出现了第一次的控制权让步。\\n\\nFushsia是一个新时代的操作系统，他的诞生几乎是建立在Windows和Linux的痛苦的基础之上的。变化的是需求，架构能不能更好的适应快速变化的需求是一个操作系统长期发展的重要保证。现在Linux和Windows都已经老态龙钟，但却仍然在坚持更新，不断的一次一次的创新和突破满足社会的需求。Windows和Linux像两个兄弟，社会对操作系统的需求Windows扛不住的时候Linux顶，Linux顶不住的地方Windows顶。双方在迭代的过程中终于逐渐的在领域层进行了划分。与其说是Linux更适合服务端，Windows更适合客户端，不如说是Linux在满足需求的过程中选择了去优先满足服务端，甚至把嵌入式都快丢掉了。Windows在选择满足需求的过程中选择了优先去满足客户端。两个都看着对方的地盘不肯放弃希望。\\n\\nFushsia建立在两个操作系统发展，定位的过程中，博采两家所长，进行的站在巨人的肩膀上的重新设计。这次，不是DEMO，用的也不是java。这次，谷歌的目标是终极。他想要在此终结操作系统的争论。我相信鸿蒙的设计不可能超脱Fushsia之外，要是天天吼着脱离时代的吊打那显然不是这个时代的人。没有人能超脱时代而存在，技术的演进必须要在已有的技术基础之上进行哲学层面，设计层面，实现层面的创新。如果说Fushsia是对Windows和Linux的创新，我相信鸿蒙应该是在Fushsia的哲学基础之上进行创新。因为没有理由谷歌的总结，实验和发现得到的优质财产鸿蒙不去继承。在这个基础之上进行修改才是合理的选择。凭空而出的不同架构，完全重写。我个人不在赞成也不太相信。等他开源看吧。\\n"}'));jctx.push(JSON.parse('{"id": "190907", "tag": "data", "text": "# SQL的行转列与列转行\\n\\n## 行转列\\n\\n指把键值关系表（如从BerkleyDB导入的数据），变成围绕一个中心元素的详细表（列通常会很多）。就从原始的很多行的KV数据，变成行数很少（因为有重复）但很宽的形式，所以叫行转列。case when和group by是典型写法\\n\\n```\\nselect name,\\n  max(case course when \'math\' then score else 0 end) math,\\n  max(case course when \'phy\' then score else 0 end) physical\\nfrom rel_score\\ngroup by name;\\n```\\n\\ncourse列被case多次，从而实现从窄表变成宽表。我把这种一个列变成多个列称为影分身，行转列一定伴随着影分身。\\n\\n### 利用Hive的map类型实现 up 23.05.06\\n\\n需求是从轨迹表，计算出每个实体在每通道的每小时出现总次数。\\n\\n第一步先得到行表： `GROUP BY id, channel, from_unixtimestamp(captime, \'yyyy-MM-dd HH\')` 。注意GROUP BY只能支持expr，不能用alias，所以最后的udf结果不能as，需要在SELECT时候重新写一遍再as hh，不确定会不会优化掉。\\n\\n第二步对第一步的行表再做一次 `GROUP BY id, channel, substr(hh, 1, 10)` 接着在SELECT中，使用collect_list(substr(hh, -2) || cnt)把小时标记，和每个小时的次数拼接成array。接着再用str_to_map(concat_ws(array))把array变成标量的map值。得到包含 id, channel, map 的行表，此时的map有最小1个最多24个kv对，已经基本达成目的了。\\n\\n最后一步就是从map分别取出24小时，再用nvl将不存在的值转成0。\\n\\n整个过程中，最难想到但也最妙的自然就是第二步，利用collect_list这个UDAF函数再结合map类型，将每个分组的内容放在一行内，使一维行表具备更高维度的内容（但似乎也破坏了范式？），从而为最后一步平铺准备好了素材。不过这个方法强依赖引擎，像SQLite只能支持group_concat一种UDAF，并且没有map类型。勉强能用group_concat构造出json，也能凑合实现，但不如Hive这么方便。\\n\\n## 列转行\\n\\n指把定义很宽的表（即列很多），变成每行只有A、B键值对的形式。经过这样的转换，行的数量会大大变多，所以叫列转行。union是典型写法\\n\\n```\\nselect name, \'math\' course, math as score from lika\\nunion\\nselect name, \'phy\' course, physical as score from lika\\norder by name, course;\\n```\\n"}'));jctx.push(JSON.parse('{"id": "190912", "tag": "security", "text": "# SASL、GSSAPI和Kerberos的理解\\n\\n## SASL\\n\\n网络协议和认证虽然是不同的领域，二者往往会结合使用。在SASL出现前，两者的组合是乘积关系，SASL使两者解耦，组合的数量变为和的关系。由于SASL的目的是解耦，所以并不包含网络功能，并不承担数据传输功能，只有得到数据后才开始进行处理。同时它又不负责具体的认证，所以种种认证实现都是是SASL插件的方式存在。\\n\\n使用最广的SASL实现是Cyrus版本（翻译过来是古波斯的居鲁士大帝），从库分布也能看出，主体框架是libsasl2.so，而各种具体实现libcrammd5.so、libdigestmd5.so放在插件目录下。\\n\\n支持的验证机制包括但不限于：getpwent、kerberos、pam、rimap、shadow、ldap\\n\\n## GSSAPI\\n\\n作用和SASL接近，适用场景有些不同。对LDAP来说，两者都适合，但对HTTP认证来说，SASL的流程有些啰嗦，使用和GSSAPI一脉的SPNEGO就更合适。由于GSSAPI产生得比较早，因此和Kerberos结合地更密切（甚至可以说是唯一的实现机制），其中GSSAPI定义开发语言的API，而Kerberos负责具体网络通信和加密过程。\\n\\n## Kerberos\\n\\n实现用得最多MIT的版本（Heimdal有，微软有个非兼容版本SSPI，而AD则是KDC和LDAP的结合体），协议在RFC定义。理念和用途与TLS不一样，krb用于多点间协同，全部使用对称加密算法，依赖参与者依赖中心点KDC，而TLS依赖非对称加密和数字证书，解决两点间通信问题。\\n\\n微软的NTLM据说是对标，用在域控管理密码和认证。但没有c和s间的互动。\\n\\n由于kerberos的实现有多种，接口不统一，GSSAPI的C语言接口定义有RFC背书，且`libgssapi_krb5.so`，即对kerberos的封装，也是我所见仅有的实现绑定，所以两者可以认为是一样的。而适配到SASL会稍麻烦。\\n\\nKerberos的认证过程可细分为三个阶段：初始验证、获取服务票据和服务验证。第一阶段：客户端向KDC中的AS发送用户信息，请求TGT，请求内容会用客户端的密钥做对称加密，由于KDC有客户端的密钥（可以是KDC给客户端，也可以是客户端告诉KDC，总之kerberos的理念就是必须信任并且把密码让KDC知道）。第二阶段：客户端拿着之前获得的TGT向KDC中的TGS请求访问某个服务的票据。第三阶段：拿到票据（Ticket）后再到该服务的提供端验证身份，然后使用建立的加密通道与服务通信。\\n\\n* KDC：Key分发中心（key distribution center），是一个提供票据（tickets）和临时会话密钥（session keys）的网络服务。KDC服务作为客户端和服务器端信赖的第三方，为其提供初始票据（initial ticket）服务和票据授予票据（ticket-granting ticket）服务，前半部分有时被称为AS，后半部分有时则被称为TGS。\\n* AS：认证服务器（Authentication Server），KDC的一部分。通常会维护一个包含安全个体及其秘钥的数据库，用于身份认证，保证客户端确实存在于KDC的密码库中。\\n* TGS：许可证服务器（Ticket Granting Server），KDC的一部分，根据客户端传来的TGT发放访问对应服务的票据\\n\\n由于KDC机制严重依赖与密钥，所以自带数据库管理工具krb5\\\\_util和kadmin。\\n\\n目前主流的中心式密钥分发，一个是Kerberos认证，像windows域控制器认证方式；另一个是Cisco GetVPN，KDC被用于分发TEK（Traffic Encryption Key)。\\n\\n## 认证流程\\n\\n1. AS认证：\\n\\n员工Alice首先到认证中心KDC报道，KDC给了Alice两只信封，一只信封A装的是Alice-KDC session key ，以及Alice ID、IP、时间戳相关信息，用KDC的密码加密，Alice不能打开，待会转交给TGS就够了。\\n另外一只信封B是用Alice的密码经过Hash做了加密，里面装着临时密钥Alice-KDC session key ，Alice用自己的密码，解密得到Alice-KDC session key。如果Alice是假冒的，自然打不开信封B，无法访问网络资源。\\n\\n2. TGS认证：\\n\\n当Alice想访问服务器S，要向TGS出示两个证件：\\n信封A和信封C。其中，信封C里面装有Alice ID、服务器S等信息，用Alice-KDC session key 加密。\\nKDC用自己的密码解开信封A（因为AS和TGS在一起），获得Alice-KDC session key，用它解开信封C。KDC检验证件合格，于是准备出票。\\n\\nKDC把票递给Alice，是两个信封：\\n信封D，里面装有Alice-S session key、Alice-TGS session key，用服务器S的密码加密，Alice不能打开，待会转给服务S。\\n信封E，里面装有Alice-S session key信息，用Alice-KDC session key加密\\n\\n3. Service认证：\\n\\nAlice解开信封E，得到Alice-S session key，并用它生成信封F，里面包含Alice ID和时间戳，来到服务器S 的面前，出示信封D、F。\\n服务器S用自己的密码解开信封D，得到Alice-S session key，然后再用它去解密打开信封F，获得信封里的Alice ID等认证信息，认证通过后，Alice访问服务器资源就用Alice-S session key了。\\n\\n## 协议交互\\n\\n程序分为C和S端，S端又分工具类和守护类。工具类有kadmin.local, `kdb5_util`等负责管理用户。注意kadmin可以让管理员在KDC之外的主机远程操作，不过最好还是在KDC上用kadmin.local。数据库以BerkeleyDB方式保存。守护类有kadmind，krb5kdc，这两个必须都启动才能正常工作。kadmind监听749和464端口，749负责admin，464负责修改密码。krb5kdc监听88端口。\\n\\nC端调用kinit principal，会找pricipal对应的KDC并获取initial credentials和TGT，服务端返回加密报文后，命令行会提示输入密码，如果正确的话，klist就能看到，退出用kdestroy。\\n\\nkinit的交互信令通过UDP发给KDC的AS，端口88。含AS-REQ和AS-REP两个报文。REQ包含标明身份的明文client name和realm，以及请求的server name(默认krbtgt)。\\n\\n输入密码只适用于交互，如果要程序化必须利用keytab方式，就是在KDC侧用kadmin.local的xst指令把某个principal的密钥导出并发给客户机，kinit用-kt选项就免去输入密码这步。默认导出了keytab后，用户密码会变，相当于以后就只能用keytab登陆了。\\n\\n## 身份标识\\n\\nprincipal标识惟一身份，格式是 `<username>/<group>@<REALM>`，比如root/Admins@HOME.COM。username也叫primary，是必填项，可以是linux下的用户名；group也叫instance，用户可以不填，服务必须有；realm可以不填，会从krb5.conf查找默认的域，如果有多个域就必须要写上。每个 realm 可以有私有配置，包括 KDC 的地址和加密的算法，都可以独立存在。有些大型公司会创建一个独立的 realm 来分发管理员的权限。\\n\\nKeytab 是一个包含了（若干）principals 和一个加密了的 principal key的文件。一个 Keytab 文件每个 host 都是唯一的，因为 principal 的定义了包含了 hostname 。这个文件可以用来认证，而不需要传递公开的密码，只要有这个 Keytab 就可以代表这个 principal 来操作。"}'));jctx.push(JSON.parse('{"id": "190913", "tag": "data", "text": "# PostgreSQL备忘\\n\\n其前身是由Stonebraker创造的ingres（1974）和postgres（1986），Postgres和ingres在90年代之前都不支持SQL，而是用的自己的QUEL语言。他的几个学生在1996年改写了postgres来支持SQL，和他没有直接关系。Stonebraker因为前两个系统对于数据库的贡献得了图灵奖。\\n\\nPostgreSQL功能完备但速度稍慢，国内一直不流行。1997年发布6.0版，之后大约每5年更新大版本，到2017年的版本10开始每年更新一次大版本。\\n\\n## 启动和命令工具\\n\\n后台命令是`pg_ctl`，是postgre或postmaster(采用多进程模型，主进程叫master，不过现在合一后，都叫postgre了)的封装，postgre用-C并指定选项名可以查看配置。启动停止状态监控都是它。创建数据库用环境变量指定PGDATA或者参数指定，比如~/pgdata且必须是空目录，接着用`pg_ctl init`或initdb初始化这个目录。会创建若干子目录和默认配置文件，模板和结构定义，有39M（版本不同稍有差异），默认创建名为postgres的数据库。\\n\\n使用`pg_ctl start`会启动监听TCP和Unix Domain两种方式，如果不想用PGDATA环境变量，就用-D指定数据库位置。默认只能在同一台主机上用psql访问 ，要想跨主机访问，要修改postgresql.conf的listen\\\\_address改为`\'*\'`和pg\\\\_hba.conf的IPv4地址改为\'0.0.0.0/0\'。初看这种启动时指定目录的方式有点不习惯，但细想可以在一台机器上启动多个完全不干扰的库，非常灵活。\\n\\n客户端连接用 psql -d postgres，如果不指定数据库，会使用登陆用户名作数据库名。\\n\\n## 概念和特色\\n\\n库-模式(schema)-对象3级结构组织。对象包括表、视图、序列、函数等。由于连接数据库时，会有默认名为public的schema，不注意的话会误以为库下面是表。\\n\\n特有的表空间TABLESPACE概念。默认有`pg_default`和`pg_global`两个表空间。分别保存在$PGDATA目录下的base和global目录，base占了初始空间的一半还多。表空间用于描述表在物理介质的存储方案，创建数据库时可以指定属于哪个表空间。\\n\\n安装完成会有3个初始库，template1, postgres, template0，其中template1是最源头的模板，另两个是从它复制得到的。因为template1允许用户修改，所以增加只读的template0表示纯净的数据库。这3个库分别对应PGDATA/base/下的3个目录，每次新增数据库，如果用默认表空间，就会在base目录下新增一个目录，目录名是oid数字，通过`select datname, oid from pg_database`能查出映射关系。\\n\\n创建一个空的数据库，目录内会初始创建数百个数字命名的文件，可以用`select relname, relfilenode from pg_class`查看每个文件的表名。有些数字文件会以fsm或vm结尾，分别对应free space map和visibility map。同样这个语句，如果加上`where relfilenode=0`会展示全局的表名。\\n\\n命令行叫createuser，但psql中是role，似乎是等价的。修改用户密码`ALTER USER postgres WITH PASSWORD \'postgres\';`"}'));jctx.push(JSON.parse('{"id": "190918", "tag": "os", "text": "# 进程线程和协程的切换开销\\n\\n测试Context Switch time(进程上下文切换时间) ，创建两个进程(实时进程)并在它们之间传送一个令牌，如此往返传送一定的次数。其中一个进程在读取令牌时就会引起阻塞。另一个进程发送令牌后等待其返回时也处于阻塞状态。发送令牌带来的开销与上下文切换带来的开销相比，可以忽略不计。 (利用管道传递令牌)\\n\\n## 测试程序(1)\\n\\n```\\n#include <stdio.h>\\n#include <stdlib.h>\\n#include <sys/time.h>\\n#include <time.h>\\n#include <sched.h>\\n#include <sys/types.h>\\n#include <unistd.h>      //pipe()\\n\\nint main()\\n{\\n    int x, i, fd[2], p[2];\\n    char send    = \'s\';\\n    char receive;\\n    pipe(fd);\\n    pipe(p);\\n    struct timeval tv;\\n    struct sched_param param;\\n    param.sched_priority = 0;\\n\\n    while ((x = fork()) == -1);\\n    if (x==0) {\\n        sched_setscheduler(getpid(), SCHED_FIFO, &param);\\n        gettimeofday(&tv, NULL);\\n        printf(\\"Before Context Switch Time %u us\\\\n\\", tv.tv_usec);\\n        for (i = 0; i < 10000; i++) {\\n            read(fd[0], &receive, 1);\\n            write(p[1], &send, 1);\\n        }\\n        exit(0);\\n    }\\n    else {\\n        sched_setscheduler(getpid(), SCHED_FIFO, &param);\\n        for (i = 0; i < 10000; i++) {\\n            write(fd[1], &send, 1);\\n            read(p[0], &receive, 1);\\n        }\\n        gettimeofday(&tv, NULL);\\n        printf(\\"After Context SWitch Time %u us\\\\n\\", tv.tv_usec);\\n    }\\n    return 0;\\n}\\n```\\n\\n测试结果(进程切换时间不超过5us)\\n\\n```\\nBefore Context Switch Time 617087 us\\nAfter Context SWitch Time 702420 us\\n\\n702420us - 617087us = 85333 us\\n85333us / 20000    = 4.26665 us\\n\\n进程切换时间为4.26665 us\\n\\n注： cpu MHz         : 2801.042\\n```\\n\\n## 测试程序(2) 使用rdtsc()获取当前时间\\n\\n```\\n#include <stdio.h>\\n#include <stdlib.h>\\n#include <sched.h>\\n#include <sys/types.h>\\n#include <unistd.h>\\n\\nlong long rdtsc()\\n{\\n    __asm(\\"rdtsc\\");\\n}\\n\\nint main()\\n{\\n    int x, i, fd[2], p[2];\\n    char send    = \'s\';\\n    char receive;\\n    pipe(fd);\\n    pipe(p);\\n    struct sched_param param;\\n    param.sched_priority = 0;\\n\\n    while ((x = fork()) == -1);\\n    if (x==0) {\\n        sched_setscheduler(getpid(), SCHED_FIFO, &param);\\n        printf(\\"Before Context Switch Time %lld\\\\n\\", rdtsc());\\n        for (i = 0; i < 10000; i++) {\\n            read(fd[0], &receive, 1);\\n            write(p[1], &send, 1);\\n        }\\n        exit(0);\\n    }\\n    else {\\n        sched_setscheduler(getpid(), SCHED_FIFO, &param);\\n        for (i = 0; i < 10000; i++) {\\n            write(fd[1], &send, 1);\\n            read(p[0], &receive, 1);\\n        }\\n        printf(\\"After Context Switch Time %lld\\\\n\\", rdtsc());\\n    }\\n    return 0;\\n}\\n```\\n\\n测试结果(进程切换时间不超过5us)\\n\\n```\\nBefore Context Switch Time 16208184381648\\nAfter Context Switch Time 16208424333213\\n\\n16208424333213 - 16208184381648 = 239951565(clock cycle)\\n239951565      * 0.357009998 ns = 85665107.74074687 ns\\n85665107.74074687 ns / 20000    = 4283.255387037 ns = 4.283255387037 us\\n\\n注： cpu MHz  : 2 801 042 000Hz\\nclock cycle = 1 000 000 000 ns / 2 801 042 000 = 0.357009998ns\\n```\\n\\n## 测试程序(3) 可直接获得进程上下文切换时间\\n\\n```\\n#include <stdio.h>\\n#include <stdlib.h>        //drand48()\\n#include <sched.h>\\n#include <sys/types.h>\\n#include <unistd.h>\\n#include <sys/time.h>      //gettimeofday()\\n#include <time.h>\\n\\ntypedef unsigned long long u64;\\ndouble clockCycleTimeS,clockRateHZ;\\n\\n/* 获取当前时间，返回秒 */\\ndouble second() {\\n    struct timeval tv;\\n    gettimeofday(&tv,0);\\n    return tv.tv_sec + 1e-6 * tv.tv_usec;\\n}\\n\\n/* 获取当前时间，返回clock cycle */\\nu64 rdtsc() {\\n    u64 tsc;\\n    __asm__ __volatile__(\\"rdtsc\\" : \\"=A\\" (tsc));\\n    return tsc;\\n}\\n\\n/* 睡眠us微秒 */\\nvoid selectsleep(unsigned us) {\\n    struct timeval tv;\\n    tv.tv_sec = 0;\\n    tv.tv_usec = us;\\n    select(0, 0, 0, 0, &tv);\\n}\\n\\n/* 计算当前CPU的工作频率 */\\nvoid calibrate() {\\n    double sumx = 0;\\n    double sumy = 0;\\n    double sumxx = 0;\\n    double sumxy = 0;\\n    double slope;\\n    const unsigned n = 30;\\n    unsigned i;\\n\\n    for (i=0; i<n; i++) {\\n        double breal,real,ticks;\\n        u64 bticks;\\n\\n        breal = second();\\n        bticks = rdtsc();\\n        selectsleep((unsigned)(10000 + drand48() * 200000));\\n        ticks = rdtsc() - bticks;\\n        real = second() - breal;\\n\\n        sumx += real;\\n        sumxx += real * real;\\n        sumxy += real * ticks;\\n        sumy += ticks;\\n    }\\n    slope = ( (sumxy - (sumx*sumy) / n) /\\n              (sumxx - (sumx*sumx) / n) );\\n    clockRateHZ = slope;\\n    clockCycleTimeS = 1.0 / slope;\\n    printf(\\"%3.3f MHz\\\\n\\", clockRateHZ*1e-6);\\n}\\n\\nint main()\\n{\\n    calibrate();\\n\\n    int x, i, p1[2], p2[2], time[2];\\n    char send    = \'s\';\\n    char receive;\\n    u64 old_time;\\n    pipe(p1);\\n    pipe(p2);\\n    pipe(time);\\n    struct sched_param param;\\n    param.sched_priority = 0;\\n\\n    while ((x = fork()) == -1);\\n    if (x==0)\\n    {\\n        sched_setscheduler(getpid(), SCHED_FIFO, &param);\\n        old_time = rdtsc();\\n        write(time[1], &old_time, sizeof(old_time));\\n        for (i = 0; i < 10000; i++) {\\n            read(p1[0], &receive, 1);\\n            write(p2[1], &send, 1);\\n        }\\n        exit(0);\\n    }\\n    else\\n    {\\n        u64 new_time;\\n        sched_setscheduler(getpid(), SCHED_FIFO, &param);\\n        for (i = 0; i < 10000; i++) {\\n            write(p1[1], &send, 1);\\n            read(p2[0], &receive, 1);\\n        }\\n        new_time = rdtsc();\\n        read(time[0], &old_time, sizeof(old_time));\\n        printf(\\"Latency time = %3.3f us\\\\n\\",\\n                1e6 * (new_time - old_time) * clockCycleTimeS / 20000);\\n    }\\n    return 0;\\n}\\n```\\n\\n测试结果(Linux-2.6.21 + RealTime Patch) Latency time = 8.129 us\\n\\n2801.226 MHz\\n\\n## 协议的意义和测试\\n\\n前面用实验的方式验证了Linux进程和线程的上下文切换开销，大约是3-15us之间（）。这个开销确实不算大，但是海量互联网服务端和一般的计算机程序相比，特点是：\\n\\n* 高并发：每秒钟需要处理成千上万的用户请求\\n* 周期短：每个用户处理耗时越短越好，经常是ms级别的\\n* 高网络IO：经常需要从其它机器上进行网络IO、如Redis、Mysql等等\\n* 低计算：一般CPU密集型的计算操作并不多\\n\\n即使3-15us的开销，如果上下文切换量特别大的话，也仍然会显得是有那么一些性能低下。例如之前的Web Server之Apache，就是这种模型下的软件产品。（其实当时Linux操作系统在设计的时候，目标是一个通用的操作系统，并不是专门针对服务端高并发来设计的）\\n\\n为了避免频繁的上下文切换，还有一种异步非阻塞的开发模型。那就是用一个进程或线程去接收一大堆用户的请求，然后通过IO多路复用的方式来提高性能（进程或线程不阻塞，省去了上下文切换的开销）。Nginx和Node Js就是这种模型的典型代表产品。平心而论，从程序运行效率上来，这种模型最为机器友好，运行效率是最高的（比下面提到的协程开发模型要好）。所以Nginx已经取代了Apache成为了Web Server里的首选。但是这种编程模型的问题在于开发不友好，说白了就是过于机器化，离进程概念被抽象出来的初衷背道而驰。人类正常的线性思维被打乱，应用层开发们被逼得以非人类的思维去编写代码，代码调试也变得异常困难。\\n\\n于是就有一些聪明的脑袋们继续在应用层又动起了主意，设计出了不需要进程/线程上下文切换的“线程”，协程。用协程去处理高并发的应用场景，既能够符合进程涉及的初衷，让开发者们用人类正常的线性的思维去处理自己的业务，也同样能够省去昂贵的进程/线程上下文切换的开销。因此可以说，协程就是Linux处理海量请求应用场景里的进程模型的一个很好的的补丁。\\n\\n背景介绍完了，那么我想说的是，毕竟协程的封装虽然轻量，但是毕竟还是需要引入了一些额外的代价的。那么我们来看看这些额外的代价具体多小吧。\\n\\n协程切换CPU开销测试，测试过程是不断在协程之间让出CPU。Go代码如下。\\n\\n```\\nfunc cal()  {\\n    for i :=0 ; i<1000000 ;i++{\\n        runtime.Gosched()\\n    }\\n}\\n\\nfunc main() {\\n    runtime.GOMAXPROCS(1)\\n\\n    currentTime:=time.Now()\\n    fmt.Println(currentTime)\\n\\n    go cal()\\n    for i :=0 ; i<1000000 ;i++{\\n        runtime.Gosched()\\n    }\\n\\n    currentTime=time.Now()\\n    fmt.Println(currentTime)\\n}\\n```\\n\\n总的来说线程切换的时间和协程的比值约是**几十倍**，线程切换在10us级别，协程在1us以下。"}'));jctx.push(JSON.parse('{"id": "190921", "tag": "lang", "text": "# JS的单线程和运行时\\n\\nJS的单线程特性(eventloop)不仅体现在浏览器上，node同样，二者的运行逻辑可能有区别。所以别的语言常见的sleep函数，都必须要用setTimeout配合Promise迂回实现。\\n\\n运行中遇到回调，会根据类型放到两种不同的回调队列。\\n\\n1. 脚本主体逻辑，创建Promise，设置定时器，又叫宏任务\\n2. Promise回调，process.nextTick，DOM变化，又叫微任务\\n\\n宏队列至多执行一个任务，就去检查微队列，直到微队列空了，事件循环会判断并做UI重绘。重绘后回到宏任务继续执行一次，如此循环。node没有UI，但同样遵守微任务批量宏任务单个的原则。\\n\\n应用最广的是Promise/A规范，属于Promise，又隶属于CommonJS。构造Promise对象传入1个两参函数，形如 Promise(function(resolve, reject))，resolve和reject都是单参函数。构造Promise时必须要执行完executero才会返回，所以new Promise动作是阻塞的，ES7增加的await则把构造Promise对象的阻塞动作给异步化。\\n\\nPromise初看起来是callback的语法糖，但最本质的区别是解耦数据的生产和消费。因为callback方式，必须在发送请求时就指定要执行的动作，而Promise的构造返回的值是代理对象，这个过程中只产生数据（如发送ajax请求），怎么处理等后续挂上then或catch方法，在then或catch方法中处理。then 方法中的回调是**异步执行**的，典型的实现方式是prototype.then的实现中，用\\n\\n```\\ntimer = setInterval(()=>{ if (this._state == \'full|reject\') { clearInterval(timer) } }\\n, 0)\\n```\\n\\n的方式不停地循环检测state状态，直到改变就执行resolve或reject方法。状态只能从pending变成fullfiled或reject，一旦状态改变后，定时器就会取消，也不会再触发回调。\\n\\n通过async关键字，把普通函数用Promise包装起来，如果直接调用async函数，得到的当然是Promise对象，如果用await方式调用，就能得到Promise之后的值。"}'));jctx.push(JSON.parse('{"id": "190926", "tag": "security", "text": "# SSL和SSH比较\\n\\n两者都是常见的安全术语，安全包含四层含义\\n\\n* 数据加密，即抓包不可读，看上去是乱码，这个最好理解，也最直观\\n* 数据完整性，这是第二个层次，即数据虽然被加密了，但万一被人篡改了怎么办？又或者数据没有收发完整怎么办？数据完整性解决的就是这类问题\\n* 身份验证，这是第三个层次，刚接触安全的话也许不会注意。虽然数据加密了，也有完整性校验了，但怎么知道发消息给你的人，就是你期望的人？直白的说类似证明**你妈是你妈**，比喻可能不太合适，但目的是一样的。\\n* 不可抵赖性，A做过的承诺，只要做了数字签名，就无法反悔。\\n\\n二者都能很好地完成前两层，但只能SSL可以实现身份验证。由于ssh自身没有认证，所以ssh和Kerberos的结合就是顺理成章的事了。Kerberos用于解决一套大系统内的身份识别、数据加密。因此在使用场景上存在很大差异。\\n\\n## 协议背景\\n\\n从名字就可以看出使用了不同的协议。解决的是两点间的加密防窥、互信。SSL和SSH都是基于公钥认证，SSL的出发点是让客户端确保服务端是可信的，而SSH反过来，让服务端确保客户端可信。尽管理论上SSL也扩展了互相认证的机制，但实际中我还没有见过SSL这方面的应用。\\n\\nSSL是会话层协议，其上可以承载各种其它协议，典型的比如HTTPS，我在公司做过一个私有协议全链路加密也是over SSL的。SSL的版本有V2、V3(V1版本因为存在重大安全缺陷，并没有公开过)。后续则更名为TLS，从V1.0->V1.1->V1.2->V1.3。因为SSLv3的漏洞被证明不再具备安全性，至少也是从TLS起使用比较好。SSLv2版本的协议和v3之后的格式上有很大不同，因此OpenSSL代码里特地有一种称为v23的方法，就是使用v3可以回落到v2。至于v3到TLS则沿用同样的总体结构(采用TLV格式)，版本号也一脉相承地从0x0300到0x0304。\\n\\nSSH是个特定应用的协议，就我所知仅远程终端操作，隧道和文件传输功能。仅有v1和v2两个版本，而且v1已经几乎绝迹。我想不明白为什么SSL的版本一直在演进而SSH却不动了。\\n\\n## 交互流程\\n\\nSSL采用客户端主动发起模式，交互采用Client-Hello、Server-Hello、Change-Cipher等过程。\\n\\nSSH在TCP连接建立后，Server端和Client端互发一段明文字符串消息SSH-2.0-xxx，xxx代表软件名字，不规定发送顺序。接着Client Key Exchange Init的流程。SSH在交互开始，服务端会把自己的公钥（注意：不是证书）给客户端，客户端工具会提示用户，第一次客户只能选择相信，如果想长期使用，就写入`known_host`文件，所以客户端不具备认证服务端的能力，只能识别变化。使用的工具和版本不同，协商算法不同，指纹也会不同，比较新的版本会协商出ssh-ed25519，老版本是ssh-rsa，dsa或ecdsa。算法生成的公私钥长度从大到小顺序RSA > DSA > ECDSA > ED25519（严格的说，RSA私钥比DSA长但公钥短，另两个全方位得短）。不管哪种都表示成MD5或SHA256值，很难记住。ssh-keyscan专门用于探测公钥，也是ssh2e协议但message code略有不同。\\n\\nssh协议在进入加密传输阶段后(ssh-keyscan得到公钥就结束，不会进入这个环节)，每个包结尾都会带上mac验证数据，带宽无法百分百的用于传输，但为了校验完整性，这点损失只能接受。\\n\\n## 身份验证\\n\\nSSL为了证明服务器是真实可信，需要给出服务器一些信息才行，便是经常听到的数字证书。直观的可以这么理解，你去拜访某个大佬，但又不知道是不是被人乔装，于是你向面前这位大佬采集了指纹，接着把指纹发到公安局，询问是否是本人，公安局如果给出肯定的答复，就可以放心地聊下去了。\\n\\n证书包含公钥和一些持有者的信息（比如域名、公司名等），与之对应的必然有一个私钥文件。两者构成了SSL服务端的必备文件。如果用OpenSSL工具生成的话，后缀名是.pem。pem可以通过普通的文本编辑器打开，是RFC1421定义的一种格式，首行和尾行是标示文件类型，中间部分是经过Base64之后的数据，因为这个特性，可以通过cat命令把多个证书文件串在一起也是可以使用的。解码后的二进制数据是符合规范，通过OpenSSL的对应命令字可以看内容。比如\\n\\n* openssl x509 -in 公钥名.pem -noout -text\\n\\n可以看到数字证书的公钥、签发者等信息，把x509换成rsa，再打开私钥文件则可以看到RSA的公私钥和计算因子。\\n\\nssh不具备证书功能，因此ssh-keygen只能生成公私钥对。openssl和ssh-keygen生成的私钥格式一样，但公钥格式差别很大，好在ssh-keygen可以把openssl的格式转换成ssh的，详细看ssh-keygen的-m选项。\\n\\n## TLS密钥的来源\\n\\n文件内容是对称加密，其密钥采用会话加密机制，不会重用。这个密钥的生成机制有3步\\n\\n1. premaster key。客户端生成随机数，用服务端的RSA公钥加密后传回服务端（先不考虑DH方式）。这里还有个要点，premaster的前两位是TLS的协商版本，一旦服务端解密后发现这个版本比client hello的版本高，说明会话被劫持，可以拒绝协商，防止降级攻击。\\n2. master key。联合premaster key和客户端、服务端互换的随机数，一共3个随机数，生成固定长度的密钥。（猜测是用hash机制）\\n3. session key。以master key为种子，通过密钥衍生算法，生成最终的加密密钥。"}'));jctx.push(JSON.parse('{"id": "191020", "tag": "protocol", "text": "# HTTP协议历史与细节\\n\\n## 来源\\n\\nLee在1980年时，便在CERN构建ENQUIRE系统，构建这个系统的经历，促使他在1989年3月开发了HTTP最早的版本0.9，当时还只是Lee在CERN的试验产品，直到1997年才发布了如今使用最广的1.1版本。巧合的是CGI版本也在同年正式归档RFC并发布1.1版（CGI起草于1993年，由于其目的就是解决HTTP的动态能力不足，当然晚于HTTP）。\\n\\n和WWW万维网有一定相似性的Gopher协议诞生于1991年，可以说和HTTP的历史相当，技术上两者区别很大：Gopher使用分层结构，而HTTP则使用链接系统。\\n\\nHTTP协议诞生时，也有其它协议，比如邮件、FTP、新闻组等协议，但这些协议都无法承载链接系统，因此Lee最终决定开发新的HTTP协议。正因为HTTP是小字辈，因此body内容的类型是从邮件标准抄的，形式上用/划分大小类别。历史上邮件发展要早得多，发送附件的需求也更迫切。\\n\\n重定向3XX至少有5个值，广泛接受的是301和302。\\n\\n* 301: 永久重定向，会影响爬虫，浏览器书签的行为，将域名改为新地址，节省下次访问时间\\n* 302: 暂时重定向，暗示会恢复，可用于临时性关闭服务\\n\\nRange头可以跳过并只传输一部分，但前提是服务器首先要在响应里用Accept-Range:\\nByte 表示支持。一旦开启会用206表示Range响应。\\n\\n语义规定在一个连接上前一个请求没完成后面的请求不会被处理，所以有了多连接，最早的RFC规定只有2个连接，但浏览器都不遵守，后来RFC只好从事实去掉了连接上限。\\n\\n## HTTPS代理\\n\\n直连的HTTPS肯定是全部加密，但如果中间要经过代理，代理就没法转发了，有两种模式\\n\\n1. CONNECT报文\\n\\n客户端发现目标网址是HTTPS且要经过代理，就会先发送CONNECT请求，并带上host和port，当对端连接上后，返回HTTP/1.1 200 Connection Established，注意不是200 OK。紧接着，代理端会尝试去连目的端，成功后代理就会建立HTTP隧道，这个隧道中流转着代理将收到的请求消息原模原样发往目的端的数据。代理除了知道目标地址外，不会获取其它内容。\\n\\n2. SSL之SNI\\n\\n利用TLS/SSL握手的第一个Client Hello报文中的扩展地址SNI (Server Name Indication)来获取。这种模式不会出现CONNECT请求，隐蔽性更好。"}'));jctx.push(JSON.parse('{"id": "191021", "tag": "lang", "text": "# 从openresty谈到rust\\n\\n大概是2015年，我开始关注nginx，在这之前，我一直从事C++的网络开发工作（通信网的信令协议栈研发，还有CORBA框架的实现），大概有七八年吧，都沉浸在C++的世界里，没有接触过什么更高级更现代的语言。开眼看世界也是最近三四年的事情，惭愧。\\n\\n接触到nginx，很自然注意到了openresty，觉得很不错。nginx代码我拜读过，觉得实现得很优化，例如http解析就用了2000多行来做，充分考虑了时空性能。当时候nginx是声名在外。openresty引入了lua，封装了cosocket，使得能在nginx的基础上很简单地做二次开发，并且因为luajit，二次开发的性能代价很小。总而言之，当时候觉得openresty十分得惊艳，进而也膜拜章亦春大神。\\n\\n当时工作有点乏味，然后也有点心思想跳槽，但是想到自己这七年来都是独孤一味地钻研C++相关的底层项目，感觉自己缺乏竞争力，所以很想学点东西，于是想到可不可以我也写一个http框架呢？luajit本身的ffi很厉害，不需要codegen就可以动态加载并访问任何C库函数，它的jit性能也很高，luajit的作者，Mike Pall也是编译器的翘楚，所以我想，可否我连nginx本身也用lua来重写呢？同时我对上提供openresty一样的api，这样所有*-resty的第三方库就可以直接拿来用了。这种思路类似于linus当年编写linux内核一样，对内重写，对外兼容POSIX，使得app可以直接拿来重用，例如bash。\\n\\n重写的工作很有趣，有很多挑战，例如我要用纯luajit来实现cosocket。openresty的cosocket，非阻塞和select都在nginx的C层面，所以每次陷入阻塞读写的时候，会先yield到C层面。另外，openresty的协程是有父子关系的，表现在一次http请求由一个父协程来处理，它生成的其他协程（一般用来访问外部资源，例如redis），则是其子协程。父协程可以等待（或者同时等待多个）子协程，而父协程退出后，子协程也会退出。纯luajit没有C的承托，所以只能通过lua的exception来做，通过特殊的异常抛出和捕获来实现openresty的cosocket。还有一个有趣的地方，就是nginx的热重启，是通过保留文件描述符并且通过父子进程的环境变量来透传重现的，用纯lua来做，并且还考虑linux的信号处理，则要费了一点心思了，但最后还是做出来了，当时候心情很愉悦。\\n\\n这个重写最终发布的开源项目就是 http://luajit.io ，这个名字也很有意思，一方面，这是一个我申请的io后缀的域名，另一方面它也是项目的名字，io框架嘛，一语双关。各种实现细节肯定不如nginx这般精致，所以性能不会达到nginx这么好，有80%就足够了，做出来后也符合我的预期。用20%的性能换取更简单的代码实现，我觉得已经很有意义了。试想，nginx和openresty的C代码加起来这么多，而我用lua重写，只有区区5000多行代码。\\n\\n发布后，收到了不少关注。不过，我也就是当一个玩具工程来练手罢了。我后来再反思，其实cosocket虽然惊艳，但是并非一枝独秀，golang就完整实现了协程化，不仅仅socket，文件访问和cpu密集型任务都可以融入到协程里面来做，所以golang具有更完整意义的cosocket。\\n\\nopenresty受欢迎，我觉得很大程度得益于它站在了巨人的肩膀上，那就是nginx和luajit。但是更好的事物都有时代的局限性。我这里展开来说一些它们的缺点。\\n\\n先说nginx吧，nginx是多进程架构，每个worker进程（单线程）公平地去抢夺进来的tcp连接，独立处理每个tcp连接上的http请求。socket读写非阻塞，每个worker进程都有一个selector来select所有socket。处理一个http请求没有进程间切换意味着更好的性能。但多进程也有弊端：\\n\\n在接受连接后就只能固定在一个进程里面，如果恰好该进程所处理的连接里面的http请求很多很繁忙，那么它也无法委托给其他进程来代劳，即便其他进程是空闲的，对于http2而言，我觉得这一缺点尤为突出。\\n多进程之间无法安全地共享资源。nginx的方案是放数据在共享内存里面，例如openresty的queue就是放里面的，并且通过放在共享内存里面的pthread mutex来同步。但是弊端很明显，对共享内存的操作不是原子的，例如上锁后，要对共享内存里面的红黑树做remove操作，那么对应的C代码就不少，对应到共享内存上，就有很多步操作，那么如果进行操作的进程异常退出，那么就会留下一个无法收拾的局面。例如，上锁后退出，资源就一直处于加锁状态，其他进程无法获取继续访问，这个还比较容易观察和调试出来。一般多进程系统都需要一个父进程来清理残局，但nginx没有这样做。\\nworker进程是单线程，无法用它来做CPU密集型任务或者磁盘IO任务，nginx为了解决这个问题，引入worker thread pool，但openresty很难利用这个新特性，因为受限于lua虚拟机只能支持单线程的事实，如果利用，线程间交互以及数据拷贝是很大问题。\\nnginx本身只是一个平台，一个特定的平台，起来一个http server给你让你处理http请求，并且能做的实现依赖于nginx导出了什么api给你，所以有时候你很难施展拳脚去适配自己的项目，例如我访问kafka，要作为它的consumer，那么就没法做了，因为没法作为server给kafka调用。\\n而且nginx最著名的特点：性能，也并非一枝独秀，目前rust就完全可以追上它，我后面会提到。\\n\\n好了，再来说一下luajit，作者确实是一个天才，我那段时间看了很多他写的文章，他的各种理论都是如此高深莫测，他的dynasm可谓解放了汇编开发的生产力，而luajit更是让人佩服。用lua来写业务逻辑，很自然会担心性能，相比官方原生的lua的解释器性能和C不是一个等级，luajit的jit弥补了这一点，使得你既可以用lua很高兴很轻松写代码，又不必过分担心性能代价。但是，有如下问题：\\n\\n最大的问题是lua版本的分裂，自lua5.2后，很多地方不再和官方lua兼容，并且长期停留在5.1上，作者没有意愿去改变这个局面。\\n源码实现太复杂，几乎只有Mike Pall自己才能维护它，但作者近几年来的开发活跃度很低，几年来都没发布2.1的正式版本，长期停留在beta，不知道他在忙什么。Mike Pall似乎早就说过要找接班人，但好像一直找不到。\\n你写的lua代码要极力去适配luajit的脾胃，才能让luajit给你实现编译，才能真的达到高性能，先不说如何调试适配是多么痛苦的事情，就说你适配了，你的代码有时候也变得很丑陋很怪异，例如要用tail call去替代循环。我写 http://luajit.io 的时候就深有体会。没错，如果jit得好，那么甚至有时候会比C更快，之所以更快，你可以认为是经过了profile适配（PGO）的C比普通的C快。但是你要极力去优化，使得有很高的编译通过率才行，这一点就不是每个人都能做到，是一个明显的心智负担。尤其对于大型项目而言，留心费神去优化每一行代码是不现实的。说白了吧，普通的C写出来有80%的好性能，但普通的lua写出来不调优，就只能有50%甚至更低的性能（虽然luajit的解释器也很快，但再快比C还是差了一大截）。所以jit，很多时候只是镜花水月而已。\\n终于说到openresty了。作者章亦春也是一个大神，它的coscoket在当时来说还是很前卫的概念。我就冒昧来谈谈它的缺点：\\n\\nopenresty的所有功能源自nginx，也就受限于nginx。而nginx只是一个特定平台，不是一门语言，所以可扩展性是有局限性的。再进一步说，nginx是用C写的，扩展模块也要用C写，openresty之后就要用lua来写的（openresty就是为了提高生产力出现的），但lua本身是一个极其简单的嵌入式语言，没有自己的生态链，其功能完全依赖于宿主系统，在这里宿主就是openresty，也就是说，你能通过lua来做的完全取决于openresty提供多少api给你，没有给你的，你做不了，举个例子，我想开一个线程来做CPU密集的加密任务，没办法，因为没API给你。但如果是一门语言，那么你想做什么就做什么。\\n你不能调用阻塞的lua api或者C函数，或者做一些CPU密集型的任务，或者大量读写文件，因为这样会阻塞nginx的worker进程的单线程，使得性能大幅度下降，而且很容易出现一些让开发者痛苦的事情，例如发现访问redis超时了，明明通过tcpdump看到redis的响应包及时到了，但就是超时，很矛盾很纠结，结果经过一番折腾后发现原来是因为做了一些阻塞的事情，使得nginx的selector在处理io事件之前先处理了timer事件，使得socket明明有数据也被openresty的api报告超时。\\nlua和C之间的数据转换是一个overhead。由于lua的数据结构和C那么的不同，所以交换数据要互相拷贝。这一点对于http请求承载大量数据的应用来说很痛苦。例如我在K公司实现文件服务器的功能，这个文件服务器不能直接委托给nginx的file send，因为要对原始文件数据做处理，例如md5校验。这也是为什么openresty后面慢慢提供一些通过luajit ffi来实现的api接口，就是为了减少拷贝，提高性能。\\n无法实现高性能的缓存，因为luajit的string interning很死板，对每个字符串，不管是常量还是动态生成的变量，都统一经过内部的哈希表来存放和去重，其目的就是为了使得用字符串作为table的key时，加快查找速度，因为比对是否同一个gcobject即可。但对缓存逻辑是一个噩梦，因为每生成一个字符串都需要哈希操作，而缓存恰好会生成很多字符串，luajit的interning哈希表在海量字符串的量级下性能很差。我在k公司做的项目对此有很深的体会。\\n在我看来，openresty相比rust，最大的好处就是lua代码能被动态更新和替换，对于静态编译语言来说是不可能的（dynamic load可以，但dynamic unload是不行的，因为符号之间的引用关联实在没法很轻易解耦）。\\n\\n我2017年去K公司的时候，发现K公司很钟情openresty，很多项目都基于openresty来做，甚至公司还向openresty捐助过一笔小钱。但K公司的人是滥用openresty，在不知道其原理机制的前提下做了很多错事，很多项目其实不应该用openresty但也用。正如后来我去到E公司发现很钟情springboot一样，我觉得现在的公司很喜欢用一些品牌项目作为基础，或因其名气，或因其简单易入门，而不是具体问题具体分析，按项目实际需要来选型。\\n\\n我曾一度觉得golang是openresty更好的选择，但golang的http性能确实不好。直到最近这半年我对rust的研究，觉得rust才是未来。\\n\\ngolang的语言设计很简陋，而相比之下，rust很美很优雅。这里不展开解释。我只说一点，那就是golang从无到有自己实现一门语言，包括编译器完全自己来做，甚至连C库都抛开，直接封装系统调用，这是我最不喜欢的，为什么呢？\\n\\n无法充分利用这十几年来的社区成果，例如gcc和llvm，所以优化度很低，例如llvm的simd，它就无法享用。\\n和C互通代价太大，但很多时候C库是避不开的。\\n不兼容目前经典的调试器，例如gdb、valgrind、systemtap，而它自带的调试器功能相对简陋。\\n而rust呢？在语言特性上非常先进，例如通过ownership解决了C/C++的问题，还不需要付出gc的代价。并且充分利用社区成果，做好语言层面就好了，生成代码和链接代码就交给更专业的llvm，这样一来既专注在语言层面，提供更多更好的特性给用户（例如最近的await），和C互通又很低成本，因为它没有绕开C库。\\n\\ngolang的协程，在rust里面就是通过futrure/async/await来做，开发效率是一样的，运行效率更是胜于golang，因为rust的协程是在编译阶段解析生成的，所有栈数据是用heap上的struct/enum来包装，并且在所有suspend点做了drop，使得内存不需要像golang的协程栈那样在运行时增量分配，也不需要gc来干扰。\\n\\n我这两三年一直做golang的开发，尤其在K公司。例如这是我最近发布的开源项目，大家有空关注一下：\\n\\nkingluo/pgcat\\n\u200b\\ngithub.com\\n\\n但是我现在觉得rust才是未来，在我接下来的技术生涯里面我会phase out掉golang。\\n\\n最后，我给一个小例子来验证一下rust的性能。这是http server和hello world。\\n\\ngolang的实现：\\n\\n```\\npackage main\\n\\nimport (\\n    \\"net/http\\"\\n)\\n\\nfunc main() {\\n    http.HandleFunc(\\"/\\", HelloServer)\\n    http.ListenAndServe(\\":8080\\", nil)\\n}\\n\\nvar str = []byte(\\"hello\\")\\n\\nfunc HelloServer(w http.ResponseWriter, r *http.Request) {\\n    w.Write(str)\\n}\\n```\\n\\nopenresty的实现：\\n\\n```\\nworker_processes auto;\\nerror_log logs/error.log;\\nevents {\\n    worker_connections 1024;\\n}\\nhttp {\\n    access_log off;\\n    server {\\n        listen 8080;\\n        location / {\\n            default_type \'text/plain; charset=utf-8\';\\n            content_by_lua_block {\\n                ngx.print(\\"hello\\")\\n            }\\n        }\\n    }\\n}\\n```\\n\\nrust hyper：\\n\\n```\\nuse hyper::service::{make_service_fn, service_fn};\\nuse hyper::{Body, Request, Response, Server};\\n\\nasync fn hello(_: Request<Body>) -> Result<Response<Body>, Infallible> {\\n    let mut res = Response::new(Body::from(\\"hello\\"));\\n    res.headers_mut().insert(\\n        \\"Content-Type\\",\\n        HeaderValue::from_static(\\"text/plain; charset=utf-8\\"),\\n    );\\n    Ok(res)\\n}\\n\\nasync fn run_server() -> Result<(), Box<dyn std::error::Error + Send + Sync>> {\\n    pretty_env_logger::init();\\n\\n    let make_svc = make_service_fn(|_conn| async { Ok::<_, Infallible>(service_fn(hello)) });\\n    let addr = ([0, 0, 0, 0], 8080).into();\\n    let server = Server::bind(&addr).serve(make_svc);\\n\\n    println!(\\"Listening on http://{}\\", addr);\\n\\n    server.await?;\\n\\n    Ok(())\\n}\\n\\nfn main() {\\n    let rt = tokio::runtime::Builder::new().build().unwrap();\\n    rt.block_on(run_server()).unwrap();\\n}\\n```\\n\\nrust actix-web：\\n```\\nuse actix_web::{web, App, HttpRequest, HttpServer, Responder};\\n\\nfn greet(_: HttpRequest) -> impl Responder {\\n    \\"hello\\"\\n}\\n\\nfn main() {\\n    HttpServer::new(|| App::new().route(\\"/\\", web::get().to(greet)))\\n        .bind(\\"0.0.0.0:8080\\")\\n        .expect(\\"Can not bind to port 8080\\")\\n        .run()\\n        .unwrap();\\n}\\n```\\n\\n服务端运行在一个双核的服务器上，在同一局域网段的另一个双核服务器上运行wrk作为客户端来压测：wrk -c100 -d60s http://testserver:8080\\n\\n结果如下，从好到坏排列：\\n\\n1. rust actix-web\\n```\\n  2 threads and 100 connections\\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\\n    Latency   654.26us  226.01us  13.21ms   97.09%\\n    Req/Sec    73.74k     9.06k  123.48k    41.13%\\n  8810858 requests in 1.00m, 0.99GB read\\nRequests/sec: 146603.79\\nTransfer/sec:     16.92MB\\n```\\n2. rust hyper\\n```\\n  2 threads and 100 connections\\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\\n    Latency   786.47us  273.89us  16.47ms   92.97%\\n    Req/Sec    63.19k     2.39k   70.41k    67.67%\\n  7544745 requests in 1.00m, 0.85GB read\\nRequests/sec: 125738.24\\nTransfer/sec:     14.51MB\\n```\\n3. openresty\\n```\\n  2 threads and 100 connections\\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\\n    Latency   801.19us  353.80us  20.29ms   97.67%\\n    Req/Sec    62.05k     2.20k   67.38k    66.08%\\n  7409230 requests in 1.00m, 1.32GB read\\nRequests/sec: 123460.63\\nTransfer/sec:     22.60MB\\n```\\n4. golang\\n```\\n  2 threads and 100 connections\\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\\n    Latency     1.33ms  652.90us  22.42ms   68.23%\\n    Req/Sec    37.89k   712.77    41.19k    76.00%\\n  4523628 requests in 1.00m, 522.00MB read\\nRequests/sec:  75392.66\\nTransfer/sec:      8.70MB\\n```\\n\\n虽然这个小例子不算严谨，但性能结果之间的比例还是可以参考的。rust的actix-web最好，这个跟网上对actix-web的赞誉是一致的，但它唯一的缺点是在代码上还没过渡到async/await。而rust的hyper也不错，跟openresty的性能差不多，这已经让我觉得很舒服。golang性能最差，这符合我一直以来对它的性能预期。\\n"}'));jctx.push(JSON.parse('{"id": "191101", "tag": "os", "text": "# 子进程执行和信号\\n\\nsystem(2)调用子进程非常方便，返回类型int，但不是脚本真正的返回值，对待这个返回值，要先用WIFEXITED是否非0，非0表示成功，再用WEXITSTATUS取返回值。从命名上看，表示只有EXIT了，才能取STATUS。从数值角度看，返回值由低8位和高24位构成。我只见过低8位全0的情况，不知道什么情况下低8位不是0。\\n\\n有个类似的函数族execve，也是执行命令，但它会放弃当前进程空间数据，切换到待执行的进程，因此exec必须在fork出的子进程执行，好处就是不会阻塞，这也是shell下执行命令的机制。\\n\\n要想让执行中的进程停止，可以用信号量，kill如果不带参数，发的是TERM信号，不是KILL。TERM可以通过TRAP或函数方式捕捉，进而在被信号触发后做一些保存工作再退出，而KILL不能被捕捉，一旦收到必须退出，因此在关进程时，优先用kill，迫不得已再用kill -9。\\n\\n并不是所有信号都会使进程退出，像SIGSTOP和SIGCONT则是使进程暂停和继续，在STOP状态的进程只是暂停，不算异常，因此system还有个判断状态函数WIFSIGNALED表示非EXITED且非STOP才是被信号了。也可以用trap命令修改信号对应的行为（再强调一次，不能捕获KILL）。\\n\\n而termux有个bug，SEGV不一定能捕捉到，有时要第二或第三次才会退出。\\n\\nHUP信号，所有网上教程都说后台进程在终端退出时会被杀掉，所以要加nohup命令。实际测试并不是这样，不管是exit/logout或者直接断掉终端并不会使后台退出，只有手动kill掉这个会话的sshd进程，才会导致后台退出。实际中几乎没有人会刻意地找出这个sshd的pid，所以只进后台不用nohup在绝大部分场景下都没有问题。用`&`进入后台的进程，TTY编号会变成和前台不同但仍会绑定一个，exit的后台进程才会显示`?`。\\n\\n要解释这个问题，要从基本概念说起\\n\\n* terminal，简称tty，DEV号5,0。包裹着shell提供输入输出，可以有多个，类似电视的遥控器。有个系统函数`char* ttyname(int fd)`，会返回句柄所绑定的tty，实测0, 1, 2这几个标准句柄对应的tty是相同的（不确定是否有方式修改）。\\n* console，DEV号5,1。最早的主机在启动完成前不能接入terminal，在启动和关闭阶段的日志会在console上显示，可以是一些灯或磁碟机，至多一个，类似电视的面板按钮\\n* pty，虚拟终端，ssh就是网络化的pty。之所以会有这个概念，是因为terminal会在设备驱动和系统读写函数间，有一个内部的转换层，但网络化缺少了这层。为了保持一致性，将网络源也抽象为终端，像串口的波特率概念还保留，比如我测试结果输入输出的波特率都是38400。pty映射到软件上的实体是pts，unix特性，linux内核的2.1.93版正式支持该特性。对应devpts文件系统，一般挂在/dev/pts下。是个主从结构，主只有1个，名字固定为/dev/ptmx，DEV号5,2。从的名字从主获取，`df=open(\\"/dev/ptmx\\") or getpt();ptsname(df);`。从的名字格式是/dev/pts/xx，每增加一个虚拟终端就增加一个。\\n\\nhangup的原意是挂断电传打字tty，引申后就是pts即ssh，所以用exit只是退出shell，并没有关闭外覆的sshd，不触发HUP信号的原因就在于此。\\n\\n在安卓6上遇到ssh登陆后提示`PTY allocation request failed on channel 0`错误，可能是关闭了ptmx所致。这就会出现ssh连接成功后，只有bash内置命令(pwd)能显示出来，其它即便执行也看不到结果。\\n\\n## 容器化的应对\\n\\n容器鼓励只有1个进程，而普通的shell进程并不能转发信号，有两种做法\\n\\n1. 用exec把作为entrypoint的shell进程替换为真正的程序，适合redis/mysql用途单一的容器\\n2. 用dumb-init或tini等专有的容器化1号进程作为启动，代替系统级的1号进程init\\n"}'));jctx.push(JSON.parse('{"id": "191105", "tag": "os", "text": "# docker和OCI规范\\n\\n容器技术最初由Docker这个产品为大众所了解，Docker这个词是公司名，容器技术和工程化的混合。工程化上一个app一个容器是最大的创新，容器化技术最初被linus嘲笑50行脚本就能完成。随着使用日渐广泛，2015年6月，Docker、CoreOS等公司制定了OCI（Open Container Initiative）开放容器计划来规范标准。\\n\\n还有一个概念CRI和OCI很接近，这个概念源于k8s，因为调度系统最直接打交道的就是容器，所以必然也会对容器有约束，所以在2016年12月发布CRI规范，但从使用角度来看，可以认为两者是相同的。\\n\\n## 规范与层级\\n\\n* 镜像image: 一般是写dockerfile后制作得到，以文件形式存储在硬盘上，包含应用软件及依赖的运行时，做得好应该尽量小。从沙盒角度看，对java有一定替代性，且从最小依赖上说，C/Go语言才能保证镜像不引入无用的依赖。\\n\\n* 运行时container: 是镜像的运行实例，实例好比是类，容器则是对象。在做镜像的dockerfile里不会限制CPU、内存、网络等条件，在运行期指定外部的资源参数。运行时又分高层运行时和低层运行时。\\n\\n高层运行时包括我们熟知的Docker外，还有Containerd和CRI-O，随着k8s的1.24版本正式删除dockershim层，可以预见Containerd将会在未来成为主流的高层运行时。\\n\\n低层实现的参考实现是runC，是由Docker用Go实现并捐给社区的，其实在Docker之前，Linux社区是有lxc方案的，但因种种原因没有流行起来。runC从2016年的1.0-rc1版，直到2021年才发布1.0正式版，期间主要的特性是增加了cgroup v2的支持，并修复了多个CVE严重漏洞。\\n\\nDocker的本质是设置了namespace和cgroup参数的进程。是沙盒概念在linux上的具体实现，安卓上运行的每个app都是类似于Docker（底座换成dalvik）的实例。Docker公司将containerd和runc捐出后，剩下的只是命令行工具的使用接口。随后开始了从沙盒技术向hyper-v虚拟化转变。\\n\\n不同的docker子命令适用于不同的层级，要区分。rmi是删除image，而rm则是删除container。\\n\\n## 工具与运行\\n\\n采用C/S架构，dockerd是后台守护，docker负责向后台发命令，包括管理镜像，打新包，提交。守护进程会依次拉起多个程序，dockerd -> dockerd-current -> docker-containerd-current -> docker-containerd-shim。运行容器则依靠docker-runc。\\n\\n配置文件在/etc/docker/，采用json格式保存，大约和开发者比较新有关系。\\n\\n## 核心概念\\n\\n1. repo 仓库。为了分发的方便，在hub大市场里存放了很多仓库，每个仓库有多个tag版本，提供相同功能。不同tag间有区别和演进\\n2. image 镜像。仓库的某个具化的tag就是镜像，对应到磁盘上的一套文件结构，是静态概念\\n3. container 容器。镜像作为进程的底座被运行起来，此时整个进程就称为容器，是动态概念\\n\\n### 命令行操作\\n\\n* pull : docker pull xyz -> docker pull repo.addr/library/xyz:latest # 仓库域名不能有http://前缀，域名后面跟固定的library\\n* run : docker run -it 。创建并执行容器。pull拉下来的镜像，可能不是local，run命令会自动把远程镜像再同步到local\\n* start : run -it的镜像，有时在容器中执行exit会导致进程退出。但是container ID还在，用 start containerID 就能重新拉起\\n* exec : 已经start的容器不能用run，要用exec才能挂载到运行中的容器\\n* stop/rm : 停止然后删除容器\\n* save/export : 将镜像保存成tar文件，差别是save会带上一些元信息，而export则是纯粹的二进制文件\\n* load : 将tar形式的镜像加载到docker的本地仓库，在images列表中能看到\\n* commit : 将容器保存为新的镜像，不是每次操作都会产生新的层，具体原理不清楚\\n* history : 按时间序从上到下显示镜像层\\n* network : 查看，操作，销毁容器宿主网络\\n\\n## 镜像\\n\\n一个save的镜像解包后是这样的（docker24.0.5），如果是export，则对应layer.tar\\n\\n```\\nsha256_folder_layerN/          # 镜像由几层构成，目录就有几个\\nsha256_folder_layerN/VERSION   # 1.0\\nsha256_folder_layerN/json\\nsha256_folder_layerN/layer.tar # 这一层更新/删除的二进制文件\\nconfig_sha256.json\\nmanifest.json\\nrepositories  # 镜像、标签以及sha256_folder名，似乎只有一层镜像才有\\n```\\n\\n如果删除某个文件，在解压开的layer层体现为内容为空的隐藏文件 `.wh.<rmfile>` 记录，wh猜测是write hidden的缩写。\\n\\n## 网络\\n\\n服务端启动后，会创建名为docker0的网桥接口，用brctl show查看这个网桥的所有interface，通常启动几个容器就有几个veth网卡，同主机之间的veth是互通的。宿主机看不到这些veth的IP4地址，要进入容器才能看。\\n\\n## 磁盘卷\\n\\ndocker volume create your_name 创建一个卷，其实就是一个目录。在启动容器时，用 `docker run -v vol_name:/some/path` 指定后，容器里对/some/path的读写就不在unionFS，而落在宿主机的目录，实现持久化。\\n\\n## harbor\\n\\n为了存储镜像和相关产物，诞生了harbor项目。Harbor 2.0 成为符合 OCI（Open Container Initiatives）规范的开源镜像仓库，能够存储多种云原生工件（Artifacts），例如，容器镜像、Helm Chart、OPA、Singularity 等等，这些统称artifacts。\\n\\n## helm\\n\\n为了将多个docker镜像编排成一个大的应用，产生了helm。通过 Helm3 可将 Helm Chart 推送到 Harbor。 在 Harbor 2.0 中，Helm Chart 不再存储于 ChartMuseum 中，而是与容器镜像一样存放在artifacts中。"}'));jctx.push(JSON.parse('{"id": "191107", "tag": "protocol", "text": "# 目录服务和NetBIOS协议\\n\\n目录代表实体，可以是一个文件或某个人的信息，通常这些信息以树状形式保存，类似目录树。目录服务是按照树状信息组织模式，实现信息管理和服务接口的一种方法。目录服务系统一般由两部分组成：第一部分是数据库（一般是分布式数据库），且拥有一个描述数据的规划；第二部分则是访问和处理数据库有关的详细的访问协议。\\n\\n目录服务与关系型数据库不同的是，读非常快，但写比较慢，也缺少事务机制，是针对特定场景的特化机制。目录不支持批量更新所需要的事务处理功能，目录一般只执行简单的更新操作，适合于进行大量数据的检索；目录具有广泛复制信息的能力，从而在缩短响应时间的同时，提高了可用性和可靠性。目录服务技术的国际标准有两个，即较早的X.500标准和近年迅速发展的LDAP标准。\\n\\n## X.500协议族\\n\\nX.500不是一个单一协议，它是由一个协议族组成：\\n\\n* X.501模型强调目录服务基本模型和概念\\n* X.509认证框架是如何在X.500中处理目录客户和服务器的认证\\n* X.511 抽象服务定义X.500被要求提供的功能性服务\\n* X.518 分布式操作过程表明如何跨越多台服务器处理目录服务\\n* X.519 协议规范即是X.500协议，包括目录访问协议DAP、目录系统协议DSP、目录操作绑定协议DOP和目录信息Shadowing协议DISP\\n* X.520 选定的属性类型要求是X.500自己使用的属性类型\\n* X.521选定的对象类即为X.500自己使用的对象类\\n* X.525复制是如何在目录服务器之间复制目录内容\\n\\n这些X.500标准中主要定义有多种内容。一个信息模型：确定目录中信息的格式和字符集，如何在项中表示目录信息(定义对象类、属性等模式)；一个命名空间：确定对信息进行的组织和引用，如何组织和命名项——目录信息树DIT和层次命名模型；一个功能模型：确定可以在信息上执行的操作；一个认证框架：保证目录中信息的安全，如何实现目录中信息的授权保护——访问控制模型；一个分布操作模型：确定数据如何进行分布和如何对分布数据执行操作，如何将全局目录树划分为管理域进行管理——目录管理模型，客户端与服务器通信的协议—目录访问协议DAP，将用户请求在服务器之间进行链接所需的目录系统协议DSP，将选定的信息在服务器之间进行复制所需的目录信息映像协议DISP，用于自动在服务器之间协商连接配置的目录操作绑定协议DOP。\\n\\nX.500虽然是一个完整的目录服务协议，但在实际应用的过程中，却存在着不少障碍。由于目录访问协议DAP这种应用层协议是严格遵照复杂的ISO七层协议模型制定的，对相关层协议环境要求过多，主要运行在UNIX机器上，在许多小系统上，如PC和Macintosh上无法使用，因此没有多少人按照DAP开发应用程序，TCP/IP协议体系的普及，更使得这种协议越来越不适应需要。\\n\\n## LDAP协议族\\n\\nLDAP协议从1993年批准，产生了LDAP V1版本，随后于1997年发布了第三个版本LDAP V3，它的出现是LDAP协议发展的一个里程碑性标志，它使LDAP协议不仅仅作为X.500的简化版，同时提供了LDAP协议许多自有的特性，使LDAP协议功能更为完备，具有了更大的生命力。\\n\\nLDAP典型应用是保存用户名和账号，并用于大型系统的认证。协议自身是明文的，所以v3版本加入了SASL支持，结合kerberos可以对整个通信过程做到加密。\\n\\nLDAP V3协议也不是一个协议，同样是一个协议族。\\n\\n* RFC 2251——LDAP V3核心协议，定义了LDAP V3协议的基本模型和基本操作\\n* RFC 2252——定义了LDAP V3中的基本数据模式（Schema）（包括语法、匹配规则、属性类型和对象类）以及标准的系统数据模式\\n* RFC 2253——定义了LDAP V3中的分辨名（DN）表达方式\\n* RFC 2254——定义了LDAP V3中的过滤器的表达方式\\n* RFC 2255——LDAP统一资源地址的格式\\n* RFC 2256——在LDAP V3中使用X.500的Schema列表\\n* RFC 2829——定义了LDAP V3中的认证方式\\n* RFC 2830——定义了如何通过扩展使用TLS服务\\n* RFC 1823——定义了C的LDAP客户端API开发接口\\n* RFC 2847——定义了LDAP数据导入、导出文件接口LDIF\\n\\n这些协议主要定义了LDAP的内容，同时主要定义了一个信息模型：确定LDAP目录中信息的格式和字符集，如何表示目录信息(定义对象类、属性、匹配规则和语法等模式)；一个命名空间：确定对信息进行的组织方式——目录信息树DIT，以DN和RDN为基础的命名方式，以及LDAP信息的Internet表示方式；一个功能模型：确定可以在信息上执行的操作的通讯协议以及在客户端进行这些操作的API接口；一个安全框架：保证目录中信息的安全，匿名、用户名/密码、SASL等多种认证方式，以及与TLS结合的通讯保护框架；一个分布式操作模型：基于Referral方式的分布式操作框架；一个LDAP扩展框架：基于控制和扩展操作的LDAP扩展框架 。\\n\\n但在LDAP协议中尚未定义通用的访问控制模型和复制协议（对应X.500的映射协议DISP），尽管不同的LDAP厂商均实现了自己的控制模型和复制机制，但是LDAP标准的发展正集中在访问控制模型、复制协议（DUP）以及扩展操作上，这些扩展操作包括查询的分页和排序、语言标签、动态目录、LDAP服务发现等。\\n\\n## NetBIOS\\n\\n起因是有机器被人格式化，定位到某IP但未能锁定是谁。得知nbtstat可以反查并确认工号。\\n\\n此协议是IBM在1983年发布，微软85年实现，比较多见确实在win系统。仅适合用于局域网且不支持域名。最初的时候跑在网络切换，虽然后来也做了over ip但依然改变不了不能路由问题\\n\\n有自定义的帧头格式，和TCPIP更类似平级关系。\\n"}'));jctx.push(JSON.parse('{"id": "191110", "tag": "book", "text": "# 生命的河流\\n\\n原创： 布尔费墨\\n\\n1、要学会和害怕的感觉共处。因为它是你拒绝，躲避，不肯承认的部分。\\n\\n2、父母并没有死，他们还活在我们的身体里。我们也不会死，孩子们活着，就是我们活着。\\n\\n3、只有把生命活出超越肉身和个体的意义，一个人才能不会恐惧肉身的消亡，个体的消失。\\n\\n提问：布老师，我最近被一件事情深深地困扰。事情是这样的：我的父亲前一阵刚刚去世。从他发病到去世的将近一年中间，我一直照顾他，陪他去大城市求医治病。但是因为这个病比较严重，所以最好的医生也是无力回天。他去世之前非常的痛苦。我也特别的难受，因为我不能为他做什么。他去世以后，我经常做梦，梦见父亲临终前的样子，那一幕一直出现在我的梦里面，让我感觉到恐惧。我害怕自己的生命也会像父亲的一样痛苦地结束。因此最近我的精神一直处于很糟糕的状态。我想请问布老师，我应该如何走出来？\\n\\n回答：\\n\\n恐惧之所以会成为恐惧，是因为你不敢面对。正因为你不敢于面对生命的无常，死亡的苦痛，所以它们才会像魔鬼一样骚扰你，恐吓你。所以你要做的是理解它，面对它，与它共处，观察它，抚摸它，与它交流，对话。只有这样，你才能从恐惧和痛苦中解脱出来。\\n\\n如果你的痛苦来自于脑海中的一个声音，那么你就要用喉咙发出声音，和它对话，也可以和它争吵，大声喊出你的想法。如果是来自脑海中挥之不去的一行字，一个概念，你就要用笔把它写下来。如果来自于一个场景，一个样子，你就要把它画下来。你这样做了，慢慢的，你就会好很多。\\n\\n为什么要这样做呢？因为在对话、叫喊、书写和绘画的过程中，你会与你的感觉长时间的共处。在共处中，你将逐渐学会不去恐惧它，而是习惯它，接受它成为你的一部分。你接受了它，就不再会感觉到恐惧了。\\n\\n要学会和你害怕的感觉共处。因为它是你的一部分，是你一直拒绝，躲避，不肯承认的部分。我经常把一个人的心灵比喻成一个房子。给你恐惧的感觉，就是躲在你房子角落中的一个受伤的小动物。如果你无视它，躲避它，它就会骚扰你，攻击你，以求得你的关注。如果你肯花时间，不怕被它抓，被它咬，坐下来抚摸它，安慰它的情绪，它就会慢慢地不再对你抱有敌意。\\n\\n每一个人都会迟早面对死亡的恐惧。我见到过的，在这一方面做得最从容的人，是我的姥姥。她在生命的最后几年经常说：我的生命没有什么遗憾了，就是结束了也没什么问题。在临终前很久，在健康的时候，她就开始做自己的寿衣。我猜测，通过一针一线地缝制自己的寿衣，与自己对死亡的恐惧长时间的共处，她才会变得如此从容。\\n\\n每一次我在面对世间的险恶，人生的无常的时候，姥姥的这一份从容都在给我力量。有时候我觉得姥姥并没有死，因为她的血还流在我的身上，我活着就是她在活着。我们每一个人的生命都是我们父母，我们祖先生命的延伸。我们的孩子也是我们生命的一部分。我们会死亡，但是我们也不会死亡。我们的生命会通过繁衍的方式一直延续下去。\\n\\n伟大的诗人纪伯伦在他的诗中这样说：Your children are not your children. They are the sons and daughters of Life’s longing for itself.  They come through you but not from you, And though they are with you yet they belong not to you. （你的孩子并不是你的孩子。他们是生命对于自身的追求的产物。他们因你而来，但不是为你而来。他们与你在一起，但并不从属于你。）\\n\\n正如毛毛虫是蝴蝶生命的第一阶段，结茧是蝴蝶生命的第二阶段，羽化成蝶，展翅飞翔是蝴蝶生命的第三阶段。我们的父母，我们和我们的孩子，都是生命在不同的阶段中的不同的表现。生命就像一条河流，父母的生命交融在一起，成为了我们，我们和配偶的生命交融，成为了我们的孩子。我们的生命看上去是独立的个体，但实际上是同一条河流在不同河段的不同样子而已。\\n\\n所以从这种意义上来说，我们的父母逝去了，但他们没有消失，因为我们就是我们的父母，我们替他们生活在世界上。我们有一天也会离开这个世界，我们的孩子们也会替我们生活在世界上。\\n\\n在汉语中，“生”有两个意思，一个是“生存”的生，另一个是“生殖”的生。这样明显不同的两个重要的概念，居然用同一个字代表。可见我们的祖先认为，“生存“和“生殖”实际上是一回事。我们会死亡，但我们也不会死亡。因为我们会用繁衍来打败死亡。\\n\\n每次我看到人对转世再生表示惊奇，我就觉得可笑。我们每个人都是我们所有祖先的转世，我们每个人也都是亿万年古老生命的再生。我们就是父母生命的延伸。所以与其感伤父母的逝去，不如认为父母并没有死，他们还活在我们的身体里。我们活着就是父母活着，我们活得好，就是父母活好了。与其恐惧自己生命的逝去，不如认为我们也不会死，孩子们活着，就是我们活着。\\n\\n不知道你有没有看过Pixar的《寻梦环游记》。那是一个非常感人的电影。这部电影说，其实一个人要死亡两次。第一次死了之后，如果世界上还有人在纪念你，你在第二个世界里就没有死。这个世界上所有的人都遗忘你的时候，你才是真的永远消失了。那么这个世界上有谁会纪念你呢？如果你是个普通人，那么你的孩子将会纪念你。如果你是个改变世界的人，那么所有的人都会纪念你。\\n\\n所以生命其实是可以超越肉身，超越个体的。生命的意义并不是你享受了什么，而是你给别人带来了什么。从这个意义上讲，很多人都是长生不老的，很多人的生命都是永恒的。也只有把生命活出超越肉身，超越个体的意义，一个人才能不会恐惧肉身的消亡，个体的消失。\\n\\n死亡给了一些人恐惧，却给了另一些人有所作为的勇气。多想想生命，多想想死亡，你就不会再恐惧死亡，你也就会更加懂得珍惜生命。正因为我们都会死亡，所以我们要尊重和善待自己的孩子，正如我们尊重和善待自己和父母一样。正因为我们都会死亡，所以我们要做一些事情，让人们在我们永别之后，还在想念我们。正因为我们都会死亡，所以我们的生命要活出超越死亡的意义。这也许就是死亡给我们的价值吧。\\n"}'));jctx.push(JSON.parse('{"id": "191115", "tag": "book", "text": "# 美国农场的破败\\n\\n守夜人总司令\\n\\n结构学：生命体在其生存结构中的求存之道！\\n\\n导读：《关于美国的三篇！》通过结构学的基本原理结合现实去理解一个社会的基础结构和变化趋势。看过大片《中途岛》的人都非常清楚，任何重大的决策都依赖靠谱的情报分析。从蛛丝马迹中看出端倪，从纷繁变化的表现中看清脉络。所有的从容都源于确定性，所有的进退失据都源于不确定的无力感！\\n\\n匮乏和过剩\\n\\n如果从结构学的视角来重新审视交易和生产，会发现单纯的数理模型存在一种粗暴的简化，并不能反应真实的市场状况。市场的核心是人，而人的行为是在自己的生存结构中求得存续！\\n\\n一直以来我们坚信是真实的需求在拉动生产，其实准确的说，应该是交易在拉动生产。有需求和能达成交易是完全两回事：生命体在受到强力约束之前，对资源的需求是无限的——这种资源会以各种各样的形式体现出来，即便只是抽象和未来的资源，生命体也拥有占据的需要！\\n\\n因此，搞清楚是哪些约束造成交易无法达成才是关键所在。如果处于同一是非判断和价值取舍的体系之下，这种共识就能轻易的对资源的分配达成一致。然而，个体之间对自我与外部资源都可能存在截然不同的判断，基于这种判断形成的生存策略会驱使自己采取\\"有利于“自身存续的求存行为。群体之间也会把这种差异性在更大的范围内呈现出来。其实，这种所谓的\\"有利于“的判断依据源于个体的感知或者某个群体形成的共识。关于这种共识的形成及如何产生作用，在《结构学》的《C3：共识的形成》中会详细论述。\\n\\n我记得《共产党宣言》中用充满激情的语调阐述了在大工业时代，传统的手工作坊，行业组织，以及经济上的独立个体必将逐渐消亡。大工业体系拥有的不仅仅是规模优势，而是一个自我强化的循环体系。伴随的规模不断扩展的还有更高的效率和密度更高的组织形式。\\n\\n开过工厂的人都能够理解，有时候你不得不放下良心去追求效率和更低的成本，因为在大工业化生产的市场竞争中，生产成本的持续走低是不可逆转的。市场并非空洞的概念，它是由实实在在的个体组成，人对资源的需求是无限的：最好是无成本获得，退而求其次，也必须要物美价廉！\\n\\n什么样子的需求导向决定了什么样的生产模式。在工业化水平稳定的状况下，开放的市场竞争中，任何低成本、高效率的生产模式必然走向高度集约化。这种集约化和对效率与成本的执着追求，会像漩涡一样把个体都卷入零件化的深渊之中！所谓人性，就是强调尊重自主权和差异性，而理性则要最大限度的消除任何不确定性。在工业化大生产中，保质保量的关键就是标准化，所谓标准化，就是流程中的每一步都是确定的！我们平时说尊重人，潜台词就是尊重差异性，容忍掉链子和犯错，接纳各种不确定。这些东西能够成立其实都依赖高成本，成本不会消失，只会转移。如果无法转移，这些需求自然就无法满足。正常情况下，一日三餐都没有着落的人是不会在乎品位的！\\n\\n一种社会资源的利用方式决定了利用这些资源的个体之间的组织形式，继而决定了这样组织起来的共同体的价值取舍的标准。他们所恐惧和捍卫的东西肯定都是有利于现有的资源利用方式的。因为在这样的资源利用方式和基于其上形成的组织形式中，他们占据着有利的位置。所有的路线之争都是权力之争，所有的权力之争都是利益之争，所以的利益之争都是为了占据更多有利于自身存续所需资源的求存行为！这种资源的争夺不仅仅包括具像的资源，也包括抽象的资源，既包括眼前的资源，也包括未来的资源，甚至包括对资源的定义权！\\n\\n不同的周期\\n\\n古典时代的东方和西方本质上是一样的：都是生命体在那个社会资源的利用能力和社会组织度下的一种求存行为所引发的各种联动状况。爱琴海沿岸破碎的地理环境只能形成山谷中村镇级别的城邦，即便偶尔出现阿依门侬这样的征服者，也无法长期的维系住。因为他们呈现出破碎的状态是由底层逻辑决定的。这个逻辑就是农业文明状态下对资源攫取能力和维系秩序所需要消耗的成本之间的天然矛盾。这种维系成本长期高于攫取成本，即便采取最残酷的压榨也无法长久。西方的文化中总是强调反抗暴政——规模太小，在当时的资源攫取和利用水平下，必须以极度的压榨才能维系。另一方面，统治力量也太小，稍微用力就可以推翻。当某种组织形式能够形成强大的统治力量的时候，突破的难度就会变得非常巨大，求存的策略会引导个体依附其上并攫取更有利于自身存续的资源。权力的核心是组织，组织能形成的层级越多，控制力越强，反之，组织的约束力就无法持续。对于个体而言，保持自己的独立状况的成本很低，而建立并维系住共同体的成本太高，整体比如会长期处于破碎状态，继而进化出一种维持自身的独立性才是神圣和正确的观念！如果中世纪的欧洲的君主知道中国的状况，他们必然无比虔诚的膜拜秦始皇。他们也无比推崇罗马治下的和平。昔日启蒙思想家伏尔泰就用夸张的语调讴歌过幅员辽阔物产丰饶的国土上秩序井然的中国人温馨的生活场景。当然，他更多的是基于遥远的想像。\\n\\n曾经在《结构学》中阐述过：所谓文明就是一个群体在共同的生存结构中的生存策略。无论是心态和思维，还是价值取舍和是非判断，都是这种生存策略的具体表现形式。个体的精神结构及其产生的生存策略如果滞后于社会现实必然造成各种冲突，不仅仅让自己感到无力而且会影响自己的命运。当千万个体都如此的时候，整个社会就会呈现周期性的衰落，甚至敌对、撕裂和暴力纷争。\\n\\n城市是文明出现的代表。工业化的城市中分工协作密度更高，聚集的人群和资源的规模远超农业文明下的社会。因此，做事必须有计划，个体也更需要守规则。今天西方社会所呈现出来的一切更多的源于工业革命之后的雕塑，而并非深植于西方文明的内核之中。\\n\\n工业文明下的时间刻度是精确的，而农业文明下的一切都大而化之。精耕细作的背后恰恰是资源的供应无法满足需求，所以才需要提高资源利用的效率。非洲大陆为什么从来没有进化出任何复杂的社会组织方式？因为他们赖以生存的食物过于丰富，在殖民者到达之前，当地人几乎不需要任何复杂的活动就能随时随地的获取他们生存所需的东西，也就没有改进的动力，一直停留在低层次的粗放式的静态平衡之中。\\n\\n东方和西方处于不同的周期之中，非洲和中东也与我们处于不同的周期之中。许多社会由于自己文化和结构特征的缘故，让自己的社会长期处于某种静态平衡的状况之中。我认为那是休眠的火山，它的力量不取决于它的现状，而取决于能够形成结构力量的因素是否准备妥当。（关于结构力量会在《结构学》的第三部分阐述）美国社会的衰落是顺着下个周期滑落，中国社会的崛起是在爬上个周期的坡。我们没有资格去嘲笑别人，我们研究别人是为了以兹借鉴！\\n\\n农场的衰落\\n\\n我们在《C33：信仰的坍塌！》中东拉西扯的讲述了，美国社会的核心共识正在被稀释，它作为是非判断和价值取舍的最高准则越来越难以渗透到还未被原有的文化体系吸纳和消化的族群的日常生活之中。这样的局面必然造成维持社会秩序的成本持续增高，而且相互对立的价值体系在原点判断上就不兼容，完全缺乏相互理解的可能——这不是从不同的教义中找几句差不多意思的经文就能掩盖过去的。\\n\\n美国社会最开始就是由两拨不同的人群构建而成的：北方的核心主导群体是安格鲁撒克逊白人新教徒。他们追求古罗马共和时代的理念和方式，在原有的社会体系中属于缺乏根基的异端。他们主动迁徙到北美大陆，是北方群体中的精英分子，北方另外一些远渡重洋的人则是旧世界的边缘人群。这样的群体结构形成了两个特征：1. 他们的祖国建立在信仰之上，并不限于某个地方或某个群体，落到现实中，则由教堂、法庭和银行组成——在美国北部的城镇建设过程中最早到达的是传教士和银行家，继而建立起来的是集市。2. 他们带有天然的扩张性，这种扩张性如同传教士和银行家的使命一样，不仅有利而且有理，在其价值体系中是一种天命昭昭的正义和荣耀之举！\\n\\n美国南方的主要群体则源于旧世界国王的封赏。农场和庄园不过是土地贵族对旧世界原有秩序的复制和模仿。从建筑风格、生活习俗和经济结构上，南方都更接近当时的欧洲。对于这个群体言而，秩序是社会生活的核心，土地或者产业是自己的根本。英国的贵族群体来自于征服者威廉的出发基地——法兰西的奥尔良地区。他们的文化基因与被征服的英伦三岛上的群体不同，在很长一段时间内，英国的官方语言是法语，民间语言才是英语。美国南部的农场主群体与中国的士大夫群体虽然形式上不同但本质上更为接近。\\n\\n南北战争的时候，北方的工业体系刚刚起步，需要采取贸易保护政策扶持自己的产业，而南方的棉花和烟草等农产品在国际市场上非常有竞争力，大力推崇没有关税门槛的自由贸易政策。北方的工业化急需大量廉价的劳动力从事车间中简单的重复工作，而南方的种植园经济把大量优质的免费劳动力禁锢在土地上。任何口号都只是鼓动人心和凝聚共识的符号，这种符号能够以极度低廉的成本组织起更大的共同体，以便在生存竞争中获得优势并突破原生存结构中的边界约束。所以，任何社会运动都起源于一场思想营销，兴旺于一个庞氏骗局，结束于秩序重建。\\n\\n在美国的南北战争中华尔街摸索出了一套向个人兜售战争债券的金融体系，它是北方取得胜利的根本。当南方的经济在战争中通货膨胀900%的时候，北方的金融体系每天募集资金已经远远超出了北方在战争的消耗。在那一刻不仅仅决定了战争的胜负，也决定了接下来社会结构的走向！南北战争结束之后，北方胜利者做的第一件事就是重建中央银行性质的机构，为这个趋势推波助澜。\\n\\n第二次工业革命以跨海电报系统和横跨两大洋的铁路网被代表，当时社会的这种高新科技高风险产业就像黑洞一样吞噬着海量的资金。传统的农场积累完全不足以筹集这样的资金量。只有华尔街能够把旧世界在第一次工业革命和殖民扩张中积累的财富吸纳过来为这样的产业进行投资。\\n\\n社会资源的组织方式一旦能够创造大量增量，由此形成的结构力量会加速这个过程——资源的配置和人群的组织，以及覆盖其上的共识都必然发生改变，以便与之契合。我们曾经在《依依东望，望的是时间！》中阐述过统治机器的组成成员必然与社会真正的统治群体相契合的问题。由此类推，可以深度理解上述的表达。\\n\\n美国发生第一次金融危机的时候，只有2%的人口受到影响。那时候的美国农场主（不一定经营农场，也包括经营独立企业）在社会经济结构中处于关键节点的位置。当1929年经济危机爆发之时，美国社会之所以遭受如此深重的波及，是因为其90%的人口已经纳入城市化和工业化的体系并由金融体系连接在一起——再也没有有组织的群体能够阻止它的渗透和影响力。二战让这套体系得到了更加蓬勃的发展，所以战后美元金融体系在全球的确立就变得顺理成章。与之相适应的是它的主流价值观在全世界被顶礼膜拜。美国社会从内而外，像章鱼一样向任何角落渗透，在这个过程中，它不仅仅有利而且有理！美国社会存在相互制衡的两个价值体系和两个群体开始呈现一边倒的趋势，1929年美国社会的经济结构开始在全世界范围内被复制。从此之后，它的任何内部危机都将深度的波及全球！\\n\\n必然的结果\\n\\n生命体的求存行为会将个体联合成更大的共同体。不管这种联合是通过建造的方式搭建起静态稳定结构，还是通过交易构建成动态稳定的结构。总的来说都是为了占据更多的资源提高能量的转化能力，从而缓解终极悖论及其衍生出来的各种影响存续的问题。\\n\\n我们在《结构学》中揭示的这个底层特征决定了事物的发展趋势——我并没有说存在某种线性的唯一发展路径。不管是线性还是螺旋，或者其它什么形式的发展轨迹，总的来说，个体联合成更大的整体是一种趋势——虽然存在瓦解和破碎，但时机成熟的时候又会走向联合成共同体——这是由生命体底层的特征和终极悖论决定的。\\n\\n然而，在这个过程之中，建造和连接是相互交织的。此消彼长，物极必返。从农业时代开始，东西方社会的组织方式最大的差异在于其结构特征：前者自上而下，后者自下而上。大一统如同宗教，将抽象的理念层层深入到现实，所以教义不能被质疑！后者则如同社群，层层向上垒积出更大的共同体，因此分裂会永不停息…\\n\\n任何共识一旦缺乏渗透到底的传导体系，就会像纸糊的窗户一样缺乏约束力。产业的萎靡和转移会让维系秩序的力量缺乏支点，虽然占据的资源总量不变但结构失衡——当延伸到全世界的连接和扩展不足以继续创造增量的时候，这个周期的结网者就会如同上个周期的农场主一样悄无声息的谢幕。如果一定要找一个类比的例子，平台型创业项目上这一点表现的非常直观：如果三公里之内不盈利，规模扩大百倍依然不会盈利，而且会亏损的更多，整体坍塌的更快！\\n\\n川普绝对不是一个人，他的所作所为是为了捍卫一个久远的立国传统。他的行为正在凝聚一个社会共识并挑战南北战争以来，数十年编织而成的社会权力结构和经济结构的密集网络——或许他只是无意识的本能反应，但他和他所代表的群体正在觉醒，他们预感到历史的车轮再一次转向，于是冲上去《向正在坍塌的地方踹上一脚！》。站在对立面的群体不管怎么恐慌的挣扎最终都阻止不了这种周期的切换。这一点不会因为这一次或下一次的选举结果而改变！\\n"}'));jctx.push(JSON.parse('{"id": "191120", "tag": "book", "text": "# 中东乱局中的攻防之策\\n\\n我们经常互相打趣的说：难道你家里有矿呀！如果你家里真的有矿而又没有能力保护好自己的矿，那么，这些矿不仅仅无法成为炫耀的资本，反而会成为危害全家生命的祸根。只有自己能够守得住的东西才是真正属于你的，否则，都只会是过眼云烟！所以，真正的拥有，依赖两种能力：一是获取，二是占据！所以我们在《结构学》的《C1》和《C4》中反复强调：那些能够穿透生命周期的传承才是力量真正的源泉，才是力量循环叠加形成磅礴之势的动力。真正的富有不是红木家具，不是钻石戒指，不是账户上的数字，而是家族庭院里盘根错节又遮天蔽日的古树，是能够传承的家教和荣誉，是多少代人编织而成的社会安全网——那是一种久远的存在和持续的繁荣！\\n\\n内外交困\\n\\n阿萨德的烂摊子\\n\\n老阿萨德出身于一个阿拉维派农民家庭。因为穷上不起学，只能去从军，以求得出路。阿拉维派人数很少，他们的教义和主流的什叶派及逊尼派都不同，属于穆斯林世界中少数中的少数。正因为如此，他们的生存环境很恶劣。这种迫在眉睫的恶劣生存环境，反而让他们拥有更高的组织度和更强的抗争意志。即便是最普通的生活状况也处于一种高度组织并高度隐蔽的状态之中。在早几天发了三次都被删除的文章中摘录过《结构学》中的一段描述：军队作为有组织的力量，首先是组织密度，其次才是暴力。所以，零时拼凑的群体，即便来势汹汹也不足为虑，真正有战斗力的是有着明确的纲领，内部纪律森严，对成员具有强约束力的组织。\\n\\n老阿萨德1970年是武装力量的负责人，利用叙利亚在1967年中东战争的败北丢失了戈兰高地引发的不满政变上位。并有针对性的建立军政学校培训阿拉维派的子弟，并将他们作为统治机器的节点布局到叙利亚社会权力体系之中。阿萨德这个姓氏的意思是狮子，老阿萨德的所作所为确实像狮子一样。铁腕手段，阿拉维派的高密度组织和对社会资源及统治机器的严密控制，再加上70年代的经济发展和石油红利。阿萨德家族在错综复杂的局面中始终掌控大局。\\n\\n任何社会在现代化过程中都矛盾丛生，特别是由传统的农业部落社会转向现代工业社会的时候。不仅仅是经济发展的不平衡，还有群体认知差异所形成的生存策略之间的冲突。如果存在差异的群体之间又缺乏产生新的共同连接或创造增量的可能。那么，这种冲突只会越演越烈，甚至不得不以暴力来裁决。只有死亡才能让这样的冲突消停。任何结构力量都是双刃剑，当年为老阿萨德建立统治的传导体系的群体开始蜕变为腐败的利益集团。经济发展的红利开始消退但人口暴涨，基本需求得不到满足的群体开始在新的求存诉求的驱动之下，重新聚集在新的旗帜下。老阿萨德去世的时候，整个叙利亚社会已经如同一个堵住散气阀的高压锅。\\n\\n乌合之众总是短视和愚昧的，端起碗吃肉咧嘴笑，放下筷子就叉着腰骂娘。他们一旦在现实中遇到困境，就会要求退回到过去，或者怀念根本不存在的抽象美好。如果现在很多人过的不如意就无比的怀念民国时期，经历过的老人从不怀念。因为他们知道你的美好想像都是假的，他的痛苦记忆知道分崩离析流离失所下真实的人生百态。\\n\\n内部失败的改革\\n\\n巴萨尔从来就不曾想过自己要治理一个国家。他追寻自己的志向去英国伦敦做了一名牙医，过自己的小日子。他也从来不曾被当作接班人训练。因为他的哥哥从小就他父亲当作接班人培养。然而，事情就是这么凑巧。在他34岁的时候哥哥车祸身亡。他的生活从此改变了航线，被送入阿拉维派的军校速成学习。叙利亚紧急修改了40岁以下不得参选总统的宪法条例，降低到34岁，为其量身打造接班之路。\\n\\n当一个专业的牙科医生放下手术刀，拿起指挥三军的权杖之时。他阴郁的脸上并没有轻松的表情。因为他父亲留给他的是一个堵住了出气孔的高压锅，随时有砸裂的可能！巴萨尔毕竟一直在英国留学生活，所谓近朱者赤，近墨者黑，他刚上台的做派很西化。将他父亲收紧的东西通通放松，在社会增加没有增加的时候，社会控制力却急剧弱化了！官僚集团作为权力传导体系不仅仅失控而且变本加厉的压榨和搜刮，下放的权力和放松的控制让其无能为力。为什么越是在经济下滑的时候要打击有组织犯罪并严抓组织建设？年轻的巴萨尔被西方的教科书了洗脑，看不清自己和所处社会的生存结构的现实，一厢情愿的依葫芦画瓢，结果事与愿违，社会矛盾不但没有缓解，而且一触即发！\\n\\n风云骤起的中东\\n\\n曾经在一年多之前为一个基金经理的朋友做投资策略分析，写了那篇预测性的文章《向正在坍塌的地方踹上一脚！》这是依据《结构学》基本原理做出的趋势性预测——后面的态势一直在向这个方向走，而且永远回不去了。当官方开始在本土建立互联网根节点的时候，这一趋势更加不可逆转。\\n\\n当山姆大叔开始从全世界收缩的时候，必然要把任何具有潜在力量的地区搞乱，必须要把核心通道截断——不管是海上的通道还是陆上的商贸和能源通道。我们在《结构学》的早期案例中阐述过：社会升级依赖的核心资源包括粮食和能源。一个社会规模越大，能够整合的深度越广，后发性越强，它对这二者的需求量就会越高。这就好比一栋房子，不管你搞多么花哨的设计和装修，地基不稳随时会造成一剑封喉的威胁——这对任何潜在敌人而言都是天大的博弈筹码。\\n\\n在印度、东非、中东、东南亚和东欧平原之几个潜在力量的区域内。山姆大叔都不遗余力的搞事情。这无所谓对错，是一种战略需要。打过战略游戏的人都清楚，在自己家基地升级的时候，必须利用不对称的方式骚扰潜在的竞争对手让其发展不起来。\\n\\n阿拉伯之春和乌克兰的动乱首先是其社会结构自身挤压的问题找不到出口。这就让内部人群发生了分化。人群一旦分化就很容易被认知的差异所形成的立场制造出对立。对立的群体会强化自己的共识并形成自我遮蔽性。这种彼此相互刺激不断自我强化和循环叠加的敌对情绪，会撕裂共同体内部的完整性，摧毁其社会的组织密度。在纷争中落下风的群体会短视的借用外部的势力，从而为外部干预提供了抓手。\\n\\n美国人就是基于对其社会结构进行深入研究之后，以四两拨千斤的方式点燃了中东的燎原之火。瞬间将这些社会的强人基于理性人为建立的现代社会的组织结构烧的片瓦不存，让松散和脆弱的经济和组织基础裸露在外，任其厮杀。\\n\\n不管怎么样，中东都不能被整合起来。这个区域在同一信仰下拥有10亿人口，而且占据工业化所需要的资源和粮食，并占据三大洲的要冲之地。一千多年前在那样低水平的社会经济基础和组织能力之下，它所爆发出来的能量让整个西方都记忆犹新，恐惧不已！现在已经腐朽者，将来可能重放异彩；现在备受青睐者，将来却可能日渐衰朽。\\n\\n多事之秋\\n\\n当大国战略都汇聚于此的时候，不管当事人怎么想，都已经由不得你了——树欲静而风不止。被裹挟着坠落深渊，时刻感到无能为力的不仅仅有生活中的个体，也包括一个社会和它的处境。\\n\\n家里有矿但自己无力守护，这些矿反而会带来杀生之祸。这种事情在殖民时代的非洲经常发生。如果某个村落的地下被西方旅行者发现了某种当地更不利用不了的矿石，那个村落往往会被驱逐或屠杀。他们并没有做错什么，甚至在浑然不觉中厄运就已经悄然降临。\\n\\n口号与目标\\n\\n人类的虚伪之处在于总是以动人的口号掩饰那些求存的基本需求。我们在《觉悟社》的《C3：共识的形成》中详细的论证这一点的形成机制和运作方式。真实的世界是复杂的，但乌合之众无法理解复杂的事物，也无法在面对复杂事物的时候抓住重点。所以渴望简化的世界，遵循简单的规则，喜欢静态的世界。互联网企业这样一句俗语：当你把品位降低一个层级，用户就会增加10倍。因此，一个社会在某个阶段的人群底色决定了什么会大行其道！\\n\\n日不落帝国从来都是战略高手。美国表弟只是继承了大表哥的技巧而已。当年第一次世界大战的时候，英国的情报机构利用两个执着、热情又深入现场的考古学家对当地社会结构准确又细致的洞察，制定了四两拨千斤肢解奥斯曼帝国的绝妙计划。他们不断鼓动阿拉伯部落觉醒追求自由并建立自己的国家，横在亚欧大陆十字路口上的庞然大物奥斯曼帝国从内部土崩瓦解了。经典电影《风中的女王》和《阿拉伯的劳伦斯》以艺术的手法演绎了这个过程。\\n\\n英国大表哥所处的时代以宗教和民族独立为口号，美国小表弟以个人自由为口号，其目标都是一样的：《结构学》中阐述的终极悖论不会消失，生命体的求存行为也不会随时间而变迁，千百年来变化的只是覆盖其上的伪装和旗帜。无论是社会还是个体，必须创造增量才会获得更多的自由。否则，则不得不为了自身的存续在存量中厮杀——无论用暴力还是诡计。\\n\\n战略性掩护\\n\\n一个人如果曾经登上过巅峰，即便遭受再强烈的打击和挫败，无论是自己还是外人都会心存王者归来的信心。如果一个人从未赢过，即便临时获得无论是自己还是别人都会心存疑虑。\\n\\n虽然俄罗斯的经济总量不及广东省，但它依然是昔日红色帝国的主体。红色帝国展示出来的力量留在记忆深处的痕迹在人心中树立了一杆大旗，一旦时机成熟，往往具有不可估量的感召力。昔日元朝灭亡之后，只要黄金家族存在一个男丁就具有聚拢草原上的所有部众去恢复祖先荣光的号召力。昔日的哈里发曾经统治过广袤的国土，所以，当ISIS起来的时候，一时风头无量，在许多穆斯林的心中激荡起恢复昔日荣光的憧憬，正是这种曾经赢过的想像，在全世界的发范围内吸引着穆斯林群体为其提供兵源和财力。\\n\\n普罗大众的视野和关注的东西与决策者的视野不在同一个维度。关注的重点自然也不一样。中国在东亚具有号召力，但它从未作为一个世界性的帝国展示过力量。这是我们的文化和生活方式决定的，农耕文明下的帝国重在建立秩序，追求长治久安和文明教化，对不能农耕的荒蛮之地缺乏征服和治理的兴趣。因为在古典的农耕时代，土地是最重要的资源。土地改造的成本决定了它的价值和对那个区域及其上人群的态度。总而言之，在西方的战略思维中，俄罗斯和中东的潜在威胁性和创造这种威胁的号召力是远大于人畜无害的东亚文明的。\\n\\n无论是中东被整合还是前苏联区域被重新激活，在这个区域的人群既拥有展示过世界性力量的集体记忆，地下也拥有丰富的资源，其文化中推崇强者和扩张的基因，也极容易鼓励他们采取对外威胁的行为。从易北河以东直到达达尼亚海峡，在到乌拉尔山以西的广袤平原区域，无论在哪方面都缺乏制约以斯拉夫文明和东正教为载体的俄罗斯的势力渗透。不管今天的状况如何，这种结构性的威胁性一直存在。所以西方需要土耳其，土耳其是其唯一能够抗衡的力量——这种力量不是因为土耳其会听话，而是因为土耳其代表了另外一个同样具有威胁的潜在力量。生活中你如何四两拨千斤的鼓舞一个人？让你想要他做的成为他自己就想做的！\\n\\n中东地区存在沙特、伊拉克、伊朗、土耳其、埃及、叙利亚具有整合十亿穆斯林的潜在力量。不管是谁来整合，只要能在工业时代整合这个地区及生活其上的十亿穆斯林，就会恢复人心之中昔日阿拉伯帝国席卷四方的记忆。因此，这几个国家任何一个冒尖都必须搞乱和敲碎，特别是在美国战略收缩的时候。\\n\\n你来我往\\n\\n人的求存行为会造成人群的分化，人群的分化必然形成冲突，在冲突中为了胜出，个体基于共同的处境和立场形成某种共识——以群体的意识替代个体的意识，相互支撑又相互制约，凝聚成共同体。共同体的形成会强化内部的约束力并加剧对外的冲突。\\n\\n这种生存竞争的博弈需要不断的创造筹码。经过普京的一系列内部操作，俄罗斯政府重新掌握了对国家经济命脉的关键资源的控制。详情见《你误解了普京！》。俄罗斯的影响力开始逐步向昔日的独联体渗透。这个两件事情先后发生：美国联合沙特打压国际石油价格，同时，乌克兰街头发生暴乱。乌克兰四两拨千斤的混乱为阻止因油价上涨回血的俄罗斯势力的渗透提供了抓手。俄罗斯被踢出G8并遭受整个西方的制裁。明面上冠冕堂皇的制裁和暗地里打压油价让俄罗斯陷入财政危机，继而引发其社会动乱是相互交织的绞杀链条。在这个回合中某个神秘力量突然为毛熊输血，不仅仅故意高价购买毛熊的石油，还乘机修建了东北放向的油气大动脉，乘机建立自己的战备石油储备系统。另外，国际油价的暴跌让某个对石油需求日益巨大的神秘力量获得了大量低价从沙特进口石油的机会，那些来不及运回来的石油设置以油轮的方式储存在海上。由此让那位中东事务的边缘人开始也有了指手划脚的资格——毕竟那条路要经过中东地区。\\n\\n俄罗斯在乌克兰的变局中变被动为主动，不仅强力收回克里米亚，而且肢解了东乌克兰的俄语地区。虽然遭受制裁，但也获得某位暖心人的鼎力输血。这一局并没有输。紧接着一股神秘的恐怖分子突然冒出来，瞬间席卷了破碎的伊拉克和俄罗斯在中东的支点同样陷入内乱的叙利亚。更巧的是，ISIS崛起的地方正是幼发拉底河谷的石油和粮食产区，而且是库尔德人聚集区！\\n\\n俄罗斯不能失去叙利亚，否则它不仅仅对土耳其缺乏制衡的支点，而且它的海空势力必然全部退出东地中海沿岸的中东腹地。它的战略空间不得不压缩到乌克兰边境。如此一来，伊朗会直接面对已经面对西面的渗透。因此，俄罗斯和伊朗不约而同的去保护叙利亚。在这样的乱局之下，叙利亚不得不将自己唯一的大港口塔尔图斯港50年的管理权限抵押给俄罗斯。俄罗斯和伊朗的前进策略恰恰是为了创造博弈的筹码。战是为了和，但你没有筹码就和不了！\\n\\n美国人理性评估了俄罗斯的艰难处境，因此，低估了俄罗斯强力干预的决心，更没有意料到伊朗会如此积极，更要命的是他们还形成铁三角了！俄罗斯非常清楚如果没有沙特的配合，单凭借美国的石油储备是无法直接把国际油价一直压低到50美元的低价。压低到这种价格的目的非常明显，那就是让俄罗斯的财政破产！这一招比战场上的刀枪更狠毒，大炮一响，黄金万两。打战打的是钱粮！所以，俄罗斯扶持了胡塞武装从背后袭击沙特。这一招很有用，逼迫沙特国王访问俄罗斯，让国际油价逐渐回升。\\n\\n攻防之道你来我往，这才是棋局的精妙之处。如果说ISIS只不过是前菜，那么鼓动库尔德人建国则是主菜上场。库尔德人有4800万，是中东第二大民族，占据两河流域的粮食和石油产区。横跨周边四个国家：叙利亚，伊拉克，伊朗和土耳其。其中土耳其境内人口最多，占据总人口20%！只要在叙利亚点燃这把火，土耳其就不得不介入，因为这个后遗症是它承受不起的。沿着扎格罗斯山脉，被武装的库尔德人可以在周边几个国家任何穿梭、藏匿和渗透。所以，土耳其才需要沿着叙利亚的边境向内推进30公里，搞出一个自己控制下的隔离地带。美国人只需要以少量的兵力占据粮食产区和油田，继而以四两拨千斤的方式鼓动，这种点燃库尔德见国之火的威胁就一直存在。原子弹的真正威胁是在发射架上，而不是投出去之后。由此创造出新的博弈筹码！\\n\\n在封锁和代理人战争的双层绞杀下，无论是俄罗斯还是伊朗国内的经济形势已经岌岌可危。俄罗斯这两年的经济增长是负数。伊朗的经济问题必然被民众所感知，而民众为了自己的存续必然采取短视的行为。这正是遍地的干材，如果再投入一些引火之人，往往能达到四两拨千斤的效果，继而让那个社会陷入恶性循环。伊朗和俄罗斯内部都能够很好的控制和恢复秩序，但是，叙利亚将后继乏力，俄伊都不得不逐渐减少投入。就在这个时候以色列进来搅局。在上一轮博弈中，美国人看似毫无作为，现在却在好发无伤的情况下，王者归来，重新占据主导。某位大善人也在关键时刻在为俄罗斯搞大型基建项目拉台经济，同时也提供投资和其它输血服务。下一局会在哪个地方出拳呢？！\\n\\n美国人不会冒然引爆库尔德人建国这颗核弹。它会坚持的是四两拨千斤的骚扰，利用地区和其社会的结构性失衡持续制造混乱。只有俄土保持战略冲突才符合其战略诉求。引爆库尔德人建国这颗核弹会把土耳其逼的跟俄罗斯一起。诚如《A97：埃尔多安错了吗？！》中阐述的一样，土耳其别无选择，他也必然会得到俄罗斯默许自己在叙利亚开拓的安全区。\\n\\n当年平定西北叛乱的时候，最重要的职位不是征西大将军，而是陕甘总督。因为他负责供应征西大军的兵马钱粮。没有了粮草，不管怎么打最后都会兵败。所以，无论是东方还是中东都会快速恢复内部秩序。并接到某位大善人的大额订单和各种合作项目，大善人也会增加能源的进口和储备并顺势推进人民币结算体系。除此之外，胡塞武装可能恰好袭击沙特的油田，或者国际主要航道上发生些什么意外冲突，造成供应紧张，人为去制造行情。我们可以拭目以待！\\n"}'));jctx.push(JSON.parse('{"id": "191205", "tag": "book", "text": "# 孙中山的秘辛\\n\\n越了解孙中山越发觉得他的可怕之处。\\n\\n1.孙中山出身很差，他父亲是村里的佃户长工，黄兴宋教仁都是中小地主出身，毛是富农，而孙中山说八辈贫农都不为过，但是呢，他有个好哥哥孙眉，孙眉很早就出国打工，其实就是做“猪仔”，先做码头工人，后来攒点积蓄开小杂货铺，再开连锁，最后经营农场，十年奋斗成为檀香山数一数二的富商，简直励志楷模，而后把孙中山接到外国读书——也就是说，孙中山童年在困苦中度过，少年后陡然而富，所以说什么武昌起义时孙中山正在美国饭店刷盘子啥的和扯淡一样。\\n\\n2.青年孙中山曾上书李鸿章，这个大家都知道，问题是，不是哪个阿猫阿狗就能把信递到权势显赫的北洋大臣手上！孙中山走的是郑观应的通道，没错，就是那位“早期维新派”“改良主义先驱”，而郑观应是轮船招商局帮办，当时“国企”前五，李鸿章的亲信——孙中山路子太野了。\\n\\n3.辛亥革命时，清朝海军一支去武昌平叛，结果被革命军策反，而另一支舰队则在程璧光率领下正在巡洋访问，而这个程璧光曾被孙中山拉拢加入了兴中会。——你们清廷用人不政审么！！更可怕的是孙中山怎么就搭上了程璧光。\\n\\n4.世传孙中山是洪门（三合会）红棍，这太低估孙中山了，三合会、洪门仅局限于广东与广东人密集的海外华侨界，而孙中山在1899年被推举为兴汉会会长，而这个兴汉会是兴中会、广东三合会、两湖哥老会的联合，这时孙中山的地位已经凌驾洪门三合会之上了，啥？司徒美堂？三合会？洪门？龙头大哥？人家两湖哥老会认么？！\\n\\n5.由4我们可以发现另一个大问题，就是此时的兴中会会长是杨衢云，并不是孙中山，而孙中山却成了兴汉会（兴中会、三合会、哥老会）的会长！权力倒挂了，果然，不到一年，杨衢云被迫卸任，孙中山当上兴中会会长。\\n\\n6.1905年7月在宫崎滔天的引荐下，华兴会会长黄兴与孙中山见面，8月华兴会就和兴中会合并组建同盟会了，并推举孙中山为领袖——是不是太草率了？\\n\\n由4、5、6三点共同引发了一个疑问，孙中山是如何成为革命党的核心的？\\n\\n孙中山早年与朋友在檀香山成立兴中会，后来到了香港，与当地革命早期组织辅仁文社接触，合并成为兴中会，辅仁文社的社长杨衢云由于资历高于孙中山，被推举为社长，孙中山为其秘书。\\n\\n1898年戊戌政变，两湖领袖谭嗣同死难，其手下唐才常、毕永年等人流亡海外，激愤于谭嗣同之死，欲采取暴力手段推翻清廷，而一直与他们接洽的便是孙中山，不久在哥老会头领毕永年的带领下，两湖流亡人士大批加入兴中会，冲击了兴中会原有的人员组成比例，而他们更倾向于拥立孙中山，毕竟关系熟。——这就像梁山上原来晁盖是老大，七个头领是他铁杆，位子坐的很稳，一天宋江上山，带着20个头领，大堂上一排座次，晁盖反而成了少数派。——于是孙中山在毕永年两湖派的支持下开始了夺权，毕永年策动哥老会，郑士良策动三合会，公推孙中山为兴汉会会长，以此逼杨衢云下台。\\n\\n这也是黄兴华兴会在短暂接触孙中山后就与其合并、推其领袖的原因，因为华兴会与两湖哥老会渊源很深，早期起义主要依靠的便是哥老会马福益，且黄兴、周震麟等人早年就是谭嗣同、唐才常、毕永年的跟班。黄兴与孙中山见面谈了一晚，估计发现两人认识的是一拨人……\\n\\n这也解释了为何日后两湖系革命党在孙中山生前的同盟会、国民党、中国国民党之中地位崇高、与广东系革命党极为密切。而这段历史在老蒋当政后被极力抹杀，杨衢云、毕永年等关键人物在蒋记国民党的党史叙事中遭到掩埋，并非在意孙中山的独尊地位哪来的，而是顾忌曾经在国民党内占据核心位置的广东系、两湖系后来怎么就没了！取代他们的竟然是被老蒋鼓吹的所谓“国民党四大元老”的江浙系。\\n\\n7.袁世凯成就了孙中山，宋教仁遇刺后，孙中山力主立即起义，黄兴主张暂缓起义，先通过法律渠道解决，结果这期间林述庆又遇害，袁世凯也取得《善后大借款》，大肆扩军，并主动攻击，于是乎二次革命惨败；一战期间，只有孙中山中华革命党还在积极反袁，章士钊程潜等人组织欧事研究会，认为中国应暂时团结于袁世凯手里、共对列强，理想很好，结果袁世凯称帝了、遭到群嘲了、土崩瓦解了，这时欧事研究会才姗姗来迟、开始反袁——这两件事使得孙中山名望空前提高，占尽先机，站队是杂技，预判才是门艺术。\\n\\n8.记得上文那个程璧光么？护法战争时，他率领民国海军随孙中山南下，反对段祺瑞政府，组建护法军政府，孙中山得以带兵入股于陆荣廷军政府，并从陆荣廷手里骗来了20营军队，组建了粤军，不久以这支军队占领闽南，两年后又用这支军队反手灭了陆荣廷，鸠占鹊巢。——不要给孙中山一丝机会，这人抓住一丁点机会都会大肆扩张。\\n\\n9.陈炯明叛变后，孙中山开始与苏俄正式合作，苏俄最初的设想是撮合吴佩孚与孙中山，但是遭到孙中山严词拒绝，本着“远交近攻”“离强合弱”的原则，孙中山组建粤奉皖反直同盟，和张作霖南北夹击直系，第二次直奉战争，吴佩孚败逃，北京政府出现权力真空，孙中山北上进京，可惜天不遂人，病逝北京，段祺瑞走了狗屎运，又一次上台。如果孙中山不死，段祺瑞已然明日黄花，张作霖威信不足，冯玉祥资历太小，那么孙中山极有可能成为民国总统，就差一步，哎。\\n\\n孙中山本着百折不挠的决心屡败屡战，一败乙未二败惠州三败黄冈四败七女湖五败防城六败镇南关七败钦廉八败河口九败广州十败黄花岗，其领导的资产阶级革命党越来越走向成熟，最后终于完成推翻清朝的伟大任务，说他是XXX以前中国最伟大的革命领袖并不为过。\\n\\n伦敦蒙难只是成名，但是没有组织基础也是没用，比如苏报案，对中国影响比伦敦蒙难要大得多，但是也没使章炳麟取代孙中山（比较有意思的是，事后章炳麟大谈苏报案的苦难，邹容死的惨烈，而后宋教仁去调查，回来说邹容是病死的，不是拷打而死的，怼得章炳麟说不出话来）\\n\\n两湖系被老蒋排挤没了，遭到边缘化。所以解放军打到湖南湖北，直接就起义了，张难先程潜章士钊唐生智周震麟等等。\\n\\n我想补充一下：\\n1、孙眉是个经商人才“茂宜王”，夸张地说就是短短几年从奴隶到土豪，后为弟弟革命倾尽家财。\\n2、孙文经杨衢云启迪之前仍秉承封建皇汉心态。\\n3、孙文在北美踌躇徘徊亦曾多次气馁，北美洪门致公堂主黄三德（洪门大佬）以及华侨们多次资助和激励孙文。\\n4、当然不要把全部华侨和孙文都想得大义凛然，孙文为了筹资曾向广大华侨发行巨额的“革命债券”，许诺革命成功后偿还。\\n但革命成功后，孙文若无其事，黄三德等人多次找孙文、上京讨债失败，此事严重激怒洪门及华侨群体。\\n5、孙文成立独尊党魁的中华革命党，曾想吞并洪门，不允许洪门立党的提议，致使洪门（致公堂）后期倒向其他政治人物。\\n6、洪门也曾被保皇派蒙蔽，后因黄三德等人赞赏孙文而改为全力支持革命党，革命党在海外筹资、演讲时，帮派人士提前清场（带棍殴驱保皇派）。\\n7、程璧光后被孙文谋害。\\n\\n1孙眉谈不上倾尽财力，帮助是有，但是毁家纾难还是太夸张。\\n\\n2孙文暗杀程璧光挺扯的，主要是唐德刚找的“证据”，在唐德刚塑造下，孙中山暗杀了宋教仁、程璧光、邓仲元，就差是孙中山用枕头闷死了黄兴了，在当时政局下，程璧光是唯一能稳住海军的人，也是孙中山较为靠谱的盟友，虽然互相言语激烈，但还没到刀兵相见的程度，另外，如果孙中山真有这么吊的暗杀队，那么在陈炯明反对自己北伐时怎么不做掉陈？还等他发动政变？怎么不做掉叶举，还等他兵变？\\n\\n是中国第一个正二八经的“工业党”，他那“知名”的实业计划是中国第一个全面的工业化蓝图，当然，在我们今天看来，这部蓝图充满了不切实际的文人空想（先总理自己也说二十万英里铁路计划不过是“图上作业”而已），但在那个时代，其实谁也不知道那些是空想，那些是可行的，那怕是詹天佑这样政治观点对立的工程师都对该次非常推崇。\\n\\n而且先总理也是中国比较早提出用工农业剪刀差解决土地问题的人，可见他对资本主义工业的系统性理解还是比较充分的\\n"}'));jctx.push(JSON.parse('{"id": "191206", "tag": "lang", "text": "# 编程语言的字符串内部表示\\n\\n最近在做中文字符校验，结合几种语言的使用，做个总结。除了ASCII字符集以外，其它文字普遍有定义和外部展示的区分，即使不考虑各国定义的标准外，也还存在Unicode和UTF8两种要区分。编程语言接收的输入一定是外部展示，然后在处理时再变成内部表示。\\n\\n## JS\\n\\n因为是内嵌在浏览器，文字的编码方式不需要JS操心，浏览器会把各种编码转成Unicode再给JS。但是JS发明的时候，Unicode还只有BMP，所以内部单元都是UCS2方式，包括String.fromCharCode会截断，比如0x20041返回的是0x41。超过BMP的字符在内部以代理对(surrogate pairs)方式表示，length取得的长度是2。\\n\\n好在新标准定义了String.fromCodePoint方法能识别代理对，能正确识别0x20041。另外对字符串变量str，用`const i = str[Symbol.iterator]()`得到的i，可以用next()方法每次迭代一个CodePoint，利用这个方法，可以构造另一套支持全Unicode的方法。也算在无奈之下的补偿方式了。\\n\\n## PHP\\n\\n没有语言规范层的定义，实际中可以用`mb_internal_encoding`获取内部编码方式。如果在`mb_`系列方法中编码和输入源不匹配，得到的错误结果要使用者自己承担。有点C语言的哲学。\\n\\n## Python\\n\\n由于出现断代变迁，2和3有较大差异。2.x内部是ASCII，3.x内部是Unicode。前者无法支持多语言，后者不是通用的外部表示（因为主流是UTF-8，在那之前则是各国不同的编码标准），因此2个版本的输入文件都有文件编码参数（可以显式指定，或跟随操作系统），如果读入的字符和指定的参数有冲突会报错。\\n\\n2.x的文字只是字节的序列，类型是str(等价于3.x的bytes)。可以加u前缀保存成Unicode，比如u\'文字\'，类型变成unicode。到了3.x时代，str升级成unicode，bytes表示字节序列。在2.x里经常要对一个str类型变量用decode(\\"utf-8\\")方法，到了3.x会调用失败，因为str已经是unicode类型，只有encode成某种编码的序列；反之byte类型才有decode方法，将一段字节流按指定的格式解码成unicode形式。\\n\\npython的base64解码，由于返回值不能保证内容是unicode可编码，所以只能是bytes类型。如果想要以str方式使用，要decode(\\"utf-8\\")后再使用。\\n\\n## Golang\\n\\n规范要求输入必须是UTF8。string类型是byte sequence，用`[]`的下标处理时，操作到每个字节。对string用range方法每次返回一个rune类型的值，以Unicode表示的一个字符，长度不定，由于语言出现得比较晚，避免了JS的坑，能表示全部范围。"}'));jctx.push(JSON.parse('{"id": "191210", "tag": "book", "text": "# 吕思勉的《三国历史》\\n\\n春秋时期，只有国的概念。兼并发展到战国，小国被吞后以县名之，而边防处为屯重兵防备，升格为郡但非常例。秦统一后防止旧国起义，布重兵在全国，郡县才成为制度。所以郡的来源实是为镇压而不是治理。\\n\\n汉承袭郡县淡化了郡镇压的作用，为防止郡的最高长官太守权力不受制约，每郡派一御史行监察之职。到汉朝改由丞相分派，御史变为刺史。一个刺史监督若干郡，起初只是职责上的划分，不是行政地域，所以并不带州名而称之为部。到灵帝时，因刘焉的提议，置若干重要州的最高长官为州牧，实际刺史做几年往往升为州牧，成为最高行政长官(西汉曾短暂实行，旋又废弃)。\\n\\n诸葛亮死后季汉的29年，蒋琬12年费袆7年姜维10年。屯田沓中在甘肃临潭县，甚至在阴平道(甘肃文县)以西。钟会进兵汉中，先破阳安关(现陕西勉县和宁强县交界，吕书中用旧名沔县宁羌县，推测成于1940年)。姜维退兵到剑阁昭化一带，而邓艾追到阴平道，下平武县经江油绵阳偷袭成都。\\n"}'));jctx.push(JSON.parse('{"id": "191212", "tag": "lang", "text": "# Promise的中立性\\n\\n## 原文\\n\\nPromise 产生的问题影响了 JS 的整个生态系统，本文将对其中一些问题进行阐述。上面这句话可能让你认为我被 Promise 折磨得心情极差，对着电脑骂脏话，于是打算在网上发泄一通。实际上并不是的，我今早刚泡好咖啡，就有人在 Twitter 上问我对 Promise 的看法，我才写下了这篇文章。我当时一遍喝咖啡一遍思考，然后向他回复了几条微博。一些人回复说最好能写成博客，于是就有了这篇文章。\\n\\nPromise 的主要目的是表示一个终将会得到的值（下文简称最终值）。这个值可能会在下一个 event loop 中得到，也可能会在几分钟后得到。还有很多其他原语可以达到相同的目的，比如回调、C# 中的任务、Scala 中的 Future，RxJS 中的 Observable 等。JS 中的 Promise 只是这些原语中的一个而已。\\n\\n虽然这些原语都能实现这个目的，但是 JS 的 Promise 是一个太过 opinionated （译注：opinionated 是主观臆断的意思，这里表示不恰当的、强加观点的）的方案，它造成了很多奇怪的问题。这些问题又会引发 JS 语法和生态系统中的其他问题。我认为 Promise 不够中立，其 opinionated 表现在下面四个地方：\\n\\n1. 立即执行而不是延迟执行\\n1. 不可中断\\n1. 无法同步执行\\n1. then() 其实是 map() 和 flatMap() 的混合体\\n\\n### 立即执行，而不是延迟执行\\n\\n当你创建一个 Promise 实例的时候，任务就已经开始执行了，比如下面代码：\\n\\n```\\nconsole.log(\'before\');\\nconst promise = new Promise(function fn(resolve, reject) {\\n  console.log(\'hello\');\\n});\\nconsole.log(\'after\');\\n```\\n\\n你会在控制台里依次看到 before、hello 和 after。这是因为你传递给 Promise 的函数 fn 是被立即执行的。我把 fn 单独拧出来你可能就看得更清晰一些了：\\n\\n```\\nfunction fn(resolve, reject) {\\n  console.log(\'hello\');\\n}\\n\\nconsole.log(\'before\');\\nconst promise = new Promise(fn); // fn 是立即执行的！\\nconsole.log(\'after\');\\n```\\n\\n所以说 Promise 会立即执行它的任务。注意在上面的代码中，我们甚至还没使用这个 Promise 实例，也就是没有使用过 promise.then() 或 promise 的其他 API。仅仅是创建 Promise 实例就会立即执行 Promise 里的任务。理解这一点很重要，因为有的时候你不想 Promise 里的任务立刻开始执行。有时候你会想要一个可复用的异步任务，但是 Promise 却只会执行一次任务，因此一旦 Promise 实例被创建，你就没法复用它了。\\n\\n通常解决这个问题的办法就是把  Promise 实例化的过程写在一个函数里：\\n\\n```\\nfunction fn(resolve, reject) {\\n  console.log(\'hello\');\\n}\\n\\nconsole.log(\'before\');\\nconst promiseGetter = () => new Promise(fn); // fn 没有立即执行\\nconsole.log(\'after\');\\n```\\n\\n由于函数是可以在后面调用的，所以用一个「返回 Promise 实例的函数」（下文简称为 Promise Getter）就解决了我们的问题。但是另一个问题来了，我们不能简单地用 .then() 把这些 Promise Getter 连起来（译注：原文说得不够清晰，我不太理解作者的意图）。为了解决这个问题，大家的做法一般是给 Promise Getter 写一个类似 .then() 的方法，殊不知这就是在解决 Promise 的复用性问题和链式调用问题。比如下面代码：\\n\\n```\\n// getUserAge 是一个 Promise Getter\\nfunction getUserAge() {\\n  // fetch 也是一个 Promise Getter\\n  return fetch(\'https://my.api.lol/user/295712\')\\n    .then(res => res.json())\\n    .then(user => user.age);\\n}\\n```\\n\\n所以说 Promise Getter 其实更利于组合和复用。这是因为 Promise Getter 可以延迟执行。如果 Promise 一开始就设计成延迟执行的，我们就不用这么麻烦了：\\n\\n```\\nconst getUserAge = betterFetch(\'https://my.api.lol/user/295712\')\\n  .then(res => res.json())\\n  .then(user => user.age);\\n```\\n\\n（译者注：也上面代码执行完了之后，fetch 任务还没开始）我们可以调用 getUserAge.run(cb) 来让任务执行（译注：很像 Rx.js）。如果你多次调用 getUserAge.run，多个任务就都会执行，最后你会得到多个最终值。不错！这样一来我们既能复用 Promise，又能做到链式调用。（译注：这是针对 Promise Getter 说的，因为 Promise Getter 能复用，却不能链式调用）\\n延迟执行比立即执行更通用，因为立即执行无法重复调用，而延迟执行却可以多次调用。延迟执行对调用次数没有任何限制。所以我认为立即执行比延迟执行更 opinionated（译注：opinionated 是贬义词）。C# 中的 Task 跟 Promise 很像，只不过 C# 的 Task 是延迟执行的，而且 Task 有一个 .start() 方法，Promise 却没有。\\n\\n我打个比方吧，Promise 既是菜谱又是做出来的菜，你吃菜的时候必须把菜谱也吃掉，这不科学。\\n\\n### 不可中断\\n\\n一旦你创建了一个 Promise 实例，Promise 里的任务就会马上执行，更悲催的是，你无法阻止的执行。所以你现在还想创建一个 Promise 实例吗？这是一条不归路。\\n我认为 Promise 的「不可中断」跟它的「立即执行」特性密切相关。这里用一个不错的例子来说明：\\n\\n```\\nvar promiseA = someAsyncFn();\\nvar promiseB = promiseA.then(/* ... */);\\n```\\n\\n假设我们可以使用 promiseB.cancel() 来中断任务，请问 promiseA 的任务应该被中断吗？也许你认为可以中断，那就再看看下面这个例子：\\n\\n```\\nvar promiseA = someAsyncFn();\\nvar promiseB = promiseA.then(/* ... */);\\nvar promiseC = promiseA.then(/* ... */);\\n```\\n\\n这个时候如果我们可以用 promiseB.cancel() 来中断任务，promiseA 的任务就不应该被中断，因为 promiseC 依赖了 promiseA。\\n正是由于「立即执行」，Promise 任务中断的向上传播机制才变得复杂起来。一个可能的解决办法是引用计数，不过这种方案有很多边界情况甚至 bug。\\n如果 Promise 是延迟执行的，并提供 .run 方法，那么事情就变得简单了：\\nvar execution = promise.run();\\n\\n// 一段时间后\\nexecution.cancel();\\n\\npromise.run() 返回的 execution 就是任务的回溯链，链上的每一个任务都分别创建了自己的 execution。 如果我们调用 executionC.cancel()，那么 executionA.cancel() 就会被自动调用，而 executionB 有它自己的一个 executionA，跟 executionC 的 executionA 互不相干。所以可能同时有多个 A 任务在执行，这并不会造成什么问题。\\n如果你想避免多个 A 任务都在执行，你可以给 A 任务添加一个共享方法，也就是说我们可以「选择性地使用」引用计数，而不是「强制使用」引用计数。注意「选择性地使用」和「强制使用」的区别，如果一个行为是「选择性地使用」的，那么它就是中立的；如果一个行为是「强制使用」的，那么它就是 opinionated 的。\\n回到那个奇怪的菜谱的例子，假设你在一个餐厅点了一盘菜，但是一分钟后你又不想吃这盘菜了，Promise 的做法就是：不管你想不想吃，都会强行把菜塞进你的喉咙里。因为 Promise 认为你点了菜就必须吃（不可中断）。\\n\\n### 无法同步执行\\n\\nPromise 的设计策略中，允许最早的 resolve 时机是进入下一个 event loop 阶段之前（译注：请参考 process.nextTick），以方便解决同时创建多个 Promise 实例时产生的竞态问题。\\n\\n```\\nconsole.log(\'before\');\\nPromise.resolve(42).then(x => console.log(x));\\nconsole.log(\'after\');\\n```\\n\\n上面代码会依次打印出 \'before\' \'after\' 和 42。不管你如何构造这个 Promise 实例，你都没有办法使 then 里的函数在 \'after\' 之前打印 42。\\n最后的结果就是，你可以把同步代码写成 Promise，但是却没有办法把 Promise 改成同步代码。这是一个人为的限制，你看回调就没有这个限制，我们可以把同步代码写成回调，也可以把回调改成同步代码。以 forEach 为例：\\n\\n```\\nconsole.log(\'before\');\\n[42].forEach(x => console.log(x));\\nconsole.log(\'after\');\\n```\\n\\n这个代码会一次打印出 \'before\' 42 和 \'after\'。\\n由于我们不可能把  Promise 重新改写成同步代码，所以一旦我们在代码里使用了 Promise，就使得它周围的代码都变成了基于 Promise 的代码（译注：不是很理解这为什么就叫做基于 Promise 的代码），即使这样做没意义。\\n\\n我能理解异步代码让周围的代码也异步，但是 Promise 却强制让同步代码周围的代码也变成异步的。这就是 Promise 的又一个 opinionated 之处。一个中立的方案不应该强制数据的传递方式是同步或是异步。我认为 Promise 是一种「有损抽象」，类似于「有损压缩」，当你把东西放在 Promise 里，然后把东西从 Promise 里拿出来，这东西就跟以前不一样了。\\n\\n想象你在一个连锁快餐店里点了一个汉堡，服务员立即拿出一个做好的汉堡递给你，但是把手伸过去接却发现这个服务器死死地抓住这个汉堡不给你，他只是看着你，然后开始倒数 3 秒钟，然后他才松手。你拿到你的汉堡走出快餐店，想逃离这个诡异的地方。莫名其妙啊，他们就是想让你在拿餐之前等一会，还说是以防万一。\\n\\n### then() 其实是 map() 和 flatMap() 的混合体\\n\\n当传递一个回调给 then 的时候，你的回调函数可以返回一个常规的值，也可以返回一个 Promise 实例。有趣的是，两种写法的效果一模一样。\\n\\n```\\nPromise.resolve(42).then(x => x / 10);\\n// 效果跟下面这句话一致\\nPromise.resolve(42).then(x => Promise.resolve(x / 10));\\n```\\n\\n为了防止 Promise 套 Promise 的情况，then 内部遇到返回值是常规的值就转换成 Promise 实例（译注：这就是 map，参见 hax 对 map 的解释 Promise<T>.then(T => U): Promise< U >），遇到 Promise 实例就直接使用（译注：这就是 flatMap，Promise<T>.then(T => Promise< U >): Promise< U >）。\\n从某种程度上说，这么做对你是有帮助的，因为如果你对其中的细节不是很了解它会自动帮你搞定。假设 Promise 其实是可以提供 map、flatten 和 flatMap 方法的，我们却只能使用 then 方法来搞定所有需求。你看到 Promise 的限制了吗？我被限制只能使用 then，一个会做一些自动转换的简化版 API，我想做更多控制都是不可能的。\\n很久之前，Promise 刚被引入 JS 社区的时候，一些人有想过为 Promise 添加 map 和 flatMap 方法，详情你可以在这篇讨论里看到。不过参与语法制定的人以 category theory 和函数式编程等理由反驳了这些人。\\n\\n我不想在这篇文章里对函数式编程讨论太多，我只说一点：如果不遵循数学的话，就基本不可能创造出一个中立的编程原语。数学并不是一门与实际编程不相关的学科，数学里的概念都是有实际意义的，所以如果你不想你创造出来的东西出现自相矛盾的情况的话，也许你应该多了解一些数学。\\n\\n这篇讨论的主要焦点就是为什么不能让 Promise 有 map、flatMap 和 concat 这些方法。很多其他的原语都有这些方法，比如数组，另外如果你用过 ImmutableJS 你会发现它也有这些方法。map、flatMap 和 concat 真的很好用。\\n\\n想象一下，我们写代码的时候只管调用 map、flatMap 和 concat 即可，不用管它到底是什么原语，是不是很爽。只要输入源有这些方法即可。这样一来测试就会很方便，因为我可以直接把数组作为 mock 数据（译注：而不需要去构造一些 HTTP 请求）。如果代码中使用了 ImmutableJS 或生产环境中的异步 API，那么测试环境中只要用数组来模拟就够了。函数式编程中说的「泛型」「type class 编程」和 monad 等都有类似的意思，说的是我们可以给不同的原语以一批相同的方法名。如果一个原语的方法名是 concat 另一个原语的方法名是 concatenate，但是实质上它们做的是几乎相同的事情，就很令人讨厌了。\\n\\n所以为什么不把 Promise 理解成跟数组差不多的概念，有 concat、map 等方法。Promise 基本上可以被 map，所以就给 Promise 添加 map 方法吧；Promise 基本上可以被 chain，所以就给 Promise 添加上 flatMap 方法吧。\\n\\n不幸的是现实不是这样的，Promise 把 map  和 flatMap 挤到 then 里面，并加了一些自动转换逻辑。这么做只是因为 map 和 flapMap 看起来很类似，他们认为写成两个方法有点多此一举。\\n\\n## 总结\\n\\n好吧，Promise 也能工作，你可以用 Promise 搞定你的业务而且一切都运行良好。没必要惊慌。Promise 只是看起来有点怪异了，而且真不幸它还很 opinionated。他们强加给 Promise 一些在某些时候毫无意义的规则。这么做问题不大，因为我们可以很容易的绕过这些规则。\\nPromise 很难复用，没关系我们可以用额外的函数搞定；\\nPromise 不能被中断，没关系我们可以让那些本该中断的任务继续执行，不就是浪费了一些资源而已嘛。真烦人，我们总是要给 Promise 做一些修修补补；真烦人，现在新出的 API 都是基于 Promise 的，我们甚至给 Promise 发明了一个语法糖：async/await。\\n\\n所以接下来几年我们都要忍受 Promise 的这些怪异之处。如果我们一开始就把延迟执行考虑到 Promise 里，也许 Promise 就是另外一番光景了。\\n如果 Promise 的设计初期就是从数学角度思考会是什么样子？这里我给出两个例子：fun-task 和 avenir，这两个库都是延迟执行的，所以有很多共同点，不同点主要体现在命名和方法可访问性上。这两个库都比 Promise 更不 opinionated，因为它们：\\n\\n1. 延迟执行\\n1. 允许同步\\n1. 允许中断\\n\\n## 反驳\\n\\n本文就是要吐槽 Staltz 最近写的这篇文章《Promises are not neutral enough》。\\n\\nStaltz 作为 Cycle.js 的作者，也算是社区名人之一。最近他搞了一个大新闻叫 Callbag（Why we need Callbags），一看名字就是给 callback 招魂的。这篇我不打算吐槽 callbag（想看吐槽 callbag 的可移步：callbag和rxjs有什么区别？），就单吐槽一下 Staltz 对于 promise 的偏见。\\n\\nStaltz 说 promise 是“opinionated primitive that introduce a lot of weirdness”，并列了四点 opinion：\\n\\n1. Eager, not lazy\\n1. No cancellation\\n1. Never synchronous\\n1. then() is a mix of map() and flatMap()\\n\\n我一点点来说。\\n\\n第一点，promise 是 eager 立即求值而不是 lazy 延迟求值。\\n\\n其实这个事情是有点扯的。因为所有语言、库里的 promise 抽象（有些叫 future 或 deferred，语义上有些差别，但是在此问题上不重要，所以这里不展开说）都是如此。也就是说如果还需要用户主动调用 x.run() 来开始计算，那就不是 promise 了。那叫 task（或 fiber，或类似的 thunk）。\\n\\n（当然不排除世界上有些傻逼库硬是要做一个 lazy future 之类的东西。其实你既然要提供不同的抽象，安安心心的叫 task 就好了，不要把概念搞乱行不行。）\\n\\n到底 task 好还是 promise 好？这本身其实有点关公战秦琼。因为两者其实是不同的抽象。task 的抽象侧重于“执行（任务）”，而 promise 的抽象侧重于“（最终的）值”。这不同的抽象选择导致不一样的语义和 API，是一件非常自然的事情。若侧重于“执行”，那自然应该允许用户选择何时执行，也没有必要限制执行一定是同步的还是异步的，甚至无所谓是否在单独线程里跑 —— 直接抵达了 thread 的领域。而若侧重于“值”，那用户为什么要 care 这个值的运算过程？\\n\\n其实如果你需要控制执行（sometimes you don’t want the promise to start right away），或重用异步任务（you may want to have a reusable asynchronous task），直接写一个返回 promise 的函数，或者一个 async 函数就好了啊！函数就是用来表达执行的啊！如此简单而自然！\\n\\nStaltz 当然知道这一点，但他强词夺理说函数就不能用 then 来 chain 了。我擦，人家 promise 就是一个异步值的原语，then 方法只是为了在没有 async/await 的时代，提供你一个利用异步值的基础设施。（否则你压根没法用啊！）然而你为什么要让它去管函数链式调用？你如果要处理一般的函数链式调用，自己 compose 函数啊，或者等着 pipeline operator 啊！（在别的地方你倒知道吹 pipeline operator，怎么说起 promise 来就忘了？？）\\n\\n说什么“Eager is less general than lazy”，完全是胡说八道。你在一个 lazy 的语言比如 haskell 里这么说也就算了，你在一个明明全然是 eager 的语言里说“eager is less general”，颠倒黑白没有这么流利的吧？\\n\\n第二点，没有 cancellation。确实 promise 没有内置这能力（cancelable promise 提案因为各种原因被撤销了）。但是现在有 cancelation 提案（tc39/proposal-cancellation）啊，而且最新版浏览器已经支持了一个非常类似的方案（DOM Standard）！（当然dom规范里的 AbortController/AbortSignal 如何跟语言规范里的机制协调可能是个棘手问题，有待处理，不过大方向是没有问题的。）\\n\\nStaltz 说“I believe lack of cancellation is related to eagerness.”不好意思，全错。你后面提到的 cancel 在向上游传播时的问题，本质上在于向上传播本身就是概念混乱的产物，跟立即执行没有半毛钱关系。建议好好再学习一下 cancelation token 提案的 architechture 部分（tc39/proposal-cancellation#architecture）。\\n\\n比较神奇的是\\n\\nTry to pay attention to the words “opt-in”, “restriction”, “always”. When a behavior is opt-in, it is neutral. When a behavior is always forced, it is opinionated.\\n这段完全是稻草人攻击。实际上 cancellation 无论是当前提案还是 dom 规范里的设施，都是独立于 promise 的，所以必然是 opt-in 的。\\n\\n其实前面的 eager 问题也是。显然返回 promise 的 function 就提供了所谓 lazy，且 promise 和 function 是独立特性，所以我们可以说你所谓的 lazy 是 opt-in 的。但是你反过来说这是 restriction？？这双重标准是怎么玩的？？\\n\\n第三点，总是异步。这一点其实没有好多说的。node callback convention 也包含了这一点（只不过 callback 形式很难强制约束这一点，这是 callback 的缺陷之一）。对此有疑问的人建议再好好读 Isaac Z. Schlueter 多年前的经典文章：http://blog.izs.me/post/59142742143/designing-apis-for-asynchrony 。\\n\\n所以 forEach 的例子正说明问题。forEach 明确的告诉你这里是同步的。promise 则明确的告诉你这里是异步的。这是为什么 promise 必须总是异步，且你应该在所有处理异步的地方都使用 promise。这样就不会出现你看到一个 callback 但是搞不清它是同步还是异步了。\\n\\n为什么同步异步之分在 JS 里那么重要？因为 JS 不是 pure 函数式语言！JS 代码会依赖副作用，而副作用取决于代码的执行时序。JS 有 run-to-completion 语义，所以只要明确是同步还是异步，其执行时序是非常容易推断的。\\n\\n下面忍不住要逐段打脸。\\n\\n    The impossibility of going back to synchronous once you convert to Promise means that using Promises in a code base will force code around it to be Promise-based even when it doesn’t make sense.\\n\\nPromise 本来就是异步原语。异步当然不能被转换为同步啊！除非你用阻塞。而在 JS 里提供阻塞等于提供一把注定会打死你自己的枪。promise 也并没有把所有代码都变成基于 promise 的，传给 then 的回调完全可以是纯同步的代码啊！\\n\\n    I can understand why async code forces surrounding code to become async too, but Promises make this effect worse by forcing sync code to become async. That’s yet another opinion inserted into Promises.\\n\\n说来说去就是说异步的传染性。你要是依赖一个异步值，你的函数当然就得是异步的啊。但是你已经 await 到一个值之后所做的计算可以抽成一个纯同步的函数啊。自己模块化做不好，怪语言设施…… 再说你不是 observable 和 pipeline operator 玩得很溜嘛，又没说不许用。\\n\\n    A neutral stance would be to have the primitive make no claims whether the data will be delivered synchronously or asynchronously.\\n\\n同样的话也可以用来批评 haskell，你们搞什么 pure，搞什么 lazy，完全不“中立”！\\n\\n    Promises are what I call a “lossy abstraction”, similar to lossy compression, where you can put stuff in that container, but when you take it out of the container, it’s not quite the same as it was before.\\n\\n对“抽象”的理解简直一团屎。按照这说法，高级语言都是“lossy abstraction”，汇编才是无损纯真的代码！\\n\\n说了半天其实 Staltz 就是有意忽略一点，Promise 对 JS 来说就是异步原语，由此施加额外约束是应有之义。你所谓“中立”的结果无非是给程序员留坑。\\n\\n最后一点，Staltz 吐槽 then() 不是正宗原味 monad。这算整篇文章比较有技术含量的部分了。然而首先，map 和 flatMap 的签名是：\\n\\n```\\nM<T>.map(T => U): M<U>\\nM<T>.flatMap(T => M<U>): M<U>\\n```\\n\\n而 then 的签名是：\\n\\n```\\nPromise<T>.then(T => U): Promise<U>\\nPromise<T>.then(T => Promise<U>): Promise<U>\\n```\\n\\n易见，then 实际上是自动 overload 版的 map/flatMap。Staltz 吐槽点就是，干嘛不直接暴露 map/flatMap 呢？这样就可以跟其他 monad 小伙伴一起玩耍啦！\\n\\n我先不说你是不是真的有场景要统一操作异种 monad，我先把你提到的“马上就要到来的”Array.prototype.flatMap 拿出来看一下。\\n\\nArray<T>.flatMap(T => Array< U>): Array< U>\\n\\n理想上其签名应该是这样的，然而，JS 不是静态类型语言啊！谁确保传进来的回调是 T => Array< U> 呢？如果返回值不是 Array，那就等于传进来了 T => U 啊。\\n\\n于是你突然发现，Array.prototype.flatMap 明明跟 Promise.prototype.then 是一样的，自动 overload 了！\\n\\n所以，在动态类型语言里，只要你不打算做运行时检查类型扔 TypeError 这种事情，flatMap 对回调的结果进行自动 wrap（从而 overload 了 map）是必然的选择。\\n\\n所以 then 就是 flatMap。唯一的问题是为什么 promise 不像 array 一样提供单独的 map？\\n\\n为什么要提供？我先不说提供单独的 map 方法让你可以得到 Promise<Promise< U>> 有毛个意义。我们谈理论。\\n\\n在 monad 鼻祖的 haskell 那里，定义 monad 只需要 2 个操作：return 和 bind。return 就是 wrap/unit，即从 T => M<T>。而 bind 就是 flatMap。\\n\\n所以 Promise 从 Haskell 本源意义上说千真万确就是一个 monad。当然我们也可以用另一个方式定义 monad，使用 3 个操作：return、fmap 和 join。\\n\\nfmap 就是 map，join 则是 flatten，即将 M<M<T>> 打平为 M<T>。\\n\\n所以本来你就有两种方式定义 monad，一种用 flatMap，一种用 map + flatten。实际上很容易理解，有了 map 和 flatten 你就可以实现出 flatMap。但是，反过来说，有 flatMap 我们也可以实现出 map 和 flatten。\\n\\n```\\nfunction map(f) { return this.flatMap(x => wrap(f(x))) }\\nfunction flatten() { return this.flatMap(x => x) }\\n```\\n\\n所以 promise 本身不提供 map 和 flatten 方法并没有任何问题。当然你可以吐槽 JS 没有内置的 mixin 语法或 extensive methods（其实都有提案），使得统一接口比较麻烦，但无论如何吐槽不到 promise 。\\n\\n当然，promise 有特殊之处，比如 wrap 操作理论上不能直接用 Promise.resolve，因为 Promise.resolve(promise) 并不返回 Promise<Promise<T>>。实际上在 JavaScript 中是不可能产生 Promise<Promise<T>> 嵌套类型的。显而易见，这一限制是出于实际编程的考虑。但是 Staltz 直接否定了这一点。\\n\\nSo it’s better to recognize that Promises can practically be concatenated, so they should have the concat method.\\n问题是你不能简单的吹说“practically”，你得拿出真实 use cases 啊！嘴炮谁不会？你倒是真拿一个把 Promise 给 concat 起来的例子啊！\\n\\n### 结论部分。\\n\\n上面我已经把 Staltz 的各点批驳完毕。\\n\\n关键点在于，promise 的出发点是提供异步原语。有意无意的忽略这一点，所有论证就都乱来了。Promise 的设计总体上没有任何问题，Staltz 希望的：\\n\\n所谓 lazy\\n直接在 promise 接口上提供 cancel()\\nresolve 时而同步时而异步\\n提供无意义的 Promise<Promise<T>>\\n才是 weird、unfortunately opinionated 的。\\n\\n    Promises were invented, not discovered. The best primitives are discovered, because they are often neutral and we can’t argue against them. For instance, the circle is such a simple mathematical concept, that’s why people discovered it instead of inventing it. You often can’t “disagree” with a circle because there’s no opinion embedded in it, and it occurs often in nature and systems.\\n\\n说不清道理，就上比喻，文章里那无聊的 food 比喻我就不吐槽了，这里又拿圆形来比喻。一股浓郁的民科风。\\n\\n实际上，编程设施全都是发明出来的。从最基本的二进制补码整数类型、IEEE754浮点数、Unicode字符，到复杂的数据结构如红黑树、bloom filter乃至神经网络，无一不是发明出来的。各种语言的语法语义也都是发明出来的符号系统。包括monad。我们发明它们用来表达运算逻辑。（其实真正搞数学的人，会告诉你数学里也是如此，符号公理系统都是发明出来的。）\\n\\nPromise 是发明出来的，node callback conversion 或者 Staltz 自己搞的 callbag 显然也都是发明出来的。或者我们换个正常点的词，这些东西是为了一定目的被设计出来的。如果有人说我发现了某某，多数是谦辞，表示不是我牛逼，只是运气好而已。真正可以被发现的，只有客观存在。编程里有什么东西是真的发现出来的？估计只有 bug 吧。\\n"}'));jctx.push(JSON.parse('{"id": "200102", "tag": "tool", "text": "# 命令行工具用法探索\\n\\n## ls\\n\\n`--hide`可以隐藏不想看的目录\\n\\n## find\\n\\n最核心参数是path和expression，这两个参数都有默认值，path是当前目录，expression就-print，相当于只输入find和tree的效果类似。所有的expression一定是`-`号开头，find解析就以此为依据。\\n\\nwindows用 `dir <findname> /-n /b /s /a-d` 模拟。\\n\\n## xargs\\n\\nxargs和find同属于findutils包，xargs原本就是为find而开发的\\n\\n## pkill\\n\\n默认仅process匹配，-f变为command line匹配\\n\\n## info\\n\\nH 打开按键帮助\\n\\n{} 向前或向后查找上一次的关键字"}'));jctx.push(JSON.parse('{"id": "200105", "tag": "os", "text": "# 硬盘操作和文件系统散记\\n\\n## 硬盘操作\\n\\n首先要明确个概念，每块硬盘都有设备和分区这层概念，一块硬盘当然对应一个设备，但会有一到多个分区，util-linux包提供了多个操作硬盘的程序。\\n\\n* fdisk: 应该是最有名的程序了，fdisk -l显示当前总线上已经识别出的设备\\n* lsblk: 显示块设备、dev的major/minor号、挂载点等。关于lsblk命令查看分区和挂载目录的关系，其实mount也能看，但如果装过容器，mount会看不清楚，这时用lsblk就很方便\\n* blkid: 只会列出分区，但可以识别文件系统。比如/dev/sda被分成了sda1和sda2，用blkid看不到sda，只能看到sda1和sda2，行为和df命令一样。而lsblk既能看到设备也能看到分区\\n* hdparm: 只知道，不太会用\\n\\n以上这些命令都是针对硬盘，所以就算没有挂载，也可以看到硬盘。\\n\\nfile命令的-s选项可以查看块设备的特性，比如`file -s /dev/sda`能看到这块盘是GRUB启动程序，接着又是若干个分区。而直接`file -s /dev/sda1`就只显示分区信息，可见/dev/下面分开显示sda和sda1并不是无意义的。\\n\\n### 磁盘挂载失败记录\\n\\n服务器磁盘被拔，导致系统进入emergency模式，即使login所有服务也未启动。原因出在盘被拔，但/etc/fstab却没有修改，系统认为缺少盘所以进了应急模式。每块磁盘会有个UUID，fstab也是通过这个来找盘。用blkid命令可以看到所有盘的UUID。两相对比去掉不存在的盘就行。\\n\\n修改后不用重启，mount -a就能挂载。这时又出现新问题，报UUID重复错误，用mkfs.xfs -f /dev/sdx格式化硬盘，再挂载就没问题了。\\n\\n磁盘写入有两种模式\\n\\n* write through: 直写式，数据不做校验直接写入磁盘，写完后再读出来后写校验值。性能差，可靠性高？\\n* write back: 写回式，数据先写到cache，再用cache计算校验值，然后数据和校验一起定入磁盘，如果cache足够大且性能强，可以一直写入。有些RAID卡要开启这种模式，除了有cache，还要有电池，保证掉电后cache数据也能写入磁盘。\\n\\n## 文件系统\\n\\n安卓有`protect_f`和`protect_s`分区，s是f的备份，专门用来保存SIM ME LOCK数据，运营商专用机就是修改这份数据达到的。原来是保存在/data分区，为保证恢复出厂时不用重新生成，干脆做成独立分区。\\n\\n文件系统单个分区上限取决于单个簇大小和簇个数，比如ext3的簇个数是uint32，取常见的簇大小4K来算，分区上限就是16TB。（似乎ext3簇大小不可改，NTFS可以改成单簇64K使上限达到256T）\\n\\nZFS的默认簇是128K，在和PG数据库配合时，其默认记录大小是8K，如果数据库用于零散查询较多的场景，最好用`zfs set recordsize=8k zp1/data`也调整到8K效率更高。"}'));jctx.push(JSON.parse('{"id": "200108", "tag": "os", "text": "# shell的模式与选项\\n\\n起因是看到有人写脚本，用/bin/cp方式复制文件，说是因为cp在复制时如果文件名相同会提示是否覆盖，导致脚本会停住。这个行为是因为操作系统对root用户默认alias cp=\'cp -i\'导致的，所以用/bin/cp绕过，我于是想到为何不在脚本开头用unalias去掉cp的定义，后面直接写cp就方便了。\\n\\n验证时却发现会提示unalias cp not found。于是在终端下尝试，第一次成功，第二次提示同样错误，这就说明在fork出的shell环境下没有alias，不需要特意用/bin/sh。但是为什么子shell没有继承alias？又加了alias发现不仅cp没有继承，其它的都没有被继承。\\n\\n网上有人说这个特性只有交互模式才会打开，即bash --login才能用，又有人说要用shopt方式显示打开，可是试了似乎都不对。忽然想到alias是shell的buildin命令，说明是进程独有的功能，而fork子进程时，只能通过环境变量传递参数，既然alias不属于环境变量，也就无法自动地传递给子进程，只能显示地加载/etc/profile之类的文件才能使alias生效。\\n\\n## 交互与登陆模式\\n\\n交互模式 interactive，仅输入bash，也是最常见的模式，为交互模式。而参数中有文件名或-c方式调用语句，就是非交互模式。看`$-`有没有i来判断。由于不需要交互，.bashrc就不会读入(新版本才有的特性)，节约脚本执行时间。\\n\\n登陆模式 login，和交互模式是完全正交的。login指非常早期就启动的shell，会读入profile类文件，后面的用户在duplicate shell操作时，是fork了这个login shell，真实得到的是ono login但interac。前文提到的通过ssh触发的bash就是这种模式。登陆模式下可以用logout退出，用shopt 观察。登陆模式用于显示tips或欢迎信息，默认不打开，su的时候就比较静默，也可以强制su --login显示欢迎词。\\n\\n习惯上，non interactive, login是很罕见的，只在部分X程序会用。\\n\\n不同模式读入配置是不同的\\n\\n```\\n/etc/profile   交互模式读入，似乎有误，当为登陆模式\\n/etc/bashrc或bash.bashrc  似乎并不会被读，通用配置保存在这里\\n~/.bash_profile   login按序读以下3个，读到停止\\n~/.bash_login\\n~/.profile\\n~/.bashrc    non-login读\\nBASH_ENV   非交互模式使用\\n```\\n\\n## 选项\\n\\nPOSIX规范要求用set控制选项，bash增加了特有的shopt并在另一个命名空间保存这些选项。set不能影响shopt，但shopt用-o可以操作set空间。set空间以全大写的环境变量为主，而shopt都是小写。\\n\\n选项会对脚本的执行带来微秒的影响，有一次我不经意间引入了`set -e -u`，导致程序无法执行，看了帮助手册才明白这代表error exit，当命令退出状态是失败时，整个脚本就退出了。由于我原来的代码中会用grep判断tar包中是否有一个文件，当不存在时grep会以失败退出，如果不加-e选项，并不会引起问题，但当更严格的-e开启后，程序就不再继续执行。而-u则对$1这样的变量展开做了更严格限制，如果不存在就退出，$@和$\\\\*不受-u开启的影响。\\n\\n## 非阻塞同步\\n\\n后台方式调用其它脚本，紧接着用`$!`记录下进程号，最后用wait方式等待结束。"}'));jctx.push(JSON.parse('{"id": "200122", "tag": "tool", "text": "# putty的配置\\n\\nputty是个免费且方便的终端工具，其它像xshell等在按下Alt时会触发菜单栏，导致使用emacs时不好用，但是putty默认的配置不如xshell方便，列举如下\\n\\n首先在Connection菜单开启保活，keepalives设置为300，否则长期不用会断开远程连接。\\n\\n默认情况下字体很少，先勾上Appearance的Allow selection of variable-pitch fonts，就能选择Lucida Console，此后关掉这个选项还是可用，怀疑是个bug。\\n\\n配色，终端定义了文本、背景和8种ANSI颜色，每一种又可以叠加Bold属性。规范只定义了有这些选择，具体如何展示还取决于终端软件的设定甚至和显示器效果也有关系。putty默认文字颜色较暗且文件夹的蓝色和背景接近，很难看清，建设改为以下配色\\n\\n以下3个数字分别表示RGB\\n\\n* Default Foregroud: 230/230/230  网上很多方案推荐全用255，这样会和Bold Foregroud一样，不能区分两种信息，最好稍暗一点\\n* Blue: 30/140/240\\n* Blue Bold: 85/190/255\\n* Red: 200/0/0\\n* Magenta: 200/0/200\\n\\n还有一些ANSI控制码，如：nA (光标上移n行 )、nB(光标下移n行 )、nC(光标右移n行 )、nD (光标左移n行 )、2J(清屏)、K(清除从光标到行尾的内容)、s(保存光标位置)、u(恢复光标位置)、?25l(隐藏光标)、?25l(显示光标)。     其中 ，\'\\\\033[0m\'用于恢复默认的终端输出属性，否则会影响后续的输出。\\n\\n基于常用参数，可定义如下单一控制宏，用于printf系列语句：\\n```\\n#define NONE                 \\"\\\\e[0m\\"\\n#define BLACK                \\"\\\\e[0;30m\\"\\n#define L_BLACK              \\"\\\\e[1;30m\\"\\n#define RED                  \\"\\\\e[0;31m\\"\\n#define L_RED                \\"\\\\e[1;31m\\"\\n#define GREEN                \\"\\\\e[0;32m\\"\\n#define L_GREEN              \\"\\\\e[1;32m\\"\\n#define BROWN                \\"\\\\e[0;33m\\"\\n#define YELLOW               \\"\\\\e[1;33m\\"\\n#define BLUE                 \\"\\\\e[0;34m\\"\\n#define L_BLUE               \\"\\\\e[1;34m\\"\\n#define PURPLE               \\"\\\\e[0;35m\\"\\n#define L_PURPLE             \\"\\\\e[1;35m\\"\\n#define CYAN                 \\"\\\\e[0;36m\\"\\n#define L_CYAN               \\"\\\\e[1;36m\\"\\n#define GRAY                 \\"\\\\e[0;37m\\"\\n#define WHITE                \\"\\\\e[1;37m\\"\\n\\n#define BOLD                 \\"\\\\e[1m\\"\\n#define UNDERLINE            \\"\\\\e[4m\\"\\n#define BLINK                \\"\\\\e[5m\\"\\n#define REVERSE              \\"\\\\e[7m\\"\\n#define HIDE                 \\"\\\\e[8m\\"\\n#define CLEAR                \\"\\\\e[2J\\"\\n#define CLRLINE              \\"\\\\r\\\\e[K\\" //or \\"\\\\e[1K\\\\r\\"\\n```"}'));jctx.push(JSON.parse('{"id": "200125", "tag": "tool", "text": "# tags的说明和比较\\n\\n通用编辑软件用于代码有两个点，看时方便跳转和写时方便补全，跳转靠的就是tags。\\n\\ntags有两种主流实现ctags和etags。ctags诞生于BSD系统，是vim能原生识别的格式，而etags是emacs的附属品。两者生成的文件格式不同，但ctags能生成etags的格式，似乎ctags使用更广，emacs上有插件能识别ctags格式。\\n\\n不同语言的要素不同，ctags有相应的选项来识别，从而更好地跳转。默认什么都不加也能工作，显然加上会更精准。识别要素有3种类别\\n\\n1. kinds: 用--list-kinds=xx 显示默认会识别哪些元素，如果要调用，用--xx-kinds=+-yy 选项\\n2. fields: 比如 i 表示如果有继承，要标明父类； a 表示如果是类的成员，要标明其public/private属性； S 表示如果是函数，要标明函数的signature；\\n3. extra: 默认只包括函数的名字，不包括类名，用了--extra=+q会有类名\\n\\n早期的tags只包含definition，universal ctags已具备简单的reference功能，外围配套还不是非常成熟。\\n\\n## 文件格式\\n\\nctags是纯文本文件，每行是一条记录，原始的vi格式很简单，`{tagname}<Tab>{tagfile}<Tab>{tagaddress}`，定义标签名，所在文件，所在行的完整内容(ex模式)。当编辑器触发跳转定义时，从tags文件找到匹配的行，并解析出对应的文件名，再根据最后的模式精确定位到行，核心功能很好理解。vim对行格式做了增强，在原来行的末尾增加`;\\"<Tab>{tagfield}...`，其中`;\\"`会被vi识别成注释，保持兼容性。后续内容是type<tab>key:value，type是单字母形式，kv对可以有多个。\\n\\netags由多个section组成，每个section对应一个源文件。段间和段内含有少量不可打印字符，绝大多数仍是文本。段与段间由两行`<\\\\x0c>`分隔，然后是文件名和tag的字节数，接下来也是每行一个tag定义，`{tag_definition_text}<\\\\x7f>{tagname}<\\\\x01>{line_number},{byte_offset}`，和ctags相比，由于直接保存行号和偏移，在尺寸上etags要小很多，但是如果对一个在编辑中的工程来说，增加内容导致行号变化，会使etags失效，而ctags方式的按文本匹配会更健壮。"}'));jctx.push(JSON.parse('{"id": "200126", "tag": "os", "text": "# 安卓程序的构建与链接\\n\\n## configure的改造\\n\\n尝试在安卓编译python，保证PATH有gcc/ar/make，再改几行脚本就行。\\n\\n1. configure以及触发的config.sub和install-sh默认通过/bin/sh执行，要换成可以运行的sh路径。\\n2. configure中有CONFIG_SHELL变量默认指向/bin/sh，可以改脚步也可以通过export这个变量来修改，但必须export，只是在shell定义没用。因为configure会fork大量进程，只有export后子进程才能感知到\\n3. 手动修改configure的`__ANDROID_API__`为某个版本，怀疑可能个用的gcc有关，好在改完这行就能用了\\n\\n## linker\\n\\n在termux(android5 API21)编译的程序，放到4.2的机器上执行，报`line 1: syntax error: unexpected \\")\\"`无法执行，第1行出现/system/bin/linker字样，故有此文。\\n\\n在android 2.x及4.0或更远古时代，系统在执行一个elf文件时，这个elf文件是固定加载到某个内存位置的。而后来llvm的出现，使得编译出来的elf文件，可以加载到内存中的任意位置，这种就叫pie。5.0后的android系统强制要求只能加载pie的文件，也就是说，使用gcc编译的固定基址的elf文件就再也不能执行了(大概这也是termux只支持clang不支持gcc的原因？)。\\n\\nAndroid在启动一个新的进程的时候，调用execv函数族trap到内核，由kernel去检查和加载可执行文件；kernel做完可执行文件的加载的同时会加载/system/bin/linker，然后由linker去加载依赖的动态库，并调用可执行文件的入口函数，完成控制权的转移。linker还参与了调试的一些东西。通俗地说，它是一个elf文件的解释器。"}'));jctx.push(JSON.parse('{"id": "200203", "tag": "lang", "text": "# [翻译]funarg问题\\n\\n很多新的编程语言都支持function as first class特性，即函数可以像普通的值一样传入或传出。但函数和变量有个最大的区别，函数会引用变量，如何保证变量的生命周期就成了问题(因此称为function argument，即funarg问题)。具体的困难在于，定义函数的环境和执行函数的环境是不同的，标准的解决办法要么禁止这种引用，要么创建闭包。主流语言的实现方式简列如下\\n\\n这个问题细化又有两种分支，向上funarg(函数调用返回函数)和向下funarg(把函数作为参数传递给函数)。\\n\\n## 向上funarg\\n\\n总共有4种方式\\n\\n1. 一种简单的做法是把变量保存在堆上，然后用GC回收，一些scheme实现这么做。但这样效率不如在栈上，且显著地增加实现复杂度，对没有GC的语言非常困难。\\n2. 逃逸分析，在编译期做筛选，只对涉及向上funarg的创建堆上变量，其它就不用管。\\n3. 在创建闭包时把值复制到闭包，但这只适合不变的值，比如ML和Java就是这种方式，ML的变量全是constant，对java来说“引用”的东西必须是final的，否则被改了之后闭包里的值不会更新。\\n4. 显式指定引用的变量，把指定的扔堆上，比如php的use语句和object-c的\\\\_\\\\_block\\n\\n## 向下funarg\\n\\n这种情况由于上层的栈还在，引用通常不会造成问题。但对于tail-call和CPS风格的代码，会有额外的工作量。此时不能简单地完全把栈替换掉，否则会触发变量无法找到的问题。相比向上funarg，向下并不是什么难题，因此Pascal语言支持向下funarg，但不支持向上funarg。\\n"}'));jctx.push(JSON.parse('{"id": "200207", "tag": "tool", "text": "# 多终端打开软件用法\\n\\n## GNU screen\\n\\n修改默认的引导键C-a时，命令行启动时使用screen -e^tt绑定到C-t。前一个t表示自定义命令字符，相当于所有命令的触发按钮，后一个t表示转义字符，因为C-t被占用了，必须按C-t t才能被screen里面的程序理解为C-t，这个特性很少用。也可以在.screenrc中加上escape ^yy转义。\\n\\n离开screen环境的常用命令(以下用sr表示)\\n\\n* sr -ls 展示当前已有的会话，本质是列出已连接的socket(有几个连接，就在~/.screen/目录下有几个文件)，如果socket断开，会显示dead，这时用-wipe可以清除这些socket\\n* sr -r [pid] 恢复，如果只有一个不用输入pid\\n* sr -xRR 如果后台有一个现有的screen，则连上去，否则创建一个新的\\n\\n在screen内的快捷键(cmd表示映射的)\\n\\n* C-? A 修改窗口名称\\n* C-? \\" 展示所有窗口，进而切换\\n* C-? : 进入交互式命令行窗口，方便临时修改配置\\n\\n一些发行版(termux、alpine)在执行时，窗口大小会变化，手动改width会提示your termcap does not specify your terminal width。原因是那些发行版使用terminfo，需要转换后才能修改终端窗口。[这里](https://www.math.utah.edu/docs/info/screen_15.html)有完整的说明。\\n\\n进入screen默认没有任何显示，通过修改hardstatus来表示(hardware的意思，似乎这个是硬件内嵌吧)。\\n\\n## tmux\\n\\n配置文件.tmux.conf\\n\\n```\\n# Send prefix\\nset-option -g prefix C-a\\nunbind-key C-a\\nbind-key C-a send-prefix\\n\\n# Use Alt-arrow keys to switch panes\\nbind -n M-Left select-pane -L\\nbind -n M-Right select-pane -R\\nbind -n M-Up select-pane -U\\nbind -n M-Down select-pane -D\\n\\n# Shift arrow to switch windows\\nbind -n S-Left previous-window\\nbind -n S-Right next-window\\n\\n# Mouse mode\\nset -g mouse on\\n\\n# Set easier window split keys\\nbind-key v split-window -h\\nbind-key h split-window -v\\n\\n# Easy config reload\\nbind-key r source-file ~/.tmux.conf \\\\; display-message \\"tmux.conf reloaded\\"\\n```\\n\\nSend prefix\\n把prefix的ctrl+b变为了ctrl+a，因为这样按起来方便些。基本上用tmux的都改了这个。\\n\\nUse Alt-arrow keys to switch panes\\n不用按prefix，直接用alt+箭头在pane之间switch。实际用过之后才发现真是太方便了！\\n\\nShift arrow to switch windows\\n不用按prefix，直接用shift+箭头在window之间switch。太方便了！\\n\\nMouse mode\\n开启鼠标模式。用鼠标就能切换window，pane，还能调整pane的大小，方便！\\n\\nSet easier window split keys\\n这一部分是用来更方便切分pane的。prefix + v 代表竖着切，prefix + h 代表横着切。比起默认的切割方法不仅直观而且方便。\\n\\nEasy config reload\\n下一次如果修改了.tmux.conf的设置的话，不用关掉tmux。直接用prefix+r,就能重新加载设置。\\n\\n2 Panes\\n\\n分割pane\\n\\nprefix + % :水平分割pane\\nprefix + \\" : 竖直分割pane\\n退出\\n\\nexit ： 退出一个pane，直接在shell里输入即可，这个比快捷键方便\\n放大一个pane\\n\\nprefix + z : 把当前一个pane放大（zoom in)。比如在用ls查看output的时候，因为一个pane可能空间太小，所以把这个pane放大，你可以把注意力全放在这个pane里。回到之前的多pane状态的话只需要重复一遍命令即可(zoom out)\\n在pane之间switch\\n\\nprefix + 上下左右的箭头 :这个说实话还是不方便，之后会有设置的方法来用鼠标选择pane\\nresize the pane\\n\\nprefix + （ctrl）+上下左右箭头 : 与上面命令不同的是，ctrl + b按完之后，不要松开ctrl，一直按着，然后再按箭头来调整。不过因为在mac下ctrl+箭头是切换屏幕，所以还得在偏好设置->键盘->快捷键->Mission Control里把对应的快捷键取消掉。\\n3 Windows\\n创建window\\n\\nprefix + c : 创建一个新的window。最下面会多出window的编号。有*号所在的window就是当前正在操作的window。\\n在不同的window间移动\\n\\nprefix + 数字1，2，3 : 因为能看到不同window的数字编号，所以直接输入想去的window的数字编号即可\\n关闭window\\n\\nprefix + & ： 关闭当前window\\n重命名window：因为创建新的window后，下面除了数字编号不同外window名称都是一样的。所以为了知道每一个window是什么，最好重命名一下。\\n\\nprefix + , (逗号）：更改window名称。但是这里遇到一个问题。更名后，我随便使用ls或cd命令后，window名称会随着目录的不同而变化。google后发现这个是zsh下oh-my-zsh的特性。于是打开~/.zshrc, 讲DISABLE_AUTO_TITLE=\\"true\\"这一行反注释掉。source ~/.zshrc后，测试更改的名称，发现一切正常。\\n\\n5 Session\\n查看所有的session（在terminal输入）\\n\\ntmux ls : 这个命令是在terminal里输入的。当前正常运作中的tmux server会显示（attached）。没有的话就是已关闭，tmux server在后台运行。\\n更名session（tmux状态下输入）\\n\\nprefix + $ : 更名后好让自己知道每一个session是用来做什么的。通常一个session对应一个project\\n创建session的时候直接命名(在terminal输入）\\n\\ntmux new -s py35 : 新建一个名为py35的session\\n断开一个session(detached) （tmux状态下输入）\\n\\nprefix + d ：退出session。在只有一个window的状态下，直接输入exit也能退出\\n重新连接某一个session wich name（在terminal输入）\\n\\ntmux a -t py35 : 重新连接py35 session。这里的a是attach的意思\\n偷懒连接上一个session（在terminal输入）\\n\\ntmux a : 如果只有一个session的话，这个是最快的连接方法\\n删除session（在terminal输入）\\n\\ntmux kill-session -a -t py35 : 删除除了py35以外的所有session\\n\\n## 附录\\n\\nvim支持的终端库有5种：tinfo, ncurses, termlib, termcap, curses。应该只是实现不同，都有相同的函数。"}'));jctx.push(JSON.parse('{"id": "200210", "tag": "book", "text": "# 罢湖广总督为天子立威！\\n\\n已经在《C1：他们到底怕什么》和《梳理流程也没用》这两篇《结构学》的应用文章中阐述过统治结构的特征及其天然缺陷。这些特征决定了置身其中的人求存时的策略和行为，也是很多行事方式的底层逻辑。既然是结构特征和底层逻辑，无论组织的规模大小都能适应，甚至能从你自己的处境中看到那条起决定作用的隐蔽轨迹…\\n\\n如果缺乏强力执行机构，任何法院的裁决都是一纸空文，法律的尊严也就淡然无存。法律的尊严是依靠教育在公民脑中所确立的自我约束观念和能够给违规者带来死亡的公共暴力来支撑的。无论是前者的内在约束还是后者的外力制约都依赖成本的维系。为什么要收税？因为维系秩序需要成本！\\n\\n管理的核心是确立规则和维护规则。适当的时候需要提前洞察需求，主动改变规则。总而言之，管理是围绕规则展开的。没有规则不成方圆，有章可循才能井然有序。《C1：他们到底怕什么》中呈现了另外一幅画卷：置身其中的人无法信任明面上的规则，只能根据形势的发展做判断并采取行动，然而，人心的动向飘忽不定——时来上下皆同力，运去英雄不自由。因此，才需要与穷者言富，与富者言贵，与贵者言高，与高者言势——置身高位者往往是极度脆弱的，必须审时度势才能守住拥有的一切，因为大势一去，万事皆休！\\n\\n我在经营企业时有一次强行推行自己的主张，结果在会上遭到所有干部的反对。当时我一意孤行的对大家说：就算我现在说服不了你们，请问我有没有这个权力要求这么做？他们恨恨的咬着牙说，你有这个权力，但我们保留意见！只有专门为屌丝写的小说中才会渲染乾纲独断的霸气，在现实生活中，这是非常危险的行为，不到万不得已切不可用之。\\n\\n因为，不管是决策正确，还是结果不如预期，都已经把其它所有人推到了自己的对立面，并给了他们一个共识，让他们凝聚成了一个整体。崇祯皇帝与整个文官集团直接对抗所造成的结果是有目共睹的。正是他们组成了决策能够落地的传导体系。你虽然可以通过置换传导体系中的节点来达到控制组织的目的。然而，忠诚和效率不可兼得！在现实中，你既需要忠诚也需要效率，何况二者本来就相辅相成。如果自己与之对立起来，不但二者不可兼得，而且会二者皆不可得！\\n\\n置换一个底层螺丝钉只需要一道命令，因为底层螺丝耦合太浅，无足轻重。然而，裁撤一个高层节点就必须小心谨慎。能够走到高位者，是业已赢得信任之人，我们在《A128：匹配和信任！》中阐述过：信任的本质是一种能够互相伤害的暴力平衡。一旦处理不好，不但会引发反噬，而且可能引起兔死狐悲的连锁反应。它所造成的结果既动摇其它节点的忠诚，也降低整个传导体系的效率。所以，任何高级节点的置换都必须先造足舆论，凝聚共识，树立一种大众公敌的形象，继而做足铺垫，与其它关键节点协同好立场，最后水到渠成之时才顺势拿下，以抚慰众人之心并凸显仲裁者的圣明和果决。\\n\\n财权、人事权、否决权 \\n\\n任何组织的总部和分部之间都存在一种控制和反控制的天然矛盾：即便是一个高端文明向一个地区派出殖民者，一旦他们站稳了脚跟并以母体为模板完成自我复制之后。它就会呈现出同样的生命体特征，并开始作为独立的生命体与母体争夺生存资源，甚至爆发敌对和冲突。美国的建国史就是这样一种生命体觉醒的过程。任何公司的分部一旦能够自我存活，就会试图快速扩展，其离心力也必然越来越强！\\n\\n因此，不管东方还是西方，无论过去还是现在。组织既通过自我复制实现扩展又通过内部控制来维系秩序。不管制度如何变革，都是在二者之中寻求一个动态的平衡。曾在《B9：总部如何管控分支》中阐述过：总而言之，总部必须控制三个关键要素：财权、人事权和否决权！\\n\\n生命体的存续依赖资源，资源的形式多种多样，却能够以统一的抽象符号来标记，这个符号就是钱。没有钱自然也做不了事，所以，首先需要控制的就是财权——财权同时包括攫取和分配。\\n\\n即便有了钱，要做事必须建立一个组织，一个能如臂指使的组织不是把人放在一起就能发挥作用，而是要建立一套有序的分工协作体系。其决定作用的是组成骨架的核心节点。千军易得，一将难求。这里的“将”就是能起到节点作用的人。正是这些人构建起一套能将决策作用于现实同时从现实中获取反馈的传导体系。组织中的资源都是围绕这些核心节点运行起来。因此，掌握对这些节点的选拔、考核、任命和否决之权，就能牢牢控制这些节点，兼顾效率与忠诚。\\n\\n虽然有了钱，也有了人，还建立起了组织，但是，做事的关键，首先是决定做什么，然后才是怎么做。资金和组织都是为怎么做好一件事而准备的，但确立正确的目标，决定做什么，不做什么，并不取决于此。皇帝不必明白做事的细节，但是他拥有决定做什么和不做什么的最终决定权。于是，他就扮演了大脑的角色，而百官组成的官僚体系扮演的是躯干和四肢的角色。\\n\\n地方自治\\n\\n一直以来人们总是会误解一些基本概念。比如，中央集权跟独裁毫无关系，它其实阐述的是总部与分部的权力分配关系。中央集权对应的是地方自治。独裁对应的是民主，它所强调的是决策的形成机制：最后的仲裁是一个人说了算，还是一群人举手表决。不管怎么样都要有个结果，任何问题有了最终的结果才能到此为止。所以，不管以哪种形式组织起来的社会，都必须面对这些核心问题：一，总部与分部的权力怎么分？二，最终的决策以什么方式产生？\\n\\n西方社会的权力组织方式，总体来说是自下而上：每一个行政区域都自己管理辖区内的事务，无需对辖区外的任何机构负责，只对自己辖区内的民众负责，同时，也只能利用辖区内的资源来解决自己的问题。从某种意义上来说，今天美国各级行政区域的权力组织方式与昔日中世纪遍布欧洲的大大小小的独立领地有着异曲同工之妙。存在差异的是形成最终决策的方式——昔日欧洲各领地由唯一的领主做出决策，今天由议会的代表举手表决。这样的一种社会组织方式，依托的理论基础存在一个天然的缺陷——它会将内部的利益冲突转化为不断分裂出更小的自治单位，从而导致不断的走向碎裂。既然英国因为自己的利益就可以脱离欧盟，那么苏格兰也同样可以为了守护自己的利益而脱离英国。为了堵住这个先天性的漏洞，美国的建国之父们做了一些修补性的尝试。\\n\\n其中最具代表性的就是汉密尔顿和杰弗逊之争。汉密尔顿主张建立全国性的中央银行体系，发展工商业，建立全国性质的公共基础设施。主张大政府，扩大联邦政府的权力，压缩各州的自治权。他远在美国的建国之初就预见美国社会的未来是以工商业为核心。与之针锋相对的是农场主出身的杰弗逊。他认为美国将长期处于农业社会，农业和庄园才是社会的基石，农场主的自主和教养是这个社会的公共品德的代表。因此，他主张鼓励欧洲移民开垦更多土地，建立更多庄园，建立悠闲又富足的乡绅社会的模型。主张小政府和地方自治。这二者争执的出发点是关于美国社会未来的产业基础和社会结构，并由此引申出社会的权力分配方式，以及这种模型下的核心群体的品格特征。\\n\\n缺乏顶层调度的自治状态在承平之时尚且能够勉力维持。一旦事有缓急，维系秩序的成本超过本区域所能承受的范围之外的时候，各自为政的状况就会变得效率低下而且无能为力。事实证明，汉密尔顿是富有远见的。美国人越来越强化联邦的权力，建立中央银行性质的金融机构，从而能让联邦政府拥有了在全国范围内调动资金的工具。发展工商业依赖更高密度的社会协作，依赖于渗透全国的公共设施，比如横跨两大洋的铁路和公路系统，邮电系统，以及后面的信息高速公路网。即便在今天的美国，国家公路也是直接由联邦政府管辖的。两百多年来，美国人在变着花样的从不同维度强化联邦政府的影响力和控制力。南北战争之后，通过宪法修正案大幅增加脱离联邦的门槛。从某种意义上来说，美国民众所接受的价值观训练与真实社会的运作方式背道而驰。相信欧洲经此一劫之后，也会幡然醒悟，开始修正其社会组织模型的天然漏洞。虽然碍于思维观念和民意裹挟的惯性，嘴上不能明说，但身体会越来越诚实。\\n\\n中央集权\\n\\n\\n真正要做到总部集权需依赖一定的基础：财权不仅关乎分配资源，攫取财富的能力一定要远高于建立直通底层的体系所消耗的成本。同样的道理，高效的供应链不仅依赖强大的控制力，更需要具备低成本的特征。否则，一竿子插到底的体系就无法维系。一旦用代理的方式来建立传导体系，每一层作为主体进行相互博弈就不可避免，整体控制力和效率也必然大打折扣。然而，即便能够做到以更低的成本建立自上而下的绝对控制，它就会逐渐进化出一种静态的封闭状态——不仅低效而且维系成本越来越高。随着规模的日益扩大和分工协作的密度增加，需要面对的问题在复杂度和响应及时性的要求上会越来越高，过于呆板和迟钝的控制体系无法满足这样的需求。一旦事有缓急，虽然可以调集所有的资源去善后，但无法讲问题遏制于萌芽状态，应对之时必然漏洞百出，事后又极力掩盖，相互推诿。\\n\\n在中国社会，财权主要体现在税收和国企系统。创造和攫取财富的工具是总部掌控财权的抓手。税收分为国税和地税，98年税改之前，中央的财政是讨饭财政。如同春秋时期周天子到各诸侯那里去化缘。98年之后，70%的优质税收划为国税，剩下的30%留作地方征收的税费。从此，中枢变得硬气，地方都争先恐后到北京设置办事处，乞求财政拨款。为了弥补地方财政的不足，就赋予了地方出让土地的特权。由此拉开了一个序幕：在中国城市化进程狂飙突进的过程中，地方政府通过这一特权让房地产行业的发展在金融的助力下如烈火烹油越烧越旺。它不仅仅让地方政府摆脱了财政困难的窘迫，也维系了原有税收制度对中枢的偏向性。因此，在过去的这二十年，中枢的财政是充裕的，地方也过的不错。彼此相安无事，避免了98年前后不是中枢跪着讨饭就是地方死给你看的那种不可调和的冲突。当然，美好的日子总是短暂的，房地产行业蓬勃发展的后遗症开始倒逼财税分配的重新博弈。又到了另一个十字路口！\\n\\n地方花钱需要通过立项来调拨资金，而立项的审批权在发改委。发改委拥有否决权，组织部拥有人事权，税务系统和国企掌控攫取财富的权力，当然，还有独立的武装力量的权力，由此构成了权力从中央到地方层层深入的抓手：发改委、国税和央企都是直属中央的垂直系统。虽然在行政关系上归地方领导，在业务上归上级同类部门领导。除此之外，还包括公安、交通、经贸委，财政等职能部门。\\n\\n中国社会目前的权力组织方式是：职能部门受平级党委和直属上级双重领导。平级党委和上级部门的双重领导这一特殊设计，源于一个非常现实的问题。垂直领导才能让权力从中枢直通末端。但是，如果把行政归属也揽括进来的话，就需要为下级的一切成本支出兜底。双重领导的好处在于，一方面能够拥有业务和人事的控制权力，又不需要为下级部门的开支成本负责。另一方面，贯彻党领导一切的方针，让同级党委能够统揽全局——因为日常事务往往是细碎和繁杂的，而且响应速度必须及时。要频繁且到位的驱使之，就必须要能掐住其七寸。这个命脉就是能发工资。除了不给当地驻军发工资，其它部门的工资都由自己辖区来划拨。从某种意义上来说，一省的一把手就是一方诸侯掌控一切，几乎是无法监督的。\\n\\n央企和国税是唯一的例外，也是自上而下的权力体系打进各辖区的钉子。国有企业——特别是央企这套体系，有着超出经济收益之外的特殊价值。曾经成功的预测过供销社体系会被重新激活并成为金融和物质双向流通的管道。我给出预测的时候，因为违背普通人的思维惯性，招来一顿臭骂，后来被现实所证实。如果从结构学的角度来观察问题：它的价值，首先是深入末端的管道体系的价值，其次才是社会经济价值——管道价值就如同道路的价值，不管道路的归属和运营权归谁，它的流通价值都是一样的。附着其上的经济价值取决于运营者。\\n\\n前苏联喜欢自己建立通道来向特定群体发福利，而希特勒的第三帝国则喜欢通过私营单位来向特定群体发福利。他们都达到了目的，虽然管道不同，但原点和受众都是确定可控的，所以在管道的选择上，哪种高效和低成本就用哪种。美国的行政权正在逐步压缩其它两项权力，而联邦政府的权力也在逐渐增大。面对日益复杂的社会治理现实，不管是东方还是西方都在探索一种方式，试图在中央集权和地方自治之间寻找一种能够切合现实需要的动态平衡。\\n\\n总督的去职 \\n\\n一般能干到省一把手的人，如果不能更进一步，往往就会平稳退休，然后写写回忆录，受人尊敬的安度晚年。有一位亲戚退下来之后依然住在省委大院里。逢年过节，现任还要去家里慰问一下老同志。所以，总督巡抚被拿下，实属百年罕见。即便强主欲以此立威，按照组织结构的特征也是不敢造次的。即便是处于集权和专制顶峰的清王朝依然不敢轻易的罢免一位总督。载沣随便找了一个由头把袁世凯开缺回籍，结果天下有事之时，再也指挥不动任何督抚了！\\n\\n经此一劫，天子的权威只会更加强化。湖广总督真的是非常不走运的撞到了枪口上，不仅民怨沸腾，而且危机扩散对其它督抚的现实利益的影响也是怨声载道。这种不需要协调就能达到上下一致的立场，被天子顺势借来立威。危机肯定会过去，过去之后的新格局开始逐渐形成。总的来说，两个重点：法制和金融。新的班底都有政法背景，另外会补齐两个非常规公共安全的助手，一个是金融安全，一个是公共卫生安全。\\n\\n在完成3.5万亿地方债务的置换之后，密集的地方债务违约虽然得到缓解。但是新的动能不足和后房地产时代的地方财政不足的问题已经迫在眉睫。国企的改革开始由经营控制转向资本和股权控制。省级地方政府开始配制金融背景的副职。预计在未来的5年之内，跟金融相关的核心法律都会修改。总的来说，控制的重心要由直接经营转向控制核心通道和资本，依托全球贸易体系讲内外连接起来，建立一个类似于华尔街的资金配置体系。在贸易通道所能覆盖的范围内剔除美元的铸币权——中国、俄罗斯、印度、伊朗正在往这个方向进行尝试，日韩也正以积极的姿态参与其中。\\n\\n纵观人类社会的发展历程，每一次科技的突破和应用的产业普及，都依赖一种巨大的长周期投入，必然催生一种新的资金配置方式及其承载体。华尔街的兴盛历史也验证了这一点。从宏观数据来看，当一个国家的科技投入和产出占世界科技成果25%的时候，它就必然会成为一个超级科技中心。而且，科技树的生长必然引发社会分工协作的组织度跃升，从而由内而外打破原有国内外的社会经济结构和产业结构。世界科技中心发生过五次转移，目前是美国，下一个会在那个需求量最大，投入比最高的社会产生。然而，这种投入依赖的资金量是巨大的，而且产业化所依赖的科研、教育和应用开发的相关配套设施的建设所需要消耗的资金更是天文数字。因此，没有一个与之相适应的资金配置体系，无异于一厢情愿。没有什么是等来的，它必须依赖富有远见的布局。\\n\\n经济形式的困难是暂时的，突发的事件也会如同池塘里的涟漪，终究归于平静。真正面临的挑战一定是影响未来的结构性调整。无论一个民族还是个人，真正的贫穷是自己消灭掉自己的未来！比如说一个缺乏积累的人，却热衷于贷款消费，遇到千载难逢的机会却拿不出启动的本钱。在比如说缺乏远见和勇气的决策中，不能在拐点到来之前完成改弦更张的布局，一直被惯性所裹挟，直到山穷水尽，车毁人亡。\\n\\n科技产业兴盛的关键在金融，金融的核心在规则，规则的核心在法制！湖广总督的去职恰好为中枢立威，集势将有利于布局，新的布局已经开始，可以拭目以待，也可以待机而动。\\n"}'));jctx.push(JSON.parse('{"id": "200301", "tag": "design", "text": "# 布尔代数与三段论\\n\\n莱布尼茨发明微积分时已定义一套符号体系，更设想了一套通用的代数体系。到了乔治布尔时，提出了用符号代表类别的理念，比如\\n\\nx表示绵羊，y表示白色，则xy表示白色绵羊。显然xx仍然表示x，如果想把符号和数字打通，只有0和1能满足，所以看起来简陋的布尔代数实在有其不得已的限制。再往前推一步，0表示空集，1表全集。\\n\\n再说三段论的证明，如果x满足y，y满足z，则x一定满足z。其中x满足y意味着x是y的子集，同时意味着x和y的补集的交集是空，即x(1-y)=0，得到x=xy。整个连续的推导\\n\\nx=xy=xyz=xz 于是得到x满足z\\n"}'));jctx.push(JSON.parse('{"id": "200314", "tag": "protocol", "text": "# 经度纬度和GeoHash\\n\\n对经纬度对应的长度，我一直有个错误的认识，经度共360度纬度180度，而地球又非常接近球形，意味着每1经度的距离只有纬度的一半。但是在看了GeoHash后发现在赤道上，1个经度或纬度的地理距离是一样的，每度约111.3km，每秒31米，换算成小数点后4位是10米，和民用GPS精度一致。有些项目要求到小数点后5位甚至6位，精度1米甚至0.1米，其实是不可能达到的。随着纬度越来越高，1个经度间的距离会逐渐减少，到北纬50只有71km，更往北则缩减得越快。\\n\\n经度是整个地球一周，此时纬度只需要标识出半周，两者结合就可以唯一定位一个点，因此纬度的范围是经度的一半，但每度是一样的。比方说从东经和西经可以区分中国和美国，但北纬却无法区分。\\n\\n网上文章说GeoHash5的分块，精度约为5km的正方形。由于到南北极点会收缩，其实每个分块是球面梯形。GeoHash5的纬度方向，严格的说只在赤道附近才是5km，北纬45度的边长只有3.93km（5km x pi x 45/360），而北纬45度以上的块，是个球面三角形，面积只有靠近赤道的1/3。当然附着切分越来越细，上下两条边的差距会变小，但始终不能认为相等。\\n\\nGeoHash有12级，因为每4级间相差1024倍，只要记4级就很快能推导出全部。每级相差8倍和4倍。\\n\\nGeoHash第1级划分是8x4个块（2纬3经），第2级则是4x8个块（3纬2经）。在编码层面，每层下探时矩阵会转置，对角值也会互换。\\n\\n以杭州为例，GeoHash5约横跨0.05个经纬度，GeoHash7跨0.0015个经纬度。"}'));jctx.push(JSON.parse('{"id": "200321", "tag": "data", "text": "# 数据库SQL优化原理\\n\\n粗略地说关系型数据库都是这几步，具体前后顺序根据不同dbms不同配置下略有小差\\n\\n1. 应用程序与数据库服务器建立链接\\n1. sql发送到数据库，数据库验证是否有执行的权限\\n1. 进入语法解析器，进行词法与语法分析\\n1. 进入优化器生成执行计划，部分dbms会检查是否有可重用的执行计划\\n1. 根据执行计划依次扫描相关表中的行，不在数据缓冲区的走io\\n1. 同时对于被扫描的行可能加锁，同时也可能会被其他sql阻塞\\n1. 扫描的行足够放入查询缓存则开始运算或直接返回，不够则生成临时表，可能消耗io\\n1. 对sql结果进行计算（可能）\\n1. 将计算完成的结果全部写入网络io（可能）\\n1. 如果事务完成则同步事务日志并释放锁，具体方式取决于dbms和当前配置\\n1. 关闭连接（可选）\\n\\n这么多步骤，每一步都有优化策略\\n\\n1. 应用程序与数据库服务器建立链接，引入数据库连接池，避免每次都与数据库建立连接，提高效率\\n1. sql发送到数据库，数据库验证是否有执行的权限。没撒好说的\\n1. 进入语法解析器，进行词法与语法分析。也没撒好说的，想要数据库在这里少用点资源就把sql写的简单点，但是差别不大\\n1. 进入优化器生成执行计划，部分dbms会检查是否有可重用的执行计划。最复杂的部分来了，任何数据库如何生成执行计划都可以写一本几百页的书。\\n\\n关系型数据库选择走什么执行计划都是基于消耗最小化的思路来的，简单来说就是走什么索引，按什么顺序走表，被扫到的数据行最少。如果你的表结构很复杂，有各种混搭的索引，你的join很多，那执行计划分析的时间就会拉长。所以sql对应的表索引简单，join或子查询少就快，复杂了优化器也会得选择困难症。\\n\\n1. 根据执行计划依次扫描相关表中的行，不在数据缓冲区的走io，存储引擎扫描表的性能消耗参考下面的list，消耗从大到小\\n\\n> 全表扫描>全索引扫描>部分索引扫描>索引查找>唯一索引/主键查找>常量/null\\n\\n要走索引对于sql语句也有要求，不能在谓词上作任何运算，扫描行数一般不能超过表的17%左右，这对你数据分布又有要求，比如你查select xxx from human where sex =\'man\'，五五开，还是走扫描。推荐一本书《Relational Database Index Design and the Optimizers》\\n\\n1. 同时对于被扫描的行可能加锁，同时也可能会被其他sql阻塞。如果扫描的行多，sql执行的时间长，被阻塞的概率就高，阻塞别人的概率也高，然后大家一起等，数据库就hung住了\\n1. 扫描的行足够放入查询缓存则开始运算或直接返回，不够则生成临时表，可能消耗io。一次取的尽量少，这不单指返回服务端的行数，应该从嵌套最深的一个子查询开始算\\n1. 对sql结果进行计算（可能）少用各种复杂的函数啊，count啊，order by啊等等\\n1. 将计算完成的结果全部写入网络io（可能），请尽量少返回一点数据，如果不行请多次分批\\n1. 如果事务完成则同步事务日志并释放锁，具体方式取决于dbms和当前配置。这里举两个代表性栗子:\\n\\nsql渣：\\n\\n```\\nfor i in (1-1000):\\nstart transaction;\\ninsert into table values (1);\\ncommit;\\nend for\\n```\\n\\nsql赞：\\n\\n```\\nstart transaction;\\nfor i in (1-1000):\\ninsert into table values (1);\\nend for\\ncommit;\\n```\\n\\nsql赞爆：\\n\\n`insert into table values (1)()...()(1000);`\\n\\n首先，sql语法是我临时自创的，这个不是关键，关键在sql渣先生是1000个事务插1000行，日志flush1000次。sql赞先生是一个事务插1000行，事务日志flush1次。sql赞爆最nice。这个例子我想表达的意思是如果你要用sql做一件事，那就要尽量让这件事占用的事务总时间最少。\\n\\n第二个例子\\nsql渣：\\n\\n`update table where id > 0 and id < 1000000;`\\n\\nsql赞:\\n\\n```\\nupdate table where id > 0 and id < 1000;\\nupdate table where id >= 1000 and id < 2000;\\nupdate table where id >＝ 2000 and id < 3000;\\n```\\n\\n这个例子我想表达的意思是如果你要用sql做一件很大的事，那就尽量让大事化成很多小事。两个例子好好体会下，一点不矛盾哦。补充一下，这里每个update都是单独事务\\n\\n1. 关闭连接（可选）。同1，别每次都关，关了也许还要重连。不关的话记得commit就好了，千万要记得commit啊！"}'));jctx.push(JSON.parse('{"id": "200327", "tag": "data", "text": "# 数据库计算理论笔记\\n\\n## 事务和隔离级别\\n\\nJim Gray于1970最早提出事务的ACID特性，虽然它们并列为四大特性，但重要程度并不同。\\n\\n* A 原子性，单机版已经很好地解决了这个问题，但分布式环境似乎仍然无解\\n* C 一致性，只描述了最终的效果，过于宏大也没有提出具体的措施，因此更像是个衍生结论\\n* I 隔离性，事务中最复杂的特性，分了多个隔离级别，较低的级别其实是在正确性上做了妥协，将异常结果抛给应用层解决，从而获得更好的性能\\n* D 持久性，它的核心思想是应对系统故障，由此衍生出诸如WAL日志、日志同步/半同步、共享等多种具体技术\\n\\n可以说事务模型的发展过程就是隔离性和性能之间平衡的历史，甚至可以说隔离性是事务核心。\\n\\nSQL92定义了4种隔离层级，不久后Jim Gray于1995年发表了经典论文《A Critique of ANSI SQL Isolation Levels》，正式提出了快照隔离的概念。同年Oracle很快就做出了回应，但它的First Update Win方案却不同于《批评》的First Commit Win方案。顺便说句PostgreSQL也和Oracle一样用了FUW方案。早期的MySQL存储引擎并不支持事务，InnoDB出现的时候，计划基于IBM的Aries算法做出MV2PL（多版本两阶段锁），但有学者在2009年基于此改造实现了快照隔离和串行快照隔离SSI，虽然如此但MySQL官方并不支持SI，只是做了可重复读RR。反倒是PG吸收了学界的成果，把SI和SSI合并到产品中。\\n\\nSQL92之所以不提快照隔离并不是想不到，而是因为当时的实现主要基于锁并发，而快照隔离的基础是MVCC。当然到了现代，MVCC已经成了一种底层技术，用来高效实现乐观或悲观并发控制。乐观和悲观的区别就如字面意义，通过两段简单的代码来展示区别\\n\\n乐观控制\\n\\n```\\nselect * from goods where id = 1   -- 不加锁读\\nbegin; -- 读之后开始事务\\nupdate goods set stock = stock - 1 where id = 1 and stock = cur_stock;  -- 更新时要注意 where 条件 “stock = cur_stock”，只有程序中获取到的库存量与数据库中的库存量相等才执行更新\\ncommit;\\n```\\n\\n悲观控制\\n\\n```\\nbegin;  -- 先打开事务\\nselect * from goods where id = 1 for update;  -- 读时用for update对数据加锁\\nupdate goods set stock = stock - 1 where id = 1;  -- 写时不再校验\\ncommit;\\n```\\n\\n可能是单机数据库的历史原因，也可能是应用层为了快速开发，占据主流还是悲观控制。\\n\\n## 一致性协议\\n\\n数据在多节点间的同步，应用较广的有这几种协议\\n\\n* 两阶段提交，即prepare和commit，要求所有节点都一致，高可用性不足\\n* paxos/raft，中心化广播协议，前者是论文的提法，后者则是后来另一篇论文给出的几乎完整实现。可以看作是复制协议的一种，属于多数共识算法，大部分节点可用即通过\\n* gossip协议，适用于P2P网络的同步协议，在节点非常多的时候，paxos负担会很重，这种场景用gossip更好\\n\\n## 分布式\\n\\nCAP三者只能选其二，也可以只求一个达到最大化，没有见过实际例子。\\n\\n* 取CA，又名强一致性 ACID，但是分布式系统必然要求P，所以可以把ACID和传统单机的数据库等同\\n* 取AP，又名弱一致性 BASE，从命名中也能看出舍弃了C，在不追求严格准确（或者说始终最新）的场景有一定应用\\n* 取CP，用得最广，似乎没有专门的一致性定义\\n\\nCAP和ACID的C，中文都叫一致性，但两者含义稍有不同。CAP的C指多副本、单操作的一致性，而ACID的C，在最初的论文定义中是指单副本、多操作的事务一致性。\\n\\n## 数据分片\\n\\n分片是单机分区机制在多副本的一种扩展，有两种\\n\\n* Hash分片，为做到适应扩容，都会用一致性Hash算法。这种做法平衡性好，但业务不敏感，扫描时必须全副本都执行，归纳起来就是写性能出众，但读性能较差\\n* Range分片，原生的分布式数据库多采用这种方案，多个分片间使用raft协议组成Group组，每个Group是最小的高可靠单元\\n\\nSort和Shuffle是MapReduce上最核心的操作，由于MR每一步都会写磁盘，因此任意节点都能恢复，同样的，只要做足checkpoint也能非常健壮。"}'));jctx.push(JSON.parse('{"id": "200330", "tag": "os", "text": "# 【考古】删除和退格键\\n\\n最初的Unix终端是Teletype ASR33，由纸带穿孔机以及纸带阅读机和键盘组成。Backspace和Delete并不属于该键盘上的按键\\n\\n在键入内容的时候如果出错，则需要按下^(ctrl)+H向teletype发送一个退格命令，使得穿孔机移回之前的位置，然后按下Rubout键再发送一个删除命令才能做到删除对应位置内容\\n\\n之后为了方便开始制造带有backspace按键的终端，同时完成退格和删除两个功能\\n\\n后来Rubout键被改名为Delete，一些Unix公司决定在键盘中加入Delete键（用于删除一个字符），这些公司决定用Delete代替^+H代表退格。因此，情况变成了一些键盘可以按下Backspace删除字符，另一些要按下Delete。\\n\\n对于现在的键盘来讲，实际情况是有Backspace键时按下后则会触发退格加删除两个操作，此时的Delete键的作用只对应删除这一个操作，因此Backspace键删除的都是光标之前的字符，Delete键删除的是光标之后的字符；如果没有Backspace键则用Delete键来代替（也是退格加删除两个操作）。\\n\\n对于一些文字（比如天城文）Backspace 会按“字母”逐个删除，Delete 则是删掉一个音节。不过这个和历史无关，也许是windows特有的做法。\\n"}'));jctx.push(JSON.parse('{"id": "200402", "tag": "lang", "text": "# 嵌套加载的目录查找方式比较\\n\\n动态语言的加载通常会有一个路径列表，加载时按列表顺序寻找。这个列表里大部分是绝对路径，但也会有当前相对路径，当嵌套加载时，相对路径如何定位就是个容易迷惑的问题。以下的目录结构为例\\n\\n```\\nmain.lang\\nutil/\\nlib/\\n    a.lang\\n    config.lang\\n```\\n\\n入口是main.lang，在main里导入包不会有歧义，但是在a.lang如何导入config就不那么明确了。下面列举不同语言的作法。\\n\\n## lua\\n\\n不管当前执行加载语句在哪个文件，相对路径查找的参考系，始终是入口执行文件。因此在a中加载config，只能写成require \'lib.config\'\\n\\n## python\\n\\nimport加载没见过绝对路径方式，默认的相对路径参考系，是入口执行文件，但可以通过`.`或`..`（但不能带`/`符）来改变相对路径所指向的目录。\\n\\n* 在a.py加载util，写成 import util，表示按main的路径来寻找\\n* 在a.py加载config.py，写成 import .config，通过.告诉解释器，以a.py的路径为相对路径，寻找包，此时config和a在同一目录下，因此.config能加载\\n\\n## php\\n\\ninclude或require语句的参数有3种形式\\n\\n1. 绝对路径，以`/`或`C:\\\\`等开头的文件，没什么好说的\\n2. 相对路径，以`./`或`../`开头的文件，始终以解释器执行入口的文件作为查找参考系，a加载config必须写作include \'./lib/config.php\'\\n3. 未确定路径，搜索路径包含`.`时，会从执行入口文件和当前嵌套加载的文件都查找一遍，在a加载config写成include \'config.php\'或include \'lib/config.php\'都可以，不愧是最强大的语言\\n\\n网上有说PHP的惯用法是在入口定义`__ROOT__`变量，其它模块文件都引用这个变量，并用绝对路径的方式加载。"}'));jctx.push(JSON.parse('{"id": "200405", "tag": "book", "text": "# 转－数学体系导引\\n\\n## 一、为什么要深入数学的世界\\n\\n作为计算机的学生，我没有任何企图要成为一个数学家。我学习数学的目的，是要想爬上巨人的肩膀，希望站在更高的高度，能把我自己研究的东西看得更深广一些。说起来，我在刚来这个学校的时候，并没有预料到我将会有一个深入数学的旅程。我的导师最初希望我去做的题目，是对appearance和motion建立一个unified的model。这个题目在当今Computer Vision中百花齐放的世界中并没有任何特别的地方。事实上，使用各种Graphical Model把各种东西联合在一起framework，在近年的论文中并不少见。\\n\\n我不否认现在广泛流行的Graphical Model是对复杂现象建模的有力工具，但是，我认为它不是panacea，并不能取代对于所研究的问题的深入的钻研。如果统计学习包治百病，那么很多“下游”的学科也就没有存在的必要了。事实上，开始的时候，我也是和Vision中很多人一样，想着去做一个Graphical Model——我的导师指出，这样的做法只是重复一些标准的流程，并没有很大的价值。经过很长时间的反复，另外一个路径慢慢被确立下来——我们相信，一个图像是通过大量“原子”的某种空间分布构成的，原子群的运动形成了动态的可视过程。微观意义下的单个原子运动，和宏观意义下的整体分布的变换存在着深刻的联系——这需要我们去发掘。\\n\\n在深入探索这个题目的过程中，遇到了很多很多的问题，如何描述一个一般的运动过程，如何建立一个稳定并且广泛适用的原子表达，如何刻画微观运动和宏观分布变换的联系，还有很多。在这个过程中，我发现了两个事情：\\n\\n* 我原有的数学基础已经远远不能适应我对这些问题的深入研究。\\n* 在数学中，有很多思想和工具，是非常适合解决这些问题的，只是没有被很多的应用科学的研究者重视。\\n\\n于是，我决心开始深入数学这个浩瀚大海，希望在我再次走出来的时候，我已经有了更强大的武器去面对这些问题的挑战。\\n\\n我的游历并没有结束，我的视野相比于这个博大精深的世界的依旧显得非常狭窄。在这里，我只是说说，在我的眼中，数学如何一步步从初级向高级发展，更高级别的数学对于具体应用究竟有何好处。\\n\\n## 二、集合论：现代数学的共同基础\\n\\n现代数学有数不清的分支，但是，它们都有一个共同的基础——集合论——因为它，数学这个庞大的家族有个共同的语言。集合论中有一些最基本的概念：*集合(set)，关系(relation)，函数(function)，等价 (equivalence)*，是在其它数学分支的语言中几乎必然存在的。对于这些简单概念的理解，是进一步学些别的数学的基础。我相信，理工科大学生对于这些都不会陌生。\\n\\n![mathtree](./img/mathtree.png)\\n\\n不过，有一个很重要的东西就不见得那么家喻户晓了——那就是“选择公理” (Axiom of Choice)。这个公理的意思是“任意的一群非空集合，一定可以从每个集合中各拿出一个元素。”——似乎是显然得不能再显然的命题。不过，这个貌似平常的公理却能演绎出一些比较奇怪的结论，比如巴拿赫-塔斯基分球定理——“一个球，能分成五个部分，对它们进行一系列刚性变换（平移旋转）后，能组合成两个一样大小的球”。正因为这些完全有悖常识的结论，导致数学界曾经在相当长时间里对于是否接受它有着激烈争论。现在，主流数学家对于它应该是基本接受的，因为很多数学分支的重要定理都依赖于它。在我们后面要回说到的学科里面，下面的定理依赖于选择公理：\\n\\n1. 拓扑学：Baire Category Theorem\\n2. 实分析（测度理论）：Lebesgue 不可测集的存在性\\n3. 泛函分析四个主要定理：Hahn-Banach Extension Theorem, Banach-Steinhaus Theorem (Uniform boundedness principle), Open Mapping Theorem, Closed Graph Theorem\\n\\n在集合论的基础上，现代数学有两大家族：*分析(Analysis)和代数(Algebra)*。至于其它的，比如几何和概率论，在古典数学时代，它们是和代数并列的，但是它们的现代版本则基本是建立在分析或者代数的基础上，因此从现代意义说，它们和分析与代数并不是平行的关系。\\n\\n## 三、分析：在极限基础上建立的宏伟大厦\\n\\n### 微积分：分析的古典时代——从牛顿到柯西\\n先说说分析(Analysis)吧，它是从微积分(Caculus)发展起来的——这也是有些微积分教材名字叫“数学分析”的原因。不过，分析的范畴远不只是这些，我们在大学一年级学习的微积分只能算是对古典分析的入门。分析研究的对象很多，包括*导数(derivatives)，积分(integral)，微分方程(differential equation)，还有级数(infinite series)*—这些基本的概念，在初等的微积分里面都有介绍。如果说有一个思想贯穿其中，那就是极限—这是整个分析（不仅仅是微积分）的灵魂。\\n\\n一个很多人都听说过的故事，就是牛顿(Newton)和莱布尼茨 (Leibniz)关于微积分发明权的争论。事实上，在他们的时代，很多微积分的工具开始运用在科学和工程之中，但是，微积分的基础并没有真正建立。那个长时间一直解释不清楚的“无穷小量”的幽灵，困扰了数学界一百多年的时间——这就是“第二次数学危机”。*直到柯西用数列极限的观点重新建立了微积分的基本概念*，这门学科才开始有了一个比较坚实的基础。直到今天，整个分析的大厦还是建立在极限的基石之上。\\n\\n柯西(Cauchy)为分析的发展提供了一种严密的语言，但是他并没有解决微积分的全部问题。在19世纪的时候，分析的世界仍然有着一些挥之不去的乌云。而其中最重要的一个没有解决的是*“函数是否可积的问题”*。我们在现在的微积分课本中学到的那种通过“无限分割区间，取矩阵面积和的极限”的积分，是大约在1850年由黎曼(Riemann)提出的，叫做黎曼积分。但是，什么函数存在黎曼积分呢（黎曼可积）？数学家们很早就证明了，*定义在闭区间内的连续函数是黎曼可积的*。可是，这样的结果并不令人满意，工程师们需要对分段连续函数的函数积分。\\n\\n### 实分析：在实数理论和测度理论上建立起现代分析\\n在19世纪中后期，不连续函数的可积性问题一直是分析的重要课题。对于定义在闭区间上的黎曼积分的研究发现，可积性的关键在于“不连续的点足够少”。只有有限处不连续的函数是可积的，可是很多有数学家们构造出很多在无限处不连续的可积函数。显然，在衡量点集大小的时候，有限和无限并不是一种合适的标准。在探讨“点集大小”这个问题的过程中，数学家发现实数轴——这个他们曾经以为已经充分理解的东西——有着许多他们没有想到的特性。在极限思想的支持下，实数理论在这个时候被建立起来，它的标志是对实数完备性进行刻画的几条等价的定理 （确界定理，区间套定理，柯西收敛定理，Bolzano-Weierstrass Theorem和Heine-Borel Theorem等等）——这些定理明确表达出实数和有理数的根本区别：完备性（很不严格的说，就是对极限运算封闭）。随着对实数认识的深入，如何测量“点集大小”的问题也取得了突破，勒贝格创造性地把关于集合的代数，和Outer content（就是“外测度”的一个雏形）的概念结合起来，建立了测度理论(Measure Theory)，并且进一步建立了以测度为基础的积分——勒贝格(Lebesgue Integral)。在这个新的积分概念的支持下，可积性问题变得一目了然。\\n\\n上面说到的实数理论，测度理论和勒贝格积分，构成了我们现在称为实分析 (Real Analysis)的数学分支，有些书也叫实变函数论。对于应用科学来说，实分析似乎没有古典微积分那么“实用”——很难直接基于它得到什么算法。而且， 它要解决的某些“难题”——比如处处不连续的函数，或者处处连续而处处不可微的函数——在工程师的眼中，并不现实。但是，我认为，它并不是一种纯数学概念游戏，它的现实意义在于为许多现代的应用数学分支提供坚实的基础。下面，我仅仅列举几条它的用处：\\n\\n1. 黎曼可积的函数空间不是完备的，但是勒贝格可积的函数空间是完备的。简单的说，一个黎曼可积的函数列收敛到的那个函数不一定是黎曼可积的，但是勒贝格可积的函数列必定收敛到一个勒贝格可积的函数。在泛函分析，还有逼近理论中，经 常需要讨论“函数的极限”，或者“函数的级数”，如果用黎曼积分的概念，这种讨论几乎不可想像。我们有时看一些paper中提到Lp函数空间，就是基于勒 贝格积分。\\n2. 勒贝格积分是傅立叶变换（这东西在工程中到处都是）的基础。很多关于信号处理的初等教材，可能绕过了勒贝格积分，直接讲点面对实用的东西而不谈它的数学基础，但是，对于深层次的研究问题——特别是希望在理论中能做一些工作——这并不是总能绕过去。\\n3. 在下面，我们还会看到，测度理论是现代概率论的基础。\\n\\n### 现代概率论：在现代分析基础上再生\\n\\n(注：我将现代概率论小节移到这)\\n\\n最后，再简单说说很多Learning的研究者特别关心的数学分支：概率论。 自从Kolmogorov在上世纪30年代把测度引入概率论以来，测度理论就成为现代概率论的基础。在这里，概率定义为测度，随机变量定义为可测函数，条件随机变量定义为可测函数在某个函数空间的投影，均值则是可测函数对于概率测度的积分。值得注意的是，很多的现代观点，开始以泛函分析的思路看待概率论的基础概念，随机变量构成了一个向量空间，而带符号概率测度则构成了它的对偶空间，其中一方施加于对方就形成均值。角度虽然不一样，不过这两种方式殊途同 归，形成的基础是等价的。\\n\\n在现代概率论的基础上，许多传统的分支得到了极大丰富，最有代表性的包括鞅论 (Martingale)——由研究赌博引发的理论，现在主要用于金融（这里可以看出赌博和金融的理论联系，:-P），布朗运动(Brownian Motion)——连续随机过程的基础，以及在此基础上建立的随机分析(Stochastic Calculus)，包括随机积分（对随机过程的路径进行积分，其中比较有代表性的叫伊藤积分(Ito Integral)），和随机微分方程。对于连续几何运用建立概率模型以及对分布的变换的研究离不开这些方面的知识。\\n\\n### 拓扑学：分析从实数轴推广到一般空间——现代分析的抽象基础\\n\\n随着实数理论的建立，大家开始把极限和连续推广到更一般的地方的分析。事实上，很多基于实数的概念和定理并不是实数特有的。很多特性可以抽象出来，推广到更一般的空间里面。*对于实数轴的推广，促成了点集拓扑学(Point- set Topology)的建立*。很多原来只存在于实数中的概念，被提取出来，进行一般性的讨论。在拓扑学里面，有4个C构成了它的核心：\\n\\n(1)Closed set, 闭集合\\n\\n在现代的拓扑学的公理化体系中，开集和闭集是最基本的概念。一切从此引申。这两个概念是开区间和闭区间的推广，它们的根本地位，并不是一开始就被认识到的。经过相当长的时间，人们才认识到：开集的概念是连续性的基础，而闭集对极限运算封闭——而极限正是分析的根基。\\n\\n(2)Continuous function, 连续函数\\n\\n连续函数在微积分里面有个用epsilon-delta语言给出的定义，在拓扑学中它的定义是“开集的原像是开集的函数”。第二个定义和第一个是等价的，只是用更抽象的语言进行了改写。我个人认为，它的第三个（等价）定义才从根本上揭示连续函数的本质——“连续函数是保持极限运算的函数” ——比如y是数列x1, x2, x3, … 的极限， 那么如果 f 是连续函数，那么 f(y) 就是 f(x1), f(x2), f(x3), …的极限。连续函数的重要性，可以从别的分支学科中进行类比。比如群论中，基础的运算是“乘法”，对于群，最重要的映射叫“同态映射”——保持“乘法”的映射。在分析中，基础运算是“极限”，因此连续函数在分析中的地位，和同态映射在代数中的地位是相当的。\\n\\n(3)Connected set, 连通集合\\n\\n比它略为窄一点的概念叫(Path connected)，就是集合中任意两点都存在连续路径相连——可能是一般人理解的概念。一般意义下的连通概念稍微抽象一些。在我看来，连通性有两个重要的用场：一个是用于证明一般的中值定理(Intermediate Value Theorem)，还有就是代数拓扑，拓扑群论和李群论中讨论根本群(Fundamental Group)的阶。\\n\\n(4)Compact set, 紧集\\n\\nCompactness似乎在初等微积分里面没有专门出现，不过有几条实数上的定理和它其实是有关系的。比如，“有界数列必然存在收敛子列”——用compactness的语言来说就是——“实数空间中有界闭集是紧的”。它在拓扑学中的一般定义是一个听上去比较抽象的东西——“紧集的任意开覆盖存在有限子覆盖”。这个定义在讨论拓扑学的定理时很方便，它在很多时候能帮助实现从无限到有限的转换。对于分析来说，用得更多的是它的另一种形式 ——“紧集中的数列必存在收敛子列”——它体现了分析中最重要的“极限”。Compactness在现代分析中运用极广，无法尽述。微积分中的两个重要定 理：极值定理(Extreme Value Theory)，和一致收敛定理(Uniform Convergence Theorem)就可以借助它推广到一般的形式。\\n\\n从某种意义上说，*点集拓扑学可以看成是关于“极限”的一般理论*，它抽象于实数理论，它的概念成为几乎所有现代分析学科的通用语言，也是整个现代分析的根基所在。\\n\\n![mathstruct](./img/mathstruct.png)\\n\\n### 微分几何：流形上的分析——在拓扑空间上引入微分结构\\n\\n拓扑学把极限的概念推广到一般的拓扑空间，但这不是故事的结束，而仅仅是开始。在微积分里面，极限之后我们有微分，求导，积分。这些东西也可以推广到拓扑空间，在拓扑学的基础上建立起来——这就是微分几何。从教学上说，微分几何的教材，有两种不同的类型，一种是建立在古典微机分的基础上的“古典微分几何”，主要是关于二维和三维空间中的一些几何量的计算，比如曲率。还有一种是建立在现代拓扑学的基础上，这里姑且称为“现代微分几何”——它的核心概念就是“流形”(manifold)——就是在拓扑空间的基础上加了一套可以进行微分运算的结构。现代微分几何是一门非常丰富的学科。比如一般流形上的微分的定义就比传统的微分丰富，我自己就见过三种从不同角度给出的等价定义——这一方面让事情变得复杂一些，但是另外一个方面它给了同一个概念的不同理解，往往在解决问题时会引出不同的思路。除了推广微积分的概念以外，还引入了很多新概念：tangent space, cotangent space, push forward, pull back, fibre bundle, flow, immersion, submersion 等等。\\n\\n近些年，流形在machine learning似乎相当时髦。但是，坦率地说，要弄懂一些基本的流形算法， 甚至“创造”一些流形算法，并不需要多少微分几何的基础。对我的研究来说，微分几何最重要的应用就是建立在它之上的另外一个分支：李群和李代数——这是数学中两大家族分析和代数的一个漂亮的联姻。分析和代数的另外一处重要的结合则是泛函分析，以及在其基础上的调和分析。\\n\\n## 四、代数：一个抽象的世界\\n\\n回过头来，再说说另一个大家族——代数。\\n\\n如果说古典微积分是分析的入门，那么现代代数的入门点则是两个部分：线性代数(linear algebra)和基础的抽象代数(abstract algebra)——据说国内一些教材称之为近世代数。\\n\\n代数——名称上研究的似乎是数，在我看来，主要研究的是运算规则。一门代数， 其实都是从某种具体的运算体系中抽象出一些基本规则，建立一个公理体系，然后在这基础上进行研究。一个集合再加上一套运算规则，就构成一个代数结构。在主要的代数结构中，最简单的是群(Group)——它只有一种符合结合率的可逆运算，通常叫“乘法”。如果，这种运算也符合交换率，那么就叫阿贝尔群 (Abelian Group)。如果有两种运算，一种叫加法，满足交换率和结合率，一种叫乘法，满足结合率，它们之间满足分配率，这种丰富一点的结构叫做环(Ring)， 如果环上的乘法满足交换率，就叫可交换环(Commutative Ring)。如果，一个环的加法和乘法具有了所有的良好性质，那么就成为一个域(Field)。基于域，我们可以建立一种新的结构，能进行加法和数乘，就构成了线性代数(Linear algebra)。\\n\\n代数的好处在于，它只关心运算规则的演绎，而不管参与运算的对象。只要定义恰当，完全可以让一只猫乘一只狗得到一头猪:-)。基于抽象运算规则得到的所有定理完全可以运用于上面说的猫狗乘法。当然，在实际运用中，我们还是希望用它 干点有意义的事情。学过抽象代数的都知道，基于几条最简单的规则，比如结合律，就能导出非常多的重要结论——这些结论可以应用到一切满足这些简单规则的地 方——这是代数的威力所在，我们不再需要为每一个具体领域重新建立这么多的定理。\\n\\n### 关于抽象代数\\n\\n抽象代数有在一些基础定理的基础上，进一步的研究往往分为两个流派：研究有限的离散代数结构（比如有限群和有限域），这部分内容通常用于数论，编码，和整数方程这些地方；另外一个流派是研究连续的代数结构，通常和拓扑与分析联系在 一起（比如拓扑群，李群）。我在学习中的focus主要是后者。\\n\\n### 线性代数：“线性”的基础地位\\n\\n对于做Learning, vision, optimization或者statistics的人来说，接触最多的莫过于线性代数——这也是我们在大学低年级就开始学习的。线性代数，包括建立在它基础上的各种学科，最核心的两个概念是向量空间和线性变换。线性变换在线性代数中的地位，和连续函数在分析中的地位，或者同态映射在群论中的地位是一样的 ——它是保持基础运算（加法和数乘）的映射。\\n\\n在learning中有这样的一种倾向——鄙视线性算法，标榜非线性。也许在很多场合下面，我们需要非线性来描述复杂的现实世界，但是无论什么时候，线性都是具有根本地位的。没有线性的基础，就不可能存在所谓的非线性推广。我们常用的非线性化的方法包括流形和kernelization，这两者都需要在某个阶段回归线性。流形需要在每个局部建立和线性空间的映射，通过把许多局部线性空间连接起来形成非线性；而kernerlization则是通过置换内积结构把原线性空间“非线性”地映射到另外一个线性空间，再进行线性空间中所能 进行的操作。而在分析领域，线性的运算更是无处不在，微分，积分，傅立叶变换，拉普拉斯变换，还有统计中的均值，通通都是线性的。\\n\\n### 泛函分析：从有限维向无限维迈进\\n\\n在大学中学习的线性代数，它的简单主要因为它是在有限维空间进行的，因为有限，我们无须借助于太多的分析手段。但是，有限维空间并不能有效地表达我们的世界——最重要的，函数构成了线性空间，可是它是无限维的。对函数进行的最重要的运算都在无限维空间进行，比如傅立叶变换和小波分析。这表明了，为了研究函数（或者说连续信号），我们需要打破有限维空间的束缚，走入无限维的函数空间——这里面的第一步，就是泛函分析。\\n\\n泛函分析(Functional Analysis)是研究的是一般的线性空间，包括有限维和无限维，但是很多东西在有限维下显得很trivial，真正的困难往往在无限维的时候出现。在泛函分析中，空间中的元素还是叫向量，但是线性变换通常会叫作“算子”(operator)。除了加法和数乘，这里进一步加入了一些运算，比如加入范数去表达“向量的长度”或者“元素的距离”，这样的空间叫做“赋范线性空间”(normed space)，再进一步的，可以加入内积运算，这样的空间叫“内积空间”(Inner product space)。\\n\\n大家发现，当进入无限维的时间时，很多老的观念不再适用了，一切都需要重新审视。\\n\\n所有的有限维空间都是完备的（柯西序列收敛），很多无限维空间却是不完备的（比如闭区间上的连续函数）。在这里，完备的空间有特殊的名称：完备的赋范空间叫巴拿赫空间(Banach space)，完备的内积空间叫希尔伯特空间(Hilbert space)。\\n在有限维空间中空间和它的对偶空间的是完全同构的，而在无限维空间中，它们存在微妙的差别。\\n在有限维空间中，所有线性变换（矩阵）都是有界变换，而在无限维，很多算子是无界的(unbounded)，最重要的一个例子是给函数求导。\\n在有限维空间中，一切有界闭集都是紧的，比如单位球。而在所有的无限维空间中，单位球都不是紧的——也就是说，可以在单位球内撒入无限个点，而不出现一个极限点。\\n在有限维空间中，线性变换（矩阵）的谱相当于全部的特征值，在无限维空间 中，算子的谱的结构比这个复杂得多，除了特征值组成的点谱(point spectrum)，还有approximate point spectrum和residual spectrum。虽然复杂，但是，也更为有趣。由此形成了一个相当丰富的分支——算子谱论(Spectrum theory)。\\n在有限维空间中，任何一点对任何一个子空间总存在投影，而在无限维空间中， 这就不一定了，具有这种良好特性的子空间有个专门的名称切比雪夫空间(Chebyshev space)。这个概念是现代逼近理论的基础(approximation theory)。函数空间的逼近理论在Learning中应该有着非常重要的作用，但是现在看到的运用现代逼近理论的文章并不多。\\n\\n### 继续往前：巴拿赫代数，调和分析，和李代数\\n\\n基本的泛函分析继续往前走，有两个重要的方向。第一个是巴拿赫代数 (Banach Algebra)，它就是在巴拿赫空间（完备的内积空间）的基础上引入乘法（这不同于数乘）。比如矩阵——它除了加法和数乘，还能做乘法——这就构成了一 个巴拿赫代数。除此以外，值域完备的有界算子，平方可积函数，都能构成巴拿赫代数。巴拿赫代数是泛函分析的抽象，很多对于有界算子导出的结论，还有算子谱 论中的许多定理，它们不仅仅对算子适用，它们其实可以从一般的巴拿赫代数中得到，并且应用在算子以外的地方。巴拿赫代数让你站在更高的高度看待泛函分析中 的结论，但是，我对它在实际问题中能比泛函分析能多带来什么东西还有待思考。\\n\\n最能把泛函分析和实际问题在一起的另一个重要方向是调和分析 (Harmonic Analysis)。我在这里列举它的两个个子领域，傅立叶分析和小波分析，我想这已经能说明它的实际价值。它研究的最核心的问题就是怎么用基函数去逼近和构造一个函数。它研究的是函数空间的问题，不可避免的必须以泛函分析为基础。除了傅立叶和小波，调和分析还研究一些很有用的函数空间，比如Hardy space，Sobolev space，这些空间有很多很好的性质，在工程中和物理学中都有很重要的应用。对于vision来说，调和分析在信号的表达，图像的构造，都是非常有用的工具。\\n\\n## 五、分析与代数结合\\n\\n当分析和线性代数走在一起，产生了泛函分析和调和分析；当分析和群论走在一 起，我们就有了李群(Lie Group)和李代数(Lie Algebra)。它们给连续群上的元素赋予了代数结构。我一直认为这是一门非常漂亮的数学：在一个体系中，拓扑，微分和代数走到了一起。在一定条件下，通过李群和李代数的联系，它让几何变换的结合变成了线性运算，让子群化为线性子空间，这样就为Learning中许多重要的模型和算法的引入到对几何运动的建模创造了必要的条件。因此，我们相信李群和李代数对于vision有着重要意义，只不过学习它的道路可能会很艰辛，在它之前需要学习很多别的数学。\\n"}'));jctx.push(JSON.parse('{"id": "200411", "tag": "protocol", "text": "# 不可打印字符与转义序列\\n\\nplan9的老人们建过一个网站cat-v.org，影射cat命令加上-v选项是邪恶的。这个选项的作用是把不可打印的控制字符显示出来，低128用^，高128用M-前缀，在一些终端类软件上会用到这些符号。\\n\\nASCII的编码0到31，0对应^@，接下来是^A-^Z，从27到31依次是`[\\\\]^_`，127是^?。从128开始，显示的时候前面会有M-前缀，比如128对应0，显示为M-^@，依此类推。而从160开始，对位字符是可打印字符，在前面加上M-，比如33是!，则161显示为M-!。\\n\\n用cat -v显示的话，制表符和回车不会按^I和^J显示，要分别用-T和-E选项，-T会把Tab显示为^I，而-E会把回车显示为$，且实际上也会另起新行。用-A则是结合了vET这三个选项，显示所有不可打印字符。\\n\\n题外话：按下键盘上的回车键，相当于按下Ctrl+M，而Tab键则相当于Ctrl+I键。在bash中用bind -P查看按键映射，会发现自动补全的按键序列只显示Ctrl+I，一旦把Ctrl+I映射成其它功能，Tab键的功能也就跟着变了。\\n\\n## ASCII码中不可打印字符\\n\\n偶然间看OpenBSD开发的mandoc.db格式，提到用了3种格式，32位int和NUL结尾字符串都很普通，但第3种字符串列表的表述`lists of NUL-terminated strings, terminated by a second NUL character`，0是NUL，second NUL查看了ASCII表，对应的是2，含义是start of text。\\n\\nASCII的前32个是控制字符，用在电传打字时代，来看看相近的几个描述，1-SOH(start of headling), 2-STX(start of text), 3-ETX(end of text), 4-EOT(end of transmission)。可以看到1开始文章标题，然后是2文章正文，3文章结尾，到4结束传输之间可能还有些附录、索引要添加。包括其它的请求应答、回车制表换行等，不可打印字符在文章结构划分、控制版式上是有实实在在的作用的。\\n\\n## 转义序列\\n\\n开发出Unix最早版本的PDP系统，既没有光标也没有删除，更没有上下左右键，有兴趣的可以体验[模拟器](http://pdp11.aiju.de/)。更友好的显示肯定是刚需，于是各厂商就开发各种转义协议，让屏幕出现光标、重绘、颜色等特性，起初厂商间各自为战，好在美国人向来有搞标准的习惯，1978年的VT100便是符合这个标准最初的成功样本。\\n\\n规范规定，转义序列在带内传输，序列总长度不固定，但必须以ESC开头，后面再跟0x40-0x5F字符(`@A–Z[\\\\]^_`)。比较常见的有\\n\\n* \\\\033[ 终端显示色彩用的就是这个命令\\n* \\\\033] 操作系统命令\\n* \\\\033_ Application Program Command(APC)\\n* \\\\033\\\\\\\\ 字符串终止，可以用于APC的结束\\n\\n最早的颜色序列只有3位，共8种颜色，加上粗体被实现为亮色，只有4位。后来又逐步扩展出8位，而libvte库更是支持24位颜色(需要依赖X11，比如xterm等图形界面)。"}'));jctx.push(JSON.parse('{"id": "200427", "tag": "os", "text": "# Linux内核与PAM模块简记\\n\\n前因是容器中启动nfsd需要依赖内核加载ko模块，分读写记一下。\\n\\nlsmod命令，或查看/proc/modules看到内核当前加载的ko模块。\\n\\n/lib/modules/{ver}-{arch}/kernel 这里放的是所有可以加载的内核模块，以4.19为例，共有3559个，但初始启动加载的只有58个。ko文件之间有依赖关系，通过modinfo查看，查看原理也是从上述提到的内核路径中查找。\\n\\n所有的ko操作命令有6个，都是/bin/kmod的别名。\\n\\n## PAM模块\\n\\n类Unix系统的一套授权管理机制，Pluggable Authentication Modules，由SUN在1995年10月提出，并由ReaHat在1996年8月首次实现。典型的效果比如接ssh失败过多时，PAM会禁止登陆，ssh自身并不提供这种机制。\\n\\n`pam_tally`基于用户的计数，当次数达到则触发规则，同时还配有`pam_tally2`应用程序查看和清空次数，不过在1.5版本的pam去掉了这个程序并引入`faillock`替代。\\n\\nLinux将PAM分为4个阶段\\n\\n1. 用户模块，检查目标用户是否符合规则，比如用户是否过期，是否有权访问某个服务等\\n2. 认证模块，检查用户认证方式，也可以和keyring交互\\n3. 密码模块，确保密码符合规则，保证密码强度\\n4. 会话模块，确定此会话的边界和属性\\n\\n业界一直对pam不支持远程操作有争议，因为这导致了kerberos不兼容，后来又发展出SASL规范。"}'));jctx.push(JSON.parse('{"id": "200506", "tag": "os", "text": "# 用户态锁\\n\\nfutex不是个完整的锁，他是“支持实现userspace的锁的building block“。也就是说，如果你想实现一个mutex，但不想把整个mutex都弄到内核里面去，可以通过futex来实现。但futex本身主要就是俩系统调用futex_wait和futex_wake.\\n\\n关闭无图模式：我的 > 设置 > 无图模式\\n为了更好的解释这个问题，这里先梳理下锁本身是怎么工作的。\\n\\n一个完整的锁需要解决几个问题：\\n\\n争抢到一个内存，如果抢到了就算是得到了锁，可以继续干活；\\n如果没抢到，可以选择：\\n继续抢（spin）\\n调用某个系统调用把自己挂起来排队\\n别的线程释放锁后，会通知排队挂起来的一个或几个线程。醒过来的线程再去重复第一步。\\n早期的锁，所有这些步骤都是内核态的。但后来大家发现，步骤1用CAS在用户态就可以干了。而多线程大部分的时候抢锁都是没有竞争的，一抢就能抢到。一下子没抢到多抢几次大概率也能抢到了。\\n\\n因此后来的锁的设计都优化成了这样：\\n\\n1. 在用户态写一段代码来抢锁，典型的实现是用CAS把一个指定的变量从0变成1。如果抢到了就结束了。此时是用户态的。\\n\\n2. 如果抢不到，就看看是不是锁的持有者就是自己。如果是，也算是抢到了（当然要对变量做特殊的标记）。否则就spin几次重新抢。这也是用户态的。\\n\\n3. 如果实在抢不到，就意味着竞争发生了，此时调用futex_wait进入内核态，去把自己挂起+排队，等着被释放锁的线程futex_wake。\\n\\n所以只有3进入内核态了。考虑到大部分情况都不是竞争很激烈的情况下，3根本就不用做。这样的锁的设计避免了由于系统调用导致的上下文切换，无疑很大的提高了效率。\\n\\nOk, 回到Java。Java的synchronized用JVM的monitor实现。而monitor实现内部用到了pthread_mutex和pthread_cond。这俩是pthread标准接口，实现在glibc里。而这俩的内部实现在Linux上目前都用到了futex。所以整体可以理解为futex帮助Java在Linux上实现了sychronized，同时Java自己也实现了很多用户态的同步代码和优化（比如锁偏向一类的）。两块代码共同提供了完整的锁功能。\\n\\n顺便说一句，基于AQS实现的JUC的那些ReentrantLock，Semaphore等内部也是类似的。其LockSupport.park内部用的也是这套东西。\\n"}'));jctx.push(JSON.parse('{"id": "200509", "tag": "lang", "text": "# 代码写法中的状态与异常\\n\\n最近在做构造数据的工作，代码是另两人写的python，在改造过程中，修正了我以往对对象和异常的认识。\\n\\n以前写代码既不爱用类和对象，也不用异常捕获，这次造数据的代码全部是定义各种函数和调用，用法不复杂。但造数据的需求很多，从而就导致函数参数非常多，写起来代码非常啰嗦。参数多的另一个坏处是在多处调用时，不容易一致。\\n\\n## 有状态的执行体\\n\\n构造表数据需要带入参数，但是这个数据其实是和函数绑定的，完全可以合并到一起，用闭包或对象来表达。函数式推崇无状态，但我不确定闭包是否为函数式所接受，但在具体的工作中，带状态的可执行体是非常有用的。\\n\\n## 使用异常\\n\\n有些表数据的构造有依赖关系，如果前置表没有被构造，这张表就不应该被构造。这时有两个选择：\\n\\n1. 隐式构造被依赖项\\n2. 返回错误或抛异常\\n\\n开始想隐式构造，动态构造函数在main函数中被sys.argv给绑定了，于是转而返回错误，至少显示提示也不失为一种选择。如果返回错误，由于表很多，代码会显得非常啰嗦，所以想到用异常。异常有个好处，具备穿透性，不管层级多深，可以直接穿过多层直到被捕获的地方，另外异常还必须要能携带值，否则只有异常类型，捕获了也无法进一步处理。python3的异常语法和2不兼容，似乎只能带str类型的变量，于是通过这条路径，把缺失的表名用异常抛出来，在main函数中显式地补上。\\n\\n反思这次的代码修改，以往偏好理论派的东西其实在实际工作中并不能很好地应对。以我现在的状况，也不可能在理论上有太多的造诣，让更多实际的代码能写得优雅，利用好常见语言的特性，更为重要和实际。\\n\\n## 模拟的隐患\\n\\nPython的异常没有ruby的retry机制，为了模拟在try块的外围加了一层while循环，并在except里用count计数累加，保证重试N次后能退出。但过了一段时间，又加了一个种异常捕获，这里忘记对count累加，导致循环无法退出。模拟的方式终归只是权宜之计，最好的办法仍是以DSL配套完整的机制才可行。"}'));jctx.push(JSON.parse('{"id": "200606", "tag": "lang", "text": "# Python的包机制\\n\\n## 包的封装\\n\\npython的第三方包默认会安装到site-package目录，除了存放源码的目录，还有一个元数据目录类似这样`<name>-<ver>.dist-info`。包的封装机制有easy_install的egg和pip的wheel两种，dist-info表示wheel打包，egg-info说明是egg包，目录中包含的文件不同。另外anaconda有自己的conda方案，没有研究过。egg不仅是发行格式，也是运行时可以直接加载的格式；wheel只是发行格式，安装就是将文件解压到site-package的过程。通常都建议wheel，毕竟有PEP背书，特殊场合比如不想被直接看到代码，打包到一个文件更简洁。python由于版本不兼容原因，最好配合venv/virtualenv指定版本，否则依赖库会冲突。\\n\\n安装PyHive包，以tar包源码形式发布，执行setup.py之后在这台机器上可用，但去site-package目录下看到的却只有一个egg包，和pip方式安装得到的几个目录方式不同，直接复制这个egg包到其它目录后，会提示无法找到PyHive。直到用easy_install安装这个egg包，才明白要在site-package下的easy-install.pth文件里添加一行关于PyHive的版本说明，才能找到。大概原因是import机制会忽略带有连字符的包，而egg包一定有连字符，需要需要.pth文件做个牵引。\\n\\n## 自定义安装位置\\n\\n标准版本启动时会执行`import site`，而embed版本则没有此行为。标准版通过-S选项关闭此特性，embed版本则通过修改.pth文件来打开此特性。如果有-S选项，会反映在`sys.flags.no_site=1`。\\n\\nsite.py一旦被导入，会在builtins中增加help, copyright, credits, license变量。除此外可以额外添加两个加载包的路径，`USER_SITE`类似全局的位置，而`USER_BASE`默认指向当前用户的`~/.local`目录。第三方可以仅给某些用户安装，因此`USER_BASE`的价值就体现出来了。但要启用这个机制还有个前提，getuid和geteuid，getgid和getegid的返回必须相同，否则会认为是sudo行为，不予加载。\\n\\n## import过程\\n\\n结合q这个包和一些试验，看整个import xxx过程发生了什么。\\n\\n1. 先判断sys.modules[\'xxx\']是否存在，有值直接结束，没值则查找文件。注意：*不是判断当前上下文是否有xxx变量*。\\n2. 找到xxx.py并读取，在开始读取前，sys.modules[\'xxx\']已经被初始化，并且具有了`__name__`、`__doc__`等内置变量\\n3. 随着对xxx.py的解析，xxx模块定义的类、函数也会被添加到sys.modules[\'xxx\']\\n4. 结束对xxx.py解析，在当前上下文，新增xxx变量，并让xxx指向sys.modules[\'xxx\']。如果在import xxx之前已经有xxx变量，会覆盖xxx。\\n\\nq这个包就在第3步结束前，覆写了sys.modules[\'q\']变量，实现了import q后，q就能使用的魔术技法，同时也隐藏了q的实现类，非常巧妙。\\n\\n## 控制符号的导出\\n\\n`__all__`变量只对import \\\\*语法有作用，如果手动地导出一个确实存在的变量，`__all__`是不会阻拦的。从字面含义也好理解，all对应的是\\\\*，当然不影响手动导出符号，不过也可见这套机制的简陋。同样py文件中的函数也是这个道理，所有以_开头的函数，用import \\\\*都是看不到的，但是如果知道名字，仍然可以手动调用，所谓防君子不防小人是也。\\n\\n## Windows环境的包特性\\n\\nPython标准包有近百个目录和文件，在分布运行时非常不便，尽管可以把第三方包做成zip，但标准包却不行。因此官方针对Windows提供了embeddable方式的二进制包，把标准包也做成了zip包，而python程序在编译时加了特殊配置，直接加载标准zip包。\\n\\nembeddable方式会寻找`python3x._pth`文件，x是次版本号，找到后将`_pth`的每行加入搜索模块的路径。\\n\\n包的加载路径，如果存在site-packages目录，它会被加入sys.path；而如果根本没有这个目录，sys.path就不会去搜索这个目录。有些包会额外产生一个命令行程序，典型的比如pip。pip在更新自己时需要替换pip.exe，但由于Windows的机制不允许替换自己，现象是pip目录会被改名为\\\\~ip，再次执行会报找不到pip。解决办法就是把\\\\~ip改回pip就可以了，因此Windows上似乎只能删了重装pip。\\n\\n## venv机制\\n\\n官方提供的venv包会把一个目录做成相对独立的环境，具体过程不复杂\\n\\n1. 在该目录下建立bin/lib目录和pyvenv.cfg文件\\n2. 将venv目录的activate文件复制到bin\\n3. 使用标准库ensurepip安装一套独立pip/setuptools到bin和lib\\n\\nvenv初始化后，source bin/activate，会把当前目录放到PATH的开头。于是当前会话下的pip操作就会把要安装的新包放到这个独立目录（退出shell或执行deactive则仍旧用全局pip）。python复用全局命令，观察此时的sys.path，会发现site-package已经换成venv指定的目录了（其它标准目录不变）。\\n\\nvenv有个个人认为很重要但默认没有开启的选项--system-site-packages，但其实也可以编辑pyvenv.cfg将include-system-site-packages = false改为true就可以了。解析pyvenv.cfg的逻辑是写死在site.py中，只要包含了基础包即可，不依赖pip。引用原始py的包后，仍可以升级且不会破坏原始的包版本。升级后，虚拟环境中是新版本的包，而原始环境仍保留不变，两边各留一套互不影响。\\n\\n还有--without-pip选项，不过除了构建虚拟环境快以外，我想不出有什么使用场景。在venv中使用pip和原生使用的配置文件是一样的，意味着用同样的代理，这也好理解，毕竟venv的机制是对PATH做文章，而pip读配置是用户的HOME目录，两者没有交集。\\n\\n## 使用C/Cython写扩展并用setup.py安装\\n\\n官方早期提供的distutil包可以制作无依赖的安装包，为支持更复杂的场景，产生了第三方的setuptools，包制作仍然基于distutil，扩展了依赖包管理。但是distutil的文件比较混乱，而且setuptools都会完整地内嵌一份，到了3.10版本官方正式确定废弃distutil，全面改用setuptools。easy_install现在也是setuptools的一个子模块。\\n\\n最基本的扩展需要setup.py和xx.c两个文件，c文件要依次注册module和method集，以及具体的method wrap实现，最终通过注册函数在加载时导入python空间。这种方式显然非常复杂，可以换用cython语法写pyx，通过cythonize转化为C语言，一样能开发扩展且极大简化开发过程。注册示例\\n\\n```\\nfrom distutils.core import setup\\nfrom Cython.Build import cythonize\\nsetup(ext_modules=cythonize(\\"xxx.pyx\\", language_level=3))\\n```\\n\\n执行setup.py有多种子命令，bdist编译egg包，如果本地装了wheel，可以用python setup.py bdist_wheel指令打成wheel包。egg包放到pypi的仓库中，无法用pip安装，会提示no match version之类错误，但包名是包含了版本的，原因不明。\\n\\n存放代码的目录可以随意命名，distutils的setup函数有非常多参数，有一些概念要注意区分\\n\\n* name=\'abc\' 包的名字，只是一个宣传用的名字，对程序运行没有特别的作用，也不要求和import的包名一致。安装之后，包描述目录的METADATA文件会显示这个name\\n* packages=[] 包安装到site-package后的目录名，可以和包名不同，也可以有多个。一般一个包安装一个目录，但像cython就会装两个目录(cython和pyximport)\\n* package_dir={} 安装到site-package的目录名和源码目录的映射关系\\n* ext_modules = [ Extension(\'x\', sources=[\'x.c\'])] C语言写成的扩展模块\\n\\n上面packages两条，我觉得都是非常糟糕的设计，灵活到让初学者非常迷惑，比如import的包名，在pip freeze却很可能找不到对应的包名，甚至描述目录名都没有与之对应，直到找到了目录的MEATDATA文件才找到包名。但也可能是import用的名字会有很多人想要，于是允许不同的包名安装时用不同的名字（相当于pip注册时是不同的），但安装后用同一个目录名。如果真的产生冲突，那就由用户自己决定。\\n\\n有些包用pip安装后会触发C编译，如果头文件不在标准路径下会失败，用`pip install --global-option=build_ext --global-option=\\"-I/your/py/head/\\"`方式添加头文件路径可以正常编译。\\n"}'));jctx.push(JSON.parse('{"id": "200725", "tag": "data", "text": "# Spark学习手记\\n\\n## 组件构成\\n\\n作为一个分布式系统，物理节点分为master和worker节点，master调度，worker计算。\\n\\n运行职责，即进程级的分为driver（属于master）和executor（属于worker），另外还有类似接口协议的进程cluster Manager（和driver通信）。既然是接口，就有多种实现，常见的有spark clusterManager（standalone和local cluster两种运行模式）、yarn clusterManager（spark on yarn） 和mesos clusterManager（spark on mesos）。\\n\\ndriver端执行main函数，并创建SparkContext，这是Spark启动最重要的类，包含两个必须设置的属性：master和appName。Executor并行计算，是一个执行Task的容器，初始化程序要执行的上下文SparkEnv，解决应用程序需要运行时的jar包的依赖，加载类。SparkContext可以创建RDD。\\n\\n## RDD\\n\\n这是Spark中最早，也是最基础的计算元素，可以理解为元素无序的向量（数组）。由于不可变性，每个RDD在Spark会话中都会被赋予一个惟一ID，这些ID又构成计算的链路，在计算出错需要重算时可以方便地恢复。\\n\\nRDD所有元素的类型相同，分为2种值类型\\n\\n1. 单Value类型：存放简单类型，如int，string\\n2. Key-Value类型：整个值的类型称为Row，Row类型的第一列是key，剩下的是values，可以想象成lisp的list，key和value分别对应car和cdr操作。针对key可以进行lookup、join等运算。当value包含的内容很多时，为了更细粒度地操作，还可以把Row类型转换为DataFrame，就能对每一列单独指定操作方法。\\n\\nRDD的五大属性和若干种实现\\n\\n1. partitions(分区数量)\\n2. partitioner(分区方法，可以为None)\\n3. dependencies(依赖关系): 运算就是在多个RDD间的变换，如果一个父RDD变换后得到多个子RDD，就是宽依赖，也称为shuffle；一个父RDD只得到一个子RDD，则称为窄依赖。\\n4. compute(获取分区迭代列表)\\n5. preferedLocations(优先分配节点列表)\\n\\n## RDD的操作和任务执行过程\\n\\n大多数文章都把RDD的操作分为transform和action两类，trans还能再细分，这里采用细分后的4种类型。\\n\\n1. 创建操作（creation）：pyspark只提供了parallelize；scala还提供makeRDD\\n2. 转换操作（transformation）：从一个RDD得到另一个RDD，绝大部分都是此类操作\\n3. 控制操作（control）：persist和cache，优化性能\\n4. 行为操作（action）：将惰性计算进行求值，比如collect, count, take, save, foreach, reduce。特别要提的是，**reduce是行为，但reduceByKey是转换**，二者不可混为一谈。\\n\\n区分的依据是：trans不会马上执行，而是等到action才会触发计算。为什么trans不触发计算呢，因为计算的成本太高，计算过程要尽量合并，很多中间步骤，在不急于显示结果时，没必要计算。以groupByKey为例，分组不是最终目的，对分组做的聚合运算才是用户真正想要的。因此分组时，只需要把计算过程规划好，不必急于把计算任务派发到数据分区。\\n\\nRDD的分类，体现在任务运行粒度上，就分为大小两种，app(1个) > job > stage。每当代码中遇到transformation（意味着要创建新的RDD），会继续分析，直到遇到action类操作，就会产生一个job来真正执行所有的transfomation和这个action。job中如果有shuffle操作（trans和action都会产生shuffle），就会产生前后两个stage（HDFS读写文件是stage内的操作，不会产生切分）。也可以说每个stage内部是窄依赖，会做fusion优化，而stage之间则是宽依赖。每个stage处理的rdd数据，又会根据其有多少个 partition，运行相同个数的 task（每个task是一个线程），每个 task 只处理一个 partition 上的数据。所以一个stage也叫一个taskset。\\n\\n任务执行过程分4步\\n\\n1. 解析代码中的RDD操作，根据转换关系形成DAG图\\n2. 将DAG图交给DAGScheduler组件（包含在SparkContext中）进行逻辑拆分，具体做法是从最后一个RDD向前回溯，遇到action算子切分出一个job，每个job内根据shuffle类划分stage\\n3. 拆分后的stage链，交给TaskScheduler（包含在SparkContext中）做物理执行，分派到具有空闲资源的worker结点\\n4. work对收到的每个调度，启动一个线程执行task，结果结果返回给TaskScheduler，最终在driver端汇总\\n\\n### 分区的解释\\n\\nRDD是个逻辑概念，它的数据通常会分布在多个worker节点，拆分的个数由partition决定，partition数量既可以大于，也能小于worker数量，计算一个真实有数据的partition对应一个task任务。分区的数量，如果直接创建，可以在参数指定，如果是从HDFS读取，则由文件分块数量决定，最小是2，大的有十几甚至上百。题外话，正因为数据是分散在多个worker节点，如果想要看到全貌，要用collect()，方法命名非常到位。\\n\\nRDD实现类举例\\n\\n1. MapPartitionsRDD\\n2. ParalellCollectionRDD\\n2. ShuffledRDD\\n3. ReliableCheckpointRDD\\n\\n## 从RDD到DataFrame的转变\\n\\nSpark最初只有RDD做为通用的计算接口，也称为Spark Core，并没有SQL功能。因为无类型，导致性能优化遇到瓶颈，在1.3版本演化出了DataFrame，天然和SQL相近，此时整个项目的核心也迁移到Spark SQL。为了管理库和表元数据，在SparkContext基础上，加入SQLContext（是个InMemory实现，2.0版本还有一个外部源实现HiveContext），就变成了SparkSession。session类有个catalog成员可以查看映射的库和表。SQL也是经由DataFrame最后转成RDD才执行。2.0版本只能指定一个catalog，3.0版开始支持multiple catalog。\\n\\n## DataFrame\\n\\n是Row类型RDD被绑定schema后的性能优化版。RDD用.toDF转化为DF（简单类型的RDD不可以转化为DF），每个DF也可以通过.rdd属性得到对应的RDD实例，通过.schema得到结构。多说一句，RDD的toDF方法，其实是构建SparkSession的时候，硬塞在RDD上的猴子方法，最终调用的还是SparkSession.createDataFrame方法。由于是从RDD转化而来，分区数和RDD一致。\\n\\n运行DataFrame算子，还是会编译为RDD后才真正执行，因此RDD仍是Spark惟一的运行时，可以将DataFrame比作编译过程的中间代码优化器。对开发者来说想要手写出和DataFrame编译成的RDD相同性能的代码，困难且无必要，因此社区鼓励大家迁移到DataFrame。"}'));jctx.push(JSON.parse('{"id": "200727", "tag": "design", "text": "# 神经网络来源与分类\\n\\n## 早期历史\\n\\n神经网络技术起源于上世纪五、六十年代，当时叫感知机（perceptron），包含有输入层、输出层和一个隐藏层。输入的特征向量通过隐藏层变换到达输出层，由输出层得到分类结果。但早期的单层感知机存在一个严重的问题——它对稍微复杂一些的函数都无能为力（如异或操作）。直到上世纪八十年代才被Hinton、Rumelhart等人发明的多层感知机克服，就是具有多层隐藏层的感知机。\\n\\n多层感知机可以摆脱早期离散传输函数的束缚，使用sigmoid或tanh等连续函数模拟神经元对激励的响应，在训练算法上则使用Werbos发明的反向传播BP算法。这就是现在所说的神经网络NN。\\n\\n神经网络的层数直接决定了它对现实的刻画能力——利用每层更少的神经元拟合更加复杂的函数。但问题出现了——随着神经网络层数的加深，优化函数越来越容易陷入局部最优解，并且这个“陷阱”越来越偏离真正的全局最优。利用有限数据训练的深层网络，性能还不如较浅层网络。同时，另一个不可忽略的问题是随着网络层数增加，“梯度消失”现象更加严重。（具体来说，我们常常使用sigmoid作为神经元的输入输出函数。对于幅度为1的信号，在BP反向传播梯度时，每传递一层，梯度衰减为原来的0.25。层数一多，梯度指数衰减后低层基本上接受不到有效的训练信号。）\\n\\n## 大发展与大突破\\n\\n在2010年代的后半程，图像和文本领域分别产生了堪称革命性的ResNet（深度残差网络）和Bert模型。\\n\\n图像领域一直沿着CNN的方向发展，最早取得突破的是Yann LeCun在1998年提出的LeNet，在32x32的小图片效果有突破，但不能处理大图片。但毕竟奠定了现代卷积神经网络的原型，即卷积，池化，全链接。\\n\\n在这之后CNN的锋芒开始被SVM等手工设计的特征盖过。随着ReLU和dropout的提出，以及GPU和大数据带来的历史机遇，CNN在2012年迎来了历史突破，这一年的ImageNet上AlexNet一举夺冠，开启了神经网络识图的时代。但AlexNet没有在方法论上给出方向，之后的VGG使用一系列大小为3x3的小尺寸卷积核和pooling层构造深度卷积神经网络，并取得了较好的效果。\\n\\n2014年的ImageNet冠军是GoogLeNet，它的主要特点是网络不仅有深度，还在横向上具有“宽度”。2015年ImageNet的冠军ResNet，更是将图像分类识别错误率降低到了3.6%，超过了正常人眼识别的精度。\\n\\n而文本领域由于前后相关性，起初都是基于RNN在做，但RNN存在串行缺陷，很难并行。文本领域的突破稍晚于图像，2017年Google提出Transform，这个模型由Encoder-Decoder组成，它的Self-Attention和Position Embedding可以替代RNN来做Seq2Seq任务。Attention是个精妙的词法袋（由Yoshua Bengio提出），但不能识别位置，配合上Position Embedding就完整地解决了机器翻译的问题。\\n\\n2018年出现的Bert也是以Transformer为基础，但只使用Decoder部分，因此只有Self-Attention，没有普通的Attention。\\n\\n2006年Hinton最早提出深度学习的概念，具体是利用预训练的方式缓解了局部最优解的问题，将隐藏层增加到了7层，实现了真正意义上的“深度”。LeCun、Hinton和Bengio一起因深度学习上的贡献获得了2018年图灵奖。\\n\\n## 各种网络的简单比较\\n\\n对主要的3种分类归纳如下：\\n\\n1. DNN：为了克服梯度消失，ReLU、maxout等传输函数代替了sigmoid，形成了如今DNN的基本形式。结构跟多层感知机一样。\\n2. RNN：DNN无法对时间序列上的变化进行建模，但时间顺序对于自然语言处理、语音识别、手写体识别等应用非常重要。为了适应这种需求，就出现了循环神经网络RNN。\\n3. CNN：图像中存在固有的局部模式（如人脸中的眼睛、鼻子、嘴巴等），所以将图像处理和神将网络结合引出卷积神经网络CNN。CNN是通过卷积核将上下层进行链接，同一个卷积核在所有图像中是共享的，图像通过卷积操作后仍然保留原先的位置关系。\\n\\n在普通的全连接网络或CNN中，每层神经元的信号只能向上一层传播，样本的处理在各个时刻独立，因此又被成为前向神经网络(Feed-forward Neural Networks)。而在RNN中，神经元的输出可以在下一个时间段直接作用到自身，即第i层神经元在m时刻的输入，除了(i-1)层神经元在该时刻的输出外，还包括其自身在(m-1)时刻的输出！表示成图就是这样的：\\n\\n为方便分析，按照时间段展开如下图所示：\\n\\n（t+1）时刻网络的最终结果O（t+1）是该时刻输入和所有历史共同作用的结果！这就达到了对时间序列建模的目的。RNN可以看成一个在时间上传递的神经网络，它的深度是时间的长度!正如我们上面所说，“梯度消失”现象又要出现了，只不过这次发生在时间轴上。\\n\\n所以RNN存在无法解决长时依赖的问题。为解决上述问题，提出了LSTM（长短时记忆单元），通过cell门开关实现时间上的记忆功能，并防止梯度消失。在序列信号分析中，如果能预知未来，对识别一定也是有所帮助的。因此就有了双向RNN、双向LSTM，同时利用历史和未来的信息。\\n\\n事实上，不论是哪种网络，他们在实际应用中常常都混合着使用，比如CNN和RNN在上层输出之前往往会接上全连接层，很难说某个网络到底属于哪个类别。不难想象随着深度学习热度的延续，更灵活的组合方式、更多的网络结构将被发展出来。\\n\\n简单总结如下：\\n\ufeff\\nCNN(卷积神经网络)、RNN(循环神经网络)、DNN(深度神经网络)的内部网络结构的区别\\n\\n先说DNN，从结构上来说他和传统意义上的NN（神经网络）没什么区别，但是神经网络发展时遇到了一些瓶颈问题。一开始的神经元不能表示异或运算，科学家通过增加网络层数，增加隐藏层可以表达。并发现神经网络的层数直接决定了它对现实的表达能力。但是随着层数的增加会出现局部函数越来越容易出现局部最优解的现象，用数据训练深层网络有时候还不如浅层网络，并会出现梯度消失的问题。\\n\\nCNN与RNN的比较\\n\\n相同点\\n\\n1. 传统神经网络的扩展。\\n2. 前向计算产生结果，反向计算模型更新。\\n3. 每层神经网络横向可以多个神经元共存,纵向可以有多层神经网络连接。\\n\\n不同点\\n\\n1. CNN空间扩展，神经元与特征卷积；RNN时间扩展，神经元与多个时间输出计算\\n2. RNN可以用于描述时间上连续状态的输出，有记忆功能，CNN用于静态输出\\n3. CNN可以达到1000+深度，RNN深度有限"}'));jctx.push(JSON.parse('{"id": "200830", "tag": "os", "text": "# 多进程与进程间通信\\n\\n在linux中，fork和vfork的系统调用都是clone，当然标记是不同。\\n\\n* fork: CLONE_CHILD_CLEARTID|CLONE_CHILD_SETTID|SIGCHLD\\n* vfork: CLONE_VM|CLONE_VFORK\\n* pthread_create: CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID\\n\\n以目前的性能优化而言，两者的开销区别并不大，更大的区别在于执行流程和内存空间不同。fork执行后，父子进程一定会被执行到，规范没有规定执行顺序，一般都是同时开始调度。而vfork则一定是子进程先执行，而且**如果子进程没有调用\\\\_exit（不是exit）或exec函数的话，父进程不会被执行**。\\n\\nfork是COW，而vfork的子进程可以修改父进程的变量（纯share，没有copy），这也是为什么父进程必须等待子进程调用\\\\_exit后才会被执行的原因。\\n\\n用strace观察锁，绝大多数都是futex函数调用，且操作都是FUTEX_WAIT_PRIVATE，很难看出区别，只有一次触发了FUTEX_WAIT。看资料说现在的锁实现，大多是先自旋一定次数，如果还获取不到，再用户态等待，不会轻易进入内核态，毕竟futex的目的就是防止程序进入内核态。子线程结束调用exit，而主线程结束调用exit_group。\\n\\n创建线程的身份是tid，但由于操作系统的进程API在前，所以同一个主线程，不管创建多少子线程，这些子线程的pid都一样。\\n\\n## 僵尸状态\\n\\n为什么会有这个状态呢？我能想到的惟一原因是父进程要取得子进程的退出状态等信息。僵尸状态是每一个进程退出前的必经过程（只有init进程例外，因为不会退出）。僵尸态只记录一个整型状态，但不止一种信息，用wait.h的特殊宏可以解析出是exit还是stop，收到的信号量等等，而且处在僵尸态的进程，/proc/<pid>/目录的文件会的owner会变成root。但僵尸进程毕竟占用内核的pid资源，所以必须回收。\\n\\n结束僵尸态有几种方法\\n\\n1. 父进程调用wait()\\n2. 父进程显式忽略SIGCHLD信号，必须用SIG_IGN才能自动结束僵尸，其它注册函数没用\\n\\n另外好像用llvm编译的程序，虽然没有注册SIGCHLD，也不调用wait，子进程仍能结束不会变成僵尸。\\n\\n## 进程会话和作业\\n\\n多个进程间会进行分组，有几种分组方式。\\n\\n* session: 一般指shell session，一次登录sh导致的所有进程都在这个session下，而sh进程就称为session的领头进程，通过ps的SID列可以查到\\n* job: 最典型用管道符串起来的多个进程，称为一次job。第一个进程是job的领头进程，通过ps的PGID列可以查到\\n\\n## 7种进程间通信机制\\n\\n1. pipe 管道，最简单，对应syscall有pipe和pipe2两种，pipe2多支持几种选项，是linux在2.6.27才加入的接口\\n2. fifo 有名管道，对应syscall是mknodat，因为有名，且对应磁盘上的文件，因此用mknod方式创建。\\n3. mmap 文件映射共享IO，速度最快（原理：在内存开辟一片缓冲区，把文件映射到内存上，你直接去操作内存就可以了）。shell中的管道符用的就是这种，但不管输入端的内容有多大，都只调用两次mmap（必须有MAP_SHARED标记），大小都是128K。\\n4. 本地socket 最稳定\\n5. 信号 携带信息量最小的\\n6. 共享内存 开辟一块内存区域，大家都能访问，一个进程退出之后，这块内存还会给你保留下来，后来者还可以继续使用\\n7. 消息队列\\n\\n## 匿名管道\\n\\n先从匿名管道说起，在shell中执行 `ls | grep xx` 时，背后的流程是当前的sh为父进程，fork出两个子进程，分别exec执行ls和grep，而且这两个子进程之间会有匿名管道pipe()连接起来。由于两个子进程的父进程都是shell，因此存在亲缘关系，匿名管道以fd方式存在，通过fork方式被两个子进程共享，这就是匿名管道可以工作的原因。\\n\\n顺便说一句，读管道要用read语句，而读命令行输入则是$#一系，由于输入形式的不同，处理逻辑也不同。\\n\\n## 有名管道\\n\\n用读方式打开有名管道，默认是BLOCK模式，意味着当没有进程写入时，会一直堵塞。而一旦有数据写入，会源源不断地读到数据，即使没有数据写入，也不会阻塞读动作。因此对有名管道的读，每次读到空，就要关闭管道，并再次尝试打开，否则CPU会急剧升高。形如以下\\n\\n```\\nwhile true {\\n    fd = open(\'fifo\', \'r\')\\n    line = fd.read()\\n    fd.close()\\n}\\n```\\n\\n观察这两种管道的使用，会发现都使用`pipe_wait`系统调用，因此都叫管道。\\n\\n匿名管道因为使用形式的关系，数据流动是单向的。而有名管道形式上是文件，当然是双向，打开用读写方式。而且有名管道涉及进程间交互，往往是双向流动。如果A到B，B直接打印到终端，人眼看上去没有区别，程序是无法捕获这段打印，有点类似内核输出报警，你能看到却没有任何方式拦截并重定向它。\\n\\n引申一点，shell脚本中怎么判断是命令行启动，还是接在管道后？这两种情况下，stdin没有区分，这时就要再往前想一步，stdin这个逻辑概念指向谁？匿名管道模式，stdin指向的显然是管道，而命令行模式下，stdin指向的是终端，真实的终端叫tty，后来网络化后叫pts，但只是表示不同，终究有个对应的实体。tty命令就是打印stdin所对应的终端，如果stdin对应的是匿名管道，则会返回错误并提示`not a tty`。除了tty，用`[ -t 0 ]`也能判断0是否为tty。对应的C函数是isatty。\\n\\n## 文件锁\\n\\n文件锁用flock保证一个进程启动时独占"}'));jctx.push(JSON.parse('{"id": "200925", "tag": "lang", "text": "# Python进阶学习点滴\\n\\n## 迭代与惰性\\n\\niterator概念体现在很多地方，甚至str都可以迭代，list(\'abc\')会返回[\'a\',\'b\',\'c\']。具备迭代的函数又分eager和lazy两种，list是eager行为，enumerate/map则是lazy行为，返回一个可迭代对象，对这个对象用for循环或tuple/list进行求值。\\n\\nlazy对象一旦被求值，这个对象就成了空壳，因为lazy对象从语义上就不把值放在内存，可以理解为外部源的一个门户或代理，当真正的外部源被求值完毕，则lazy代理自然没有了内容来源。\\n\\n内建3大基础类型tuple/list/dict都具备对lazy迭代对象求值的能力，dict因为语义原因，每次迭代必须有两个值。\\n\\n求值是严格模式，要想实现惰性，由于缺少宏和编译期展开能力，能想到的办法只有foo(lambda: x)，然后在函数体内展开。\\n\\n## 多行lambda\\n\\n语法上要求返回一个expression，不能出现冒号和赋值（因为赋值是statement，可以用3.8后的:=assignment expression）。利用tuple和切片索引来打包多个独立行为，利用if的一行式来做简单的条件\\n\\n```\\ndef main(n):\\n    return lambda x: (\\n    print(x),\\n    x+1 if x > 0 else x-1,\\n    x + n)[1:]\\n```\\n\\n## 多线程\\n\\n拜臭名昭著的GIL所赐，多线程只在IO密集场景下有一战之力。即便只能用到一个核，锁还是必须的，但这个锁和OS的锁不同，是语言级别的锁，不会触发futex调研。有人解释说这种锁的获取和释放，会引起GIL的调度，暂时不能确定。另外py3新增了asyncio后，多线程的使用场景似乎更少了。\\n\\n## 多进程\\n\\n多进程库有两种构造进程的方式，Process（构造一个）和Pool（构造多个功能相同的进程）。从实际效果来看，每生成1个进程，实际会生成2个线程。以生产消费模型，结合队列来举例子。\\n\\n先说队列Queue，生产者用put方法，消费者用get方法，但是这里有个隐秘且反直觉的地方，调用put会将队列的计数加1，但get并不会减1，需要在get之后再调用task_done才行，背后的原因是get允许异步获取，所以必须消费者确认得到消息后，才能将队列次数减1。队列的次数可以通过empty方法得到。真实代码中，生产者会用队列的join方法，join会阻塞直到队列为空才执行下去。\\n\\n就产生了这样一种方式，消费者用with Pool结构，在这个结构内，用Process来创建生产者，生产者全部start()后，会挨个join()，直到每个生产者执行中，队列的join通过后，才会结束。*注意，这里有两个join，分别作用在队列和进程上，而进程的join又被队列的join所阻塞，最终等待消费者消费完所有消息，这就构成了完整的闭环*。当生成者结束后，with语句块的生命周期结束，调用Pool的`__exit__`方法，它又触发了Pool的terminate()，将所有消费进程强行停止，于是所有进程就都正常回收了。\\n\\n一开始我看这段还很疑惑，为什么while Tue循环里只有队列的get，看不到判断和退出，其它是用了with块的方式强行中止了进程，自然就不用判断队列。\\n\\nJoinableQueue objects should only be shared between processes through inheritance\\n\\nPool创建的进程，和Process没有继承关系。跟踪系统调用发现，都是用clone函数，无非用的标志位不同\\n\\n* CLONE_VM: VM shared between processes，内存共享，大约等于线程\\n* CLONE_CHILD_CLEARTID|CLONE_CHILD_SETTID:  Store child thread ID in child memory.Erase child thread ID in child memory space when child exits.\\n* CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID:\\n\\n## 进程池\\n\\n使用进程池Pool启动多进程建议用`apply_async`，这个方法默认不会阻塞，想要等待必须连用Pool的close和join方法，网上文章几乎不提为什么。看了源码才知道，Pool有4种状态，INIT，RUN，CLOSE，TERMINATE。构造进程池对象时，内部会经由INIT状态切到RUN状态。CLOSE状态是为了配合join使用，如果不切换到CLOSE状态，join动作会报错。join内部调用到的方法有wait，只是觉得都用join还是有些混淆。\\n\\n## 多进程的队列\\n\\n底层使用操作系统的pipe作为传输，但为了实现任意py对象的传输，在数据写队列前，会先用pickle序列化，读出的一方会先确认pipe内的消息长度，读出后再反序列化。复杂队列的实现，发送者每次发一条消息，会创建一个线程，由这个新的线程向pipe写数据。\\n\\n## defaultdict\\n\\n出人意料的是这个容器是builtin的，实现在`_collection`包中，不是一个独立的磁盘文件，而是和C语言实现打包在一起，可能对字典的操作需要极高的性能，因此无法用py实现吧。\\n\\n## namedtuple\\n\\n是一个函数返回一个用type方法动态构建的类\\n\\n## pickle序列化\\n\\n首字节固定0x80，然后跟1字节的版本号，截止3.8共有1-5的版本。\\n\\n每遇到新的复杂结构（tuple/list/dict），都会写入一个新的标记符，`EMPTY_XX`，然后跟着具体的值。\\n\\n结构内的字符串，以类型+长度+值的方式保存（典型的TLV格式）。\\n\\n字典内容都结束后，以一个\'s\'（SETITEM动作）把kv的pair对加入字典。\\n\\n最后以\'.\'结尾这个pickle。\\n\\n当然过程中会用MEMOIZE技术复用已保存的字符串，达到节约空间的效果。整个pickle不仅仅记录了值，更记录了从一片空白到完成所有对象的整个操作步骤，在构建过程中逐步还原出对象。\\n\\n## 魔术方法\\n\\n`__getitem__`作用于方括号下标，而`__getattr__`作用于对象的点式取值。还有要注意的是，这两个方法虽然是class上定义，但却只对实例后的对象生效。\\n\\n## 类型标注\\n\\n初看`Union[int, str]`语法会觉得很困惑，因为下标引用只能是1个值，但是换成Union(int, str)又会提示不是callable，说明只能是`__getitem__`方法，再自己实现后才明白原来[int, str]会被转换成[(int, str)]形式。\\n\\nOptional基于Union扩展，但做的时候偷了个懒只能传递单参数，因此实际用的时候往往会写成`Optional[Union[]]`形式。\\n\\n## 源码初读\\n\\n几个关键目录的目标\\n\\n* Object和Python: 定义对象的内存布局，核心的so要实现的编译及导入功能\\n* Lib: py实现的标准库\\n* Modules: py库会引入c实现的so(lib-dynload目录)，都在这里实现\\n* Parser和Grammar: 词法语法解析"}'));jctx.push(JSON.parse('{"id": "201009", "tag": "tool", "text": "# shell的历史和流派\\n\\n## 源起Bourne\\n\\n最初unix系统用的是ken thompson写的shell，不过这个只在贝尔实验室内部用，最早广泛流行的version 7 unix系统的shell是Bourne shell在1979年重写的，可以说Bourne的版本是最初的原型，已经具备了大多数结构化编程的功能。\\n\\n## csh\\n\\n1990到2000年代在BSD系统上比较多见，是Bill Joy写的另一种风格的shell，意图是加强交互性，但也被批评不适用于编程（比如不支持在脚本中定义函数）。后来FreeBSD又强化出了tcsh，由于使用习惯和Bourne版本差别较大，似乎只有FreeBSD把它作为root用户默认，普通用户不用csh，开发也不太活跃。\\n\\n## ksh\\n\\nDavid Korn基于Bourne的代码，又借鉴了csh的作业控制的改进版，加入了emacs和vi风格的编辑方式。ksh88是POSIX规范的蓝本，另有ksh93是另一个主要的版本。但其所属权一直归AT&T所有，不算开源软件。ksh的很多衍生版本用在商业Unix上，Android 4.0后默认的mksh也是ksh的后代（之前是ash）。\\n\\n## ash和dash\\n\\nBourne版本毕竟存在版权所属问题，Kenneth Almquist重新实现了一个版本，特点是执行速度很快且节约内存，相比ksh，少了行编辑和历史命令。后来debian基于它维护了dash（Debian Almquist shell），虽然行编辑和历史命令作为可选项支持了，但仍然不完全满足POSIX（缺少国际化和多字节）。也正是因为其精简，dash的0.3.8-5版本被busybox所集成，用在很多嵌入式系统上。\\n\\n## bash\\n\\nGNU组织开发了bash，是大多数Linux发行版的默认shell，功能非常丰富。但是由于GPL协议的关系，也受到不少非议，OS X的bash版本就长期停留在3.x，后来干脆换成zsh来规避GPL。\\n\\n试举一个特性，通过`PROMPT_COMMAND`环境变量来控制显示，和PS1的区别在于PS1只是显示字符串，而PROMPT会先执行后面的语句，把语句的结果作为提示符。这就是z.lua似乎没有特别地增加路径，却可以记录每次到过路径的原因。\\n\\ncomplete是可配置的选项，对特定命令丰富补全功能。\\n\\n## zsh和fish\\n\\n对bash的扩展仍然觉得不够，于是有了这两个版本，了解不多，先记一笔。"}'));jctx.push(JSON.parse('{"id": "201101", "tag": "net", "text": "# 二三层网络和MAC地址\\n\\n根据OSI的七层模型，二层协议包含PPP、ARP，而三层包含IP、IGMP。\\n\\n1. 不同网段（子网）的ip通信，需要经过三层网络。相同网段的ip通信，经过二层网络；\\n2. 二层网络仅仅通过MAC寻址即可实现通讯，但仅仅是同一个冲突域内；三层网络需要通过IP路由实现跨网段的通讯，可以跨多个冲突域；\\n3. 二层网络的组网能力非常有限，一般只是小局域网；三层网络则可以组大型的网络。\\n4. 二层网络基本上是一个安全域，也就是说在同一个二层网络内，终端的安全性从网络上讲基本上是一样的，除非有其它特殊的安全措施；三层网络则可以划分出相对独立的多个安全域。\\n\\n二层交换机实质就是一张大的查找表，记录MAC和IP的对应关系，因此有ARP协议也是很自然的事情。但是受限于交互机的内存以及以太网络的冲突，网络容量不会太大，这也是子网掩码大多都设置为255.255.255.0的原因。\\n\\n## MAC地址拾遗\\n\\n通常认为MAC地址是全球唯一，其实MAC地址的本意是保证在一个广播域内唯一，因为MAC是以太网下的概念，帧中继、ATM等通信方式都是没有MAC地址的。\\n\\nMAC地址的高24位被称为OUI，组织单位标识符，正规厂商需要花钱向IEEE购买之后才能使用。这就有一则历史趣闻，1990年代，steve deering在研究IP组播时，希望能拿到和组播IP地址相等数量的MAC地址，D类IP地址有效位数是28位，意味着需要购买2^4个OUI，当时一个OUI的售价是1000美金，steve的经理jon postel觉得1万6美金太贵，但是愿意在预算外再购买1个OUI，并分出其中一半给steve研究，于是MAC的组播地址就变成了OUI为01-00-5E，有效位数低23位的地址空间。进而导致组播时，IP地址只有后23位被映射到MAC，也就是说每32个组播IP地址共用同一个MAC地址的现状。"}'));jctx.push(JSON.parse('{"id": "201224", "tag": "os", "text": "# fork与exec考\\n\\nFork 最早可考的来历是 1962 年 Melvin E. Conway 的论文 A Multiprocessor System Design，这篇文章中 Conway 提出可两个原语：Fork 和 Join，Fork 用来分叉，Join 用来聚集。这篇文章用了 Process 这个词，但是和现在的「进程」完全不是一回事。后来，有个叫做 GENIE 的分时系统实现了这套处理逻辑。\\n\\nexec 的起源则是早期 Unix 中 Shell 的运行方式：Shell 启动用户程序的时候会直接把用户程序的代码覆盖 Shell 的代码并清空内存，等执行完了再用 exit() 把 Shell 代码重新初始化一遍。于是，在运行用户进程前后 Shell 几乎没法保留任何信息（这其实和 80 年代家用电脑挺像的，DOS 的 INT 21/4B 在处理 COM 的时候也差不多。）\\n\\n为了解决这个问题，最简单的办法就是把 Shell 整个内存空间给复制一遍再覆盖，Unix 于是借鉴了 GENIE 分时系统里面的 Fork 来做这个复制的活，这就是 fork-exec 二件套的来历了。\\n\\nDOS也是这个工作模式。最初大家都要挤占实模式下的640k运行内存，这块内存在DOS启动后会先被command.com占据，就是它提供了dos的shell；当用户敲了一个“外部命令”（也就是其它程序）时，这个“外部命令”就把目标应用加载进来、覆盖掉自己（exe和com还各有不同执行方式），只保留加载器所在的那一丁点内存；等用户程序执行结束、控制器返回加载器代码，这段代码就把重新加载回内存。\\n\\n有时候用户程序可能特别大，640k都不够用（其实刨去其它零碎也就600k不到能用）；那么用户还要自己搞个ovl文件，自己加载进来（并把自己之前占用的空间覆盖掉，所以叫“覆盖文件”；当然也会留下执行加载的那点代码不覆盖，不然就没得恢复了），然后跳转到ovl入口继续执行代码逻辑——有的程序可能需要载入N个不同的ovl才能完成自己的工作（有的大型软件一套几十张软盘，运行时需要依照提示在不同时刻插入不同的软盘）。\\n\\n再后来内存/磁盘越来越大，计算机运行起来就不再需要这么捉襟见肘了。\\n\\n但由于这个历史，各OS上的exec类系统调用都有一个“干掉发起调用的进程的副作用”这个“特性”就遗留至今。\\n\\n## 创建进程性能比较\\n\\nwindows没有fork这样快速“复制”一个进程的手段，导致每次启动进程都需要从头开始执行fork前的所有逻辑。因此，在Linux上普遍采用的、把进程当“稍微重一点的线程用”的设计方法，在Windows上性能消耗很大，所以类似架构就不太行得通。\\n\\n有一个windows/linux创建进程速度的对比评测：硬件平台为Core 2 Duo T5450 1.66GHz，1GB内存。操作系统为Windows XP SP3/Ubuntu 10.04\\n\\n被创建的子进程是另外一个立即退出的空进程，所以这里仅仅比较了创建进程本身的效率差异，并未利用到fork的优势。\\n\\n结论是：windows创建一个进程平均需要8ms（125个/秒），而Linux则需要0.28ms（3570个/秒）。\\n\\n这个实验并不严谨，使用的API也不都是效率最高的那种。不过基本上还是可以说明问题的。\\n\\n## 分离的原因\\n\\nMIT 的教学用操作系统 xv6 文档第 14 页给出了一个理由：\\n\\nNow it should be clear why it is helpful that fork and exec are separate calls: between the two, the shell has a chance to redirect the child’s I/O without disturbing the I/O setup of the main shell.\\n\\n和 Operating System:Three Easy Pieces 的观点是一致的：分离这两个函数，让 I/O redirection 的实现变得很容易。但这里重点是不会影响到 main shell 的 I\\\\O。如果你接着读下去，文档里提到了假如我们把这两个函数合并成 forkexec，的确可以在 fork 前重定向：\\n\\nThe shell could modify its own I/O setup before calling forkexec (and then un-do those modiﬁcations);\\n\\n合并两个接口最大的问题是，必须还原之前的设置。举个例子，比如想让子进程输出到某文件，父进程打印子进程的 pid 到 stdout：\\n\\n如果在 fork 之前重定向，需要做额外的还原：\\n\\n```\\nint main() {\\n  int stdout_dup = dup(1); // 存住 stdout，之后恢复\\n  close(1);\\n  open(\\"output2.txt\\", O_WRONLY);\\n\\n  if ((pid = fork()) == 0) {\\n    execvp(\\"echo\\", argv);\\n  } else {\\n    wait(NULL);\\n    dup2(stdout_dup, 1); // 还原设置，否则 pid 会被打印到 output2.txt\\n    printf(\\"%d\\\\n\\", pid);\\n  }\\n  return 0;\\n}\\n```\\n\\n很明显，这个额外的还原操作，让 I/O redirection 的代码变得复杂，也增加了程序员的心智负担。\\n\\n## 接口语义\\n\\nglibc里面有一个函数叫posix_spawn，类似于CreateProcess，其实现就是调用clone(vfork) + execve。\\n\\n这么设计原因就是让系统调用足够原子化。我们来看fork，做法是 1) 创建进程的内核对象(分配一块系统内存) 2) 复制内存映射表(只是标记为COW) 3) 复制线程环境(一组寄存器的值)。然后等着老进程新进程的线程竞争执行即可，其他什么都不用做了，甚至连调用堆栈都不用重新创建(只不过由于COW机制很快会触发另一个中断，这是另一回事)。\\n\\n然后来看exec，它做了 1)关闭部分系统资源(比如fd会关闭，shm不会关闭，取决于系统实现) 2) 清空内存映射表 3) 清空同进程下所有线程，仅留一个tid和pid相同的那个线程 4) mmap源文件和对应的interpretor，比如script就是sh，elf文件就是ld 5) 设置线程环境为interpretor的入口地址。然后和fork一样等着线程自行参与竞争即可，注意有些事情并不是在系统调用过程中做的，比方说加载exe依赖的动态库(如libc)，调用init(初始化全局变量)，调用main函数等，都是在interpretor里面做的。\\n\\n从两个系统调用的实现来看，已经相当精简，fork的语义仅有\\"创建进程\\"一事，没有大量的内存操作，速度飞快，exec的语义也被精简成\\"从头开始执行程序\\"，虽然在多任务linux系统中有涉及到进程(线程)操作，但在语义上并不涉及进程概念。这种语义上的精简对于上层软件开发提供了更大的灵活性。\\n\\n在fork和exec之间建立子进程的运行环境，包括但不限于：\\n\\n继承或不继承文件描述符，文件重定向，切换当前目录，设置环境变量，切换根目录，设置signal环境，建立进程会话，SUID/SGID，设置资源限制，建立调试环境，等等。\\n\\n这些事情由父进程做不合适，会污染父进程的环境，用api做，要怎么设计接口？Linux继承了Unix的fork/exec，再看win32的CreateProcess有多少参数，对比一下就能明白其设计理念。\\n\\n## 脚本并行执行\\n\\n使用`&`符/nohup/xargs/coproc可以实现非阻塞甚至并行跑多进程。循环启动多进程示例，把`&`放在{}后\\n\\n```\\nfor num in `seq 1 ${all_num}`\\ndo\\n{\\n\\tsleep 1\\n\\techo ${num}\\n} &\\ndone\\n```\\n\\nxargs的-P选项控制每次最大的并行数，资源有限场景可用\\n\\n```\\nseq 1 ${all_num} | xargs -I {} -P ${thread_num} sh -c \\"sleep 1;echo {}\\"\\n```\\n\\n使用`wait $!`等待子进程结束（$!表示上一个进程，可以不写。注意不要用$$，代表是当前进程）。用Ctrl-C停止主进程后，会把后台子进程也同时停掉，说明子进程并不是始终被1号进程托管。\\n\\ncoproc从手册描述上看是协程，但本质仍是一个预定义了输入输出文件描述符(COPROC[0]和COPROC[1])的后台进程。\\n\\n"}'));jctx.push(JSON.parse('{"id": "201225", "tag": "tool", "text": "# vim的自动补全\\n\\n自动补全有15种模式（:help ins-completion）。其中有两种的补全列表内容与另外两种相同，只是排序不同\\n\\n1. 文字编辑用的 3 种:\\n\\n* K 模式    （Vim 默认: CTRL-X CTRL-K） -- 字典补全，查找字典文件中的匹配单词，组成补全列表\\n* H 模式    （Vim 默认: CTRL-X CTRL-T） -- 分类补全，查找分类文件（thesaurus 文件）中的匹配单词，组成补全列表\\n* S 模式    （Vim 默认: CTRL-X s）        -- 拼写建议\\n\\n2. 自定义模式，通常要写函数的2种:\\n\\n* O 模式    （Vim 默认: CTRL-X CTRL-O） -- 全能补全，由一个自定义函数生成补全列表，又名omni-complete，和filetype绑定，在autoload路径下找{filetype}complete.vim文件并找到其中的补充函数，自带有10多种常见语言的补全实例。\\n* U 模式    （Vim 默认: CTRL-X CTRL-U） -- 自定义补全，也是由自定义函数生成补全列表\\n\\n3. 所有人都喜欢的4种:\\n\\n* n 模式    （Vim 默认: CTRL-N）        -- 关键字补全，查找 \'complete\' 选项指定文件中的匹配单词，组成补全列表\\n* N 模式    （Vim 默认: CTRL-X CTRL-N） -- 关键字补全，查找当前 buffer 里的匹配单词，组成补全列表\\n* 另外两种: p 模式与 P 模式，分别与 n 模式和 N 模式相同，只是补全列表中候选词的排序相反。\\n\\n4. 程序员用的3种:\\n\\n* T 模式    （Vim 默认: CTRL-X CTRL-]） -- tag 补全，查找 tag 中的匹配单词，组成补全列表\\n* I 模式    （Vim 默认: CTRL-X CTRL-I） -- 头文件补全，查找当前 buffer 和 include file 中的匹配单词，组成补全列表\\n* D 模式    （Vim 默认: CTRL-X CTRL-D） -- 定义补全，查找当前 buffer 与 include file 中匹配的名称定义，组成补全列表\\n\\n5. 特殊语境下专用的3种:\\n\\n* V 模式    （Vim 默认: CTRL-X CTRL-V） -- Vim 补全，查找 Vim 的命令名, 函数名等等，组成补全列表\\n* F 模式    （Vim 默认: CTRL-X CTRL-F） -- 文件名补全，查找匹配的路径或文件名，组成补全列表\\n* L 模式    （Vim 默认: CTRL-X CTRL-L） -- 整行补全，查找 \'complete\' 选项指定文件中匹配的整行内容，组成补全列表\\n\\n## 插件解析\\n\\n以easycomplete使用为例，不同的语言定义不同的completor、constructor、gotodefinition、command指令。\\n\\n## 问题\\n\\n遇到奇怪的问题，在vim环境下发现PATH变量和修改的路径一样，但是executable()只认原生的路径，最终仍要把程序移到标准目录才行。"}'));jctx.push(JSON.parse('{"id": "201227", "tag": "lang", "text": "# 实用的shell编程技巧\\n\\n* skill#0: 不可逆操作引用环境变量时用${var:?\\"undefined \'var\'\\"}\\n\\n比如:\\n\\n```\\nrm -fr ${dir}/ # 如果dir未定义, 则删除根目录.\\nrm -fr ${dir:?\\"undefined \'dir\'\\"} # 如果dir未定义, 报错. \\n```\\n\\n* skill#1: 脚本出错即停使用 set -e -o pipefail\\n\\n脚本开头第一句话, 写:\\n\\n```\\n#!/bin/bash\\nset -e -o pipefail\\n```\\n\\n如果出现单行或者单行管道命令出现错误, 脚本会停止执行并且报错.\\n\\n* skill#2: 获取basedir并且发起一个非util命令时使用绝对路径\\n\\n```\\nscript=$(basename ${BASH_SOURCE:-$0})\\nbasedir=$(cd $(readlink -f $(dirname ${BASH_SOURCE:-$0}));pwd)\\n${basedir}/bin/execuable\\n```\\n\\n用绝对路径的好处是用命令ps -C execuable可直接获得可执行程序的绝对路径. 不然的话, 需要查看/proc/${pid}/cwd 确定路径, 比较麻烦. 所以, 能省事就省事.\\n\\n* skill#3: 检查后台进程是否成功启动\\n\\n```\\nset -e -o pipefail\\nsleep 1000 &\\npid=$!\\nkill -0 ${pid} # kill -0 检查进程是否存活\\n```\\n\\n先要获取后台进程的pid, 然后用kill -0检查是否存活.\\n\\n* skill#4: 优雅退出时清理用trap\\n\\n```\\nmkdir /tmp/some.dir\\n\\nfinally(){\\n   local last_status=$? #最后一条命令的执行结果\\n   trap \\"\\" EXIT #避免执行finally嵌套调用死循环\\n   rm -fr /tmp/some.dir #清理工作\\n   exit ${last_status} #真正退出\\n}\\n\\ntrap finally EXIT\\n```\\n\\n用trap给EXIT事件注册一个处理函数finally, 进入finally首先要获取最后一条命令的执行结果, 然后重置EXIT事件的处理函数, 否则可能会发生嵌套调用死循环.注意: normal/abnormal exit都会调用EXIT的处理函数, 此不同于on_exit.\\n\\n* skill#5: 参数传递使用shift\\n\\n```\\nscript=$(basename ${BASH_SOURCE:-$0})\\nusage=\\"FORMAT: ${script} <srcdir> <dstdir>\\"\\nsrcdir=${1:?\\"undefined \'srcdir\', $usage\\"};shift\\ndstdir=${1:?\\"undefined \'dstdir\', $usage\\"};shift\\n```\\n\\n* skill#6: 通配符中含有$((表达式))时使用eval\\n\\n```\\nnum=100\\nfor i in $(eval \\"echo {0..$(($num-1))}\\");do echo $i; done   # 用eval可以构造特别复杂的序列\\n```\\n\\n* skill#7: eval可建立soft reference, 动态修改referenced对象\\n\\n```\\nname=10\\nname_ref=name\\necho $(eval \\"echo \\\\$$name_ref\\")\\n```\\n\\neval类似perl/python的eval, 能够在运行时, 把一段字符串, 当成代码执行, 并且可以读取和修改当前环境中绑定的变量. 具有元编程的能力, 可用于构造比较复杂的代码.\\n\\n* skill#8: 使用perl正则\\n\\nshell不够, perl来凑; perl的sysadmin功能远强于python. 推荐使用perl.\\n\\nperl正则简约统一, onelinar足以替换sed/awk/grep。推荐perl的另外一个原因是, perl提供了非常丰富的括号类型, 便于写脚本。\\n\\nsed/awk/grep的正则, 属于不同的dialect, 需要查看或者记忆三套规则, 容易混淆. 复杂的正则表达式, 拼正确往往需要化费一定时间. 简单场景, 比如搜索一个完整的单词, 用sed/awk/grep无妨, 复杂的正则表示, 建议用perl re.\\n\\nsed和perl的对应关系\\n\\n```\\n# E0表示最后一行\\nsed \'1,$!d\' dat.txt\\nperl -lne \'print if /1..E0/\'\\n\\n# re addr range\\nsed \'/begin/,/end/!d\' dat.txt\\nperl -lne \'print if /begin/../end/\'\\n\\n# substitution\\nsed \'/begin/,/end/s/foobar/Foobar/g\' dat.txt\\nperl -lpe \'s/foobar/Foobar/g if/begin/../end/\' dat.txt\\n\\n# in-place substitution\\n \\nsed -i \'/begin/,/end/s/foobar/Foobar/g\' dat.txt\\nperl -i -lpe \'s/foobar/Foobar/g if/begin/../end/\' dat.txt\\n```\\n\\nawk和perl的对应关系\\n\\n```\\nawk \'{print $1}\' dat.txt\\nperl -aF -lne \'print $F[0]\' dat.txt\\n\\nawk -F: \'{print $1}\' dat.txt\\nperl -aF: -lne \'print $F[0]\' dat.txt\\n\\nperl -aF\'[;,\\\\s]+\'  \'print $F[0]\' dat.txt #用正则/[;,\\\\s]+/分割字符串\\n```\\n\\ngrep和perl的对应关系\\n\\n```\\ngrep word dat.txt\\nperl -lne \'print if /word/\' dat.txt\\n\\ngrep -Rin foobar *\\nfind -type f |xargs -i perl -lne \'print if /foobar/i\' \'{}\'\\n```\\n\\nperl的其他举例\\n\\n提取email地址 `perl -lne \'print $1 if /\\\\b(\\\\S+\\\\@\\\\w+(\\\\.\\\\w+)*)/\' foobar.html`\\n\\n批量修改文件名\\n\\n```\\nfind -type f |perl -lne \'chomp;rename $_=>\\"$_.bak\\"\'\\nfind -name \\"*.bak\\" |perl -lne \'chomp;rename $_=>$1 if /^(.*)\\\\.bak$/\'\\n```\\n\\n批量替换字符串 `find -name \\"*.cpp\\" -type f |xargs -i perl -i.bak -lpe \'s/\\\\b0xdeadbeef\\\\b/0XDEADBEEF/g\' \'{}\' `\\n\\n* skill#9: 获取含特定关键字的java进程pid的数组\\n\\n```\\n# DataNode相关java进程pid存入positional variables\\nset -- $(ps h -C java -o pid,cmd | perl -ne \'print $1 if /^\\\\s+(\\\\d+).*DataNode/\')\\nfor p in $*;do\\n    echo $p\\ndone\\n```\\n\\n用positional variables捕获数组, 使用$* $@ $# $n shift操作数组, 比较方便.虽然declare -a也可定义数组, 但难以记忆, 容易出错.\\n\\n* skill#10: 统计日志中某些词出现的频率\\n\\n```\\n# 假设日志中包含包含\\"2018-10-08 12:00:00.345 [INFO/WARN/FATAL]...\\"信息, 统计INFO, WARN, FATAL的出现次数.\\nperl -lne \'$h{$1}++ if /^\\\\d{4}-\\\\d{2}-\\\\d{2}\\\\s+\\\\d{2}:\\\\d{2}:\\\\d{2}\\\\.\\\\d{3}\\\\s+\\\\[\\\\b(\\\\w+)\\\\b/}{print join \\"\\\\n\\", map{\\"$_:$h{$_}\\"} keys %h\' log\\n```\\n\\n* skill#11: here doc\\n\\n```\\n不允许{backslash\\\\, $variable, $(cmd), $((expr))} interpolation, 边界词DONE用单引号\\n\\ncat <<\'DONE\'\\n....\\nDONE\\n允许{backslash\\\\, $variable, $(cmd), $((expr))} interpolation, 边界词DONE用双引号或者裸词.\\n\\ncat <<\\"DONE\\"\\n....\\nDONE\\n\\ncat <<DONE\\n....\\nDONE\\ntrim每一行前置的空白符用<<-\\n\\ncat <<-DONE\\n  one\\n     two\\n       three\\nDONE\\n```\\n\\n* skill#12: 写函数其实很方便\\n\\nreturn 0/1表示执行成功/失败, 函数用标准输出流返回结果, 使用$()提取返回值.\\n\\n```\\n# 函数 abs_path\\nabs_path(){ #函数名字为abs_path\\n  usage=\\"abs_path <path>\\"\\n  # 参数传递用positional variables\\n  local p=${1:?\\"undefined \'path\': $usage\\"};shift #用local避免污染全局环境变量\\n  if [ -f $p ];then\\n    p=$(cd $(dirname $p);pwd)/$(basename $p)\\n  elif [ -d $p ];then\\n    p=$(cd $p;pwd)\\n  else\\n    # 错误返回1, 输出到标准错误流\\n    echo \\"error: \'$p\' is missing or is not a file/directory\\" >&2\\n    return 1\\n  fi\\n  # 成功返回0, 输出掉标准输出流\\n  echo $p \\n  return 0\\n}\\n\\n# 调用函数abs_path, 返回结果保存在cwd中.\\ncwd=$(abs_path .)\\n过程 add_bridge和del_bridge\\n\\nadd_bridge(){\\n  local usage=\\"add_bridge <bridge-name> <subnet>\\"\\n  local bridge=${1:?\\"undefined <bridge-name>: $usage\\"};shift\\n  local subnet=${1:?\\"undefined <subnet>: $usage\\"};shift\\n\\n  del_bridge $bridge\\n  ip link add $bridge type bridge\\n  ip link set dev $bridge up\\n  return 0\\n}\\n\\ndel_bridge(){\\n  local usage=\\"del_bridge <bridge-name>\\"\\n  local bridge=${1:?\\"undefined <bridge-name>:$usage\\"};shift\\n\\n  if ip link list | grep \\"\\\\<$bridge\\\\>\\" >/dev/null 2>&1;then\\n    ip link set dev $bridge down\\n    ip link delete dev $bridge\\n  fi  \\n  return 0\\n}\\n\\n使用source或者.将函数所在的脚本文件include到主脚本中.\\n\\n# assume that funtions.sh contains all your util funcitons\\nsource funtions.sh\\n. funtions.sh  \\n```\\n\\n* skill#13: 死循环用colon(:)\\n\\n```\\nwhile : ;do\\n  t=$(($RANDOM%10+1));\\n  echo sleep $t secs; \\n  sleep $t;\\ndone\\n```\\n\\n* skill#14: 字符串比较\\n\\n```\\n# 判断字符串是否为空\\n[ -z $s ] #错误\\n[ -z \\"$s\\" ] #正确\\n\\n# 判断字符串是否为不空\\n[ -n $s ] #错误\\n[ -n \\"$s\\" ] #正确\\n\\n# 判断字符串是否相等\\n[ $s = \\"OK\\" ] #错误\\n[ x$sx = \\"xOKx\\" ] #错误\\n[ \\"x${s}x = \\"xOKx\\" ] #正确\\n```\\n\\n* skill#15: 判断字符串是否为合法IP地址\\n\\n```\\nip=\\"192.168.1.1\\"\\nill_formed=$(echo $ip|perl -lne \'print \\"ill-formed\\" unless /^\\\\d{1,3}(\\\\.\\\\d{1,3}){3}$/\'\\nif [ -z \\"${ill_formed}\\" ];then\\n  echo \\"match\\"\\nelse\\n  echo \\"not match\\"\\nfi\\n```\\n\\n* skill#16: 判对一组token是否包含某一个词\\n\\n```\\n#!/bin/bash\\n\\ncontains(){\\n  local usage=\\"Usage: contains <w> <elm0> <elm1> ...\\"\\n  local w=${1:?\\"undefined \'w\', ${usage} \\"};shift\\n  if [ \\"$#\\" -eq 0 ];then \\n    echo \\"Error: missing arguments, ${usage}\\" >&2\\n    return 1\\n  fi  \\n  perl -e \\"@h{qw/$*/}=(1)x$#;print \\\\$h{qq/$w/}\\"\\n  return 0\\n}\\n\\ncontains $*\\n```\\n\\n* skill#17: 如果Shell嵌入Perl无法解决问题, 那么就用Perl嵌入Shell\\n\\n```\\n#!/usr/bin/perl\\nuse strict;\\nuse warnings;\\n...\\nmy stdout=`shell_cmd` or die \\"$!\\"; # backticks enclose shell cmd.\\n...\\nmy stdout=qx(shell_cmd) or die \\"$!\\"; # qx enclose shell cmd\\nskill#18: 打印Linux系统调用的标准errno和errmsg\\n\\nperl -le \'foreach(0..133){$!=$_;print \\"$_:$!\\"}\'\\n```\\n\\n* skill#19: 不用docker在本地搭建分布式系统\\n\\n```\\n# 创建网桥\\nip link add ${bridge} type bridge\\nip link set dev ${bridge} up\\n\\n# 创建一条ethernet网线\\nip link add ${eth} type veth peer name ${br_eth}\\n\\n# 把网线的一头接到网桥上\\nip link set dev ${br_eth} master ${bridge}\\nip link set dev ${br_eth} up\\n\\n# 创建网络命名空间\\nip netns add $netns\\n\\n# 把网线的另外一头接到新创建的网络命名空间上.\\nip link set ${eth} netns ${netns}\\n\\n# 设置命名空间中以太网卡的网络地址\\nip netns exec ${netns} ip link set dev ${eth} name \\"eth0\\"\\nip netns exec ${netns} ifconfig \\"eth0\\" ${ip} netmask 255.255.255.0 up\\nip netns exec $netns ifconfig \\"lo\\" up\\n\\n# 如此往复可以创建多条连接在同一个网桥上的网线, 网线的另外一头处于不同的网络命名空间.\\n\\n# 创建转发规则(Ubuntu 16.04, Manjaro可用)\\niptables -t nat -A POSTROUTING -s ${subnet}.0/24 ! -o ${bridge} -j MASQUERADE\\nsystemctl restart iptables\\n \\n# 用nc或者python -m SimpleHTTPServer测试网络: 略\\n\\n# 启动脚本start.sh, 使用独立的UTS, Mount命名空间.\\nunshare -u -m bash -x ./start.sh \\n\\n# 修改hostname\\nhostname ${hostname}\\n\\n# 挂载目录\\nmount -B ${dir} ${mount_point} # 挂载目录\\n\\n# 启动脚本start_server.sh, 使用独立的网络命名空间.\\n# 测试脚本中启动的服务, 拥有独立的UTS, mount和network命名空间.\\nip netns exec ${netns} ./start_server.sh \\n```\\n\\n* skill#20: 解决ssh远程执行nohup命令hang住问题\\n\\n如果不关闭nohup的标准{输入, 输出, 错误}文件, ssh远程执行nohup命令会hang住.\\n\\nssh localhost \\"nohup python -m http.server 2>&1  &\\" #hang\\n使用 exec fd <&- 关闭文件fd\\n\\nssh localhost \\"exec nohup python -m http.server 2<&- 1<&- 0<&-  &\\"\\nskill#21: 使用xargs逐行处理标准输出\\n\\n如果前一个命令的标准输出为文件列表, 逐个处理文件, 则可以用到xargs命令.\\n\\n比如替换一组文件中的某一个特定的字符串.\\n\\nag -G \'.*\\\\.(cc|cpp|c|C|hh|hpp|h|H)$\' \'stdio\\\\.h\' -l | xargs -i{} perl -i.bak -lpe \'s/stdio.h/cstdio/g\' \'{}\'\\nskill#22: 批量替换文件名\\n\\n当文件名中包含空格或者其他不可打印字符时, 使用perl rename函数, 而非mv.\\n\\n```\\n# 后缀.MD修改为.md\\nag -G \'.*\\\\.md$\' -l |perl -lne \'chomp;rename $_ => \\"$1.md\\" if -f && /(.*)\\\\.md$/\'\\n# 文件名后缀添加.bak\\nag -G \'.*\\\\.md$\' -l |perl -lne \'chomp;rename $_ => \\"$_.bak\\" if -f\'\\n# 去掉文件名后缀back\\nag -G \'.*\\\\.bak$\' -l |perl -lne \'chomp;rename $_=>$1 if /(.*)\\\\.bak$/\'\\n```\\n\\n* skill#23: 匹配除Windows Vista之外的其它Windows版本.\\n\\n```\\nperl -lne \'print if /^Windows\\\\s+(?!Vista)/i\' <<\'DONE\'\\nwindows vista\\nwindows xp\\nwindows 2003\\nwindows 95\\nDONE\\n```\\n\\n* skill#24: 平移copy, 将一个目录中所有文件平移到另外一个目录下.\\n\\n方法1: 使用cpio命令. 用户把 /root/gcc-5.4_prefix中的文件原封不动地平移到/usr下.\\n\\n```\\ncd /root/gcc-5.4_prefix\\nfind -type f |cpio -o > /root/gcc-5.4-bin.cpio\\ncd /usr\\ncpio -id < /root/gcc-5.4-bin.cpio\\n```\\n\\n方法2：分别操作目录和文件\\n\\n```\\ncd /root\\nfind gcc-5.4_prefix -type d |perl -lpe \'s{gcc-5.4_prefix}{/usr}g\'|xargs -i{} mkdir -p \'{}\'\\nfind gcc-5.4_prefix -type f |perl -lne \'$src=$_; s{gcc-5.4_prefix}{/usr}g; qx(cp \\"$src\\" \\"$_\\")\'\\n```\\n\\n* skill#25: bash中逻辑算符||和&&与C语言不同, 不具有优先级\\n\\n```\\n: || echo \\"OK1\\" && echo \\"OK2\\" && echo \\"OK3\\"\\n# 依然会输出 OK2 OK3\\n# 上述语句等价于\\n((: || echo \\"OK1\\") && echo \\"OK2\\" )&& echo \\"OK3\\"\\n\\n# 如果想获得和C一样的语意, 使用\\n: || (echo \\"OK1\\" && echo \\"OK2\\" && echo \\"OK3\\")\\n```\\n\\n* skill#26: 编写交互式工具 - 选择列表\\n\\n```\\nselectOption(){\\n  test $# -gt 0\\n  select opt in $*;do\\n    echo ${opt}\\n    break;\\n  done\\n}\\n\\n$a=$(selectOption \\"foobar\\" \\"bazz\\" \\"deadbeef\\")\\necho $a\\n\\n执行结果:\\n$ opt=$(selectOption \\"foobar\\" \\"bazz\\" \\"deadbeef\\")\\n1) foobar\\n2) bazz\\n3) deadbeef\\n#? 1\\n$ echo $opt\\nfoobar\\n```\\n\\n* skill#27: 编写交互式工具 - 确认yes/no\\n\\n```\\nconfirm(){\\n  echo -n \\"Are your sure[yes/no]: \\"\\n    while : ; do\\n      read input\\n      input=$(perl -e \\"print qq/\\\\L${input}\\\\E/\\")\\n      case ${input} in\\n        y|ye|yes)\\n          break\\n          ;;\\n        n|no)\\n          echo \\"operation is cancelled!!!\\"\\n          exit 0\\n          ;;\\n        *)\\n          echo -n \\"invalid choice, choose again!!! [yes|no]: \\"\\n          ;;\\n      esac\\n    done\\n}\\n```\\n\\n使用input=$(perl -e \\"print qq/\\\\L${input}\\\\E/\\")转小写，然后：\\n\\n输入匹配到yes的前缀, 则继续执行;\\n输入匹配到no的前缀, 则输出\\"operation is cancelled!!!\\", 并且退出脚本;\\n其他输入, 均非法, 继续提示输入.\\n\\n* skill#28: shell opt选项save和restore\\n\\n用在什么场景, 比如我们编写一个函数, 希望在这个函数局部地修改shell opt, 并且函数退出时, 恢复到原来的shell opt. 即函数的执行不影响整个脚本的shell opt.\\n\\n```\\n foobar(){\\n    local oldshopt=$(set +o)\\n    set -e -o pipefail\\n    ...\\n    set +vx;eval \\"${oldshopt}\\"\\n    echo ${result}\\n }\\n```\\n\\n使用set +o保存shell opt, 使用 set +vx; eval \\"${oldopt}\\"恢复老的opt.\\n\\n* skill#29: 通用的checkArgment函数\\n\\n```\\ncheckArgument(){\\n  local name=${1:?\\"missing \'name\'\\"};shift\\n  local arg=${1:?\\"missing \'arg\'\\"};shift\\n  local alternatives=${1:?\\"missing \'alternatives\'\\"};shift\\n\\n  if [ -z ${alternatives} ];then\\n    echo \\"ERROR: empty alternatives for \'${name}\', value=\'${arg}\'\\" >&2\\n    exit 1\\n  fi\\n\\n  if test x$(perl -e \\"print qq/${alternatives}/=~/^\\\\w+(?:\\\\|\\\\w+)*$/\\")x != x1x;then\\n    echo \\"ERROR: alternatives must be in format word1|word2|word3..., name=\'${name}\', value=\'${arg}\', alternatives=\'${alternatives}\\" >&2\\n    exit 2\\n  fi\\n\\n  if test x$(perl -e \\"print qq/$arg/=~/^(?:${alternatives})$/\\")x != x1x; then\\n    echo \\"ERROR: unmatched argument, name=\'${name}\', value=\'${arg}\', alternatives=\'${alternatives}\'\\" >&2\\n    exit 1\\n  fi\\n}\\n\\ncheckArgument \\"service\\" \\"master\\" \\"master|regionserver\\"\\n```\\n\\n* skill#30 date命令操作\\n\\n```\\ndate +\\"%s\\" #输出时间戳, 单位为秒\\ndate +\\"%Y%m%d_%H%M%S\\" #输出20190818_163017\\ndate +\\"%Y%m%d_%H%M%S\\" -d@1566116945 #时间戳1566116945转日期\\nperl -e \'print qx(date +\\"%s\\" -d \\"$1-$2-$3 $4:$5:$6\\") if qq(20190818_162905)=~/^(\\\\d{4})(\\\\d{2})(\\\\d{2})_(\\\\d{2})(\\\\d{2})(\\\\d{2})$/\' #日期转时间戳\\n\\nperl -e \'print time()\' #输出时间戳\\nperl -MPOSIX=strftime -e \'print strftime \\"%Y%m%d_%H%M%S\\", localtime(1566117946)\' #时间戳转日期\\nperl -MPOSIX=strftime -e \'print strftime \\"%Y%m%d_%H%M%S\\", localtime(time())\' #时间戳转日期\\nperl -MTime::Piece -e \'print Time::Piece->strptime(\\"20190818_164546\\", \\"%Y%m%d_%H%M%S\\")->strftime(\\"%s\\")\' #日期转时间戳\\n```\\n\\n* skill#31 彩色输出\\n\\nshell脚本中, 需要用不同的颜色对失败或者成功进行彩色高亮输出, 可以提高运维脚本的好用性.\\n\\n首先给出一个调色板, color_palette.pl.\\n\\n```\\n#!/usr/bin/perl\\nuse strict;\\nuse warnings;\\n\\nmy @fg=(31..37,90..97);\\nmy @bg=(40..47,100..106);\\nmy @ef=(0..8);\\n\\nfor (1..@fg*@bg*@ef) {\\n  my $i=($_-1)/(@bg*@ef);\\n  my $j=($_-1)%(@bg*@ef)/@ef;\\n  my $k=($_-1)%@ef;\\n  my $fg=$fg[$i];\\n  my $bg=$bg[$j];\\n  my $ef=$ef[$k];\\n  print \\"\\\\e[${fg};${bg};${ef}m \\\\\\\\e[${fg};${bg};${ef}m\\\\\\\\e[m\\\\e[m\\";\\n  if ($_%10==0){\\n    print \\"\\\\n\\";\\n  } else{\\n    print \\" \\";\\n  }\\n}\\n用户可以从调色板的输出结果中, 选择自己偏好的颜色.\\n\\n首先, term的颜色怎么编码呢? 使用三元组.\\n\\n前景色;背景上;特效\\n比如：\\"97;105;5\\",表色前景白色, 背景粉色，特效闪烁.\\n然后, 颜色作用的范围有起始标记, 被起始标记包围的文字会被彩色打印.\\n\\n开始标记: <ESC>[dd;dd;dm\\n\\n结束标记: <ESC>[m\\n\\n比如要用“前景白色, 背景粉色，特效闪烁”输出deadbeef, 则使用下列ascii串\\n\\n<ESC>[97;105;5mdeadbeef<ESC>[m\\n问题的关键是, 怎么转移后者输入<ESC>键呢?\\n\\nC语言风格的printf使用\\\\e表示<ESC>, perl语言的print/printf函数, shell的printf, echo -e命令和C保持兼容. 因此在这三种场景下,输出上述彩打foobar, 使用命令\\n\\nprintf \\"\\\\e[97;105;5mdeadbeef\\\\e[m\\" # shell\\nperl -e \'printf \\"\\\\e[97;105;5mdeadbeef\\\\e[m\\"\' # perl one-linar command\\necho -e  \\"\\\\e[97;105;5mdeadbeef\\\\e[m\\" # -e enable escape-char\\nshell的echo命令录入ESC略有不同, 使用<CTRL-V><ESC>按键输入<ESC>键, 终端一般显示为^[, 记住直接输入^[并不管用.\\n\\necho \\"^[[97;105;5mdeadbeef^[[m\\" #使用<CTRL-V><ESC>输入<ESC>\\necho -e  \\"\\\\e[97;105;5mdeadbeef\\\\e[m\\" #使用转义字符.\\n```\\n\\n写一个小脚本(colorprint.sh)使用一下彩打.\\n\\n```\\n#!/bin/bash\\nset -e -o pipefail\\nbasedir=$(cd $(dirname $(readlink -f ${BASH_SOURCE:-$0}));pwd);\\ncd ${basedir}\\narg=${1:?\\"^[[95;41;5mmissing \'arg\'^[[m\\"};shift\\nif [ \\"x${arg}x\\" = \\"xfoobarx\\" ];then\\n   echo -e \\"\\\\e[32;100;1mOK\\\\e[m: arg is foobar\\"\\nelse\\n   echo -e \\"\\\\e[31;100;1mERROR\\\\e[m: arg is not foobar\\"\\nfi\\n```\\n\\n* skill#32: 处理命令行参数\\n\\n使用perl处理命令行参数 下面是使用fio, 从并发度和iosize两个维度持续加压, 测试磁盘性能的脚本.\\n\\n```\\n#!/usr/bin/perl\\n\\nuse strict;\\nuse warnings;\\nuse Getopt::Long;\\n\\nour ($OPT_concurrencyInit, $OPT_concurrencyLinearVarying, $OPT_concurrencyExponentialVarying) = (1, 0, 2);\\nour ($OPT_ioSizeInit, $OPT_ioSizeLinearVarying, $OPT_ioSizeExponentialVarying) = (256, 0, 1);\\nour ($OPT_fileSize, $OPT_directory, $OPT_timeout, $OPT_stopOnSaturation) = (1*2**19, \\"/mnt/nefs/0/fiotest\\", 7200, \\"true\\");\\nour ($OPT_concurrencyMax, $OPT_ioSizeMax) = (500, 64*2**10);\\n\\nsub options(){ map {/^OPT_(\\\\w+)\\\\b$/; (\\"$1=s\\" => eval \\"*${_}{SCALAR}\\") } grep {/^OPT_\\\\w+\\\\b$/} keys %:: }\\n\\nsub usage(){\\n\\tmy $name = qx(basename $0); chomp $name;\\n\\t\\"USAGE:\\\\n\\\\t\\" . \\"$name \\" . join \\" \\", map{/^OPT_(\\\\w+)$/; \\"--$1\\"} grep {/^OPT_\\\\w+\\\\b$/} keys %::;\\n}\\nsub show(){\\n\\tprint join \\"\\\\n\\", map {/^OPT_(\\\\w+)\\\\b$/; (\\"--$1=\\" . eval \\"\\\\$$_\\" ) } grep {/^OPT_\\\\w+\\\\b$/} keys %::;\\n\\tprint \\"\\\\n\\";\\n}\\n\\nGetOptions(options()) or die usage();\\nshow();\\n\\nsub workloadGenerator{\\n\\tmy ($C, $C_lvary, $C_evary, $IO, $IO_lvary, $IO_evary) = @_;\\n\\tsub(){\\n\\t\\tmy ($c, $io) = ($C, $IO);\\n\\t\\t$C += $C_lvary;\\n\\t\\t$C *= $C_evary;\\n\\t\\t$IO += $IO_lvary;\\n\\t\\t$IO *= $IO_evary;\\n\\t\\t($c, $io);\\n\\t}\\n}\\n\\n\\nmy $startup = time();\\nsub since{my $start=shift; time()-$start}\\n\\nmy $WLGen = workloadGenerator(\\n\\t$OPT_concurrencyInit, $OPT_concurrencyLinearVarying, $OPT_concurrencyExponentialVarying,\\n\\t$OPT_ioSizeInit, $OPT_ioSizeLinearVarying, $OPT_ioSizeExponentialVarying,\\n);\\n=pod\\nfor (1..100){\\nmy @a=$WLGen->();\\nprint \\"@a\\\\n\\";\\n}\\n=cut\\n\\nsub normbw{\\n\\tmy ($num, $unit)=split \\",\\", shift;\\n\\tmy %conv=(\\"B\\"=>1, \\"KB\\"=>2**10, \\"MB\\"=>2**20, \\"GB\\"=>2**30);\\n\\t$num*$conv{$unit}/1024;\\n}\\nsub normlat{\\n\\tmy ($num, $unit)=split \\",\\", shift;\\n\\tmy %conv=(\\"usec\\"=>0.001, \\"msec\\"=>1, \\"sec\\"=>1000, \\"min\\"=>60000);\\n\\t$num*$conv{$unit};\\n}\\nqx(echo -n \'\' > result.dat);\\nqx(mkdir -p $OPT_directory);\\nmy $fio_args=\\"--ioengine=psync --sync=1 --direct=1 --group_reporting --unlink=1 --rw=write --directory=$OPT_directory\\";\\nmy $count=0;\\nwhile(1){\\n\\tif (since($startup) > $OPT_timeout) { print \\"timeout:\\\\n\\"; exit 0; }\\n\\tmy ($concurrency, $ioSize) = $WLGen->();\\n\\tif ($concurrency > $OPT_concurrencyMax || $ioSize > $OPT_ioSizeMax) { \\n\\t\\tprint \\"concurrency=$concurrency;ioSize=$ioSize\\\\n\\";\\n\\t\\texit 0;\\n\\t}\\n\\n\\tprint qq(fio $fio_args --numjobs=$concurrency --name=bs${ioSize}K --bs=${ioSize}K --size=${OPT_fileSize}K > stdout),\\"\\\\n\\";\\n\\tqx(fio $fio_args --numjobs=$concurrency --name=bs${ioSize}K --bs=${ioSize}K --size=${OPT_fileSize}K > stdout);\\n\\tdie $! if $?;\\n\\tqx(mv stdout stdout.${count});\\n\\n\\tmy $curr=\\"stdout.\\" . (${count}-0);\\n\\tmy $curr_bw_unit = qx(perl -ne \'print \\"\\\\$1,\\\\$2\\" if/^\\\\\\\\s+write:.*bw=\\\\\\\\b(\\\\\\\\d+(?:\\\\\\\\.\\\\\\\\d+)?)\\\\\\\\s*(\\\\\\\\w+)\\\\\\\\b/\' $curr);chomp $curr_bw_unit;\\n\\tmy $curr_bw=normbw($curr_bw_unit);\\n\\tmy $curr_iops = qx(perl -ne \'print \\"\\\\$1\\" if/^\\\\\\\\s+write:.*iops=\\\\\\\\b(\\\\\\\\d+)\\\\\\\\b/\' $curr);chomp $curr_iops;\\n\\tmy $curr_lat_unit= qx(perl -ne \'print \\"\\\\$2,\\\\$1\\" if/^\\\\\\\\s+lat\\\\\\\\s*\\\\\\\\((\\\\\\\\w+)\\\\\\\\).*avg=\\\\\\\\b(\\\\\\\\d+(\\\\\\\\.\\\\\\\\d+)?)\\\\\\\\b/\' $curr);chomp $curr_lat_unit;\\n\\tmy $curr_lat=normlat($curr_lat_unit);\\n\\tqx(echo \\"$concurrency\\\\t$ioSize\\\\t$curr_bw\\\\t$curr_iops\\\\t$curr_lat\\" >> result.dat);\\n\\tif ($OPT_stopOnSaturation eq \\"true\\" && $count > 0) {\\n\\t\\tmy $prev=\\"stdout.\\" . (${count}-1);\\n\\t\\tmy $prev_bw_unit = qx(perl -ne \'print \\"\\\\$1,\\\\$2\\" if/^\\\\\\\\s+write:.*bw=\\\\\\\\b(\\\\\\\\d+(?:\\\\\\\\.\\\\\\\\d+)?)\\\\\\\\s*(\\\\\\\\w+)\\\\\\\\b/\' $prev);chomp $prev_bw_unit;\\n\\t\\tmy $prev_bw=normbw($prev_bw_unit);\\n\\t\\tmy $prev_iops = qx(perl -ne \'print \\"\\\\$1\\" if/^\\\\\\\\s+write:.*iops=\\\\\\\\b(\\\\\\\\d+)\\\\\\\\b/\' $prev);chomp $prev_iops;\\n\\t\\tmy $prev_lat_unit= qx(perl -ne \'print \\"\\\\$2,\\\\$1\\" if/^\\\\\\\\s+lat\\\\\\\\s*\\\\\\\\((\\\\\\\\w+)\\\\\\\\).*avg=\\\\\\\\b(\\\\\\\\d+(\\\\\\\\.\\\\\\\\d+)?)\\\\\\\\b/\' $prev);chomp $prev_lat_unit;\\n\\t\\tmy $prev_lat = normlat($prev_lat_unit);\\n\\n\\t\\tmy $delta=abs(($curr_bw - $prev_bw)/$curr_bw);\\n\\t\\tif ($delta < 0.0005) {\\n\\t\\t\\tprint \\"curr_bw=$curr_bw; prev_bw=$prev_bw; delta=$delta\\\\n\\";\\n\\t\\t\\texit 0;\\n\\t\\t}\\n\\t}\\n\\t$count++;\\n}\\n```\\n\\n* skill#33: 删除日志目录中的文件, 只保留近期3个文件\\n\\n下面脚本是安全的，不会出现误删/或者～, 也不会出现多删除.\\n\\n```\\n#!/bin/bash\\nset -e -o pipefail\\nbasedir=$(cd $(dirname $(readlink -f ${BASH_SOURCE:-$0}));pwd)\\n\\ndir=${1:?\\"undefined \'dir\'\\"};shift\\ntest -d ${dir}\\ndir=$(cd ${dir};pwd)\\ntest ${dir} != \\"/\\"\\ntest ${dir} != \\"${HOME}\\"\\n\\ncd ${basedir}\\n\\necho \\"clean ${dir} ...\\"\\nfilenum=$(ls -rt ${dir}|wc -l)\\necho \\"${dir} has ${filenum} file(s)\\"\\nif [ ${filenum} -le 3 ];then\\n  exit 0\\nfi\\n\\nfor f in $(ls -rt ${dir}|head -n -3);do\\n  if [ ! -f ${dir}/${f} ];then\\n    echo ${dir}/${f} is not a file >&2\\n    continue\\n  fi\\n  echo rm ${dir:?\\"undefined \'dir\'\\"}/${f:?\\"undefined \'f\'\\"}\\n  rm ${dir:?\\"undefined \'dir\'\\"}/${f:?\\"undefined \'f\'\\"}\\ndone\\n```\\n\\n* skill#34: shell编程参考书推荐\\n\\n只推荐UNIX Shells by Example (4th Edition)，推荐理由：\\n\\n包括Unix/Linux系统启动后的初始化阶段的内容.\\n包括了bash, sh, ksh, tcsh四种shell方言.\\n讲解了shell中的pipe，redirection, fork, exec，dup的机制，可以结合APUE学习系统编程.\\n专门分章节讲解了sed/awk/grep的各种变种.\\n内容组织合理, 先给出了各种shell方言的不同，然后详细讲解了各种shell的细节\\n"}'));jctx.push(JSON.parse('{"id": "210106", "tag": "os", "text": "# 多核CPU之间的异同\\n\\nPower是标准的SMP架构，而X86则是NUMA。由于SMP访问内存速度一致，因此Power可以轻松上16socket，而NUMA对内存区别对待，访问别的核内存要通过QPI总线，所以很难上4socket。\\n\\nPower的每核线程数能到8甚至16，但X86只有2线程，还被大肆商业鼓吹。好在X86的单socket核数并不差，还略高一些。\\n\\nPower在负载很高甚至99%的情况下能持续运行几周甚至月（也许和CPU架构未必强相关），而X86就容易不稳定。尽管如此X86通过价格低廉，辅以外围集群技术的弥补，仍然成为主流。\\n\\n## 差异说明\\n\\nNUMA出现得晚（20世纪90年代），解除了SMP内存的bandwith限制，但需要软件优化。\\n\\n因为是对内存访问的差异，所以到底是NUMA好还是UMA好，是要看具体应用的。如果应用本身是每个CPU（或者CPU内部的单个核心）长时间持续运行一个线程，那么NUMA把这个线程用到的数据尽可能放到这个CPU的本地内存中当然会更有性能优势。如果是把大量的数据加载到内存中，根据外部请求创建不同的线程随机访问内存中的一部分数据，短时间的处理后线程结束，则是UMA的平均延迟会更低。一般来说，前者通常是一些运算量很大的应用；后者通常是各种服务器（例如网站、数据库等）。这也是为什么Linux内核允许配置为NUMA或者UMA两种模式，多路系统的BIOS通常允许配置为NUMA模式或者UMA模式的原因。\\n\\n从另一方面来说，现代的多核CPU，内部都有独立的1级缓存和2级缓存，也可以认为本质就是NUMA架构。但如果扩展到所有内核都有独立的内存控制器，则会导致成本过于高昂；此外也无法通过内存交错技术提升内存带宽。"}'));jctx.push(JSON.parse('{"id": "210120", "tag": "net", "text": "# 网络代理概念与区别\\n\\n## 模式\\n\\n* 全局模式 所有连接全从指定的端口转发出去，简单却不灵活\\n* PAC模式，全称代理自动配置，由网景公司在1996年在2.0版本的navigator上开发，是一段JS脚本。根据目的端地址选择不同的出口。在火狐浏览器上与全局模式是二选一关系，谷歌可以装插件单独设置PAC，但应该也是屏蔽全局模式\\n\\n## 类型\\n\\n* 正向代理: 比如内网通过网关访问互联网，在客户端侧显式设置\\n* 反向代理: 在集群最外侧做负载均衡，在服务端侧显式设置\\n\\n往往公司的正向代理会做行为管理，客户端感知不到它的存在。有几种模式，透明代理/匿名代理和中间人模式。透明代理是做包转发，而中间人模式取自中间人攻击，代理会和客户端先建立https连接，再由代理和目的端建立连接，没有隐秘性。\\n\\n## 代理协议\\n\\n连接到代理服务器也需要指定协议\\n\\n* http 对代理转发端来说最方便，但隐蔽性不够，即使用https也会因为代理多出一条CONNECT从而暴露目的，多用于企业或学校内网\\n* socks 专为代理设计的协议，定义足够简洁且历史悠久，支持的软件也很多\\n* shadow_sock 为解决socks加密和隐蔽性不够而开发的新协议，有变体，应用较多\\n* 各类VPN 这个工作在IP层，比以上的传输层代理更通用\\n\\n## socks应用\\n\\nsocks协议非常简单，有4，4a，5共3个版本。socks4只支持TCP，版本5增加了UDP，也成了当今代理界的事实标准。ssh的-D隧道就是在客户端启动的socks5代理。\\n\\n整个流程包含认证和确定目标两个阶段，最简单不作认证的情况下，两次交互以后的数据就是纯转发了。因为协议是明文且特征明显，很容易被识别出真正的目的地址，要用socks5穿墙是不可能的，往往是用在本地程序和本地加密代理间。\\n\\nshadowsocks的本地端就以socks5方式接受数据，之后把数据混淆后转给ss服务器，回复的数据最终以socks5方式给到应用程序。\\n\\nIE浏览器支持socks代理，但似乎只支持4，但要注意不能填http/ftp，只能填写socket那栏，socks代理才能生效。但是4不能承载dns协议，如果目的端是域名而不是IP，代理无法生效，此时用代理插件而不是系统代理就能解决。\\n\\n## 实现一个最简单的HTTP代理\\n\\n最简单的代理，得到HTML的主体内容并回复给请求者，以PHP为例，最简单的做法是用curl取得数据。要注意的是对于HTTPS，要关闭验证否则会得不到数据。另一种做法是用`file_get_contents`，在某些环境要配置签发CA的根证书，没有无法获取，且只能得到HTTP的body，header描述信息会丢失。\\n\\n不管是curl和file函数，获取到的网页主体HTML内容是一致的。但网页的复杂性在于HTML还包含了CSS和JS代码，需要额外下载。如果是绝对地址可能到不可达；相对地址在展开时，浏览器看到的是代理地址，所以会补全成代理的地址，这时显然就不能获取到资源文件了。所以代理的难点，就在于尽可能穷举各种URL的形式，并替换成指向源端的地址。"}'));jctx.push(JSON.parse('{"id": "210129", "tag": "os", "text": "# mount和文件路径改写\\n\\nmount的参数很多，关键概念就是将device挂到mountpoint。其它的参数是因为device必然涉及很多控制选项。\\n\\n有两个重要的关联文件\\n\\n* /etc/fstab 启动时要挂载哪些设备，用UUID标记部分磁盘分区，记录物理分区，注意整块盘没有UUID。使用systemd系统时，systemd接管了挂载/etc/fstab的任务。在系统启动的时候，systemd会读取/etc/fstab文件并通过systemd-fstab-generator工具将该文件转换为systemd unit来执行\\n* /etc/mtab 内核已挂载的文件系统，像proc、sys这类特殊的文件系统都会记录\\n\\n## proc下的3个mount文件解析\\n\\nmountinfo\\n\\n* mount ID\\n* 父mountID\\n* device主编号:子编号\\n* mount源路径\\n* mount目的路径\\n* mount属性，如ro/rw\\n* mount点share subtree的flag：shared:23，共享组ID；slave:24，master的组ID，直近の共有を継承しているシステムのマウントID；unbindable:不能被bind\\n* 文件系统名称\\n* 设备名（取决于`show_devname()`内容，否则和文件系统一样）\\n* 超级块的属性，比如ro/rw\\n* 超级块的选项（文件系统所属的`show_options()`内容）\\n\\nmounts\\n\\n* 设备名（取决于`show_devname()`）\\n* mount目的路径\\n* 文件系统名\\n* mount属性，如ro/rw\\n* 超级块option，我所见都是0\\n* mount options，我所见都是0\\n\\nmountstats\\n\\n* 内容较少，且条目数和mounts一样，不再介绍\\n\\n## proot\\n\\n沿着文件路径改写再往前想，如果把整个发行版的内容挂载到某个目录，并以此目录为根，我们就在一个系统内有了另一个子发行版。限制根目录访问是chroot系统调用，需要root权限，于是又产生了proot这个不需要特殊权限的应用程序。\\n\\n虽然都带root字样，但两者差别极大。chroot是系统函数，而proot则是基于ptrace接口的应用程序，p猜测是pseudo的简写。proot对fork的子进程做了ptrace挂钩，当子进程读写文件时，由父进程转成对/proc/pid/fd的读写，实现了子进程内对文件路径的改写。"}'));jctx.push(JSON.parse('{"id": "210202", "tag": "net", "text": "# 防火墙与iptables\\n\\n至少要两块网卡分别控制流进和流出，才能实现完整的防火功能，即使是纯软防火墙也要两张卡。\\n\\nLinux中起防火墙作用的是Netfilter，而iptables是管理控制netfilter的工具，可以使用它进行相关规则的制定以及其他的动作。iptables是用户层的程序，netfilter是内核空间的。\\n\\niptables有两个版本，legacy依赖getsockopt/set内核接口，功能上相对受限，新版本改为依赖`nf_tables`接口。从名字就能看出是对table的操作，每种table有不同类型的内置chain，每个chain又有条数不等的rule。\\n\\ntable有以下5种\\n\\n* filter 默认table，3种内置chain(INPUT/FORWARD/OUTPUT)\\n* nat 4种内置chain(PREROUTING/INPUT/OUTPUT/POSTROUTING)\\n* mangle 下面这3个没看到有效信息，先跳过\\n* raw \\n* security\\n\\n## 命令解释\\n\\niptables的命令，就是选哪个table(-t)，对链做哪些操作(-I/-R/-A/-D/-S)，最后的参数是rule。看例子 iptables -I FORWARD -o br0 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT\\n\\n首先没有-t表示默认filter，-I表示向FORWARD这条转发链添加动作，具体的rule包括转发目标接口br0，-m和-j是rule-specification，连起来表示转发到br0的包，只要匹配到连接跟踪时，则接受，复用该连接回到连接发起的地方。\\n\\n-j有3种特殊的jump动作: SNAT, DNAT, MASQUERADE\\n\\n### iptables-save\\n\\n把所有table打印出来，有:和-A两种链\\n\\n1. :INPUT ACCEPT [3:180]，:KUBE-SERVICES。表示chain名，有内置5种和用户自定义\\n2. -A OUTPUT或-A KUBE-SERVICES，后面跟具体的-d -j选项表示动作"}'));jctx.push(JSON.parse('{"id": "210205", "tag": "os", "text": "# Linux的权限与sudo辨析\\n\\n## 组\\n\\nid命令显示gid和groups输出，原因是每个用户只有一个初始组，但会加入多个组。当只有一个组时，这两个输出相同，加入多组就能看到区别。\\n\\n组也有密码，但很少用，实际中多用sudo来完成权限管控。\\n\\n## 权限\\n\\nlinux的权限管控主要体现在两方面：\\n\\n1、文件权限 2、进程权限\\n\\n文件权限包括五种：\\n\\n* r：可读取文件内容或目录结构\\n* w：可修改文件的内容或目录的结构（但不包括删除）\\n* x：文件可被系统执行或目录可被作文工作目录\\n* s：文件在执行阶段具有文件所有者的权限\\n* t：使一个目录既能够让任何用户写入文档，又不让用户删除这个目录下他人的文档\\n\\n一个文件拥有三组权限，所有者权限、所属组权限、其他人权限\\n\\n进程权限\\n\\n进程就是用户访问计算机资源的代理，用户执行的操作其实是带有用户身份信息的进程执行的操作。这里介绍两个最重要的进程权限id\\n\\nreaal user id(ruid)：执行进程者的 user id，一般情况下就是用户登录时的 user id effective user id(euid)：决定进程是否对某个文件有操作权限，默认为ruid\\n在文件权限和进程权限id里，s文件权限和euid权限id是sudo实现提升权限的根本。一个进程是否能操作某个文件，取决于进程的euid是否拥有这个文件的相应权限，而不是ruid。也就是说，如果想要让进程获得某个用户的权限，只要把进程的euid设置为该用户id就可以了。在具体一点，我们想要让进程拥有root用户的权限，我只要想办法把进程的euid设置成root的id：0就可以了。\\n\\nLinux提供了一个seteuid的函数，可以更改进程的euid。函数声明在头文件里。\\n\\nint seteuid(uid_t euid);\\n但是，如果一个进程本身没有root权限，也就是说euid不是0，是无法通过调用seteuid将进程的权限提升的，调用seteuid会出现错误。 那该怎么把进程的euid该为root的id：0呢？那就是通过s权限。\\n\\n如果一个文件拥有x权限，表示这个文件可以被执行。shell执行命令或程序的时候，先fork一个进程，再通过exec函数族执行这个命令或程序，这样的话，执行这个文件的进程的ruid和euid就是当前登入shell的用户id。\\n\\n当这个文件拥有x权限和s权限时，在shell进行fork后调动exec函数族执行这个文件的时候，这个进程的euid将被系统更改为这个文件的拥有者id。\\n\\n比如，一个文件的拥有者为user_1，权限为rwsr-xr-x，那么你用user_2的文件执行他的时候，执行这个文件的进程的ruid为user_2的id，euid为user_1的id。\\n\\n创建一个main.c文件，并写入如下代码：\\n\\n```\\n#include <stdio.h>\\n#include <unistd.h>\\n\\nint main(int argc, char* argv[])\\n{\\n        printf(\\"ruid: %d\\\\n\\",getuid());\\n        printf(\\"euid: %d\\\\n\\",geteuid());\\n        return 0;\\n}\\n```\\n\\n运行结果如下：\\n\\n```\\nruid: 1000\\neuid: 1000\\n```\\n\\n通过chmod和chown为文件更改拥有者和添加s权限\\n\\n```\\nsudo chown root ./main\\nsudo chmod +s ./main\\nruid: 1000\\neuid: 0\\n```\\n\\n此时由于文件的s权限，euid已经变为了root的id：0\\n\\n将代码修改如下：\\n\\n```\\n#include <stdio.h>\\n#include <unistd.h>\\n\\nint maind(int argc, char* argv[])\\n{\\n    printf(\\"ruid: %d\\\\n\\",getuid());\\n    printf(\\"euid: %d\\\\n\\",geteuid());\\n\\n    if(execvp(argv[1], argv+1) == -1){\\n        perror(\\"execvp error\\");\\n    };\\n    return 0;\\n}\\n```\\n\\n编译后执行\\n\\n```\\nsudo chown root ./main\\nsudo chmod +s ./main\\n./main apt update\\n```\\n\\n可以看到，已经成功运行apt并进行了软件列表的更新。查看sudo的权限，就是一个拥有者为root且拥有s权限的可执行文件。\\n\\n-rwsr-xr-x 1 root root\\n\\n实际的sudo实现要比这复杂的很多，比如检查配置文件，来决定哪些用户可以使用sudo，为了安全考虑sudo还要求验证ruid的用户密码等。\\n\\n## 记录用户登陆行为有3个文件\\n\\n* utmp: /var/run/utmp，记录当前正在登录系统的用户信息，默认由who和w记录当前登录用户的信息，uptime记录系统启动时间。u表示up\\n* wtmp: /var/log/wtmp，记录当前正在登录和历史登录系统的用户信息，默认由last命令查看。w表示when\\n* btmp: /var/log/btmp，记录失败的登录尝试信息，默认由lastb命令查看。b表示bad\\n\\n这3个命令据考证在1971年的Unix v1版本就出现了，当时文件记录在/tmp目录，所以这个有些随意的名字就一直沿用至今。文件是二进制格式，3个文件遵循相同的记录格式，解析参考/usr/include/utmp.h文件。\\n\\n## 文件隐藏权限\\n\\nOperation not permitted，用lsattr查到有i权限，用chattr去掉后通过。也可能文件本身没有问题，但归属的目录有问题，用lsattr -a查看目录并操作。\\n\\n文件属于e2fsprogs包。"}'));jctx.push(JSON.parse('{"id": "210211", "tag": "os", "text": "# 线程模型与调度\\n\\n共有3种线程模型，以x:y命名，即x个用户线程对应y个内核调度实体(Kernel Scheduling Entity，这个是内核分配CPU的对象单位)。\\n\\n1. 多对一(M:1)的用户级线程模型。似乎没有实现，缺点在于：多线程并发执行，如果一个线程执行阻塞的IO操作，内核接管这个操作，用户态的其他线程都会被阻塞，因为这些线程都对应同一个内核调度实体。这时内核不知道用户态有多线程，无法把它们调度到其他处理器，也无法通过优先级来调度。这种模型只在单核处理器上有一定意义。\\n2. 一对一(1:1)的内核级线程模型。典型的是POSIX的pthread，每个用户线程都对应各自的内核调度实体。由内核来调度的结果就是：线程的每次操作会在用户态和内核态切换，影响速度。另外如果出现大量线程，会在内核分配同等数量的线程调度实体，影响系统性能。\\n3. 多对多(M:N)的两级线程模型。典型的是golang的协程调度，结合了1：1和M：1的优点，每个线程可以拥有多个调度实体，也可以多个线程对应一个调度实体。但这种模型的线程调度，必须由内核态和用户态一起来实现，典型如go语言在1.2版本后内嵌支持了（1.1时代是1：1模型）。因为当多个对象操作一个资源时，肯定要有同步机制，用户态和内核态的分工合作导致实现该模型非常复杂。Linux的第二代模型NGPT用了多对多模型，但性能上仍输给了使用一对一模型的第三代NPTL。（其实NPTL曾经也想使用M:N，但因为太复杂，且要对内核进行大范围改动，最终还是用了一对一）。\\n\\n## golang调度\\n\\nGo的调度器内部有三个重要的结构：M，P，G\\n\\n* M是对内核级线程的封装，数量对应真实的CPU数，一个M就是一个线程，goroutine就是跑在M之上的；M是一个很大的结构，里面维护小对象内存cache（mcache）、当前执行的goroutine、随机数发生器等等非常多的信息\\n* P全称是Processor，它处理的是协程与队列，用于执行goroutine的。每个Processor对象都拥有一个LRQ（Local Run Queue），未分配的Goroutine对象保存在GRQ（Global Run Queue ）中，等待分配给某一个P的LRQ中，每个LRQ里面包含若干个用户创建的Goroutine对象。\\n* G代表一个goroutine，它有自己的栈，instruction pointer和其他信息（正在等待的channel等等），用于调度。\\n\\nGolang采用M:N线程模型，对系统线程（内核级线程）进行了封装，暴露了一个轻量级的协程goroutine（用户级线程）供用户使用，而用户级线程到内核级线程的调度由golang的runtime负责，调度逻辑对外透明。goroutine的优势在于上下文切换在完全用户态进行，无需像线程一样频繁在用户态与内核态之间切换，节约了资源消耗。\\n\\n这张图是正在运行中的状态，有2个物理线程M，每一个M被一个处理器P管理，每一个P也都有一个正在运行的goroutine（蓝色），灰色的那些goroutine并没有运行，而是处于等待被调度的ready就绪态。P维护着这个队列（称之为runqueue）。\\n\\n![go-runtime-state](img/gorun1.jpg)\\n\\nP的数量可以通过GOMAXPROCS()来设置，它其实也就代表了真正的并发度，即有多少个goroutine可以同时运行。Go语言里，启动一个goroutine很容易：go function 就行，所以每有一个go语句被执行，runqueue队列就在其末尾加入一个goroutine，在下一个调度点，就从runqueue中取出一个goroutine执行。\\n\\n当一个OS线程M0陷入阻塞时（如下图)，P转而在运行M1，图中的M1可能是正被创建，或者从线程缓存中取出。\\n\\n![go-runtime-block](img/gorun2.jpg)\\n\\n当MO返回时，它必须尝试取得一个P来运行goroutine，一般情况下，它会从其他的OS线程那里拿一个P过来，如果没有拿到的话，它就把goroutine放在一个global runqueue里，然后自己睡眠（放入线程缓存里）。所有的P也会周期性的检查global runqueue并运行其中的goroutine，否则global runqueue上的goroutine永远无法执行。\\n\\n另一种情况是P所分配的任务G很快就执行完了（分配不均），这就导致了这个处理器P很闲，但是其他的P还有任务，此时如果global runqueue没有任务G了，那么P不得不从其他的P里拿一些G来执行。一般来说，如果P从其他的P那里拿任务的话，会拿run queue的一半，这就确保了每个OS线程都能充分的使用，如下图：\\n\\n![go-runtime-schedule](img/gorun3.jpg)\\n\\n## MPG相关QA\\n\\n1. M和P的数量如何确定？何时会创建M和P？\\n\\n    a) P的数量由启动时环境变量$GOMAXPROCS或者是由runtime的方法GOMAXPROCS()决定（默认是1）。这意味着在程序执行的任意时刻都只有$GOMAXPROCS个goroutine在同时运行。\\n\\n    b) M的数量受go语言本身的限制，go程序启动时，会设置M的最大数量，默认10000.但是内核很难支持这么多的线程数，所以这个限制可以忽略。\\nruntime/debug中的SetMaxThreads函数，设置M的最大数量。一个M阻塞了，会创建新的M。\\n\\n    c) M与P的数量没有绝对关系，一个M阻塞，P就会去创建或者切换另一个M，所以，即使P的默认数量是1，也有可能会创建很多个M出来。\\n\\n    d) P何时创建：在确定了P的最大数量n后，运行时系统会根据这个数量创建n个P。\\n\\n    e) M何时创建：没有足够的M来关联P并运行其中的可运行的G。比如所有的M此时都阻塞住了，而P中还有很多就绪任务，就会去寻找空闲的M，而没有空闲的，就会去创建新的M。\\n\\n2. M选择哪一个P关联？什么时候会切换P与M的关联关系？\\n\\n    M会关联到创建了这个M的那个P。当M因系统调用而阻塞时（M上运行的G进入了系统调用的时候），M与P会分开，如果此时P的就绪队列中还有任务，P就会去关联一个空闲的M，或者创建一个M进行关联。（也就是说go不是像libtask一样处理IO阻塞的？不确定。）\\n\\n3. 就绪的G如何选择进入哪个P的就绪队列？\\n\\n    默认情况下：P的数量是1（M不一定是1），所以如果我们不改变GOMAXPROCS，无论我们在程序中用go语句创建多少个goroutine，它们都只会被塞入同一个P的就绪队列中。\\n\\n    有多个P的情况下：如果修改了GOMAXPROCS或者调用了runtime.GOMAXPROCS，运行时系统会把所有的G均匀的分布在各个P的就绪队列中。\\n\\n4. 如何保证每个P的就绪队列中都会有G\\n\\n    如果一个P的就绪队列所有任务都执行完了，那么P会尝试从其他P的就绪队列中取出一部分到自己的就绪队列中，保证每个P都有任务可以执行。\\n\\n## Erlang的调度\\n\\nBEAM的调度模式在2006从单线程切换到多线程（最早在1998年由一个硕士着手研究），有点类似go的MG模型，没有P。相比go的原生调度，由于BEAM是虚拟机形态，调度灵活程度更高。\\n\\n在BEAM中，除了process之外，还有3种调度单位：端口（ports）、链入式驱动（linkd-in drivers）和系统级活动（system level activities）。这三种特殊的任务形式主要用来进行IO操作和执行其他语言的代码等功能。\\n\\n## Go和Erlang的比较\\n\\ngo是协作式调度，除非进入内核阻塞态，协程一直运行，这和它native的实现有一定关系。而erlang是轮转调度，分了4个优先级，基于VM机制可以抢占。"}'));jctx.push(JSON.parse('{"id": "210216", "tag": "data", "text": "# hadoop体系理解\\n\\nhdfs师从gfs的设计理念，也是面向大数据量、高吞吐的场景设计，因此单个文件默认设置为64M。而过多的小文件也会给元数据管理带来极大的负担，甚至导致OOM。\\n\\nhadoop除了存储还包含了调度，在容器环境从上向下分了若干层\\n\\n* DataNode: 同时还执行NodeManager进程\\n* ResourceManager: 对应yarn，管理service和node两个维度。node看到datanode上的节点内存和vCore数量。\\n* NameNode: 存储了hdfs所有的元数据，hdfs命令也在这一层执行，同时hdfs还是很多daemon的执行入口。1.0时代存在单点问题，2.0支持主备模式，仅主节点提供读写，主备切换控制的ZKFailOver也运行在这里\\n* JournalNode: 为了支撑NameNode的主备切换，需要有共享存储层，业界不同厂商提出了多套方案，最后Cloudera的QJM方案被合入trunk，就是JN层。使用EditLog机制，用2N+1个副本保存数据，允许N个节点失效。当NameNode发生主备切换时，备机要从JN上同步完数据后才能工作\\n\\n## 配置文件\\n\\n分为core、hdfs、mapred、yarn四个核心xml配置，start-dfs和start-yarn命令可以启动服务。\\n\\n## hdfs元数据管理\\n\\nNamenode主要维护两个元数据文件\\n\\n* fsimage: 保存了最新的元数据检查点，包含了整个HDFS文件系统的所有目录和文件的信息。对于文件来说包括了数据块描述信息、修改时间、访问时间等；对于目录来说包括修改时间、访问权限控制信息(目录所属用户，所在组)等。简单的说，Fsimage就是在某一时刻，整个hdfs 的快照，就是这个时刻hdfs上所有的文件块和目录，分别的状态，位于哪些个datanode，各自的权限，各自的副本个数等。注意：Block的位置信息不会保存到fsimage，Block保存在哪个DataNode（由DataNode启动时上报）。\\n* editlog: 主要是在NameNode已经启动情况下对HDFS进行的各种更新操作进行记录，HDFS客户端执行所有的写操作都会被记录到editlog中。\\n\\n写入元数据： 在NameNode运行时会将内存中的元数据信息存储到所指定的文件，即${dfs.name.dir}/current目录下的fsimage文件，此外还会将另外一部分对NameNode更改的日志信息存储到${dfs.name.dir}/current目录下的edits文件中。fsimage文件和edits文件可以确定NameNode节点当前的状态，这样在NameNode节点由于突发原因崩溃时，可以根据这两个文件中的内容恢复到节点崩溃前的状态，所以对NameNode节点中内存元数据的每次修改都必须保存下来。如果每次都保存到fsimage，效率就特别低效，所以引入编辑日志edits，保存对元数据的修改信息，也就是fsimage文件保存NameNode节点中某一时刻内存中的元数据（即目录树），edits保存这一时刻之后的对元数据的更改信息。\\n\\n读取元数据： 启动NameNode节点时，从镜像和编辑日志中读取元数据。\\n\\n因此fsimage和editlog是互相配合，这又引申出另一个进程SecondaryNameNode，主要有两个作用，一是镜像备份（不是NN的备份，但可以做备份），二是日志与镜像的定期合并。\\n\\n## Yarn\\n\\n前身是1.x时代的JobTrack和TaskTrack，其中JobTrack是单点而且既管资源也管任务调度，职责过多，所以演化出了二代目Yarn，不仅做了水平拓展，还对功能做了拆解，Yarn最核心的组件是ResourceManager和NodeManager，通过yarn rmadmin -getAllService看到rm1和rm2两个节点的active/standby状态，因此不会有单点故障。\\n\\n任务提交流程\\n\\n1. 客户端向ResourceManager提交任务请求，如果条件具备，则返回一个JobID和临时的hdfs路径，状态NEW或NEW_SAVING\\n2. 客户端向hdfs路径上放好运行所需的资源，进行job正式提交，状态SUBMIT\\n3. RM将job请求转交给调度器，调度器确认客户端有队列权限且资源足够分配AppMaster，状态ACCEPT\\n4. ResourceManager在NodeManager中找一个物理节点，启动AppMaster（如spark的driver和flink的jobManager），状态RUNNING\\n5. AppMaster继续向RM申请资源，确保NM上可以创建任务；然后找NodeManager创建Container，并执行子节点任务\\n\\n注意第4步状态虽然是RUNNING，但只有AM在运行，分布式任务往往要启动更多子节点，但从YARN的角度无法知道子节点是否在运行，也因此会限制AM占用资源的上限，否则会出现AM互相等待而任务永远无法启动的窘境。\\n\\n因为都基于yarn执行任务的流程框架，所以spark和flink的运行过程是非常相似的。\\n\\n## Hive的数据分区\\n\\n对关系型数据库而言，随着数量的扩大，计算会越来越困难，这时将数据按一定规则拆分，减少每块的大小，从而提升速度。分区将数据切分，每个分区都是全部数据的一部分，整体构成全部数据。\\n\\n对hive而言，由于不能update，所以只能每次全量更新，这就导致离线计算特性，每天全量计算一遍数据，因此hive的分区是update的一种替代，更类似时序的概念，不同的分区对应hdfs不同的目录，只表示新旧，不会将数据切分，每个分区都是全量。"}'));jctx.push(JSON.parse('{"id": "210322", "tag": "data", "text": "# 对公有云上数仓的调研\\n\\nSnowflake的数仓产品在架构上分为三级，从下到上的功能分别是（以Amazon为例，这块有论文相对详细，MG两家没什么资料）\\n\\n1. DataStorage：基于Amazon S3，存储数仓数据。选型时在S3和自建HDFS间有过权衡，最终还是选择了S3，从经济上更合算，且关注点聚焦在应用层。\\n2. VirtualWarehouse：每个VW由数量不等的Amazon EC2弹性计算实例构成，在向用户销售时，使用S->M->L这种服务尺寸，用户看不到EC2的数量。由于计算规格的单价已经分档，后续的付费就是基于时间来计费，Snowflake还贴心地给用户提供了超过多少时间停用的选项，有点类似运营商流量套餐超限保护，避免按调用次数付费场景下，写出了烂SQL，结果账单爆表的问题。\\n3. CloudServices：这块是Snowflake的核心自研产物，包括SQL执行引擎（三大特性：列存、向量化、push方式，上游主动给下游推数据，据说能提高缓存效率，之前很多引擎，都是基于Volcano模型的pull方式）、表的元数据管理（KV形式存储）、并发控制和事务管理。\\n\\n计算存储分离\\n\\n业界有一种主流的架构称为Shared-Nothing，指对一个很大的表数据，系统把它按照某种规则拆分成N份，拆分之后由N个worker来分别处理其中的一个分区。这样的好处是架构比较简单，所有worker上的处理逻辑都一样，worker节点之间不共享任何数据，查询执行的过程中没有资源的争抢，效率很高，而且拆分之后普通的机器就可以计算很大的查询，不再需要什么特殊的高配机器。它最大的缺点是，把计算资源和存储资源捆绑在一起，引起以下问题：\\n\\n1.  当集群的节点数发生变化(升级，扩缩容等等)的时候，Shared-Nothing 需要对数据重新进行分布，而这个是需要消耗大量的计算资源的，在这期间用户在线查询的性能会受到影响。\\n2.  不同场景对于机器配置的要求不一样，一个对于数据导入很好的配置(IO intensive)对于复杂的在线查询(CPU-intensive)就不一定适合，而为了支持所有的场景，最后机器的配置要取个折中，从而无法达到最好的性价比。\\n3.  集群的软件版本有升级的需要。虽然理论上可以一个接着一个地升级，但是工程实现会很复杂。\\n\\n由于Snowflake把存储和计算分别部署在S3和EC2上，实现了分离。对前面提到的Shared-Nothing的几个问题，对于异构工作负载的问题，用户可以为不同的场景分配不同的计算层机器，用完了之后可以释放掉（这点和Snowflake的计费模式也有关）。又因为EC2和S3没有任何关系，在计算节点扩缩容时，当然不需要对数据进行重分布操作。\\n \\n技术特性问答\\n\\n* 如何解决存算分离带来的性能问题？\\n\\n每台Worker节点都配备了SSD，这个SSD并不保存原始数据，而是保存被之前查询请求过的热数据，做到在性能和成本间的平衡。为了提高缓存文件的磁盘命中率，Snowflake的查询优化器在调度TableScan的时候会根据表对应的底层文件名，以一致性hash的算法把数据加载的请求分到这些worker节点上，保证对同一个文件的请求可以尽量落到同一个worker节点上去，提高命中率。\\n因此从大的架构来看Snowflake做了计算和存储的分离，但是如果看缓存的设计，会发现计算和存储又绑定到一起了。只不过这个绑定不明显，而且只存储被查询的数据，不是全量数据。\\n\\n* 如何实现更新？\\n\\nSnowflake系统里面的数据文件都是只读的，当用户对数据进行更新的时候，系统会产生新的文件，把老的文件替换掉，但是每个文件本身是只读的，这样的模式特别适合S3的存储特性（只能覆盖写，不能追加写），同时也方便实现MVCC -- 只要让每个查询始终读查询开始时的对应的版本的文件就好了。\\n\\n* 如何实现事务？\\n\\n事务是通过 Snapshot Isolation的方式来实现的，所谓的Snapshot Isolation, 指的是一个查询能看的数据是这个查询开始时整个系统的一个快照，跟类似系统一样，Snowflake也是通过MVCC来实现Snapshot Isolation的。\\n\\n* 为什么不用索引？\\n\\n1. 索引依赖对文件随机读，而S3系统并不适合随机读取。\\n2. 索引会降低查询、加载的效率，数仓数据量都特别的大，降低了加载的效率在需要做数据恢复的时候是很大的问题。\\n3. 索引需要用户手动创建，会加重用户使用成本。\\n\\n* 索引的替换方案是什么？\\n\\n在每个数据文件上保存数据的min/max类统计数据，通过对这些元数据进行扫描可以判断是否要扫整个文件，避免扫描所有文件。这种方案在顺序大块数据时效果很好，对数据载入、查询优化、查询执行的影响也非常小。\\nSnowflake对半结构化的列也会生成min/max。除了静态剪枝，Snowflake还会运行期动态剪枝。例如在hash join时，Snowflake会在构建端统计join key的分布，再传到探测端用来过滤数据，甚至有机会跳过整个文件。\\n\\n* 如何做到数据加密？\\n\\n数据会在两个地方加密，一个是网络传输时，一个是磁盘写入时（如Amazon S3）。\\n存储数据的加密滚动策略：磁盘上保存数据用的加密key是一直在变化的，具体策略是定期创建新的key，之后旧的key只用来解密，不能再加密了。当确定一个key要被弃用后，用这个key加密的文件会被用新的key重新加密。"}'));jctx.push(JSON.parse('{"id": "210323", "tag": "design", "text": "# 图灵机与lambda演算比较\\n\\n计算模型的一个重要用途是研究complexity和程序的效率。比如在图灵机模型上你可以简单地定义状态转移为时间意义上的“一步”，程序使用的纸带大小为空间上的消耗。 然而 λ-calculus 上没有特别简单的cost model让你可以直观地谈论时间和空间复杂度，这很大程度上限制了 λ-calculus 作为一种描述算法和复杂度类的元语言。\\n\\n图灵机也是做不出来的.. 因为长度是要无限的... 有限长度的图灵机和 DFA 是等价的，也就是其实和 λ 演算是不等价的。等价只是从可计算性和多项式时间内的可计算性来讲的。要论上具体数量级和系数，基本上没有哪两个计算模型是完全等价的。\\n\\n虽然现代程序语言是图灵完全的，但是和图灵机本来的操作方法是差了非常多的.. 如果要写得像一点的话估计就是 goto 指针满天飞舞的情况.. 和现代编程体验也是差了不知道多少的..\\n\\n甚至现代程序语言的“函数式”趋势我也都觉得本质不是往 λ 演算方向走，而是类型系统，还有就是尽量去写成状态机了。\\n\\n除了图灵机与λ演算外，其实还有许许多多的计算模型，它们都等价：\\n\\n* 图灵机\\n* λ演算\\n* 一阶逻辑\\n* 时序逻辑MPTL\\n* 动态逻辑\\n* petri网\\n* 进程代数\\n* 递归可枚举语言\\n\\n这些计算模型都是相互关联有所侧重的，比如说图灵机能接受的语言是递归可枚举语言，一阶逻辑的归约是λ演算，一阶逻辑的扩充是时序逻辑、动态逻辑，进程代数关心迁移而图灵机关心状态。\\n\\n这些计算模型能力都等价，它们从不同的视角去看待计算这件事情，面对着不同的问题，采用不同的计算模型效果是不一样的。在有些问题里面，用图灵机就表达不清楚，但是用递归可枚举语言就能很好地解释。图灵机需要知道系统内部状态，而进程代数只需要关心交互过程。动态逻辑和petri网能给出计算的全局状态，而时序逻辑、图灵机、进程代数则“只见树木不见森林”。\\n\\n最后，我只能说，针对合适的问题，有合适的模型。“普遍接受”是因为见过的问题少了。\\n\\n希尔伯特最初提出 23 个问题的时候，对计算问题只是大概说了一个「mechanical」，当时谁也说不定「machanical」的形式定义。图灵的模型无疑更接近「mechanical」的本意。而且后来图灵从哲学上把图灵机和人脑做了一些比较，也得到了业界的广泛认可。这些在图灵的传记《Enigma》里专门有描述。特别说了图灵发现 Church 的论文首先被 reivew，非常沮丧，但是最后评议还是认为图灵的模型更有创意。\\n\\n考虑到硬件结构、空间复杂度等问题，自然数不会用church encoding表示，递归也往往不会真编码成Y combinator 。虽然有个东西叫De Bruijin Notion，可以把lambda term编码到形似0101的二进制形式。。\\n\\nLisp Machine也是建立在Von-neumann体系结构上的，只不过用专用硬件、指令加速某些操作，比如用List处理器高速完成动态类型检查，专门的List存储器实现树状的表存储，把nil之类的常量存到专用寄存器，对某些结构并行求值。。\\n\\n各种Abstract Computing Machine（CESK、CLS、SECD 等）的提出、编译技术（譬如CPS、Defunctionlizing变换、LISP-2 GC）的进步、以及体系结构的发展（内存、微处理器等），使得普通PC上也能准确、高效地实现函数式语言。\\n\\n最后实际普遍使用的computation model是Von-neumann模型，都带着可随机访问的内存。很少有真拿一条纸带左右移动算东西的。Von-neumann能流行，主要是因为这个能用电子元件做出来，而且速度和其他能做出来的model比要快不少。\\n"}'));jctx.push(JSON.parse('{"id": "210404", "tag": "data", "text": "# 数据库的执行优化\\n\\n现代数据库都基于成本做CBO优化，CBO的难点在评估不同规则组合的期望时间，这里就会有组合爆炸的问题，为此就有了两种模型：Volcano模型和Cascades模型。其中Calcite使用的是Volcano模型，而Orca使用的是Cascades模型。这两种模型的思想都基于成本最优假设，即局部最优化后即达到整体最优化，不同点在于Cascades模型并不是先Explore、后Build，而是边Explore边Build，从而进一步裁剪掉一些执行计划。\\n\\nVolcano模型是一种经典的基于行的流式迭代模型(Row-BasedStreaming Iterator Model)，主流的关系数据库Oracle，SQL Server, MySQL等都采用了这种模型。在Volcano模型中，所有的代数运算符(operator)都被看成是一个迭代器，它们都提供一组简单的接口：open() -> next() -> close()，查询计划树由一个个这样的关系运算符组成，每一次的next()调用，运算符就返回一行(Row)，每一个运算符的next()都有自己的流控逻辑，数据通过运算符自上而下的next()嵌套调用而被动的进行拉取。\\n\\n和Volcano的相对应，推送模型最早在一些流媒体计算中被使用，随着大数据时代的来临，在一些基于内存设计的OLAP数据库也被大量使用起来，例如HyPer、LegoBase等。\\n\\n![sql-pull-push](/img/sql-pull-push.jpg)"}'));jctx.push(JSON.parse('{"id": "210421", "tag": "tool", "text": "# vim的扩展与插件\\n\\n## 理念的区别\\n\\n扩展的最终目的，是把操作映射为脚本化的描述，说到这点不得不和EMACS做个对比。\\n\\nEMACS统一用函数表达，函数和变量在EMACS中体现得非常彻底，而vi由于其操作第一性，并不是每个操作都有对应的函数（比如说hjkl代表的移动，没有直接对应函数来表示这个行为，只能cursor间接实现）。VimL脚本实质是ex命令的集合，因为vi有多模式，操作要注意是在什么模式下进行（可以是normal或execute方式的动态化操作）。但是很多原来只是给人看的操作，通过`redir => var`方式，也能被变量捕获，进而获得一定程度的脚本化能力，这也是vim自身在演化过程做出的调整。\\n\\n因此VimL脚本的思路和EMACS不同，操作是交互式的，并不是所有操作都适应脚本化。比如移动窗口到下一个位置，对人有意义，但对精确的脚本作业就没有实质价值。VIM把所有的按键都赋予很高效的操作方式，脚本层面看起来就不一致甚至丑陋，而EMACS则在函数层面更一致，也导致经常要连续按多个按键才能触发一个动作。\\n\\n## 脚本与扩展\\n\\n前面提到vi逐渐演化成今天的样子，所以脚本中有多种方式来触发动作，典型有3种\\n\\n1. execute 动态执行ex模式的命令\\n2. call 执行指定函数\\n3. normal 输入操作指令\\n\\n扩展主要会用到以下3种方式\\n\\n1. 快捷键，最终触发函数或命令（含自定义和内建命令）\\n2. 命令，触发内建命令或函数\\n3. 操作宏，似乎更像Ad-Hoc操作\\n\\n函数是一系列操作的批量作用，两者结合达成最终目的。\\n\\n快捷键最终都是映射到命令，所以格式一定要用`:call xx<CR>`。即用冒号触发命令模式，再用回车结束。\\n\\n自定义命令即不需要冒号也不需要回车，前者是已经在命令模式，又因在命令模式一定会按回车，所以不用写回车。\\n\\n## 函数参数\\n\\n必须明确写出参数个数，否则运行时报错而不是静默地处理为NULL，可变参数a:000的类型是list，即使不传值也会构造一个空list，先用a:0取得长度，再取数。静态函数由于最终被展开为`<SNR_xx>`，不知道具体名字，所以特意引入<SID>相对表示。\\n\\n## 模拟的包机制\\n\\n官方只做了autoload加载，包机制是爱好者开发的，是沿着autoload的进一步封装。调用package#import函数，获得某个指定模块的字典对象，接下来就可以在这个字典对象上执行函数调用，看起来和常见的编程语言风格更接近。\\n\\n## 插件原理\\n\\n由于支持写扩展命令，某人把他写好的扩展命令，用vim和用户交互的接口，包括命令、函数、<plug>键映射、事件代码的方式开放给别人用，便是个插件。\\n\\n插件是一个具有特定结构的目录。其中最重要的一级子目录是plugin目录，如果整个目录在vim的rtp列表中，则这个目录的plugin子目录内的每个vim文件（不管多深）都会在启动时被加载，但不确保加载顺序。这种加载方式只适合互相之间没有关联的场景，且也不能做到懒加载。逐渐地衍生出了autoload目录，autoload内的vim文件，只有在其它文件出现call xyz#abc()函数调用时，才会去加载autoload/xyz.vim文件，进而调用abc函数。有了autoload机制后，现在的插件几乎都变成了plugin子目录下仅有1个vim文件，其它文件都移到autoload目录按需调用。\\n\\n有些插件希望自己的加载顺序靠后一些，因此目录下如果有after/plugin文件夹，则这个文件夹内的所有vim文件至少会在plugin后面加载。\\n\\nplug是个单体文件，放在**runtimepath简称rtp**的autoload目录，必须命名为plug.vim，*必须小写*否则会找不到（原因从前述机制可以明白）。用`echo &rtp`查看选项值，如果不包含插件目录，配置`rtp+=your-dir`。这个插件用法是先调用plug#begin()，然后用Plug命令加载各种插件目录，最后执行plug#end()。原理是#begin()时会初始化g:plugs字典，在Plug时把各种路径写入这个字典，到#end()时，会遍历g:plugs，并source每个目录的plugin/ftdetect/after等关键目录下的所有vim文件，从而实现插件加载。\\n\\n## 问题排查\\n\\n配置了若干插件，但是调整了一些文件后发现又失效了。现象是插件管理的Plug系命令有效，但Rainbow命令出不来，就要从插件的加载会依赖rtp路径，用echo &rtp发现我的配置路径并不在列表中，但Plug又是可用的，加载Plug之后rtp路径被修改了。由于最后加载的spf13.vim是抄的，搜索rtp没结果，再搜索runtimepath，果然用=把结果全部重置了，但并不影响已经载入的Plug命令。问题找到去掉赋值语句就行了。\\n\\n排查问题首先还是要对机制熟悉，再从现象反推各个环节。"}'));jctx.push(JSON.parse('{"id": "210611", "tag": "lang", "text": "# 理解shell的换行和打印\\n\\n写sh时想把一段文本的json变量传给程序，但因为带了换行符，总是失败。大概是因为sh面向终端操作，而换行符又是命令发起的标志，哪怕这个换行符被放在字符串中，也会认为是命令提前结束。因此要把文本中的换行去掉。\\n\\n网上说用cat xx | xarags可以实现，实测会把双引号也去掉，对于json来说不可接受，最终用sed的\':a;N;s/\\\\n//;ta;\'语句实现。\\n\\n带换行的文本\\"ab\\\\ncd\\"存入变量时，直接echo的话，换行会显示成空格，用echo -e才能显示换行，var=$(cat xx)把文件内容赋值，回车会真的转成空格，即使echo -e也还是显示空格。但是：文本最后不管多少个换行，只要换行后没有内容，都不会记入变量。\\n\\n## 动态更新已打印文本\\n\\n`printf \\"%s\\" abc;sleep 1;printf \\"\\\\r%s\\" def`\\n\\n这句语句会先显示abc，1秒钟后用def替换。奥妙有两处\\n\\n1. \\\\r回车来到开头打印，进而更新已打印出的内容\\n2. 用printf而不是echo，因为echo会默认在末尾追加换行，而回车只能回到这一行的开头，如果已经换行就再难回头，所以必须用printf才能实现动态刷新效果\\n\\n终端控制有个非常有名的软件包ncurses，6.2版本自带了1750种历史上曾经存在的终端序列描述，不过现在仍活跃的恐怕不超过10种了。这个包里最有用的命令也许是tput，`tput cup x y`可以自由地定位光标位置。准确地说参数所对应的位置，是PS1的首字符的位置，而光标位置则会被推到后面。\\n\\n## Excel的回车符读取和替换\\n\\nexcel导出的csv中，正常回车是0D 0A，单元格内的回车是0A。\\n\\nfread的r模式无法识别0D，严格说是连着0A起读，直接被吞了。只有rb模式才会逐个字节识别。换句话说，r模式fread(1,1)的次数比总字节数要少，rb才等于总字节数。\\n\\n## 光标控制\\n\\n编程语言用`\\\\`作为转义序列的起始符，而终端则选择了ESC（033或0x1B或\\\\e）作为转义序列的首字母，之所以只是首字母，是因为ESC后面还要跟二级转义符，范围是`@A–Z[\\\\]^_`，这32个中又以`ESC+[`这组称为Control Sequence Introducer（简写作CSI）至今仍广泛使用在光标控制和色彩显示上。"}'));jctx.push(JSON.parse('{"id": "210614", "tag": "lang", "text": "# erlang和其上的扩展语言\\n\\n## 程序组成和功能\\n\\ncent发行版拆得比较细，最核心的erts运行时单独成包，其它lib目录下的库，像compiler,debugger,edoc,kernel,stdlib都是独立的包。\\n\\n* erl: 负责启动模拟器并在终端执行命令，感觉更像个REPL。启动有很多的参数，和其它程序不一样的是选项风格，有`+`和`-`两种类型。erlexec负责加载EMU（现在都是beam了），由EMU负责真正的调度\\n* erlc: 负责将源码编译为beam字节码，和其它编程语言类似\\n* escript: 以解释（非编译）的方式执行源码。在很多其它解释型语言里，erl和escript是同一个程序，如果参数有源文件，就解释执行，否则就进入REPL，但erlang把这两个分开，因为escript的执行要求源码必须有main/1函数，更像C语言指定入口，而不是脚本语言遇到什么语句都会执行\\n* epmd: 严格说并不在PATH路径，也不需要手动启动，当调用erl带上-sname或-name xx@ip参数，会自动启动epmd。即使erl程序退出或崩溃，epmd依然在后台监听\\n\\n启动顺序\\n\\nrun_erl/to_erl（可选，准备有名管道和日志环境） -> erl -> erlexec（在erts目录） -> beam（或beam.smp，很早期是jam）\\n\\nerlang下载时标识的是OTP版本，这个版本也决定了不同节点的程序能否组成集群，非常重要。而运行erl会显示erts/eshell的版本，要区别这两个版本。\\n\\n## 文档\\n\\n安装包后没有文档，从官网下载man包，并放到erlang的根目录，用`erl -man xx`查看。\\n\\n## 类型分析\\n\\n属于扩展包，typer和dialyzer是最成功的两个包。对有标注过类型的源码进行分析，并找出潜在的错误。\\n\\n## lfe的编译\\n\\n由于lfe是shell脚本，源码发布时就在目录中，编译的目的只是为了生成所需的beam文件，用make方式，把erl源码编译为beam，再将一个c文件编译为可执行程序。\\n\\n执行命令前先配置ERL_LIBS路径，参数展开为`erl -user lfe_init -extra`执行。可见执行的底座仍是beam。"}'));jctx.push(JSON.parse('{"id": "210623", "tag": "lang", "text": "# JoeArmstrong看OO\\n\\n最初他认为Erlang不是OOP，而是FP，但是他的导师不同意。\\n\\n老爷子后来认为Erlang是OOP，但是这个OOP和其他人理解的不一样：\\n\\n常规认为OOP=封装+继承+多态。\\n老爷子认为OOP=消息传递 + 隔离 + 多态，其中消息传递最重要，隔离和多态都源自于消息传递。\\nSmalltalk的作者Alan Kay更是认为Messaging是唯一重要的事情。\\n从这个角度，Erlang非常OOP。所以老爷子其实是支持OOP的，但是他支持的不是题主要问的Java那种OOP。\\n\\n为了说清楚上面的问题，我下面把常规认为的OOP称为OOP-A（以早期Java、C#为代表），老爷子理解的OOP称为OOP-B（代表是Erlang）。\\n\\n首先OOP-A语言会非常淡化messaging这件事，或者它们已经把messaging的概念简化成方法调用。而messaging则要求必须有个mailbox，或者消息队列的概念，用来存储还没处理的消息。在OOP-A的语境下，带真正messaging的Object的形式被称为“Actor“，JVM生态下的代表作是Akka。但是Erlang一开始就是基于messaging的。\\n\\n如评论区里所说，smalltalk和ruby语言表达出了“messaging”的概念，本质上是一种方法动态调用的机制，与Erlang/Akka的messaging不同。\\nErlang虽然支持“继承”，但都没有将其看作为特别核心的概念。\\n\\n也许OOP-A里的“封装“和OOP-B里的“隔离”容易被理解为差不多的意思，但实际二者有很大的区别。OOP-A中强调的是“把状态隐藏在Object”内部，所以搞了public和private方法等。 (相关回答：大宽宽：既然Java反射可以访问和修改私有成员变量，那封装成private还有意义么？）\\n\\n但是OOP-B的隔离的目标很简单直接，即要求一个Object crash了其他Object可以不受影响。想象一下在Java程序里的如果有一个Object因为某种原因hang了，也许就会造成死锁，以至于整个程序都不能工作了。而在Erlang里会推崇“supervisor”模式：一个Object hang了，它的supervisor Object会侦测到并且做一些动作（比如杀掉hang的Object，然后新创建新的Object,），程序整体仍然可以跑。这个思路在Erlang里被称为let it crash。\\n\\n对比“隔离”，OOP-A的封装是一种“设计思维”，即在设计上让两个相互独立的东西可以分开，底层实现上有没有关联并不是其关注重点。OOP-B的隔离是从高可用出发的。并且Erlang要求一个Object运行在一个“进程“上（这里的进程是抽象概念，不特指操作系统进程），这样就顺带解决了并发中同步、互斥之类很恶心的问题。更进一步是，Erlang的Object隔离和消息传递可以跨机器。这个特性便利了如RabbitMQ这类系统的开发。有人提到过OOP不利于高并发，但是OOP-B明显是更加容易高并发。\\n\\nOOP-A和OOP-B都提到多态。实际上，OOP-A的多态是建立在“类型“的is-a的基础上的。比如一个Cat类是因为继承了Animal类，才能对“叫”这个方法进行多态的。但OOP-B可以不在意is-a关系。OOP-B的多态就是单纯的觉得任何Object，只要应该有某个能力，就可以“注入”进去。\\n\\n比如在Java写一个业务代码，比如有5种差异很大的产品，比如汽车零件、书、基金理财、手机和会员充值服务。在一个宣传界面上希望这5个产品都能有获取一行简单介绍、一行复杂介绍和一个图标的功能。对于OOP1语言，一定要将他们继承自某个基类，并override掉基类方法才行。你可以想象到它们虽然都是“产品”但是根本就是不同的东西，甚至是5个业务部门各自维护的东西，弄一个共同基类出来无比尴尬。即使弄出来了，单继承的限制也阻碍了这个需求的进一步变化的可行性。其实，这些“产品”仅仅是在展示这件事情上有共性而已，强行发明一个公共基类常常会得到反常识和不灵活的设计。\\n\\n对于OOP-B语言，多态被看作是不同的Object收到同样消息后行为不同。它们只要各自处理“展示”这个事件就行了。这样做自由度更高。\\n\\nBTW, 现在Java实现这种多态可以用interface实现的方式来做。\\n总结下。深入的讨论编程范式时，单纯的用是不是OO已经不能表达清楚的意思了。这就好像简单的说“川菜”好不好吃很模糊，细究下来必须用某家饭馆的某个大厨做的某道菜来细细的品评。我对OOP-A和OOP-B的个人理解是，OOP-B更加自洽，它的目标就是建立庞大但是能容错的程序，这就引发了采用messaging的方案，以及由于messaging得到隔离和多态。整个Erlang的体系都是围绕这个核心做的。当然这些特性并不一定适合你的场景。但我觉得这是一个值得推崇的分析问题-解决问题的思路和做事方式。\\n\\n相反，OOP-A把几个漂亮概念凑一起，对系统设计起到的作用过于宽泛以至于无法落地。比如封装怎么封，谁该和谁相互隐藏，这种并没有什么规则可以遵循，最终还是靠经验。所以有人会争论用不用private、到底是msg.send还是msgMgr.send(msg)这类问题。要解决的问题本身却得不到重点的关注。OOP-A折腾来折腾去就会发现，除了那些漂亮的名词和概念，已经很少关心软件开发本来要解决的问题，如管理软件复杂性、提高可维护性。开发时为了解决实际问题，还是得从业务角度出发思考，以及配合一些“设计模式”才能真的落地。也许在某些特定领域（比如GUI），OOP-A用起来比较贴切，但是整个业界或者培训界显然是过分强调了它们的优势，以至于到了其他OOP-A并不擅长的领域，带来大量设计和编码上的错误。而且很不幸一票编程语言按照OOP-A的思想被做了出来，开发者去跟一众并没有什么卵用的语言的特性较真，反过来却离“创造与解决问题的方案贴切的编程方式“越来越远。（相关回答：大宽宽：面向对象编程的弊端是什么？）\\n\\n最后再次强调下，上文中虽然写了OOP-A和OOP-B，这个仅用于解释Armstrong的原文的意思，这个提法并非是一般性概念。请特别留意：\\n\\n并非说世界上只有OOP-A和OOP-B。实际上C++的OOP，Java的OOP，Ruby的OOP，Erlang的OOP等等都多多少少有些区别。看看下文中老爷子的最后一句“You can try it and see it for yourself“. 即在了解别人的思路的同时，可以有自己的不同的理解。OOP是什么其实不重要，重要的是你看了之后有自己的思考和认识！\\n并非说OOP-B是OOP-A的升级。OOP-B也并不一定比OOP-A更加适合你的问题。此外也没有哪个比另外一个更“好”。我们无法精确的定义什么是“更好的”。比如评论区里有人并不喜欢let it crash这种方式。只有当问题相对确定了，我们才能搞清楚方法是不是“更适合”。\\n以下是老爷子的回答原文。\\n\\nIs Erlang Object Oriented?\\n\\nJoe Armstrong: Smalltalk got a lot of the things right. So if your question is about what I think about object oriented programming, I sort of changed my mind over that. I wrote a an article, a blog thing, years ago - Why object oriented programming is silly. I mainly wanted to provoke people with it. They had a quite interesting response to that and I managed to annoy a lot of people, which was part of the intention actually. I started wondering about what object oriented programming was and I thought Erlang wasn\'t object oriented, it was a functional programming language.\\n\\nThen, my thesis supervisor said \\"But you\'re wrong, Erlang is extremely object oriented\\". He said object oriented languages aren\'t object oriented. I might think, though I\'m not quite sure if I believe this or not, but Erlang might be the only object oriented language because the 3 tenets of object oriented programming are that it\'s based on message passing, that you have isolation between objects and have polymorphism.\\n\\nAlan Kay himself wrote this famous thing and said \\"The notion of object oriented programming is completely misunderstood. It\'s not about objects and classes, it\'s all about messages\\". He wrote that and he said that the initial reaction to object oriented programming was to overemphasize the classes and methods and under emphasize the messages and if we talk much more about messages then it would be a lot nicer. The original Smalltalk was always talking about objects and you sent messages to them and they responded by sending messages back.\\n\\nBut you don\'t really do that and you don\'t really have isolation which is one of the problems. Dan Ingalls said yesterday (I thought it was very nice) about messaging that once you got messaging, you don\'t have to care where the message came from. You don\'t really have to care, the runtime system has to organize the delivery of the message, we don\'t have to care about how it\'s processed. It sort of decouples the sender and the receiver in this kind of mutual way. That\'s why I love messaging.\\n\\nThe 3 things that object oriented programming has it\'s messaging, which is possibly the most important thing. The next thing is isolation and that\'s what I talked about earlier, that my program shouldn\'t crash your program, if the 2 things are isolated, then any mistakes I make in my program will not crash your program. This is certainly not true with Java. You cannot take 2 Java applications, bung them in the JVM and one of them still halts the machine and the other one will halt as well. You can crash somebody else\'s application, so they are not isolated.\\n\\nThe third thing you want is polymorphism. Polymorphism is especially regarding messaging, that\'s just there for the programmer\'s convenience. It\'s very nice to have for all objects or all processes or whatever you call them, to have a printMe method - \\"Go print yourself\\" and then they print themselves. That\'s because the programmers, if they all got different names, the programmer is never going to remember this, so it\'s a polymorphism. It just means \\"OK, all objects have a printMe method. All objects have a what\'s your size method or introspection method.\\"\\n\\nErlang has got all these things. It\'s got isolation, it\'s got polymorphism and it\'s got pure messaging. From that point of view, we might say it\'s the only object oriented language and perhaps I was a bit premature in saying that object oriented languages are about. You can try it and see it for yourself.\\n\\n原文见：Ralph Johnson, Joe Armstrong on the State of OOP\\n"}'));jctx.push(JSON.parse('{"id": "210703", "tag": "lang", "text": "# 并发编程模型\\n\\n说说两种内建在编程语言中的并发流派：Akka/Erlang的actor模型与Go语言的协程Goroutine与通道Channel代表的CSP(Communicating Sequential Processes)模型\\n\\n## Actor模型\\n\\n主角是Actor，类似一种worker，Actor彼此之间直接发送消息，不需要经过什么中介，消息是异步发送和处理的。Actor模型描述了一组为了避免并发编程的常见问题的公理:\\n\\n1. 所有Actor状态是Actor本地的，外部无法访问。\\n1. Actor必须只有通过消息传递进行通信。\u3000\u3000\\n1. 一个Actor可以响应消息:推出新Actor,改变其内部状态,或将消息发送到一个或多个其他参与者。\\n1. Actor可能会堵塞自己,但Actor不应该堵塞它运行的线程。\\n\\n## CSP模型\\n\\nworker之间不直接彼此联系，而是通过不同channel进行消息发布和侦听。消息的发送者和接收者之间通过Channel松耦合，发送者不知道自己消息被哪个接收者消费了，接收者也不知道是哪个发送者发送的消息。\\n\\nGo语言的CSP模型是由协程Goroutine与通道Channel实现：\\n\\n1. goroutine: 是一种轻量线程，它不是操作系统的线程，而是将一个操作系统线程分段使用，通过调度器实现协作式调度。是一种绿色线程，微线程，它与Coroutine协程也有区别，能够在发现堵塞后启动新的微线程。\\n1. channel: 类似Unix的Pipe，用于协程之间通讯和同步。协程之间虽然解耦，但是它们和Channel有着耦合。\\n\\n## Actor模型和CSP区别\\n\\nActor之间直接通讯，而CSP是通过Channel通讯，在耦合度上两者是有区别的，后者更加松耦合。同时，它们都是描述独立的流程通过消息传递进行通信。主要的区别在于：在CSP消息交换是同步的(即两个流程的执行\\"接触点\\"的，在此他们交换消息)，而Actor模型是完全解耦的，可以在任意的时间将消息发送给任何未经证实的接受者。由于Actor享有更大的相互独立,因为他可以根据自己的状态选择处理哪个传入消息。自主性更大些。\\n\\n在Go语言中为了不堵塞流程，程序员必须检查不同的传入消息，以便预见确保正确的顺序。CSP好处是Channel不需要缓冲消息，而Actor理论上需要一个无限大小的邮箱作为消息缓冲。\\n\\nActor是CSP的一个特例，CSP比Actor更加灵活。Erlang将Actor发挥到了极致，通过spawn_link/monitor机制，发展出了OTP框架；CSP比Actor更加灵活，Go目前还未有相似框架。\\n"}'));jctx.push(JSON.parse('{"id": "210721", "tag": "data", "text": "# PySpark分析\\n\\n## 执行过程\\n\\n常用的有local和yarn两种模式，写代码或调错阶段，无特殊情况用local，速度快很多。\\n\\npyspark和scala的spark不同在于，某些情况下数据会从jvm回传给py，这个回传的过程是怎么样的？首先，Spark会先把所有py文件放到此次任务driver端所在的节点，比如我的环境放在 /yarn/nodemanager/usercache/xxx/appcache/application_xx/container_xx_01/main.py 目录，启动py的命令是`path/bin/python main.py --arg=xx`。同时spark会在driver放一个pyspark.zip，解决Py与spark集群通信的问题。driver端任务运行一段时间后，如果发现计算需要把数据传递给executor上的python，就会启动`path/bin/python -m pyspark.daemon`，没有额外的参数。pyspark.daemon会fork一个进程，然后在子进程里执行pyspark.worker.main函数，数据读写的源头也改为来自socket。实际代码中先会做dup，把socket复制出来提高效率。driver和executor之间通过环境变量和socket传递数据和代码（似乎是pickle序列化），此时的executor会在container_xx_02或03目录内执行。\\n\\n进入py代码后，先构建SparkContext对象，构建过程会查找并执行`spark-submit pyspark-shell`命令，构建一个java的gateway，再通过Py4J包，以类似RPC的方式把py代码通过Gateway发送到jvm，进行spark操作。如果计算过程中需要python的udf，则数据必须发送到work节点，过程是由spark启动python的worker.py进程，并以环境变量的方式把端口告知worker，worker会用socket去连接这个port，并做一系列判断，比如driver和worker的python版本必须一致，计算结束后再用socket发送回spark。理论上只要数据不回传给py，开销只是方法的传递，性能和scala的实现是一样的，如果有数据回传，速度会降低一倍以上。\\n\\n## PySpark内容\\n\\n### 包层次\\n\\n顶层目录pyspark包含SparkConf、SparkContext、RDD等spark的基础概念，包含sql、streaming、ml、mllib等多个子模块。\\n\\n### 流程和关键概念\\n\\n如果是写类SQL功能，流程是套路化的\\n\\n1. 获取SparkConf，设置master和appName。我只用过yarn模式\\n2. 把Conf作为参数传给SparkContext。注意，必须构造context，否则无法和spark通信。Conf可以没有，但考虑要设置的参数很多，用Conf方便，另外还有序列化类参数可传入，默认用pickle序列化py和jvm之间的数据\\n3. 通过Context来获取SparkSession。这个Session是属于pyspark.sql的类，整合了SQLContext和HiveContext等多个SQL会用到的功能\\n\\n拿到SparkSession后，读取文件得到的数据呈现形式就是DataFrame类，这个类具备很多SQL语义的API（因为Session就是sql包下的一个类）。DataFrame可以链式操作，即操作后返回的值大部分情况下仍是DataFrame，如果做了groupBy操作，得到的是GroupedData类型。\\n\\n### PySpark命令\\n\\n执行这个命令，会自动加载shell.py脚本并初始化sc(pyspark.context), spark(pyspark.sql.session，对应原生SparkSession类), sql(spark.sql的别名), sqlCtx/sqlContext(pyspark.sql.context.SQLContext)共4个全局变量。"}'));jctx.push(JSON.parse('{"id": "210901", "tag": "think", "text": "# 对昼伏夜出和朝九晚五两个技战法的分析\\n\\n单看这两个模型的名字，含义好像是非此即彼的，研究它的时间划分，以及计分细节，才体会到这两个模型想表达含义的差异。\\n\\n## 模型定义\\n\\n昼伏夜出定义了4个时间点，晚上11点到早上的5点，如果出现就加一分；从早上9点到下午1点出现就减一分，其他时间段不计分。而朝九晚五划分了6个时间点，早上7点到10点以及下午的4点到7点出现会加一分，晚上的10点到早上的4点，出现会减0.5分。累计10天，总分大于一定阈值就判定为对应人群。\\n\\n## 模型意图分析\\n\\n从时间划分来看，昼伏夜出的昼仅指上午，定位的是经常在夜间出没的人员，所以晚上出现加分，同时因为上午要休息，所以上午出现会减去同样的分数。该模型针对比如有盗窃嫌疑的人，这些人往往是习惯于晚上踩点，上午休息。而另一种三班倒的人群，是晚上出工，差不多早上8,9点会回家休息，通过对上午出现减分，就把踩点的小偷和三班倒的人员做了一个区分。因为这个模型关注是盗窃人员，所以对于下午的活动就不在意了。通过这样的时间划分方式，就比较准确的找出昼伏夜出人员。\\n\\n朝九晚五从时间段来看，想表达的是在早上和傍晚的通勤时间常出现，深夜到凌晨少出现，从单次的扣分和加分不相抵，能看出来该模型并不要求晚上不出现，这里也有个细节，并不关注中午这个时段是否出现。因为他想找出的就是在早晚通勤时段有活动的人，所以中午是否活动并不影响判断。\\n\\n相比于昼伏夜出模型，朝九晚五想做的是对白天活动的人群做细分，就是上班时间比较规律的这群人。典型的如公务员或一些窗口办公人员。如果我们把这个模型的时间段调整一下，比如把早上的时间不变，晚上的时间定义在8点到12点，能得到了一个早出晚归的人群，就是加班时间比较久。\\n\\n以上是一天的记分规则，像这种模型一般来说都会统计过去一周或者一个月的总分值。在这方面也有一个很有趣的点，就是它在算每天的总分时，会设定一个上下限阈值，最低不低于0分，最高不高于两分。如果直观地看规则，对朝九晚五规则来说，如果某个人白天不出现，晚上出现了是会变成负分的，但因为阈值的存在，并没有出现负分。我分析他的意图是考虑如果周末的晚上出没较多，这个负分就会对其他天的出行造成一个负面的影响，但是这个周末晚上的活动又是在允许范围内的。既然这个模型是要找出具备通勤规律的人，那么偶尔一两天晚上频繁出现，就不应该对评价造成一个很负面的影响。"}'));jctx.push(JSON.parse('{"id": "211016", "tag": "net", "text": "# 以太和IP网之外的一些网络\\n\\n对网络来说，第一层物理层的种类相对较少，就我所知无非是光纤、双绞线、单芯线，受限于物理介质不会有太多花样。但在这些介质上传输信号，就必然要定义信号的标准和传输方式，所以链路层（二层）的协议可谓数不胜数，不过大浪淘沙，现在几乎只剩下802协议，但是回顾曾经丰富多彩的链路协议也能看出通信发展与演化。\\n\\n## 802.x\\n\\n以太网、令牌环以及无线网络都是这个家族的一个子类别，之所以是同一个家族，是因为共同遵守802.2的LLC链路控制协议，MAC地址也是这套规范定义的。\\n\\n以太帧除了承载IP包，还能承载ARP、VLan等。\\n\\n## ATM\\n\\n现在估计知道ATM网的人不多了，它采用的信元交换理念（cell switch），和电路交换和包交换都不一样。ATM网协议比TCP/IP协议复杂，也完善的多，基于电信思维制定的ATM网明显比基于计算机专家搞的TCP/IP协议完美太多。论技术，ATM协议绝对更适合通信未来发展，采用虚链路的连接方式，QOS有保障，带宽有保障，传输利用率也更高更稳定，整个网络的流量管理更强大，网络可控性高太多，对现在的流媒体等应用绝对更友好，基于ATM网的上层应用应该就简单很多，而不用像面对TCP/IP协议一样需要自己考虑网络稳定性，而且更强的网络控制和流量管理能力，可以大幅度降低大流量下的网络并发难度，减少现在因为突发流量导致网络崩溃。\\n\\nATM网络虽复杂，但是应用层绝对简单，面对用户应该比TCP/IP协议友好很多。其实TCP/IP协议表面看很简单，然而如果真正自己部署，要运营维护好难度相当高，因为自主性太强，灵活度太高，用户需要自己面对很多灵活的规划部署，这其实相当有挑战性。用TCP/IP协议构建一个小网可能很简单，然而网络复杂一点，就相当有难度。至于成本问题，我一直认为ATM设备贵只是因为他没机会像TCP/IP网一样得到大规模推广，没有规模应用，成本是无法降低的，如果当年率先得到推广的是ATM网而不是TCP/IP网，那ATM设备绝对可以降低成本，而且以电信思维制定的电信网络，往往都是网络端功能强大而复杂，但是接入终端则易总简单且成本低廉，就像我们曾经的固定电话一样，复杂而昂贵的电信局端设备干了基本绝大多数工作，用户客户端其实简单而廉价，所以ATM网当年倘若可以得到大规模应用，其整体成本不见得真就高昂，而且现在云计算的大规模应用，更是把这种将复杂工作放在后端，以简化终端的思想，其实挺适合ATM的技术思想。\\n\\nATM输就输在时间上，ITU-T基于电信网思维经验制定出一个庞大复杂的ATM协议花费了巨大精力和时间，然而计算机领域的专家，根本就不考虑那么多，只求简单快捷，有问题后面再迭代修补，结果标准还没定产品已经跑前面去了，以实战替代标准，所以随着TCP/IP协议的一统江湖，却越来越显示出IP协议在面对流媒体，语音，视频电话等应用时的力不从心，通过在IP协议上修修补补，以求弥补TCP/IP协议的不足，然而本质问题解决不了，只能尽力优化，所以导致为了适应新应用需求，整个TCP/IP协议其实越来越复杂，越来越庞大，虽然光传输的兴起极大的解决了带宽问题和部分QOS问题，然而现实中传输带宽用不是无线的，QOS问题不可能全寄托于传输链路没问题。今天各种应用大爆发，全网融合以IP协议一统天下，然而当年那个天赋异禀却时运不济的ATM只能叹息生不逢时。"}'));jctx.push(JSON.parse('{"id": "211102", "tag": "lang", "text": "# 几种语言的包加载和管理机制\\n\\n## Python和Lua\\n\\n算是比较经典的中心化包管理和分发机制，官方或半官方地提供中央仓库，本地开发需要包时从中央仓库下载到本地的某个公共目录，然后各个项目都从本地公共目录引用（但不会复制到项目下）。比较有意的是，中心仓库可以保存同一个包的多个版本，也可以指定版本下载到本地，但却只能保存一个版本，换版本只能采用覆盖机制。我所知的大部分90年代的动态语言都是这个机制。\\n\\n## Go\\n\\n设计初衷是分布式库管理，下载包就是很原始的去各种网站获取，于是就有了代理方把各种常用的库进行汇总，虽然是代理但间接担当了中心仓库的功能。\\n\\nGo的本地仓，通过将库名和版本号分成两级目录方式，保存了同一个库的所有版本内容，但是代价是v2及以上版本的库和v1库被认为是两个不同的库。\\n\\n## Java\\n\\n总体来说包管理和Go的机制有点像，官方没有考虑过包管理机制，由社区逐渐开发完善。支持在本地缓存保存多版本，最终在具体项目则引入对应版本的包。\\n\\n## PHP\\n\\n相比其它语言，2012年发展出的包管理软件composer算是比较晚的，因此也受了js的npm和ruby的bundle很多影响。由于语言在加载特性上也更少，并不适合作为全局工具，因此更偏向项目级，默认是对某个项目的包管理，也导致多个项目间的代码重复问题。当然composer的global命令也提供本地的公用仓，但毕竟加载机制相比其它语言弱一些，要依赖额外的文件，总有些不完备的感觉。"}'));jctx.push(JSON.parse('{"id": "211115", "tag": "os", "text": "# 搭建最小化的Linux系统\\n\\n有个很有名的发行版Linux From Scratch，非常地繁琐，我们可以从一个近似的形态去一窥究竟，也从中了解很多和二进制执行相关的内容。\\n\\n看过toybox作者给aboriginal写的介绍可知，最小化的系统只要具备4个文件就可以运行：linux、toybox、musl、tcc。linux作为内核没什么要说的，其它3个值得一说\\n\\n* toybox: 另一个同样定位但更强的软件是busybox，这几乎是惟一的应用层全静态链接软件，不依赖libc，只要选对CPU指令集，就可以在主机工作。为什么全静态链接如此重要，稍后解释\\n* musl: 虽然看起来只是个C库，但同时它也是个动态加载器\\n* tcc: 编译器自然是少不了的，在编译的时候可以指定interp的路径，可以适配不同系统的动态加载器名\\n\\n极简环境可以从Android的终端开始进行模拟，首先在这个终端中放入busybox，至少具备了各种操作能力。\\n\\n## 遇到的问题\\n\\n在低版本安卓编译的程序，到版本7后，因为要求可执行程序必须用*-fPIE*方式编译，通常动态库为了动态加载到多个不同进程，都会添加-fPIC标记，但执行程序本身是独立的虚假内存空间，可能出于安全的考虑吧，不是PIE编译的话就不能运行了。"}'));jctx.push(JSON.parse('{"id": "211218", "tag": "os", "text": "# 内存使用的观察和理解\\n\\n## 内存使用表现\\n\\n进程能使用的内存肯定是有上限的，如果慢慢增长，VSZ会持续增长，RSS会到一定量开始波动，但最终还是会因超限被内核kill掉。如果突然申请大量内存，会更早地被kill。VSZ一旦增长，就不会再减少，即使用不到，也会保持这个大小。\\n\\n比如一台8G内存的安卓7.1，每次分配50M内存，VSZ在接近4G、RSS接近3G时退出，但如果调大成先1.25G再750M，即使还不到2G的VSZ也会被kill。\\n\\n## free命令输出\\n\\n为什么 free 命令不直接称为 cache 而非要写成 buff/cache？ 这是因为缓冲区和页高速缓存的实现并非天生就是统一的。在 linux 内核 2.4 中才将它们统一。更早的内核中有两个独立的磁盘缓存：页高速缓存和缓冲区高速缓存。前者缓存页面，后者缓存缓冲区。当你知道了这些故事之后，输出中列的名称可能已经不再重要了。\\n\\n## 用ulimit限制\\n\\nVMEM和AS同义词，AS表示Area Space。python3.10如果只设置soft上限，超过后会收到异常但不会被kill。如果设置内存阈值时低于当前进程使用量，会收到SegmentFault错误然后退出。ulimit有soft和hard两个值，在控制上二者并没有区别，都会限制资源的使用，区别是：\\n\\n1. 无论何时，soft总是小于等于hard\\n2. 无论是超过了soft还是hard，操作都会被拒绝。结合第一点，这句话等价于：超过了soft限制，操作会被拒绝\\n3. 一个process可以修改当前process的soft或hard。但有一些要求：\\n * 修改后soft不能超过hard。也就是说soft增大时，不能超过hard；hard降低到比当前soft还小，那么soft也会随之降低。\\n * 非root或root进程都可以将soft可以在[0-hard]的范围内任意增加或降低。\\n * 非root进程可以降低hard，但不能增加hard。即nofile原来是1000，修改为了900，在修改为1000是不可能的。（单向，只能降不能升）\\n * root进程可以任意修改hard值。\\n\\nbash内建的ulimit默认显示soft，修改时同时影响soft和hard。"}'));jctx.push(JSON.parse('{"id": "211222", "tag": "data", "text": "# SQL的JOIN种类与选择\\n\\n## JOIN关联和WHERE谓词\\n\\n关系代数鼓励把重复的数据拆分，必然导致查询时要把分开的表再合并起来，这个合并的动作在关系代数里称为JOIN连接。连接分交叉连接（再细分出内连接）和外连接（再细分出左连接、右连接、全连接）。很重要的区别是交叉连接时，两张表是对等关系，而外连接有关注表和补充表的区分。回顾一下SQL规范，\\n\\n* SQL89时没有明确的JOIN语法，而是用逗号实现CROSS连接。\\n* SQL92时，出现JOIN。由于CROSS JOIN的语义就是笛卡尔积，因此不能有ON条件；而INNER JOIN是笛卡尔积的过滤，必须有ON条件。但MySQL实现得不规范，CROSS，INNER是等价的。JOIN是INNER的简写形式，自然也等价。此时的外连接语法是在从表后面带上`(+)`\\n* SQL99出现了LEFT和RIGHT连接，而且允许多张表用多个JOIN语句分段写，可读性更好。也因此目前常见的写法都是按SQL99写的\\n\\n交叉连接可以简写为 FROM a , b，结果是所有连接中最大的，实际应用一般都会选INNER，即带了ON条件。**外连接必须有ON语句**。一开始我经常把ON语句误写作WHERE，看其他人的代码，也发现这种错误，说明这对SQL掌握不深的人来说，可能是普遍现象，详细剖析下这两个关键字的语义区别。\\n\\n从简单的单表查询可知，WHERE是对结果表做过滤的谓词。JOIN动作是针对两张表的笛卡尔积，为了满足只取特定的JOIN结果，引入了ON谓词，专门用于多表JOIN过程中的判定，所以虽然WHERE和ON后面都可以跟比较语句，但两者的作用阶段是不同的。如果不用ON，只用WHERE最终也能得到正确结果，但是理论上一定会带来性能的额外开销：前面提到WHERE是针对单张表，意味着JOIN必须生成所有的结果集，得到这个结果集后，才能做WHERE过滤，这就会导致中间结果集过大，而ON恰恰能解决生成结果表过程匹配的问题。另外前面提到了优化器会把WHERE动作前置，但是并不会把WHERE条件作用于JOIN的过程中，所以说ON是JOIN的伴生动作，而WHERE是完全独立的另一个阶段，这两个阶段的顺序可以调换，但绝不会融合。\\n\\n连接首先分交叉连接和外连接，两者结果的约束是很大的。交叉连接的结果数是两张表的积，而外连接则是以一张表为准。\\n\\n外连接细分了LEFT、RIGHT、FULL这3种连接，LEFT OUTER JOIN可以简写成LEFT JOIN。左右只是方向不同，只需要实现一种就可以。左连接后面的限定条件*可能不生效*，结果既包含符合满足限定的连接行，也包含不满足限定的左(或右)行，这些不满足限定的行会由NULL来填充。这正是NULL必须存在的理论依据。所以即使表定义的某列规定了NOT NULL，但在连接结果还是会出现NULL，无法避免。两张表的LEFT JOIN的意义不太明显，如果有多张表会更好理解。\\n\\n考虑学生选课场景，学生和课之间是多对多的关系，表s记录了学号和学生的详细信息，表c记录了课程信息，表sc记录了学号和课程号的关联，如果要还原出学生姓名和课程名字，用这句\\n\\n```\\nselect s.Name,C.Cname from student_course as sc left join student as s on s.Sno=sc.Sno left join course as c on c.Cno=sc.Cno\\n```\\n\\n在计算过程中，用sc表作为左连接的左表，先替换学生信息并保持住课程的信息(暂时还无意义)，等第二次左连接的时候，用课程信息替换掉上一次左连接的内容，最终的select结果中不保存sc的任何内容。\\n\\n## JOIN的实现算法\\n\\n有单机和分布式，但是单机是基础，如下3种\\n\\n1. Nest Loop Join: 最简单但性能也最低，拿左表的每一行，从右表循环匹配，复杂度O(MxN)。过程中可以利用右表的索引来加速。\\n2. Sort Merge Join: 将两张表分别进行排序，然后再扫描的时候，因为顺序已经固定，所以就不需要做全表扫描，因此连接的复杂度是O(M+N)。不过考虑到对两张表排序的成本, 不能过分乐观。\\n3. Hash Join: 将小表的joinkey和关联内容提取出来，对joinkey列做hash，得到中间表保在在内存，对大表做scan并按同样的hash去内存中找到匹配记录\\n\\n对于常见的等值连接来说，如果小表的内容足够小，都会采用Hash的方式。要注意的是，这个足够小，并不是仅指joinkey，而是要把关联的内容一起算上看总大小。\\n\\nNest Loop尽管复杂度高，但在不等值连接的时候一般都用这种方式，因为Sort Merge要求表必须做排序，而排序的成本不低，所以权横后还是会选择用的Nest Loop。\\n\\n分布式场景怎么又增加了shuffle和broadcast这两种策略，和单机版组合理论上一共有6种策略。但是spark放弃了broadcost和sort merge组合，比hash性能不足，能力上又不如NestLoop，因此最终就只有5种策略。\\n\\n## semi和anti\\n\\n这两种都是从子查询优化中演化出来的，也间接说明原生几种join的表达力不足。\\n\\nleft semi join表示半的语义，具体有这几条\\n\\n1. 只能select左表数据，这也是semi最核心的含义\\n2. 结果不会受右表关联重复数据的影响，从第一点可以看出，右表只是用于关联，不参与结果构建，也就不会导致重复\\n3. 必须搭配left/right其中一种，不能单独semi，否则无法确定取哪一半\\n\\nanti表示的反，等效与先left再取右边为null，但写起来方便。可以left anti join，也可以直接t1 anti join t2取t1有而t2没有的数据。\\n\\n这两种更像子查询优化而不是独立语义，所以没在标准中找到，但部分实现会支持。"}'));jctx.push(JSON.parse('{"id": "211226", "tag": "os", "text": "# SU的执行过程与用户登陆机制\\n\\n起因是在ssh中执行\\"su xx;whoami\\"被卡住无法返回，于是看了源码后解开疑问。\\n\\nsu切换用户的核心逻辑如下\\n\\n```\\nfork();\\nif (pid==0) {\\n  setuid();\\n  exec(command);\\n}else {\\n  wait();\\n}\\n```\\n\\n解读一下就是su会创建子进程，父进程会等待子进程结束才会返回，而子进程默认执行的命令是登陆shell然后开始等待用户输入，对于ssh远程执行命令的我们来说显然不是想要的，办法就是\\"su xx -c \'command\'\\"，利用-c选项指定子进程要执行的命令，执行完结束回到主进程，就不会阻塞远程执行了。\\n\\n在分析的过程中，又引申出一些新的点\\n\\n如果一个用户在passwd配置的是nologin，执行su会报错，原因同上，默认不带参数触发了调用shell，但用户又是nologin，于是报错。这种用户只是用于配合特定软件执行功能。\\n\\n计算密码用到的crypt函数在unistd.h和crypt.h都有声明，但是只include unistd.h编译会告警，执行更是会core dump。原来是unistd.h被条件宏保护起来，于是编译器找不到声明，默认返回int，这就和定义不符，进而导致执行时core dump。"}'));jctx.push(JSON.parse('{"id": "220115", "tag": "lang", "text": "# Python的数据科学相关库介绍\\n\\nPython在数据科学领域能取得如此成功，离不开支撑它的众多库，但很多人即使用了这些库很久也不清楚这些库的历史和渊源。\\n\\n最早也是最基础的，应该是NumPy了，其前身发起于1995年的Numeric库（当时Python才面世6年），创始人Guido van Rossum也在其中扩充了Python语法（尤其是数组索引方式）。在演进的过程中，出现和竞品Numarray，Numeric在小规模上速度较快，而Numarray适合大量的数据。显然这种情况并不是大家想看到的，于是Travis Oliphant对这两个库做了统一，并最终在2006年发布了NumPy的1.0版本并持续演化至今。\\n\\nNumPy主要的功能是向量和矩阵运算，然而学术界的需求显然不止于此，于是2001年，Travis Oliphant, Eric Jones, Pearu Peterson等人将一些基于Numeric库的科学计算的程序，以SciPy的名字作为一个整体发布。随后不久IPython和Matplotlib也陆续发布，整个数据分析的生态就此奠定。2014年从IPython分出来的Jupyter也同样是数据分析的利器。\\n\\n大概是觉得NumPy还不够快，Oliphant在2012年启动Numba项目做jit加速。顺便说一句，Oliphant还是Anaconda的联合创始人，Numba也是Anaconda的资助项目。\\n\\n如果说NumPy/SciPy这一支是源于学术界的科学计算，另一个同样有名的库Pandas则源起自Wes McKinney于2008年在AQR资本管理公司做量化分析的工作需求，因此不仅具有强大数据提取、分析功能，还有众多的外部数据接入功能。\\n\\n为了追求性能，这些库都用了C或Cython实现，NumPy这一支由于和科学计算更强相关，还依赖BLAS/LAPACK这样的线性代数专用库。通常编译的NumPy会使用openblas，而Anaconda会采用inte免费提供性能更好的libmkl库实现BLAS接口（但不开源）。\\n\\n机器学习是科学计算和量化分析之外，另一个数据科学的重镇，David Cournapeau在2007年启动的scikits.learn项目，从名字就能看出是SciPy Toolkit，这个系列最有名的两个包是scikit-learn和scikit-image。顺带说一句，scikit-learn在Python语言中，是以import sklearn方式导入，导入名和包名不完全一样。\\n\\n前面提到这些库的底层实现用了C或Cython，这个Cython和平时用的CPython一字之差，是一个有着类似Python语法，但又有所扩充的语言。Cython语言的理念源于2002年的Pyrex（一个更好地编写Python扩展模块的语言），在2007年的时候，SageMath库的开发者不满于Pyrex的一些限制，提交了补丁给Pyrex的作者Greg Ewing，但被Ewing拒绝。于是Sage的开发者们fork出了SageX和Sage一起发布，但不久后他们发现单独的SageX很受欢迎，于是就把SageX剥离出来，并合并了lxml库，重新命名为Cython发展至今，而Pyrex在2010年发布了0.9.9后不再有新版本。使用Cython语法写的代码，最终会被C语言编译器生成二进制代码，在优化了性能的同时，还提供了相较C扩展Python模块更简单的写法。"}'));jctx.push(JSON.parse('{"id": "220201", "tag": "tool", "text": "# 压缩技术浅谈\\n\\n凡涉及存储和传输，就一定会涉及压缩，不同领域的需求和特点也各不同\\n\\n## 文本\\n\\n目前我们日常使用的各种压缩软件，追根溯源都是LZ77算法的衍生。看名字就知道它是Lempel和Ziv在1977年发明的算法。它是基于字典编码理论的一种实现，细分静态词典和动态词典，静态编码指编码器事先准备好词典，如果文本中的词不在词典中，则不进行压缩；动态词典则基于对文本的统计，LZ77是动态词典的开创者，同时也是当今各种泛用形文本压缩算法的原型。\\n\\nLZ77算法有滑动窗口和前向缓冲（Lookahead Buffer）两个概念，先读入的会放入滑动窗口，并作为动态词典的样本，同时对后续的文本尝试匹配，匹配成功则进行替换，不成功则进入滑动窗口用于后续替换，如此迭代直到整个文本被处理完。后来的研究者基于LZ77的理念，在实现细节上做了很多优化，也形成了如今种类繁多的改进算法。\\n\\n基于LZ77的理念，就比较好理解为什么许多软件会有多个最快压缩和最大压缩的级别可选，核心就是通过控制滑动窗口的大小和匹配的阈值来调节计算过程。比如大数据领域的Snappy算法就是控制匹配长度的下限为4来提升压缩速度，另外它还设置了每个压缩块长度32k，块之间互相独立，因此只用2个字节就能表示块中的偏移，滑动窗口每次移动4字节而不是LZ77的1字节，种种优化措施下来，Snappy的压缩速度非常可观。另一种用于互联网的Brotli算法，加入预定义字典的方式（有点动静结合的意思），提升压缩率。\\n\\n## 声音和图像\\n\\n由于人类自身感官的限制，声音和图像在压缩过程中是允许丢失一定精度（其实在数字化采样的时候，原始精度就已经丢失了），就有了无损与有损的划分。加之采样又有整数采样和浮点采样，所以音视频的压缩算法比文本要丰富得多。\\n\\n以音频采样为例，无损领域有两个非常有名的编码格式APE和FLAC，后者就只使用整数采样，又因为音频播放器往往都会用DSP解码，只使用整形对DSP来说无疑极大降低了硬件的要求，这也是FLAC现在比APE更主流的一个小因素。\\n\\n## zip文件头\\n\\nzip作为压缩格式虽然不是压缩比最高，但由于其诞生年代早没有专利保护，受到了操作系统和各种开源社区的广泛支持。有次遇到被7z压缩的文件用zip解压，报错PK版本过低，原来是magichead后面会有两个字节表示所需要解压软件的最低版本。而PK正是zip的发明者Phil Katz的首字母。"}'));jctx.push(JSON.parse('{"id": "220204", "tag": "net", "text": "# 分布式哈希技术摘录\\n\\n简称DHT，是一种广泛应用在分布式存储和P2P网络的技术概念，具体实现方式有多种。最初的4种实现CAN（内容可定址网络）、Chord、Pastry、Tapestry都发表于2001年，从此以后该领域的研究就日渐深入。\\n\\nDHT由于离散性、伸缩性、容错性的特性，有个关键的技术点：任一个节点只需要与系统中的部分节点沟通，当成员改变时，只有一部分工作必须要完成（数据或键的发送、刷新哈希表）。\\n\\n技术构成上，基础抽象是键空间，键空间分区则将键空间分成数个区域，整个系统中的节点被分到键空间的某个分区。分布式系统必然有频繁的节点进入和离开，就需要一种算法来减少节点变化对系统的影响，业界比较成熟的有3种\\n\\n1. 一致性哈希 consistent hash\\n2. 最高随机权重哈希 rendezvous hash\\n3. 近邻匹配哈希 locality preserving hash"}'));jctx.push(JSON.parse('{"id": "220312", "tag": "data", "text": "# 分布式计算在Spark上的实现\\n\\n分布式计算是个很早的课题，在一个集群环境下，必然会利用多个节点共同计算，注意不是同时计算，因为数据会有倾斜，只是会尽可能多地把节点利用起来。当前技术在对待多个节点的身份并不对等，都会分为主从类型，各自叫法不同\\n\\n| - | hadoop | spark | flink |\\n| ---- | ---- | ---- | ---- |\\n| 主节点 | JobTracker | Driver | JobManager |\\n| 从节点 | TaskTracker | Executor | TaskManager |\\n\\n## MapReduce与shuffle\\n\\nHadoop普及了MapReduce概念，其实map和reduce是很大的概念，Spark在宣传上最大的特点是RDD，但计算模型仍然可以划分为map和reduce两个阶段。经常在Spark听到shuffle术语，其实Hadoop也有这个概念。它是数据在Map Task和Reduce Task之间流动时的一种重新分配，是否进行shuffle由数据的依赖关系决定。shuffle有以下3种\\n\\n* 流式shuffle：左端Task每当处理完成一条数据，就序列化到缓存，并立刻传送给右端的Task。\\n* 批式shuffle：左端Task每当处理完成一条，序列化到缓存（缓存不够需要压到磁盘），但并不立刻传送给右端的Task，而是等到所有数据处理完成之后才传送给右端的Task。Hadoop和Spark采用的模式与此类似，不过是右端主动来取，而不是左端主动发送。\\n* 兼容shuffle：左端Task每当处理完成一条，序列化到缓存，等到缓存满了之后再传送给右端的Task。\\n\\n理论上说，在兼容shuffle模式下，如果缓存仅容纳一条记录，那么就是流式shuffle；如果缓存无限大，那么就是批式shuffle。实际中，通过设置缓存块超时值：超时值为0，则为流式处理，超时值无限大，则为批式处理。Flink可以设置数据传输的模式。\\n\\n## 内存划分\\n\\nHadoop饱受诟病的是节点间的数据交换依赖HDFS，节点把数据落盘导致速度缓慢，Spark和Flink都以不同的方式来解决该问题\\n\\n| - | 负责执行的内存块 | 负责缓存的内存块 | 其它内存块 |\\n| --- | --- | --- | --- |\\n| Spark | Execution Memory | Storage Memory | other |\\n| Flink | Memory Manager | Network Buffer Pool | Remaining Heap |\\n\\n其中负责缓存的内存块就是上一个节点计算完成并等待下一个节点来取数的的暂存区域，SparK由下游Task来取数据，而Flink是上游主动向下游发送数据，如果下游没有空间上游就不推送同时也会停止消费。因此Flink天然没有反压的问题。\\n\\n## 计算的序列化\\n\\n分布式计算的关键是调配代码和数据，由于数据量远大于代码，因此核心是**代码分发到各个数据节点**。由于计算的灵活性加上节点处理器的不确定性，要求代码是平台无关且可灵活序列化，在MR时代采用分发Jar来实现计算的分布，而Spark则利用Scala语言更进一步实现函数的分发。Spark为了扩大使用面，和Python做了深度整合，因此也必然要求Python代码能以函数为粒度实现编译和分发。Python原生的序列化库Pickle会把函数和类以引用的方式序列化，这在分布式环境下显然是不够的，于是最早由PiCloud公司（13年合并到了DropBox）扩展实现了CloudPickle库，它能将函数和类序列化成值，解决了分布式环境下的分发问题，当时的CloudPickle只能序列化Py2，Spark继续扩展使它能支持Py3和PyPy。\\n\\n理论上CloudPickle可以序列化任意Python对象，但Spark的计算框架要求Driver和Executor各司其职，因此不允许Python对SparkContext序列化（自然也就不允许对SparkSession序列化），具体的方式是在`__getnewargs__`方法抛异常来提示用户。这也解开了我最初对collect函数返回结果给Driver的疑问，既然collect不能在Executor调用，那么collect的发起者只能是Driver，结果当然也返回Driver。\\n\\nSpark和Python的交互在进程级别是socket通信加Arrow的内存列式存储，而语言层面则是udf装饰器，udf有几个重要的参数：函数本体、返回类型、执行类型和是否确定性。前两个很直观，解释下后两个参数。\\n\\nPySpark的执行类型有`BATCHED_SQL`、`SCALAR_PANDAS`、`GROUP_MAP`、`GROUP_AGG`、`WINDOW_MAP`多种。BATCHED是最简单的Row-at-a-time，而后面几种则是对Column或DataFrame进行处理与合并，效率会高一些。而确定性则是一个比较冷门的概念，输入输出确定的函数称为确定性，而即使输入确定输出也不确定的则称为不确定性，典型的如日期函数或统计总量。之所以要特意强调这点，是因为执行器会对确定的udf做一些优化合并，如果写的udf是非确定性但引擎不知道，可能会引起结果不正确。这个是理论上的解读，我没有实际遇到过，没有很深的理解。"}'));jctx.push(JSON.parse('{"id": "220405", "tag": "os", "text": "# Kubernetes笔记\\n\\nk8s不仅是软件，它还是虚拟化软件的组织体系，它定义了运行时、网络、存储的接口，自身实现则专注于容器的调度。\\n\\n## 体系标准\\n\\n* CRI: 包含运行时和镜像两个子集，由于k8s晚于docker，所以CRI规范和docker推出的OCI是兼容的\\n* CNI: 比较有名的有flanel和calico，据说flanel最简单，calico更灵活，我只见过calico，还要继续研究\\n* CSI: 不确定k8s自身的PV/PVC/StorageClass是否属于这个体系，只知道topolvm是一种实现\\n\\n## 基本概念\\n\\nPod是k8s的最小单元，将多个容器封装在一个整体，在Pod中Linux的各种namespace以及存储卷是共享的。Pod是豆荚的意思，每个容器则是一个豆子，多个豆子共同包裏在豆荚内，形象生动。\\n\\nk8s有JSON和YAML两种描述格式，JSON用于API，暂时还不了解。YAML则是配管。做helm应用模板是个高层封装，由于包含了很多内容不易理解，但最基础的内容并不复杂。YAML文件包含4个部分\\n\\n* apiVersion: 不考虑复杂特性填v1，但其实有不少于8个可选项\\n* kind: 类型非常丰富，而且当apiVersion变化后，取值范围也不一样\\n* metadata: 是个复合值，不可缺少的是name属性\\n* spec: 也是个复合值，属性最多的段。helm模板做的各种封装也针对spec\\n\\n## kind\\n\\n* Pod: 似乎生产环境不会用，必须太基础，但从学习的角度，这是k8s的第一步\\n* Service: 将一个或多个Pod封装，提供稳定的服务。包括Pod间负载均衡，服务级虚拟地址（但只限本机访问）\\n* ReplicaSet/Depolyment: Pod难免会挂掉，这种模式就保证了始终能运行指定数量的Pod\\n* StatefulSet: 相比Depolyment增加了持久化数据的能力。和Deployment是主要应用于生产环境的类型\\n* ReplicationController\\n* PersistentVolume/PersistentVolumeClaim: \\n\\nkubectl作用在整个集群上，找到某个pod在哪台物理机，就可以在那台机上用docker进入。"}'));jctx.push(JSON.parse('{"id": "220421", "tag": "data", "text": "# Flink引擎学习\\n\\n## 数据集\\n\\nFlink和Spark都采用了数据集（算子）+SQL方式提供编程接口，SQL上手简单但能力受限，而数据模型则相对难学但也更强大。\\n\\n|  |  基础会话（构建数据集） | 表会话（可执行SQL） | 数据集类型 |\\n| --- | --- | --- | --- |\\n| Spark | SparkContext | SparkSession | RDD |\\n| Flink | StreamExecutionEnvironment | StreamTableEnvironment | DataStream |\\n\\n既然是数据集，肯定就有数据来源，可以从文件或表映射，也可以从无限流的连接映射出来，一旦映射后就只能基于这个原始的映射源计算。\\n\\n而SQL语句都不依赖数据集，属于会话级的接口，因为SQL是在一段文本中操作多个数据源，所以显然不会被绑定到某个特定的数据集。\\n\\nStreamTableEnvironment能提供Table和DataStream之间的互转。同样的，基本废弃不用的BatchTableEnvironment则提供了DataSet和Table的互转能力，只是随着DataSet的逐渐消亡，可以不用管这种运行环境。\\n\\n从Flink 1.9开始有两种planner：old 和 blink。blink实现了流批一体，因此将批处理视为流式处理的特殊情况。所以blink不支持表和DataSet之间的转换，批处理作业将不转换为DataSet应用程序，而是跟流处理一样，转换为DataStream程序来处理。因为流批统一，Blink planner也不支持BatchTableSource，而使用有界的StreamTableSource代替。\\n\\nTable 总是与特定的 TableEnvironment 绑定。不能在同一条查询中使用不同 TableEnvironment 中的表，例如对它们进行 join 或 union 操作。\\n\\nTable API中表到DataStream有两种模式：\\n\\n* 追加模式（Append Mode）：用于表只会被插入（Insert）操作更改的场景。\\n* 撤回模式（Retract Mode）:用于任何场景。有些类似于更新模式中Retract模式，它只有Insert和Delete两类操作。得到的数据会增加一个Boolean类型的标识位（返回的第一个字段），用它来表示到底是新增的数据（Insert），还是被删除的数据（老数据，Delete）。\\n\\n## 运行时与调度\\n\\n采用经典的Master-Work模型，Master会创建App进程，包含了三个组件，Dispatcher、ResourceManager和JobManager。Dispatch接收客户端请求，并创建出Job。Job根据任务生成Graph并向Resource申请资源。Resource有多种实现，可以是Local，也可以借由Yarn或K8S管理资源。\\n\\n每个Work（TaskManager）是一个JVM进程，进程中的task将共享TCP连接和心跳消息。启动的TaskExecutor跑在空闲的TaskSlot（线程）上，一个拥有3个slot的Task，会将内存平均分成三份给每个slot，slot数量通常和CPU数相同。Executor和Slot都通过Resource来分配。\\n\\n由于流批一体，Flink的调度策略也适用于不同类型的计算，有三种实现：\\n\\n* Eager：适用于流计算，同时调度所有的task，对数据不终结的流而言，这种方式很自然\\n* LazyFromSources：适用于批处理，当上游数据处理完，调度下游数据。如果不lazy的话，计算效率会差\\n* PipelinedRegion：以流水线的局部为粒度进行调度\\n\\n### 数据传输\\n\\nRegion要解决什么问题？这就要回到适合流批作业的不同数据传输机制（shuffle）\\n\\n* Pipeline： 上下游Task之间直接通过Netty进行网络传输，因此需要上下游同时运行，适合流。又细分了是否有Bounded模式，区别在于是否限制网络缓冲的数量\\n* Blocking： 上游Task会首先将数据进行缓存，下游Task去取数时上游作业甚至可以停掉，互相不依赖对方的存活，适合批\\n\\n基于这两种类型的传输，Flink将ExecutionGraph中使用Pipeline方式的Task子图叫做Region，从而将整个Graph划分为多个子图。\\n\\nPipeline方式也存在缓存，但又要考虑实时性，于是就有了基于信用的流量控制机制（Credit-Based），来降低延迟，工作原理：\\n\\n1. 发送端将自己缓冲区积压的数据大小加入到发送的数据当中，一并发给接收端\\n2. 接收端接收到发送端发过来数据之后，根据其缓冲区积压的数据大小，生成一个信用值，并将信用值返回给发送端\\n3. 发送端会根据信用值所限定的范围，尽可能的多传输缓冲区数据\\n\\n如此，每个发送端都被授予一个信用值，如果某发送端数据积压过多，那么它所被授予的信用值，就能够使之尽量多发送数据，从而减少积压量，这种机制会在出现数据倾斜时很好的分配网络资源。\\n\\n除了基于信用的机制外，任务链机制更能直接减少数据传输的开销，如果上下游两个Task的并行度相同并且满足其它条件，会将这两个Task合并，直接在内存中复用数据。\\n"}'));jctx.push(JSON.parse('{"id": "220721", "tag": "data", "text": "# spark性能调优记录\\n\\n## 资源配置\\n\\n和运行速度相关度最大的是instance数量，我做的业务因为数据量在千万以内，内存只有6G，实例数只会分配个位数。实测发现2个比1个提升明显（至少50%以上），3个比2个有提升但幅度开始减少（30%左右），再往上提升就更少了。而内存在保证不OOM的情况下，多给也只会减少JVM的GC时间，对性能没什么提升。\\n\\n## udf和udtf\\n\\n同行逻辑最初的版本是用udf做，尽管经过数次优化，但始终有内存占用过大问题，计算过程是先对点位分组，然后把每组的数据`collect_list`后交给udf来计算，pyspark的udf每次传递100条数据，到了这个逻辑传递的其实是100个分组，内存肯定很高。但细想会发现这其实这是个标准的udtf过程，于是想到换用udtf每次传递1个分组，内存肯定可以降下来。开始还担心由于传递次数变多，而且udtf得到的是pandas dataframe，需要转换成原生的list，会有性能下降，实测不仅内存确实减少，而且性能提升2倍左右。\\n\\n这就涉及一个apache的跨项目的arrow库，所传随着大数据组件越来越多，组件间的数据传递成为一个大的开销，社区当然有人意识到这个问题，于是组织起来开发了arrow这个高效的序列化库，经过arrow序列化后的库，不需要反序列化，收到后放到内存就能直接用，udtf利用了arrow库，而udf并没有，说真的arrow对性能有这么大的提升，真的是没有想到。\\n\\n换成udtf后在k8s会遇到程序终止问题，查看了instance内存，虚拟内存竟然用了9G。经人指点发现是numpy的内存占用受`OMP_NUM_THREADS`影响，默认和CPU核数一样，服务器40核所以内存占用极大。但是我开始验的时候，导入numpy只会多出200M左右的虚拟内存，过了一天意识到验证用的是anaconda，而pyspark是开源的python，开源版numpy依赖的openblas会依赖OpenMP，从环境变量名也可以看出就是OpenMP的行为，而anaconda的并行库是intel的MKL，不会根据CPU核创建这么多线程。\\n\\nPySpark内存的使用分3部分\\n\\n* jvm: 主要计算在这里完成\\n* overhead: 发生shuffle时，netty要用这块内存缓存网络数据\\n* python: 使用udf或rdd会占用\\n\\n## 查看UI\\n\\n正在运行中的代码，第一个job页会显示active job，下面还会有很多complete job。每个job会被分拆成一到多个task，task又会分到不同的instance执行，所以job执行完就表示代码中的一段逻辑完全运行完成，不用担心是否只是部分instance运行完。看tasks往往会看到很多标记了skipped，这里有很多原因：一方面可能是数据被缓存，所以跳过，另一方面也可能是数据倾斜，让引擎以为需要这么多task，但实际执行后发现没有数据，于是就跳过了。job和代码的映射关系还不清楚，但只要代码不改，job的数量就不会变化。"}'));jctx.push(JSON.parse('{"id": "221019", "tag": "lang", "text": "# promise和future的区别\\n\\npromise/future是指差不多的东西，只是不同语言的叫法不同。少数语言可能同时有promise/future并有差异，如果同时有两者，一般future指获取值的能力（只读视图），可翻译为「期值」（future作为金融术语即为「期货」），promise指设置值的能力，可翻译为「约定」。这些术语与cancel没有关系。（这个误解可能来自于早期的DOM Future草案有cancel而后来改名为Promise时同时删去了cancel？）\\n\\n为什么promise不支持cancel？从用例需求的角度，当然是有cancel和progress的需求的，所以原本DOM future的草案里也有这些能力，但JS标准化要考虑的问题比较多。绝大多数时候只会推进大家有一致意见的东西。像cancel的能力后来DOM是改用了AbortSignal机制，估计将来JS也是会标准化的（虽然已经延宕了很久，目前也还不知道到底什么时候会推进）。而progress的能力则由DOM ProgressEvent来完成了。\\n\\n早期JS社区的某些promise库则使用promise/deferred来表示future/promise。JS后来流行并标准化的promise的设计是两种能力的合体，promise本身的接口（then）提供获取值的能力，而promise构造器工厂中的resolve/reject函数提供设置值的能力，不再有单独的deferred接口。\\n\\n对于合体型的promise/future概念，我提出了「期约」作为译名（一个原因是「期约」作为「期/约」的合体可对应future/promise的合体，这样就不必在不同语言中因为采用future还是promise作为术语的不同而译名也不同），为《 JavaScript高级程序设计（第4版）》中译本所采用。\\n\\n在 Promise 提出之前，除了规范里存在事件循环，普通前端是基本不讨论事件循环这个概念的，那就更不用说 microtask 了。\\n\\n的确是 Promise 让这两个知识点成为焦点，为了解释那些代码执行顺序问题。但 microtask 是要比 Promise 的提出更早一些，最早它是为了定义 MutationObserver 的行为而产生的，只存在于 HTML 和 DOM 规范里。\\n\\n在 ES6 里想要给 JS 加上异步的时候，最早也不是为了 Promise，而是 Object.observe()， V8 为实现 Object.observe 加上了类似 microtask queue 的机制，当时 ES6 没有打算加 Promise，而是 DOM 规范想要加一个类似功能的名为 Future 的东西，后来决定直接加在 JS 里，为了 nodejs 里也能用，改名 Promise，DOM 里就不搞了。"}'));jctx.push(JSON.parse('{"id": "221119", "tag": "lang", "text": "# continuation的理解\\n\\nScheme 和SmallTalk并不采用堆栈来保存上下文，而是将这些信息保存在continuation记录中。这些continuation记录和堆栈的Frame的区别在于，它不采用后入先出的线性方式，所有continuation记录被组成一棵树（或者图），从一个函数调用另一个函数就等于给当前节点生成一个子节点，然后把系统寄存器移动到这个子节点。一个函数的退出等于从当前节点退回到父节点。这些节点的空间回收是由垃圾回收器(garbage collection)来管理。如果没有引用这个continuation记录，则它就是可以被删除的。这样的调用方式和堆栈方式相比，它可以在一个函数内的任何位置储存自己的上下文信息，然后，在以后某个适当的时刻，从其它的任何一个函数里面返回到自己现在的位置。\\n\\n由于每次延续被恢复的位置不同，可以理解为函数拥有了多个不同的入口点，从这个角度可以和协程一起理解。 [[协程剖析]]\\n\\nPython的yield教程都说是生成器，思考其实质，函数的上下文被保护，从而可以被多次调用，精神层面和continuation是一脉相承，而且加入了send和throw函数，也更方便易用。\\n\\nlua表面上只有协程，但其实和continuation是相通的。[[Lua的Continuation]]"}'));jctx.push(JSON.parse('{"id": "221122", "tag": "tool", "text": "# 打包软件的故事\\n\\n起因是想解压rpm和deb包，发现并不是zip压缩，rpm需要rpm2cpio工具转成cpio做进一步处理，而deb要用ar x命令解压得到内容。cpio和ar都不是最常见的打包软件，于是诱发我去了解背后的原委。\\n\\n最为人熟知的打包软件应该是tar了，有史可查最早在1978年随着system 7发布，后来也搭载在III和V以及BSD一起发布。tar会递归地遍历目录然后打包，这个递归动作不能取消，由于命令行操作的便利性，tar成了最流行的打包工具。tar有很多变体，支持的格式不尽相同，后来出了POSIX规范，至少我没有遇到需要特定版本的tar才能解析的问题。\\n\\ncpio是copy in copy out的简称，不支持递归查找源始文件，所以不适合命令行，通常提供文件清单或配合find一起用。常见的似乎只有rpm和initrd会用cpio方式。\\n\\n如果说tar和cpio还算打包软件，ar则更多的归属到编译体系。ar最常见的用法，是把多个.o文件合并成.a，并用ranlib给.a添加符号索引，进而加快链接速度。具备把多文件合并的功能，更偏向cpio的定位。把deb文件解开后，得到数个tar文件，不明白为什么会选择这种方式。"}'));jctx.push(JSON.parse('{"id": "221123", "tag": "os", "text": "# 修复操作系统问题记录\\n\\n## 忘记root密码\\n\\n只适用于centos，在选择内核列表时，按e进入编辑模式，在linux16命令的参数中加入init=/bin/sh进入单用户模式，执行mount remount后，用passwd可以重置，最后用exec /sbin/init重启。"}'));jctx.push(JSON.parse('{"id": "221201", "tag": "security", "text": "# 公私钥格式的认识\\n\\n公私钥对做为一个概念，最后一定会有形式用来记录与传输，以RSA为例展开讲讲。\\n\\nRSA公钥由n和e两个数字构成，e通常是65537，重要的是n，这是一个非常大的质数。一些函数库会用类甚至数组来表示RSA公钥。但这只是内存中的表示，并不适合序列化，又分ssh和ssl两个流派，而ssh的两个版本又不同。\\n\\n## SSH-1\\n\\nSSH 1协议只支持 RSA 算法，所以公钥也为RSA特化，格式为所有字段以单个空格符分隔，各字段依次为选项、位数、指数、系数、注释。第一个字段是可选的，表示该条目（行）是否以数字开头，选项字段不会以数字开头。最后一个字段注释，如果在生成密钥时没有给定注释，默认注释为密钥的创建者，注释仅仅是提供给用户查看密钥时作为一个辨识标记，在 SSH 使用中没有任何作用。\\n\\n```\\n2048 65537 1234 username@hostname\\n```\\n\\n## SSH-2\\n\\n非对称加密肯定不能局限于RSA，所以公钥格式也做了改变。所有字段仍以单个空格符分隔，各字段依次为选项、密钥类型（keytype）、base64编码后的密钥、注释。第一个字段是可选的，表示该条目（行）是否以数字开头，选项字段不会以数字开头。最后一个字段注释同样只起提示作用。\\n\\n密钥类型（keytype）可能是 ecdsa-sha2-nistp256, ecdsa-sha2-nistp384, ecdsa-sha2-nistp521, ssh-ed25519, ssh-dss 或 ssh-rsa。\\n\\n```\\nssh-rsa AAAAB3 username@hostname\\n```\\n\\n除这种格式外，ssh还支持IETF SECSH 公钥格式，像这样\\n\\n```\\n---- BEGIN SSH2 PUBLIC KEY ----\\nAAAAB3 username@hostname\\n---- END SSH2 PUBLIC KEY ----\\n```\\n\\n## SSL\\n\\nssl工具的默认编码方式默认就是这种带BEGIN和END页眉页脚的块，块的内容称为PEM格式Privacy Enhanced Mail，是一种特殊的base64。从两端可以很清楚的看出内容的类型。RSA公钥类型是RSA PUBLIC KEY。没有任何前缀的PUBLIC KEY则代表X509公钥。\\n\\n## PKCS#8\\n\\n私钥可以用PKCS8方式存储。私钥首先会使用PKCS#5的标准进行加密，然后将其进行base64编码，转换成为PEM格式进行存储。\\n\\n## Java语境下的keystore与truststore\\n\\nSSL/TLS通信时，会用到密钥库（keystore）和信任库（truststore）。\\n\\n* KeyStore-密钥库\\n\\nKeyStore存储私钥和相关的证书，或者相关的证书链（由客户证书和一个或多个证书颁发机构CA证书组成）。它通常用于表明通信一方的身份。\\n\\n* TrustStore-信任库\\n\\nTrustStore则相反，密钥库通常用于保存标识自身身份的证书，而信任库用于保存识别他人(第三方)身份的证书，用于校验与我们通信的第三方是否可信。\\n\\nJava的密钥库机制有5种格式：JKS(java key store)、PKCS12(前身是微软的.pfx，也有.p12)、JCEKS、BKS、UBER。前两种比较常见，JDK8之前，默认格式为私有的JKS；从JDK9开始，默认格式为开放的PKCS12。\\n\\njks是java用的存储密钥的容器。可以同时容纳n个公钥或私钥，后缀一般是.jks或者.keystore或.truststore等，各个公司或机构叫法不同而已。不管什么后缀，它还是一个容器，比如把只包含\\"受信任的公钥\\"的容器存成.truststore文件等。\\n\\n用jdk/bin目录下的keytool对其进行查看，导入，导出，删除，修改密码等各种操作。也可以对jks文件加密码，输入正确才可以操作此容器中密钥。\\n\\n## 文件体现\\n\\n配置Web Server时往往也要有Private Key File和Certificate File，可以分开也可以用cat或openssl合并为1个pem或pfx文件。客户端通常不配置，因为加密由服务端的Private Key决定，但有些客户端会不信任服务端提供的Certificate，此时必须在客户端也配置相同的文件。\\n\\n遇到过一个问题，想通过hive外部表的方式向ES写数据，但开源的jar包连接开启https的ES总是报错，原因是不信任服务端证书。在python中通过关闭SSL认证规避了该问题，但jar包并没有提供关闭SSL认证功能。最终只能下载服务端的证书，并配置truststore路径才通过。\\n\\n## 题外话\\n\\n虽然ssh的公钥格式自成一派，但它的私钥却遵循了PEM格式，标识符OPENSSH PRIVATE KEY。也意味着openssl工具可以操作ssh私钥。\\n\\nPKCS是Public-Key Cryptography Standards的意思，它是RSA公司提出的公司私有规范，共15条。但由于RSA公司的行业影响力大，部分规范也被RFC和openssl软件支持。除了#8外，#7和#12是影响很大的标准，PKCS12可以看做是PKCS7的扩展，在PKCS12中可以存储证书，私钥或者CRL。和PKCS7相比，PKCS12可以额外存储私钥。"}'));jctx.push(JSON.parse('{"id": "221218", "tag": "net", "text": "# 对netcat的探索\\n\\n有些很弱的主机无法安装sshd，又需要远程操作时，完全可以用nc。\\n\\n大多数教程讲nc用GNU版本，用-e选项就能反弹shell，但为了学习原理，不妨用更原始的下面这种方式。\\n\\n`cat tmpf | bash 2>&1 | /system/bin/toybox nc -l -p 6666 > tmpf`\\n\\n即使是toybox自带的nc，都能正常工作。来解释下原理。\\n\\nnc是把cat的功能应用在socket上，而cat的原意除了打印，首先是用来concatenate files。平时我们操作的是文件，但在nc的场景，更重要的是concatenate socket and stdin/out。所以我们倒着看上面的命令，nc监听端口后，将来自这个端口的输入输出消息，和终端的stdin/out绑定；绑定后再重定向到fifo文件。\\n\\n其实真正要绑定的是nc监听的端口和shell，但管道符只能单向流，所以最开始引入fifo文件，利用cat把fifo的输出端绑给shell，最后的时候把fifo的输入端绑给nc，借fifo把nc和shell间的双向循环变成形式上的三角循环，虽然不够优雅，却非常巧妙。"}'));jctx.push(JSON.parse('{"id": "230208", "tag": "web", "text": "# 两个小微JS库的使用\\n\\n因为网站重构，本来不想使用JS用了htmx库，奈何实在拉胯，只得重新用JS，但不想用太复杂的库遂选了两个，一个MVVM一个类jQuery库，记录一些JS的惯用法。\\n\\n## psQuery\\n\\n说说$变量的构造，在库的开始定义一个单变量的函数，在函数定义完成后惯例性的调用，此时传入this参数（对应window）。然后在代码中用了句`n.$||(n.$=t)`。这个n就是this，t则是构建好的类jQuery对象，先判断全局是否已经定义$变量，没有就把自己挂接上去。\\n\\n## DB.js\\n\\nMVVM库，希望监听的DOM元素增加类似`db=\\"text:spanText,class:red\\"`属性。当你手动执行DB.scanHTML后，会扫描document所有节点，如果有db属性就会用DB.observable转化成可监听对象，然后把db属性去掉。接下来操作js对象就能自动触发DOM元素的变化。只要保证js的对象名，和db属性某个冒号后的名字一样，就能绑定。\\n\\n单纯的绑定没大价值，有意义的是compute属性，实现了一个元素依赖其它元素的自动更新。"}'));jctx.push(JSON.parse('{"id": "230601", "tag": "net", "text": "# CDN的来源与应用\\n\\n万维网自1990年推出以来，已从简单的客户端服务器模型演变为复杂的分布式体系结构，在演化过程中，CDN是其中很重要的基础设施。最早的CDN公司Akamai诞生于1998年，虽然经历了二十多年的发展，但是至今没有形成完整的范，各家的具体实现也不一样。CDN的核心点有两个，一个是缓存，一个是回源。\\n\\n* 缓存：就是把资源复制一份到CDN服务器上的过程，缓存的管理需要协议，主要有ICP、HTCP、CARP。\\n* 回源：当CDN发现自己没有这个资源（一般是缓存的数据过期了），转头向根服务器（或者它的上层服务器）去要这个资源的过程。\\n\\n## CDN协议\\n\\nICP(internet cache protocol)：最初的缓存控制协议，参考RFC2186。基于UDP协议实现的轻量级的缓存内部通信协议，被用于在Cache服务器之间相互查询web资源信息，以确定当前被请求的资源是否在其他服务器上。一个缓存服务器发送ICP请求给它的邻居，邻居会用ICP消息响应，如果有的话就是HIT无就是MISS。\\n\\nHTCP(hypertext caching protocol)：RFC2756，管理一组http cache服务器并监控相关的缓存活动。该协议机制与ICP类似，都是通过向邻居服务器发送查询请求并获得应答来反映web对象在集群中的缓存情况。但设计ICP协议时考虑的是HTTP/0.9协议，查询资源是否存在时只允许缓存发送URL。HTTP版本1.0和1.1引入了很多新的请求首部，这些首部可以和URL一起用来确定文件是否匹配。只在请求中发送URL可能无法得到精确的响应，而HTCP允许兄弟缓存之间通过URL和所有的请求及响应首部来相互查询文档是否存在，以降低错误命中的可能。另外HTCP还允许兄弟缓存监视或请求在对方的缓存中添加或删除所选中的文档，并修改对方已缓存文档的缓存策略。\\n\\nCARP(cache array routinig protocol)：CARP是ICP的一个替代品，通过建立HASH函数用于划分cache服务器集群的URL空间，通过HASH算法将用户对URL的请求准确路由到服务器阵列中的任一成员上，消除了阵列中重复缓存数据，实现了对cache资源的高效定位。CARP和ICP都允许管理者通过使用多个代理服务器来提高性能。优势：\\n\\n1. 无需资源查询和应答的过程，降低网络传输开销\\n2. 消除了重复缓存数据，每份url保存一份，节约空间\\n3. 具有更好的扩展性，可以灵活的增删服务器节点\\n\\n额外说一句，CARP也是共享地址冗余协议的缩写（Common Address Redundancy Protocol），是一种能让多台网上主机共享同一个IP地址的协议。它的设计目标在于为故障移转（failover）提供冗余的主机作为备援。\\n"}'));jctx.push(JSON.parse('{"id": "230625", "tag": "tool", "text": "# Markdown的渊源与流派\\n\\n## 历史与标准\\n\\nJohn Gruber和Aaron Swartz（测试）于2004年发明了Makrdown编辑格式，它最初是定位给web写作者，因此首要的功能就是markdown到html转换。由于简洁的设计，在网络上受到极大的追捧，因为面向html的设计初衷，它的元素也分为块级元素和行内元素。开始的功能并不完整，其实这也不是什么问题，但是Gruber认为没有一种规范能满足所有人的需求，也不愿意扩展Markdown语法，在发布同年的12月，版本更新到1.0.1就不再迭代。后来社区想成立一个standard markdown的论坛也被他拒绝了。最终导致了Markdown演变到今天，虽然已是互联网最流行的书写格式，但五花八门的扩展也始终是一个无法消除的问题。\\n\\nGruber定义了一套非形式化的语法，并且提供了markdown.pl脚本来验证格式的正确性，但毕竟不是严谨的定义。从2012年开始Jeff Atwood就提议要标准化地描述Markdown格式，最终在2014年，由UC Berkley的哲学教授John MacFarlane作为主要编写者，共同确定CommonMark成了至今最完整和详实的规范定义，虽然没有达到1.0，但已经被众多网站接受。CommonMark和其它流派不同，并不强调功能的扩展，而在明确定义诸如优先级、缩进、嵌套等容易引起歧义的地方。\\n\\n## 各种流派\\n\\n虽然有众多的扩展变体，RFC7764还是记录了几个比较流行的方言\\n\\n### GitHub Flavored Markdown\\n\\nGitHub在2017年发布了基于CommonMark，有形式化描述的扩展标准。这个也许是接受度最广，甚至个人觉得有可能成为事实标准的增强版。\\n\\n### PHP Markdown Extra\\n\\n虽然名字带了PHP，但也有Ruby(Maruku)和Python Markdown实现。区块代码和表格的扩展语法和GFM一样，接受度也比较高。\\n\\n### Pandoc\\n\\n与其说是一种markdown流派，更确切的定义是格式转换界的顶峰，作者就是上文提到的CommonMark的发起者MacFarlane。它使用的语法和GFM不太一样，其扩展语法格式的流行程度远不如这个软件本身。\\n\\n### Kramdown\\n\\n据作者自称是最快的纯Ruby实现，支持输出LaTeX，同时还支持XML2RFC格式，我猜是不是因为这个特性所以被RFC收录了。\\n\\n## 语法体会\\n\\n开始使用tiddly，需要把md的语法平转成WikiText，为此还写了个小工具。好在除了标题和有序列表外，我自己常用的都可以做到一样，但还是对以往写的内容做了些调整\\n\\n1. 标题用#语法，不要用==或--，因为后者在标题行的后一行，转换时会稍麻烦\\n1. 行内引用和块引用的区别是，块引用在code标签外面还包了一层pre标签，由此改样式必须要配置pre code父子语法 [[CSS的一些理解]]\\n1. 少用md的`*word*`语法，浏览器默认的斜体样式渲染中文不好，且容易误匹配\\n1. 用了md至少5年以上，才知道引用语法是>"}'));jctx.push(JSON.parse('{"id": "231101", "tag": "web", "text": "# 不合时宜的CSS\\n\\n在Web领域HTML/CSS/JavaScript三者各司其职似乎被广泛认可，三剑客各自独立产生，最终又一起提供页面能力，人们自然要给这样一种组合方式一个说辞，于是便产生了现在广为接受的分层说法。理念很美好但它们其实都有互相重叠的地方，而且三者间的互操作性其实并不好。但为什么传统的GUI编程却没有一个采用这种方式呢？\\n\\n看Java Swing、Andorid、Flutter等方案，或者是纯代码，或者是轻度引入某种布局DSL，至少GUI领域不认为布局、样式、逻辑要严格分离，更多的是统一在一起，由一个体系进行描述。或许回答这个问题还是从历史中找答案。\\n\\nHTML的首个版本出现于1991年，彼时它被发明的初衷还是文档显示和链接，不需用户交互能力，渲染结果完全交给终端软件。1993年6月，Robert Raisch在www-talk的邮件列表给了一个提案，用一种名为RRP的方式来指定元素样式。但是Mosaic浏览器并没有接受该提案。之后围绕着样式语言的定义经过了很多讨论，甚至出现过一个叫DSSSL的类scheme语法的图灵完备方案，最终经多方博弈后，终于在1996年11月发布了CSS规范的第一版，然后由于实现的复杂性，直到2000年3月才有浏览器完整支持它。而JS则是1995年12月首次推向市场。虽然看起来JS比CSS要早，但JS只是NetScape/Brendan Eich的单一行为，而CSS的讨论时间和牵涉方要充分得多。\\n\\n随着Web应用愈发普遍，Web早已不再只是文档展现，而是事实上的应用化了，而且应用的规模还明显变得越来越复杂。从这个角度重新审视，再将三者按功能分层就显得有些不合时宜，这也是20年代以来前端组件化被普遍认可，CSS也更为的作为组件的一个切面而不是单独的一层。\\n\\nCSS的值通过HTML的class属性起作用，但class在设计之初其实承载了更通用的功能，并不是为仅用于CSS。随着HTML5定义了更多的语义化标签，一定程度上削弱了class的设计目的，而组件化时代class的表意作用进一步削弱，才演变成今天这种只用于附加CSS的功能。\\n"}'));jctx.push(JSON.parse('{"id": "231110", "tag": "web", "text": "# DOM理解\\n\\nJS作为一门编程语言，想要操作文本形式的HTML，必然要把HTML结构化，DOM就是将HTML的文本进行标准化的产物。由于HTML天然的树状层级特性，转化为DOM是很自然的，但这不代表两者等价，这里就展开谈谈一些概念和细节。\\n\\n## 节点Node和元素Element的异同\\n\\n一句话概括：结点不一定是元素，而1个元素一定是1个结点。\\n\\n节点有nodeType属性，最常见的有：1元素、2属性、3文本，还有别的类型，比如代表整个HTML的document节点，类型是9。还有注释(8)、!DOCTYPE(10)等类型。\\n\\n元素是编程时打交道最多的，入门课程就会学的getElementById方法，从名字就告诉我们获取的是DOM元素，基于某个元素，通过childNodes获取到元素下的子节点。一个简单的P元素只有1个类型为Text的child节点。\\n\\nDOM建立在JS语言上，因此有类型（而HTML由于是文本，可以认为只有string一种类型）。结合前面提到的概念，类型体系是这样\\n\\n```\\nObject -> EventTarget -> Node -> Element -> HTMLElement -> HTMLInputElement\\n```\\n\\n## HTML attribute和DOM property\\n\\n两者大多数时候可以不区分地使用，列举一些主要的差异\\n\\n1. 写HTML时，可以给元素设置非标的attribute，比如`<p foo=\\"bar\\">`是合法的；但是这些非标attribute在映射为DOM时，如果用.foo访问会得到undefined，但可以用.getAttribute(\\"foo\\")得到值。自定义attribute按照HTML5规范，建议命名成`data-*`，也有些项目会命名成`x-*`。\\n1. HTML以宽松著称，因此大小写不敏感，但DOM既然基于JS，肯定要区分大小写，在上面的例子中，由于foo是在HTML中定义的，所以大小写不敏感，用.getAttribute(\\"FOO\\")也能得到值。\\n1. attribute和property会自动同步，但input.value是唯一的例外，它的同步是单身的attribute -> property，只修改.value不会改变attribute。\\n"}'));jctx.push(JSON.parse('{"id": "231229", "tag": "data", "text": "# 用离线计算工具实现流式计算的思考\\n\\n## 离线计算思维的缺陷\\n\\n传统的处理逻辑是：每日凌晨以后开始对上一个自然日的数据进行归档、计算，并在白天之前完成计算。也许对互联网公司的业务场景，这样是合适且够用的，但到了感知数据场景，存在几个严重的不足\\n\\n1. 数据必然有延迟，导致每日凌晨以后，上一个自然日的数据往往没有齐备，这时启动计算肯定是不完备的\\n2. 数据计算部署在甲方且没有运维，一旦某天异常中断，下一次自动触发的计算结果会不正确\\n\\n用流计算能解决这两个问题吗？理论上可以，但这又牵涉到团队技能栈、计算资源开销、切换等许多问题，加上数据计算(hadoop)和数据使用(ES/MySQL)在不同的存储，而且数量都很大，更新的成本很高。\\n\\n## 解决办法\\n\\n计算需要内存，因此一定是有界的。要想解决问题2，每次的计算必须要知道上一次的计算边界，并延续计算，而不是现在这种被trigger_time定义的计算。\\n\\n外部存储选什么？常见的MySQL、Redis都会增加部署资源，考虑到读写便利性和记录的数量不大，可以使用ZNode来存储上一次计算状态。\\n\\n为了支持任意时间打断计算并恢复，一天一次触发会导致较多的时间被浪费，但是如果改为6小时，会不会导致白天清空数据并重推，需要考虑。\\n\\n由于计算模式的变化，出现两种方式：1次1天和1次多天。"}'));jctx.push(JSON.parse('{"id": "240109", "tag": "book", "text": "# 西游\\n\\n## 唐僧丧徒\\n\\n离开大唐时，唐僧带了两个自己信任的徒弟，但如来并不想看到唐僧有自己的私人班底，于是指挥手下变作妖精吃了这两个徒弟。太白金星觉得太过火，救了唐僧。随后唐僧独自一人见了一个猎户，还成功超度其亡父，大概从这里开始，唐僧也明白了所谓小乘经不能渡人其实是谎话\\n\\n## 观音禅院黑熊精\\n\\n悟空随唐僧后第一战，打得难解难分。观音见已有悟空，遂挪用了如来给的禁箍，将黑熊精收为手下\\n\\n## 镇元大仙人参果\\n\\n虽为地仙但奈何门派力微，借人参果攒局与悟空结拜，更借果树被推倒，得取经团队人情，得以提升门派地位\\n\\n## 三打白骨精\\n\\n此妖本名尸魔，但妖不算作难，而是悟空负气出走才是难。此时取经团队刚凑齐，内部并不稳定，没遇上厉害妖魔，唐僧也不觉得悟空本领，故借此机把他赶走，八戒沙僧也觉得还有进步空间，共同挤兑走悟空。\\n\\n## 奎木狼与宝象国\\n\\n经历白骨精后，悟空回到花果山，却见其手下被猎户屠戮，杀千余人。取经团队遇黄袍怪奎木狼，八戒沙僧完全不够看。唐僧在朝堂上被变成老虎，小白龙觉得自己可以立功，于是有了全书唯一的出手，可惜仍是不敌，只得托八戒找回悟空，白龙后面再没有主动出手。\\n\\n悟空回来了，令八戒沙僧摔死奎木狼两孩子。悟空和奎木狼打成平手，最终还是上天庭招回了奎木狼。被派去给老君烧火，而原来的两位童子即将在平顶山与悟空斗法。\\n\\n经此战，悟空初步确定地位，但最终还是要等六耳猕猴之后才最终成立\\n\\n## 平顶山被轻松团灭\\n\\n悟空被银角大王放山压住，取经团队全员被捉，最后谜底揭开竟是太上老君的童子，悟空开始明白取经之路不易\\n\\n## 乌鸡国佛道拉锯\\n\\n乌鸡国王起初借佛家立国，后因求雨无门又借道士之力，但为佛家所忌，文殊派青毛狮子杀道士，推国王入井，据国三年。国王被悟空借得金丹复活后，更是敬心礼佛，从此西行之路又多一个佛国\\n\\n## 黑水河与白龙马\\n\\n此难悟空开始明道，不再打打杀杀，只是几番言语便借西海龙马与龙太子降服小鼍龙。有趣的是，白龙马自称西海龙王之子，却全程未现身。有说白龙马是取经开始被斩的泾河龙王化身，权当一听\\n\\n## 车迟国的三难\\n\\n并不是一处一难，车迟国在盘点时就有，搬运，斗法，去道兴僧共三难\\n\\n## 中点通天河\\n\\n灵感大王是观音的金鱼，此妖有异能使河结冰，亦能控制天气，说明观音已有绕过天庭控制降雨的能力\\n\\n## 女儿国和蝎子精\\n\\n道教利用子母河将此变为造人机器，女儿国王才想借唐僧来摆脱被控制的命运\\n\\n## 真假美猴王\\n\\n女儿国王是第一个在通关文碟上给三徒弟留名的国家，以此为契机悟空正式提出要编制。六耳猕猴也许是猴子的救命毫毛变的，但终是借此让如来承认了猴子\\n\\n## 牛魔王的悲剧\\n\\n铁扇公主和玉面狐狸两段姻缘都属于入赘，加上其弟如意真仙把持女儿国，打造了牛魔王在西牛贺洲的生意。最终被佛道天庭三家联合绞杀\\n\\n## 祭赛国的九头虫\\n\\n63回目，碧波潭万圣公主偷了舍利，悟空与八戒合斗公主附马九头虫不敌，此虫乃羽虫，是九头鸟。遇上经过此处的二郎神（为何来此是谜），联手后才由哮天犬咬下一头后跳往北海。此时悟空力主放过九头虫，成了书中唯一没有背景还活着但没有被收编的妖怪（黑熊怪，蜈蚣精被收编了）。有几点值得说道\\n\\n猴哥与二郎神究竟关系如何？\\n\\n> 二郎神曾火烧花果山，4万7千小猴只留得不足千只，按说这是刻骨深仇，但换个想法，二郎神真的没有能力找到那躲藏的小猴吗？还是二郎神施得障眼法，倘换得其他人，是不是会斩草除根。猴哥自己西天取经一路对各种山头的小怪同样斩尽杀绝，想念及此许是回过味来，感激二郎神当年留了自己猴子猴孙的性命，喊声七圣兄弟恐怕也是真心\\n\\n二郎神的背景\\n\\n> 书中交待得清楚，二郎神是玉帝的外甥，玉帝妹妹思凡嫁给凡间杨姓男子，生下二郎神。玉帝将妹妹镇在山底，二郎神劈山救母（也许是玉帝授意），还得名师指点，习得一身好本领。\\n\\n为何放走九头虫\\n\\n> 可能确实打不过，再者九头虫是牛魔王的朋友，甚至可能是和猴哥当年的结拜兄弟。牛魔王一战做得太绝，猴哥内心也许有愧，此时如来只要取回宝物，没必要非杀死九头虫\\n\\n## 朱紫国的反杀\\n\\n观音安排了部下带着专克悟空的法宝，不料却被悟空使计换掉并反杀。最后朱紫国没有成为佛教的附庸，而是依然在道家和悟空的掌中\\n\\n## 盘丝洞和蜈蚣精\\n\\n七只蜘蛛是纺织的打工人，蜈蚣精则是做药的打工人\\n\\n## 比丘国\\n\\n## 半截观音白鼠精\\n\\n遇到白鼠精后，唐僧便大病三日，算作一劫\\n\\n## 灭法国灭僧反成僧\\n\\n国王要杀1万名和尚，岂料最后自己和满朝文武都成了和尚\\n\\n## 隐雾山的豹子精\\n\\n似乎是取精路没有背景，但悟空却不敢下杀手，反而处处小心，虽然最后还是被杀，但也体现了悟空的成长\\n\\n## 凤仙郡求雨\\n\\n## 观音代佛祖攒局\\n\\n看起来观音没有得到明显的好处，但是收获做一个成功项目的经验，为他以后的铺路是很有帮助的。悟空表面上的打打杀杀固然威风，但是观音怎么去调动平衡组织的能力，也是很有难度的。为将者让对方找不到你的套路，对下又要严明赏罚，规则明确，对上和对下是两套完全不同的法则"}'));jctx.push(JSON.parse('{"id": "240205", "tag": "think", "text": "# 对于笔记的思考\\n\\n整个2023年做了很多笔记方面的学习和思考，包括anki和tiddlywiki，但实践下来反而把自己的老本行给丢了。\\n\\n我原来所有的数据都是基于sqlite的数据库，由于站点一度迁移到sdf，为了简化转变成用markdown加git管理。但是这个转变过程没有考虑一些私有文档，加上整个内容体系也梳理得不完整，所以一年多的工资都没有记录。最近几个月把pb完善的差不多，加上又学了全文检索，sdf的功能也支持数据库。所以还是想重新回归到数据库模式。回想半年前还做了很多从markdown写入数据库的工具，现在又要反过来写一遍，也是挺折腾的。\\n\\n## 标签编码\\n\\n因为学习了卢曼卡片笔记，为模仿还特意设想了一套数字编码的方式，但时间久了发现根本记不住，可能对我最自然的方式就是不刻意打标签，直接用关键词(拼音)检索。\\n\\n## 一些尝试\\n\\n写mytid时，投入了很大精力，但事后看来用的并不多。我觉得有两个原因，第1是编辑修改太不方便，第2个是外部的形态不是一个独立窗口，所以用起来不符合我的个人习惯，现在做一个本地GUI的，基于数据库的一个笔记。\\n\\n经过一周开发出的GUI工具，做到除了几个长篇的内容外，都归集到1个数据库文件。好处是清爽简洁，但太依赖编辑工具，加上缺少内容预览能力，导致记录了近200篇内容但整理的时候没有着力点。笔记不同于日记，必须有主题而且便于回看，否则就成了没有整合的散乱数据。\\n"}'));jctx.push(JSON.parse('{"id": "240315", "tag": "data", "text": "# 对大模型与的理解与思考\\n\\n23年12月意外地被拉进大模型项目后大约跟了3个月，不得已学着理解这其中一些概念，一些不成熟的思考\\n\\n## 模型相关概念\\n\\n早期模型的权重和激活参数（tensor）是用PyTorch的pickle保存，现在主流的有huggingface设计的safetensor和ggml定义的gguf。\\n\\nsafetensor支持五种框架：pytorch、TensorFlow、flax（jax）、paddle（paddlepaddle）、numpy。\\n\\n模型规模与量化\\n\\n10B以下通常称为小模型，再结合量化方式就可以确定使用资源，比如7B模型如果用BF16，大小是`7G*2Byte=14G`；如果用Q4_0量化，大小是`7G*0.5Byte=4G`。量化由框架和硬件共同决定，至少有十多种，我所知常见的有fp16/int8/int4。\\n\\n模型的核心结构是张量，我下载过1B的模型文件只有200个张量，平均每个张量的参数有500万之多。\\n\\n## 传统机器学习分类概览\\n\\n虽然ML已经日渐式微，但了解其思想才能更好地理解现在的方向。机器学习的目的有三大类：回归、分类、聚类。再辅以配套技术：降维、模型选择和预处理。\\n\\n## 有监督-回归线性回归逻辑回归\\n\\n## 有监督-分类\\n\\n* KNN决策树\\n* 支持向量机\\n* SVM和朴素贝叶斯\\n\\n## 无监督-聚类K-means\\n\\n# 集成学习\\n\\n将多个弱模型整合成一个强模型，有bagging和boosting两个流派\\n\\n## bagging派之随机森林\\n\\n## boosting派之XGBoost其实还有AdaBoost和GBDT，但XGBoost最有名\\n\\n# 强化学习\\n\\n在人工智能领域属于少见的行为主义学派（控制论）。实现时与神经网络关联很深，似乎只有AlphaGo成功了，似乎出了游戏领域没有成功的例子"}'));}var config_txt=`
{"edit":true,
 "tagtr":{
  "os":"操作系统","net":"网络原理","data":"数据库技术","security":"加密与安全",
  "protocol":"通信协议","web":"Web开发","design":"软件设计",
  "lang":"编程语言","tool":"软件工具使用","think":"所思所想","book":"读书笔记"
 }
}`;var config=JSON.parse(config_txt);
function _uniid(base){return `u${base}${Math.round(Math.random()*65536)}`}
function renderText(txt){
  if ("#"==txt[0]){return marked.parse(txt.replace(/\[\[([^\] ]+)\]\]/g, "*$1*"))}
  else {return `<p>${txt.replace(/\n/g, "<br/>")}</p>`}}
function dumpobj(e){var t= typeof e;for (let i in e){t=t+`\n${i} : ${e[i]}`};alert(t)}
function _ttl_of_text(txt){var sp= "#"==txt[0]?2:0;return txt.substring(sp, txt.indexOf("\n"))}
function _close_btn(uid){return `<input value="close" type=button onclick="$tm.ev_rmnode('${uid}')"/>`}
function saveFile(flname, txt){
  var a = document.createElement('a')
  a.download = flname
  a.href = URL.createObjectURL(new Blob([txt], {type: 'text/plain'}))
  a.click()
}
function createTitleLink(ttl, i){
  if (i!=undefined) {
	return `<p class="s_item" onclick="$tm.ev_shwCard(${i})">${ttl}</p>`
  }else {return `<p>ERR LINK: ${ttl}</p>`}
}
function createAllTopH(){
  var toph=""
  for (let t in tag2ttl){
	var showh = config.tagtr[t]?config.tagtr[t]:t
	toph+=`<h2 onclick="$tm.ev_shwHd('${t}')">${showh}</h2>`
  }
  return toph
}
function createCata(tag){
  var div = document.createElement('div')
  uniid=_uniid(tag)
  div.id=uniid
  div.className="card sec_pad"
  tag2ttl[tag].sort()
  var ttl_lnk=""
  for (let ttl of tag2ttl[tag]){
	ttl_lnk+=createTitleLink(ttl, ttl2idx[ttl])
  }
  ttl_lnk+=`<hr />${config.tagtr[tag]?config.tagtr[tag]:tag}${_close_btn(uniid)}`
  div.innerHTML=ttl_lnk
  return div
}
function createCard(art, idx){
  var div = document.createElement('div')
  var uniid = _uniid(art["id"])
  div.id=uniid
  div.className="card art_pad"
  var ttl=_ttl_of_text(art["text"])
  var lnkelem=""
  if (lnkmap[ttl]){
	let lst=lnkmap[ttl].split(",")
	for (let v of lst){
	  lnkelem+=createTitleLink(v, ttl2idx[v])
	}
  }
  var edtbtn = config.edit?`<input value="edit" type=button onclick="$tm.ev_shwEdt(${idx})"/>`:"";
  var tag= art["tag"]=="unknown"?"":`_${art["tag"]}`
  div.innerHTML=renderText(art["text"])+`<hr />${art["id"]}${tag}
	${lnkelem}
	${edtbtn}
	${_close_btn(uniid)}`
  return div
}
function insert_div(target, div){
  document.getElementById(target).before(div)
  window.scrollTo({"left": div.offsetLeft, "top": div.offsetTop, behavior: "smooth"})
}
function _find_bykwd(kwd) {
  var ret = []
  var kl = kwd.split(/\s+/)
  var klen = kl.length
  for (let i in jctx) {
    var mc=0, mp, mt=""
    for (let j=0;j<klen;j++){
	  if (0==kl[j].length){mc++;continue}
	  var txt = jctx[i]["text"]
	  if (128>kl[j].charCodeAt(0)) {/*ignoreCase english*/
	    mp = txt.search(RegExp(kl[j],"i"))
	  } else {
		mp = txt.indexOf(kl[j])
	  }
	  mc += mp>=0?1:0
	  mt += mp>=0?`${txt.slice(Math.max(mp-5, 0),mp)}<span class="kwd_em">${kl[j]}</span>${txt.slice(mp+kl[j].length, mp+kl[j].length+6)} `:""
	}
    if (mc==klen) {ret.push([i, mt])}
  }
  return ret
}
var tmout
var ttl2idx={}
var tag2ttl={}
var lnkmap={}
// event function definition
top.$tm.ev_findkwd=function(){
  function _search() {
    var kwd = document.getElementById("kwd").value
    if (kwd.length==0) {document.getElementById("kwd_show").innerHTML ="";return}
    var lst = _find_bykwd(kwd)
    var jmp_ttl = ""
    for (let pr of lst){
	  let i=pr[0], mt=pr[1]
      let ttl = _ttl_of_text(jctx[i]["text"])
      jmp_ttl += createTitleLink(ttl, i)+mt
    }
    document.getElementById("kwd_show").innerHTML = jmp_ttl
  }
  clearTimeout(tmout)
  tmout=setTimeout(_search, 250)
}
top.$tm.ev_rmnode=function(id){var n=document.getElementById(id);n.remove()}
top.$tm.ev_save=function(idx, taid){
  var art = jctx[idx]
  var ta = document.getElementById(taid)
  saveFile(`${art["id"]}_${art["tag"]}.md`, ta.value)
}
top.$tm.ev_chgVorE=function(mdid){
  var md = document.getElementById(mdid)
  if (md.style.display=="none"){
	md.style.display="block"
  } else {
	md.style.display="none"
  }
}
top.$tm.ev_shwCard=function(idx){
  var div = createCard(jctx[idx], idx)
  insert_div("kwd_show", div)
}
top.$tm.ev_shwHd=function(tag) {
  var div = createCata(tag)
  insert_div("eTopTag", div)
}
top.$tm.ev_shwEdt=function(idx){
  var div = document.createElement('div')
  var art = jctx[idx]
  var uniid = _uniid(art["id"])
  div.id=uniid
  div.className="card art_pad edit_zone"
  var spid = _uniid("sp"+art["id"])
  var taid = _uniid("ta"+art["id"])
  var mdid = _uniid("dv"+art["id"])
  div.innerHTML=`<span style="color: blue">Draft Zone</span>
	<div style="display: flex">
	<div class="auto_high sd_by_sd">
	  <span id="${spid}" class="auto_high"></span>
	  <textarea id="${taid}" class="auto_high"></textarea>
	</div>
	<div id="${mdid}" style="display: none" class="sd_by_sd prv_pad"></div>
	</div>
	<hr />
	<input value="preview" type=button onclick="$tm.ev_chgVorE('${mdid}')"/>
	<input value="save" type=button onclick="$tm.ev_save(${idx}, '${taid}')" />
	${_close_btn(uniid)}`
  insert_div("kwd_show", div)
  var ta = document.getElementById(taid)
  ta.value = art["text"]
  document.getElementById(mdid).innerHTML = renderText(ta.value)
  ta.addEventListener('input', function(ev){
	document.getElementById(mdid).innerHTML=renderText(ev.target.value)
  })
  // textarea height auto to rext
  var d_span = document.getElementById(spid)
  var d_area = document.getElementById(taid)
  d_span.innerHTML = d_area.value+' ';
  d_area.addEventListener('input', function(e) {
    d_span.innerHTML = d_area.value+' ';
  })
}
top.$tm.ev_boot=function(){
  load_jctx()
  for (let i in jctx) {
    let ttl = _ttl_of_text(jctx[i]["text"]); ttl2idx[ttl]=i
    let tag = jctx[i]["tag"]
	if (!tag2ttl[tag]) {tag2ttl[tag]=[]};tag2ttl[tag].push(ttl)
	let lnk=jctx[i]["text"].match(/\[\[[^\] ]+\]\]/g)
    if (lnk){
	  for (let v of lnk) {
		let to_lk=v.slice(2, -2)
		if (lnkmap[ttl]===undefined){lnkmap[ttl]=to_lk}
		else {if (-1==lnkmap[ttl].indexOf(to_lk)){lnkmap[ttl]+=`,${to_lk}`} }
		if (lnkmap[to_lk]===undefined){lnkmap[to_lk]=ttl}
		else {if (-1==lnkmap[to_lk].indexOf(ttl)){lnkmap[to_lk]+=`,${ttl}`}}
	  }
    }
  }
  document.getElementById("eTopTag").innerHTML=createAllTopH()
  var dt = new Date();
  document.getElementById("eFter").innerHTML=`Generated at ${dt.getFullYear()}/${dt.getMonth()}/${dt.getDate()}, 共${jctx.length}篇笔记<br />© 2014 - ${dt.getFullYear()} 由mytid强力驱动`
}
})(this);
//markdown
!function(e,t){"object"==typeof exports&&"undefined"!=typeof module?module.exports=t():"function"==typeof define&&define.amd?define(t):(e=e||self).marked=t()}(this,function(){"use strict";function s(e,t){for(var n=0;n<t.length;n++){var r=t[n];r.enumerable=r.enumerable||!1,r.configurable=!0,"value"in r&&(r.writable=!0),Object.defineProperty(e,r.key,r)}}function i(e,t){(null==t||t>e.length)&&(t=e.length);for(var n=0,r=new Array(t);n<t;n++)r[n]=e[n];return r}function g(e,t){var n;if("undefined"!=typeof Symbol&&null!=e[Symbol.iterator])return(n=e[Symbol.iterator]()).next.bind(n);if(Array.isArray(e)||(n=function(e,t){if(e){if("string"==typeof e)return i(e,t);var n=Object.prototype.toString.call(e).slice(8,-1);return"Object"===n&&e.constructor&&(n=e.constructor.name),"Map"===n||"Set"===n?Array.from(e):"Arguments"===n||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)?i(e,t):void 0}}(e))||t&&e&&"number"==typeof e.length){n&&(e=n);var r=0;return function(){return r>=e.length?{done:!0}:{done:!1,value:e[r++]}}}throw new TypeError("Invalid attempt to iterate non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}function n(e){return c[e]}var e,t=(function(t){function e(){return{baseUrl:null,breaks:!1,gfm:!0,headerIds:!0,headerPrefix:"",highlight:null,langPrefix:"language-",mangle:!0,pedantic:!1,renderer:null,sanitize:!1,sanitizer:null,silent:!1,smartLists:!1,smartypants:!1,tokenizer:null,walkTokens:null,xhtml:!1}}t.exports={defaults:e(),getDefaults:e,changeDefaults:function(e){t.exports.defaults=e}}}(e={exports:{}}),e.exports),r=(t.defaults,t.getDefaults,t.changeDefaults,/[&<>"']/),l=/[&<>"']/g,a=/[<>"']|&(?!#?\w+;)/,o=/[<>"']|&(?!#?\w+;)/g,c={"&":"&amp;","<":"&lt;",">":"&gt;",'"':"&quot;","'":"&#39;"};var u=/&(#(?:\d+)|(?:#x[0-9A-Fa-f]+)|(?:\w+));?/gi;function p(e){return e.replace(u,function(e,t){return"colon"===(t=t.toLowerCase())?":":"#"===t.charAt(0)?"x"===t.charAt(1)?String.fromCharCode(parseInt(t.substring(2),16)):String.fromCharCode(+t.substring(1)):""})}var h=/(^|[^\[])\^/g;var f=/[^\w:]/g,d=/^$|^[a-z][a-z0-9+.-]*:|^[?#]/i;var k={},b=/^[^:]+:\/*[^/]*$/,m=/^([^:]+:)[\s\S]*$/,x=/^([^:]+:\/*[^/]*)[\s\S]*$/;function v(e,t){k[" "+e]||(b.test(e)?k[" "+e]=e+"/":k[" "+e]=w(e,"/",!0));var n=-1===(e=k[" "+e]).indexOf(":");return"//"===t.substring(0,2)?n?t:e.replace(m,"$1")+t:"/"===t.charAt(0)?n?t:e.replace(x,"$1")+t:e+t}function w(e,t,n){var r=e.length;if(0===r)return"";for(var i=0;i<r;){var s=e.charAt(r-i-1);if(s!==t||n){if(s===t||!n)break;i++}else i++}return e.substr(0,r-i)}var _=function(e,t){if(t){if(r.test(e))return e.replace(l,n)}else if(a.test(e))return e.replace(o,n);return e},y=p,z=function(n,e){n=n.source||n,e=e||"";var r={replace:function(e,t){return t=(t=t.source||t).replace(h,"$1"),n=n.replace(e,t),r},getRegex:function(){return new RegExp(n,e)}};return r},S=function(e,t,n){if(e){var r;try{r=decodeURIComponent(p(n)).replace(f,"").toLowerCase()}catch(e){return null}if(0===r.indexOf("javascript:")||0===r.indexOf("vbscript:")||0===r.indexOf("data:"))return null}t&&!d.test(n)&&(n=v(t,n));try{n=encodeURI(n).replace(/%25/g,"%")}catch(e){return null}return n},$={exec:function(){}},A=function(e){for(var t,n,r=1;r<arguments.length;r++)for(n in t=arguments[r])Object.prototype.hasOwnProperty.call(t,n)&&(e[n]=t[n]);return e},R=function(e,t){var n=e.replace(/\|/g,function(e,t,n){for(var r=!1,i=t;0<=--i&&"\\"===n[i];)r=!r;return r?"|":" |"}).split(/ \|/),r=0;if(n.length>t)n.splice(t);else for(;n.length<t;)n.push("");for(;r<n.length;r++)n[r]=n[r].trim().replace(/\\\|/g,"|");return n},T=function(e,t){if(-1===e.indexOf(t[1]))return-1;for(var n=e.length,r=0,i=0;i<n;i++)if("\\"===e[i])i++;else if(e[i]===t[0])r++;else if(e[i]===t[1]&&--r<0)return i;return-1},I=function(e){e&&e.sanitize&&!e.silent&&console.warn("marked(): sanitize and sanitizer parameters are deprecated since version 0.7.0, should not be used and will be removed in the future. Read more here: https://marked.js.org/#/USING_ADVANCED.md#options")},Z=t.defaults,q=w,O=R,C=_,U=T;function j(e,t,n){var r=t.href,i=t.title?C(t.title):null,s=e[1].replace(/\\([\[\]])/g,"$1");return"!"!==e[0].charAt(0)?{type:"link",raw:n,href:r,title:i,text:s}:{type:"image",raw:n,href:r,title:i,text:C(s)}}var E=function(){function e(e){this.options=e||Z}var t=e.prototype;return t.space=function(e){var t=this.rules.block.newline.exec(e);if(t)return 1<t[0].length?{type:"space",raw:t[0]}:{raw:"\n"}},t.code=function(e,t){var n=this.rules.block.code.exec(e);if(n){var r=t[t.length-1];if(r&&"paragraph"===r.type)return{raw:n[0],text:n[0].trimRight()};var i=n[0].replace(/^ {4}/gm,"");return{type:"code",raw:n[0],codeBlockStyle:"indented",text:this.options.pedantic?i:q(i,"\n")}}},t.fences=function(e){var t=this.rules.block.fences.exec(e);if(t){var n=t[0],r=function(e,t){var n=e.match(/^(\s+)(?:```)/);if(null===n)return t;var r=n[1];return t.split("\n").map(function(e){var t=e.match(/^\s+/);return null!==t&&t[0].length>=r.length?e.slice(r.length):e}).join("\n")}(n,t[3]||"");return{type:"code",raw:n,lang:t[2]?t[2].trim():t[2],text:r}}},t.heading=function(e){var t=this.rules.block.heading.exec(e);if(t)return{type:"heading",raw:t[0],depth:t[1].length,text:t[2]}},t.nptable=function(e){var t=this.rules.block.nptable.exec(e);if(t){var n={type:"table",header:O(t[1].replace(/^ *| *\| *$/g,"")),align:t[2].replace(/^ *|\| *$/g,"").split(/ *\| */),cells:t[3]?t[3].replace(/\n$/,"").split("\n"):[],raw:t[0]};if(n.header.length===n.align.length){for(var r=n.align.length,i=0;i<r;i++)/^ *-+: *$/.test(n.align[i])?n.align[i]="right":/^ *:-+: *$/.test(n.align[i])?n.align[i]="center":/^ *:-+ *$/.test(n.align[i])?n.align[i]="left":n.align[i]=null;for(r=n.cells.length,i=0;i<r;i++)n.cells[i]=O(n.cells[i],n.header.length);return n}}},t.hr=function(e){var t=this.rules.block.hr.exec(e);if(t)return{type:"hr",raw:t[0]}},t.blockquote=function(e){var t=this.rules.block.blockquote.exec(e);if(t){var n=t[0].replace(/^ *> ?/gm,"");return{type:"blockquote",raw:t[0],text:n}}},t.list=function(e){var t=this.rules.block.list.exec(e);if(t){for(var n,r,i,s,l,a,o,c=t[0],u=t[2],p=1<u.length,h=")"===u[u.length-1],g={type:"list",raw:c,ordered:p,start:p?+u.slice(0,-1):"",loose:!1,items:[]},f=t[0].match(this.rules.block.item),d=!1,k=f.length,b=0;b<k;b++)r=(c=n=f[b]).length,~(n=n.replace(/^ *([*+-]|\d+[.)]) */,"")).indexOf("\n ")&&(r-=n.length,n=this.options.pedantic?n.replace(/^ {1,4}/gm,""):n.replace(new RegExp("^ {1,"+r+"}","gm"),"")),b!==k-1&&(i=this.rules.block.bullet.exec(f[b+1])[0],(p?1===i.length||!h&&")"===i[i.length-1]:1<i.length||this.options.smartLists&&i!==u)&&(s=f.slice(b+1).join("\n"),g.raw=g.raw.substring(0,g.raw.length-s.length),b=k-1)),l=d||/\n\n(?!\s*$)/.test(n),b!==k-1&&(d="\n"===n.charAt(n.length-1),l=l||d),l&&(g.loose=!0),o=void 0,(a=/^\[[ xX]\] /.test(n))&&(o=" "!==n[1],n=n.replace(/^\[[ xX]\] +/,"")),g.items.push({type:"list_item",raw:c,task:a,checked:o,loose:l,text:n});return g}},t.html=function(e){var t=this.rules.block.html.exec(e);if(t)return{type:this.options.sanitize?"paragraph":"html",raw:t[0],pre:!this.options.sanitizer&&("pre"===t[1]||"script"===t[1]||"style"===t[1]),text:this.options.sanitize?this.options.sanitizer?this.options.sanitizer(t[0]):C(t[0]):t[0]}},t.def=function(e){var t=this.rules.block.def.exec(e);if(t)return t[3]&&(t[3]=t[3].substring(1,t[3].length-1)),{tag:t[1].toLowerCase().replace(/\s+/g," "),raw:t[0],href:t[2],title:t[3]}},t.table=function(e){var t=this.rules.block.table.exec(e);if(t){var n={type:"table",header:O(t[1].replace(/^ *| *\| *$/g,"")),align:t[2].replace(/^ *|\| *$/g,"").split(/ *\| */),cells:t[3]?t[3].replace(/\n$/,"").split("\n"):[]};if(n.header.length===n.align.length){n.raw=t[0];for(var r=n.align.length,i=0;i<r;i++)/^ *-+: *$/.test(n.align[i])?n.align[i]="right":/^ *:-+: *$/.test(n.align[i])?n.align[i]="center":/^ *:-+ *$/.test(n.align[i])?n.align[i]="left":n.align[i]=null;for(r=n.cells.length,i=0;i<r;i++)n.cells[i]=O(n.cells[i].replace(/^ *\| *| *\| *$/g,""),n.header.length);return n}}},t.lheading=function(e){var t=this.rules.block.lheading.exec(e);if(t)return{type:"heading",raw:t[0],depth:"="===t[2].charAt(0)?1:2,text:t[1]}},t.paragraph=function(e){var t=this.rules.block.paragraph.exec(e);if(t)return{type:"paragraph",raw:t[0],text:"\n"===t[1].charAt(t[1].length-1)?t[1].slice(0,-1):t[1]}},t.text=function(e,t){var n=this.rules.block.text.exec(e);if(n){var r=t[t.length-1];return r&&"text"===r.type?{raw:n[0],text:n[0]}:{type:"text",raw:n[0],text:n[0]}}},t.escape=function(e){var t=this.rules.inline.escape.exec(e);if(t)return{type:"escape",raw:t[0],text:C(t[1])}},t.tag=function(e,t,n){var r=this.rules.inline.tag.exec(e);if(r)return!t&&/^<a /i.test(r[0])?t=!0:t&&/^<\/a>/i.test(r[0])&&(t=!1),!n&&/^<(pre|code|kbd|script)(\s|>)/i.test(r[0])?n=!0:n&&/^<\/(pre|code|kbd|script)(\s|>)/i.test(r[0])&&(n=!1),{type:this.options.sanitize?"text":"html",raw:r[0],inLink:t,inRawBlock:n,text:this.options.sanitize?this.options.sanitizer?this.options.sanitizer(r[0]):C(r[0]):r[0]}},t.link=function(e){var t=this.rules.inline.link.exec(e);if(t){var n,r=U(t[2],"()");-1<r&&(n=(0===t[0].indexOf("!")?5:4)+t[1].length+r,t[2]=t[2].substring(0,r),t[0]=t[0].substring(0,n).trim(),t[3]="");var i,s=t[2],l="";return l=this.options.pedantic?(i=/^([^'"]*[^\s])\s+(['"])(.*)\2/.exec(s),i?(s=i[1],i[3]):""):t[3]?t[3].slice(1,-1):"",j(t,{href:(s=s.trim().replace(/^<([\s\S]*)>$/,"$1"))?s.replace(this.rules.inline._escapes,"$1"):s,title:l?l.replace(this.rules.inline._escapes,"$1"):l},t[0])}},t.reflink=function(e,t){var n;if((n=this.rules.inline.reflink.exec(e))||(n=this.rules.inline.nolink.exec(e))){var r=(n[2]||n[1]).replace(/\s+/g," ");if((r=t[r.toLowerCase()])&&r.href)return j(n,r,n[0]);var i=n[0].charAt(0);return{type:"text",raw:i,text:i}}},t.strong=function(e,t,n){void 0===n&&(n="");var r=this.rules.inline.strong.start.exec(e);if(r&&(!r[1]||r[1]&&(""===n||this.rules.inline.punctuation.exec(n)))){t=t.slice(-1*e.length);var i,s="**"===r[0]?this.rules.inline.strong.endAst:this.rules.inline.strong.endUnd;for(s.lastIndex=0;null!=(r=s.exec(t));)if(i=this.rules.inline.strong.middle.exec(t.slice(0,r.index+3)))return{type:"strong",raw:e.slice(0,i[0].length),text:e.slice(2,i[0].length-2)}}},t.em=function(e,t,n){void 0===n&&(n="");var r=this.rules.inline.em.start.exec(e);if(r&&(!r[1]||r[1]&&(""===n||this.rules.inline.punctuation.exec(n)))){t=t.slice(-1*e.length);var i,s="*"===r[0]?this.rules.inline.em.endAst:this.rules.inline.em.endUnd;for(s.lastIndex=0;null!=(r=s.exec(t));)if(i=this.rules.inline.em.middle.exec(t.slice(0,r.index+2)))return{type:"em",raw:e.slice(0,i[0].length),text:e.slice(1,i[0].length-1)}}},t.codespan=function(e){var t=this.rules.inline.code.exec(e);if(t){var n=t[2].replace(/\n/g," "),r=/[^ ]/.test(n),i=n.startsWith(" ")&&n.endsWith(" ");return r&&i&&(n=n.substring(1,n.length-1)),n=C(n,!0),{type:"codespan",raw:t[0],text:n}}},t.br=function(e){var t=this.rules.inline.br.exec(e);if(t)return{type:"br",raw:t[0]}},t.del=function(e){var t=this.rules.inline.del.exec(e);if(t)return{type:"del",raw:t[0],text:t[1]}},t.autolink=function(e,t){var n=this.rules.inline.autolink.exec(e);if(n){var r,i="@"===n[2]?"mailto:"+(r=C(this.options.mangle?t(n[1]):n[1])):r=C(n[1]);return{type:"link",raw:n[0],text:r,href:i,tokens:[{type:"text",raw:r,text:r}]}}},t.url=function(e,t){var n,r,i,s;if(n=this.rules.inline.url.exec(e)){if("@"===n[2])i="mailto:"+(r=C(this.options.mangle?t(n[0]):n[0]));else{for(;s=n[0],n[0]=this.rules.inline._backpedal.exec(n[0])[0],s!==n[0];);r=C(n[0]),i="www."===n[1]?"http://"+r:r}return{type:"link",raw:n[0],text:r,href:i,tokens:[{type:"text",raw:r,text:r}]}}},t.inlineText=function(e,t,n){var r=this.rules.inline.text.exec(e);if(r){var i=t?this.options.sanitize?this.options.sanitizer?this.options.sanitizer(r[0]):C(r[0]):r[0]:C(this.options.smartypants?n(r[0]):r[0]);return{type:"text",raw:r[0],text:i}}},e}(),D=$,L=z,P=A,B={newline:/^\n+/,code:/^( {4}[^\n]+\n*)+/,fences:/^ {0,3}(`{3,}(?=[^`\n]*\n)|~{3,})([^\n]*)\n(?:|([\s\S]*?)\n)(?: {0,3}\1[~`]* *(?:\n+|$)|$)/,hr:/^ {0,3}((?:- *){3,}|(?:_ *){3,}|(?:\* *){3,})(?:\n+|$)/,heading:/^ {0,3}(#{1,6}) +([^\n]*?)(?: +#+)? *(?:\n+|$)/,blockquote:/^( {0,3}> ?(paragraph|[^\n]*)(?:\n|$))+/,list:/^( {0,3})(bull) [\s\S]+?(?:hr|def|\n{2,}(?! )(?!\1bull )\n*|\s*$)/,html:"^ {0,3}(?:<(script|pre|style)[\\s>][\\s\\S]*?(?:</\\1>[^\\n]*\\n+|$)|comment[^\\n]*(\\n+|$)|<\\?[\\s\\S]*?\\?>\\n*|<![A-Z][\\s\\S]*?>\\n*|<!\\[CDATA\\[[\\s\\S]*?\\]\\]>\\n*|</?(tag)(?: +|\\n|/?>)[\\s\\S]*?(?:\\n{2,}|$)|<(?!script|pre|style)([a-z][\\w-]*)(?:attribute)*? */?>(?=[ \\t]*(?:\\n|$))[\\s\\S]*?(?:\\n{2,}|$)|</(?!script|pre|style)[a-z][\\w-]*\\s*>(?=[ \\t]*(?:\\n|$))[\\s\\S]*?(?:\\n{2,}|$))",def:/^ {0,3}\[(label)\]: *\n? *<?([^\s>]+)>?(?:(?: +\n? *| *\n *)(title))? *(?:\n+|$)/,nptable:D,table:D,lheading:/^([^\n]+)\n {0,3}(=+|-+) *(?:\n+|$)/,_paragraph:/^([^\n]+(?:\n(?!hr|heading|lheading|blockquote|fences|list|html)[^\n]+)*)/,text:/^[^\n]+/,_label:/(?!\s*\])(?:\\[\[\]]|[^\[\]])+/,_title:/(?:"(?:\\"?|[^"\\])*"|'[^'\n]*(?:\n[^'\n]+)*\n?'|\([^()]*\))/};B.def=L(B.def).replace("label",B._label).replace("title",B._title).getRegex(),B.bullet=/(?:[*+-]|\d{1,9}[.)])/,B.item=/^( *)(bull) ?[^\n]*(?:\n(?!\1bull ?)[^\n]*)*/,B.item=L(B.item,"gm").replace(/bull/g,B.bullet).getRegex(),B.list=L(B.list).replace(/bull/g,B.bullet).replace("hr","\\n+(?=\\1?(?:(?:- *){3,}|(?:_ *){3,}|(?:\\* *){3,})(?:\\n+|$))").replace("def","\\n+(?="+B.def.source+")").getRegex(),B._tag="address|article|aside|base|basefont|blockquote|body|caption|center|col|colgroup|dd|details|dialog|dir|div|dl|dt|fieldset|figcaption|figure|footer|form|frame|frameset|h[1-6]|head|header|hr|html|iframe|legend|li|link|main|menu|menuitem|meta|nav|noframes|ol|optgroup|option|p|param|section|source|summary|table|tbody|td|tfoot|th|thead|title|tr|track|ul",B._comment=/<!--(?!-?>)[\s\S]*?-->/,B.html=L(B.html,"i").replace("comment",B._comment).replace("tag",B._tag).replace("attribute",/ +[a-zA-Z:_][\w.:-]*(?: *= *"[^"\n]*"| *= *'[^'\n]*'| *= *[^\s"'=<>`]+)?/).getRegex(),B.paragraph=L(B._paragraph).replace("hr",B.hr).replace("heading"," {0,3}#{1,6} ").replace("|lheading","").replace("blockquote"," {0,3}>").replace("fences"," {0,3}(?:`{3,}(?=[^`\\n]*\\n)|~{3,})[^\\n]*\\n").replace("list"," {0,3}(?:[*+-]|1[.)]) ").replace("html","</?(?:tag)(?: +|\\n|/?>)|<(?:script|pre|style|!--)").replace("tag",B._tag).getRegex(),B.blockquote=L(B.blockquote).replace("paragraph",B.paragraph).getRegex(),B.normal=P({},B),B.gfm=P({},B.normal,{nptable:"^ *([^|\\n ].*\\|.*)\\n *([-:]+ *\\|[-| :]*)(?:\\n((?:(?!\\n|hr|heading|blockquote|code|fences|list|html).*(?:\\n|$))*)\\n*|$)",table:"^ *\\|(.+)\\n *\\|?( *[-:]+[-| :]*)(?:\\n *((?:(?!\\n|hr|heading|blockquote|code|fences|list|html).*(?:\\n|$))*)\\n*|$)"}),B.gfm.nptable=L(B.gfm.nptable).replace("hr",B.hr).replace("heading"," {0,3}#{1,6} ").replace("blockquote"," {0,3}>").replace("code"," {4}[^\\n]").replace("fences"," {0,3}(?:`{3,}(?=[^`\\n]*\\n)|~{3,})[^\\n]*\\n").replace("list"," {0,3}(?:[*+-]|1[.)]) ").replace("html","</?(?:tag)(?: +|\\n|/?>)|<(?:script|pre|style|!--)").replace("tag",B._tag).getRegex(),B.gfm.table=L(B.gfm.table).replace("hr",B.hr).replace("heading"," {0,3}#{1,6} ").replace("blockquote"," {0,3}>").replace("code"," {4}[^\\n]").replace("fences"," {0,3}(?:`{3,}(?=[^`\\n]*\\n)|~{3,})[^\\n]*\\n").replace("list"," {0,3}(?:[*+-]|1[.)]) ").replace("html","</?(?:tag)(?: +|\\n|/?>)|<(?:script|pre|style|!--)").replace("tag",B._tag).getRegex(),B.pedantic=P({},B.normal,{html:L("^ *(?:comment *(?:\\n|\\s*$)|<(tag)[\\s\\S]+?</\\1> *(?:\\n{2,}|\\s*$)|<tag(?:\"[^\"]*\"|'[^']*'|\\s[^'\"/>\\s]*)*?/?> *(?:\\n{2,}|\\s*$))").replace("comment",B._comment).replace(/tag/g,"(?!(?:a|em|strong|small|s|cite|q|dfn|abbr|data|time|code|var|samp|kbd|sub|sup|i|b|u|mark|ruby|rt|rp|bdi|bdo|span|br|wbr|ins|del|img)\\b)\\w+(?!:|[^\\w\\s@]*@)\\b").getRegex(),def:/^ *\[([^\]]+)\]: *<?([^\s>]+)>?(?: +(["(][^\n]+[")]))? *(?:\n+|$)/,heading:/^ *(#{1,6}) *([^\n]+?) *(?:#+ *)?(?:\n+|$)/,fences:D,paragraph:L(B.normal._paragraph).replace("hr",B.hr).replace("heading"," *#{1,6} *[^\n]").replace("lheading",B.lheading).replace("blockquote"," {0,3}>").replace("|fences","").replace("|list","").replace("|html","").getRegex()});var F={escape:/^\\([!"#$%&'()*+,\-./:;<=>?@\[\]\\^_`{|}~])/,autolink:/^<(scheme:[^\s\x00-\x1f<>]*|email)>/,url:D,tag:"^comment|^</[a-zA-Z][\\w:-]*\\s*>|^<[a-zA-Z][\\w-]*(?:attribute)*?\\s*/?>|^<\\?[\\s\\S]*?\\?>|^<![a-zA-Z]+\\s[\\s\\S]*?>|^<!\\[CDATA\\[[\\s\\S]*?\\]\\]>",link:/^!?\[(label)\]\(\s*(href)(?:\s+(title))?\s*\)/,reflink:/^!?\[(label)\]\[(?!\s*\])((?:\\[\[\]]?|[^\[\]\\])+)\]/,nolink:/^!?\[(?!\s*\])((?:\[[^\[\]]*\]|\\[\[\]]|[^\[\]])*)\](?:\[\])?/,reflinkSearch:"reflink|nolink(?!\\()",strong:{start:/^(?:(\*\*(?=[*punctuation]))|\*\*)(?![\s])|__/,middle:/^\*\*(?:(?:(?!overlapSkip)(?:[^*]|\\\*)|overlapSkip)|\*(?:(?!overlapSkip)(?:[^*]|\\\*)|overlapSkip)*?\*)+?\*\*$|^__(?![\s])((?:(?:(?!overlapSkip)(?:[^_]|\\_)|overlapSkip)|_(?:(?!overlapSkip)(?:[^_]|\\_)|overlapSkip)*?_)+?)__$/,endAst:/[^punctuation\s]\*\*(?!\*)|[punctuation]\*\*(?!\*)(?:(?=[punctuation\s]|$))/,endUnd:/[^\s]__(?!_)(?:(?=[punctuation\s])|$)/},em:{start:/^(?:(\*(?=[punctuation]))|\*)(?![*\s])|_/,middle:/^\*(?:(?:(?!overlapSkip)(?:[^*]|\\\*)|overlapSkip)|\*(?:(?!overlapSkip)(?:[^*]|\\\*)|overlapSkip)*?\*)+?\*$|^_(?![_\s])(?:(?:(?!overlapSkip)(?:[^_]|\\_)|overlapSkip)|_(?:(?!overlapSkip)(?:[^_]|\\_)|overlapSkip)*?_)+?_$/,endAst:/[^punctuation\s]\*(?!\*)|[punctuation]\*(?!\*)(?:(?=[punctuation\s]|$))/,endUnd:/[^\s]_(?!_)(?:(?=[punctuation\s])|$)/},code:/^(`+)([^`]|[^`][\s\S]*?[^`])\1(?!`)/,br:/^( {2,}|\\)\n(?!\s*$)/,del:D,text:/^(`+|[^`])(?:[\s\S]*?(?:(?=[\\<!\[`*]|\b_|$)|[^ ](?= {2,}\n))|(?= {2,}\n))/,punctuation:/^([\s*punctuation])/,_punctuation:"!\"#$%&'()+\\-.,/:;<=>?@\\[\\]`^{|}~"};F.punctuation=L(F.punctuation).replace(/punctuation/g,F._punctuation).getRegex(),F._blockSkip="\\[[^\\]]*?\\]\\([^\\)]*?\\)|`[^`]*?`|<[^>]*?>",F._overlapSkip="__[^_]*?__|\\*\\*\\[^\\*\\]*?\\*\\*",F.em.start=L(F.em.start).replace(/punctuation/g,F._punctuation).getRegex(),F.em.middle=L(F.em.middle).replace(/punctuation/g,F._punctuation).replace(/overlapSkip/g,F._overlapSkip).getRegex(),F.em.endAst=L(F.em.endAst,"g").replace(/punctuation/g,F._punctuation).getRegex(),F.em.endUnd=L(F.em.endUnd,"g").replace(/punctuation/g,F._punctuation).getRegex(),F.strong.start=L(F.strong.start).replace(/punctuation/g,F._punctuation).getRegex(),F.strong.middle=L(F.strong.middle).replace(/punctuation/g,F._punctuation).replace(/blockSkip/g,F._blockSkip).getRegex(),F.strong.endAst=L(F.strong.endAst,"g").replace(/punctuation/g,F._punctuation).getRegex(),F.strong.endUnd=L(F.strong.endUnd,"g").replace(/punctuation/g,F._punctuation).getRegex(),F.blockSkip=L(F._blockSkip,"g").getRegex(),F.overlapSkip=L(F._overlapSkip,"g").getRegex(),F._escapes=/\\([!"#$%&'()*+,\-./:;<=>?@\[\]\\^_`{|}~])/g,F._scheme=/[a-zA-Z][a-zA-Z0-9+.-]{1,31}/,F._email=/[a-zA-Z0-9.!#$%&'*+/=?^_`{|}~-]+(@)[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\.[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)+(?![-_])/,F.autolink=L(F.autolink).replace("scheme",F._scheme).replace("email",F._email).getRegex(),F._attribute=/\s+[a-zA-Z:_][\w.:-]*(?:\s*=\s*"[^"]*"|\s*=\s*'[^']*'|\s*=\s*[^\s"'=<>`]+)?/,F.tag=L(F.tag).replace("comment",B._comment).replace("attribute",F._attribute).getRegex(),F._label=/(?:\[(?:\\.|[^\[\]\\])*\]|\\.|`[^`]*`|[^\[\]\\`])*?/,F._href=/<(?:\\[<>]?|[^\s<>\\])*>|[^\s\x00-\x1f]*/,F._title=/"(?:\\"?|[^"\\])*"|'(?:\\'?|[^'\\])*'|\((?:\\\)?|[^)\\])*\)/,F.link=L(F.link).replace("label",F._label).replace("href",F._href).replace("title",F._title).getRegex(),F.reflink=L(F.reflink).replace("label",F._label).getRegex(),F.reflinkSearch=L(F.reflinkSearch,"g").replace("reflink",F.reflink).replace("nolink",F.nolink).getRegex(),F.normal=P({},F),F.pedantic=P({},F.normal,{strong:{start:/^__|\*\*/,middle:/^__(?=\S)([\s\S]*?\S)__(?!_)|^\*\*(?=\S)([\s\S]*?\S)\*\*(?!\*)/,endAst:/\*\*(?!\*)/g,endUnd:/__(?!_)/g},em:{start:/^_|\*/,middle:/^()\*(?=\S)([\s\S]*?\S)\*(?!\*)|^_(?=\S)([\s\S]*?\S)_(?!_)/,endAst:/\*(?!\*)/g,endUnd:/_(?!_)/g},link:L(/^!?\[(label)\]\((.*?)\)/).replace("label",F._label).getRegex(),reflink:L(/^!?\[(label)\]\s*\[([^\]]*)\]/).replace("label",F._label).getRegex()}),F.gfm=P({},F.normal,{escape:L(F.escape).replace("])","~|])").getRegex(),_extended_email:/[A-Za-z0-9._+-]+(@)[a-zA-Z0-9-_]+(?:\.[a-zA-Z0-9-_]*[a-zA-Z0-9])+(?![-_])/,url:/^((?:ftp|https?):\/\/|www\.)(?:[a-zA-Z0-9\-]+\.?)+[^\s<]*|^email/,_backpedal:/(?:[^?!.,:;*_~()&]+|\([^)]*\)|&(?![a-zA-Z0-9]+;$)|[?!.,:;*_~)]+(?!$))+/,del:/^~+(?=\S)([\s\S]*?\S)~+/,text:/^(`+|[^`])(?:[\s\S]*?(?:(?=[\\<!\[`*~]|\b_|https?:\/\/|ftp:\/\/|www\.|$)|[^ ](?= {2,}\n)|[^a-zA-Z0-9.!#$%&'*+\/=?_`{\|}~-](?=[a-zA-Z0-9.!#$%&'*+\/=?_`{\|}~-]+@))|(?= {2,}\n|[a-zA-Z0-9.!#$%&'*+\/=?_`{\|}~-]+@))/}),F.gfm.url=L(F.gfm.url,"i").replace("email",F.gfm._extended_email).getRegex(),F.breaks=P({},F.gfm,{br:L(F.br).replace("{2,}","*").getRegex(),text:L(F.gfm.text).replace("\\b_","\\b_| {2,}\\n").replace(/\{2,\}/g,"*").getRegex()});var M={block:B,inline:F},N=t.defaults,W=M.block,X=M.inline;function G(e){return e.replace(/---/g,"—").replace(/--/g,"–").replace(/(^|[-\u2014/(\[{"\s])'/g,"$1‘").replace(/'/g,"’").replace(/(^|[-\u2014/(\[{\u2018\s])"/g,"$1“").replace(/"/g,"”").replace(/\.{3}/g,"…")}function V(e){for(var t,n="",r=e.length,i=0;i<r;i++)t=e.charCodeAt(i),.5<Math.random()&&(t="x"+t.toString(16)),n+="&#"+t+";";return n}var H=function(){function n(e){this.tokens=[],this.tokens.links=Object.create(null),this.options=e||N,this.options.tokenizer=this.options.tokenizer||new E,this.tokenizer=this.options.tokenizer,this.tokenizer.options=this.options;var t={block:W.normal,inline:X.normal};this.options.pedantic?(t.block=W.pedantic,t.inline=X.pedantic):this.options.gfm&&(t.block=W.gfm,this.options.breaks?t.inline=X.breaks:t.inline=X.gfm),this.tokenizer.rules=t}n.lex=function(e,t){return new n(t).lex(e)};var e,t,r,i=n.prototype;return i.lex=function(e){return e=e.replace(/\r\n|\r/g,"\n").replace(/\t/g,"    "),this.blockTokens(e,this.tokens,!0),this.inline(this.tokens),this.tokens},i.blockTokens=function(e,t,n){var r,i,s,l;for(void 0===t&&(t=[]),void 0===n&&(n=!0),e=e.replace(/^ +$/gm,"");e;)if(r=this.tokenizer.space(e))e=e.substring(r.raw.length),r.type&&t.push(r);else if(r=this.tokenizer.code(e,t))e=e.substring(r.raw.length),r.type?t.push(r):((l=t[t.length-1]).raw+="\n"+r.raw,l.text+="\n"+r.text);else if(r=this.tokenizer.fences(e))e=e.substring(r.raw.length),t.push(r);else if(r=this.tokenizer.heading(e))e=e.substring(r.raw.length),t.push(r);else if(r=this.tokenizer.nptable(e))e=e.substring(r.raw.length),t.push(r);else if(r=this.tokenizer.hr(e))e=e.substring(r.raw.length),t.push(r);else if(r=this.tokenizer.blockquote(e))e=e.substring(r.raw.length),r.tokens=this.blockTokens(r.text,[],n),t.push(r);else if(r=this.tokenizer.list(e)){for(e=e.substring(r.raw.length),s=r.items.length,i=0;i<s;i++)r.items[i].tokens=this.blockTokens(r.items[i].text,[],!1);t.push(r)}else if(r=this.tokenizer.html(e))e=e.substring(r.raw.length),t.push(r);else if(n&&(r=this.tokenizer.def(e)))e=e.substring(r.raw.length),this.tokens.links[r.tag]||(this.tokens.links[r.tag]={href:r.href,title:r.title});else if(r=this.tokenizer.table(e))e=e.substring(r.raw.length),t.push(r);else if(r=this.tokenizer.lheading(e))e=e.substring(r.raw.length),t.push(r);else if(n&&(r=this.tokenizer.paragraph(e)))e=e.substring(r.raw.length),t.push(r);else if(r=this.tokenizer.text(e,t))e=e.substring(r.raw.length),r.type?t.push(r):((l=t[t.length-1]).raw+="\n"+r.raw,l.text+="\n"+r.text);else if(e){var a="Infinite loop on byte: "+e.charCodeAt(0);if(this.options.silent){console.error(a);break}throw new Error(a)}return t},i.inline=function(e){for(var t,n,r,i,s,l=e.length,a=0;a<l;a++)switch((s=e[a]).type){case"paragraph":case"text":case"heading":s.tokens=[],this.inlineTokens(s.text,s.tokens);break;case"table":for(s.tokens={header:[],cells:[]},r=s.header.length,t=0;t<r;t++)s.tokens.header[t]=[],this.inlineTokens(s.header[t],s.tokens.header[t]);for(r=s.cells.length,t=0;t<r;t++)for(i=s.cells[t],s.tokens.cells[t]=[],n=0;n<i.length;n++)s.tokens.cells[t][n]=[],this.inlineTokens(i[n],s.tokens.cells[t][n]);break;case"blockquote":this.inline(s.tokens);break;case"list":for(r=s.items.length,t=0;t<r;t++)this.inline(s.items[t].tokens)}return e},i.inlineTokens=function(e,t,n,r,i){var s;void 0===t&&(t=[]),void 0===n&&(n=!1),void 0===r&&(r=!1),void 0===i&&(i="");var l,a=e;if(this.tokens.links){var o=Object.keys(this.tokens.links);if(0<o.length)for(;null!=(l=this.tokenizer.rules.inline.reflinkSearch.exec(a));)o.includes(l[0].slice(l[0].lastIndexOf("[")+1,-1))&&(a=a.slice(0,l.index)+"["+"a".repeat(l[0].length-2)+"]"+a.slice(this.tokenizer.rules.inline.reflinkSearch.lastIndex))}for(;null!=(l=this.tokenizer.rules.inline.blockSkip.exec(a));)a=a.slice(0,l.index)+"["+"a".repeat(l[0].length-2)+"]"+a.slice(this.tokenizer.rules.inline.blockSkip.lastIndex);for(;e;)if(s=this.tokenizer.escape(e))e=e.substring(s.raw.length),t.push(s);else if(s=this.tokenizer.tag(e,n,r))e=e.substring(s.raw.length),n=s.inLink,r=s.inRawBlock,t.push(s);else if(s=this.tokenizer.link(e))e=e.substring(s.raw.length),"link"===s.type&&(s.tokens=this.inlineTokens(s.text,[],!0,r)),t.push(s);else if(s=this.tokenizer.reflink(e,this.tokens.links))e=e.substring(s.raw.length),"link"===s.type&&(s.tokens=this.inlineTokens(s.text,[],!0,r)),t.push(s);else if(s=this.tokenizer.strong(e,a,i))e=e.substring(s.raw.length),s.tokens=this.inlineTokens(s.text,[],n,r),t.push(s);else if(s=this.tokenizer.em(e,a,i))e=e.substring(s.raw.length),s.tokens=this.inlineTokens(s.text,[],n,r),t.push(s);else if(s=this.tokenizer.codespan(e))e=e.substring(s.raw.length),t.push(s);else if(s=this.tokenizer.br(e))e=e.substring(s.raw.length),t.push(s);else if(s=this.tokenizer.del(e))e=e.substring(s.raw.length),s.tokens=this.inlineTokens(s.text,[],n,r),t.push(s);else if(s=this.tokenizer.autolink(e,V))e=e.substring(s.raw.length),t.push(s);else if(n||!(s=this.tokenizer.url(e,V))){if(s=this.tokenizer.inlineText(e,r,G))e=e.substring(s.raw.length),i=s.raw.slice(-1),t.push(s);else if(e){var c="Infinite loop on byte: "+e.charCodeAt(0);if(this.options.silent){console.error(c);break}throw new Error(c)}}else e=e.substring(s.raw.length),t.push(s);return t},e=n,r=[{key:"rules",get:function(){return{block:W,inline:X}}}],(t=null)&&s(e.prototype,t),r&&s(e,r),n}(),J=t.defaults,K=S,Q=_,Y=function(){function e(e){this.options=e||J}var t=e.prototype;return t.code=function(e,t,n){var r,i=(t||"").match(/\S*/)[0];return!this.options.highlight||null!=(r=this.options.highlight(e,i))&&r!==e&&(n=!0,e=r),i?'<pre><code class="'+this.options.langPrefix+Q(i,!0)+'">'+(n?e:Q(e,!0))+"</code></pre>\n":"<pre><code>"+(n?e:Q(e,!0))+"</code></pre>\n"},t.blockquote=function(e){return"<blockquote>\n"+e+"</blockquote>\n"},t.html=function(e){return e},t.heading=function(e,t,n,r){return this.options.headerIds?"<h"+t+' id="'+this.options.headerPrefix+r.slug(n)+'">'+e+"</h"+t+">\n":"<h"+t+">"+e+"</h"+t+">\n"},t.hr=function(){return this.options.xhtml?"<hr/>\n":"<hr>\n"},t.list=function(e,t,n){var r=t?"ol":"ul";return"<"+r+(t&&1!==n?' start="'+n+'"':"")+">\n"+e+"</"+r+">\n"},t.listitem=function(e){return"<li>"+e+"</li>\n"},t.checkbox=function(e){return"<input "+(e?'checked="" ':"")+'disabled="" type="checkbox"'+(this.options.xhtml?" /":"")+"> "},t.paragraph=function(e){return"<p>"+e+"</p>\n"},t.table=function(e,t){return"<table>\n<thead>\n"+e+"</thead>\n"+(t=t&&"<tbody>"+t+"</tbody>")+"</table>\n"},t.tablerow=function(e){return"<tr>\n"+e+"</tr>\n"},t.tablecell=function(e,t){var n=t.header?"th":"td";return(t.align?"<"+n+' align="'+t.align+'">':"<"+n+">")+e+"</"+n+">\n"},t.strong=function(e){return"<strong>"+e+"</strong>"},t.em=function(e){return"<em>"+e+"</em>"},t.codespan=function(e){return"<code>"+e+"</code>"},t.br=function(){return this.options.xhtml?"<br/>":"<br>"},t.del=function(e){return"<del>"+e+"</del>"},t.link=function(e,t,n){if(null===(e=K(this.options.sanitize,this.options.baseUrl,e)))return n;var r='<a href="'+Q(e)+'"';return t&&(r+=' title="'+t+'"'),r+=">"+n+"</a>"},t.image=function(e,t,n){if(null===(e=K(this.options.sanitize,this.options.baseUrl,e)))return n;var r='<img src="'+e+'" alt="'+n+'"';return t&&(r+=' title="'+t+'"'),r+=this.options.xhtml?"/>":">"},t.text=function(e){return e},e}(),ee=function(){function e(){}var t=e.prototype;return t.strong=function(e){return e},t.em=function(e){return e},t.codespan=function(e){return e},t.del=function(e){return e},t.html=function(e){return e},t.text=function(e){return e},t.link=function(e,t,n){return""+n},t.image=function(e,t,n){return""+n},t.br=function(){return""},e}(),te=function(){function e(){this.seen={}}return e.prototype.slug=function(e){var t=e.toLowerCase().trim().replace(/<[!\/a-z].*?>/gi,"").replace(/[\u2000-\u206F\u2E00-\u2E7F\\'!"#$%&()*+,./:;<=>?@[\]^`{|}~]/g,"").replace(/\s/g,"-");if(this.seen.hasOwnProperty(t))for(var n=t;this.seen[n]++,t=n+"-"+this.seen[n],this.seen.hasOwnProperty(t););return this.seen[t]=0,t},e}(),ne=t.defaults,re=y,ie=function(){function n(e){this.options=e||ne,this.options.renderer=this.options.renderer||new Y,this.renderer=this.options.renderer,this.renderer.options=this.options,this.textRenderer=new ee,this.slugger=new te}n.parse=function(e,t){return new n(t).parse(e)};var e=n.prototype;return e.parse=function(e,t){void 0===t&&(t=!0);for(var n,r,i,s,l,a,o,c,u,p,h,g,f,d,k,b,m,x="",v=e.length,w=0;w<v;w++)switch((u=e[w]).type){case"space":continue;case"hr":x+=this.renderer.hr();continue;case"heading":x+=this.renderer.heading(this.parseInline(u.tokens),u.depth,re(this.parseInline(u.tokens,this.textRenderer)),this.slugger);continue;case"code":x+=this.renderer.code(u.text,u.lang,u.escaped);continue;case"table":for(a=o="",i=u.header.length,n=0;n<i;n++)a+=this.renderer.tablecell(this.parseInline(u.tokens.header[n]),{header:!0,align:u.align[n]});for(o+=this.renderer.tablerow(a),c="",i=u.cells.length,n=0;n<i;n++){for(a="",s=(l=u.tokens.cells[n]).length,r=0;r<s;r++)a+=this.renderer.tablecell(this.parseInline(l[r]),{header:!1,align:u.align[r]});c+=this.renderer.tablerow(a)}x+=this.renderer.table(o,c);continue;case"blockquote":c=this.parse(u.tokens),x+=this.renderer.blockquote(c);continue;case"list":for(p=u.ordered,h=u.start,g=u.loose,i=u.items.length,c="",n=0;n<i;n++)k=(d=u.items[n]).checked,b=d.task,f="",d.task&&(m=this.renderer.checkbox(k),g?0<d.tokens.length&&"text"===d.tokens[0].type?(d.tokens[0].text=m+" "+d.tokens[0].text,d.tokens[0].tokens&&0<d.tokens[0].tokens.length&&"text"===d.tokens[0].tokens[0].type&&(d.tokens[0].tokens[0].text=m+" "+d.tokens[0].tokens[0].text)):d.tokens.unshift({type:"text",text:m}):f+=m),f+=this.parse(d.tokens,g),c+=this.renderer.listitem(f,b,k);x+=this.renderer.list(c,p,h);continue;case"html":x+=this.renderer.html(u.text);continue;case"paragraph":x+=this.renderer.paragraph(this.parseInline(u.tokens));continue;case"text":for(c=u.tokens?this.parseInline(u.tokens):u.text;w+1<v&&"text"===e[w+1].type;)c+="\n"+((u=e[++w]).tokens?this.parseInline(u.tokens):u.text);x+=t?this.renderer.paragraph(c):c;continue;default:var _='Token with "'+u.type+'" type was not found.';if(this.options.silent)return void console.error(_);throw new Error(_)}return x},e.parseInline=function(e,t){t=t||this.renderer;for(var n,r="",i=e.length,s=0;s<i;s++)switch((n=e[s]).type){case"escape":r+=t.text(n.text);break;case"html":r+=t.html(n.text);break;case"link":r+=t.link(n.href,n.title,this.parseInline(n.tokens,t));break;case"image":r+=t.image(n.href,n.title,n.text);break;case"strong":r+=t.strong(this.parseInline(n.tokens,t));break;case"em":r+=t.em(this.parseInline(n.tokens,t));break;case"codespan":r+=t.codespan(n.text);break;case"br":r+=t.br();break;case"del":r+=t.del(this.parseInline(n.tokens,t));break;case"text":r+=t.text(n.text);break;default:var l='Token with "'+n.type+'" type was not found.';if(this.options.silent)return void console.error(l);throw new Error(l)}return r},n}(),se=A,le=I,ae=_,oe=t.getDefaults,ce=t.changeDefaults,ue=t.defaults;function pe(e,n,r){if(null==e)throw new Error("marked(): input parameter is undefined or null");if("string"!=typeof e)throw new Error("marked(): input parameter is of type "+Object.prototype.toString.call(e)+", string expected");if("function"==typeof n&&(r=n,n=null),n=se({},pe.defaults,n||{}),le(n),r){var i,s=n.highlight;try{i=H.lex(e,n)}catch(e){return r(e)}var l=function(t){var e;if(!t)try{e=ie.parse(i,n)}catch(e){t=e}return n.highlight=s,t?r(t):r(null,e)};if(!s||s.length<3)return l();if(delete n.highlight,!i.length)return l();var a=0;return pe.walkTokens(i,function(n){"code"===n.type&&(a++,setTimeout(function(){s(n.text,n.lang,function(e,t){if(e)return l(e);null!=t&&t!==n.text&&(n.text=t,n.escaped=!0),0===--a&&l()})},0))}),void(0===a&&l())}try{var t=H.lex(e,n);return n.walkTokens&&pe.walkTokens(t,n.walkTokens),ie.parse(t,n)}catch(e){if(e.message+="\nPlease report this to https://github.com/markedjs/marked.",n.silent)return"<p>An error occurred:</p><pre>"+ae(e.message+"",!0)+"</pre>";throw e}}return pe.options=pe.setOptions=function(e){return se(pe.defaults,e),ce(pe.defaults),pe},pe.getDefaults=oe,pe.defaults=ue,pe.use=function(a){var t,n=se({},a);a.renderer&&function(){function e(i){var s=l[i];l[i]=function(){for(var e=arguments.length,t=new Array(e),n=0;n<e;n++)t[n]=arguments[n];var r=a.renderer[i].apply(l,t);return!1===r&&(r=s.apply(l,t)),r}}var l=pe.defaults.renderer||new Y;for(var t in a.renderer)e(t);n.renderer=l}(),a.tokenizer&&function(){function e(i){var s=l[i];l[i]=function(){for(var e=arguments.length,t=new Array(e),n=0;n<e;n++)t[n]=arguments[n];var r=a.tokenizer[i].apply(l,t);return!1===r&&(r=s.apply(l,t)),r}}var l=pe.defaults.tokenizer||new E;for(var t in a.tokenizer)e(t);n.tokenizer=l}(),a.walkTokens&&(t=pe.defaults.walkTokens,n.walkTokens=function(e){a.walkTokens(e),t&&t(e)}),pe.setOptions(n)},pe.walkTokens=function(e,t){for(var n,r=g(e);!(n=r()).done;){var i=n.value;switch(t(i),i.type){case"table":for(var s,l=g(i.tokens.header);!(s=l()).done;){var a=s.value;pe.walkTokens(a,t)}for(var o,c=g(i.tokens.cells);!(o=c()).done;)for(var u,p=g(o.value);!(u=p()).done;){var h=u.value;pe.walkTokens(h,t)}break;case"list":pe.walkTokens(i.items,t);break;default:i.tokens&&pe.walkTokens(i.tokens,t)}}},pe.Parser=ie,pe.parser=ie.parse,pe.Renderer=Y,pe.TextRenderer=ee,pe.Lexer=H,pe.lexer=H.lex,pe.Tokenizer=E,pe.Slugger=te,pe.parse=pe});/*! jQuery v3.6.1 | (c) OpenJS Foundation and other contributors | jquery.org/license */
</script>
</head>
<body onload="$tm.ev_boot()">
<nav><h1>CardMemo</h1> <label><input id="kwd" type="search" oninput="$tm.ev_findkwd()" placeholder="search"></label>
</nav>

<div class="card kwd_pad" id="kwd_show"></div>

<section id="eTopTag" class="card sec_pad">
</section>

<footer id="eFter" class="footer"></footer>
</body></html>
