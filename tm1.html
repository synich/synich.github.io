<!DOCTYPE html>
<html lang="zh">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<title>CardMemo1</title>
	<meta content="width=device-width,initial-scale=1,maximum-scale=1.0" name="viewport">
<style>
body{color:#111;background-color:#f4f4f4;font-family:Montserrat, sans-serif;}
h1{font-size:2em;background-color:#202020;color:#e7e7e7;margin:0;padding-top:0.5em;padding-left:0.5em;}
h2{font-size:1.5em;color:#037;padding-top:0.2em;margin:0.2em;}
h3{color:#409eff;}
p{font-size:1.2em;}
em{color:#00f;font-style:normal;}strong{color:#f00;font-style:normal;}
pre{white-space:pre-wrap;font-size:1.1em;}
code{background-color:#f1f1f1;font-size:1.1em;color:#d73737;}
pre code{display: block;border: 1px solid #cccccc;}
blockquote{border-left:5px solid #bbb;padding-left:0.5em;}
ul li{list-style:circle;}ol li{list-style:hiragana;}
table{border-collapse:collapse;border:1px solid;}th{border:1px solid;}td{border:1px solid;}
textarea{font-family:Montserrat, sans-serif;width:100%;height:80vh;font-size:1.1em}
article{background-color:hsl(60, 9%, 87%);max-width:80rem;margin:0 auto;padding:0 1rem;}
.card{opacity: 0.87;position: relative;max-width:80rem;margin:0 auto 8px;
box-shadow: 0 2px 2px 0 rgba(0, 0, 0, .14), 0 3px 1px -2px rgba(0, 0, 0, .2), 0 1px 5px 0 rgba(0, 0, 0, .12);
border-radius: 8px;background: white;}
div.card h1{font-size:1.8em;color:#026;background-color:#f0f0f0;}
.sec_pad{padding: 8px 12px;}
.art_pad{padding: 2px 12px;}
.kwd_pad{padding: 0px 12px;}
div.edit_zone{border: 4px solid blue;}
div.auto_high{position: relative;}
span.auto_high{display: block;white-space: pre-wrap;word-wrap: break-word;visibility: hidden;}
textarea.auto_high{position: absolute;top: 0;height: 100%;line-height: 20px;padding:0px 4px;box-sizing: border-box;}
div.sd_by_sd{flex:1;}
.prv_pad{padding-left:8px;}
span.kwd_em{color:red}
.footer{margin: 0 auto;text-align: center}
nav {background: #202020;max-width:80rem;padding:0 12px;margin:0 auto;display: flex;}
nav h1 {flex: 3;}
nav label {color: #fff;padding-top: 0.5em;}
.s_item{margin: 10px auto;text-decoration: underline;color: blue;}
@media screen and (max-width: 400px) { #kwd{width: 100px;} }
</style>
<script type="text/javascript">
!(function(top){ top.$tm||(top.$tm={})
var jctx=[];
function load_jctx(){
/*include_mds_start*/
jctx.push(JSON.parse('{"id": "140225", "tag": "lang", "text": "# 【译】Scheme的面向对象呈现（部分）\\n\\n## 关于Scheme的OO呈现。\\n\\n话题因为读者疑议而起，川合先亮出自己的观点，Scheme的OO呈现和别的语言并无太多不同，只是因为规范里没有定义，导致了多种不同的实现。如果采用CLOS的风格（他自己的Gauche就是），形式上就是（动词 名词）。这和很多OO语言采用名词.动词在语法顺序上是反的。但这不是更自然吗？川合先是吐槽，很多人认为名词 动词的方式更合理，只是他们早就习惯了这种方式，并没有真正去思考为什么。\\n\\n## 抽象的角度\\n\\n程序常说要抽象，是以对象还是函数来抽象？川合觉得如果以函数为抽象，将函数互相传递可以带来更丰富的表现力。\\n\\n以树的遍历为例子，如果是面向类的话，需要事先定义tree, leaf, node这些类。\\n\\n如果是函数导向，则将对树操作的函数是这个样子：\\n\\n```\\n(define (tree-walk tree proc leaf? walker)\\n    (define (rec node)\\n      (walker (lambda (n) (if (leaf? n) (proc n) (rec n))) node))\\n    (if (leaf? tree) (proc tree) (rec tree)))\\n```\\n\\nleaf?取树的节点，返回是不是叶子，walker是取得树节点的函数，对node所有子节点进行高阶函数调用的方法。如果树是用列表来表现，leaf?就是(lambda (x) (not (pair? x)))，walker就是for-each。树如果具现化为文件系统，leaf?就替换为file-is-directory?，walker就是(lambda (proc x) (for-each proc (list-directory x)))\\n\\n类指向的好处是，看到数据定义，可以知道要如何操作，但操作就必须要从具体的类或树开始继承（如果支持接口继承，会好一点）\\n\\n函数指向的好处是，在呈现概念时比较纯粹，对树可能的操作并不作限制，如果要让tree-walk运行起来，只要传入适当的leaf?和walker函数就可以。但是也存在可能需要传入的函数不止2、3个，可能会是5个甚至10个，如果看这10个函数，就很难发现tree-walk的本来用意了。\\n\\n## 实例解读\\n\\n看了翻译的文章，看个实际的Gauche-Scheme对象系统，它上承STklos，是从最早的TinyCLOS继承下来的概念，有三个最重要的概念\\n\\n* Class\\n* Generic Function\\n* Method\\n\\nCLOS系统中，Method并不属于特定的Class。通过define-method宏定义出来的变量，\\n是Generic Function的实例。\\n\\nGauche的write/display函数，面对一个复杂对象，会调用和这个对象有关的\\nwrite-object函数，通过它来呈现。类似Lua的`__tostring`或JavaScript的toString方法。"}'));jctx.push(JSON.parse('{"id": "140303", "tag": "security", "text": "# 精巧的安全和DH算法\\n\\n连续的每周六天上班着实太累，周日外面阳光明媚可却在家睡了一下午觉，到了晚上才缓过劲来。基本就在昏睡中度过一个周日。周末只有一天的感觉真是太不好了。\\n\\n一周的工作计划总是被意外的紧急情况打断，这周是安全问题。以前总是看到××公司安全意识薄弱，今天算是到自家头上了，由于协议久远，从现在看来几乎是弱智般的加密防范，也许那个时代根本不知安全为何物吧。从去年年中开始不停地爆出安全漏洞，今次又发现一个问题。因为这次的问题加上上周刚做的加密方案，把以前模糊不清的各种加密原理重新梳理一遍，不需要明白算法，至少对称非对称和信息摘要的应用场合，以及如何组合这些算法达到安全加密的过程，有了个完整的概念。回过头去看，就发现加密算法的精巧。就算知道了加密流程和算法，但设计完整的流程就是能让人徒呼奈何。\\n\\n因为工作太多，自己的学习也被耽搁了。写了小段Scheme代码，但解释器不给力，报了变量未定义错误，却不知道究竟是哪一行的变量，而Scheme的移植性又相当差，稍微有用点的函数都是与实现相关，换个解释器还不知道要修改多少代码。看来以后还是要用Racket，其他的实现都不够完整。用Emacs写代码暂时还没发现特别的好处，一切都可以定制的特性让它成为神的编辑器，可是对不熟悉的人来说实在太难用，我还算是对Lisp比较了解的，用到今天才明白它的设计思路和好处，但真正掌握还需要慢慢熟练，就如这篇教程说的，花一年时间，并且做到理解而不是判断。\\n\\n在不安全的信道建立加密会话，又叫密钥协商，RSA是密钥传输算法，但它完全由客户端决定密钥，严格得说不算协商，只有Diffie–Hellman，简称DH算法是真正的协商，它基于离散对数，A准备a,g,p三个数，B准备b。其中g取2或5，a,b,p则是非常大的质数。p至少1024位，相当于300多位的十进制数。\\n\\n```\\nAlice --- g, p , (g^a) % p, 正文用A表示 --> Bob\\nAlice <--   (g^b) % p, 下文用B表示      --- Bob\\n```\\n\\n也有些文章把A和a称为Alice的DH公私钥，B和b称为Bob的DH公私钥。通过以上交互，Alice和Bob分别计算 (B^a) % p = (A^b) % p = K，接着K就可以用于对称加密的密钥。\\n\\n以上算法解决保密，认证还是要依赖PKI或其它方式。\\n\\nDH算法又细分静态DH和临时DH(EDH)两种，静态的p是不变的，保存在硬盘上，固然节约了计算开销，但和RSA一样都不能实现前向安全，只有临时DH才满足前向安全。DH的生成步骤比RSA要多一步，先生成参数（上文提到的p），再根据参数文件生成DH公私钥对。对应的openssl命令分别是dhparam和genpkey。\\n\\n除了离散对数，也可以用椭圆曲线实现，ECDH。但是从量子计算角度看，椭圆曲线弱于离散对数，考虑到量子计算还不成熟，ECDH还是被广泛接受的。"}'));jctx.push(JSON.parse('{"id": "140307", "tag": "net", "text": "# UDP广播多播和IPv6记要\\n\\n## 广播与多播\\n\\nUDP的socket才有的特性，其中广播是socket级的特性，需要setsockopt时指定SO_BROADCAST选项，而多播是IP级的，比如加入一个多播组，用的是`IP_ADD_MEMBERSHIP`和`IP_DROP_MEMBERSHIP`。\\n\\n为什么一个是IP级，另一个是socket级，大概是因为广播包一定会通过IP层，直到UDP层才会做处理，因此用SO前缀；而多播地址是D类网段，加入多播组时，网卡会知道，会在网卡级收到消息时就过滤，连驱动层都不能到，更别说UDP层了，所以用了IP为前缀的选项。\\n\\n广播时socket如果要接收，要先将自己绑定到INADDR_ANY和广播的端口，一旦感知到消息再通过recvfrom从`INADDR_BROADCAST`的相同端口接受数据。发送则不需要绑定，直接sendto到`INADDR_BROADCAST`的约定端口就可以了。广播的接收与发送因为地址只有一个`IPADDR_BROADCAST`，所以只能靠端口区分，接收端也必须作一次bind。\\n\\n多播是与地址相关，只要bind地址就可以了，和端口关系不大，之所以现在的代码都要绑定地址和端口，是因为历史上Solaris对多播要求必须做端口的绑定，所以后来的代码出于跨平台的考虑，都加入了端口绑定。\\n\\n加入多播组有三个选择，IP_ADD_MEMBERSHIP，`IPV6_JOIN_GROUP`和`MCAST_JOIN_GROUP`。前两个是与IP协议版本相关，不能混用，而MCAST是协议无关，使用的地址结构体也要大得多，至于功能是一样的。\\n\\n## IPv6\\n\\n源和目的地址从32位扩大到128位，分为高低两个64位，高位表示网络类型(单播/组播/任播)、子网标识，低64位则表示网卡地址，可以由MAC地址计算。加上其它的控制标志，IPv6的报头从20字节扩大到40字节。\\n\\nMAC地址48位同样分为上下两个24位，高24位是厂商标识，低24位则是网卡标识。从最高位开始数的第7、8位有特殊的含义，第7位如果是0表示IEEE分配，如果是1则表示本地分配。没见过是1的，第8位是0表示单播MAC，1表示组播MAC。当发送广播包时，会在发送前把MAC地址的第8位改成1，静态情况下通过ifconfig无法看出来，只有运行期抓包才能发现。由于第7和8都是0，所以正常12数字的MAC地址的第2个数字一定0bXX00即4的倍数。\\n\\nIPv6的socket默认可以接收IPv4的连接请求，除非显示打开`IPV6_V6ONLY`选项。所以如果用netstat看到只监听v6端口，不妨先尝试v4的连接。"}'));jctx.push(JSON.parse('{"id": "140313", "tag": "lang", "text": "# 数字的精确与不精确\\n\\n很久不写Scheme，写了个判断质数的函数却永远返回成功，看代码逻辑看不出问题，于是只能一个个函数去试验，好在Scheme交互式写法很容易就能逐个函数地检查问题。终于发现问题出在数字运算的精度上。\\n\\n简单的质数判断逻辑是从2开始，直到这个数的平方根为止挨个去试，如果有一个能被整除，就不是质数；反之就是。但取余是个整数运算，而平方根的结果就算做了取整依然是浮点数，于是用浮点数对整数取余的结果，哪怕它实际上是0，但反应在浮点数里却可能是37e-52这种结果，而这和0是不相等的，导致每次计算的判断都为假，最后这个数就被作为一个质数报上来了。原因找到后，只要在开平方取整后，再做个inexact->exact的操作就可以把浮点变成等值的整数。计算结果也就正常了。\\n\\n出这个错的原因，一方面因为Scheme是弱类型语言，而在强类型语言里浮点和整形计算是要做区分的，像C会报类型不匹配警告，而ML则干脆就区分了整形和浮点数的运算符，但Scheme是在运行时悄悄地执行，也不报错。难怪历史上总有弱类型语言容易出错的报怨，大家也都是一路吃着苦头过来的。另一方面在RnRS里有一个完整的章节就用来描述数字的概念及相应的操作，以前看的时候不明白为什么要花费这么多笔墨描述数字的概念，以及那一族奇怪的exact?,inexact?inexact->exact，这回算是彻底明白了。正因为Scheme弱类型的特点，需要人为地判定并做显示的数字类型转换，才能得出正确的计算结果。\\n\\n说个C语言的浮点数处理，float/double是可以memset的，结果就是0.000000。估计也是为了兼容吧。"}'));jctx.push(JSON.parse('{"id": "140523", "tag": "protocol", "text": "# UTF8编码规范小记\\n\\n看了Lua5.3的work2代码，从简单但个人觉得最常用的UTF8库看起，通过代码很快就明白UTF8的规则。\\n\\n以前看中文UTF8编码，总是奇怪为什么一定是0xEx打头的三个字节，比如“中国”这两个字的编码分别是：E4 B8 AD和E5 9B BD。如今明白UTF8的解析规则，这一切就很好理解了。说句题外话，Unicode的当前最大值范围是0x10FFFFFF(17个位面)，共有21字节，short类型表示不下。\\n\\n首先UTF8是照顾ASCII编码的，毕竟人家是老前辈了，所以第一个字节在0x80以下，UTF8的解析规则就直接结束。如果是大于等于0x80，则最高位1后的1的个数表示后面还跟着几个字节，这些跟在首字节后的字节数据，术语称为continuation byte。因此欧洲编码占用两个字节，则首字节一定是0xCx(110x xxxx)，而CJK的编码占用三个字节，首字节必然是0xEx(即1110 xxxx)。如果不符合此规则，则为非法。\\n\\n首字节的规则看完了，接下来说continuation byte的约束，代码是这样写的：\\n```\\nif ((cc & 0xC0) != 0x80)  /* not a continuation byte? */\\n        return NULL;\\n```\\n也就是说，continuation byte的值范围一定是在0x8*~0xB*之间(必须是10** ****)。由于continuation byte的范围被限定了，能表达的有效位数只有6位，每个字节的低6bit被按序组装成完整的值，就可以得到对应的Unicode值了。\\n\\n附更全的考古\\n\\nRob Pike 在 2003 发的邮件，讨论的是 UTF-8 编码诞生之初的故事。Rob 和 Ken 是 UTF-8 的共同发明人。读罢不仅深化了对 UTF-8 编码的理解，更为大师们的智慧所折服。现在整理成文分享给大家。\\n\\n故事是从 Plan 9 操作系统开始的。为了让 Plan 9 支持 Unicode (ISO 10646)，Rob 和 Ken 选用了 UCS 编码（标准制定的 16 位编码方案，后来扩展成了 UTF-16）。虽然使用了 UCS 编码，但对 USC 编码并不满意，原文是 but we hated it。当整个工作几近完成的时候（大约在 1992 年的九月份），X/Open 组织有人给他们打电话，让 Rob 和 Ken 投票支持所谓的 FSS/UTF 编码方案。Rob 和 Ken 提出要根据自己的经验设计一个更好的编码方案。X/Open 的人接受了这个提议，但要求尽快提交方案。吃晚饭的时候，Ken 在餐桌上就完成了编码规则的设计。回到实验室，他们给 X/Open 发邮件说明了新编码的设计大纲。X/Open 的人则回复说 Rob 和 Ken 的方案比他们自己方案更好，并且询问什么时候能实现这一编码。当天是周三，Rob 以为 X/Open 会在下周一开始投票，所以就保证说下周一给出完整实现。\\n\\nRob 和 Ken 当晚就开始编码，Ken 负责实现 UTF-8 编解码逻辑，Rob 负责改造现有的 c 库和图形库。到了第二天，编码工作就已完成，俩个人开始使用新编码对 Plan 9 上的文本文件进行转码。到周五，Plan 9 系统完全基于新编码运行了。Rob 和 Ken 称这种新的编码为 UTF-8。然后，UTF-8 改变了历史。\\n\\n根据 Google 2012 年的统计，当年 web 领域 UTF-8 编码的占比就已经超过了 60%。\\n\\n可是，Rob 和 Ken 为什么没有采用 X/Open 的编码方案呢？Rob 指出 X/Open 的编码方案和当时的好多编码一样，没有自同步这一特性，所以他们提出了 UTF-8 方案。我们会在下文解释这个自同步特性。\\n\\n为了把事情说清楚，Rob 联系 Russ Cox 查询当年的来往邮件。然后 Russ 真的找到了相关邮件，甚至还给出了 1992 年的邮件发送记录！邮件记录了 UTF-8 最早的设计方案。\\n\\nFSS/UTF 编码全称是 File System Safe Universal Character Set Transformation Format。为什么要考虑这个文件系统安全呢？因为在 unicode 出现之前，计算机普遍使用 ASCII 编码。UNIX 的文件系统使用 /，也就是 0x2f，作为路径分隔标志。另一方面，c 语言使用 0x00 表示字符串的结尾。而 ISO/IEC 10646 (Unicode) 制定 UCS-2 编码使用双字节编码，最多支持表示 65535 个字符（code point）。UCS-2 编码一定会出现某个字符编码包含 0x2f 或 0x00 情况。例如，「⼀」的 UCS-2 编码是 0x2f00，同时包含了 0x2f 和 0x00。UNIX 系统和 c 语言基本没法处理使用 UCS-2 编码的数据。如果非要使用 UCS-2 编码，那就只有一个办法——将老数据使用 UCS-2 转码。这显然不现实。\\n\\n所以 Rob 和 Ken 给新编码制定了几条指导原则：\\n\\n兼容历史文件系统，文件名不能包含 0x2f 和 0x00\\n兼容现有程序，非 ASCII 字符编码不能部分包含 ASCII 编码\\n与 UCS 编码转换要简单\\n首字节需要指明后续字节长度\\n编码格式不要浪费空间\\n自同步\\n前两条讲得是一个事情。ASCII 编码范围是 0x00-0x7f，新编码方案中非 ASCII 字符的编码序列不能包含 0x00-0x7f 范围的内容，不然现有的系统和程序会把这部分内容当成 ASCII 处理而导致混乱。\\n\\n第六条说的是错误恢复。简单来说，程序从文件的任意部分开始读取，可能只读到一个字符的部分编码字节，从而无法实别这一字符。但没关系，编码方案需要支持程序快速跳过有问题的字节，然后正常解码。\\n\\n这六条原则一言一蔽之，多快好省。\\n\\n最终的编码方案使用变长字节编码，不同范围的字符使用不同长度的字节编码，最多使用 6 个字节，可表示范围为 [0,0x7fffffff]。\\n\\n其中，ASCII 字符 [0x00-0x7f] 的编码方式与现有 ASCII 编码保持一致，已有的 ASCII 编码无需做任何改动。其他字符使用多字节编码。\\n\\n为了实现第一条和第二条原则，多字节编码的每个字节的最高位永远是 1，而 ASCII 字符编码的最高位是 0，所以从根本上杜绝了编码冲突。\\n\\n为了实现第四条原则，多字节编码以 11{1,5}0 开头。1 和 0 之间 1 的数量表示后续字节的长度（这里借用了正则的表示方式）。\\n\\n为了实现第五条原则，编码规定，如果一个字符的编码可以有多种表示方式，则选用最短的表示。\\n\\n为了实现第六条原则，编码序列的后续字节都是以 10 开头的。如果程序读到了受损的文件，只能有三种情况：1、当前字节最高位是 0，则是合法 ASCII 字符；2、当前最高两位是 11，则是合法的多字节编码；3、当前字节最高两位是 10，则是其他字符编码的一部分，跳过，直到读到最高位为 0 或最高两位为 11 为止。\\n\\n举个例子，汉字「吕」的 Unicde 编码是 U+5415，对应二进制为 0b0101010000010101，需要 15 bit，所以使用三字节编码，对应二进制拆成（从低位到高位）三部分，分别是 0b0101, 010000, 0b010101，再拼上编码前缀得到 0b11100101, 0b10010000, 0b10010101，对应十六进制为 0xe5, 0x90, 0x95。所以汉字「吕」的 UTF-8 编码是 0xe59095。\\n\\n完整的编码规则如下表：\\n\\nBits  Hex Min  Hex Max  Byte Sequence in Binary\\n1    7  00000000 0000007f 0vvvvvvv\\n2   11  00000080 000007FF 110vvvvv 10vvvvvv\\n3   16  00000800 0000FFFF 1110vvvv 10vvvvvv 10vvvvvv\\n4   21  00010000 001FFFFF 11110vvv 10vvvvvv 10vvvvvv 10vvvvvv\\n5   26  00200000 03FFFFFF 111110vv 10vvvvvv 10vvvvvv 10vvvvvv 10vvvvvv\\n6   31  04000000 7FFFFFFF 1111110v 10vvvvvv 10vvvvvv 10vvvvvv 10vvvvvv 10vvvvvv\\n最终 ISO 标准化的 FSS/UTF 编码方案可以从这里获取。\\n\\nIETF 也制定了 RFC3629 对 UTF-8 做了进一步标准化。RFC3629 制定的版本将 UTF-8 的表示范围限制在了 [0-10FFFF]，所以只需要 4 个字节就够了。标准原文\\n\\nRestricted the range of characters to 0000-10FFFF (the UTF-16 accessible range)\\n如果大家对这个问题感兴趣，可以参考 Stijn de Witt 的这篇文章。此处就不展开讨论了。"}'));jctx.push(JSON.parse('{"id": "141002", "tag": "lang", "text": "# setjmp的机制及lua中的异常\\n\\nsetjmp/longjmp是C标准的函数，常用的做法是用来实现异常/跳转。原型如下：\\n\\n* int setjmp(jmp_buf env);\\n* int longjmp(jmp_buf env, int err);\\n\\n这组函数依赖于`jmp_buf`的变量类型，从接口声明看，\\n`jmp_buf`是值类型的，但每次调用setjmp都会把当前的各个寄存器值包括PC保存起来，\\n供以后longjmp来恢复，所以这个`jmp_buf`一定是指针语义的。\\n看了GCC 3.4.5的定义，将宏简化之后就是 typedef int `jmp_buf`[16];\\n也就是说`jmp_buf`类型其实是个数组，而数组在传参时又是作为指针来处理，\\n所以setjmp能改变`jmp_buf`所对应的值，之后的longjmp才能恢复回来。\\n实测在32位的XP系统上，只用了0~6共7个值，其余都是置0。\\n\\n如果没有setjmp就直接longjmp，因为PC值和各种寄存器值一定是乱的，\\n必然导致系统崩溃。调试模式下是ntdll下抛异常。\\n而每一次的setjmp都将当前状态写入到jmp_buf中并返回0，\\n因此多次调用setjmp以后，longjmp会回到最后一次setjmp的地方。\\n\\n再说说setjmp在lua中的应用。\\n\\nlua在内部执行操作时，大都是调用luaD\\\\_pcall，\\n这内部调用到了luaD\\\\_rawrunprotected，在内部会进入LUAI\\\\_TRY这个宏。\\n如果用C++编译，这个宏就被展开成try{}块；如果是C，\\n这个宏就被展开成if (setjmp() == 0) {action}这样的形式。\\njmp\\\\_buf的值会随着L带到action中，一旦发生无法补救的错误，\\n就会通过luaD\\\\_throw函数，在判断了存在jmp\\\\_buf后，\\n再调用LUAI\\\\_THROW宏，实质就是longjmp的形式直接返回。\\n由于先判断了L中是否有jum\\\\_buf，也就不会有异常的死机问题。\\n\\nLua的语法层面并不支持try/catch/throw这种显式的异常处理方式，\\n但是做一些不符合规定的操作，比如数字加nil，\\n字符串和nil拼接等等动作，Lua会执行出错，\\n如果不是在pcall内执行，导致程序提前终止，\\n这其实就是一种变相的固定类型的异常，\\n只是自定义异常类这块功能没有开放罢了。\\n\\n只有系统自带的操作，在执行非法时抛出个可捕获的异常，\\n用pcall/xpcall来模拟try/catch，而用类似`1+nil`的方式模拟throw。\\n要想程序能够跑完，就要时刻注意用pcall的方式把函数执行做个封装，\\n而如果想提前终止，也可以用故意写非法语句来达到类似的效果。\\n但是写的非法语句毕竟不能携带自定义信息，只能靠代码行号来反推，\\n效果上就差强人意了。\\n\\n"}'));jctx.push(JSON.parse('{"id": "150329", "tag": "lang", "text": "# Lua的编译期和运行期区分\\n\\n虽然是一门解释型语言，但Lua其实也分了编译期和运行期，只是通常在lua的程序里顺带把luac的功能给自动执行了。但作为一个运行效率为第一位的语言，编译期更多的意义在于把源码转译为伪字节码，不会作过多语义上的校验。比如下面这个例子。\\n\\nfunction a:foo()  print(\\"hello\\") end\\n\\n如果直接用lua运行，会报attempt to index global \'a\'(a nil value)，但实际上在编译期，这仍然是可以通过的。\\n\\n如果用luac先执行，会得到两个chunk，一个是main，一个是函数定义。main中有四条语句：\\n\\nGETGLOBAL    CLOSURE   SETTABLE  RETURN\\n\\n前两句是可以顺利执行的，a虽然不存在，会默认赋值nil。但到SETTABLE时，这个nil就原型毕露了。也就对应上面运行时那句attempt to报错。\\n\\n也就是说luac只能做到语法层面的校验，但基于性能的考虑，不会做语义层面的判断(如果要做的话，代码量可就不止当前的2万行了)。\\n\\n说下MetaLua对编译的作法，在编译理论里，parse和compile是两个阶段，source经过parse只能生成AST，再把AST送compile才能生成执行码(可以是机器指令或VM指令)。YACC也好ANTLR也好，都只是parse工具。Lisp语法就直接是AST了所以不需要parse但还是要有compile。由于有两个阶段，MetaLua也提供了mlp和mlc两个工具对应。非Lisp风格的编程语言如果要扩展，多少都要在parse阶段做些处理，典型如增加关键字，就在parse阶段把新增的关键字转译成AST里的function，才能在compile后正常执行。\\n\\n因为MetaLua的存在，将源程序先编译成luac再执行就能看出明显的区别，compile阶段的操作可以在编译成luac时很直观地看出来，且不会带到执行期。\\n\\n最后补充几个Lua的语法细节\\n\\nLua的函数到底是传值还是传引用？这是我从王垠的\\n[这篇文章](http://www.yinwang.org/blog-cn/2016/06/08/java-value-type)\\n想到的。\\n\\n上面这篇文章的结论是Java从语义层面，只有引用类型。原生类型看起来像值类型，\\n只是一种实现的优化。既然Lua也是从Lisp/Scheme系继承而来，\\n就做个实验验证下，到底Lua是否符合王垠所定义的引用类型。\\n\\n字符串拼接如果报nil错误，假如有多个nil只会提示最后一个错误，不确定是否lua编译器按从右向左计算参数的方式？"}'));jctx.push(JSON.parse('{"id": "150616", "tag": "lang", "text": "# 函数参数的传值与传引用及语义\\n\\n一年前因为工作上的需要，把一些文档在Apache上以网页的形式呈现出来，当时为赶着快速上线，就边学PHP边对着HTML语法，用最原始的方式把网站给搭出来了，做完后又忙着其它事，网站就放着没去优化它。\\n\\n最近偶然看网页时，看到有文章提到PHP的函数是显式区分传值和传引用的，如果不在参数前加上&，就按传值调用。可怜我之前一直以为PHP和Java一样，是自动根据类型做判断，复杂对象类型自动转引用的。结果回头再看代码，大量的数据库中查找出来的记录，在传参时都把array以值的方式复制了一遍再做处理。因为流程是单向的，数据库中取到的数据也就是在网页上展现一下，当时能看到效果就没去深究，才导致这个问题一直过了一年才发现。\\n\\n今天和大牛聊起这个事情，大牛说学任何语言，第一步就是要搞明白函数的传递模型。在任何语言中，函数都是最基本的抽象单元，一门语言可以没有类，可以没有原生Hash，但一定会有函数。而函数的边界，也基本就是语言的边界了。比如是传值还是传引用，静态词法定界还是动态词法定界，函数是否可匿名等。\\n\\n简单地记一下，C/C++，PHP默认是传值调用，可以用&显示指定传引用调用。\\n\\nLua，Python的函数定义中参数没有修饰符，也没有提领提作，因此语法上没有传值还是传引用的区分。数字和字符串出于实现的方便，会被inline，表现出的行为类似传值调用，复杂类型如Lua的table，Python的List、Dict的行为类似传引用。\\n\\n除函数之外，像foreach的循环，PHP也是可以使用引用的。比如\\n\\n$vec1  = array([1, 2], [3, 4], [5, 6]);// 此处语法不正确的，只为示例二维数组\\n\\nforeach ($vec1 as $r) {$r}这里的$r也是值，即使它指向的是个数组，但仍然是复制了一份，不能修改。如果想显示地表示引用，需要写成foreach($vec1 as &$r)。而像这种for循环，在Lua里如果值是简单的数字/字符串，是值类型，如果是复杂结构，就是个引用，可以修改原始值。\\n\\n以我所知的语言像Java，Ruby，JavaScript都不提供语法级的值和引用区分，当然像Perl这种词法超级复杂的语言是支持通过\'\\\\\'显示引用的。\\n\\n追记：在读R5RS的1.1语义节看到这么一句，Scheme过程的参数总以值的方式传递，即无论过程是否需要实参的值，实参表达式都会在过程获得控制权之前被求值。ML、C和APL是另外三种总以值的方式传递参数的语言。也就是说从Scheme的层面来看，不论是传值还是传引用，由于都是eager eval，都算是Call-by-Value，至于传的是值是引用，都是要计算的。这与Haskell语言懒惰求值(Lazy-evaluation)的语义，或Algol 60语言按名调用(Call-by-name)的语义截然不同。在Haskell和Algol 60的这两种语义中，直到过程需要实参表达式的值时，才会对它们求值。为什么Scheme中不区分传引用和传值呢？一来因为函数式语义，根本就不赞成传引用这种会改变参数的行为，在那里变量只有在返回时才允许被改变，另外Scheme也多少有点脱离实际机器，更偏向于理论研究的语言，那么为了提高速度而只传一个const&的方式，在它的语言规范里也被认为不是必须的，所以没有被记录。因此在Scheme看来，这些过程式语言中传值与传引用的区别，那都不是事，究竟是Call-by-Value还是Call-by-Name才是它真正要关心的语义。\\n\\n学一门语言，最重要的是学idiom，而最基础的，则是理解函数的行为，是为记。\\n"}'));jctx.push(JSON.parse('{"id": "150628", "tag": "lang", "text": "# lua闭包和其他语言比较以及修改upvalue\\n\\n## 闭包能力比较\\n\\n构建闭包的特殊性在于捕获非本地的栈上变量，如果是访问全局变量，不能称为闭包。最早明确这个特性的大约是scheme吧，lua和js也照样实现。而python则用nonlocal关键字更加显示地表明要捕获上级栈的变量，但同时又不能是global，所以看似怪异，细想倒也有几分道理。\\n\\n```\\ndef foo():\\n    conf = 555  #  newclo捕获这个变量稀松平常，都能做到\\n    def newclo():\\n        nonlocal conf\\n        print(conf)\\n\\ndef main():\\n    conf = 111  # 起初以为即使foo中不定义conf，lua和js能捕获这个定义，但python和scheme不行，实际是lua和js把变量提升为全局变量，能引用但已不是闭包了\\n    foo()\\n```\\n\\n## 修改闭包自由变量\\n\\nlua闭包中引用的upvalue类似于面向对象中实例的私有成员，是不应该被外界修改的，或者说外界也感知不到这个存在。今天看lua的手册，debug库中存在getupvalue/setupvalue函数对，利用这两个函数可以获取/修改upvalue。这两个函数访问upvalue的方式是用一个int类型的index编号，而文档对这个编号的含义也不作保证，所以这个功能放在debug库也算合理吧。\\n\\n首先对闭包来说，upvalue是什么时候创建的呢？是在lparser.c中由解析过程创建的，当解析器每识别一个变量，如果这个变量在函数栈上未定义，则会逐级地往上找直到找到为止，之后就在函数的proto中增加一个upvalue。因为每个闭包都含有独立的upvalue列表，所以upvalue必然是词法定界的。\\n\\n虽然文档说index的含义是随意的，但通过代码还是可以知道，就是upvalue在函数中被最先引用的顺序。如果一个函数定义如下：\\n\\n```\\nlocal function foo()\\n  local b = 2\\n  local a = 1\\n  return function () print(a) b = b+1 end\\nend\\n```\\n\\n内部返回函数先调用了print(a)，print在栈上未定义，则它就是第一个upvalue，又因为print是定义在顶级函数的`_ENV`变量中，所以这个函数的第一个upvalue就是_ENV，第二个自然是a，第三个是b。这个a、b的定义顺序无关。另外由于`_ENV`是在lua5.2后引入的定义，在lua5.1中的话，1就指a，而2是b。也就是说这个功能是版本不兼容的。不过本来lua的兼容性就不是完美向后，且这个又是个debug函数，考虑到引入`_ENV`后的概念统一性，这个变动还是值得的。\\n\\n至于在其它语言中是否存在修改upvalue的机制，暂时还没有找到，等找到了再补上。\\n"}'));jctx.push(JSON.parse('{"id": "150719", "tag": "os", "text": "# 在CentOS和FreeBSD上安装OpenResty的一些记录\\n\\n花了两个周末的时间，分别在CentOS6.6和FreeBSD10.1上安装并跑起了OpenResty，虽说没什么技术难度，但有些遇到的问题还是记录一下，方便以后查找。\\n\\n一开始我是想在cygwin上编译，但是卡在MAP_BIT32宏上过不去，想想cygwin毕竟只够练手，真正的编译还得用正牌的系统，就装上了VMWare9，上真正的OS。\\n\\n先说CentOS，这个问题比较少，因为我的硬盘和内存都不足，所以下的是CentOS6.6的minimal版，默认的安装包非常少，像GCC、Perl、OpenSSL都没有，好在yum非常成熟，这些很快就装好了。但有两个问题要说一下：\\n\\n1.安装完系统，没有eth网卡，通过ifconfig只能看到lo，不知道为什么采用这么谨慎的策略。简单地话通过ifup eth0就行了，但关机就不行了，还是得改/etc/sysconfig/network-script/ifcfg-eth0，把ONBOOT=yes写上，这样从windows才能访问虚拟机。\\n\\n2.编译和安装其实问题都不大，一把直接过，但nginx启动后，windows下却怎么也连不上，始终报超时。netstat看到端口是开放的，ssh也能用啊。这个问题想了一个多小时，改nginx配置不少于10次始终无果，最后终于有网上文章说是防火墙作祟，最后chkconfig iptables off一把，问题解决。今天再看，发现CentOS默认是打开SELinux的，也许这就是原因吧，SELinux还没细研究，总之能用就算OK了。\\n\\n再说FreeBSD，这个问题就麻烦多了，由于文档少，国内用得人不多，理解它的ports系统就花了很久。我以10这个版本说说：\\n\\nports是以源代码编译为导向的软件包机制，又名ports collection，这是BSD家族的正牌安装方式，默认安装时如果没有装，需要通过portsnap工具先生成目录结构。原理就是在/usr/ports/下生成一个巨大的目录树，其中的顶级的Makefile和README等文件，各种软件又按类别放在子目录下，比如devel/、www/等等。因为顶级有Makefile，所以可以在/usr/ports目录下通过make执行查找，（其实用whereis命令更简单）。要安装时，再进到具体的目录，通过make install方式就自动编译装好了，在这个目录的Makefile会记录源代码的下载地址、编译选项等等。默认不需要configure，这点比较方便。ports也是需要更新的repository，更新工具就是portsnap fetch命令。第一次要执行portsnap extract，但这个操作非常耗时，执行一次以后就不要再执行了。下载后的repository保存在/var/db/portsnap/目录下，都是分散的文件，我目前的版本有大概2万5千个文件。\\n\\n但每次都要自己编译未免太费时间，于是就有了直接下载编译好的文件方式，这就是pkg。在版本10以前，是pkg_***工具集，到10之后，统一成pkg一个命令。所以官方对pkg的命名是pkgng以示区别。在执行之间一样要先下载repository，使用pkg update命令。但默认的repository用的美西服务器，速度太慢，始终只有10k，导致update一直无法完成，好像是FreeBSD不同意其它网站同步源，国内源很少，也许根本没有。只能在pkg.freebsd.org上找，最后尝试了pkg0.ydx.freebsd.org后，速度终于上到20～30k，总算完成了pkg update。和ports不一样，pkg方式是保存在/var/db/pkg/repo.sqlite文件里，就是个sqlite3的文件，里面记录了2万5千个软件的地址、描述信息等。除了ydx源，2017年6月又发现了几个新源：\\n\\n* pkg0.bme.freebsd.org\\n* pkg0.nyi.freebsd.org\\n* pkg0.isc.freebsd.org\\n* pkg1.chinafreebsd.cn\\n\\nupdate完成后，后面的安装软件就顺利了，把OpenResty依赖的包装上，需要注意的是，OpenResty是用gmake编译的，在Linux下，就等同于make，但FreeBSD的make却不同于gmake，所以还要另外再安装gmake。我自己也手欠，装了个gmake-lite，真搞不懂make这么个小玩意还有lite版。结果还是报错，于是又对gmake-lite做了个软链接生成gmake，接下来的编译都很顺利了。编译并安装后，从windows访问也没有问题。\\n\\n不管CentOS和FreeBSD，编译都不是问题，说明OpenResty的软件包做得很好，主要还是对系统的配置等外围工作花费时间。"}'));jctx.push(JSON.parse('{"id": "150904", "tag": "lang", "text": "# Chomsky的4型文法与BNF\\n\\n按序有4种文法，从强到弱排列如下\\n\\nType-0：也称短语文法，产生式为A-〉B，A和B均包含terminal和nonterminal，表达力最强，等价与图灵机\\n\\nType-1：也称为上下文相关文法，CSG。是0型的特例，要求|A|<=|B|。与0型的差异暂时还不明白。\\n\\nType-2：也称为上下文无关文法，CFG。是1型的特例，要求A只能是一个nonterminal，由于只有一个，因此也就没有上下文，故而当然是上下文无关了。对应下推自动机Push Down Automaton，是带一个栈的有限状态机扩展，比图灵机的双栈要弱。下推自动机也分确定型和非确定型，两者的能力不相等，其中非确定型等价于CFG。\\n\\nType-3：也称正则文法，是2型的特例，由于2型已经限定了左侧，故3型的限制在于右侧至多有两个符号，且只能是两种形式，A->a，或者A->aB。a是terminal，A->a很好理解，状态已经推导确定，A->aB我的理解是3型文法具备cleene闭包特性，可以无限推导，但由于不带栈，故不能记忆状态。而A->Ba这种文法，必须要先把B压栈，再lookahead一次，才能确定是否符合文法规则，因此不属于文法3类型。3型对应的自动机是有限状态机。\\n\\n前面说的是语言学的纯理论部分，接下来看BNF方法记述\\n\\nBackus Naur Form定义于1960年代，是一种格式化的语法记法。\\n所谓格式化是可以严格推导、能用数字证明的方法。\\n\\n原始的BNF格式能表达Context Free Grammar。只是由于语法偏少，\\n所以后人又做了扩充。扩充有两大流派\\n\\n* EBNF Extended BNF，是PASCAL的作者wirth做的扩展，后来也被ISO标准化定案\\n* ABNF Augmented BNF，有IETF的RFC标准定义的扩展格式\\n\\n与我最初想像的不同，有RFC背书的ABNF并不是最广泛使用的格式，\\n还是EBNF用得更多一些。比如Lua5.1的EBNF定义，使用了22条规则就把所有语法规则定义完了。\\n两套表示法以及BNF的表达能力是一样的，只是书写时的简便程度不同。\\n似乎并不是所有的语言都能用EBNF来表达，不过语言最好还是要设计得符合简洁才好。\\n\\nBNF只是一种记述法，对应编译的语法分析阶段，像YACC的语法就和BNF很类似，\\n但不完全一致，典型的比如`::=`这个符号就直接简写成`=`了。\\n好在没有特别大的差异，基本都是一眼就能看得懂的转义。"}'));jctx.push(JSON.parse('{"id": "151006", "tag": "os", "text": "# Andoird上用kbox模拟linux环境\\n\\n随着这几年安卓机的军备竞赛，一拨拨的性能“落后”的旧手机被淘汰下来闲置在家，却又不能发挥作用。手头就有一个13年的老机，A8单核，1G内存放在角落蒙灰已经一年多了，想想自己好歹算个程序员，这个设备不利用起来甚是可惜，这些年也不爱折腾设备了，这次国庆闲来有空，就想着把安卓装个linux，多少也能跑个apache搭个服务器，多少也算物尽其用。\\n\\n由于是老机，root挺顺利的，顺便熟悉了下adb和fastboot的一些命令。安装好busybox，按说明busybox是自带httpd的，但是只有httpd没有PHP或其它脚本，这服务器也是没什么实际价值，还好集成PHP的APK非常丰富，比如anmpp这个项目，在android上部署nginx、mysql、php和postgre，可以实现一个完整的服务器功能。要注意apk只是个UI，毕竟体积摆那儿，还需要另外下载anmpp.zip包才行，第一次不知为何下载下来的二进制包不正确，解压后无法运行，又重新下了一次，运行后用浏览器打开，熟悉的phpinfo界面弹出，这算是基本可用了。有了服务器，再配上路由自带的花生壳域名绑定，这样随便在哪里，都可以访问自己的网页了，不用花一分钱，而且因为是手机还特别省电，非常好。\\n\\n## kbox\\n\\n到2019年2月，kbox共4个版本，kbox1已经不维护，kbox2在ls时总有些小问题，\\n加上busybox带的工具似乎-h选项总是没用，kbox4安装不成功，只能用kbox3。按作者自己的介绍，\\nkbox3是为Android5适配的，但我刷了Andoird5.1再安装kbox3总是报dlopen not found，\\n一度只能在Android4.4下使用kbox3。直到有一天偶然在stackoverflow上看到有人提和我一样的问题，\\n才在这个页面的2015年6月30日日志下看到月个fix版的libfakechroot.so可以下载，\\n将这个重命名成libfakechroot.so并替换原来/lib/下的文件，Android5下也可以用kbox3了。\\nkbox用deb的包格式，所说是busybox支持，所以工作量可以少一点。\\n\\nkbox3配备的GCC版本是4.9，但默认安装后，哪怕编译最简单的文件，也会报cannot create temporary file in /tmp/:错误，我按这个关键字，\\n都说是TMPDIR环境变量设置有问题，可我看脚本写的TMPDIR=/tmp却看不出错误，\\n换成/home，就报类似的/home/:错误，导致我一直以为是多了后面的:引起的路径非法。\\n因为手头还有一部Andoird4.4上跑的是GCC4.7没有问题，再看GCC4.7的写法，\\n是TMPDIR=$KBOX/tmp，再看KBOX=/data/data/jackpal.androidterm，并按这个方式改写了GCC4.9，\\n终于成功运行，虽然还会报unused DT type 0x1d in libmpc.so之类，\\n在另一篇文章中看到，通过readelf -d libmpc.so可以看到0x1d段类型是RUNPATH的信息段，即使丢弃也没有影响，这才放心。\\n\\n那么为什么GCC在kbox下一定要写成TMPDIR=$KBOX/tmp这种完整写法，其它软件却没有这个问题呢？\\n联想到上面提到的libfakechroot问题，查了些资料，大概是这样的：\\n因为kbox旨在未root的手机上安装类linux环境，但显然安卓的app是被安装到/data/data目录下各自的目录，\\n因此就需要伪造一个根目录环境，这也是fake这个名字的由来。\\nfakechroot的原理，就是改写环境变量LD_PRELOAD=/data/data/.../lib/fakechroot.so，\\n让linker先行加载这个动态库，并在这个库中提供open/chroot/dlopen等一系列接口，\\n让程序以为自己是在/目录下。但是也许是GCC没有用到linker动态加载（似乎说得通），\\n所以当TMPDIR目录直接写成/tmp，找到的是安卓设备真正的/tmp，显然kbox无法向这个目录写入数据，因此一直不能正常运行。\\n可惜kbox的作者在GCC4.7版本中并未注释TMPDIR必须是完整路径，可能在了解的人看来，这不值一提吧。\\n\\ngit也有点小问题，连接https域名会报ssl证书不对，解决方法是git config --global http.sslVerify false去掉校验即可。\\n\\n另外Andoird5.1上的dropbear无法使用，提示不是position independent execution。\\n难道作者自己都没有测试过吗？还好有utelnet程序，这个程序虽然能跑，\\n却每次在putty上输入用户名就结束，看帮助文档才发现需要utelnetd -l /bin/bash指定程序才可以。\\n作者给dropbear作了一个sshd_daemon.sh的wrap脚本，参数很多，其中-A,-U,-G,-N,-C这5个，\\n都是为了解决Android系统去掉了用户概念导致程序不兼容。\\ntelnet也可以作个类似的wrap脚本。用telnet连上后速度好像比ssh稍快，shell下显示也正常，\\n但vim打开文件，显示的行数只有20行，似乎是哪个TERM的参数没有设置对，这个问题暂时还没有解决掉，留待以后。\\n\\nroot与非root安装linux的区别是这样的：没有root的设备最麻烦的就是权限问题，虽然是你的手机，可是程序却不能随意地写和执行，如果是root过的手机，就可以很明显地在/data/data目录下看到，每个程序的用户名都是不一样的，类似app12这样带了数字(当然会有些预装app的用户名是system，这种会有多个)，由于每个程序只能在自己的目录下为所欲为(这样也防止了程序往SD卡乱写)，因此kbox的安装包必须要放在这个jackpal目录下。所以我通过电脑把安装包放到SD卡，在terminal看来却是root用户，好在SD卡可读，于是通过cat命令把安装包移到jackpal目录下(原生可能没有mv)，然后在jackpal下运行。kbox的网站提供了一些deb包，像coreutils、dropbear、gcc等，下载到本机用dpkg安装，因为只是个人作品，没有仓库也没有apt。建议先装dropbear，是个轻量级的ssh server，有了这个就可以通过电脑来远程执行手机上的命令了。由于安卓的单用户特性，dropbear提供了6个专门的选项，好在作者提供了`ssh_daemon.sh`可供学习。kbox上提供的最重量级的是gcc，拿lua试编译了一次，问题多多，列举如下\\n\\nlocale.h里的localeconv()->decimal_point[0]这个函数是个假实现，原因是bionic C库把它阉割了，导致编译不过，好在这个地方直接写死返回\'.\'就行，然后没有ranlib命令，更坑的是ar好像也不支持s选项，其实原因是默认的ar是指向busybox的软链接，功能不完整。只要找到gcc所在的真实目录，在PATH路径下做个软链接或写个shell脚本，再删除原来指向busybox的ar以可以用解决了。最后在链接时又报没有log2，看了源代码这个是属于C89后加入的函数，看来bionic把这个也给阉割了，唉，还好luaconf.h已经预料到这种情况，打开C89宏，总算编译成功了。\\n\\n看了kbox3，也是对android的C库各种吐槽，包括奇怪的权限设置、服务缺失、乱用UID、奇葩的API等等问题，连lua这么简单的程序都被编译得如此恶心，想来那些大神们只会遇到更奇怪的问题吧。\\n\\n折腾半个下午加晚上，以后配上一个键盘，至少出门在外可以简单地用手机做点事情了，前提是最好有个大点的屏幕。等有空再试试kbox3，或者GNURoot Wheezy等类似的非Root版linux，手机也要发挥工作机的作用才行。\\n\\nkbox只能算半截的工程，它不是完整的apk程序，而是依赖能提供shell环境的apk，并利用这个环境内可写可执行(/sdcard只能写，不能执行也不能创建软链接)，构造一个属于kbox的环境。而Termux，相当于把kbox做的事情和apk整合到一起。"}'));jctx.push(JSON.parse('{"id": "151129", "tag": "os", "text": "# 两个一直理解错误的编译问题\\n\\n1.dll是可以直接替换而不需要重新编译的。\\n\\n一直以来，我都以为只有so可以做到直接替换，而dll则不同。因为dll可以选择在编译时候通过.lib方式将dll中的符号表进行绑定。此前我一直认为只有代码中显示的调用LoadLibrary方式调用才是真正安全的。但简单写了个例子，发现如果dll导出的全是C函数的话，则可以直接替换，至少在我验证中是没有问题的。而所说的dll hell更多的是发生在导出类的场景下。反正我是严格使用C风格，也不喜欢导出类这种使用方式。至于具体原因，还要再仔细看看书。\\n\\n2.MingW可以使用第三方提供的.lib/.dll方式编译，且可正常用。\\n\\n遇到目标机器只安装了MingW，但库却是给VC准备的。但既然MingW可以编译出.lib/.dll，且看了下MingW自带的.a，二进制文件从结构上和.lib是大致一致的。于是修改.lib为.a，当然还要加上前缀lib，用-l选项可以编译成功，跑了几段程序都正常运行。原因我想是在windows平台，.a只是个命名习惯，最终二进制层面还是要遵守习惯，.dll肯定是PE结构，现阶段大胆猜测.a也是和.lib是一样的。\\n\\n以上两点只有不完整测试，不敢保证一定正确。后面如果从资料里看到解释的原因，再回到这里修正。"}'));jctx.push(JSON.parse('{"id": "160109", "tag": "lang", "text": "# GCC编译4阶段的一些理解\\n\\n起因是这样的，安装了GCC4.7和4.8两个版本，但是4.8不知什么原因输出临时目录总是出错，原因及修改方法见这里，\\n所以只能用4.8配合-pipe选项先生成.o文件，再用4.7链接成可执行程序。于是想了解下这么做为什么是可行的。\\n\\nC语言的编译分4个步骤，第一步cpp预编译，后缀名.i，这一步因为宏的机制几乎没有新特性，且功能也不多，不会有太大的变化。这个不详细研究了。第二步cc1编译成汇编语言，这是整个编译最复杂的地方，涉及语言特性支持和优化，一般说的版本就是指cc1，C++则是cc1plus。\\n由这步生成后缀.s的汇编文件。第三步as(又名gas)将汇编语言转机器码并生成对应平台的目标文件，如ELF或COFF文件，最后由ld将多个目标文件生成可执行程序或库，文件格式为ELF或PE。\\n\\n其中的第三、四步用的as和ld，其实并不在gcc的范畴内，其版本号是属于binutils这个项目下，\\n因为as的工作在于把汇编语言转机器码，并生成对应平台的目标文件，\\n生成机器码这步没什么好说的，不同指令集有各自的代码，相对比较直观。\\n但要生成各种平台对应的目标文件，这就涉及到一个抽象层，而一般用得最多的，\\n就是BFD库，如果输入as -v也会出现as BFD version字样，生成的目标文件经ld链接，\\n而ld只是个软链接，真正的文件可能是ld.bfd，也可能是ld.gold。\\n看名字就知道ld.bfd表示使用BFD库来生成平台相关文件，而ld.gold则是google研发的链接版本，\\n据说速度很快，但我的机器上没有安装，也不清楚依赖的gold库到底是个什么库，\\n只知道gold版只支持ELF，所以GNU必然不变采用作为默认实现，其功能应该和BFD是类似。\\n\\n由于是两个软件包，怎么配套并没有一个非常严格的要求，因此用gcc4.8编译，最后用4.7链接也问题不大。只是默认会链接到4.7的库目录。如果想用4.8的目录，则可用用--sysroot选项来指定。\\n综上来看，编译的几个阶段，重心是不一样。而每两个阶段间都需要有一个规范。cc1和as之间采用的是AT&T规范，as和ld之间则是平台相关的目标格式。正是因为有了这些规范，4步编译才能看起来仿佛一步似地完成。\\n\\n## 一些有用的编译指令\\n\\n`gcc -print-file-name=libc.so`获得libc.so的位置\\n\\n`libstdc++`是`g++`的专属库，gcc命令不能自动和C++程序使用的库联接，使用`gcc -lstdc++`就可以。\\n\\n静态编译带运行时，`g++ -static-libgcc -static-libstdc++`\\n\\n编译时设置rpath和dynamic linker（绝对路径）：gcc -Wl,-rpath=\'/my/lib\',-dynamic-linker=\'/my/lib/ld-linux.so.2\'\\n\\nrpath，全名run-time search path，是elf文件中一个字段，它指定了可执行文件执行时搜索so文件的第一优先位置，一般编译器默认将该字段设为空。elf文件中还有一个类似的字段runpath，其作用与rpath类似，但搜索优先级稍低。搜索优先级:\\n\\n`rpath > LD_LIBRARY_PATH > runpath > ldconfig缓存 > 默认的/lib,/usr/lib等`\\n\\n如果需要使用相对路径指定lib文件夹，可以使用ORIGIN变量，ld会将ORIGIN理解成可执行文件所在的路径。`gcc -Wl,-rpath=\'$ORIGIN/../lib\'`\\n\\n无法编译程序时，可以通过patchelf修改rpath和interpreter。\\n\\n```\\npatchelf --set-rpath \'$ORIGIN\' your_program\\npatchelf --set-interpreter /my/lib/ld-linux.so.2 your_program\\n```\\n\\n利用$ORIGIN方式把依赖so放一起，portable化。也可以使用pwd获取当前路径，使用相对路径指向本地lib。\\n\\n```\\npatchelf --set-rpath `pwd`/../lib your_program\\npatchelf --set-interpreter `pwd`/../lib/ld-linux-x86-64.so.2 ./your_program\\n```"}'));jctx.push(JSON.parse('{"id": "160131", "tag": "os", "text": "# Widnows的编译库的理解\\n\\n## 生成动态库\\n\\nwindows下生成动态库，会输出3个文件。通过dumpbin把三者的段内容分别打印并比较一下。\\n\\nexp类型也是COFF OBJECT，即和编译生成的.obj是一样的。\\n\\n打印/symbols，只有exp有大量的输出，而dll和lib没有输出。因为/symbols表示COFF 符号表，只有exp和obj能输出。exp的symbols分两类，Static和External，意义很直接。\\n\\n打印/imports，只有dll有大量输出，大多是依赖系统库，如MVVCRT等，而lib和exp无输出。只对exe和dll有意义。\\n\\n打印/exports，dll和lib都有大量输出，而exp没有输出。dll和lib的输出差异在于，dll输出的符号和函数中一致(似乎是Name)，而lib的符号则多了一个下划线前缀(似乎是Symbol Name)。\\n\\n另外编译后的资源文件.res也是COFF OBJECT类型，也是按段来组织的。\\n\\n另外lib和exp都无法反编译，即/disasm无输出，应该是内部只有符号表，无text段的关系。而dll是有大量的反汇编代码。说明编译时导入的lib也就是起到了符号寻路的作用，没有真正有意义的代码段。\\n\\ndll的反汇编代码，尤其跳转类je/jne指令后面都是绝对地址，说明不是地址无关代码，需要运行时做基址重定位，即ReBase修正。\\n\\n## 使用动态库\\n\\n使用dll库时需要一个同名的.lib，称为导入库。而windows下的静态库的后缀也是.lib。这是经常让人迷惑的地方。由于Linux没有对应导入库的形态，编译时直接指定.dll已可以。\\n\\n但是MinGW移植的GCC做得更友好一点，编译时直接指定dll文件名，就可以生成可执行文件，其实是不需要导入库这东西。相比起来VC作为原生编译器，限制反而更多一点。MinGW作为Port，当然也能支持导入库。一般情况下VC生成的导入库可以直接被GCC读取(用cdecl导出的)，如果是stdcall导出的符号，因为VC会加上“`_`”前缀，所以把“`_`”去掉就可以给GCC用了。还有一种方式是用pexports从dll中导出.def文件，再用dlltool也能生成导入库。从这个角度看，MinGW直接支持编译时指定dll，也是理所当然的。\\n\\n另外MinGW下有一个工具叫reimp，整个代码都不大，简单地看了代码，导入库的格式如下，头部的MagicNumber是!<arch>\\\\n共8个字符，再之后是结构体\\n\\n```\\nstruct ar_hdr {\\n  char ar_name[16];\\n  char ar_date[12];\\n  char ar_uid[6];\\n  char ar_gid[6];\\n  char ar_mode[8];\\n  char ar_size[10];\\n  char ar_fmag[2];\\n};\\n```\\n\\n而且这个结构体会重复多次出现，此结构出现两次后，会出现一段字符串表，所有需要导入的符号都在这里。但是数量上会多一点。比如dll有128个符号，字符串表会有128x2+3=259个符号。x2是因为每个符号都是有一个对应的`__imp_`对应符号，另外+3是在首部有`__IMPORT_DESCRIPTOR_`和`__NULL_IMPORT_DESCRIPTOR`开头的字符串，末尾处有一个0x7F开头的字符串(对应ASCII的del键，不是个可打印字符)。这3个去掉之后，剩下的导出符号就可以对上了。\\n\\n最后用这个方法做了个试验，找到一个tcmalloc.dll，然后通过pexports生成.def文件，再用dlltool生成导入库，用gcc编译成功通过且能运行。直接用dll也运行正常。\\n"}'));jctx.push(JSON.parse('{"id": "160204", "tag": "security", "text": "# SSH点滴\\n\\n## 验证方式\\n\\n从日志能看到3种验证方式，debug3: preferred publickey,keyboard-interactive,password。后两种表现上都是密码输入，区别是password是RFC-4252(sec 8)定义的，而keyboard在RFC-4256定义。理论上keyboard会询问用户各种问题，但从实现角度看，只用了密码一种方式。所以两种不同的规范看起来就像一样了(甚至xshell面对keyboard模式能自动输入密码)。两者都可以在`sshd_config`中独立控制，keyboard是KbdInteractiveAuthentication(也可以不设置，用ChallengeResponseAuthentication)，password是PasswordAuthentication。\\n\\n使用的加密套件是一直在加强的，遇到过用15年的dropbear连接20年的版本，会报没有合适的mac套件，如果是openssh可以加`KexAlgorithms diffie-hellman-group1-sha1`强制允许不够安全的加密方式。\\n\\n## 公钥登陆\\n\\nTinysshd不支持用户名密码登陆(甚至还删除了RSA公钥，只支持ed25519)，又比如安卓的用户体系被裁剪，只有PubkeyAuthentication。部分魔改的安卓程序可以支持用户登陆，比如dory的nodejs，就支持将密码做了SHA256的值保存到~/.ssh/doryauth，不过不是通用做法。\\n\\n首先使用ssh-keygen -t rsa -C \\"your@email\\"工具产生公私钥对，会提示输入passphrase，这是私钥的一个密码，相当于做了二次的保密。如果是生产环境，这个私钥的密码是必须要设置的，我用在内网和虚拟机比较多，再说用公钥登陆本来就是为了方便，所以暂时先不设了，但从安全性角度看，为私钥加个密码，在私钥丢失的时候，还是很有作用的。除了rsa还有dss, dsa, ecdsa, ed25519等很多方式，从7.0版本开始默认不再支持dss。\\n\\nSSH2版本的公钥文件格式有IETF SECSH(似乎又叫SSL PEM)和OpenSSH两种格式，SSH1已经看不到，不去管它。\\n\\n* SSL PEM: 文件内容以`-----BEGIN RSA PUBLIC KEY-----`开头，以`-----END RSA PUBLIC KEY-----`结尾\\n* OpenSSH格式: 从OpenSSH 7.8版本(18年7月)开始作为默认格式，内容全在一行，以ssh-rsa开头，rsa可以换成其它加密技术\\n\\n命令执行后，生成密钥对，分别是私钥id\\\\_rsa和公钥id\\\\_rsa.pub(算法不同名字会有差异)。需要把公钥上传服务器你想登陆的用户名目录下。\\n把生成的公钥文件id\\\\_rsa.pub上传并导入ssh服务器的用户目录下的~/.ssh/authorized\\\\_keys文件(OpenSSH和Dropbear都是这个文件)。这样服务器的配置就完成了。补充一点权限相关内容，.ssh目录需要0700权限，而authorized\\\\_keys则需要更严格的0600权限。\\n\\n为什么上传公钥呢，因为公钥是你发送给运维的，当然不能含有密码，从这个角度看，私钥是更不能外泄的。\\n\\n接下来就是配置客户端了，只要能拿到RSA私钥的关键数据(即N、E数)，私钥的文本格式不重要。选用putty或SecureCRT的作法稍有不同，\\nputty用的格式比较特殊，需要使用puttygen这个工具把ssh-keygen生成的id\\\\_rsa转成.ppk后缀的文件，\\n不过这不影响私钥的数据。如果原始的私钥是带passphrase，puttygen在转换时也会要求输入原始密码，如果输入正确，可以修改密码，\\n如果输入错误，则是无法转换的。passphrase是用sha256加密，所以puttygen实际上是无法得知原始密码的。当然转换后保存的也是经sha256计算得到的值。**如果用命令行ssh，一定要保证id\\\\_rsa以LF结尾**，出现过误将回车符保存成CRLF，导致ssh报错Invalid format。如果本地有多份id\\\\_rsa私钥，用-i选择指定。虽然默认会用当前用户名路径下的id\\\\_rsa，但不代表绑定当前用户名，比如从A机器用u1用户登陆B机器的u2，即使私钥文件放在u1的目录下，只要指定了登陆B用u2用户，私钥就会和u2目录下的公钥匹配。*私钥放在哪里，并不代表绑定哪个用户，但公钥放在哪个用户的目录下，是绑定该用户的*。\\n\\n到这步，公钥和私钥都准备好了，怎么在登陆时让putty自动找到私钥呢？putty对不同的ssh服务器有个session的概念，首先load需要登陆的服务器session，在Connection->Data菜单的Auto-login Username输入登陆的用户名，\\n这样就能在服务器对应目录下寻找公钥，然后在Connection->SSH->Auth的Private key file for authentication中配置转换好的.ppk私钥路径。最后把这些改动save到putty的session中。之后对这个session直接点击open，就可以用公钥方式登服务器了。\\n\\n**归纳起来就是：先用ssh-keygen生成公私钥，公钥上传sshd服务器，私钥指定给ssh客户端。**\\n\\n在配置了公钥登陆后，甚至可以禁止密码登陆方式，修改/etc/sshd/sshd_config文件，PasswordAuthentication no。默认允许密码认证。\\n\\n为了方便使用公钥，专门设计出了ssh-agent和ssh-add这两个程序。首先用ssh-agent $shell启动代理，代理会在/tmp用域套接字监听，然后用ssh-add添加私钥，如果有phrase则输入，代理就得到了私钥。之后再连接远程就不再需要输入私钥的phrase。\\n\\n主流的生成公私钥对工具是ssh-keygen，偏偏putty提供了类似的puttygen，但格式又不同，生成公私钥对后，千万不要用save public key按钮，因为openssh不识别这种文件格式，需要把窗口中的内容复制出来。\\n\\n用termux时遇到了server refused our key的错误，折腾再三，将`/usr/etc/ssh/sshd_config`内容加上这几句。似乎0.73版本后没有问题。\\n\\n```\\nPasswordAuthentication no\\nPubkeyAuthentication yes\\nAuthorizedKeysFile ~/.ssh/authorized_keys\\n```\\n\\n通过看putty的log，了解公钥认证的流程。网络连接和加密算法协商之后，putty会从私钥中生成公钥并发给服务器，如果配置了该公钥，服务器会返回接受该公钥。然后putty再发送公钥的签名，签名也被接受后，就进入Access Granted状态。打开一个session，得知agent-forwarding port-forwarding pty user-rc x11-forwarding这些属性，设置pty的速度，双向都是38400kbps，至此会话建立成功。\\n\\n结合以上的流程，可能失败的原因是缺少最后一句配置，指定公钥文件保存的位置。对sshd来说，收到putty提供的公钥，如果不知道去哪里找，显示会refused。但是对多用户系统是否也能这么写？怀疑应该是可以的，因为即使是公钥登陆，也必须指定用户名（公私钥对和用户名没有关系）。有了用户名，sshd就能从~映射到对应的用户目录。\\n\\n## keygen的使用\\n\\n* ssh-keygen -y -f 私钥  # 从私钥计算公钥，可用-yf\\n* ssh-keygen -l -f 公钥  # 从公钥计算指纹，可用-lf\\n\\n## 隧道\\n\\n平时用ssh感觉永远是连上远程主机并打开shell，其实只有加密连接远程主机这步不可缺少，在远程主机上打开shell是个默认行为，如果选择不打开shell，这时连接已经建立，就可以利用这条加密连接做些其它事，这就是隧道（又叫端口转发，因为是基于ssh的端口，工作在TCP层）。\\n\\nssh连接建立后，双端配合启动隧道功能。隧道在客户端打开，所以是ssh在监听，而sshd负责消息转发。以L本地转发为例，客户侧的程序ClientProgram和ssh间是明文通信，ssh和sshd之间当然是密文，到了服务端的sshd侧，再按明文发给预设的端口，就完成了隧道的使命。\\n\\n因为ssh原本的任务就是加密并在server端启动shell进程，隧道无非是把启动shell改成向另一个指定端口转发消息，和整个流程是契合的。\\n\\n## 认证代理\\n\\n使用公私钥登陆时，如果所有主机用同一个私钥还好，但现实往往不同主机配不同私钥，ssh只认`id_rsa`一个名字（算法不同名字不同），这就导致要手动指定私钥。为解决这个问题，就有了ssh-agent和ssh-add这套方案，可以一次性手动把所有私钥通过ssh-add加到agent，如果私钥有passphrase，只要在add时输入一次，只要agent不挂，以后不用再输入，这样看起来私钥带上passphrase也并不麻烦。但有点让我介意的是，即使退出终端agent并不会结束，下一个人或者其他人登陆这台主机，可以可享agent规则登陆所有你登陆的主机，只是无法知道passpharse。虽说并没有更多的权限，但总感到有些不妥。\\n"}'));jctx.push(JSON.parse('{"id": "160214", "tag": "lang", "text": "# stackless和stackfull概念在VM上的一些理解\\n\\n以前知道有个stackless的python实现，但不明白是什么意思，看一篇分析Lua虚拟机的文章也提到了这个概念，就做个记录。\\n\\nstackless python的意义在于不需要C语言的call stack作为python的堆栈，因此CPython又被称为stackfull的实现。由于依赖了C语言的堆栈，必然对实现有了限制，典型的就是多线程之间需要Global Interpreater Lock，导致实际的单线程。又比如yield的一层限制。再比如GC就很难用tracing方式，而只能用引用计数方式。Lexical closure也没有实现，而是保存变量的引用，因此Python有个Vyper的OCaml实现，解决的好像就是这个问题。\\n\\n反观Lua的虚拟机实现，基本上是stackless方式的实现，摘一段奇异技术点博客的分析：基于虚拟机的语言的call stack有两种可能的设计，一是称为stackfull方案，借用Host主机的stack，Byte－Code的函数调用比如Call指令对应native代码的函数调用，即X86的call指令，这种情况下，虚拟机stack随Byte－Code函数调用层次的增加而增长。二是stackless方案，由虚拟机维护额外的call stack数据结构，Byte－Code的函数调用和其他指令一样，在虚拟机的同一个循环中完成，虚拟机的stack不体现Byte－code函数的调用层次。\\n\\nLua虚拟机的stack，存储在lua_State结构的StkID stack字段中，是个数组，包括函数指针（Lua和C都可以），函数的参数和返回值，Lua函数的局部变量。但在stack字段缺少C代码stack的东西，如C语言的call stack，函数的返回地址，帧指针栈指针EBP、ESP信息。那么这些信息保存在哪里呢？ 其实Lua虚拟机是双stack结构，保存在CallInfo＊ ci这个字段里。CallInfo结构保存了函数位置，这个函数可以是Lua或C。当Lua作为caller时，返回地址保存在CallInfo的u.l.savedpc里，如果C函数作为caller，返回地址在VM stack。C函数发生yield时，VM的stack被破坏，该coroutine下次resume的地址由u.c.k决定。\\n\\n所以对yield设计来说，相当于在整体stackless的Lua虚拟机设计中导入一个额外的stackfull，也因此Lua51要求C语言的yield必须在return时调用，只有这样，才能很好地衔接stackless和stackfull两种结构。就好像GC，在Lua整体采用的是root－tracing，或名mark and sweep方式，但为了方便C语言操作，也提供了`luaL_ref`／`luaL_unref`的引用计数方式让C语言影响虚拟机的工作状态。"}'));jctx.push(JSON.parse('{"id": "160218", "tag": "lang", "text": "# 使用Lazy-Stream方式实现Fibnacci数列\\n\\n起因是看到一篇讲stackless方式coroutine的文章，给的例子是用js写的。用Lua重写了一遍，感觉有些思路上以前没有想到过，做点纪录。\\n\\n要实现Lazy，假设采用function fibNext()的形式，每一次调用fibNext()，都会返回下一个数，且可以无限调用。显然这个函数要return一个数字，那么要怎么实现状态的更新从而在下一次调用时得到下一个数据呢？如果用OO的方式，很简单把状态和方法绑定到一个对象上就可以了，那么函数式中对应的就是闭包，在Lua中的名字就是upvalue。\\n\\n首先函数的基本形态应该是这样的：function fibNetx() return ?, fibresult  end。?处肯定只能是一个function（因为限定了不用OO方式）。传入的function会替换掉fibNext，因此需要在fibNext外面做一个wrap\\n\\n<pre>\\nwrapNext function()\\n  local i, j, next = 0, 1\\n  local yld = function(k, i)\\n  next = k\\n  return i\\nend\\n\\n next = function() yld(function()\\n   local tmp = i; i = j; j = temp + j\\n  j) end\\n\\n  return next()\\nend\\n</pre>"}'));jctx.push(JSON.parse('{"id": "160304", "tag": "web", "text": "# Openresty代码初读\\n\\n我在公司内网的服务器从Apache httpd换成Openresty也有半年左右了，切换之后没有去深入研究，最近重新开始研究，一点初步的理解，记录在这里。\\n\\nnginx给我最初的印象不是快或者节省资源，而是它居然的扩展机制。现在的软件都说自己是插件化体系，放个dll或so进去就可以增加功能，但nginx却需要每次重新编译，把扩展代码和执行程序编在一起才行。好像淘宝有个Tengine的扩展，可以用动态库的方式扩展，不过openresty没有用，那就还是看nginx的代码好了。\\n\\nopenresty的编译也是用configure脚本，却不是用GNU的auto系，而是在平级目录下有个auto目录，里面有各式各样的脚本检测OS或编译器选项，这块不清楚是不是个独立的项目，又或者是作者自己手工写的。\\n\\nnginx编译添加模块的方式是在./configure后面用--add-module=指定路径方式，从configure脚本可以看到，是在指定目录下寻找config文件，如果有再从config文件读入相应的源代码和模块名信息。config定法也不复杂，就定义一些shell变量，然后统一被写入编译文件列表。nginx内一个很重要的概念是模块，代码中是个名为ngx_module_t的结构体，官方提供的http和mail功能是用模块，扩展功能也是同样实现这个模块。在core目录下，可以找到`extern ngx_module_t  *ngx_modules[];`这样一句声明，而在main函数中就直接循环遍历这个数组了。找遍nginx目录也没有找到这个变量定义的地方，再结合每次扩展需要重新编译，恍然大悟去编译目录objs/下果然找到`ngx_modules.c`这个文件，里面赫然定义了`ngx_module_t *ngx_modules[] = {`以及之后的若干个模块，之就是nginx静态编译扩展的原理了。模块分了CORE、CONF、HTTP和MAIL四个大类但定义是分散在core/http/mail三个目录下，似乎除了CORE会用于逻辑判断，其它几个并没有严格地规定。模块版本号目前都是1，也没有做逻辑判断，可能是为了将来扩展吧。另外模块中真正起作用的，就是content指针和7个函数指针。不过有些扩展模块并未实现函数指针，只有content是必须实现。或许是因为大多数模块并不需要参与nginx的核心调度，只要有content环境能和核心进行交互即可。像openresty中非常重要的lua扩展，也只不过实现了7个函数指针中的`init_process`这一个函数。\\n\\n由于模块是编译进程序，运行自然也就和nginx在同一个地址空间，遍观如今排名前20的主流语言，体积小功能完整的，还真就只有lua了。因为扩展是直接在nginx的worker进程跑，如果扩展出点问题，worker进程是会直接挂掉的，开始我不知道，用ngx.say去遍历打印ngx内部的成员名和类型，结果浏览器就没有结果显示，后来看了代码才发现，因为table中有ngx.say不支持的类型值，结果lua扩展直接触发了abort();这个问题后续还是要注意，如果nginx中要执行长会话动作，这种abort还是很危险的。"}'));jctx.push(JSON.parse('{"id": "160328", "tag": "protocol", "text": "# PNG格式的启发\\n\\n都说PNG格式是二进制格式中的优秀范例，文档也写得非常好。这周断断续续看了RFC2083，常有拍案之处。\\n\\nPNG的总体格式是8字节的格式头和一系列的chunk构成。\\n\\n先说8字节头，8字节分别是137 80 78 71 13 10 26 10。第一字节特意用了一个非ASCII字符，防止编辑器将PNG文件误认为是文本文件，同时可以检测程序是否过滤了最高位(似乎说的是邮件处理程序？)。Lua编译出的二进制文件也用了类似的思路，不过那里用还是ASCII的不可打印字符027。\\n\\n头部之后就是一连串的Chunk。Chunk也有个固定格式，4字节的长度+4字节的类型+数据+CRC32。为什么把长度放在类型前面？因为CRC是流式计算的，也许一开始并不知道最终的长度，所以如果把类型和长度互换，可能会造成CRC的计算困难。而且因为最开始已经有文件头，先放长度也不会造成识别的困难。再说一个小细节，4字长度文档特意标注是一个无符号整数，但范围是2^31-1，即最高位一定是0，原因是考虑到部分编程语言无法表示4字节的无符号整数(至少Java就是这样)。另一个我在工作中遇到有点类似的情况是，可能会有代码一开始错误地按int来实现，当发生对接错误的时候，才意识到要改代码，这时只要限定范围即可，算是保留了一点裕量。\\n\\n类型部分很有趣，PNG的Chunk类型有两种。一种是大写字母开头，称为Critical，比如IHDR、IEND，再一种是小写字母开头，如sPHY。如果增加了新的Critical类型，客户端无法识别，可以提示用户升级客户端，而不重要的Chunk又可以跳过。当然Critical不是必须要带，只是携带的时候，就相当于需要服务端和客户端做一个版本同步保证。这种策略不需要版本号，也可以达到C/S各自地升级兼容。\\n\\nPNG的设计目标是用于文件的保存和传输，但其中Chunk的设计策略对交互式的协议也是有借鉴作用的。"}'));jctx.push(JSON.parse('{"id": "160412", "tag": "lang", "text": "# C++模板引起的一个二进制兼容问题\\n\\n问题来源是这样的，公司的基础库里，用于实现Observer模式的Signal库是模板写的。模板嘛实现代码都在.h头文件里，在之前的一个版本里，因为要解决一个bug，对Signal模板类增加了两个成员变量，在提交时内部几个人评审，都觉得模板既然是在各自的cpp内实例化，且不涉及对象的传递，即使改变了类大小，也不会引起问题。然而最终集成的时候，就是挂在Signal类里。\\n\\n一度我以为是应用的使用者在两个不同的库之间（这两个库编译时引用不同版本的头文件），传递了Signal的实例引起，但后来经同事提醒，加上回忆起之前做的一个实验，发现确实是增加类变量引起的不兼容问题。原因如下：\\n\\n模板类在编译时，的确是在每个编译单元即cpp生成的.o中实例化出来的，但是这个实例化出来的函数（或类）的链接属性是Weak。通过readelf -s命令可以查看。正常如果不是手写attribute((weak))属性，编译出的要么是Global要么是Local。由于是Weak属性，如果实例化时的参数类型一样，生成的函数名也一样，而在不同模块生成的.o中的模板代码尽管不同，但因为名字相同，在最终的链接环节，会因为Weak的原因随机挑一个进入最终的可执行程序。而挑选哪一个是由链接器决定的，无法预测。因此当A库用了size更大的模板类，而B库用了原始版本，链接时如果恰巧选择了A库实例化的Signal类最终进入可执行程序，则会破坏B库中紧跟在Signal类后的变量。反过来，如果链接时选择了B的类进入可执行程序，则A在执行时还是用的原始库，不会破坏数据，但修改Signal的bug的期望也落空了。\\n\\n怎么在A、B库不同步更新头文件的情况下，解决这个问题呢？目前能想到的只是保证不崩溃，但做不到百分百修复bug。方法就是模板类也用pImpl方式实现，即模板类的成员变量仅使用一个void* internal指针，具体的数据在这个指针所指向的堆上扩展。这样不论链接器选择哪个版本的模板类，大小始终是一样的。如果用的不是模板类，也一样要遵守这个原则，只是非模板类因为是Global，所以可以控制最终链接进的版本，而使用模板就没这么幸运了。换句话说，如果要用C++的类作为接口，不论是普通类或模板类，为了扩展并保证二进制兼容，一定要遵守pImpl守则。"}'));jctx.push(JSON.parse('{"id": "160505", "tag": "os", "text": "# 安卓野Rom手动清毒记\\n\\n去年底换了个TCL手机，因为原生Rom不好用恰好网上的Rom也比较多，反复尝试就Flyme还算好用，可惜在ROM之家或ROM基地等几个网站上下到的Flyme多少有点问题。有一天偶然在论坛上看到有人自制的Flyme包，使用后觉得算是做得比较好的Rom，就一直用到现在。期间发现流量开关经常会被自动打开，但正好过去的三个月移动送了好几个G的流量，也没觉得有关系，甚至一次被自动下了软件，也没下决心去查。直接上个月底手机自动发短信并且自动读取验证码，然后被扣6块钱时，我才觉得彻底被愚弄了。此时发现原本的root权限也没有了。此时即使查出了病毒，也无计可施了。\\n\\n从种种迹象来看，中毒的可能性有两个，一是野Rom自带的病毒，但是这病毒的潜伏期4个月也太长了吧，再一个就是上个月曾经下载了一个免费的VPN软件。其它都是从豌豆荚下载，可能性很小。缩小疑问点开始确认。\\n\\n先重新线刷野Rom，并查杀病毒，果然立刻查出一个病毒文件。但是这个文件和上一个病毒的名字也不一样，难道现在的刷机脚本还会在安装时起个随机化的名字了？然后再重装那个免费VPN软件，没有问题。且网上查了下那个VPN软件是个相当知名的软件，看来问题不是在VPN上。\\n\\n这样一来，就肯定可以锁定野Rom了，既然已经查出一个，那很可能就还有别的，永远不要相信杀毒软件报的无病毒假象。因为之前简单研究过安卓的文件布局，重点就落在/system/app和/system/priv-app目录里，并结合Kingroot的预装软件分析结果，陆陆续续找出有5、6个疑似病毒。比如有个叫Boot.apk的程序，居然在app和priv-app下都安装了一份，简直丧心病狂，删！再一个名字叫System.apk的程序，虽然名字很高大上，但安卓怎么会取这么个名字呢，删。安卓apk有个好处，文件内容可以直接看，尤其是AndroidManifest.xml这个文件能看出很多蛛丝马迹。举个例子，有个apk的package写的是com.android.sadk。名字一个就露着古怪，网上只查到一条有人说360报是病毒，但其它没有报。宁可错杀不能漏过，删。还有个APK，minSdkVersion居然是8，正常至少也会是15以上吧。用这么低的版本图个啥？删。还有个APK，居然申请了DELETE_PACKAGE权限，靠就凭这点，不是病毒都把丫给删了。如是断断续续地看了两天，把所有名字可疑的APK看了个遍，到后来几乎要对PicoTTS下手，还好查到svox是被google收购的公司，才放过一马。不过其实就算删了，对我日常使用也没什么影响。\\n\\n回想起来，最大的问题还是我自己大意了，之前虽然也听过野Rom的各种危害，但没往深处想，被自动打开流量开关也没在意。直到被自动订阅增值服务扣了6块钱才醒觉被人当了羊沽。幸运的是一方面自己多少还对系统有点了解，加上安卓毕竟比Windows要简单得多，什么dll注入，二进制感染似乎还没有发展起来（或许是我不知道），要清除还是容易多。对不想折腾的人，建议还是买iPhone算了。\\n\\n手机对于现在的人，已经关联了太多的隐私和金钱，这个很多人已经说得很透了。所以在这上面，投入再多的安全性关注都是有必要的。至少我自己的主手机就是iPhone，安卓上装的无非就是新闻、阅读和游戏之类的app。但这次事件之后，我也感觉到后怕，今天我还有精力去逐个APK查看是否可疑，未来还有这样的精力去做吗？安卓Rom我是不敢再刷了，下一部手机，我想也只能换iPhone（或者Nokia的1系，不知还能不能买得到），安卓终究只能作为一台游戏机般的存在了。\\n"}'));jctx.push(JSON.parse('{"id": "160522", "tag": "web", "text": "# Url Rewrite和PHP路由的初步认识\\n\\n使用PHP开发网站，最基本的做法是将Url路径指向某个php页面，然后通过GET或POST方法向这个页面传递参数来实现。如果是GET方式，Url通常是这样(POST因为Url上看不出什么，不在本篇讨论之列)：\\n\\n* web.site/index.php?key1=value1&key2=value2\\n\\n这种风格比较基本，但存在一些问题：\\n\\n1. 如果Url固定后不允许更改(在大型系统内很正常)，则后期重构会受到限制\\n2. 代码实现时会不自觉地受制于这种模式，很难做到逻辑分离\\n3. 风格不够Restful，内容没有资源化\\n\\n因此我看到业界更提倡的方式，是转化成这样：\\n\\n* web.site/key1/value1/key2/value2\\n\\n显然这种Url是无法直接定位到PHP脚本的，必须要借助Url Rewrite。Apache和Nginx都支持Url Rewrite，除了可以通过配置文件进行设置，\\nApache还可以在每个目录下通过.htaccess文件进行自定义，也更灵活。\\n别小看了.htaccess自定义，如果你使用的是虚拟主机，根本没有可能去修改Web服务器的主配置，这时想做Url Rewrite，修改.htaccess几乎是惟一的方式。在.htaccess中配置这样一条规则 `RewriteRule !\\\\.(js|ico|gif|jpg|png|css)$ index.php`\\n\\n意思是把所有不是js、css等结尾的Url请求，统统重新定位到index.php文件。\\n经过这一步，请求就进到PHP的处理领域了。这个index.php并不是通常意义上包含内容的首页，而是一个动态分发器。\\n先把Url进行分解，这里你可以自定义分割符，最传统的是\'/\'，当然也可以用一些古怪的符号，不过我不建议这么做，毕竟会造成理解上的困难。\\n如果有些虚拟服务商不允许改写web server的配置，也可以手动地使用index.php/key/value/param的Url风格。\\n\\n## 超小型框架CEPHP的实现\\n\\n把Url分解成数组后，CEPHP的做法比较死板，取数组的[0]为class名，[1]为method名，后面的就做为参数传递给method了。做了这样的转换，后续就可以对数组如何创建对象做些重定向。\\n\\n通过Url得到class名，接下来的关键是如何实例化这个class。直接new一定会提示找不到类定义，就必须依赖语言的动态特性。这里岔开提一句，从表达力上来说比较公认的是Lisp > Ruby == Python > PHP。PHP在灵活性上能和Ruby比肩的也只有OO方面，而函数级别的魔性还是远不如Ruby的。\\n\\nPHP5支持`__autoload`函数，随后的SPL又定义了6个`spl_autoload`开头的函数，其中`spl_autoload_register`且于替代`__autoload`。它能接受一个string表示的函数名，在new的时候使用register的函数去寻找类的定义。除此之外用define给`CLASS_DIR`赋值，再配合`spl_autoload_extensions`也能正常地工作。\\n\\n说完了类，再说method。PHP的类支持包括`__construct`/`__call`在内的多种魔术方法。比如实现了`__call`方法，如果调用的方法不存在，就会fallback到`__call`的实现，然后根据第一个入参即方法名，可以决定要如何处理这个请求。这个特性在Ruby称为`method_missing()`方法。\\n想像一下通过这个特性，像getByName、getById、getByAge这三种Url就可以只实现一个getBy方法，然后把Name、Id、Age作为参数传递到getBy方法中，非常简洁。\\n\\n## YXcms的路由实现\\n\\n基于CanPHP的二次开发系统，路径使用index.php?r=default/column/index&col=demoshow风格，估计是为解决在虚拟主机上无法直接配置的缘故，方便一些小企业。index.php入口首先reqiure了protected/core.php并执行run函数。按顺序最关键的两个函数urlRoute和autoload。\\n\\nurlRoute将`$_REQUEST[\'r\']`拆分成app/controller/action三级并用define函数保存，如果没有则分别赋予默认值default/index/index。app似乎是区分Mobile或PC。接着注入的autoload，定义一个array，其中包含9条类名到文件路径的映射。用foreach逐一匹配，一旦匹配就加载这个文件。为什么要设置这么多路径？一方面不会把所有的类放在同一个目录下，另一方面由于是二次开发系统，要保留原有框架的autoload机制，用多路径逐条匹配就成了很好的选择。最后用controller拼接上\\"Controller\\"作为类名，通过`class_exists`判断是否存在，存在则构造对象并调用action方法。默认的首页路径映射到indexController.php，它又层层继承向上5次才能找到根类，每次类声明时的extends语句，同样会触发autoload。\\n\\n默认的controller动作是display，需要用于模板引擎的知识，暂时放一放，从构造函数跟踪进去发现又new了baseModel类，最终使用了CanPHP的cpModel类。"}'));jctx.push(JSON.parse('{"id": "160601", "tag": "security", "text": "# SSL杂记\\n\\nSSL和OpenSSL的关系，就好比C++和Visual C++的关系。OpenSSL是业界公认的烂代码，但也许是出来比较早，在江湖上已立稳了脚跟，因此尽管有很多人不爽，但毕竟现有项目大量的依赖，就我所知的一些fork项目都是采用头文件兼容，而重新实现的方式，也许若干年后OpenSSL会变成一个接口标准，那也是后话了。\\n\\nOpenSSL库在Linux下就一个文件，而在Windows下是分为libeay32和ssleay32两个文件，其中libeay是和加密算法相关的，包括AES、RSA、MD5等，而ssleay则是SSL握手、网络收发数据相关，因而需要依赖于libeay。取这么怪的名字是因为最初的作者是Eric A. Young而得名。\\n\\n用vc6编译openssl，自带perl脚本生成makefile，但还是有很多遗漏，有两点\\n\\n1. ms目录下有个文件要加no-asm，否则自带的汇编文件在vc6的masm无法编译，类似编nginx也遇到过md5和sha1有使用汇编的选项，大概hash类算法规律，用汇编效率提升明显。\\n2. 编译要加’__i386__\'选项，否则编crypt库会有链接错误，原因不明国内网站没有答案，是在英文站上看来的，不确定是否ssl部分也需要。\\n\\n## 实现SSL连接(PHP为例)\\n\\n在我的安卓手机上运行PHP，由于域名解析机制不知什么原因，无法正常工作，只能先在PC上解析出IP，用PHP的socket机制完成连接。如果是HTTP连接使用\\"tcp://ip\\"的方式，再手工构造HTTP的GET请求，网页的内容就拿到了，如果是HTTPS则麻烦一点。\\n\\n首先PHP支持\\"ssl://ip\\"或者\\"tls://ip\\"，虽然看起来是不同的协议，但至少我安装的PHP环境发起的Client Hello请求都是TLS1.0(请求包头是16 03 01)，但是握手结束PHP会报类似这样的错误 `Peer certificate CN=`example.server\' did not match expected CN=`ip\'`\\n\\n原因是TLS连接时服务端会发送它的数字证书，证书的CN(CommonName)记载的内容和请求的IP地址不符合。\\n\\nfsockopen是PHP4时代的接口，设计时并没有考虑传入SSL连接的选项，到了PHP5，提供了整套Stream Classes，包括了socket、context、filter、bucket等完整的网络连接设施。这些中可以用`stream_socket_client`函数，配合最后一个参数`stream_context`。使用`stream_context_create`构造一个不做检验的TLS请求(内网很多证书都是自签名，必须要跳过)，构造语法array(\'ssl\' => array(\'verify_peer_name\'=>FALSE, \'verify_peer\'=>FALSE)); 同时关闭验证证书和CN。这里的verify_peer_name是配合peer_name选项，允许用户对站点设置指定名称。\\n\\n题外话，不同的语言都提供类似的操作，比如Go提供了InsecureSkipVerity:true关闭校验。默认情况会提示x509: certificate signed by unknown authority。\\n\\nSSL_connect并不关心证书校验，成功返回后可以对SSL结构体进一步分析，有60多种X509_V_ERR_的定义，对DEPTH_ZERO_SELF_SIGN_CERT会网开一面，否则不予承认这个连接。\\n\\n注意必须是二维的array结构，而且这里只能是ssl，如果传入\'tls\'无法构造合法的context。一切准备妥当就可以完成SSL握手了，接下来在这个连接上发送HTTP的GET请求，对读和写数据来说就是透明的。\\n\\n`stream_context`由option和parameter两部分组成，option除了前面提到的ssl，还有socket/http/ftp。parameter目前我只看到一种notification，用于设置回调，在`STREAM_NOTIFY_*`事件发生时触发回调。context不仅能用于stream，也能用于fopen和`file_get_contents`。\\n\\n再来分析TLS握手流程，从数据上看客户端发送的数据要远小于服务端回复的数据，大约是<1K和5K这个量级。原因是服务器会带回完整的证书和cipher list，而客户端只做验证并选择一个cipher方式，因此数据量才会有这么大的差距，其中光是Server Hello中的Certificate环节的内容就长达2960字节。握手结束服务器会生成session ticket，长度192字节，有效期18小时。"}'));jctx.push(JSON.parse('{"id": "160611", "tag": "web", "text": "# PHP与Web服务器的集成方式\\n\\nPHP早期作为Web开发语言，监听HTTP请求并不在PHP做（虽然可以用-S选项来监听http请求，但毕竟不专业），产生环境中往往是由Web服务器(如Apache或Nginx)完成，当检测到是一个动态网页的请求，比如Url的后缀是.php，则把请求转给PHP程序，由它来处理后续的工作。在Windows上个人觉得比较好的集成工具是[PhpStudy](http://www.phpstudy.net)，集成了Apache/Nginx/Lighttpd等多种服务器(最新的2016版把Lighttpd去掉了)，而且支持多种PHP版本，就以PhpStudy安装后为例，分别说说两者的集成方式。\\n\\n## Apache\\n\\n官方标准的方式有三种，经常用到的有两种(CGI基本用不到，完全被FastCGI替代)。分别是\\n\\n* 作为Apache内建模块运行，官方文档称为handler方式\\n* 以FastCGI方式运行\\n\\nhandler方式就是在httpd的worker进程直接执行php程序，这种方式的配置会加载一个php-sapixx.conf文件(PhpStudy的写法，非官方)，xx是PHP的版本号，\\n比如55、70等。从conf文件可以看到，其通过LoadFile和LoadModule指令加载了php5.dll和php5apache2_4.dll。数字随着使用的版本而变。\\nLoadModule直接和Apache交互，从dll名字也可以看出，包含了php和apache两个程序，像PHP这么复杂的应用，不可能完全通过module代码完全实现，\\nmodule更像是个桥接器，真正的任务还是要通过PHP来完成，因此和LoadModule配套，还要用LoadFile指令载入php5.dll，负责真正的PHP执行代码。\\n另外PHP5.2版本，还通过LoadFile载入了libmysql.dll。也许是PHP和MySQL没有打通吧。如果module载入成功，通过\\n\\n`PHPIniDir \\"D:/phpstudy/php52/\\"`\\n\\n这句指令来设置php.ini的路径。(命令行的php方式可以使用-c选项，在宿主环境下就要配置了)。岔开一句，载入lua扩展只要LoadModule就可以，不需要LoadFile来指定lua.dll的位置。\\n遍观所有配置，除了PHP的SAPI方式，也只有httpd-proxy-html.conf配置，用了LoadFile来加载zlib.dll,iconv.dll,libxml2.dll。\\n\\nFastCGI方式则不同，需要先加载FastCGI的运作器，注意模块名是fcgid，而不是fastcgi，这是两个不同的项目，差别我引用网上的说法：\\n\\n> `mod_fastcgi`因为实现方式的限制，所以可能会创建了很多不必要的进程，\\n  而实际上只需要更少的进程就能处理同样的请求。\\n  `mod_fastcgi`的另外一个问题是每一个CGI的多个进程都共享同一个管道文件，\\n  所有到同一个fastcgi的通讯都通过这个同名的管道文件进行，\\n  这样当出现通讯错误的时候，根本不知道正在通讯的是哪一个fastcgi，\\n  于是也没有办法将这个有问题的进程杀死。\\n\\n> `mod_fcgid`尝试使用共享内存来解决这个问题。共享内存里面有当前每个fastcgi进程的信息\\n  （包括进程号，进程使用的管道文件名等），当 每次尝试请求fastcgi工作的时候，\\n  Apache将会首先在共享内存里面查询，只有在共享内存里面发现确实没有足够的fastcgi进程了，\\n  才会创建 新的进程，这样可以保证当前创建的进程数量刚好能够处理客户的请求。\\n  另外，由于每一个fastcgi进程使用不同名称的管道文件，\\n  所以可以在通讯失败的时候知道到底哪个fastcgi进程有问题，而能够尽早的将其剔除。\\n\\n所以现在apache官方推荐使用的模块就是fcgid了。有一个专门的fcgid.conf文件，fcgid的参数很多，\\n比较典型的，如FcgidMaxProcesses表示最多允许打开多少个进程。由于参数由Apache来读取，创建进程，控制进程的数量也同样是Apache。\\n所以这种模式下可以看到的httpd进程中，有些并不是执行Web请求，而是执行PHP的宿主。有了宿主，接下来就是找到PHP并执行，和php关联的是这句指令\\n\\n`FcgidWrapper \\"D:/phpstudy/php55n/php-cgi.exe\\" .php`\\n\\n把请求直接导向了php-cgi程序。php-cgi本身就依赖于php5.dll，\\n因此FastCGI方式下不需要通过LoadFile来载入php5.dll。指定php.ini仍然不能少，通过\\n\\n`FcgidInitialEnv PHPRC \\"D:/phpstudy/php55n\\"`\\n\\n这种方式，Apache会常驻进程，减少每次请求的创建进程开销。fcgid的耦合度比Handler方式更小，体现在\\n\\n1. httpd进程的作用分离，Web请求和PHP执行在两个进程\\n2. 载入PHP方式，从.dll换成了.exe，从而避免了代码的强耦合。换句话说，Handler方式必须依赖php5apache2_4.dll，而CGI方式调用PHP的程序即可。\\n\\nHandler和FastCGI的方式，进程的所有者都是Apache，随着PHP自身的演化，5.3.3版本后的PHP官方代码也支持FastCGI模式，就是PHP-FPM(FastCGI-Process-Manager)，\\n这个包还没有windows的移植版本。从命名就能看出，它是一个进程管理软件。\\nPHP-FPM是daemon程序，它启动一个进程池，和Web之间通过监听TCP端口或Unix域套接字来进行通信。\\n并会随着负载大小动态地增加或减少进程数量(可配置)。因此Apache的2.4版本之后，又增加了一种模式`mod_proxy_fcgi`，这种模式下Apache不需要知道PHP的文件或库位置，只管把请求发到指定的端口或域套接字就可以了。\\n\\n## nginx\\n\\n与Apache相比，nginx官方实现不支持动态载入模块，所有的功能都需要在编译时指定，也就没有对应Apache的handler方式一说。\\nnginx也没有和PHP做整合，在nginx里不会看到PHP路径配置，仅支持类似Apache的mod_proxy_fcgi配置方式，由于Windows版本没有PHP-FPM，因此运行PHP并监听端口，通过phpstudy这个管理程序来实现。\\n\\n从nginx的配置可以看出，在和PHP通信时，有大量的fastcgi_xx的指令。其中的`fastcgi_param`指令，就对应CGI规范中的Request Meta-Variables。\\n比如`SRIPT_NAME`、`QUERY_STRING`。这些值需要在nginx.conf中设置，nginx会把`fastcgi_param`设置的值传递到PHP。从而在PHP中`_SERVER[\\"SCRIPT_NAME\\"]`的方式可以取值。\\n\\n比起CGI的RFC规范，PHP可用的Meta-Variables要多一些。比如RFC只定义了`SCRIPT_NAME`和`QUERY_STRING`，\\nPHP多定义了`SCRIPT_FILENAME`和`REQUEST_URI`。`REQUEST_URI`是`SCRIPT_NAME`和`QUERY_STRING`的字符串连接。`SCRIPT_NAME`和\\n`SCRIPT_FILENAME`的差别在于`SCRIPT_FILENAME`是绝对路径，nginx中一定要通过指定`SCRIPT_FILENAME`才能真正调用到PHP脚本，`SCRIPT_NAME`就是相对路径了。\\n\\n现在RESTFul大行其道，以资源形态表示的URL上，是肯定不会看到script.php的字样的，最直接的做法，就是在nginx配置这样一句：\\n\\n`fastcgi_param  SCRIPT_FILENAME  $document_root/script.php;`\\n\\n也就是说虽然在URL上看到的只是个资源，但是到了Web端仍然是对应到具体的PHP文件。在这个script.php中可以再从`REQUEST_URI`分离出资源信息，\\n从`REQUEST_METHOD`得到操作信息，这样就可以完成资源到操作的转换。因为CGI出现的背景就是执行独立程序，因此规范直接定义`SCRIPT_NAME`就不奇怪了。如果请求报错no input file，说明nginx找不到php文件所在位置，一种解决方法是用root指令设置完整的根路径，保证`$document_root`值是对的。如果不设置root，默认会指向nginx程序所在的html目录，再以这个为根，自然就找不到php文件。\\n\\n像`REQUEST_URI`这种值，其实都是由Web服务器来设置的，如果不在RFC规范，就完全看Web服务器的实现了，因此会有些框架做些兼容处理。\\n\\n## 小结与比较\\n\\n比较两种Web服务器的加载后进程列表，选择apache启动方式，进程管理器只能看到数个httpd进程，而选择nginx的话，除了nginx还能看到数个php-cgi程序。\\n原因就是apache的FastCGI方式是以自身程序模块在运行，在httpd进程中执行php程序，因此进程管理器看不到php的名字。而nginx更有代理的味道，把请求数据向php-cgi监听的端口送去后，就和nginx无关了，因此php-cgi是以独立进程方式存在。\\n\\n这方面还遇到过一个奇怪的问题，本地调试网页用httpd正常打开，用nginx却总是超时。nginx下php-cgi默认分配的是9000端口，于是用netstat -ano查了到底哪个进程占用了9000端口，果然这个端口被其它程序给占住了，但是phpstudy并不会报异常，也就表现在nginx超时，如果用openresty方式运行就不会有这个问题，因为openresty也是类似httpd方式，直接在nginx内执行业务逻辑。\\n\\n"}'));jctx.push(JSON.parse('{"id": "160718", "tag": "lang", "text": "# 几种语言作用域的比较\\n\\n## 起因\\n\\n一段lua程序\\n\\n```\\nwhile do\\n  local ctx = ...\\nend\\nsaveToFile(ctx)\\n```\\n\\n程序执行到最后，总会报一个写入nil的错误。我一度以为是在处理数据时没有赋值，但反复核对都没有遗漏，\\n最后也不知怎么就想到可能是执行saeToFile函数时，ctx出了while作用域，导致引用了一个新的变量，这时ctx就是nil。\\n果然尝试把ctx的local限定词去掉，程序就执行正常了。\\n\\n## lua\\n\\n这个疑问引起了很大的好奇，在C语言里，变量的构造和使用是严格区分的，带了类型就是声明变量，而不带类型则是使用。由于动态类型语言没有类型，该如何区分？重新看了Lua的手册，local的说明中有一句：Notice that each execution of a local statement defines new local variables.\\n说明用local声明的变量，是定义(即创建一个存储位置)。那么没有用local声明的变量，文档中并没有明确的说明，按我的理解，没有local则是变量查找。\\n\\n如果这个scope之前有local定义或是同名变量，则引用已定义变量。如果没有，由于Lua的可见性是内部可以看到外部，\\n即`_ENV`层层向外的链表结构，在本层找不到，会向外部寻找，直到最外层的global范围。如果global也没有的话，\\n就会自动在global创建这个变量。可见沿着`_ENV`向上查找才是本意，找不到情况下创建变量只是个副产物。\\n因此Lua语言中尽量使用local的意义就在于，避免对外部环境的污染。又或者不经意间就修改了同名的global变量(在好的编码风格中不太会发生)。\\n\\n如果拿Lua的local和JavaScript的var相比较，作用很相似，带var表示定义一个变量，没有var则是向上查找，\\n同样也会在全局空间创建该变量。(但是注意，这两门语言的祖先Scheme，却不允许这种未经声明的变量访问。\\n当然如果改写Lua中顶级_ENV的元表或是修改js的prototype，也能达到同样效果，只是默认是允许而已)。\\nJS的编程风格也一直倡导要尽可能用var定义变量，防止不经意间污染全局空间。\\n但是JS的作用域中没有block作用域这一层，因此对照上例，即使在while内用var定义变量，超出while的语法作用域，仍然访问到。\\n除非到了function定义结束标识，这个变量的作用域才结束。\\n\\n## JS\\n\\n作用域混合了动态和静态两种，用this捕获的变量是上下文决定，或者说可以用apply指定。非this捕获的变量是静态的词法作用域。动态作用域臭名昭著，定义lambda语法时，就限定了这种情况下的this是静态捕获的。固然好，但一个this有两种作用域，很多人是迷惑的。\\n\\n## PHP\\n\\n作用域和JS有点像，只有function能创建新的作用域，花括号不构成块作用域，但比JS更弱的是，PHP不能链式地向外查找变量。有人说因为解释器用了barrier方式控制变量的绑定，取巧地控制变量的解析规则，这样实现很简单。他认为，严格意义上PHP没有作用域概念。\\n\\n在PHP函数作用域内无法直接看到外部定义，所以PHP增加了global关键字，表示这个变量是向最外部环境的引用。以下两句话的效果是一样的。\\n\\n```\\nglobal $var;\\n$var =& $GLOBALS[\\"var\\"];\\n```\\n\\n同样，用unset($var)也不会影响全局变量，因为只是删除了局部作用域内创建的引用变量而已。\\n\\n但是global关键字的局限也很明显，试想定义一个嵌套函数，在内层嵌套中想访问外层函数，但非全局变量，就没有办法了。\\n只能在访问全局变量或者访问本函数定义变量中二选一。\\n至少我在PHP5.6版本，是无法实现内层函数访问外层函数变量的效果。\\n因此PHP也不是一个lexical scope的语言（Lua和JS是的）。在闭包的实现时，\\n需要用和global类似的use语句，才能实现向上一级的变量引用。但也不能等同于穿越作用域，而是在这个函数域内新建变量而已。\\n至于use中使用&，是被Scheme放弃的动态词法范围语义，在PHP和C++11中，都还是被保存了下来。\\n\\n链式访问我能想到的典型应用是用函数来实现对象，即让函数有状态。Lua或JS通过定义一个函数，并返回这个函数内嵌套定义的另一个函数来实现。\\nPHP无法链式访问，但和C语言一样，支持函数内的static关键字，使得函数可以记录一些状态。但是PHP创建的函数，无法多次实例化，而且PHP虽然可以在函数内嵌套定义函数，但语法的限制(变量必须带$前缀，函数没有，类似lisp-2的双命名空间)，不能返回这个函数，也就没有很多烧脑的写法。\\n从灵活性来看，使用static变量的函数显然是弱于链式访问构造的闭包。\\n\\n**PHP虽然加入了namespace机制，但只能保护类、函数、常量。global访问的变量，仍然共享全局命名空间。**\\n\\n## Python\\n\\n没有块作用域，也没有链式作用域。Py3加入了nonlocal，可以在定义空间向上访问。\\n\\nPython的global关键字，和PHP有两点区别。\\n\\n1. Python只能访问全局空间的变量，加上global的目的，是未了改写这个全局变量，如果以只读方式用这个变量，不需要加global。\\n1. Python的global只能访问这个文件的命名空间，相当于寻找module内的变量\\n\\n## Ruby\\n\\n由于语法要素没有花括号，没有块作用域，遇到module/class/def这三个关键字会打开一个新的作用域，这个作用域和外部是隔绝的，无法链式向上级访问。这就造成一个很奇怪的现象，class内定义def却不能访问def外的局部变量。不过Ruby的思想是用`@`代表实例变量，`@@`代表类变量的方式来控制。而不是简单的局部变量。加上Ruby的全局变量用$表示，就造成了Ruby有四种变量命名的特色。\\n\\n如果想打破常规的作用域，可以用Module.new/Class.new/define_method这三个等价的方法名来替换关键字，使作用域平铺。\\n\\n## 环境和实现\\n\\nSICP介绍计算模型有个很重要的概念环境。在教学概念中环境是个链接，当前函数栈帧是链表的最末端，如果当前环境找不到变量unbound，会向外层层寻找。\\n\\nlua的环境没有使用outer的概念，但mujs为求简单是这么用的。catch和with会创建新env并用outer指向当前环境，JS除了这两个关键字，callfunction会创建，等执行完再restore旧环境。\\n\\n## 总结\\n\\n从作用域访问灵活性看：Lua/ES6（有块有链式） > ES5（无块有链式）> Python（无块有受限链） > PHP/Ruby（无块无链式）\\n\\nPython和Ruby本来就没有块作用域的语法要素，比较有无块作用域有失公允。"}'));jctx.push(JSON.parse('{"id": "160813", "tag": "lang", "text": "# RAII、智能指针和GC\\n\\nC++作为接近底层控制的语言，天然地要负责资源管理。资源并不单指内存，\\n还包括了文件句柄。从这个角度看，动态语言所带的垃圾回收只管理内存，\\n却不能正确地回收文件句柄。`C++`在长期发展的历程中，实践总结出了RAII这个特性，\\n也是这门语言区别于其它语言的最大特征。\\n\\n在解释RAII之前，先来看`C++`的一个特性：栈上变量的自动析构。\\n`C++`是打着A Class With C的名号发展起来的，类是最初区别于C的地方，\\n通过定义类，然后使用类来创建/销毁对象就是最基本的动作。\\n加之变量可以在栈上分配，一个在栈上分配的对象，在函数结束后由于内存已经被回收，\\n必须要在内存回收前执行析构，所幸这个动作由编译器替我们做了。\\n\\n就是这么个看似很普通的特性，却在实践中发展成了资源管理的最佳方式。\\n试想如果在函数执行过程中，会涉及很多资源(包括内存和句柄)。在执行过程中如果发生错误，\\n需要结束函数并释放资源，如果每次都写if/else，并写上很多重复代码，代码一定很难看。\\n这时就可以把这些需要的资源，封装成一个类，在开始执行前，通过构造对象的方式，\\n在对象的构造函数中获取这些资源，接下来执行逻辑，一旦发生了错误，直接退出函数即可。\\n因为编译器会自动执行对象的析构函数，只要我们写好析构函数，不管在函数的哪个地方出错，\\n相当于编译器都会自动地替我们回收这些资源。\\n\\n这里的构造函数中获取资源，就是RAII：Resource Acquisition Is Initialization。\\n两句话表述的方向不同，但强调的意思是一样的：把构造和获取资源等同起来。\\n\\n刚才给的例子使用栈上变量，那么堆上变量怎么办？办法就是把堆上变量封装成栈上变量。\\n把new的操作结果，作为一个栈上对象的构造参数传递，\\n从而在栈上对象析构时把new的结果delete。而承担了这种任务的对象，就是智能指针。\\n随着使用场景的不同，智能指针又细化出了多种类型\\n\\n* 资源共享型：shared_ptr以及为了解决环形计数而引入的weak_ptr\\n* 所有权控制型：auto_ptr、unique_ptr\\n\\n这些指针的实现方式和差异，各种文章介绍的很多，这里就不细说了。\\n\\n写这篇文章的缘由，是在公司内网看到有人发帖提问，通过一个构造函数的出参返回一个指针好不好？\\n虽然这个问题相当的愚蠢，但我想也许正是因为`C++`的复杂和灵活，才会让这样的蠢问题出现。\\n结合上面的介绍，指针往往代表了一个资源(否则要指针干嘛？)，如果把资源放出来，\\n一定会带来资源的手动管理问题，显然也违背了RAII的最佳实现实践方针。\\n\\n## RAII的感知和函数动态创建\\n\\nRAII无非就是让使用者在退出栈之前，得到一个感知的机会，本质还是汇编层面才能做，所以C语言在这里一点办法都没有。脚本语言的栈是在C层面控制的，因此可以记录和追踪生命周期，但在C语言自身，除非扩展语法，在函数退出前能注入一段行为，才能解决这个问题。\\n\\n延续也类似，在语言层面把运行的流程暴露出来，让人可以介入并控制。C语言的函数不仅不能嵌套定义，也不能在运行过程中定义。所有的函数都被编译到text段，整个生命周期永远存在，这使它比堆上数据就多了一份持久，但也少了运行期动态变化的能力。\\n\\n## Lua的GC\\n\\n使用三色标记法，对象分为白灰黑三种颜色。白表示死对象，可以用白事来简单记忆。经过标记为灰，灰再到黑。剩下的白对象就被收集了。先把所有的对象放在白链上，然后扫描这条链，把能reach到的对象放在灰链，再遍历灰链，把所有对象都mark成黑后，在灰链为空时把白链的对象清空，从而达到垃圾收集的目的。\\n\\nLua对表的GC做了特别的优化。5.1的时代只要表具备weak属性，全放在g对象的weak链处理。到了5.2时代作了细化，weak链被拆成三条链，只有weak value的表记录在g对象的weak，weak key的表记录在g对象的ephemeron，key和value都是weak则记录在allweak。\\n\\n每次扫描时会用sweeplist遍历，最多遍历count次，如果是白对象，则释放它。"}'));jctx.push(JSON.parse('{"id": "161011", "tag": "lang", "text": "# Lua调试器clidebug使用说明\\n\\n用lua -lclidebug xxx.lua来启动，进入后会停在第一行。\\n接下来介绍常用命令。\\n\\n* setb linenum [file] -- 设置指定行号的断点，默认打在当前文件\\n* tb linenum [file] -- 设置临时断点，执行到该断点后，即取消断点\\n* delb linenum [file] -- 删除指定行号的断点，默认打在当前文件\\n* listb -- 列出所有断点\\n* run/cont -- 执行程序\\n* s [num] -- 单步进入，默认1步，可指定步数\\n* n [num] -- 单步跳过，默认1步，可指定步数\\n* fin -- 跳出函数\\n* p varible -- print, but format is somewhat different\\n* display varible -- 增加一个变量名到列表，以后每次单步会打印列表中的变量值\\n* undisplay -- 清空display列表\\n* vars [levelnum] -- 显示指定层级变量，默认1\\n* what funcname -- 显示函数信息\\n* exit -- stop debug\\n\\n最后以上这些命令可以写在执行路径下的./clidebug.cmd里，比如文件里写setb 10，就能在启动后在10行打个断点。程序启动后会读这个文件，在经常调试时会比较方便。\\n\\n大概说下原理，通过-lclidebug导入调试库，但这个库会先执行一个pause函数，\\n在pause里创建好一个协程coro_debug，这个函数会执行yield。\\n并通过debug.sethook(debug_hook, \\"crl\\")，\\n在debug_hook函数内，又通过debug.getinfo(level, \\"S\\")的方式得到执行的脚本名，\\n当debug_hook被回调出后，如果没有断点，则直接return，从回调返回，\\n把控制权交给主函数进行，即sethook的函数，如果有断点，会resume这个coro_debug函数，\\n在coro_debug里做while循环并io.read(\\"*l\\")，等待用户输入动作，\\n只有run/step/next这三个命令，会触发yield动作，其它命名处理后，等待下一次用户输入。\\n\\n这个流程的关键一环，是Lua自带了sethook这个函数，因为有了它Lua会在执行的过程中，\\n每次的call或单步，都会回调进hook函数。如果仅仅是这样，只能在hook函数中做一些固定的动作，\\n要让debug真正可用，就要在hook中引入协程，hook先让渡执行权，由用户来输入，\\n在协程中判断用户输入，如果是打印或设置断点，则执行后还在协程中，\\n只有step/next/run等命令，才会让渡回hook函数，每次hook函数被回调出来，\\n都会计算当前行号，如果这个行号上没有断点，hook回调结束，让主程序继续走下去。如果有断点，则resume协程。\\n\\n通过这种方式，从而托管了后面的脚本文件的执行。\\n\\n编程语言说到底还是函数的调用，调用成链必然会形成层次，debug.getlocal的第1个参数，表示的就是调用栈的层数。不同的语言可能表示法会有不同，lua用1表示当前的函数层（即调用链最末端的函数），然后以此为基准向main函数逐层递增。C语言的当前层是0，语言风格使然。恐怕不会有语言以main函数为1开始计算，这样的话很难定位到当前调用函数的层级，而出问题的往往是当前函数。"}'));jctx.push(JSON.parse('{"id": "161019", "tag": "web", "text": "# 表单的请求类型\\n\\n有很多的文章会讲http协议里，Post和Get的区别，记录我的理解。\\n\\n不管是Get或者Post请求，除非是单纯获取信息类请求，总是会带些参数，如果参数有多个，就存在多参数的区分问题。Get请求通常只使用Url(注意这只是HTML的用法，不是HTTP的规定)。所以就需要定义规范，在1994年的时候Berners Lee等人制定了RFC1738规范(URL定义)。特殊字符用%[0-9A-F]{2}方式转义，使用&来区分多个参数，每个参数再通过=分成key和value。\\n\\n所以Get的URL往往像这样：`example.com/act.cgi?key1=value1&key2=value2`。\\n但是Post的请求内容并不在Url中，而是在http协议头之后，这段内容没有规定，只是一段无格式的Buffer。为了解决Post的body无约束的缺失，在http规范里有个Context-Type字段，比如定一个Application/Json，Application/XML等等的格式。\\n\\n## Application/x-www-form-urlencoded\\n\\nhtml中表单Form元素，使用post method时默认会使用`Application/x-www-form-urlencoded`格式。这个命名的`x-`表示它是个扩展规范，`www-form-`和HTML的表单能很自然地联系，最后的urlencoded表示它和Get请求在Url中带参数的风格是一样的，也是用&和=来区分，从而减少开发者的学习成本。如果输入内容包含=或+，也会按urlencoded方式转义，也就意味着内容如果是base64的内容，不需要额外对=进行转码。\\n\\n我不知道为什么当时会用这么一个略显冗长的格式，也许在定义的时候，JSON或XML都还不引人注目，而Get又是urlencode编码，也许为保持一致于是就用了它。\\n\\n当`Content-Type`使用了`x-www-form-urlencoded`时，PHP会把Post内容按上面说的格式来解析，最终赋值给`$_POST`变量，其它方式不会赋值到`$_POST`。\\njQuery的post方式也使用HTML的默认格式，在js语言层面看起来写的是json数据，但网络传输时最终把json转化成用`=`和`&`分隔的URL方式，\\n到了PHP侧再用`$_POST`来提取。这个过程中，js/传输/PHP各自用符合自己特性的方式，但最终仍是无疑地进行交互。\\n\\njson比urlencoded方式更有表现力的地方在于支持数组，抓包后发现jQuery把数组arr:[1, 2]转换成arr%5B%5D=1&arr%5B%5D=2来发送，\\n相当于服务端依次收到arr[]=1和arr[]=2两个值。至少PHP能够识别这种数组表示法。\\n\\n## multipart/form-data\\n\\nurlencoded的方式有个不足，就是传输二进制数据的效率非常低，极端情况如果全是不可打印字符的话，数据量会增大3倍。\\n如果是传输图片或大文件，Form表单的input使用file类型，enctype要使用`multipart/form-data`(如果不指定则默认urlencoded方式)。\\n\\nmultipart表示这个请求有多个部分，每个部分会标记`Content-Disposition: form-data; name=\\"xxx\\"`，如果是file，会额外多出一个filename=\\"file real name\\"。这时二进制数据就不做任何转换地发送到服务器。\\n如果有多个二进制数据(即multipart)，就用Boudary来区分。`$_POST`能解析不带filename的部分，惟独文件不能解析，即使`file_get_contents(php://input)`方式也不支持(就这一种不支持)，还不知道该怎么读取。\\n\\nGet是否支持在body中携带参数？标准没有规定不允许，但是浏览器不支持。为了兼容性考虑，只在URL中带参数是更好的选择。如果真的构造了在body的get请求，可以用原生内容，也可以从`$_REQUEST`变量读取。但PUT请求时，无法解析，也许是PHP的原因，暂未追究根因。\\n\\n[[浏览器的网络请求发展史]] [[C语言的HTTP请求]]# 表单的请求类型\\n\\n有很多的文章会讲http协议里，Post和Get的区别，记录我的理解。\\n\\n不管是Get或者Post请求，除非是单纯获取信息类请求，总是会带些参数，如果参数有多个，就存在多参数的区分问题。Get请求通常只使用Url(注意这只是HTML的用法，不是HTTP的规定)。所以就需要定义规范，在1994年的时候Berners Lee等人制定了RFC1738规范(URL定义)。特殊字符用%[0-9A-F]{2}方式转义，使用&来区分多个参数，每个参数再通过=分成key和value。\\n\\n所以Get的URL往往像这样：`example.com/act.cgi?key1=value1&key2=value2`。\\n但是Post的请求内容并不在Url中，而是在http协议头之后，这段内容没有规定，只是一段无格式的Buffer。为了解决Post的body无约束的缺失，在http规范里有个Context-Type字段，比如定一个Application/Json，Application/XML等等的格式。\\n\\n## Application/x-www-form-urlencoded\\n\\nhtml中表单Form元素，使用post method时默认会使用`Application/x-www-form-urlencoded`格式。这个命名的`x-`表示它是个扩展规范，`www-form-`和HTML的表单能很自然地联系，最后的urlencoded表示它和Get请求在Url中带参数的风格是一样的，也是用&和=来区分，从而减少开发者的学习成本。如果输入内容包含=或+，也会按urlencoded方式转义，也就意味着内容如果是base64的内容，不需要额外对=进行转码。\\n\\n我不知道为什么当时会用这么一个略显冗长的格式，也许在定义的时候，JSON或XML都还不引人注目，而Get又是urlencode编码，也许为保持一致于是就用了它。\\n\\n当`Content-Type`使用了`x-www-form-urlencoded`时，PHP会把Post内容按上面说的格式来解析，最终赋值给`$_POST`变量，其它方式不会赋值到`$_POST`。\\njQuery的post方式也使用HTML的默认格式，在js语言层面看起来写的是json数据，但网络传输时最终把json转化成用`=`和`&`分隔的URL方式，\\n到了PHP侧再用`$_POST`来提取。这个过程中，js/传输/PHP各自用符合自己特性的方式，但最终仍是无疑地进行交互。\\n\\njson比urlencoded方式更有表现力的地方在于支持数组，抓包后发现jQuery把数组arr:[1, 2]转换成arr%5B%5D=1&arr%5B%5D=2来发送，\\n相当于服务端依次收到arr[]=1和arr[]=2两个值。至少PHP能够识别这种数组表示法。\\n\\n## multipart/form-data\\n\\nurlencoded的方式有个不足，就是传输二进制数据的效率非常低，极端情况如果全是不可打印字符的话，数据量会增大3倍。\\n如果是传输图片或大文件，Form表单的input使用file类型，enctype要使用`multipart/form-data`(如果不指定则默认urlencoded方式)。\\n\\nmultipart表示这个请求有多个部分，每个部分会标记`Content-Disposition: form-data; name=\\"xxx\\"`，如果是file，会额外多出一个filename=\\"file real name\\"。这时二进制数据就不做任何转换地发送到服务器。\\n如果有多个二进制数据(即multipart)，就用Boudary来区分。`$_POST`能解析不带filename的部分，惟独文件不能解析，即使`file_get_contents(php://input)`方式也不支持(就这一种不支持)，还不知道该怎么读取。\\n\\nGet是否支持在body中携带参数？标准没有规定不允许，但是浏览器不支持。为了兼容性考虑，只在URL中带参数是更好的选择。如果真的构造了在body的get请求，可以用原生内容，也可以从`$_REQUEST`变量读取。但PUT请求时，无法解析，也许是PHP的原因，暂未追究根因。\\n\\n[[浏览器的网络请求发展史]] [[C语言的HTTP请求]]"}'));jctx.push(JSON.parse('{"id": "161023", "tag": "os", "text": "# 一次安卓刷机失败的修复过程\\n\\n手头有个华为手机，自带的EMUI实在太难用，偶然在华为论坛找到一个flyme的链接，大喜过望马上准备刷机。那篇帖子提供了两个链接，并且告诫说，\\n如果其中一个ROM导致黑屏，可以刷另一个ROM。本来这个时候，应该把两个ROM都下载后再开始刷机，但因为下载速度实在太慢，加之自己的大意，下载完一个ROM就急切地开始刷机了。果然悲剧发生了，刷完之后一进入系统就黑屏了。\\n\\n在这个状态下，电脑不能识别手机，也就无法把新的ROM再拷贝进去，本想试着把新的ROM拷贝到TF卡，让Recovery从TF卡升级，\\n但进到Recovery，可能是Recovery的缺陷，一旦执行mount TF卡，就失去响应了。这时我已经有点着急了，难道只能线刷？网上线刷包倒不难找，\\n但是一来下载要花时间，二来线刷包和卡刷包的区别在哪里？既然有卡刷包，也能进到Recovery，非要线刷不可吗？\\n\\n又在Recovery的菜单里找起来，惊喜地看到有个sideload的选项，说明写着通过adb sideload命令，可以把文件导入到手机。\\n看来可以在电脑上把卡刷包给写到flash上，但是操作之后却提示无法找到设备。猜想很可能是没有驱动，去哪里找驱动是个麻烦的问题。好在现在有各种方便的刷机工具，靠它来装上驱动，还是挺方便的。于是随便找了个下载安装，\\n再输入adb devices命令，果然手机被识别出来了。接下来手机侧点击sideload，有了驱动后再一次电脑上输入sideload命令，把卡刷包写入手机。经过漫长的等待，手机总算活过来了。\\n\\n手机修复后，重新去思考修复过程，发现只要Recovery能用，且和卡刷包的版本是配对的，就能救回来。因为遇到过问题，从Android4.4系统，下载的5.0的卡刷包，升级后就不能引导进应用系统了。接下来就仔细缕缕这其中的关系：\\n\\n先从系统结构说起：比如一个跑在x86上的linux，启动流程是先进入BIOS，然后引导kernel，最后执行init程序，就能进入shell或GUI了。那么对应手机，分别有如下这几个阶段：\\n\\n* fastboot 也叫bootloader 对应BIOS，一般是u-boot来实现，功能比较简陋，无法交互，目的是引导到下一个阶段，比如Meta,factorymode,recovery,normal这几种模式。这种模式下的刷机，俗称线刷。\\n* recovery 这个就包含了kernel和定制的init的程序。这种模式下的刷机，俗称卡刷。\\n* normal 就是我们平时打开手机的flyme或MIUI系统，当然有kernel和init。\\n\\nrecovery和normal都带有kernel，可以分别独立启动，通常按电源键，会直接运行normal模式，只有同时按下音量键（具体取决于手机厂设置），才会选择recovery模式。只要这两个中任何一个正常，就能看到开机画面了。所以上文提到的就是recovery可用时的刷机策略。\\n\\n但是如果Recovery坏了，或者Recovery和想升级的rom包不匹配，就需要更新Recovery了。更新Recovery有两种方式：\\n\\n1. fastboot工具。如果Recovery有问题，这时选择进入手机的bootloader模式，(比如我这个华为手机，音量+和电源键是进入Recovery，音量-和电源是进入fastboot/bootloader)。\\nbootloader模式和adb是不同的，驱动也不一样，会出现adb能识别而fastboot识别不了的情况。要用fastboot flash recovery filename命令，\\n来写入第三方的Recovery。bootloader比Recovery的阶段早，所以这个阶段可以写Recovery，fastboot模式由于不具备交互界面，只能在电脑上操作，\\n2. 使用厂商提供的专用工具，还需要刷机包有分区表(通常卡刷包是不会有的)，\\n从分区表可以看到第一个和最后一个分区名为pgpt(primary gpt)和sgpt(secodary gpt)，\\n说明是按GUID Partition Table而不是MBR方式管理分区的。我手头的手机Recovery分区是16M，有了这个基础，下一步就是卡刷了。\\n\\n很多厂商不希望玩家刷机，就故意把Recovery的功能做得很简陋，或者限制刷入包的签名，同时又在bootloader上做限制，不允许更新Recovery。\\n这就需要先解除bootloader的限制，即俗称的unlock。经过这一步，手机便失去了保修，换来的是可以自由地写入Recovery，然后各种Rom就可以烧入手机了。\\n\\n前文还提到Recovery和Rom会不匹配，这就涉及另一个概念：底包。\\n经常在刷机论坛能看到底包说法，打开底包可以看到非常多的文件，\\n包括上文提到过的recovery，system.img,boot.img,userdata.img等文件，\\n还有些像moden_ltg.img,trustzone.bin,logo.bin等文件，\\n还有在操作中惟一可以由用户选择的文件——分区表。\\n\\n不管卡刷也好，fastboot重写recovery，如果没有正确的分区表，也是不可能的。\\n从这里可以看出，如果要把系统写到一块完全空白的flash，确实需要线刷底包，\\n但是一般说的黑屏啊救砖什么的，通常分区表不至于损坏，只要下载到版本合适的Rom或Recovery，\\n就一定能救砖成功。\\n\\n底包含有基带moden，还有用于DRM版权及支付的trustzone.bin文件，\\n这些文件都是厂商不愿意开放出来，且ROM的作者也不会去修改的地方。\\n可以认为卡刷包是把底包中和应用相关部分给替换的部分。\\n\\n底包中往往有完整的分区表，比如MTK6752有24个分区，有ext4和RAW两种格式。\\n但是并不是每个分区都会写文件进去，像NVRAM分区保存的是IMEI串号，\\n就只定义了分区大小为5M，但不管哪种刷机方式都不会去改写它。\\n从这里也能看出：分区表绝对不能破坏，否则IMEI一旦丢失就没有任何方式能挽回，\\n除非保存过NVRAM的内容，否则只能返厂重写。\\n\\n手机变砖后能和线刷工具通信，说明内部有一块固化的代码，MTK平台称为Bootrom，\\n代码固化在NOR flash上，同时还有一小块SRAM，执行DA程序，DA是Download\\nAgent的简称，用于接收线刷工具发到手机的数据。\\n所以至少MTK平台的启动第一步，并不是uboot，而是这块Bootrom。\\n这部分是无法访问的，如果被破坏，只能返厂维修了。\\n\\n最后附一个MTK6752的分区实录，总计有24个分区，列出部分。\\n<pre>\\npreloader 256K\\npgpt(first) 512K\\nproinfo  3M\\nnvram(IMEI) 5M\\nboot      20M\\nrecovery  20M\\nlogo      8M\\ntee1(trustzone)  5M\\ntee2(trustzone)  5M\\nsystem    1.5G\\ncache     320M\\nuserdata  1180M\\nsgpt(last)    512K\\n</pre>\\n"}'));jctx.push(JSON.parse('{"id": "161104", "tag": "lang", "text": "# 一个GDB和GCC版本不同引起的定位问题\\n\\n有同事问起调试过程中，触发了SIGFPE除0错误，但是通过core的bt命令，\\n却发现出在pthread_create函数上，非常不可思议。今天找了部门对汇编最熟悉的大师，\\n原来问题是出在编译使用的是GCC5.2版本，但是调试用的GDB因为使用的libc和GCC不匹配，\\n导致符号表错误，而GDB是通过偏移量并从符号表中读取符号，\\n一旦版本不匹配，读到的符号也是错误的。\\n\\n解决方案是通过GDB的set sysroot命令来重新定位到GCC的库中，强制确保libc库的正确性。\\n怎么知道正确的sysroot路径呢？就从编译的信息来，通过ld的-t选项，能得到libc的路径。\\n比如写一个gcc hello.c -Wl,-t的方式，就知道从哪个目录下引用了哪些库。\\n把这个目录再通过set sysroot在GDB环境中设置一遍。\\n但是仅有sysroot还不够，因为出问题的往往是自己写的库，因此还要用\\nsolib-search的方式把自己编写的库，导入GDB的搜索路径下，\\n经过这样一遍的尝试，再用bt命令就能定位到正确的函数了。\\n\\n顺便再说说用GDB查看栈帧的理解：\\n\\n程序被加载到内存后，以windows为例，程序数据如main，func这些函数的汇编语言代码，用disas main来观察，保存在0x00401300左右的内存空间，而栈空间在0x0028ff00左右位置。用i reg仔细看eip,ebp,esp这三个寄存器，eip始终在代码区徘徊，而ebp和esp沿着栈空间一直向下生长（值不停地变小）。\\n\\n每次汇编的call一执行，会把当前的ebp、eip、函数参数(如果有的话)依次保存在栈上，所以入参从0x8(%ebp)开始算，而eip的值通过反汇编可以看到，是call的下一条指令位置。从而在leave指令可以用上次的栈和pc值回到上层函数的call之后继续执行。也可以用disas eip的值，看eip要执行的汇编代码是什么。\\n\\n所以递归的时候，每一次的函数入参和返回地址eip，用x/50x ebp address命令能看得很清楚。这就是bt能打印函数执行地址的原因，那些值其实都沿着栈内存写着，bt只是帮人翻译出来罢了。"}'));jctx.push(JSON.parse('{"id": "161113", "tag": "web", "text": "# 简说CSRF\\n\\n网络攻击中有种技巧，叫CSRF(Cross-site Request Forgery)，跨站请求伪造。\\n什么意思呢：\\n\\n正常用户和服务器之间的请求是真实的请求，而CSRF的请求，仍然是用户和服务器之间的请求，\\n但这种请求并不是用户主动有意发起的，而是被黑客施以社工的方式，诱导用户点击，\\n由于最终仍是用户发起，所以服务器在技术上是无法区分到底是客户真实的用途，\\n还是被社工诱骗的结果。这种攻击技法技巧在技术上是这样的：\\n\\n首先HTTP协议是无连接的协议，但实际的应用场景很多时候是需要连接的，在编程上就会通过\\nsession方式来记录这个会话。但是和C-S模式往往使用TCP连接不同，浏览器的socket连接是无法控制的。\\n因此服务端无法做到把session和连接绑定，只能退而求其次和IP绑定。\\n可想而知，如果用户的浏览器有多个标签页，这些页签发起的请求，在服务器看来都是合法的。\\n这时黑客布置一个诱骗点击，用户点击后，会触发一个向服务器的请求，比如向黑客汇款，\\n因为是在同一个浏览器上发出的，就让服务器以为是用户主动向黑客汇款，于是一次攻击就成功了。\\n\\n原因是浏览器发起连接的行为不可控制，而根本恐怕还在于HTTP在协议设计之初的无连接性。\\n因为无连接，所以默认是短连接，而浏览器为了提高加载速度，又以用户不可控的方式去建立连接。\\n当然HTTP的设计之初，只是一个内部的信息交互系统，正是这个系统的极大成功，\\n被告后人用来做各种各样的业务，才引入这样一种本不该有的问题吧。\\n"}'));jctx.push(JSON.parse('{"id": "161120", "tag": "web", "text": "# PHP两种模式下的调试功能\\n\\nPHP语言相较于其它语言一个很大的不同，从一开始就定位在一种宿主语言。\\n它是由Web服务器来调用，而不像其它脚本语言，如Perl或Python那样用于命令行。\\n因此在PHP5以前，默认的主程序都是以cgi的SAPI模式运行，到了PHP5以后，\\n默认的php.exe才切换为cli的SAPI模式，而php-cgi.exe则代表cgi方式的执行体。\\n这两种模式支持的语法和特性是一样的，差异点有：\\n\\n1. 输出是否会带上html标签(CGI带，cli不带)\\n2. daemon时作用不同\\n\\n先说监听模式，php-cli能通过-S选项打开build-in的Web Server模式，这时就不需要开Apache了，\\n初学者使用这种方式上手PHP还是挺不错的，但比起完整的Web服务器，不能做URL Rewrite等功能。\\n而php-cgi的-b选项是FastCGI Server模式，这种模式不支持HTTP请求，只支持FastCGI请求。\\nFastCGI的specification比较简单，开始的请求头是8字节描述，包括版本号、类型信息，\\n接着就是各种CGI定义的元数据，比如`SCRIPT_FILENAME`等字段，php-cgi判定协议头，\\n并读取这些信息，执行完成后再将应答返回给Web服务器。因此这两种模式的作用差异是很大的。\\n\\ncli和cgi的调试也很不一样。cli模式使用phpdbg.exe程序，用法和GDB等类似，\\n在命令行下进行操作，而cgi模式需要用到扩展模块xdebug，且开启xdebug还不够了，\\n需要和另一个进程以C-S模式交互才行。\\n\\ncli模式使用phpdbg，最开始是5.4版本以补丁形式出现，到了PHP5.6以上，官方合入了这个补丁，\\n通过命令行方式启动，载入程序后可以打断点、单步或查看栈帧等。\\n和普通的命令行调试器很像，就不多做介绍了。\\n\\nxdebug是个远程调试扩展插件，需要在php.ini中载入对应的dll，\\n且还要配置`xdebug.remote_enable`为1才能用，\\n离奇的是，即使仅载入dll也会造成性能开销，因此如果不需要调试时，\\n务必把载入dll行给注释掉。\\n前面提到xdebug是C-S形的调试器，xdebug自身嵌在PHP内，是S端，因而必须要配置C端的地址，\\n指令就是如下两条：\\n<pre>\\nxdebug.remote_host = \\"127.0.0.1\\"\\nxdebug.remote_port = 9000\\n</pre>\\n通常C和S在同一台机器上，`remote_port`代表的是C端的监听端口。\\n当xdebug收到`XSESSION_DEBUG_START`这个特殊的字段，\\n就表示要开始调试，并向上例中的9000端口发起协商，通常xdebug客户端集成在IDE中，\\n在IDE内进行单步/设断点等操作，遵循xdebug协议向PHP服务发请求，就能达到调试的目的。\\n"}'));jctx.push(JSON.parse('{"id": "161124", "tag": "security", "text": "# X509证书与GPG验证\\n\\n## 证书定义\\n\\n加密体系中证书是非常重要的一环，最有名的标准就是X.509。它使用ASN1格式描述，这个标准有3个版本，主要用的是V1和V3版本。证书大小通常在1K字节左右。\\n\\nX509证书有几种格式，openssl默认使用PEM格式(Privacy Enhanced Mail)，而12306则使用了DER格式(Distinguished Encoding Rules)。DER是ASN.1这种二进制编码标准的一个实现方案(还有一种叫BER)，C函数中的`d2i_X509`和`i2d_X509`，d就代表DER，i则指internal，即C的struct格式。用openssl看的话，要加上-inform der才能正确地打开。\\n\\n证书的开始是版本号(1或3)，然后是证书序列号(Serial Number)。序列号是整数形式，比如：ab:a5:7c:fb:27:3c:50:91。是个64位数字。虽然名字叫序列号，但不能只靠这个做惟一区分，因为X509标准只要求序列号在同一个发行者或者颁发者(Issuer)下惟一即可（通常是每签发一个证书就加一）。\\n接下来是签名，签名算法一般是非对称+散列，比如sha1WithRSAEncryption。再是发行者，Issuer有很多个字段，其中必须有的是C国家，ST省，O组织，OU组织单元和CN通用名称(CommonName必须是域名，比如`*.waer.com`)。比如发行者就是德国某州的Apache测试组织。组织后面是证书有效期，包含不早于和不晚于两个时间点。然后是主体或授与者(Subject)信息，同样有C国家、ST省份、O组织等类似的部分，身份介绍后是授与者的公钥，比如1024bit的RSA公钥，这部分显示时似乎总是以00:开头，然后是RSA的exponent，0x1001。\\n\\n最后是整份证书的签名，否则无法证明公钥及其所有者的信息一致。这里再次用了sha1WithRSAEncryption方式，计算方式我猜测是这样：\\n先用sha1计算，然后用私钥生成签名，拿到证书的人，用公钥解密后的值，和证书的sha1值比对，只有对上了，说明这份证书才是正确的，防止被人伪造。\\n\\n上面列的字段都是X509的V1版本，V3在签名前面还会多出许多内容，从结构和原理上差不多就是这些。V3多出了扩展(颁发机构，CRL，使用者密钥标识)，关键扩展(密钥用法)，属性(指纹和指纹算法)。\\n\\n一份数字证书，最核心的内容就是这几件事：\\n\\n1. 谁给你签发的(Issuer)\\n2. 证书有效期\\n3. 你的身份是谁(Subject)\\n4. 你的公钥，用于通信时交换密钥\\n5. 使用签发者公钥对以上信息hash做的签名，防伪造\\n\\nX509覆盖的范围比较多，从头文件看，除用于认证的X509，还有CRL(证书吊销)、REQ(证书申请)、NAME(证书持有者信息名字)、ATTRIBUTE、EXTENSION五种扩展功能。\\n\\n## 证书签发流程与自签证书\\n\\nPKI体系的证书存在链式依赖，下游证书由上游证书签发，最顶级的根证书没有签发者，只能是自己给自己签发，但因为各种浏览器都集成了这些签发者的公钥，所以仍被认为有效，反之如果签发证书使用的顶级公钥没有被集成进浏览器，就会提示用户有风险。12306的根证书就是没有被广泛集成进浏览器的自签发证书。使用证书给别人签发证书，就是上游签发。\\n\\n从上一节数字证书包含的内容来看，包含两个不同的公钥。当我们在学习做自签发证书的时候，为简单起见，这两个公钥会用同一个。下面来看步骤：\\n\\n1. 第一步生成私钥，RSA用`openssl genrsa`命令，ECDSA用`openssl ecparam -name secp521r1 -genkey -param_enc explicit`。带上`param_enc`的私钥会把参数都嵌入，体积大一点，否则只有曲线名称，但遇到版本不匹配时，可能无法构造曲线。另外如果担心私钥泄密，还可以在生成私钥的时候用AES-CBC或其它算法对私钥进行保护。得到的私钥文件已经包含了公钥信息。虽然有了私钥，可是没有任何表明身份的信息啊。\\n2. 第二步生成证书申请，使用`openssl req`，这步要输入上一步生成的私钥。如果没有私钥，你的申请信息就可以被随意篡改，这显然不是证书的本意。申请文件一般用.csr作为后缀。\\n3. 最后一步签发证书，用`openssl x509 -req -signkey`命令，signkey是自签名的关键，生成的就是根证书了。还有另一种生成自签名证书方式，把申请和签发证书两步合二为一，命令`openssl req -new -x509 -days 365 -key keyca.pem -out pubca.pem`。\\n\\n有了自签发的根证书，服务器证书类似，第一步先生成私钥，第二步也是生成申请，其中带上服务器的信息，第三步将申请和服务器的公钥交给根机构，由根机构用根私钥对服务器申请加密，输出的文件就是服务器证书了，这时用的命令是`openssl x509 -req -CA -CAkey`。和自签名的差异是参数从signkey换成了CA和CAkey。从这个流程看，证书显然包含了信息和公钥。\\n\\n还有另一种签发方式`openssl ca -keyfile keyca.pem -cert pubca.pem -in svr.csr -out pubsvr.pem -days 99`，这种方式有几个限制\\n\\n1. 必须在当前目录下创建demoCA目录，这个目录内还要有newcerts目录，空的index.txt文件、内容为01的serial文件。\\n2. 根证书（自签名证书）和申请者的Province和Unit必须一致，否则无法签发。\\n\\n最后看一张图了解客户端对证书的认证过程\\n\\n![x509-verify](/img/x509-verify.png)\\n\\n## 使用GPG来验证文件\\n\\n常见的方式有MD5验证，但是问题在于你怎么确信看到的MD5就是真实的呢？使用更高级别的GnuPG吧，它是符合OpenPGP标准的加密软件，可以加解密，还能签名或验证。最早由德国人开发了PGP软件并大受欢迎，但由于是个商业软件，就出现了OpenPGP标准，而gpg则是最广泛使用的实现，全名GNU Privacy Guard，名字如此相似，不知是故意还是巧合。\\n\\n先从最常用的验证说起吧。签名文件一般是.asc或.sig结尾，命令 `gpg2 --verify check.asc filename`\\n\\n签名文件放在前面，在这个流程里还是依赖一个中心化的公钥服务器，比如Openresty的声明如下：\\n\\n    releases are signed by the public PGP key A0E98066 of Yichun Zhang\\n\\n可以在pgp.mit.edu网站查到，A0E98066是RSA key ID，可以检索。不知道这算不算PKI。"}'));jctx.push(JSON.parse('{"id": "161125", "tag": "web", "text": "# Apache和Nginx配置的理解\\n\\n前文有提到过PHP是怎么和Apache和Nginx整合的，作为最流行的两大Web服务器，从配置文件来看看这二者对Web业务的理解。\\n\\n还是先从和外部程序(如PHP)的结合性说起，Web服务器要想实现动态网页效果，最早是CGI方式，\\n另外还有Python定义的WSGI(包括衍生出的uwsgi)，以及不太常见的SCGI。Nginx支持这三种方式都是比较松的耦合，\\n通过`fastcgi_pass`把HTTP请求转给CGI服务器处理。另外一个很像的指令是`proxy_pass`，\\n二者的差异是`proxy_pass`是纯透传，即Back-to-back。而`fastcgi_pass`要做的工作则多得多，\\n不仅要构造一堆的CGI变量定义，还要在这些定义之前增加符合FastCGI规范的协议头。\\n另外php的cli方式不支持，一定要使用php-cgi -b port方式才支持fastcgi协议的请求。\\n用`uwsgi_pass`则是转成uwsgi协议给对应的程序处理。所以Nginx只做协议转换，不会调用外部进程。\\n\\n正是因为Nginx支持各种非HTTP协议的适配和转换，又不集成外部程序，它被普遍地认为是反向代理的模板。\\n\\nApache当然也支持转发，通过加载`mod_proxy`插件和相应的配置，把HTTP请求转给独立的外部进程。除些之外，Apache和PHP还有一种结合更紧密的方式，\\n即通过`AddHandler fcgid-script .php`这条指令，把路径名是.php结尾的请求，\\n识别成fcigd方式，进而通过FcgidWrapper指令声明的执行程序，直接运行PHP程序了。\\n虽然这种方式也是调用php-cgi.exe程序，但不是-b监听的方式。\\n因此在我的win8.1系统上出现一个很奇怪的故障，即Apache的`mod_fcgid`可以运行，\\nNginx却死活跑不起来。OpenResty深度整合了lua(主要还是程序小)，达到像Apache的效果。\\n\\nApache和Nginx在Web功能的配置上还是很像的，比如统一定向到错误页面\\n\\n这是Apache\\n> ErrorDocument 404 /missing.html\\n\\n这是Nginx\\n> error_page  404              /404.html;\\n\\n这里有个初学者很容易误解的坑，用PHP返回的错误码，服务器是不理会的。\\n原理是Web服务器只认自身产生的错误码，对外部程序返回的HTTP头内的错误码不做识别。\\nNginx还好一点，可以用`fastcgi_intercept_errors on;`这条指令强制打开，进而达到错误码重定向的功能，Apache就比较惨了，如果是Proxy的返回，\\n还能用ProxyErrorOverride来识别，但对FastCGI方式没有直接支持，只能以WorkAroud方式绕过，具体怎么绕，还没搞明白。\\n\\n## nginx和tomcat协作\\n\\ntomcat是符合servlet规范的一个实作，规范定义了web.xml，包含servlet类名，很多MIME项，所以很大，一般不用看。\\n\\n业务配置在conf/server.xml中，最多可配6层结构。最外层定义惟一的server，是整个tomcat大的业务入口，这层要监听一个关闭端口，默认是8005。server下可以有多个service，其中可以定义多个connector和惟一的engine，每个connector负责一种protocol和端口，支持的protocol有ajp/1.3和http/1.1。ajp是Apache JServ Protocol，似乎只有httpd支持，如果要和nginx配合，要依赖http的connector才行。engine下层是若干个host元素，每个host通过appBase属性规定了war包的位置。context中指定url路由对应的servlet，不过这套做法已经近乎绝迹，最里还有Logger等就不提了。\\n\\n之所以会有这么多层，也是需求使然。服务要拆分，每个服务监听不同端口，就要在service层实现。对虚机运营商来说，监听端口惟一，但想尽量多卖主机，于是Host就有存在的价值。service和engine是一对一绑定，我觉得可以合一，而context也没有存在的必要。但最起码，service和host是无法被简化的。\\n\\n由上可知tomcat自身是可以做web服务器的，类似PHP支持http和cgi两种协议。但真正部署时，还是用动态处理能力。\\n\\nnginx可以配置upstream，层级在http之下和server平级。比如upstream tomcat，在location定义`proxy_pass http://tomcat;`一句就能反向代理过去了。其实直接在`proxy_pass`后面写ip和port应该也可以。\\n\\n从命令行启动tomcat的入口是catalina.bat，使用了cmd的一个语法`start title dosth`，即start特殊命令，从而可以打开一个名为title的新cmd窗口，并执行dosth命令。否则就在窗口下直接执行。\\n\\n### nginx打印变量\\n\\n1. `add_header X-debug \\"$var\\" always;`指令，客户端就能看到某个变量。如果不加always，只有成功的响应才会添加头，不过这个参数在1.7.5以上版本才支持。\\n2. `add_header Content-Type text/plain;return 200 \\"$var1 $var2\\";`，直接在内容上显示变量，没有header内容会变成下载，不利于调试。\\n\\n## 在小米路由的使用\\n\\n小米路由器使用Nginx监听80端口，配置文件在/tmp/sysapihttpdconf/目录下，\\n首页目录在/www下，这个目录没有什么内容，index.htm中最主要的就是这句：\\n`<meta http-equiv=\\"refresh\\" content=\\"0; url=/cgi-bin/luci/web\\">`。\\n这个标签含有浏览器刷新和重定向两种功能，最终被重定向到了url所指向的地方。\\n在Nginx的配置脚本中，有`set $script_name /cgi-bin/luci`\\n在/www目录下，有cgi-bin/目录，其中又有luci这个文件，\\n\\nluci只是个入口，这其中会require相当多的文件，比如sgi.cgi，dispatcher等等。"}'));jctx.push(JSON.parse('{"id": "161204", "tag": "web", "text": "# CGI与FASTCGI规范的理解\\n\\n## CGI语义以及基于Busybox使用\\n\\n作为最早的Web交互规范，由于足够简单甚至连busybox都能支持，只要做到以下两点就可以\\n\\n1. 在网站根目录下创建cgi-bin目录（必须是这个名字，否则作为普通的目录，只会读取文本不会执行）\\n2. 在cgi-bin目录下创建文件，子目录也可以，并具有执行权限，但文件名不要和系统自带命令同名，我就遇到过命名为env后，程序一直执行不会退出\\n\\n然后在浏览器端，只要访问/cgi-bin/xxx，就可以触发执行CGI程序。RFC规范定义了以下环境变量给脚本读取使用：\\n\\n* REQUEST_METHOD: GET/POST等HTTP方法，busybox只实现了GET/POST，其它方法会报错501 Not Implemented\\n* REQUEST_URI: 请求的完整路径\\n* QUERY_STRING: 把URI的?之后部分提取出来，保存到这个变量\\n* SCRIPT_NAME: 被执行脚本的相对路径，Web根目录为/\\n* PATH_INFO: 额外的路径信息，由客户端给出的。换句话说，脚本可以由他们的虚拟路径名来访问，在这个路径的末尾附带额外的信息。这个额外信息被作为`PATH_INFO`发送。这个信息如果在传递给CGI脚本之前来自URL就可以由服务器来解码。如果请求http://example.com/test/test.php/a/b?k=v，则PATH_INFO的值为/a/b。\\n* PATH_TRANSLATED: 服务器提供的PATH_INFO的转换版本，它需要路径并且为它做虚拟到物理的映射。busybox不支持。\\n* SERVER_PROTOCOL/GATEWAY_INTERFACE/SERVER_SOFTWARE: 值类似HTTP/1.0、CGI/1.1，告知服务器运行版本\\n* stdout: 这并不是环境变量，对于POST请求的内容来说，URI之外的数据，需要脚本从stdout来读取，所以也提一下\\n\\n## FastCGI协议\\n\\nCGI规范了传输数据的环境变量命名（以及stdin/stdout用法），但只适用父子进程。FastCGI是网络化的，可以跨进程甚至节点使用，协议为8字节对齐，头是个8字节的标志位：\\n\\n```\\ntypedef struct _fcgi_header {\\n    unsigned char version;\\n    unsigned char type;\\n    unsigned char requestIdB1;\\n    unsigned char requestIdB0;\\n    unsigned char contentLengthB1;\\n    unsigned char contentLengthB0;\\n    unsigned char paddingLength;\\n    unsigned char reserved;\\n} fcgi_header;\\n```\\n\\n这个格式缺少协议头标志(MagicFlag)，大概那个时代都是如此吧。版本好像只有1，type是消息类型共有10种：\\n\\n```\\ntypedef enum _fcgi_request_type {\\n    FCGI_BEGIN_REQUEST      =  1, /* [in]                              */\\n    FCGI_ABORT_REQUEST      =  2, /* [in]  (not supported)             */\\n    FCGI_END_REQUEST        =  3, /* [out]                             */\\n    FCGI_PARAMS             =  4, /* [in]  environment variables       */\\n    FCGI_STDIN              =  5, /* [in]  post data                   */\\n    FCGI_STDOUT             =  6, /* [out] response                    */\\n    FCGI_STDERR             =  7, /* [out] errors                      */\\n    FCGI_DATA               =  8, /* [in]  filter data (not supported) */\\n    FCGI_GET_VALUES         =  9, /* [in]                              */\\n    FCGI_GET_VALUES_RESULT  = 10  /* [out]                             */\\n} fcgi_request_type;\\n```\\n\\n比较常见的有`BEGIN_REQUEST`/`END_REQUEST`(网络化后标识请求应答状态用)，PARAMS(代替环境变量)，STDIN/STDOUT(名字和CGI一样，含义则作了泛化)。\\n\\nBEGIN/END的payload部分是定长的，BEGIN定义\\n\\n```\\ntypedef struct _fcgi_begin_request {\\n    unsigned char roleB1;\\n    unsigned char roleB0;\\n    unsigned char flags;\\n    unsigned char reserved[5];\\n} fcgi_begin_request;\\n```\\n\\nrole表示Web服务器期望应用扮演的角色。分为三个角色\\n\\n```\\ntypedef enum _fcgi_role {\\n    FCGI_RESPONDER  = 1,\\n    FCGI_AUTHORIZER = 2,\\n    FCGI_FILTER = 3\\n} fcgi_role;\\n```\\n\\nflags包含一个控制线路关闭的位：FCGI_KEEP_CONN：\\n\\n* 0，则应用在对本次请求响应后关闭线路。\\n* 非0，应用在对本次请求响应后不会关闭线路。一般都是非0，减少连接开销。\\n\\nEND定义：\\n<pre>\\ntypedef struct _fcgi_end_request {\\n    unsigned char appStatusB3;\\n    unsigned char appStatusB2;\\n    unsigned char appStatusB1;\\n    unsigned char appStatusB0;\\n    unsigned char protocolStatus;\\n    unsigned char reserved[3];\\n} fcgi_end_request;\\n</pre>\\nappStatus是应用级别的状态码。protocolStatus组件是协议级别的状态码；\\nprotocolStatus的值可能是：\\n\\n* `FCGI_REQUEST_COMPLETE`：请求的正常结束。\\n* `FCGI_CANT_MPX_CONN`：拒绝新请求。这发生在Web服务器通过一条线路向应用发送并发的请求时，后者被设计为每条线路每次处理一个请求。\\n* `FCGI_OVERLOADED`：拒绝新请求。这发生在应用用完某些资源时，例如数据库连接。\\n* `FCGI_UNKNOWN_ROLE`：拒绝新请求。这发生在Web服务器指定了一个应用不能识别的角色时。\\n\\n另外PARAMS、STDIN/STDOUT由于受协议单次数量64K的限制，如果要分包，\\n则采用最后带一个长度为0的请求表示结束。有点类似HTTP的CHUNK传输方式。\\n\\n详细说下chunked方式，回复的HTTP包头如果标识是chunked方式，包头结束后(即单独的一个空行`\\\\r\\\\n`)，接下来就是若干个chunk，格式遵循这个格式：该chunk的字节长度加上回车，然后是正文数据加上一个回车结束。\\n\\n比如发送abcd四个字节，这个chunk是`34 0d 0a 61 62 63 64 0d 0a`，34和回车表示这个块有4字节，正文数据的长度匹配后再跟一个回车，当所有带内容的chunk都结束后，要再发送一个结束包`30 0d 0a 0d 0a`，30和回车表示块有0个字节，这个不存在的正文后再跟一个回车，内容结束。长度按16进制表示，比如一个附件是44307字节，抓包是`61 64 31 33 0d 0a`，表示ad13，转成十进制正好是44307。\\n\\n## FastCGI在nginx和PHP的应用\\n\\nFastCGI作为解决CGI协议的后继者，已深得人心，在Nginx和PHP中都默认支持。比如php-cgi虽然名字是cgi，但是-b模式开启的其实是FastCGI模式。再配合上Nginx的`fastcgi_pass`指令，动态网页的环境就完成了。\\n\\n从Nginx的配置语句也可以看出点端倪，fastcgi部分一共支持两个预置变量\\n\\n* $`fastcgi_script_name`\\n* $`fastcgi_path_info`\\n\\n从命名看出和CGI规范也是符合的，那么这两个变量怎么赋值呢？\\n\\n答案就是通过`fastcgi_split_path_info`这个命令字。这个命令的参数是捕获两个变量的正则表达式，捕获对象是$uri，前一个赋值给`script_name`，\\n后一个赋值给`path_info`。`PATH_TRANSLATED`这个变量好像没什么用，没有在nginx内赋值程序也能正常执行。\\n\\n看一段PHP代码时，发现URL映射很不寻常，用了/index.php/article/?s=a这种格式。印象里.php这个SCRIPT_NAME在末尾，最多就是再跟个`QUERY_STRING`。查了CGI规范，允许这种写法，且后面的/article/还有标准名字，叫`PATH_INFO`。\\n\\nPHP对`PATH_TRANSLATED`的支持有点问题，以前是和`SCRIPT_FILENAME`一样，但这不符合CGI规范，现在默认已修正，但还有个cgi.fix_pathinfo=1选项能倒退回以前的行为。归根结底CGI就是先定位到一个文件，在这个文件基础上附带参数。参数分两段，`/`之后(含/)的`PATH_INFO`和`？`之后的`QUERY_STRING`。在Apache或PHP -S选项下，只能写成/index.php/article，而nginx由于用了更灵活的正则匹配方式，写成/index.php-article也可以识别并正确引导。\\n\\n`parse_url`函数会拆解成5个部分，scheme, host, path, query, fragment。在这套定义中`script_name`是path的一部分，不是独立元素。"}'));jctx.push(JSON.parse('{"id": "161213", "tag": "web", "text": "# BW博客系统简探\\n\\n从index.php开始看，先用`include_once`手动导入system.php，这里有个逻辑很有意思：\\n检查conf这个目录下有没有info.php文件，如果没有则使用header的Location重定向到install向导。\\n然后定义了`spl_autoload_register`，把类文件的目录确认到inc目录。\\n\\n准备工作之后，index.php自动加载Canonicalization类，在构造Canonicalization时会读取一个全局的\'M\'变量，根据M的值会决定一个mode目录下的文件，这个M的值通过loader方法返回作为`include_once`的参数，触发了mode目录下对应的文件。\\n\\n首页没定义M，默认值是index，经switch的计算变成cate.mod.php。mode目录下都是php文件，且不是定义，都是执行流程。\\n先读取数据，创造View类，这是BW自己写的模板引擎，\\n其思路是把页面拆成若干部分，每次在输出前选择需要的部分，\\n选取后调用View->setWorkFlow保存，支持preg替换实现了load/loop/if三种语法结构。\\n替换后的结果送给浏览器渲染。\\n\\n在代码层面，具体的mode代码只管调用View的finalize。会调用generateOutput，这里引入components.php并把一个$parts的变量赋值。\\n设置theme成员变量。比如default，\\n进而把theme/default设为文件的读入源。通过`ob_start`方式把文件载入，最终输出。\\n\\n路由用的是`$_SERVER[\'PHP_SELF\']`。这个变量和`$_SERVER[\\"REQUEST_URI\\"]`相比，\\n少了`QUERY_STRING`部分，比`$_SERVER[\'SCRIPT_NAME\']`会多一些脚本后的值。\\n至于`__FILE__`和`$_SERVER[\'SCRIPT_FILENAME\']`这两个是一样的，不过使用场景不一样，\\n因为表示的是本地的路径(即Windows是D:\\\\这种风格，当然这在nginx.conf还是有大用的)。\\n\\nbw甚至还有一套插件系统，会把注册的手册写入SQLite的extensions表，在启动时读入，\\n然后去根目录的extension目录找同名文件夹，然后加上`ext_`前缀构造类，\\n并调用类的init方法。网页的插件大约就是这个模样。"}'));jctx.push(JSON.parse('{"id": "161217", "tag": "web", "text": "# PHP的SESSION机制\\n\\nHTTP/HTML起初是为展示文件而设计的，天然就是短连接没有状态。\\n像登陆业务却需要长连接，加之PHP又不具备daemon化特征，因此解决这个问题就要有些技巧。\\n\\n先说短连接，TCP基于无连接的IP能达到流式效果，大概是有TCP首部的序号和确认序号机制，\\n要在HTTP的短连接上要达到同样的效果，一样要有类似TCP序号的标记，这就是COOKIE。\\n比如第一次登陆后返回一个特殊的COOKIE值，下次客户端把COOKIE带上，就能在短连接上模拟长连接的效果了。浏览器出于安全方面的考虑，不会主动添加COOKIE，都是由服务端增加，有时会对COOKIE设置超时时间，到了之后浏览器删除。\\n\\n传输层面的问题解决了，接着就是服务端识别问题。如果像C或Java一直在监听，只需要把会话号记在内存就可以了，PHP却只能依靠持久化的方式，比如写文件来标记。\\n前面提到COOKIE必须是服务端主动添加，要开启该功能就要调用`session_start`函数，也可以理解为服务端要向HTTP回复中写入Set-Cookie了。\\n\\n通过HTTP请求抓包中的COOKIE部分进一步地理解(如果是服务端返回则用Set-Cookie)：\\n\\n* Cookie: TRACKID=6a366db255a08732cc44b1e1913dd2da; PHPSESSID=hamehnglgsj2sg6nbguq2146o3\\n\\nTRACKID是Lighttpd的`mod_usertrack`模块产生的，用于配合clickstream功能，不去分析它，只关注PHPSESSID。PHP的session和上例的Key=Value类似，对应PHP的两个函数：\\nKey是`session_name()`，可以在php.ini自定义，对应HTTP包头中的标记，不同的语言都会有不同定义，JSP默认用JSESSIONID定义。\\n\\n* session.name = PHPSESSID\\n\\nValue是`session_id()`，同样在php.ini有两个设置项\\n\\n* `session.hash_function` = 0  // 0-MD5，1-SHA1\\n* `session.hash_bits_per_character` = 5 // 每5bit生成一个可打印字符\\n\\nvalue不能由用户定义，但可以变换表现形式。以上的例子使用MD5且每5bit表现成一个字符，因此128/5=26。和抓包符合。\\n\\n下一个问题，每次请求来的时候PHP被唤醒，因此必然会把持久化的session恢复到内存。持久化方式有files、memcache、redis等，当然最简单的还是files。\\n\\n* `session.save_handler` = files  // 对应的方法`session_module_name()`\\n* `session.save_path` = \\"/tmp\\"\\n\\n如果files就要配置保存路径。对应memcache的话就是IP和端口。\\nfiles的名称一般是`sess_idvalue`，对应刚才的抓包，持久化的文件名就是`sess_hamehnglgsj2sg6nbguq2146o3`。每次请求到来，根据Cookie构造出session文件名，如果能读取文件，说明会话存在，从这个文件就可以还原回上一个状态。\\n\\n当然session的id值不能一成不变，默认3小时一换。通过`session.cache_expire = 180`来调整。\\n会话的id值如果想省事可以交给PHP来生成。高级点的玩法比如通过浏览器请求的其它数据来构造，\\n然后先调用`session_id`再调用`session_start`，就能自定义会话号了。\\n不过看反馈，似乎把`session.use_strict_mode`置为1会失效。\\n\\n如果要在PHP中打开会话，调用`session_start()`，先检查`$_COOKIE`变量(由HTTP包头的Cookie构造得来)里的PHPSESSID。\\n如果存在和COOKIE[PHPSESSID]对应的文件，就读取这个文件，并通过`session_decode()`得到`$_SESSION`变量，\\n除非我们手动管理会话的持久化方式(比如用redis或其它数据库)，否则不调用`session_start`直接访问`$_SESSION`，因为变量没有构造，PHP会报警告。\\n\\n`$_SESSION`里的键值对的持久化方式可配\\n\\n* session.serialize_handler = php\\n\\nphp和serialize()一样，还有binary等其它方式。至于会话内容可以通过`session_encode()`看到，修改后再用`session_decode()`设置回`$_SESSION`。\\n\\n说完服务端，再说说浏览器端。每次发起请求，看似只是个地址，但头部至少有Host, Connection, Agent, Referer, Cookie字段。即使跨域也会携带Cookie，这也是引起CSRF的根本原因。\\n\\n总结起来可以说，Cookie是有形的手，而Session是无形的手，要启动这只无形的手，需要`session_start`的一声令下。"}'));jctx.push(JSON.parse('{"id": "161219", "tag": "web", "text": "# PHP模板引擎学习\\n\\n用了3种模板引擎，从Smarty入手，但是这个库很大，文件又多。另外找了两个模板库，\\nTinyButStrong(简称TBS)和RainTPL。TBS这个库很有欺骗性，可能和Smarty比确实小，\\n但也有近150K。说真的不能算tiny，而且它的功能有点过于强大了。\\n可以直接把SQL查询语句写到模板赋值里，\\n这大大超过了我的期望。RainTPL是个约30K的单文件，在3者中最符合我胃口。\\n\\n既然是模板引擎，除了最常用的赋值，次常用的就是循环了，TBS太复杂，\\n就比比Smarty和RainTPL吧。\\n\\nSmarty的循环语法相当不直观，类似下面这样\\n<pre>\\n<% foreach item=rs from=$arivList %>\\n<% $rs %>\\n<% /foreach %>\\n</pre>\\n尤其是item=和from=那两句，每次都让人无法记住，而且你还不知道怎么表示key。\\n反观RainTPL，简单到爆啊有没有\\n<pre>\\n{loop=\\"arivList\\"}\\n{$value}\\n{/loop}\\n</pre>\\nRainTPL直接把键值命名固定，和Tiny一样。其实我觉得这种地方真没有定制化的必要，\\n都是程序员，简单直观就行了。有现成的$key和$value，谁愿意自定义啊。\\n而且自定义又增加了上下文关注的成本，我觉得是非常不划算的。\\n\\n从刚才的循环可以看出，RainTPL使用了`{}`花括号对方式来标记，\\n和TBS的`[[]]`又或者Smarty的自定义一样，和HTML区分开。这里又要说说Smarty，\\n这种没有必要的自定义，挺分散精力的。\\n\\nRainTPL除了{loop}和{/loop}之外，也提供了常用的其它语法\\n\\n* {include=\\"xxx\\"} 从html模板的目录下导入文件，由于RainTPL可以配置后缀，\\n所以这里不用填.html字样\\n* {if=\\"expr(true/false)\\"}{elseif=\\"\\"}{else}{/if} 分支语法，风格一致很好记\\n* {function=\\"foo($bar)\\"} 在html写函数，不过暂时觉得没什么用？\\n* {$value.name|strtoupper} 把一个变量作为`|`后面的函数的参数，用返回值替换，\\n有点pipe的味道，不过我还是倾向尽量不要在模板中引进这种太花巧的语法。\\n* {noparse}{/noparse} 在这中间的变量不作转换\\n* {ignore}{/ignore} example没有示例\\n"}'));jctx.push(JSON.parse('{"id": "170106", "tag": "tool", "text": "# 排版软件的故事\\n\\n英文中把文字处理分为Typewrites和Word Processors两大类。平常用的Microsoft Word\\n是所见即所得的字处理系统，适合日常的书信、报告。而专业的书籍排版由于周期长，\\n版面要求精细往往有更高的要求。当前最有名的是TeX，在TeX之前是贝尔实验室诞生的roff系统\\n(GNU实现版叫groff)，不过现在比较式微。另外还有XSL-FO也经常被企业用来制作文档，\\n好像Apple的一些文档就是用这个格式。不过这个标准实在不怎么样，2013年11月后，\\nW3C推荐CSS3 Page作为替代标准，这个XSL也就永远地停留在1.1版本不再演进了。\\n\\n先说句题外话，由于这两个排版工具出现的年代还是Unix的远古时期，那时的编辑器分为\\nline editor和screen editor。line的典型就是sed，screen则是现在耳熟能详的vim/Emacs。\\n不过现在硬件性能提高，各种编程语言也很易用，惟一还有人知道的sed也显得无关紧要了。\\n\\nTeX的第一版是1978年发布的，通常也称为TeX78。而roff要早一点1973年。\\n既然roff的历史更早，就从它说起吧。roff的全称是run off，和所见既所得的排版区分，用off表示离线的概念。\\nroff分为nroff和troff两种实现。现在我们用的GNU groff则是对这两个版本的封装，和gcc封装\\ncpp、cc1、as、ld是一个意思。\\n\\nnroff使用等宽字体，行为像打字机，man的背后就是用它，在终端上至今都运行得很好。\\n而troff可以用各种字体，适合于打印机。最早的nroff只能用在C/A/T打印机上(phototypesetter)，\\n原因就是贝尔实验室在1973年买了台C/A/T。这是台1971年设计的打印机，共支持4种字体：\\n英文字符Roman的regular/bold/italic再加一个特殊记号的Special。\\n买了之后Ossanna才基于C/A/T硬件写出了nroff，在今天看来，只为一种打印机写程序是很死板的，\\n直到1979年Brian Kernighan重写了ditroff，取意device independent troff。\\n现在看到的troff都是ditroff了。直接的现象是groff程序字体目录下devps、\\ndevlbp这些带dev前缀的目录，就是能被ditroff处理的字体。\\n\\n高德纳发布的TeX由于只支持英文，在东亚国家是无法使用的。最早着手解决这个问题的\\n是日本的ASCII社，发布了pTeX程序，p是publishing的意思。慢慢的TeX社区也意识到这个问题，\\n就有了XeTeX，后来又有了luaTeX，都能支持Unicode编码。\\n\\n中文地区很有名的是CTeX套装包，安装后程序的目录结构是这样的：\\n最重要的是miktex目录，是个windows下很好的移植版本。这个目录下的miktex/bin包含各种可执行程序。\\n包括pdfTeX、XeTeX、luaTeX三大著名引擎以及其它各种需要的程序。\\n其中pdfTeX是三者中最老的，它最早支持了pdf特征，不过似乎不支持Unicode。\\n和bin平级的还有各种辅助目录，比如font等等。\\n\\n其次重要的就是CTeX目录，这里包含了旧式的cct包和其它中文宏包。\\n也是这个套装的命名来源。处理程序有了，Ghostscript和GSview则用于预览。\\nWinEdt目录是TeX的集成开发环境，最后一个UserData放的好像也是字体和配置。\\n\\n想要从命令行直接运行LaTeX，即使是我都感到非常困难，背后的概念实在太多。\\n所以有Lyx这样的套件来简化，它只用到了XeTeX和luaTeX这两种引擎。"}'));jctx.push(JSON.parse('{"id": "170108", "tag": "tool", "text": "# 排版和字体的关系\\n\\n上一篇说了排版，排版之所以这么复杂，和字体有很大关系。\\n西文字体每个词长度不一致，在排版上首先要处理的是一行文字的fill/justify/hyphen问题。\\nroff的任务就是处理文字的这3大问题，其它的诸如表格、公式、图片则需要tbl/eqn/pic来辅助。\\n\\n要解决好justify问题，必须要知道每个文字的宽度。至于文字怎么描绘，\\n其实排版软件可以不关心，丢给打印机就行。这里要引入两个字体中基础而重要的概念：\\n\\n* metric 指文字尺寸，具体包含字符编码定义、字符宽度和四个角的坐标。\\n* glyph 指某个文字的外形，即要怎么描绘。早期是点阵方式，现在都是矢量字库，给定字符的一些点，并用贝塞尔贝曲线把这些点连接起来。\\n\\n刚才提到排版软件不关心glyph，roff也确实是这么做的。它的字体就只含metric不含glyph。发送给output device的只是文字的编码和尺寸。\\n\\nroff和TeX把字体中的metric和glyph分离，二者由于历史久远，用的都是现在很少见的字体格式(严格说是metric)。\\nroff叫DIT(Device Independent Troff)。而CTeX目录下能找到很多后缀是.TFM文件(TeX Font Metric)。\\n\\nAdobe的metric叫AFM文件(Adobe Font Metric)，含文字的宽度和四角坐标。字形glyph是PFB格式。\\nPFB是Type1字体的Binary形式，可以用pfbtops转成pfa文件(其实就是ps源码)，因而支持矢量方式放大无锯齿。\\n\\n以上3种metric格式可以互相转换，roff目录下的afmtodit和tfmtodit，miktex下的afm2tfm，都是用于metric转换。\\n\\nroff做完排版，渲染就交给具体的机器，不关心字形，用的glyph也是随着不同的机器而不同。比如devps，输出为ps就依赖pfa文件。而高德纳为了追求TeX的效果优美，给制作glyph开发了METAFONT。这是一个独立完整的工具链。\\n\\nTeX输出的字体格式，早期当然是 MetaFont -> 点阵 GF(generic font) -> 输出设备驱动；后来有 pk 点阵字体(其实是gftopk转换后的压缩格式，是PacKed简写，好随便啊)；再后来有 PostScript 矢量格式的 Bluesky 人工重制的 computer modern字体和程序自动重制的 cm-super 字体等。\\n\\n最早的TeX只支持读取tfm文件，一个完整的TeX字体（MetaFont生成的）为一个tfm文件和pk文件，前者负责字体的抽象部分（如ligature，kern等），后者负责描述字体的实体部分（即字体的glyph具体长什么样子）。TeX出现的时候Adobe还没成立，为了让打印机能复用pk字体，后来一些开发者将MetaFont的字体转换成PostScript的字体，通过dvips或者dvipdfm将dvi转换成ps或者pdf文件。\\n\\n## 现代字体格式\\n\\nroff和Tex都是相对古早和偏极客的技术了，说说更被大众熟知的字体吧，按历史发展脉络大致如下\\n\\nType1 -> TrueTypeFont -> OpenTypeFont(Type2) -> WebOpenFontFormat\\n\\n从名字就能看出，Type1是Adobe众多Type X中最早也是最有名的，原因有几个:和PostScript一起出现得最早，标准开放，支持hint因此在小字号效果较好。作为对比Type3虽然支持完整的PS特性，但没有hint，也缺少在各平台编辑软件。所以尽管现在不是主流格式(相对TrueType)，但在技术上无法忽略。\\n\\n为了对抗Adobe，微软和苹果联合发布了目前依然是最常用的TrueType字体，但后来微软又和Adobe一起发布OpenType，由于微软同时参与两个标准，所以OpenType如果包含TrueType字体，后缀仍用.ttf；如果包含PostScript，则用.otf后缀(叫Type2顺理成章)。也许大家都觉得分离式字体不好，所以自TrueType以后，都是整合成一个文件的路数。\\n\\nwindows上常见的字体还是TrueType，一般以.ttf结尾。中文宋体的后缀是.ttc，意思是TrueType Font Collection，是把多个文件整合到一个文件中，多用于CJK的字体包。\\n\\n随着Web化普及，为克服传统的字体文件过大问题，2009年诞生了WOFF字体，使用压缩技术，通常比TrueType小40%。后来的WOFF2则更进一步用brotli替代了原先的zlib算法，达到更高的压缩率。这些字体都采用sfnt封装技术。\\n"}'));jctx.push(JSON.parse('{"id": "170110", "tag": "tool", "text": "# groff中间格式翻译\\n\\n使用x作为控制命令，#号后面是注释(不确定是否必须放在开头)。\\n输出分为prologue和body两大部分。\\n通过man的例子可以看到，最简单的骨架大概是这样的：\\n\\n```\\nx T xxx    # device name like ps or X100\\nx res x y z\\nx init\\npnum       # this is page\\nx font 1 R # this 3 line indicate font has been chosen\\nfnum\\nsnum\\n# text begin position\\nVxx\\nHxx\\n# your text\\ntyour\'s input letter\\n# end\\nx trailer # this is actually just ignored\\nVxx\\nx stop\\n```\\n\\ngroff的中间语言为简单命令、画图命令(D族Graphics Commands)和\\n控制命令(x族Device Control Commands)三大系列。\\n这个例子大量使用了x这个指令族。\\n\\nD族中最灵活的指令是D~画B样条，另外有画arc、cicrle、line等各自形状，\\n加上填充颜色。这些指令构成了pic这条扩展命令的基础。\\npic能画的图形也就是上述说的这些。\\n\\n说完中间格式再说说字体。字体文件放在devxx目录下，分为DESC和其它两大类。\\n两种文件的指令集不同。\\n具体的字体文件分为两段式，先是开头的字段说明如name或spacewidth，\\n接下来是kernpairs(可选)和charset(必选)。charset格式如下：\\n\\n    name metrics type code [entity_name] [-- comment]\\n\\n真实的例子像这样：\\n\\n    u0041_0300\\t24\\t0\\t0x00C0\\n"}'));jctx.push(JSON.parse('{"id": "170121", "tag": "lang", "text": "# Json中的null和undefined\\n\\n由于Json是来自于JavaScript，因此讨论Json中的字段必须要回归到JS中。\\nnull在JS语言定义里是一个字面量，且是基本类型。如果typeof null会返回Object。\\n据说是因为想把一切变量都作为对象，所以会有这种定义。虽然这是个历史错误，组委会也曾经讨论过改成null，\\n但是考虑到大量代码已经在使用，就不去改变它了。\\nnull的类型是Object这点争议很大，但既然规范如此只能按这个思路去理解它。\\n大概就是null不是空引用，而是一个原始值，它期望被引用成一个对象，因此null自己也是Object。\\n\\n而另一个undefined则不是基本类型，它是全局对象的一个属性，更像是值。\\ntypeof undefined比较明确直观，还是undefined。\\n\\n然后回到Json，构造一个变量比如val = {a:1, b:2}，此时val.c的值是undefined。\\n原因是这里本来就没有c这个属性，也并不期望c会引用另一个对象，\\n所以值不能是null。另外我觉得，比如把a的值赋为null，在动态类型的角度\\n这样做也无可厚非，但是静态类型是有严格的界限的，如果a应该是string，\\n结果被置为null，会改变它的类型。\\n\\nJavaScript秘密花园称undefined更像其它语言的NULL，而js的NULL在语言内部另有它有。\\n比如js的函数未定义返回值，返回undefined。在PHP中未定义函数返回的是NULL。\\nLua函数未定义也是返回类似nil的效果(我理解这更像是一种编译器的优化作用，而非固有语义)。\\n比如function foo(a) a=a+2 end这样一个函数，直接print(foo(1))会输出一个空行，\\n而如果显示地return nil，则print会输出nil，说明Lua的VM在某种程序区分了undefined和nil，\\n只是无法在Lua中表现而已。\\n\\n再说一个关于undefined的事，将一个JSON串序列化成对象，如果取一个不存在的值，jsoncpp库会根据取的类型赋以默认值，\\n如asInt是0，asString则是\\"\\"。但在JS里，则直接返回undefined，如果对这个值进行parseInt，返回的也是NaN，而不是0。\\n所以严格来说，jsoncpp对不存在的值进行asDouble要返回NaN，但并没有这么做。\\n一方面是因为`C++`语言没有对应undefined的概念，加上又是一门强类型语言，用之前必须要指定一个值，\\n所以只能拿近似的NULL并转换成对应类型的0或\\"\\"充数了。"}'));jctx.push(JSON.parse('{"id": "170202", "tag": "os", "text": "# procfs记录\\n\\n## 历史\\n\\nprocfs诞生于1984年的Unix第8版，愿望是对ptrace的一种改良。起初是每个进程对应一个文件，经过Plan9改造成伪文件系统，且成了Linux的代码来源，所以在Linux用得非常多。Linux多年的改进，已经不限于进程的内容，还加入了CPU、内存、中断等各种信息。\\n\\nFreeBSD用的是sysctl，并对procfs说`Gone but not forgotten`。原因大概是sysctl最初就是4.4BSD开发出来的，而BSD社区的人更倾向用sysctl，加之procfs的代码在BSD社区中没什么人维护，所以就逐渐转移了。Linux的/proc/sys/也具备类似sysctl的功能，命名风格很像但不相同。类似的，solaris的kstat的实现是用ioctl去操作/dev/kstat。sysctl和solaris都是专属命令工具。相应的，/proc伪文件系统，可以直线用各种命令行工具操作。\\n\\n因为procfs下被塞进了太多东西，所以Linux的2.5版开发了/sys/虚拟文件系统。\\nsysfs最初是设计用于提供设备驱动的统计数据，后来不断扩展，能察看和操作内核对象。在2.6内核出现了configfs用于创建和销毁内核对象，两者互为补充。不过在configfs并不是都有的。\\n\\n造成两个系统差异的根本是内核对sysctl支持程度不同。BSD内核直接开放sysctl，所以整个社区也倾向用它，而Linux虽然也有sysctl，但却是基于procfs的一个wrap，性能上会差很多。\\n\\n## 解读\\n\\n* smaps: 程序自身以及加载so的段内存映射。第1个似乎是程序自身程序\\n\\n* task目录: 只有多线程程序，进入这个目录才会发现更多的TID对应的具体信息\\n"}'));jctx.push(JSON.parse('{"id": "170203", "tag": "web", "text": "# CSS的一些理解\\n\\n## 写在前面\\n\\nHTML是SGML/XML的一种特殊应用或者说DSL，标准的网页写法是`<!DOCTYPE html>`，与之对照的DocBook的首行写法是`<!DOCTYPE article>`，而SVG图像的写法是`<!DOCTYPE svg PUBLIC >`。\\n(`<!DOCTYPE>`是SGML的语法，和注释语法`<!-- -->`参照就好理解了)。\\n凡是符合XML定义的文档都必须通过DOCTYPE指定DTD，而浏览器天生就为显示HTML，即使不指定DTD，只要开头有`<html>`标签就默认当作网页来解析了。\\n既然是SGML系，整体风格都是树状。原生如h1,p,table等标签就属于CSS1范围的选择器，浏览器内建了各种HTML标签的CSS基础样式，因此最简单的网页，哪怕不定义任何CSS也具备一定可读性。当然除了原生的选择器，还有类选择器、ID选择器以及伪类等高级用法(当然对应CSS的级别也更高)，这时就必须由用户指定样式，浏览器只负责渲染。\\n\\nCSS作为大HTML的一部分往往会被浏览器缓存，虽然在HTML层面可以用一些方法控制缓存策略(比如PHP的setheader或者在HTML用<meta HTTP-EQUIV>>标签强制修改缓存策略为no-cache，但CSS作为外链的附加属性就没这么幸运了。通常的作法是在引入CSS文件的末尾加上?v=1标志，当CSS内容有更改时，则改变v的值，由于CSS文件链接在HTML中，HTML可以控制不用缓存，浏览器读取到新的v值就会重新获取CSS文件。否则只能用Ctrl-F5的方式强制更新，界面才会用上新样式。\\n\\n前端领域一直在快速变化着，对CSS的认识也有很多流派，就有一些人认为 [[不合时宜的CSS]]\\n\\n## 视口\\n\\n手机版页面的文字非常小，且经常要来回地拖动。几经查找看到viewport概念，是Apple的mobile safari首先提出，后来各个移动浏览器厂商都跟进了。具体地说在html的head部分加这这样一句，网页效果会如你所预期那样：\\n\\n```\\n<meta name=\\"viewport\\" content=\\"width=device-width,height=device-height,initial-scale=1.0,maximum-scale=1.0,user-scalable=no\\" />\\n```\\n\\n这里面最重要的莫过于width=device-width和inital-scale=1.0两句，由于不同设备的宽度不同，有了device-width指定可以大致做到不同页面如预期，但如果没有inital-scale，至少在这个博客上会非常难看，正文栏所占的宽度很窄，加上之后所有的内容就正常了。再说一句user-scalable，如果没有这句，每次焦点到输入框，页面会稍稍扩大一点，有种跳变感。再者对手机网页来说一旦可以缩放，反而会来回拖动体验未必就好，不如一开始就把布局字体设置妥当，之后就不必调整了。\\n\\n## CSS五大主题 up 18年3月24日\\n\\n第一次学以为CSS就是布局，随着看文章变多，才知道范围庞杂，至少包括\\n\\n* 样式: 范围最广，包括但不限于颜色/字体\\n* 数字/单位/函数\\n* 布局: 盒模型\\n* 层叠和继承\\n* 选择器: 很难记忆，但它是理解CSS的关键 [[论为什么CSS难学]]\\n\\n### 样式\\n\\n这可能是相对比较好理解的主题，也是最早就有的内容。HTML5丰富了b/i等各种样式元素，使HTML更专注于语义层面。\\n\\nvalue是元素的属性值，比如form控件当前的值。而innerText和innerHTML是元素开始和结束标签之间的值，可能不能编辑，比如div元素。\\n\\n### 数字/单位/函数\\n\\n这块内容比较繁琐，也很难记，加上还要考虑各种不同屏幕的差异，细节非常多。\\n\\n* px/em/rem: 默认字体大小16px，对应1em\\n* vw/vh: 相对宽高，1表示1%的总宽度/高度\\n* fr: grid布局的单位\\n\\n关于px单位，引用hax的解释\\n\\n>    CSS规定，浏览器应该对像素值进行缩放调节，以保持阅读体验的大体一致。也就是要保持一定像素的长度在不同设备输出上看上去的大小总是差不多。 因此CSS提出了“参考像素”（reference pixel）概念。规范使用视角来定义“参考像素”，1参考像素即为从一臂之遥看解析度为96DPI的设备输出（即1英寸96点）时，1点（即1/96英寸）的视角。 请注意这个差别——CSS规范定义的参考像素并不是1/96英寸，而是1/96英寸在一臂之遥的看起来的视角。通常认为常人臂长为28英寸，所以其视角可以计算出来是0.0213度，即(1/96)in / (28in * 2 * PI / 360deg)。\\n\\n可以看到px和物理分辨率并不等价，对PC而言，由于人眼和显示器的距离与CSS定义基本一致，二者近似划等号；而手机的分辨率虽然高于PC，但仍然要符合规范，因此手机屏幕宽度px值会比分辨率小很多，具体多少px由每个厂商各自定义。从而保证了16px字号在不同显示设备上看起来的视觉效果是接近的。\\n\\n函数只有预定义函数，比如counter/calc可以进行数值计算，url则可以进行外部资源的导入。要想添加自定义函数还得靠预处理器。\\n\\n### 布局\\n\\n盒模型包括margin, border, padding, conntent 四个部分。差别是对高宽的范围定义。\\n\\nCSS最初并没有定位在布局功能，只是意外地发现盒模型配合float可以实现布局效果，但用float方式不仅需要很多hack手法，还破坏元素间关系，所以增加了flex和grid作为更专门的布局手段。\\n\\n规范定义的盒模型只有block和inline两大类，block的原始语义是一个元素占有一行，主要有div/list-item/table这几种。block能内嵌block/inline，而inline只能内嵌inline。（题外话：由于table的历史比CSS更早，所以CSS用在table时，会有特殊的地方。再提下CSS与HTML历史的兼容性，由于CSS出现得比HTML晚，因此它一定要把HTML中所有的元素的特性纳入到自身的体系结构中。比如HTML的head标签不会显示，对应盒模型的属性就是display:none，不会影响布局，而body就是display:block，作为顶层的BOX容器呈现。任何新生事物都要能包容已有系统的能力，才是可被推广的系统。）\\n\\n和布局相关的三个关键字的优先顺序为display(不为none)>float(不为none)>position。CSS早期的术语来自印刷排版，被用于布局的float就来自印刷的图文混排，而position虽然字面意思就是定位，有relative、absolute、fixed等多种方式，且确实能实现精确定位，但强依赖尺寸计算，有些场景反而不如float好用。\\n\\nfloat用在布局时，一个父div内顺序放置多个div，每个div都设置成float，宽度未满时从左向右排列，如果宽度达到父div的上限，另起一行排列。举例来说，如果父div的宽度是90%，第一个子div是50%，第二个子div是40%，这两个就在同一行，如果第二个也是50%，就会被挤到下一行。\\n\\n归根结底本来每个div单独占据一行，如果想让多个div在同一行，就要破坏div的block特性，让想处在同一行的多个div能float(漂浮)起来，注意必须都float才行。一旦这样块之间就再不是固定的排列关系，而要取决于div宽度总和，如果宽度够就被放在一行了。如果超出了，还是排列到下一行。排到下一行后，可以用left或right来决定对齐方式。\\n\\ninline-block方式是对早期bug的一种不得已的合理化。比如有3个顺序的div，如果1和3都是inline-block且总宽度和小于父block，直接把1和3排列到一行里，如果这一行的剩余宽度还能放下第2个div，就放在同一行，否则在下一行排列。但是如果第二个div是float:left，会放在第一个div前面。\\n\\n### 层叠和继承\\n\\n两个相近但不同的概念，先说层叠，CSS的C代表层叠，也是CSS与其它布局方式最大的不同。CSS的所有变量定义是全局的，因此必然存在冲突，解决的办法就是层叠的规则。样式来源有5个\\n\\n* `<a style=\\"\\">`  属性样式，又称内联样式\\n* `<style >`  内部样式表\\n* `<link>` 外部样式表，又名外部样式表\\n* 浏览器用户自定义样式\\n* 浏览器默认样式\\n\\nCSS权重规则的特殊性可以用4个整数来表示，例如1，0，2，0这样一个4元数表示，计算规则从高到低排列如下：\\n\\n1. 对于内联规则，权重值表示为1，0，0，0\\n1. 对于规则中的每个ID选择符，权重值表示为0，1，0，0\\n1. 对于规则中每个类选择符和属性选择符以及伪类，权重值表示为0，0，1，0\\n1. 对于规则中的每个元素名或者伪元素，权重值表示为0，0，0，1\\n1. 对于通配符，权重值表示为0，0，0，0.\\n\\n最终得到结果就是这个规则的权重。两个权重值的比较类似字符串大小的比较，是从左往右依次比较，第一个数字大的规则的权重高。\\n\\n还有一种层叠，`<p class=\\"A B C\\">`，这时ABC三种样式会层叠后作用在p元素上，ABC属性的层叠原则，和class属性中的排列顺序无关，而是取决于怎么定义，其中规则非常复杂，这里就提最简单的一种，所有都是单独定义（没有父子、兄弟或important时），最后的定义覆盖早先的定义。如果A最后被定义，层叠的结果就是A。\\n\\n继承这个特性是由HTML的结构化特性导入的。像color、font-size、font-family、text-align这些属性，会在给父元素设定后传递到子元素甚至孙元素的样式中，这些子元素/孙元素会得到样式的渲染，就是CSS的继承机制。不是所有属性都会继承，像margin/float等都不会继承\\n\\n### 选择器\\n\\n由于HTML的树状结构，对元素渲染时一定会遇到对某种具有父子或兄弟的元素采用特殊属性的场景，选择器提供了丰富的语法来支持如何选中树结构的某类元素\\n\\n## 学习心得\\n\\n实现侧边栏固定且沉底效果\\n\\n父元素使用`position: fixed`保持锁定,子元素使用`position: absolute;bottom 1em;`实现沉底效果\\n\\n特性解释\\n\\n为什么会有高度塌陷特性\\n\\n> 其实是为了兼容老一辈设计师,在堆叠两个元素时,高度如果叠加会很难看,标委会做了妥协,认同了高度塌陷这种反理工男直觉的特性\\n\\nfloat 和 absolute 有两个特性\\n\\n* 包裹性: 元素默认的宽度是占满整行的,哪怕内容很少,也会以空白填充满这一行.但一旦加了 float,会导致元素的宽度收缩到和内容一样,这种情况下,就可以在该元素的水平方向继续放置别的元素(左右取决于 float 的值)\\n* 破坏性: 父元素的高度塌陷.由于 float 元素脱离了文档流,导致父元素无法获取子元素的高度,于是父元素不再具有高度\\n\\n理解浮动要引申出流的两种概念\\n\\n* 文档流: 相对于盒模型\\n* 文本流: 相对于文字段落\\n\\n元素浮动后,\'\'脱离了文档流,但没有脱离文本流\'\'.前半句是说,紧随它的元素盒会占据浮动元素 Z 轴的底部位置；后半句则意味着紧随元素的文本,仍然认同浮动元素的文本,因此是跟随在后面.\\n\\n## 问题排查\\n\\n* 上下两个元素设置一样的 max-width,但显示时上窄不宽\\n\\n原因是下面的元素设置了 padding 的左右值,而上面的元素未设置默认 0.max-width 默认表示 content 宽度,除非指定 border-box,才表示带边框的盒宽度\\n\\n## HTML转PDF的技巧\\n\\nCSS的@media print可以单独控制打印稿的样式，格式\\n\\n```\\n<style>\\n@font-face {font-family:\\"MyF\\";src:url(\\"file:///C:/Windows/Fonts/lucon.ttf\\");}\\n@media print {\\np.xx_font { font-family:\\"MyF\\"; !important}\\n}\\n</style>\\n```\\n\\n用wkhtmltopdf一定要加上--print-media-type才生效。-s 指定页大小，格式化的有 A0-A9, B0-B10，另外还有数种Letter, Ledger, Folio, Tabloid格式。要控制页边距，则用 -B -T -L -R 后面跟实际的物理单位控制。一台5.5寸手机大约在B7和B8之间。\\n\\n指定字体更复杂一些，首先通过font-face定义一个字体名，并用绝对路径方式定位到字体，因为是src:url导入的外部ttf文件，所以必须通过css类关联到元素才能改变字体。\\n"}'));jctx.push(JSON.parse('{"id": "170219", "tag": "lang", "text": "# 函数式和对象式，表达式和语句\\n\\n伞哥在微博提到，ML的函数语法如果有多个参数，当参数没有完整传入时，并不是像Lua/PHP等一样赋值为nill，而是返回一个curry化的函数。这种思路如果移到协议处理上来，和组件化的实现是不同的拆分方式。\\n\\n协议入口收集所有的参数，如果用curry化的思路，则每个步骤只处理一个参数，然后返回新的函数，并处理剩下的参数。如果第一个参数要做分派，则可能会返回两个不同的函数。通过这种方式，把过程拆分。\\n\\n如果是对象化的拆分，则根据业务划分若干阶段，每个阶段对应一个类，这种方式不会严格限定参数个数，可能第一次就处理所有的参数。不过函数式其实也可以处理所有参数，返回的函数接收新的参数也无妨。不管怎么样都是一个拆分的过程。\\n\\n## 函数式典型函数的理解\\n\\nscala没有break和continue关键字，因为它并不鼓励中途退出或跳过机制，而应先待循环的数据进行过滤再完整处理。引申出对函数式几个最典型函数的思考。\\n\\n* filter 传入函数 x => bool，只保留返回true的内容，达到缩减原始数据的效果\\n* map 传入函数 x => z，返回一个新的，但长度不变的向量数据集\\n* reduce 传入函数 x, y => z，返回一个“标量值”。之所以打引号，是形式上返回的结果可能不是一个简单的数字，但维度上，和原始向量数据的任一项是相同的\\n\\n如果要取向量的前3项怎么办？这时可以在filter中传入闭包，用闭包的状态是否到3来控制返回true还是false，因此这三个构成函数式处理的完备集合。另外从这种处理方式可以看出，只要顺序迭代器就能满足计算，并不需要随机迭代器，但从处理的便利性和效率上来说，随机迭代器有其不可替代的优势。\\n\\n对一个数据集做groupBy操作的结果，就是典型的顺序迭代器，一方面不知道总长度，更重要的是内部数据的无序性，导致随机访问没有意义。\\n\\n## 表达式和语句\\n\\n在PL界，不管平时有没有注意，大都会区分expression和statement。expression的定义是计算并返回值，而statement表示操作，对返回值没有要求，甚至干脆禁止。看似都有计算过程，无非是对返回值的区别，但细想下去，如果没有返回值，就只能靠全局变量来通信，显然是不行的。对函数式编程而言，expression是强要求。\\n\\nJS细分了语句和批语句，批语句必须有{}，典型如switch,try,catch,finally。而像if,for,while都可以省略。Lua严谨，只有批语句的概念。\\n\\n最直观体现两者区别的就是赋值。lua或python的赋值是statement，没有返回值，因此print(a=1)会报语法非法。而C、JS则把赋值后的左值返回，python3.8也加入了:=，使赋值成为表达式。还有scheme的set!实现了赋值，但返回是未定义值，可以打印但无意义。\\n\\nLua的函数返回0到多个值，而JS的函数只能且一定会返回一个值。返回多值的函数如Lua和Go，一种惯用法是返回值第一个为bool表示成功或失败，剩下的是实际需要的返回值。而JS和PHP都只能返回单值，加上JS的函数签名不支持显式引用，如果JS要从函数出参取值，只有使用对象才可以。"}'));jctx.push(JSON.parse('{"id": "170224", "tag": "web", "text": "# Openresty的应用开发\\n\\n每个版本都是在nginx的基础上做扩充，所以版本号会多出一位。ngx_lua、memc、srcache都是扩展。自带resty的命令行工具，启动一个`master_process off`的nginx程序，主要用于验证扩展的lua程序是否正确，配合测试极好。\\n\\n用lor框架开发，首先要记录关于路径的部分。启动脚本是通过nginx加载指定的配置文件来启动，从而实现dev或prod的简单分离。从nginx.conf看，整个流程的路径从app/main.lua进入，所有的路由也都记在这里。\\n\\n先在main.lua打印看lua的package.path，lor的默认配置类似\\"./app/?.lua;?.lua;...\\"，\\n当前路径的.到底是哪里的？开始我错以为是main.lua所在的路径，这是受了PHP的影响。\\n因为nginx和PHP的开发，说到底nginx只是个fastcgi的转发器，最终还是用PHP来跑，\\n所以PHP的话，路径是首个PHP文件入口，但是openresty方式不是，利用的是nginx的prefix path，默认是/usr/local/openresty/ngingx/这个。\\n但是我们的程序显然不可能放在这里，所以这个路径没有意义。幸好nginx提供了-p选项，在lor的start.sh脚本写法是这样：\\n\\n* nginx -p `pwd`/ -c conf/nginx-${PROFILE}.conf\\n\\n通过-p的方式把prefix path导引到lor所在的目录，于是main.lua中require(\'app.server\')就能顺利找到了。\\n\\n使用lord脚手架生成的程序，在根目录有main,server和router这三个文件，\\nmain的注意事项上面已经介绍过了，接下来说router。Web应用开发最主要的就是处理URL请求，\\n再细化一点，要根据方法要区分GET/POST。这个过程行话称为后端route。\\n能看到router文件中有类似app:get(\\"/hello\\", function(req, res, next) end)这样的定义，\\n这是一种框架定义的简写法，表明有GET请求到/hello路径时，触发与之关联的方法。\\nURL的写法似乎只支持原始的和/hello/:id/这一种扩展。不过即便是这样，\\n要实现PHP的Cemvc框架的路由效果也足够了。比如定义一个/lor/:cls/:mth/:param/的路由规则，\\n根据cls从已加载的业务代码中找对应的类。(因为lua语言的require如果失败会强制退出，\\n只能先加载再查询，这是语言不同带来的使用风格不同)。\\n另外function处理细节也比较多，后续再写了。\\n\\nserver是封装lor库的内容，使用app:erroruse函数，可以增加一些错误处理机制。简单的Web开发通过这三个脚手架差不多可以搞定了。\\n\\nnginx程序共四大阶段， 初始化 -> 重写 ->  内容  ->  日志。初始化阶段只在启动时会执行一次，以后再也不会执行，一般定义全局变量或加载常用模块，之后的请求就不用去磁盘加载文件了。如果这个环节的代码抛异常，会导致nginx启动失败。重写和内容对应客户端的一次请求，而日志在响应之后，因为是异步操作，不会影响响应时间。\\n\\n初始化分 init(作用于master) 和 `init_worker`(作用于worker进程)，重写有 ssl_certificate,(这是可选的) set, rewrite, access ，内容有 content(balancer), `header_filter`, `body_filter` ，日志只有 log 。\\n\\n每个阶段能做的操作是不同的，比如init阶段由于还没有收到连接，所以ngx.say没有地方可以输出，显然是不能执行的，只能执行ngx.log操作。相应的指令是 `error_log`，要指定写入的文件名和级别，如果代码中的级别低于`error_log`设置的级别，就不会输出。这条指令的名称略带迷惑性，不限于error级别，所有的级别都可以打印。最低级别的debug，需要编译时打开--with-debug选项才行，当然如果用户指定这个级别也能输出。\\n\\n开发阶段会开启`lua_code_cache off;`，这句指令只影响请求到来时要不要创建新的VM，显然对初始化阶段的语句是无效的。\\n\\n请求的值可以从 ngx.var.xx 中得到，比如地址是 ngx.var.uri ， 参数是 `ngx.var.query_string`。其实一旦存在，还有更简便的方法，ngx.var.arg_keyname直接可以获取。\\n\\n取body稍有些不同，因为nginx的定位是消息转发而不是处理，只要读出Header就能满足，默认不会读内容。需要的话用ngx.req.read_data()，再调用local body = ngx.req.get_body_data()\\n\\n支持响应请求后再做事情，有ngx.eof()和ngx.timer.at(delay, callback)两种做法。\\n\\n数据库很方便，集成MySQL连接池后，简单的两句话得到值，用ipairs遍历res，每次遍历的值，再用数据库的列定义去取值。\\n\\n```\\nlocal mysql_pool = require \'applua/mysql_pool\'\\nlocal ok, res, state = mysql_pool:query(\'select * from one_table;\')\\nif ok then\\n  for k,v in ipairs(res) do ngx.say(k..\' : \'..v.name) end -- change name to other column\\n  ngx.say(res[1].name)  -- direct access first result\\nend\\n```\\n\\n正常结束，则返回的res是table，异常时res就代表错误码，此时state也会被赋值，额外介绍下，根据 X/Open 和 SQL Access Group SQL CAE 规范 (1992) 所进行的定义，SQLERROR 返回 SQLSTATE 值。SQLSTATE 值是包含五个字符的字符串 。五个字符包含数值或者大写字母， 代表各种错误或者警告条件的代码。SQLSTATE 有个层次化的模式：头两个字符标识条件的通常表示错误条件的类别， 后三个字符表示在该通用类中的子类。成功的状态是由 00000 标识的。SQLSTATE 代码在大多数地方都是定义在 SQL 标准里的。\\n\\n如果SQL语句是INSERT或UPDATE，得到的res是key-value的table，会记录数据库受影响的状态。打印结果像这样\\n\\n```\\ninsert_id : 3\\naffected_rows : 1\\nserver_status : 2\\nwarning_count : 0\\n```\\n\\n* 注意，SELECT返回的table格式，和另外三种都不一样。查询是数字下标，且值还要展开一层，而修改类的操作就是普通的k-v对。\\n\\n在worker进程执行os.execute有个很坑的特性，sh的环境变量不一样。原因是我做了个升级脚本，在命令行下怎么运行都正常，但work就会报java版本不匹配，拉不起程序。最后发现在shell中执行的java是/etc/profile中额外加入的java8，而worker中是看不到这个路径的，于是找了版本7。用env打印会发现少非常多变量。最后把/usr/bin/java定位到java8得到解决。"}'));jctx.push(JSON.parse('{"id": "170227", "tag": "lang", "text": "# LuaJIT的编译过程和FFI接口\\n\\n编译LuaJIT比Lua要复杂很多，共分三个步骤。先看src目录下的host目录，首先要编译出host内的minilua，用它驱动dynasm/dynasm.lua并配合`vm_xxx.dasc`来生成`buildvm_arch.h`(但是也可以在Makefile中指定minilua的替代品，所以它并不是严格意义的必须)，这个头文件是生成buildvm程序的关键文件。有了buildvm之后，再用它生成`lj_vm.o`和一系列的`lj_xxx.h`以及jit/vmdef.lua文件，都具备后才能最终生成LuaJIT程序。\\n\\n但是偶尔也有意外，比如我在Win7环境用gcc编译，本来期望生成`lj_vm.o`，却生成了`lj_vm.s`汇编文件，用gcc转成.o会报错，大意是.hidden位置不对。我查了原因似乎是这样，.hidden是ELF格式的指示符，在windows平台没有这种特性，所以会报错。说明虽然gcc本身跨平台，但如果用了些汇编级别的文件格式相关的指令，还是会编译不过的。但这个可以规避，至少vc就没有这个问题，应该是某个编译开关没考虑周全导致的。除了这个，生成的动态文件名也有些差异，windows平台是51，而其它平台是5.1，不知道为什么windows会少一个点，莫非又搞特殊化？LuaJIT的接口一直保持和5.1兼容，后来也慢慢导入5.2的接口，到2.1.0版本共引入了8个5.2的C-API。\\n\\nbuildvm的作用是，它会先执行`build_code`，再根据处理器和OS生成汇编码，比如windows就是`emit_peobj`。\\n\\nOpenResty的核心模块`ngx_lua`是用Lua的CFunction方式实现的，\\n从issue得知有lua-resty-core是基于ffi的实现，且后续会放弃对CFunction方式的支持。\\n看了LuaJIT的FFI介绍并简单看了源码，才发现错过了这么好东西。\\n\\nFFI简单的说就是只要能拿到动态库(dll/so)均可，并且有相应的函数声明，\\n就可以直接地从LuaJIT中调用C语言函数。而且调用方式非常简单直观，\\n就和调用C语言一样，完全不需要像Lua那样的各种压栈操作。\\n\\n实现原理是需要先调用ffi.load(\\"ssl\\")，这个函数的内部实现就是LoadLibrary/dlopen。\\n再通过ffi.cdef中定义的函数名，通过GetProcAddress/dlsym找到函数地址就能调用了。\\n当然这里还有些cdecl/stdcall的转换动作。\\n如果在Windows平台上还会默认加载kernel32/user32/gdi32这三大默认库，\\n因此常用函数甚至不需要load就能调用了。\\n\\n有这么好用的功能，难怪`ngx_lua`的实现都换成FFI方式了。"}'));jctx.push(JSON.parse('{"id": "170301", "tag": "lang", "text": "# LuaUnit记录\\n\\n单元测试的条件如果是函数，则首4字母为test，如果是表，则表名和函数名前4字母都为test，均忽略大小写。判断代码\\n\\n* if string.sub(s,1,4):lower() == \'test\' then\\n\\n可以这样来执行测试命令\\n\\n* lua example.lua test1 test2\\n\\n表示只测试test1和test2，注意这里大小写必须匹配上才行。\\n如果没有，则还按全局搜索出来的测试。\\n\\n函数入口上看，首先是runSuiteByNames，然后会从`_G`中取合适的名字，\\n生成table后再调用runSuiteByInstances\\n\\n用过luaunit的两个版本，3.0和3.2。其中3.0的内部函数大量使用了全局函数，甚至一些标记开关都用了全局函数，这显然破坏了环境。\\n到了3.2版本则全面收敛了这种往全局空间写符号的恶习，包括assertEquals等都在table里，不再是全局函数。\\n但是3.2在执行时一定要用.run(...)语法。开始我误写成:run()语法，在3.0能正常执行，到了3.2总是出错，经过打印才恍然大悟把self给压栈了。\\n执行的时候可以传入各种参数，非常灵活方便。\\n\\n* ut.run(\'-v\', \'-o\', \'tap\', \'testA\', \'testAa1\')\\n\\n再比如执行测试时，有些函数需要一些特殊的参数，比如一个文本解析函数，需要传入一个文件对应的fd，这时使用class的测试方式就能提供额外的便利，可以给这个class定义setUp和tearDown方法(命名全小写也可以)，而且用testA:setup() self.xxx end这种格式也是允许的。luaunit框架这部分的执行流程是这样：\\n每个test函数都会进入execOneFunction执行一次，执行前后判断有无setup/teardown，有就自动调用这两个方法，执行则通过xpcall因此即使内部assert/error也不会异常退出。执行结果保存下来后，退出前执行endTest函数，会根据PASS/FAIL/ERROR分别增加计数结果。\\n\\n如何非侵入式地写测试呢？比如有个lib.lua库，想对其中很多的内部函数写测试，\\n直接在lib.lua写显然相当不友好，肯定再建立一个ut.lua来放置测试用例。两者如何关联呢？\\n\\n1.lib.lua中require \'ut\'，这种方式相当于把require之前的lib.lua的环境作为ut的ENV，所有想导入ut.lua的符号只能走这个ENV，\\n显然只能以全局函数的方式传递给ut.lua，明显不合理，放弃。\\n\\n2.ut.lua中require \'lib\'，这种方式可以把lib.lua中要测试的函数封装在另一个专门做ut的导出表，并在ut.lua中接收并测试，\\n但是有个问题，就是lib.lua到底要返回正常的导出表，还是给测试的导出表，无法区分。目前想到的办法，只能在导出的附近定义一个常量，\\n通过修改常量的方式来测试。虽然还是有改动，但也是目前惟一能想到的方式了。\\n\\n说完luaunit，再引申说说PHPUnit，其实单元测试在我理解，就是语言有机制能提供当前环境中的所有符号名，lua用`_G`变量，而PHP有`get_defined_functions`和`get_declared_classes`这两个方法，通过同样的策略可以实现和luaunit一样的调用方式。不过PHPUnit似乎要指定类名才能执行测试，我觉得这种方式未免笨拙了。\\n\\n最后附记两个Lua小技巧：\\n\\n1.检查一个字符串是否全落在字符集中，执行string.gsub(\'[]\', \'\')，并检测结果是否为空串\\n\\n2.判断string.find的返回布尔值，使用return not not string.find方式"}'));jctx.push(JSON.parse('{"id": "170304", "tag": "os", "text": "# 并发和并行\\n\\n先比较两者的定义：\\n\\n* 并行是parallel，指多进程可以互不干扰地执行程序，与之相对应的则是串行。如果处理的数据不同，自然不用加锁。并行存在数据的归集操作，Perl6也提供了Promise等原语支持。\\n* 并发是concurrent，指多个程序同时运行的现象，注意用词，并发的重点在于它是一种现象，至于实现并发是并行，还是快速切换的串行，反而不重要。所以并发就涉及锁是不严谨的，要说对同一资源的多核并发时，才会涉及锁。\\n\\n并发更多的强调的是有没有这样的能力或特征，它是从事物的性质和对外表现上来说的，它不在乎内部如何实现，相对而言是在更高层次上的概括；而并行则规定了它们在物理上一定是同时进行的，相对而言更严格。\\n\\n存在很多的[[并发编程模型]]，有一本《七周七并发模型》的书介绍了诸如：多进程/多线程的并发模型、异步事件并发模型，Erlang 的 Actor 并发模型和 Golang 的 CSP 并发模型。\\n\\n## 并行涉及的概念解析\\n\\n并行在软件层面大多是创建线程，线程有两种属性join和detach。pth的线程实现有5个队列NRWSD，分别是new/ready/wait/suspend/dead。join属性的线程在退出时加入dead队列，因此依然被调度，而detach属性的线程则不会，因此直接把线程控制变量free掉不再调度。所以退出时也不一样，join用`pthread_exit`可以捕获退出状态，detach可以直接用return。\\n\\n条件变量必须配合锁，在wait前显式地获取锁，在wait函数内进入cond等待队列并释放锁，然后线程block住，将将调度权交还系统。直到另一个线程signal或broadcast才重新执行。而signal函数如果发现cond队列为空，不执行任何动作直接返回。\\n\\n信号量并不是pthread定义的，各个平台函数名也不同，等效于mutex和condition再外加一个计数器的总和。因此mutex和condition可以认为是线程同步的原语。\\n\\n比如公司的RPC网络框架库，后台启动4个业务线程，平时以semaphore的方式等待，消息到了就在epoll线程执行加1操作，接着就会有一个业务线程被执行。但是这个场景中直接用condition是不行的，试想如果4个业务线程都还在执行中，此时又来一个请求，如果是condition的语义，由于所有业务线程都在执行导致cond队列没有等待，这时的signal没有任何意义，导致这个请求丢失。当然如果真用condition，RPC框架也不是这么实现了。\\n\\n## perl6对于同步和并发的探索\\n\\n从slide上摘录要点。\\n\\n* 线程 存在数据竞争\\n* 锁 会导致死锁\\n* 条件变量 spurious wakeups？不清楚是什么\\n\\nPerl6给出的解决方式，用start启动一个promise，再await就可以得到promise结果。\\n\\n支持monitor和actor模式，类似Java的synchronizised同步块语法，可见多线程抢夺资源是如此的普遍，编程语言都会作出方便的支持，Perl6提供了OO::Monitor和OO::Actor两种原语。\\n\\n## 异步接口转为同步接口案例\\n\\n起因是图片识别人脸的协议最早的对接方式是阻塞的，新品改成异步方式，本来以为异步转同步很简单，真正实做才发现细节值得思考。\\n\\n首先异步通常意味着执行的结束时间很长且不确定的，但转同步的时候必须要加上限制约不能无限等待，等待的最长时间全凭经验，是无法量化的因素。\\n\\n接着考虑多线程同步的问题，异步通常需要订阅回调函数，执行并等待的线程A和回调执行结果的线程B间就必然存在资源竞争的问题。常见的等待方式就在是A线程启动一个带超时的信号量(semaphore/event)，并由线程B来释放它。但是如果线程B被触发时线程A的信号量已超时并过期，B就不应该释放。但目前基础库中并没有办法探测A的信号量是否还在等待。因此提高了复杂性。\\n\\n再进一步考虑，执行函数能否并发执行，如果不能并发则在上层调用前就要加锁防止重入。"}'));jctx.push(JSON.parse('{"id": "170305", "tag": "os", "text": "# 系统性能分析的理解\\n\\n曾经以为性能分析一定要用看起来很高深的工具，实际上重点还是在于对系统各个方面的理解。对《性能之巅》观测指标做个分类，分为软件和硬件，软件类包含操作系统、文件系统和进程，而硬件包含CPU、内存、磁盘和网络。\\n\\n## 进程状态\\n\\nps会显示多种状态\\n\\n* S 可中断睡眠，可以被外部信号或内核唤醒，比如网络等待\\n* D 不可中断睡眠，只能被内核唤醒，比如读写磁盘，虽然不占CPU但占着其它硬件，且必须一直拿着这个硬件，否则会导致硬件损坏\\n* T或Z 停止或僵尸\\n\\n另有几种文档说BSD状态，但好像也会显示\\n\\n* <和N 高低优先级\\n* s session leader\\n* l 多线程\\n* \\\\+ 前台进程组，不理解，似乎不重要\\n\\n## CPU\\n\\n最粗略的观察通过uptime和top，看变化趋势和整体分布，要注意的是load和usage是不是维度的度量，两者甚至可能出现很大的偏差。因为load统计可以大体等同于R和D状态的进程总数，表示运行中的进程数，但是D状态不会占用usage，所以如果出现有大量读磁盘的进程时，load会明显高于usage；理论上猜测（没有遇到过），当进程数较少，但某些进程使用多核计算，会出现usage高于load的情况。\\n\\nCPU的计时分了很多状态:  usr, sys, nic,  idle,  io(wa),   irq(hi),   sirq(si)\\n\\nusr、sys和nic是某个进程的耗时，nic是低优先级(1~19)进程的用户态耗时，而io、irq计算整个系统的耗时，类似于公摊，不计入进程耗时。进程还要观察上下文切换，也会导致CPU过高。\\n\\n## 内存\\n\\n内存首先分为物理内存和虚拟内存（swap分区）。\\n\\n内存有cache和buffer。buffer对应block device，比如文件系统的MetaData，量并不大，知道就好不用太关注。\\n\\ncache比较重要，它表示程序曾经往Disk写入的数据，除非系统判断内存不足，不会去清理cache，所以经常看起来很大，但不必担心。\\n\\nps有个-o选项，可以输出非常多的信息，说说内存。\\n\\n* rss，resident set size，表示常驻物理内存的大小。这里有个要注意的，在计算so共享库的时候，会全部计算进去，实际上so的多存往往是多个进程共用，对系统的占用并没有表面上来得严重。累计了CODE段和DATA段的总大小。用pss做总和才是正确的值，p表示比例，共享的内存按比例均分。\\n* sz，比rss大\\n* vsz，虚拟内存，最大。等于swap和rss总和。\\n\\n另有pss(proportional set size)是将so内存按比例统计，对每个进程来说更准确。uss则完全不计入so内存。\\n\\npmap可以给出更细的检测报告，每个so库的每种段，堆和栈占用多少内存全部统计分明。\\n\\n内存在系统中有4种状态\\n\\n1. 未载入(不用关心)\\n2. 已载入，但未映射\\n3. 已载入，且已映射\\n4. 已载入，但被换到虚拟内存\\n\\n通过工具看到最多的，3代表常驻内存RSS，2,3,4合起来又名VSS\\n\\n监测可以针对系统级进程。监测的原理分为计数器和跟踪，另外profile也有，但使用面会窄些。\\n\\n* 计数器方式：由于内核本就维护各种统计数据，因此计数方式的采集可以认为是零开销。基于计数器方式有sysstat工具包，涵盖了一系列专项的工具，如pidstat/mpstat/iostat等。另外sar是system active report的简写，虽然没有stat但也是sysstat的一员。其它各自针对不同资源进行监测。还有一个procps-ng包，包括了vmstat/free/ps/top等经常会用到的工具，形成两大派别。netstat是早已有之，不在这两个派别内。\\n* 跟踪方式：又叫事件，系统级典型如perf/systemtap，进程级有strace/gdb，基于系统事件方式的采样。找到哪个环节出问题，针对性的采集数据。Perf是Linux内核自带的性能监测工具，自2.6.31版开始引入所以发行版都会带这个功能。它配合内核的`perf_events_open`接口(也是perf惟一的接口)使用。而systemtap更像是CentOS专门的工具，默认不带要另外安装。\\n\\n## 计数器方式\\n\\n计数器方式可以很快地看出系统的负载，最复杂的命令是sar，用sar -A可以看到所有数据，底层有sadc(采集数据)和sadf(输出格式化数据)支持。再说几个工具的特性。\\n\\niostat可以监视IO(-d)和CPU(-c)，类似的top命令观测CPU时也有iowait指标，也体现了IO的度量，IO不仅受磁盘影响，也会影响CPU的使用率。\\n\\npidstat从名字可以看出，用于找出问题出在哪个进程，指标包括IO，内存缺页，栈的使用大小。\\n\\n## 跟踪方式\\n\\n2.5版本内核支持了ftrace特性，并以tracefs文件系统方式展现给用户。如果打开了该特性，可以在/proc/mounts查找tracefs的挂载点，并切换到root（sudo不行！）进入该目录（一般是/sys/kernel/debug/tracing/）。既然是类文件系统，通过修改文件来打开跟踪和观察。这种方式操作不友好，trace-cmd包可以简化一些。ftrace的实现依赖于内核在gcc编译阶段留的桩，编译内核的参数缺省会用\\"-pg -mfentry -mrecord-mcount\\"，前两个参数给每个函数开头插入5个字节的callq指令，而最后一个参数则在vmlinuz的`mcount_loc`段记录了所有内核函数的地址。但是所有函数都留桩显然开销太大（下降13%），所以ftrace在内核启动时会callq指令替换成nop指令。当用户对特定函数开启了追踪，用callq替换nop，将追踪信息写入ring buffer输出给用户。\\n\\n2.6版本出现了perf，因为ftrace只管抓trace数据并没有分析，perf在trace数据分析方面做出了很多成果。在trace数据采集方面，perf复用了ftrace的所有插桩点，并且加入了采样法(硬件PMU)。PMU是一种非常重要的数据采集方法，因为它大部分是硬件的，所以可以做到一些软件做不到的事情，获取到一些底层硬件的信息。\\n\\n> PMU是什么：像L1 cache失效、分支预测失败等几种处理器特性对软件的性能有很大的影响，然而依赖时钟进行定期采样的 profiler 模式无法揭示程序对这些处理器硬件特性的使用情况。处理器厂商针对这种情况，在硬件中加入了 PMU 单元，即 performance monitor unit。PMU 允许软件针对某种硬件事件设置 counter，此后处理器便开始统计该事件的发生次数，当发生的次数超过 counter 内设置的值后，便产生中断。比如 cache miss 达到某个值后，PMU 便能产生相应的中断。捕获这些中断，便可以考察程序对这些硬件特性的利用效率了。\\n\\nBPF源于1992年的Berkeley Packet Filter论文，触发Linux社区在97年也跟进并实现了Linux Socket Filter机制，但长久以来只有tcpdump这个应用。BPF原理如下图。经网卡驱动层的报文在上报给协议栈的同时会多出一路来传送给BPF，再经后者过滤后最终拷贝给用户态的应用。除开tcpdump，当时的 RARP 协议也可以利用 BPF 工作(Linux 2.2  起，内核开始提供 rarp 功能，因此如今的 RARP 已经不再需要 BPF 了)\\n\\n![bpf-germ](/img/bpf-germ.jpg)\\n\\n其中的filter是类似汇编码的指令，为了防止注入，对BPF的指令做了很多数量和长度的限制。由于内核态开销大，3.x时代出现了JIT for BPF，2013年对BPF做了彻底重写，命名为eBPF，最终在3.17时代进化出全新的eBPF，并持续发展了seccomp、XDP、traffic control等机制。"}'));jctx.push(JSON.parse('{"id": "170312", "tag": "lang", "text": "# Lua中引入对象风格的价值和loop的实现\\n\\n用弱类型语言写代码，函数多了以后参数具备明确含义就很重要了。就好比web开发不可能总是用原生的json包打天下，定义一个类，更多的也是对接口的一个契约，使其在函数名之外具备更详细的自解释性。至于C++面向对象三要素的封装尤其访问性封装和继承，目前我还没觉得有什么用处，对动态语言来说多态已经在语法层面失去价值，反而使接口和实现分离这个最本初的愿望更直接地体现出来了。\\n\\n接下来先分析loop.base的实现原理，base是基本，就做了最简单的引入类和实例概念：整段代码20行，如下\\n\\n```\\nfunction rawnew(class, object)\\n\\treturn setmetatable(object or {}, class)\\nend\\n\\nfunction new(class, ...)\\n\\tif class.__init then\\n\\t\\treturn class:__init(...)\\n\\telse return rawnew(class, ...)\\n\\tend\\nend\\n\\nfunction initclass(class)\\n\\tif class == nil then class = {} end\\n\\tif class.__index == nil then class.__index = class end\\n\\treturn class\\nend\\n\\nlocal MetaClass = { __call = new }\\nfunction class(yourDef)\\n\\treturn setmetatable(initclass(yourDef), MetaClass)\\nend\\n```\\n\\n创建类需要指定具名字段并返回一个可以call的物件，因此创建是function，返回的则是设置了metatable中`__call`字段的table。如果没有定义任何东西，库也会默认生成个{}，而接下来这句设置`__index`的作用要在new中才会体现。先来看`__call`对应的的函数new。触发这个方法时，第一个传入的参数是class这个function生成的物件，从rawnew函数可以看到这个物件被当作一个object的元表，此时object需要能访问到类中定义的成员，显然需要`__index`方法，又因为这个object不能再创建对象，所以也不会有`__call`字段定义。到此功能原型就出来了。\\n\\n上面说完了base类，这时还不具备继承功能，先说单继承，这是loop.simple的职责，simple要实现继承，在base基础上要再做两件事：\\n\\n1. 要能够访问到基类的属性\\n2. 既然是继承类，也要能够构造实现，也就要有`__call`方法\\n\\n来看simple的代码\\n<pre>\\nlocal DerivedClass = ObjectCache {\\n\\tretrieve = function(self, super)\\n    -- return a new class extended super with __call, so it\'s different from origin super\\n\\t\\treturn base.class { __index = super, __call = new }\\n\\tend,\\n}\\nfunction class(subDef, super)\\n\\tif super then\\n\\t\\treturn DerivedClass[super](initclass(subDef))\\n\\telse return base.class(subDef)\\n\\tend\\nend\\n</pre>\\n如果class的第二个参数(父类)非空，则通过DerivedClass[super]的方式生成一个带`__call`的强化版super类，且索引也指向super。再以subDef为参数向super类上附着子类的参数，这样继承的目的就达到了。"}'));jctx.push(JSON.parse('{"id": "170318", "tag": "net", "text": "# ARQ可靠传输协议\\n\\nTCP是可靠传输协议，但并不是惟一的，甚至在无线环境下都不是最好的选择。可靠传输有三种算法模型:\\n\\n1. Stop-and-wait ARQ\\n2. Go-Back-N ARQ\\n3. Selective Repeat ARQ\xa0/ Selective Reject\\n\\nTCP是Go-Back-N的一个变种。已经有非常多的文章提及TCP的特性并不适合无线网络。另外有种KCP协议，两种协议的设计初衷不同：\\nTCP是为流量设计的（每秒内可以传输多少KB的数据），讲究的是充分利用带宽。而 KCP是为流速设计的（单个数据包从一端发送到一端需要多少时间），以10%-20%带宽浪费的代价换取了比 TCP快30%-40%的传输速度。TCP信道是一条流速很慢，但每秒流量很大的大运河，而KCP是水流湍急的小激流。为什么TCP会选择方式，我猜想大约是和LAN的碰撞特性相关，LAN是基于碰撞检测模型，如果每个节点都频繁地向网络发送消息，网络很容易堵塞，为了充分利用带宽，设计TCP的时候就以必须配合LAN的特性。但到了无线通信时代，如果发送数据不是基于碰撞检测，这个模式就未必是最优的模型。\\n\\nKCP可以跑在UDP上实现可靠传输，如果客户端服务端都是自己的，可以利用这种模式来做业务优化。\\n\\nTCP的拥塞控制算法的简要状态机，加性增窗和乘性减窗。TCP会一直尝试动态调整窗口，如果增大成功，则线性地以常量方式增加滑窗，一旦发送失败，减少一半滑窗。这种机制是非常克制的，在多个节点共同组成网络时，可以尽最大可能利用网络但又不会堵塞。4.9内核引入了google的BBR算法，对计算策略做了优化，发送失败会等待10个周期才减窗，且幅度只有3/4，防止线路噪音造成的意外衰减。"}'));jctx.push(JSON.parse('{"id": "170323", "tag": "lang", "text": "# Python自学手册\\n\\n整个执行包是目录不敏感的，比如编译时指定安装目录是/usr/py3/目录，安装后整体移动到/opt/py3/目录后，依然能正常运行。熟用dir/help函数帮助，不过help依赖pydoc，如果是精简环境会出异常。\\n\\n常用的sys和os，级别并不一样，sys是built-in模块，os只是个普通的py脚本文件。比如sys.path和os.path就很不一样：sys.path是普通数组，而os.path是个module，主要提供一系列操作函数。\\n\\n## 类型\\n\\n从大的分类来说，有两种分类，类型（Type）和实例（Non-Type）。类型中有两个特殊的存在，type和object。所有的内置类型如tuple、list都继承自object（即`list.__bases__`是(object,)），同时它们的type就是type（即`list.__class__`是type）。\\n\\n所有的值，不管是简单的数字、字符串、None或复杂的容器类型，都有所属的class。不同的class具备的特性不同，比如sequence属性就是tuple/list/str还有range类型特有的(range不仅是一个函数，其生成对象的类型就是range，可以迭代)。\\n\\n## 类和继承体系\\n\\n从py3开始，声明一个新的class默认继承自object，前面提过除了object外，还有个特殊的type，因为class关键字其实是对type的封装，class A:声明形式等价于A=type(\\"A\\", (object,), dict=())，所有的类对象，都是type的派生（严格的说是type产生了metaclass，而由此再产生普通类）。\\n\\npy支持多继承，使用MRO解析方法调用顺序，这就对继承有了约束。比如B(A)，那么只能C(B, A)，不可以C(A, B)，因为后者无法满足MRO的要求。当super作用在多继承的子类时，也只会解析出最优先的惟一类，不会把所有父类都调用一遍。\\n\\n## 迭代\\n\\n有两个容易混淆的概念，iterable和iterator。iterable只要支持`__iter__`，可以配合for使用，list、tuple等可迭代对象都是要迭代的。而iterator除了要支持`__iter__`外，还要支持`__next__`，但只能迭代一次，不能重复迭代，优势则是占用内存较少。最简单的构造iterator方式是通过iter()方法转换。\\n\\n## 模块的查找（finder）与加载（loader）\\n\\n最小的代码单元称为module，主要有2种类型\\n\\n1. pure python module: 纯用py写的单元，最简单的情况下，单个py文件就是一个module\\n2. extension module: 用C语言写的py扩展，so或dll文件\\n\\n多个module可以组成package，一般含有`__init__.py`的文件夹称为regular package，还有种namespace package。\\n\\n不管是module还是package，都可以用import xxx来导入，但深入去看还是有区别的。通过import导入的模块可以用del删除，但千万别把自带的给删了，那就再也找不回了。import语句本质是`__import__`函数的二次封装，还有一个importlib包，可以修改一些导入细节，实现特殊效果。\\n\\nimport动作的背后，分为find、load、bind三个阶段动作：find失败会执行load，有些文章会把finder和loader合起来称为importer。find过程可以加hook，通过`sys.meta_path`或`sys.path_hooks`变量来调整行为。bind则是把sys.modules中这次被导入的变量加到globals()或locals()对应的字典，这样代码中才能直接引用。这里有个非常triky的地方，比如import mod，找到mod.py（或者`mod/__init__.py`）并执行到结尾，import语句会往sys.modules写mod变量，再将modules[\'mod\']也绑定到globals()。但是如果mod.py自己向sys.modules写mod，import语句就会直接将这个变量导入globals()，这样就能使import的模块不再是module类型，而是任意指定类型。反观lua，require必须显示赋值给某个变量，把加载和绑定分开，非常清晰，而python最终引入as显然也是认识到import存在的问题。\\n\\nimport可以导入包、模块、函数、变量，如果包和模块同名，会优先加载包。寻找的顺序：builtin包 --> sys.path（这里又按当前路径、py库目录、二进制库、site-package顺序查找）。加载前会先判断是否已经在sys.modules字典，已经加载过的变量不会再次加载，可以用importlib.reload来强制重新加载。import语句执行后，会绑定一个新的本地变量，变量名是left-most值。比如import a.b.c，执行后会隐式创建a变量，如果要重命名，就要用额外的as关键字，我觉得是不优雅的。sys空间下，共有4个和加载相关的变量\\n\\n1. sys.path: 查找路径列表\\n2. sys.modules: 保存已加载模块的字典，启动后这里就会有很多预加载模块，但因为没有在全局命名空间bind到变量，不能直接引用，这时import只需要绑定变量即可，速度很快\\n3. sys.path_importer_cache: 类似sys.path，但内容更多\\n4. sys.meta_path: 查找器finder列表，一般用内置实现，也可以自定义（实现一个定义了`find_spec`类方法的类）\\n\\n导入变量额外说一句，据不完全观察，导入的变量是当前时刻的状态值，导入后，即使被导入模块的值定义发生改变，在引用方无法察觉到，这是件好事，本来也不应该以这种方式来共享一个全局变量。\\n\\n实际中一般会用from package import subpack/module方式，这个语法甚至可以从module加载函数，个人觉得有点过于灵活了。另外from import加载的时间，要慢于import整个加载。\\n\\n`__import__`的细节要复杂得多，因为from/import这套组合可以有多个参数，而`__import__`只有一个字符串，这就带来一个歧义，导入a.b时，究竟是返回a还是b？此时就要通过fromlist来区分，不带fromlist时，返回最左侧的a；如果fromlist是个tuple或list且全部是str值，返回最右侧的b，fromlist只要有str值即可，随便填什么都行。之所以做成这样，我猜测原来想利用fromlist来指定加载的子模块，后来发现多此一举，干脆就退化成指标加载最左或最右的标记位了。\\n\\nimport能导入3个层面的对象，造成这么复杂的原因，猜想可能是最初的import只能导入module，后来随着规模变大，又引入了package的概念，语法上增加了from，可能为了适用性，把from适用于module，导入函数。虽然简单，背后却不简洁。\\n\\n总结两者的差异如下\\n\\n* package: 有特有属性`__path__`，而且可以在`__init__.py`通过`__all__`列表控制`import *`的导出。无法通过getattr获取module\\n* module: 只能整体内容导出，似乎不能控制。可以用getattr获取function或class\\n\\n## 文件身份的识别\\n\\n前面说过一个py文件就是一个module，其自带很多内置属性，加载的方式不同，会导致这些内置属性的值发生变化。\\n\\n* `__all__` ，控制导出的符号列表，但又只适用于部分导出场合\\n* `__file__`，在磁盘上的绝对路径，.py结尾\\n* `__name__`，如果在命令行被调用，则被赋予`__main__`这个特殊名，如果是被import，是不带py的相对文件名（取决于顶级调用路径）。\\n* `__package__`属性，如果这个文件平级没有`__init__.py`文件，那么`__package__`的值是None，否则就是这个文件所属文件夹的名字。\\n* `__doc__`，文件开头的整体声明，不得不说对文档的重视程度还是不错的\\n* `__spec__`和`__loader__`，模块在加载器的对象描述，不同类型模型的加载器各不相同\\n\\n展开说下`__loader__`，随着载入模块的不同，有3种\\n\\n1. _frozen_importlib.BuiltinImporter 用在内嵌模块，比如sys\\n2. _frozen_importlib_external.SourceFileLoader 用在标准库的py文件，比如os\\n3. _frozen_importlib_external.ExtensionFileLoader 用在C写的so扩展库\\n\\n虽然语法中没有类似package或namespace关键字，实际上会把每个文件中创建的函数、变量限定在一个范围内，猜测是`__name__`这个命名空间。\\n\\n## 对代码格式统一的努力\\n\\n1. 缩进曾被作为卖点之一，但现在似乎更倾向用外置format工具来做。用了缩进后，不能做压缩，也多出了特有的类似pass的占位语句。\\n2. 函数形参可以加`*`或`**`，表示这个变量是tuple或dict。只看效果是个很简单的语法糖，但用这种形式强制规定了元组在前，字典在后的形式，并引出了posional argument和keyword argument两个概念。\\n\\n## 装饰器\\n\\n@方式在函数外部引入的装饰器，会导致实体函数的元属性被装饰器拦截，如果想保留实体函数的元属性，要额外地import functools import wraps\\n\\n```\\nfrom functools import wraps # 引入functools模块的wrap装饰器方法\\n\\ndef repeat_twice(func):\\n    @wraps(func)\\n    def wrapper(*args, **kwargs):\\n        func(*args, **kwargs)\\n        func(*args, **kwargs)\\n    return wrapper\\n\\n@repeat_twice\\ndef foo():\\n    print \'hello world\'\\n\\nprint foo.__name__      # Out: foo\\n```\\n\\n## 异常与警告\\n\\nwarnings子系统，纯py代码，调用.warn后向stderr输出，也可用filter方式拦截输出\\n\\n## 搭建PyPI仓库\\n\\n仓库本质上是个http服务，目录包含若干压缩包和这些包的索引，PEP定义过仓库的规范，通常仓库的目录结构类似下面这样：\\n\\n```\\n/pypi\\n|__packages\\n    |__/51/36/32/cc660efa43e482b97d4c2c2bcfdfde03b4f88c82f261d128cf/pandas-1.0.1-cp38-cp38-linux_aarch64.whl\\n|__simple\\n    |__pandas\\n```\\n\\npackages下放whl或tar包，包名必须带版本号，否则无法进行语义化比较，不能放其它类型的文件；simple是索引目录（通过dir2pi /pypi命令，递归遍历目录内容后自动生成），pip查找或安装时，先在索引目录定位到包。包有wheel和源码两种形式，wheel是编译好的格式，安装比较快，如果只有源码包，则会下载到本地并编译成wheel（默认在~/.cache/pip/wheels/），在下次安装时能加速。"}'));jctx.push(JSON.parse('{"id": "170324", "tag": "security", "text": "# VPN概念解释\\n\\nVPN的本意是把来自不同子网的设备放在同一个子网内，构建虚拟网络。既然要并网，肯定要做身份认证，而PPP点对点协议天生就带认证属性，这也是家庭网络都是PPPoE方式接入。\\n\\n实现VPN的协议很多，举我所知的几种\\n\\n1. PPTP  微软出的规范，RFC2637。必须基于IP或TCP协议(至少要3层网络)，加密密钥最高支持到128bit，强度比较弱，甚至在iOS10的时代直接被苹果给抛弃了，但是因为是微软自家的东西，又出了SSTP后继，好像没什么人在用\\n2. L2TP  思科提出，RFC2661，广泛使用\\n3. IPSec 用XAuth认证用户，model config分配IP。由于XAuth有版权且没有标准化，兼容性不如L2TP。运行在用户态的IKE daemon和处理实际IP报文并运行在内核态的IPSec协议栈，不同的OS实现不同。\\n4. IKEv2 iOS10去掉PPTP后，新支持的类型。特性是IKEv2的MOBIKE(见RFC4555)扩展，VPN建立后切换网络(如从4G到3G)不会掉线。另外认证也支持EAP，比IPSec只支持XAuth好像更高级\\n5. OpenVPN/ShadowSocks/V2Ray 这些更多的是穿越工具，分类上有些并不属于VPN，也没有RFC标准，一般都只是某个开源软件的实现，因此Android/iOS系统都需要额外安装对应的客户端软件，系统本身不自带\\n\\n## L2TP\\n\\nLayer 2 Tunnel Protocol的缩写，Layer 2这里指的是PPP协议，通俗地说，就是为了运输二层协议PPP而存在的。L2TP因为有PPP，负责AAA，也就是认证、授权、计费（Authentication, Authorization, Accounting）。除了IP网，还可以跑在ATM, MPLS, 帧中继等网络。由于L2TP 传输安全性太差，于是人们在 L2TP 外层再套一个 IPSec 来保证传输过程的安全性，传输HTTP的话就是这样一个层级\\n\\n```\\nIP/UDP(4500)/ESP/UDP(1701)/L2TP/PPP/IP/TCP/HTTP\\n```\\n\\nIPSec使用ESP加密，除上面介绍的传输模式外，还有另一种方式IP/ESP/UDP(1701)/L2TP/PPP，也叫隧道模式。这种方式IP层的负载是ESP，往往过不了NAT，并不适用于发起VPN者的网络环境。而前面提到的方式虽然会有两层UDP，但容易过NAT，这也是单纯技术上最佳的选择并不会被市场接受。\\n\\nL2TP似乎只有6个字节，每两字节一段，分为3段。第1段是协议和标志位，第2段是Tunnel ID，第3段是Session ID。后面这两个ID看起来是绑定的，但方向不同值不一样，命名为Session ID有点不对题。其上的PPP只有4个字节，1字节Address，1字节Control，2字节的承载协议类型（此例中指明是IP）。比TCP三卷本的说明少了最开始的0x7E。\\n\\n## IPSec和IKE\\n\\nIPSec方式工作在IP层，其涵盖的ESP和AH协议主要是规定IP包的格式，因此在连接对端时，只要服务器域名不需要端口。\\n\\n中间人攻击是针对加密会话的初始化阶段进行的，IPSec 的初始化阶段显然要考虑这个问题，所以提出了XAuth规范，但该规范不如IKE的EAP，说到这里就要引出IKE协议了。IKE 协议在1988年11月发布v1版，2005年升级到v2版。是在奥克利协议（Oakley protocol）与ISAKMP协议的基础之上发展出来的，它和IPSec是独立的两套协议，但人们发现二者组合非常互补，所以现在往往一起提。由于IKE使用X.509安全认证，问题就转化成了面对中间人攻击，我们要如何去验证 IKE peer 的身份呢？也就是说，我们要如何确定对方就是我们要联络的人呢？IKE 协议里Message type 5 和 type 6 就是负责这个事情的。具体来讲有三种方法：\\n\\n1. 预共享密钥：Pre Shared Key，简称PSK。用大白话就是双方商定一个密钥作为彼此认证的手段\\n2. 公钥加密：需要配置用户证书/CA证书/服务器证书\\n3. 数字签名\\n\\nXAuth似乎只支持预共享密钥和公钥加密，对应了XAuth和PSK/RSA选项，EAP不再依赖PSK。\\n\\n### StrongSwan\\n\\n基于IPSec最早的项目名叫FreeS/WAN，所以现在都沿用了swan这个名字，是Secure Wide-Area Networking首字母的缩写。这个项目停止维护后，衍生出OpenSwan、LibreSwan、StrongSwan。StrongSwan的主程序名就叫ipsec。\\n\\n## OpenVPN\\n\\n通过四层的TCP/UDP建立连接，然后客户端会从服务端得到私有网络的配置信息，进而客户端会在其主机上创建TUN网卡，该网卡的地址和服务器在同一个网段，从而构成私有网络。\\n\\nTUN/TAP网卡是linux2.4版本出现的最早的虚拟网络，TUN网卡工作在三层，主要和应用程序直接打交道，为了模拟一张完整的网卡，再配套一张工作在二层的TAP网卡，整个网络栈就齐备了。\\n\\n使用iproute2的ip命令来创建TUN网卡，需要root权限。此外TUN还用于做IP隧道，IP4和IP6组合起来共有4种类型。"}'));jctx.push(JSON.parse('{"id": "170329", "tag": "protocol", "text": "# 协议为什么要分包\\n\\nTCP是流式传输协议，每次在传输就要告知对端一个这次数据的长度，否则在流上无从断句。像HTTP就有Content-Length字段用于标识包长度。但是公司的协议除了总长度，还有分包长度，比如数据超过32K后，每次只发送32K，这个特性有什么意义呢？\\n\\n这个特性和数据发送模型有关，公司协议是一条连接上可以并发地发送多条请求，即第一条请求的应答还没到，就可以发出第二个请求。HTTP则没有这个特性，HTTP的多请求利用同时创建多个TCP连接来实现。但是如果在一个连接上有多组请求应答，假设第一个应答有100K,第二个应答只有10字节，但是如果把第一个100K直接写入socket，再写入第二个10字节，则后面的10字节必须要等待100K发送完成才会继续发送，这对简单应答就很不利，所以强制将数据拆散32K,只要发送中途线程被调度到，就有机会把这10字节发出去，如此一来就可以尽早收到简短的回复包了。"}'));jctx.push(JSON.parse('{"id": "170403", "tag": "web", "text": "# php-fpm记录\\n\\nPHP的组成，从内到外大致分3层\\n\\n1. 解析器核心，在形态上表现成php.dll，实质是zend引擎，做语法解析和字节码执行。对应配置php.ini\\n2. 函数和标准库\\n3. 外覆层，引出SAPI概念，进入解析器的入口可以有多种模式，这些模式就称为SAPI。比如php-fpm，对应配置php-fpm.conf\\n\\n写web程序时，可以很方便地调用`$_GET`，这个变量不是核心层的特性，而是在SAPI层解析了CGI环境变量后，再传给核心的。所以不同的SAPI，会提供不同的外围特性。\\n\\n比如在linux下默认编译出的有php(cli)、php-cgi(cgi)和phpdbg(dbg)这3个可执行程序，如果要配合nginx，在编译选项增加`--enable-fpm`就能得到php-fpm(fpm)。它们都能解析PHP，PHP-FPM存放在/usr/sbin/下，其它几个则在/usr/bin/下。但是不知为何linux并没有用动态库，上述4个程序都是静态编译，每个29M，这样做很浪费空间，也许是我编译选项没有打开？逐个说明这几种SAPI：\\n\\n* cli : 命令行接口，也是其它语言最常见的模式，像python/ruby等程序都可以理解为cli模式。\\n* debug : 调试接口，和`perl -d`方式效果相同(也许其它语言也有类似的)。这个接口似乎是5.6或稍早的版本被合进主干的。\\n* cgi : 这个接口就体现PHP天生为Web语言的一面了，支持FastCGI/CGI规范，相当于在PHP的语言内核外，增加了对FastCGI网络请求的解析，在windows版的phpstudy默认就是运行4个`php-cgi`进程常驻后台。\\n* fpm : 最初只是个第三方开发的PHP进程管理器，后来在5.4时代被官方合并，并支持PHP解析。是目前主流的FastCGI容器方案，由于用了fork只能运行在`*nix`上。\\n\\n由于php-fpm只是外围入口，很多php自身的参数仍然需要设置，所以它有两个配置选项，-c指定php.ini路径，-y指定fpm路径。重启使用kill -USR2 PID方式，关闭使用-INT。如果要快速找到pid可以打开配置中定义的pid文件路径，默认因为不保存所以要用ps加grep来查找。\\n\\n要想加速php，少不了opcache模块，从5.5.3开始默认包含。它属于zend extensions，并且要指定完整so路径。原理是把编译后的PHP字节码缓存到内存，下次请求来的时候，根据文件名找到编译后的字节码，就能极大地节省时间。PHP对应cli模式，执行完毕就退出，显然这种模式无法利用缓存在内存的字节码，但不知为何7.1版本默认打开cli模式下的缓存。既然cli模式不行，通过PHP-FPM常驻内存，并fork多个子程序，子程序和父进程使用共享内存，子程序能完整地执行PHP字节码，并不依赖cli程序。一个佐证是Android上的phprunner程序中，就只有惟一的PHP-FPM程序配合lighttpd运行；而PHP Server这个包选择php和php-cgi程序，没有web服务器和php-fpm，靠php的web模式也能接收网络请求。\\n\\n还要注意的一点，一旦打开缓存，所有的PHP的内容就都会用缓存的数据。我之前页面中的一些数据采用PHP的方式内嵌，导致缓存后无法更新，只有重启PHP进程才能更新数据，后来改成从txt文本读取才解决这个问题。"}'));jctx.push(JSON.parse('{"id": "170405", "tag": "protocol", "text": "# HTTP2特性学习\\n\\nHTTP2在制定时要保证不破坏语义且要尽可能地兼容，为了平滑地从HTTP/1.1升级到HTTP/2，会用到Upgrade协议头，但这样就会消耗一整个来回做升级动作，在标准制定时Google/FireFox的人都非常反对这一点，且HTTP2的前身SPDY就是利用TLS握手阶段进行协商，还定义了一套称为NPN的协议，HTTP2也类似，最终规范要求至少要TLS1.2版本，且协商协议换成了ALPN。这两者的差异在于ALPN是服务端最终确认协议细节，而NPN则是客户端确认。\\n\\nHTTP1.1有个很大的限制，每次请求在应答到来之前不能发下一个请求。因为协议本身没有标识请求序号的字段，导致只有等待响应收完才能发新的请求，要么干脆建立多个连接，在每个连接上并行地发请求。但是建立连接的开销是非常大的，在HTTP2时代，终于通过在请求头，规范叫Frame里加上了一个31bit的无符号sequence id的方式把问题解决了。用31bit是考虑到跨语言，比如Java没有unsigned int，如果一定要用uint32，就必须使用int64方式，显然划不来。\\n\\nFrame是个9字节的二进制段，包含长度、类型、标志和请求序号四部分，非常紧凑。长度只有24bit。请求序号采用客户端奇数服务端偶数的方式配对。"}'));jctx.push(JSON.parse('{"id": "170429", "tag": "protocol", "text": "# P2P及SIP和xinetd\\n\\nP2P穿透涉及的协议有STUN/TURN/ICE，STUN是真正的UDP打洞，但只适用于cone NAT的网络环境下(完全、限制、端口限制三种都支持)，因为STUN的核心是子网内的客户端和公网建立连接后，NAT映射后的公网地址要能被另一个客户端使用，只有cone NAT才满足这个条件，symmetric NAT不允许公网端口复用，因此无法即使从公网上获取了NAT后的地址，也不能用来和另一个对端连接。\\n\\n对symmetric网络，只能使用中继方式，就用到TURN的方式，ICE要解决的问题和TURN类似，但两者的差异还没有完全清楚。\\n\\nP2P之后两个端就要建立会话，SIP是定义非常严谨的协议，明确地分了4个层级，基础的用ABNF规定了文档用语的格式，然后是传输层，接着是和业务关联最紧密的事务层，事务层之上还有个可选的事务用户(TU)，但这一层并不是必须的，比如无状态的proxy就没有TU一说。\\n\\n## xinetd类程序\\n\\n知道xinetd这玩意属于偶然，本想尝试着在linux上跑cvs的server端，然而还是失败了。所有的服务端程序都需要监听端口，比如httpd就自己监听80，但是如果有大量非高频程序，要监听各式各样的端口，全数都启动显然是浪费资源，super server daemon也就是xinetd就是解决这类问题。这个程序的前身是inetd，不过现在都切换到xinetd了。\\n它的功能是配合/etc/service配置项，监听各种各样的端口，然后把端口请求转发给相应的程序。比如在/etc/xinetd.d/目录下配置2401端口由cvs监听，平时cvs不会启动只有2401端口来请求时就唤醒cvs来处理。很多本身不带网络服务的程序，通过xinetd就具备了通信功能，有点CGI的味道。\\n\\n从功能上可以看出xinetd属于优化类程序，并不是默认自带程序，Alpine linux甚至都没有包。在Cent7下通过yum install xinetd安装，也可以通过下载包手动安装，依赖很少。xinetd程序也很小，x64版本不到200K。安装后还需要通过service xinetd start启动，这样才真正开始监听。\\n\\n用xined监听telnet遇到问题，系统默认telnet只能监听23端口，但是这要求有root权限，这种情况下要先在service增加一个伪telnet服务，让这个服务监听新端口，然后配置这个伪服务，最终导给telnet监听。\\n\\nbusybox有类似的程序tcpsvd，配套telnetd和ftpd一起使用。"}'));jctx.push(JSON.parse('{"id": "170516", "tag": "os", "text": "# OpenBSD学习与使用\\n\\n系统分为内核文件和应用层套件，根目录下放置启动器boot和内核文件bsd，对一些支持多核的芯片，会另有bsd.mp文件，但不清楚此时bsd是否仍必须。\\n\\n用ksh作为默认shell，功能少很多。每个版本升级会带来若干改动，升级换内核前必须做好充分准备工作。\\n\\n## 系统工具\\n\\n* syspatch 更新系统的应用层套件\\n* pkg_add 包管理器，修改/etc/installurl可以换源\\n\\n## ps程序走读\\n\\nps程序要从内核读取进程消息，BSD内核上承SunOS使用了kvm.h，这并不是Linux下的虚拟机，而是kernel virtual memory的意思。是用户态读取内核的交互接口，kvm的一些操作需要root权限，这也是BSD系列的ps和Linux的ps不同的原因。\\n\\n大致来说，先用`kvm_openfiles`打开一个kvm句柄，然后用`kvm_getprocs`读取内核参数，并返回一个`kinfo_proc`数组，用qsort对数组进行排序，排序的比较方式有DEFAULT/CPU/MEM三种，内存排序值得说说，`kinfo_proc`是个非常大的结构，计算内存使用了其中有的tsize/dsize/ssize三个变量，分别表示text/data/stack size，另外还有rssize，即RSS，注释是current resident set size指包括栈和堆在内的占用物理内存。但排序并不把这个值计算在内。显示的时候还有VSZ表示virtual size，但奇怪的是在OpenBSD上，VSZ却比RSS还小。\\n\\nps在检测进程状态有个-t选项，表示只显示与这个tty关联的进程，/dev/下有100多个tty，命名都是/dev/tty开头，这是在paths.h的`_PATH_TTY`宏来定义，这个文件定义了很多与路径相关的变量，Linux也有，应该是为了让程序跨平台用的。与操作者相关的是ttyp0和ttyp1，另外还有ttyC，ttyc、ttyP、ttyVI等好几个大类的终端。\\n\\n另外还有大量的代码都是在处理各种参数，因为ps的参数实在太多了。"}'));jctx.push(JSON.parse('{"id": "170525", "tag": "protocol", "text": "# 网络相关头文件所属目录的关系\\n\\nunix下的网络文件分布的目录比较多，初看会觉得很乱且难记，试着整理一下。\\n\\n本着unix下一切皆文件，所有的网络操作都通过抽象的socket操作，即socket是这些网络的承载者，不同的网络主机有各自的socket，并处在不同地址上。socket的头文件是sys/socket.h，比较直观也很好记。\\n\\n对网络来说，不同的网络不能直接通信，所以socket首先要和地址绑定，不同的网络方式地址格式不同，要确定地址就要先确定网络方式，这里引入第一个概念`AF_XXX`宏，AF指Address Family，除了常见的IP网络(有`AF_INET/AF_INET6`两种)，还有像Bluetooth、AppleTalk、IPX(Novell)等不常见格式。OpenBSD支持36种，而Linux支持40种。从数量来看好像差不多，但两个系统间互相之间的交集并不多。Linux支持的NFC/CAN格式在BSD下不存在，同样BSD也有很多Linux没有的，不过总的来看BSD的网络协议更冷门一点，也许和它历史更久，用得也少有关系。\\n\\n因为不同的地址族使用不同的协议，所以还定义了一套`PF_XXX`的宏，PF指Protocol Family，除了前缀不同，其它和AF宏完全一样。既然有三十多种地址，地址的格式必然不会相同，struct sockaddr解决的就是这个问题，这是个变长的结构，否则无法支持未来的网络协议族，因此这个结构最重要的就是长度和family字段，定义方式和TLV的思想是一致的。sockaddr相当于父类，具体每种协议族有各自的表示，像`sockaddr_in`是IP网络地址，而appletalk就是`sockaddr_at`，命名风格非常统一。不过并不是每个协议族都有专用地址，net80211/就没有。\\n\\n虽然socket.h文件比较长，但和操作相关的accept/bind/connet/listen等占比重不高，其余大量各种宏和数据结构操作的定义。比如`SOCK_STREAM/SOCK_DGRAM`，这样看起来，这两个定义适合各种网络，而不仅仅是TCP/UDP。\\n\\n理解了socket.h，就能知道网络的family有非常多，每种family下肯定还有很多的选项，这么多的协议族肯定要分开保存管理，所以在/usr/include/目录下有net/目录，还有形如netinet/、netmpls/、netatalk/、netax25/等等具体协议族的目录。\\n\\n先说net/目录，这下面的文件特点是大都`if_xxx.h`风格，主要的用途是查询(inquery)各种network interface。比如`IFF_UP/IFF_MULTICAST`操作。BSD和Linux在这里又显出很大的差别，BSD中定义了名为ifnet的结构，用于内核操作网络接口man(9)，但Linux没有。\\n\\nnet的作用更多在于操作网卡，具体的协议比如IP协议则定义在netinet/目录下，这里的in.h(我猜应该in是internet的简写)定义了IP协议的各种应用，如TCP/UDP/ICMP/IGMP/ESP/AH等。这些定义都以`IPPROTO_`作为前缀，是IP PROTOCOL的简写。\\n\\n这样一路看下来，网络头文件的规律就很清晰了。最后再说一个稍有点特殊的头文件，arpa/inet.h，这里定义了各种IP地址的数字表示和字符串表示的转换函数，为什么放在arpa目录，我猜是因为：IP网络的定义是由IEEE提出的，但第一个实现这个网络的是arpanet(1968年构想，直到1975年才有60个节点)，可能是当时开发时觉得，需要一个工具性质的地址转换函数，就放在arpa这个有点项目专用性质的目录下了，但后来随着用的人很多，所以就保留至今，没有移到netinet目录。另外arpa/目录下还有telnet.h/ftp.h/tftp.h等文件，原因是arpanet要求主机实现telnet/ftp/tftp协议，这也是一个网络最基本且必须的功能。所以arpa/目录作为历史的见证一直保留到今天。"}'));jctx.push(JSON.parse('{"id": "170526", "tag": "net", "text": "# 从ifconfig接口看网卡\\n\\nifconfig显示的除了网卡，还有网桥bridge，因为if表示接口，没有限定必须是网卡。\\n\\nip命令比ifconfig显示的网卡数量多一些，ip能显示的网卡，都在/proc/net/dev里保存着。\\n\\nip区分了link和address命令，link显示的接口，会显示出attach到ether/loopback/ipip。address显示的是link的超集，有些网卡有多地址，用link只有一条，而address就会把所有的地址都显示出来。\\n\\n## 网络工具包的变迁\\n\\nifconfig/route/netstat/arp/rarp等网络管理经典软件（属于net-tools包），起源于BSD TCP/IP工具箱，旨在配置老式Linux内核的网络功能。自2001年以后，它在Linux社区的发展就止步不前，很多发行版默认不安装该包，甚至有弃用net-tools的打算，改而使用iproute2替代。net-tools通过procfs(/proc)和ioctl系统调用去访问和改变内核网络配置，而iproute2则通过netlink协议与内核通讯（这套协议和unix域套接字、inet在同一层级）。由于netlink是Linux独有，BSD社区依然使用net-tools工具。\\n\\n网卡的模式在if.h定义，有十多种。这些状态大多是可以组合，少数互斥(环回LOOPBACK，bond的MASTER/SLAVE)。说几个可能不那么常见的\\n\\n* LOWER\\\\_UP：注释表明Driver signals L1 up (since Linux 2.6.17)，是物理层的标志。LOWER\\\\_UP表示以太网线已插入，并且设备接入到网络。而UP在LOWER\\\\_UP的基础上，还要求网卡使能（个人理解是被ifup）。\\n* NO-CARRIER：可以和UP一起，但表示网络不通。可能的原因有：网线故障、无线未在SSID认证、驱动故障（极少数）。\\n* NOARP：对于BORADCAST型网络（以太网或无线电packet radio），ARP标志默认打开，如果显示NOARP则表示ARP被禁用，可能是网络形态不同，也可能确实遇到故障。\\n* PROMISC: 混杂模式，接受目的MAC不是本网卡的包。抓包软件和虚拟网卡会用到。\\n\\nifconfig会显示发送和收到的包数据，单位多见MiB，这个单位表示2^20，在1998年12月定义的ISO/IEC80000规范里可查，同一家族有kibi, mebi, gibi, tebi, pebi, exbi, zebi, yobi，i取自binary的第2个字母，所以这些单位都用bi后缀。而平时常见的MB往往会视场景，可能是10^6，也可能是2^20。以精确而言，MiB是更好的写法。\\n\\nRX和TX的包数据里，会另外显示5种异常状态的数据（frame和carrier是单向）\\n\\n* Errors: The total number of transmit or receive errors detected by the device driver.\\n* Dropped: The total number of packets dropped by the device driver.\\n* Overruns: 驱动拿到的包，会放到内核的Ring Buffer（FIFO队列），如果网络流量过大超过CPU处理速度，就会导致overrun。ethtool -g查看，ethtool -G修改参数。\\n* Frame: 收包特有，一般表示收到的帧过小或过大，比如不符合8bit的帧。\\n* Carrier: 发包特有，carrier原意是调制用的载波，此处表示因载波异常或不匹配导致数据发不出去。\\n\\n## Linux与BSD的网卡差异\\n\\nLinux下的网卡只有lo和eth两张，但是OpenBSD还额外多两张虚拟网卡，enc和pflog。这两张网卡都是基于pf而存在，因此也就好理解为什么是OpenBSD特有的网卡。\\n\\nenc和ipsec特性配套，pflog则是pf log的简写。IPSec有四大特点：\\n\\n1. 数据加密\\n2. 内容完整\\n3. 身份认证\\n4. 防重放攻击\\n\\nIPSec有两个协议族，ESP(Encapsulating Security Payload)和AH(Authentication Header)，差异在于\\n\\n* ESP具备以上四条特性，但只对IP的负载生效，不保证IP头的安全\\n* AH重心在认证，因此缺少数据加密功能，但它能保护IP头\\n\\n如果要让socket启用IPSec，OpenBSD的netinet/in.h下定义了很多IPSec的宏，如`IP_AUTH_LEVEL/IP_ESP_TRANS_LEVEL/IP_ESP_NETWORK_LEVEL`以及`IPSEC_`开头的很多宏，可惜这些并不跨平台，Linux系统定义在linux/ipsec.h中，且是通过枚举方式，数量也没有OpenBSD详细。\\n\\n从默认网卡的配置和头文件定义就能看出，OpenBSD的确是在践行着最安全操作系统的理念。\\n\\n## bond网卡制作\\n\\n服务器通常有多张网卡，要求配置为bond模式，对cent系来说，并不用特殊的命令，只要添加一个ifcfg-bond0的纯文本文件，重新启动网络服务就好。\\n\\n展开了说，bond是由普通eth网卡组成，同时修改那几个ifcfg-eth的文本，使它们映射到bond，而所有的IP，网关，掩码都在bond配置。似乎还要启动一个内核模块，具体原因不明。\\n"}'));jctx.push(JSON.parse('{"id": "170531", "tag": "tool", "text": "# Word的标题样式和多级列表关系\\n\\n对一篇有结构层次的文档而言，章节标题的编号是很重要的，它能很直观地给出这部分内容在整个文章中的位置和前后关系。虽然通过给标题刷上样式，也能出现编号，但这种编号只能是简单的一个数字，想要达到类似1.1，1.2.1这样具备层次的效果，只靠标题样式无法实现。需要利用Word中被称为`多级列表`功能，它不同于简单的编号，也无法在样式的菜单中实现。\\n\\n定义一个想要的多级列表，需要通过独立的多级列表菜单进入。在备选的列表库中，提供了几种多级列表样式。如果要自定义的话，有几个很重要的点要注意\\n\\n1. 将定义后的多级列表链接到样式，这点非常重要。我猜测是样式只记录了自身编号，所以样式的编号菜单不论再怎么折腾，只能实现一级数字的效果，无法实现多级序号并列。要显示多级序号，必然要参照更高一级别的编号，如果实现在样式中，按程序员的行话，就会造成标题间的强耦合，而微软又是一个非常强调工程师文化的地方，并不考虑使用者是否好用，所以没有把多级列表的设定放进样式菜单。\\n2. 怎么让多级列表能识别上一级标题，不要出现明明第二章了，却还是1.4这种荒诞的样式呢？在设定新的多级列表中，又有两个选项，此级别的编号样式和包含的级别编号两项，包含的级别编号就能自动继承上一级标题。但要注意这两个编号的顺序不要反，否则会出现本级标题在前，大标题在后的怪异效果，即明明是第二章第一节，应该显示2.1却显示成了1.2。搞不懂为什么要有这种灵活性，按我想法，直接固定上级标题在前，本级标题在后，岂不是更方便使用。难道在多语言环境中，会出现本级标题在前高级标题在后的需要吗？"}'));jctx.push(JSON.parse('{"id": "170610", "tag": "os", "text": "# dmesg和BSD初期版本的故事\\n\\ndmesg最早出现在3BSD时代。\\n\\n1975年Ken Thompson请了一年休假并来到Berkeley担任客座教授，Ken在Berkeley安装了Version 6的Unix，并实现Pascal编译器。这时Bill Joy因为优化这个编译器而出现在历史舞台上。因为其它学校对这个系统也很感兴趣，Joy在77年着手完成系统的拷贝并最终在1978年3月发布了称为1BSD的版本，共卖出30份。接着1979年5月发布了2BSD版本，这个版本有两个程序至今还在用，就是vi和csh，共卖了75份。\\n\\n头两个版本是Joy初试牛刀，同期发生的重要事件是1978年Berkeley买了VAX机，当时贝尔实验室也为VAX做了适配并命名为UNIX/32V（基于Version 7 Unix）。但这个系统并没有优化好VAX的虚拟内存特性，于是Berkeley的学生大幅重写了内核并把2BSD的程序也移植到了VAX机，最终在1979年底发布了3BSD。从这个版本起，BSD便不再是UNIX的clone了。\\n\\ndmesg在OpenBSD的实现并不复杂，利用sysctl接口的`CTL_KERN`和`KERN_MSGBUFSIZE`命令字获取信息的长度。再用`KERN_MSGBUF`获取真正的内容。不过这两个枚举在FreeBSD上没有定义，OpenBSD中定义的KERN操作枚举值要比FreeBSD来得多，大概也是两套系统在逐渐演化过程中发生的差异吧。\\n\\n内核文件是名为bsd的大约10M的文件，不像Linux的vmlinuz文件，bsd就是个普通的ELF执行文件，内核文件不止一个，比如bsd.mp用于多核系统，还有bsd.rd是类似光盘镜像的文件，如果用syspatch升级内核，还会产生一个bsd.syspatch61的备份文件。根目录下还有boot文件，类似于grub，启动顺序也是BIOS->boot->bsd这个顺序。\\n\\n安装包使用`pkg_xxx`系列，应该是和FreeBSD类似，使用tar包方式，tar包其实有多种格式，GNU的tar用的默认格式是gnu，但OpenBSD用的是ustar，是1988年的posix版本，另外有2001版posix标准的tar，GNU宣称未来也会切换到这种方式。安装包的地址从/etc/installurl获取，目前我只找到清华的repo是\\nhttps://ftp.openbsd.org/pub/OpenBSD和https://mirrors.tuna.tsinghua.edu.cn/OpenBSD。\\n\\nOpenBSD的代码是用cvs管理的，看来落伍但社区觉得已经足够。先说说分支管理：风格很固定，每个版本有`OPENBSD_6_1_BASE`和`OPENBSD_6_1`两个标签(symbolic name)，其中BASE是revision，也就是Milestone，一般是决定开发新版本时，创建一个后续不再更新；而`OPENBSD_6_1`则是基于这个revision的branch，是真正的发行代码。\\n"}'));jctx.push(JSON.parse('{"id": "170620", "tag": "lang", "text": "# 从Javascript函数类型理解计算和对象\\n\\n对任何程序语言来说，函数的设计是最核心的特质，函数涉及的变量作用域、参数的值和引用语义这些基础概念体现了语言设计的核心价值。JS的原则是一切皆对象，typeof null的结果是Object，自然function也是对象。定义一个function foo变量，可以用foo.xxx语法取成员变量。原因是凡是对象都可以用点号来索引成员，既然foo是函数（对象），当然也可以用点号语法。\\n\\nJS的对象可以和Lua元素的`__call`元方法或者`C++`的operator()比较。由于JS的函数是对象，因此可以用`.`符号从对象中索引成员，这就是[].push.apply这种神奇语法的来由。这里的两个点号分两段理解，第一个点从[]这个空的数组对象中取到push方法，第二个点从push方法提取apply方法。注意push是函数，但同时也是对象，因为函数对象有apply成员，所以可以从push索引到apply。\\n\\n以上这几种语言中，函数可以认为是一种拥有计算能力的对象，而计算则是在一个有限的环境下进行变量操作。对JS来说，环境就是this变量，对Lua则是`_ENV`。换句话说把`C++`成员函数的第一个this参数理解成环境，也未尝不可。这一点从MuJS的C接口`js_call`必须先压入一个this参数可以体现出来。\\n\\n## prototype和constructor\\n\\nJS的对象体系最大特色是原型和constructor。记住一个概念，JS的12种类型里，所有变量都有隐式原型`__proto__`，只有Function类型才有显式prototype，由于prototype是Object类型对象，所以它只有`__proto__`属性。\\n\\n通过new Function获得的值，如果不是Function，就不会有prototype，只有隐式的`__proto__`，且指向Function的prototype。这样做的目的是维持继承体系。用代码展示更直观：\\n\\n```\\nvar obj = new afunc()\\nobj.__proto__ === afunc.prototype    // 非函数类型的值没有prototype，但会有个隐式的变量指向其构造者的原型\\n```\\n\\nconstructor也是函数衍生出的概念，只有函数和prototype指向的对象才有constructor。用function foo()定义一个函数，foo.constructor指向Function()，而foo.prototype.constructor指向foo，这是两个不同的对象，要注意区分。new一个构造函数在MuJS通过专用的`js_constructor`语法来调用，和`js_call`惟一的差异就是少了压入this这步操作。\\n\\n任何函数都可以作为构造函数被使用，考虑new的语义是先创建一个空的对象，把这个函数中涉及this的语句操作，作用在新创建出的空对象上。最后返回这个对象，因此return语句就自动失效了。"}'));jctx.push(JSON.parse('{"id": "170707", "tag": "data", "text": "# 使用xapian和scws进行全文检索\\n\\n中文的全文检索最难的是分词，暂时只有scws结合xapian能跑起来。scws是个分词库，用在生成倒排索引阶段，建立索引和查询还是要利用xapian才能完成。\\n\\n生成索引是查询是两个相反的过程，输入一个或多个document的描述到index，生成B-tree或其它格式的数据库，输出一个关键字给search，search从索引数据库把document还原出来。\\n\\nxapian的索引和查询命令分别是simpleindex和simplesearch，索引生成的数据库是个目录，内部的文件比较多，simplesearch指定到数据库目录，再输入关键字，会按匹配程度从高到低排列出来。"}'));jctx.push(JSON.parse('{"id": "170728", "tag": "lang", "text": "# wren语言记录\\n\\n一门很小且很快的语言，EOS的作者BM对wren语言非常推崇，并整合到EOS中。\\n\\n下载源码后先到src目录下看看wren的代码结构。目录结构很简洁，核心代码都在vm目录，一万行出头，光有vm还不够，另外的module目录实现了基本的io/os/timer功能，代码才800多行，代码少的原因是依赖libuv。还有optional目录，不需要uv，支持了随机数和元的功能。以上3个是库，还有个单独的cli生成可执行文件。\\n\\n在windows下无法通过make自动编译成功，原因是Makefile的调用Python脚本，使用了Linux下的#!语法，在windows需要调用前显示地加上python字样。首先将vm下的代码生成libwren.so，这步比较顺利。但编译cli版本会失败，原因是需要下载uv，但用的机制是git和python的gyp机制，gyp的源码地址无法访问，好在cli程序的.o目标文件能编译出来，只要手动修改支持uv的头文件和库，就可以用了。\\n\\n前面提到编译wren需要python，原因是这样的。一个编译器如果纯用C写，工作量是很大的，如果在实现了语言分析的基础(或最小子集)后，直接用新的语言来定义扩展功能显然更方便，wren用的方法就是用wren语言写扩展，然后用python把这个扩展用文字替换方式变成C风格的字符串，通过C语言的include机制在虚拟机加载字符串，最后调用`wrenInterpret`接口加载到vm。所以换个角度想，作者直接用python把wren转换好再上传，就不需要客户端安装python了。但这种写完虚拟机，并用新语言进行扩展的作法值得学习。\\n\\n通过wren.h来一窥与C语言的交互，毕竟作为wren目的是提供一种快的可嵌入的纯粹的脚本引擎，vm部分没有集成任何外围库。在C语言宿主程序要用wren源码，只有上面提到过的`wrenInterpret`接口，它支持传入字符串，但不支持传入文件名或文件指针，原因是它没有IO库。载入脚本后最自然的想法就是传参并调用函数，传参用`wrenSetSlot***`函数族，Slot类似Lua中栈的索引，比较好理解。但是函数调用就很不一样了，共有3个步骤\\n\\n1. `WrenHandle* wrenMakeCallHandle(WrenVM* vm, const char* signature)` 构造一个函数签名对象\\n2. `wrenGetVariable(WrenVM* vm, const char* module, const char* name, int slot)` 加载包含method的变量，另外准备好参数\\n3. `WrenInterpretResult wrenCall(WrenVM* vm, WrenHandle* method)` 执行第一步构造得到的函数签名\\n\\nwren是class-based的语言，且为了支持大规模开发，支持module，因此作为最小执行粒度的函数，要经过module->class->method这样一条路才能找到。module一般对应文件，class包含两个特殊的函数定义allocate/finalize，构造是必须的，析构可选。allocate需要从wren中调用，它的原型是`typedef void (*WrenForeignMethodFn)(WrenVM* vm);`，没有返回值是因为wren的函数必须且只能返回一个值(默认返回null)，所以就省略了。finalize的原型是`typedef void (*WrenFinalizerFn)(void* data);`，没有vm参数是原因是它in the middle of GC。为了减少查找method的开销，甚至把函数签名放到C的空间，而不是vm上。另外函数签名也是wren特有的，目的都是为了提高执行速度。\\n\\nwrenInterpreter的执行流程是先加载`main`模块(指cli下运行，如果是host内执行可以是别的模块)。wren的编译把parser和compiler分成了两个类别，先把module和source保存在parser，再传入compiler输出一个ObjFn，再将这个Fn包装成Closure，最后把Closure包装成Fiber，到这一步才真正开始执行。"}'));jctx.push(JSON.parse('{"id": "170806", "tag": "protocol", "text": "# 区块链的运行机制\\n\\n区域链本质上是一种由交易驱动的，由共识确认并跃迁的状态机。区块链由区块以单向链表方式连接，并利用哈希的特性保证了数据的不可篡改性。\\n\\n交易可以是BTC的转账支付，也可以是ETH的智能合约。每个人都可以发起交易(相当于向区块链提交一个合并请求)，这笔交易会保存在矿工节点的内存中(普通节点只传播，但不保存)，当这笔交易没有记入主链前，就不具备合法性。要合入主链需要矿工的确认，由于每个块的容量有限，矿工只会选择手续费高的一些交易合入区块。如果块容量上限太小，或出现爆发性的交易数量，就一定会有交易驻留在矿工的内存(常说的网络堵塞了)，才有BTC的扩容争议。一旦交易被矿工commit，且最终被成功地seal(以上两个词取自ETH的日志)。这条交易就具备了永久的合法性(严格地说还要再加上若干次确认，否则有可能出现在分支上，最终还是被更长的链超越而视作无效)。\\n\\n众多矿工同时竞争向主链的提交，依赖共识算法来决定哪个矿工取得这一轮的权利。方式有很多，如PoW或PoS等。PoW算法达成共识非常消耗成本，因此对完成条件的个体会有激励，这个激励的形式就是增发的数字货币。\\n\\nBitcoin交易有Coinbase、P2PKH、P2SH几种（隔离见证后，又增加了P2WPKH和P2WSH）。\\n早期的交易（高度62061以下）的交易数都是1，这些交易都是coinbase交易，输入没有签名，长度也比较短，典型长度0.215K，sequence通常是0xFFFFFFFF。P2PKH的`tx_in`脚本比较长了，包含签名和公钥，71(签名)\\\\+65(公钥)\\\\+1\\\\+1=138(两个都分别是长度占位)。但是从密码学角度看，有了签名(即R和S)，只要再配上个`rec_id`(范围0-3)是可以反推出公钥的，如果采用这种方式能极大地减少输入脚本长度。\\nP2PKH交易的`tx_out`，脚本长度25(用1字节表示)，脚本中5字节是操作符，20字节是HASH160的结果，加上8字节的金额总共是34Bytes。\\n\\n以太坊来目前也是PoW共识机制，它的挖矿算法称为Ethash，这是个比较高层的概念，每个Ethash持有GenericFarm，这个Farm下再持有多个miner，从这个结构看，应该是受了farm和miner的关系就像矿池分解任务给节点的关系。最终的验证通过farm来完成。验证的术语是seal，cppeth自带的seal只有CPU，也许要用上GPU挖矿要用另外的程序吧。seal的封印对象是BlockHead，另外BlockChain对象的作用还没有明白。\\n\\n以太坊Trie的设计，对轻客户端友好，每个区块头的三个指针代表了三个核心的树：状态、交易、收据。\\n\\n交易树比较简单，收据是一个RLP编码的数据结构，除了索引变得更加简单，logbloom的使用也让轻客户端使用起来非常方便。\\n\\n区块头的设计和轻客户端是密切相关的。绝大多数节点并不需要完全同步，但要求访问数据的便利性。\\n\\n区块内的主要数据结构是MPT，这里面稀疏区域用KV节点。在状态和账户的树里，diverge nodes 深度为64，使用sha3(k)作为key，非常难以DOS攻击。\\n\\n目前整个状态的访问查询可以变得更快，全节点的全同步也可以变得很快。因为紫皮书带来了新的方向，压缩算法或是uncle区块实现等，紫皮书引入了POS机制，更友好的轻客户端同步实现，计分和测了实现， 分片以及跨分片通信等。\\n\\n作为公开链的区块链，必然需要密码学为依托，比特币选用了非对称算法中的椭圆曲线SECP256K1，经历了时间的考验被证明是安全可靠的，以太坊和BitShares也沿用了相同的椭圆曲线。\\n\\n以上是相同的部分，当然也有些不同的部分，不过这些不同只是在使用链的方式不同，不影响区块链的特性。\\n\\nBitcoin中只有一笔笔的交易，这些交易会存入一个地址，但并没有帐号。可以想象成有很多张支票，每张支票都有一个谜题，谁能解开这个谜题谁就能使用这张支票，如果一个人说他有很多比特币，或者他有一张大额支票，或者他有一堆小额支票。而以太和Bitshares是有帐号概念的。又比如链的生长速度差别就更大了，Bitcoin基本固定10分钟，以太则15秒，但是因为依赖PoW，并不是严格遵循这个周期，而Bitshares用的DPoS机制，能严格保证3秒出一个块(其实是1～30秒范围内可设置，取决于committee的投票结果)。\\n\\n按老董的讲解，至少符合三个条件的区块链的项目才有可能是好项目：\\n\\n1. 必须是在线上建立信任，并基于此信任生发出的项目\\n2. 逻辑必须是清晰明确且简单的，一方面区块链的计算能力偏弱，另外从技术上写出安全的智能合约极难，为避免风险，也应用用简单的方式\\n3. 使用区域链所带来的收益要高于成本(任何商业项目都适用)"}'));jctx.push(JSON.parse('{"id": "170808", "tag": "lang", "text": "# flex和bison的理解\\n\\n这两个工具是编译理论都会介绍的经典工具，分别用于词法和语法分析。词法比较简单，虽然有NFA和DFA的区分，但总的来说就是把原子的字符按规则合并成符号，但语法分析就有LL和LR两种差异很大的流派。从词法分析向LL演进，是比较自然的方式，但词法进到LR，中间存在一道鸿沟，这时我觉得更好的做法是先学习LR的语法分析，理解LR的思维，自然就明白为什么、何时需要词法，以及flex和bison两个工具的协作模式。\\n\\n为什么Bison这种通过工具生成解析代码的方式被称为LR分析器，而手写解析器一般都是LL分析法呢？这两种方式都是BNF的解析方式，而BNF属于产生式文法，指先定义文章包含段落，段落包含句子，句子再包含单词，着眼点是从最顶层的结构，逐步扩展细化，最终推演到单词环节结束的过程。\\n\\n不管是LL还是LR，解析词法符号都是从左向右，两者都是L，没有不同。如果将符号形成一个句子，就有了分歧。手写分析器是从左向右一旦符号成为一个合法句子，解析结束，优先从最左侧进行推导，所以称LL法。而Bison的解析思路，即使已经达到推演条件，还会继续读进符号，只有在读进的符号不能推演，才会结束，优先从最右侧进行推导，所以Bison的作法称为LR。看Bison的规则，人脑很难自然地联想出从文章细化到句子乃至单词是怎么结合上的，因此LR方式通常是用机器生成代码。\\n\\nLL的术语是First/Follow集，而LR则称为shift/reduce。读入符号(shift)再生成句子(reduce)，这和书写yacc的规则是逆过程，不过不用担心，工具会把正确地完成这个逆过程。既然要先shift，就一定会有栈保存符号，Bison在语法分析前，先创建200长度的数组作为栈。每条规则的执行都会改变栈的深度。默认规则动作$$=$1就是在栈保存值，有这个值后面的解析才能找回值。\\n\\n生成词法解析代码用flex一个二进制文件就够了，而生成语法解析代码不能只有bison二进制程序，必须配套多个m4脚本，这些文件称为skeleton（比如yacc.c或lalr.java等代码模板）和XSLT的输出模板目录，保存在/usr/share/bison。而且不同语言用到的文件也不一样。比如要实现C语言输出，至少要7个文件。\\n\\n## flex\\n\\n调用flex不需要特别的选项，windows平台可以加一个`--nounistd`防止编译错误。\\n\\nlex的外部输入源有文件和字符串两种形式，但内部归约到一个统一的宏`YY_CURRENT_BUFFER`，这个buffer在lex内部以栈的形式保存，可以存在多个，也可以push/pop。\\n\\nbuffer可以从`extern FILE* yyin;`创建，默认读出16K的内容来生成buffer，也可以是字符串，字符串可以包含0。使用文件方式比较简单，在yylex函数中，如果判定外部没有初始化yyin，则将它赋初值为stdin。\\n因此在函数入口需要申明`extern FILE* yyin;`并从希望读取的文件来给yyin赋值。\\n如果不使用yyin，也可以用字符串，方法是用`yy_scan_string(C风格字符串)`或`yy_scan_bytes(二进制串)`指定字符串，再将返回的`YY_BUFFER_STATE`指针传给`yy_switch_to_buffer`，这样yylex()的输入就自动定向到字符串了。当然记得最后不要忘记调用`yy_delete_buffer`把指针给释放了。\\n\\nlex的第一部分，要写上%option noyywrap(对版本有要求)，因为lex产生的代码会用到yywrap()这个函数，也可以把这个函数直接定义成`#define yywrap() 1`，上述这句也就是lex帮你定义这个宏。如果%option没用，变通方式直接定义yywrap()函数并返回1也可以(这也是flex库默认提供的实现，因为这个库太没用，基本都是手写这个函数)。\\nlex可以更改默认的变量名前缀，不用yy。如果把lex和其它语法分析器配合使用，会有效果。另外lex支持生成可重入代码，但在和bison配合时比较别扭，关于可重入的说明，在lex和lemon的文章中介绍。\\n\\n### 踩坑记\\n\\nflex的action部分如果要输出`[[`或`]]`，比须写成`\\"[\\"\\"[\\"`，否则不仅会被吞掉还会警告。示例将py的长注释转为lua格式，方括号要转义\\n\\n```\\n\\\\\\"\\\\\\"\\\\\\"|\\\\\'\\\\\'\\\\\' { EXATR(v); if(0==v->st_lc){ TRANS(\\"--[\\"\\"[\\"); v->st_lc=1;\\n```\\n\\n## bison\\n\\nbison处理文件最好加上-d和-t -r all选项，-d输出头文件，用于给flex指明终结符的定义，后面会详述。-t -r all输出详细报告，报告的内容分4部分\\n\\n1. Grammer：从0开始编号，0也是终结态$accept，自动生成。其它都是用户自定义规则\\n2. Terminal：每个条目都是一个符号且定义了int值，对应lex返回的枚举或该字符的ASCII值，有两个特殊终结符，$end(0，代表YYEOF)和error(256)\\n3. Nonterminal：对应rule。就包括$accept，还会详细标明每条规则出现在哪条grammar的左或右，左右是语法分析很重要的特性\\n4. 最后是各种state,从0开始编号，会显示具体的shift或reduce动作。如果有冲突，会提示哪几个state存在歧义，大多数state会带一个default的reduce规则，当然也有不存在default的。如果default对应的是accept，这个state就是最终态了\\n\\n除了-t -r all选项，还可以通过-g和-x选项输出automaton的graph和xml report，报告类似分为grammar和automaton两部分\\n\\n* Grammar是各条BNF规则的描述\\n* 接着是Terminal和Nonterminal定义,Nonterminal的第一条同样是隐式的$accept\\n* automaton是多个state的合集,描述的是各个state之间的转换关系,每个state下面有itemset、action、solved-conflicts\\n* action包括了transition（shift和goto状态）和reduction（和rule关联）\\n\\n通过yacc的规则，也生成了解析的C语言文件，但是数据(终结符，用%token定义的符号)需要从lex获取。前面提到bison -d会生成头文件，这个头文件就是给lex包含的，lex自己不需要生成头文件（因为就一个int yylex()函数原型）。除去注释，yacc生成的头文件包含4条内容\\n\\n1. 一个enum的枚举声明，对应yylex()的返回符号类型\\n2. 声明YYSTYPE类型，int或union，这里的S指semantic的意思\\n3. 声明一个YYSTYPE类型的变量，yylval\\n4. 声明int yyparse()函数原型(低版本bison不会生成)\\n\\n除了第4条比较显而易见，说说前3条必须存在的原因\\n\\n先说enum枚举。lex在识别词法后，yylex()的返回值要把词的类型告知yacc，所以需要yacc在首部申明`%token ***`，token对应终结符，正好对应lex，还有一种%type，对应的是非终结符，用在yacc内部。\\n这个头文件就包含了%token声明的枚举定义。%token/%type不是C语句，不需要;结尾，当然带了也没关系。\\n\\nyacc能支持递归，因此写规则时会出现循环引用和空规则。以下是最简化的lisp语法解析\\n\\n```\\nsexp: /*empty-rule*/ {}\\n  |   sexp one_exp {}\\n\\none_exp: \'(\' mul_em \')\' {}\\n  |   T_VARNAME {}\\n\\nmul_em: one_exp {}\\n  |  mul_em one_exp {}\\n```\\n\\n当规则引用自身时，**自己一定出现在左边**，否则会无限循环，又因为是产生式规则，右边的式子代表最新reduce的结果。规则互相引用时，也会有些微小的差别，不然又会引起循环。\\n\\n## 对外函数接口\\n\\nlex和yacc各自对外的惟一函数分别是int yylex()和int yyparse()，两个函数都无入参且返回int。虽然是自动生成的代码，但抛开各种表的数值不谈，流程还是能看明白的。\\n\\nyylex()看似没有入参但其实是通过外部变量作为输入源，一方面有历史原因，而且既要接受文件句柄，又要接收字符串，一种类型较难表达，只能退而求其次用一种并不巧妙的方式。出参是识别到的终结符类型枚举（文件结束时返回0），枚举值由bison定义，标识符枚举从258开始（跳过单个字符的范围），需要int来表示。\\n\\nyyparse()无参但有输入，输入就来自于其内部调用的yylex()。yyparse()返回的int表示错误码，共有0/1/2三种值，0代表正确，1表示异常，2表示内存耗尽（比如shift导致栈过深）。\\n\\n## 交互与变量传递\\n\\nyyparse()调用yylex()，涉及两种类型的数据传递\\n\\n1. 这次的token类型是什么？\\n2. 这次的token要表达什么含义？\\n\\n第1个简单，通过yylex()返回的int来表示，第2个就相对复杂，让我们进入lex看。lex的上下文，当前识别出的原始字符串，保存在yytext里，类型是`char*`，长度保存在yyleng，它和strlen(yytext)是一样的。但是yytext是yylex函数内的变量，yyparse()不能使用，正确的处理方式：**将yytext处理并保存到yylval变量**。\\n\\nyylval是由bison定义的全局变量，它是yy lookahead value的简写，代表了一次识别出的终结符的具体值，调用yylex()后，yylval就可能有了数据，在yyparse()内部将yylval依次保存到yyvsa数组（通过yyvsp指针），类型和yylval一样也是YYSTYPE。在bison的上下文，用$1、$2语法来引用yyvsp数组中的对应位置，从而实现了变量传递。YYSTYPE默认是int类型，不是玩具程序的话，肯定需要更复杂类型，就用到yacc的%union{}语法来替换int类型。YYSTYPE（就是刚才定义的union）包含在头文件中，lex才能看到union的声明，识别到符号后，进而将yytext转换成相应的类型。\\n\\nyyparse()是双栈式推进，yyssa表示state stack，yyvsa表示value stack，状态栈记录当前shift或reduce的阶段，而语法分析并不是最终目的，还需要输出分析结果，因此每一步的中间值也要记录下来，所以就有了值栈。两个栈的初始长度都是200，如果栈满了之后可以通过自定义的栈生长函数扩容，但最大不要超过10000。yyssa的当前状态经过yypact和yytable的转换，可以计算出要从yyvsa上POP多少个元素，根据.y文件的定义对yyvsa数组进行索引定位。\\n\\n## 实战flex和bison注意事项\\n\\n日常处理协议要做太多的转换工作，想试着能否用类似google的proto描述方式来自动化生成。决定用flex和bison再配合一个script语言如lua或js来做。期间走了不少弯路。\\n\\n语法解析的bison会强制要求实现`yyerror(char*)`函数，但其实回调的信息很简单，基本就是syntax error没有指向性，这是LALR的固有缺陷，有两个改善的办法。在yyparse()调用之前打开调试开关\\n\\n```\\nextern int yydebug;\\nyydebug = 1;\\n```\\n\\n能打印出每个符号读入，shift/reduce的步骤。\\n\\n如果嫌错误信息太长，可以语法分析错误时增加行号显示，要做两件事\\n\\n1. 让flex对行号自增，加这条规则 `\\\\n {yylineno++;}`\\n2. 让bison在yyerror中显示行号\\n\\n```\\nextern int yylineno;\\nvoid yyerror(const char* str){\\n  printf(\\"\\\\nBison error at line:%d, %s\\\\n\\",yylineno, str);\\n}\\n```\\n\\n还有个小的细节要注意，打印到stderr而不是用printf输出到stdout，在后期会体现出便利性。\\n\\nflex解析后的token的内容保存在yytext，同时yyleng记录了有效长度。通常这个值要传递给bison，并在语法规则匹配后再利用这些值做逻辑，但是最好不要在bison直接用yytext，因为等到触发bison的规则时，yytext/yyleng表示的是最后一个token，前几个token的值无法直接用yytext得到。通常作法是把词法匹配后的字符串dup一份，这就要求bison在匹配后还要做free的动作，不仔细配对很容易出错，我的办法比较讨巧，既然要dup字符串涉及内存管理，不如直接把这时的yytext传给script engine，利用脚本的垃圾收集机制管理内存。即脚本在flex阶段收集素材，而bison阶段处理素材。\\n\\nbison的规则允许直接用单字符的终结符，要用上这个特性，flex规则的末尾要写上`. {return yytext[0];}`，如果不写，yylex()不会返回这个单字符，而使用flex默认的ECHO规则将这个单字打印到console上，并不会传递给bison。\\n\\n脚本引擎和分析代码之间的交互有两个接口，分别是在flex调用的push(token, str)和bison调用的reach(rule)。语言先用lua，最终还是决定换成更大众的JavaScript，一是为了自己熟悉，另外JS的受众更多，维护人员会更好交接。关于JS的引擎单开一篇写。\\n"}'));jctx.push(JSON.parse('{"id": "170814", "tag": "tool", "text": "# 重新认识Makefile\\n\\n不要片面地把Makefile理解成程序编译工具，更广义地说是个基于文件依赖关系的管理工具。可以通过make制定规则、调用shell命令，也可以在Makefile中定义变量、条件和函数调用实现复杂的功能。Makefile包含五种块：显式规则、隐式规则、变量定义、指令和注释。\\n\\n## 显式或隐式规则rule\\n\\n```\\nTARGET ... : PREREQUISITES ...\\n        RECIPE1\\n        RECIPE2\\n```\\n\\nTARGET可以表示一个文件名或动作名(Phony Target)，PREREQUISITES是文件列表，并作为TARGET的输入。隐式规则的区别是有且只有一个`%`，用于匹配文件名，通常是文件类型的替换。\\n\\n先说TARGET，因为含有两个意思，如果指定的目标名恰好有个同名文件，文件名会优先于动作名。常见的all/clean规则一般表示的是动作名，如果Makefile所在的目录中恰好有文件名是all，那你就等着看all is update to date吧。要避免这种错误，就必须显式地声明Phony Target，告诉make不要管那个同名文件，使用的语法是`.Phony : all clean`。\\n\\n之所以有时候不指定phony，执行make clean也能成功，是因为make按文件名先去找clean文件，找不到才去执行该规则的动作，而该动作通常无论如何都不会生成一个clean文件，因此不写phony也没有问题。\\n\\n但以上说的是clean这种没有依赖的目标，如果有依赖，情况又不一样了：\\n\\n假设目录中有个clean文件，按说执行make clean是不会有动作的。但当我们把目标写成 `clean : *.o`，执行clean目标需要先找到.o文件，这时make就不理会有没有clean文件，而是去查找.o的隐式规则，找到后去生成.o文件，如果clean的recipe又恰好是删除操作，又会把关联的.o再删除一遍，很无厘头吧。做这个测试也只是为了理解make的运行规则。\\n\\n其实理顺了make的规则也就那么几点，无非就是显式/隐式规则的目标查找和一些内建函数的用法以及一些奇怪的变量名，好在我看来常用的特殊变量就三个，也有点规律。像$^就是显示规则中:后面依赖项，另外$<和$@则是隐式规则的源和目标，<表示源，@表示目标，基本上勉强能算上字面意思吧。\\n\\n## 变量与使用\\n\\n原始的Makefile的变量定义比较简单，只有`=`一种定义，`=`在使用时会递归地查找右边变量的定义，有时会引起不希望的副作用，GNU make引入了`:=`避免递归问题。另外还定义`?=`和`+=`两种赋值符，分别表示不存在才赋值和追加赋值。\\n\\n变量除了用`=`族显示定义，也会继承自同名的环境变量。可以在执行make前先export环境变量实现条件编译，以下示例实现了如果VENDOR变量为1，就额外链接一些库。如果环境变量不是想要的，但又不能改，可以用make -e遮蔽并重新定义。\\n\\n```\\nifeq ($(VENDOR), 1)\\n  EXTLIB = -llpeg -llsqlite3\\nelse\\n  EXTLIB =\\nendif\\n```\\n\\n自带很多函数实现很方便的操作。比如要找到所有含有jpg图片的目录，就可以这样：\\n\\n```\\nSUBDIRS = $(sort $(dir $(wildcard */*.jpg */*.jpeg)))\\nprint:\\n        @echo $(SUBDIRS)\\n```\\n\\n函数调用语句和变量引用是类似的，先用wildcard尝试通配jpg或jpeg的文件名，剩下的dir和sort是因为不关心图片内容，只要文件夹名。sort带去重功能，可有可无。\\n\\n命令前带@表示不打印命令本身，还有个更有用的前缀-，表示即使这行命令出错，也继续执行。比如-include，如果找不到要包含的文件，不会停下来，make会提示Error 1(ignored)且继续运行。直到遇到TARGET无法达成才报错，并显示`***`，也可以显示调用$(error your prompot)来提示错误。-可能是GNU扩展，如果要通用化，最好用sinclude代替。\\n\\n## automake\\n\\n1994年9月第一次提交，依赖于1992年开发的autoconf和更基础的m4。automake和autoconf的版本号演进各自独立，似乎不是一个团队开发。其做法从最初就没有大变化，从`*.am`文件生成`*.in`文件，只是规模从最初的500行代码发展到如今几万行规模。"}'));jctx.push(JSON.parse('{"id": "170816", "tag": "security", "text": "# RSA/DSA/EC三种算法记录\\n\\n从Openssl的命令行操作来一探这三种非对称加密的端倪。三者的操作命令并不对称，支持的列表如下\\n\\n* RSA：genrsa/rsa/rsautl\\n* DSA：dsaparam/gendsa/dsa\\n* EC：ecparam/ec\\n\\n## RSA说明\\n\\n生成私钥的命令是`openssl genrsa -out xxx.pem 2048`生成2048的私钥，但文件并不是2048bit，因为RSA私钥包含的内容很多，要看私钥文件的具体内容，可以用`openssl rsa -noout text xxx.pem`显示，从内容可以看出，modulus和privateExponent是2048bit，publicExponent是0x10001，其它的prime1/prime2等都是指定位长的一半，即1024bit。同理如果genrsa指定的长度是1024，modulus和privateExponent是1024bit，prime1/prime2等都是512bit。modulus和publicExponent共同构成了公钥文件的内容。RSA的加密会用到padding算法，解密必须指定相同的padding才能成功，因此其使用上的复杂度要高于椭圆曲线。\\n\\n使用openssl rsautl系列命令可以加解密。公钥加密私钥解密用`-encrypt -decrypt`，私钥加密公钥解密则是`-sign -verify`这对命令，但是libressl版的openssl支持用私钥调用-encrypt，却无法解密，不知道算不算bug。\\n\\n进行加密时为防止同样的明文得到的密文一样，都会填充数据，1.5版本填充方式适用于加密和签名，而OAEP只适用于加密，PSS只适用于签名。\\n\\nRSA的数字签名应用非常广泛，被固化到U盘作为签名私钥，有种更新的算法RSA-FDH(Full Domain Hash)。PDF的1.5版本只支持2048位的RSA签名。\\n\\n## DSA说明\\n\\nDSA生成公私钥比RSA要多一个步骤，先用dsaparam生成参数文件，这份参数文件可以被多个用户共用，生成每个用户各自的公私钥对。决定签名结果的因素有HASH算法和KEY的长度（推荐1024以上），生成参数命令`openssl dsaparam -out dsaprm.pem 1024`。可以看到生成文件就包含P/Q/G三个大数。P和Q都是素数，且P-1必须是Q的整数倍。\\n\\n用dsaparam指令的`-genkey`也能直接生成公私钥，独立的genkey指令则可以对生成的公私钥文件进行AES/Camellia加密。这样生成的文件内既有公钥又有私钥，显然不适合分发，需要把公钥提取出来，命令`openssl dsa -in dsakey.pem -out dsapub.pem -pubout`，坑爹的是`-pubout`参数在dsa的帮助命令里居然没有，但从rsa命令的帮助能看到。。。\\n\\n有了公私钥文件，接下来可以选择一个文件进行签名和验证。Openssl并没有直接提供类似dsautl命令验证签名，需要用dgst指令完成。签名命令`openssl dgst -sha1 -sign dsakey.pem -out sign.dat yourfile`。其中sha1可以换成任意想要的摘要算法。比如选用了1024bit的私钥，生成的sign.dat是46bytes，DER编码的二进制文件，解码DER的话能得到两个大数R和S（位数一样），这一点和RSA的签名不同，两个大数的验证算法和RSA不同，这也是为什么DSA不能用来做加密的原因。验证签名命令`openssl dgst -verify dsapub.pem -sha1 -signature sign.dat yourfile`，通过会显示Verified OK，反之显示Verified Failure。\\n\\nDSA的密钥强度标准和RSA是一样的，都推荐2048bit。\\n\\n## EC椭圆曲线\\n\\n共有三种用法\\n\\n1. Elliptic Curve DSA，用椭圆曲线做DSA，数字签名。\\n2. ECDH，用椭圆曲线做密钥交换。\\n3. ECIES，椭圆曲线的公钥加密。\\n\\nOpenssl的命令行工具支持前两种，并内建若干条曲线，比如下载的libressl自带了90条曲线，选好曲线的名字如secp256k1，则参数值（prime/A/B/Generator/Order/Cofactor）就确定了。曲线有prime域和binary域两种。域会有位宽，通过openssl的ecparam生成的参数长度和位宽正相关，但并不严格地成线性关系。\\n\\n使用椭圆曲线和DSA类似，也必须要两个步骤。先确定一条曲线参数，基于这条曲线参数生成公私钥。但Openssl的命令行没有genec指令，都是ecparam指令。\\n\\n1. 首先用`openssl ecparam -name secp256k1 -out secp256k1.pem`先生成一条曲线参数，生成的参数文件内容只有8字节（Base64后12字节）。如果直接用`openssl ecparam -text -noout`只能看到ASN1 OID: secp256k1描述，需要再加上`-param_enc explicit`参数，就能看到域类型和曲线的A/B值等很多值。前面提到了因为曲线描述一旦确定，则所有参数就确定了，所以这些参数我理解，并不是保存在参数文件，而是硬编码在Openssl内。所以8字节的参数文件看上去就有很多输出了。但是这样会有兼容性问题，因为具体的参数硬编码在Openssl程序内，那么高版本程序新加入的曲线，在低版本就会出现无法解析的错误。要避免这种情况，可以通过生成时加上`-param_enc explicit`，这样生成的曲线文件就会大很多，也完整很多。\\n\\n2. 有了参数文件，就可以生成私钥了，命令`openssl ecparam -genkey -in secp256k1.pem -out key256k1.pem`。同样的，要避免高版本和低版本的配套问题，加入`-param_enc explicit`参数就可以了。其实这步和上一步合并也没有问题。通过私钥文件生成公钥的命令是`openssl ec -pubout`，和DSA一样，`-pubout`在帮助中看不到。\\n\\n使用椭圆曲线进行签名和验证和DSA类似（但不确定是否就是ECDSA），签名`openssl dgst -sha1 -sign eckey.pem -out ecsign.dat yourfile`，验证`openssl dgst -sha1 -verify ecpub.pem -signature ecsign.dat yourfile`。选用secp256k1曲线的签名结果是71字节以DER编码的文件。简单说明一下：\\n\\n首字节是0x30，第二个字节是0x45，十进制69表示该字节之后的文件长度，69\\\\+2=71能够和文件总长度对上。第三个字节固定是0x02。第四字节0x21表示R的长度，偏移33字节后又是0x02，后一字节0x20表示S的长度，到此文件结束。不过没搞明白的是通过程序看到的R和S长度一样，为什么保存到文件R和S长度就不一样了。\\n\\n最后说下椭圆曲线的操作是点在操作，计算用加法，计算结果判断是否无限或在曲线上。\\n\\n椭圆曲线的操作体现在C函数的接口，则是`EC_KEY`和`EC_GROUP`这两个重要的概念。一条选定参数的曲线就是一个group，用`EC_GROUP_new_by_curve_name`获取一个group，从头文件找枚举代表一种算法。\\n用`EC_KEY_new`创建新的key，这样的key虽然名字叫key但只是个空的容器，必须先和group关联。当然也可以用`EC_KEY_new_by_curve_name`一步生成绑定好的key。\\n\\nkey和group有了关联之后，才能调用`EC_KEY_generate_key`生成公私钥。私钥是个很大的素数，在OpenSSL表现为BIGNUM类型，可以用`BN_print`看结果。公钥则是点，是`EC_POINT`类型，这个类型不开放，所以不能直接打印，如果看源码，POINT内部包含了X和Y两个BIGNUM（其实还有个Z也是BIGNUM，但不确定有什么用）。比如secp256k1的私钥是256bit的数(并不要求是素数)，公钥是形如(X, Y)的点对，计算方式是\\n>Q(x,y) = K * G(x,y)\\n\\nK就是256bit的大数，G随着椭圆曲线的确定是惟一确定的，对应ecparam的G参数。X和Y也都是256bit，所以公钥是512bit。比特币看不出来，但ETC的钱包采用的是HEX编码，容易看出pubKey的长度是privKey的两倍。\\n\\n虽然公钥保存成512bit没有错，但其实忽略了椭圆曲线一个重要特性**对称性**。来看椭圆曲线的公式：\\n>Y^2 = X^3 + aX + b\\n\\n只要知道公钥点的X，公钥点的Y就能通过开平方计算出来，只要再配合正负号，就可以知道完整的公钥点了。这个发现就是**压缩公钥格式**的来历，严格地说并不是压缩，只是去掉了一半冗余信息。甚至有人开玩笑地说中本聪不是密码学出身，否则怎么会一开始想不到要使用压缩公钥这种形式。\\n\\n私钥生成后就可以做签名和验证了。不同算法sign得出结果的长度从`ECDSA_size`获取，从48到153字节不一而足。ECDSA签名的结果同样是两个大数R和S，且位数一样。R和S的长度取决于算法，范围跨越20到71，因此把这个范围乘以2，再转成DER编码，就和前面提到的48~153能关联起来了。\\n\\n用椭圆曲线做密钥交换，即ECDH也很方便，BitShares的加密通信就是ECDH\\\\+AES，ECDH的流程比较简单，A和B各自持有一对椭圆曲线的公私钥，交换公钥后，再用自己的私钥乘对方的公钥，得到的结果就可以用来做AES密钥。比DH的流程要容易理解。"}'));jctx.push(JSON.parse('{"id": "170818", "tag": "lang", "text": "# 如何在struct里追加指针\\n\\n这在其它公司或开源项目没有什么用，但至少在我目前的工作上还是有一定价值的。想象一下不同的部门共用同一份头文件，头文件中复杂的类型只能用结构体。如果要在结构体增加任何元素，都要保证结构体长度不变。对char或是int32问题不大，指针在不同平台长度是不一样的，如果一个部门用32位编译，增加指针，试问要怎么减长度才能保证在64位平台长度不变？曾经考虑过32位平台加宏，在指针后面带一个int32并用宏控制，但是想找到各种平台都能识别的宏很困难。\\n\\n先说思路，既然要保证32位和64位相等，肯定是向上取长度，即让指针占据8字节，有三种做法：\\n\\n1. 把指针和int64用union包裹起来放到结构体里，如下\\n<pre>\\n    struct {\\n        int elem1;\\n        int elem2;\\n        union {\\n            char* p;\\n            int64_t placeholder;\\n        }u;\\n    };\\n</pre>\\n\\n这样做不好的地方在于取指针p必须要多一重u，使用者会感觉不方便。\\n\\n2. 既然用union看起来别扭用着也不方便，让struct强制以8字节对齐，然后把指针放在8字节位置，同时指针后面的元素必须是int64/double，这样32位系统下，指针后面会有4字节的隐藏字节，但也不能用，64位就是按8字节对齐的。缺点是指针后面的元素必须是8字节，有时会很浪费。如下\\n<pre>\\n    struct {\\n        int elem1;\\n        int elem2;\\n        char* p;      /// 32位系统，p后面有4字节空间，但不要使用\\n        int64_t ensureAlignBy8;\\n    };\\n</pre>\\n\\n3. 定义一个占位宏，根据系统特性将宏展开成int32_t或是空语句，也是最终我决定采用的方式，宏类似这样\\n<pre>\\n#ifdef (_WIN64)\\n#define POINTER_ALIGN8(n)\\n#elif (_WIN32)\\n#define POINTER_ALIGN8(n) int32_t unused##n;\\n</pre>\\n\\n这里有个小坑，宏的展开必须包含`;`，我最初的实现是宏的调用尾部加分号，过了几个月有人向我反馈编译不过。原因是VC在编译C语言模式(即.c后缀)时，要求结构体的定义中不能出现一行单独的`;`，但是在执行块中可以这么用。VC编译`C++`模式或GCC都没有这个限制。当我遇到这个错误时，曾尝试通过将64位下的宏扩展为一个空结构体，VC会报C标准不允许结构体没有成员。"}'));jctx.push(JSON.parse('{"id": "170820", "tag": "net", "text": "# libuv代码走读\\n\\n虽然并不提供Makefile，但通过CMake的脚本很容易就把要编译的文件找到，编译宏只有两个。\\n\\nuv的核心是loop，加上两个父级的抽象类型，handle和request。uv支持的18种句柄都是`uv_handle_t`或其子类。句柄派生出3个层级，如果只关心网络的读写，主要看`uv_stream_t`及衍生出的tcp，pipe,tty。从tcp的定义能很清晰地看出3层关系。\\n```\\nstruct uv_tcp_s {\\n  UV_HANDLE_FIELDS\\n  UV_STREAM_FIELDS\\n  UV_TCP_PRIVATE_FIELDS\\n};\\n```\\n\\nuv库多数接口都是非阻塞的，阻塞有`uv_run`，`uv_thread_join`，`uv_sem_wait`，`uv_rwlock_wrlock`等，线程类的好理解，但是文档并没有说run要阻塞多久。自己的测试结果来看，如果没有任何操作下执行run会立刻结束，如果在run之前执行一个内网连接并发送读取数据，大约会阻塞几毫秒。\\n\\n看`uv_run`的代码，最核心的数据loop里包含一个`uv_handle`的最小堆，run的时候每次从堆中取出顶点并执行。这就解释了如果一开始就执行run，因为堆中没有数据就立刻返回，如果有一个handle，则等待这个处理完成，run就结束了。\\n\\n因为`uv_run`的这种特性，必须要在执行它之前将所有会用到的句柄注册到loop，回调并不神秘，所有的接口如果允许传入回调函数，这个回调函数都会注册到loop中，并在符合条件时被触发。以TCP客户端为例说一下：\\n\\n传统上socket的connect操作如果用阻塞模式，执行时间是无法预期的。uv封装后的函数是`uv_tcp_connect`，最后一个参数是函数指针`uv_connect_cb`。这个指针就会先注册到loop，再尝试发起连接，直到connect成功或失败，这个回调就被执行。但这个回调只能被执行一次，显然我们肯定希望这个tcp连接收到数据就能持续地被回调，就要在`uv_connect_cb`的实现里注册一个读回调，函数名是`uv_read_start`，最后一个参数也是回调，这个回调会常驻loop，一旦有数据就能执行回调。除非显式地调用`uv_read_stop`。这两个函数没有tcp字样，原因是uv中把tcp/pipe/tty抽象成了`uv_stream_t`类型。\\n\\nstream的读写包含`uv_read_start`，`uv_read_stop`，`uv_write`。既然是读写，必然涉及`uv_buf_t`。读有两个回调，第一个回调是让用户分配buf空间，分配的大小是写死的！tcp和udp是65536，tty是8192或1024，只有pipe是运行中决定。当空间创建后，再把这块buf用来recv，把读出的数据写进去后，触发第二个回调。所以这两个每个都必不可少，且回调间有严格的时序关系。\\n\\n做到这一步还有个问题，此时流程已经运行到`uv_run`且已经阻塞住了，没法输入数据，这时就要用上三个并列的很有用的类型，idle/prepare/check，这三个实现代码很巧妙，用宏的方式定义，并通过传参的方式复制了三遍，第一次我用常规方式搜索代码无果，才发现是用了宏展开方式来实现的。\\n\\n三者和具体的业务态在loop的执行顺序是idle -> prepare -> specific poll -> check。由此可知poll执行前后会被调用，作一些校验和保证，类似Effiel的前验和后验概念。这三者都是寄生形态，如果没有tcp之类的事件，单独的idle不能永续存在。\\n\\nuv内部两个核心也是仅有的数据结构:heap和queue。heap查找最小值(似乎只用于timer)，queue遍历(loop, threadpool, pipe会用到)。实现得简洁干净，值得一读。\\n\\nuv的缓存`uv_buf_t`采用了和各自平台一致的定义方式，unix下是iovec，windows下则是WSABUF。因为内部实现时，如果buf数量大于1时会调用writev来替代write，所以参照iovec/WSABUF的定义就不奇怪了。\\n\\n`uv_run`返回之后要用`uv_loop_close`把loop关掉。和demo上演示得不同，这个函数不一定返回成功，就是说可能释放是失败的。释放包括iocp,timer,以及前面提到的idle,prepare,check句柄。\\n\\n说说线程库，创建用`int uv_thread_create`，返回成功与否，参数有3个，分别是tid，cbfunc,ud。调用之后要用`uv_thread_join`，内部实现是调用WaitForSingleObject。"}'));jctx.push(JSON.parse('{"id": "170822", "tag": "net", "text": "# 【翻译】select的历史和epoll的不足\\n\\n## 5种IO模型\\n\\n1. 阻塞IO\\n2. 非阻塞IO\\n3. 多路复用\\n4. 信号驱动\\n5. 异步IO\\n\\n阻塞IO不提，非阻塞IO只是减少了从请求发出到真正开始读的时间，但把数据从内核读到应用层，仍然会阻塞进程，只有异步IO才是完完全全的，从请求发出到得到数据的过程，应用侧完全感知不到，最典型的就是windows的IOCP了。据说Java的模型只用到了多路复用模型，IOCP无用武之地，所以为了跨平台考虑，还是Linux的epoll更好，如果到windows平台只能降级到select模型。但是不明白.Net怎么在Linux下实现异步IO模型？\\n\\n要谈多路复用，就要对Unix进行一次考古。\\n\\n诞生于1960年代中期的分时复用理念，相对于当时的批处理模式(batch-processing)，可谓是巨大的革新。而Unix是1970年才有的，因此它也要面对并试图解决批处理模式的问题。\\n此时Unix面临的阻塞有3种，CPU、磁盘IO、用户输入。\\n\\n接着谈谈pipe，此时并没有通用的进程间消息机制，也没有semaphore，pipe足以解决当时的问题。因为在3BSD的时候，每个进行只允许最多20个FD，每个用户最多只有20个进程，这种限定下确实不需要IPC和IO复用。同时正是这个限制，也导致了为什么select的接口参数`fd_set`会设计成一个长数组(在当时却并不长)。\\n\\n## TCP/IP诞生\\n\\n1983年诞生的4.2BSD引入了早期版本的TCP/IP协议栈和BSD socket API，虽然在今天看来似乎是理所当然的，其实当时还有一套System V Revision 3的STREAMS接口作为竞争者(现在已经没有人用了)。BSD socket API同时带来了select。\\n\\n同样的1983年，Rob Pike为Unix 8th Edition开发了Blit，一个图形化的终端。由于当时的BSD并没有类似System V的IPC机制，要实现Blit需要select来实现console的多路复用。\\n此处作者向Kirk McKusick求证了select的历史，非阻塞IO和select是同一时间出现的，但非阻塞并不好用，因此select成了最自然的选择。\\n\\n早期的Unix没有select，是因为当时只能做文件操作，而网络的出现也必然导致select的诞生。\\n\\n有4种避免阻塞的方式\\n\\n1. 非阻塞IO模式\\n2. 使用signal，即SIGIO，Linux上用`fcntl(F_SETSIG)`\\n3. 由系统提供接口，告知哪个FD可读写，select/epoll\\n4. 进程告诉系统，对哪些FD感兴趣，并注册回调，kqueue/IOCP\\n\\n三大平台IO复用的时间，依次是windows在1994年加入了IOCP，FreeBSD在2000年6月引入kqueue，Linux最晚，2002年引入epoll。\\n\\nBryan Cantrill(Joyent)曾猛烈地抨击epoll，提到两个缺陷，在Solaris系统的/dev/poll模型下存在惊群问题，而epoll的语义和/dev/poll很接近，因此也同样存在惊群问题。但是IOCP和kqueue的接口语义和epoll很不一样，似乎这样不容易引起惊群问题。\\n另一个问题则是epoll在应用层的语义是整形的fd，但内部实现却是内核对象，两者不一致导致在一些边缘场景下会出现奇怪的问题。\\n\\n惊群问题直到内核4.5版本，epoll加入了EPOLLEXCLUSIVE才得以解决，这就限制了epoll在多线程环境的运用。其实如果一开始就设计得好，是不会出现上述两个问题的。这也是要批评epoll的原因。\\n\\n先说惊群的问题，多线程使用epoll的典型场景是HTTP 1.0的短连接模型，很自然的会希望利用多CPU来均衡负载，但却做不到。\\n\\n## 电平触发 - 不必要的唤醒\\n\\n这种模式epoll和select的语义都会引发惊群问题\\n\\n1. 内核收到新的连接\\n2. 唤醒线程A和B\\n3. 线程A和B都结束`epoll_wait`\\n4. 线程A能成功的accept，但B会EAGAIN失败(或者反过来，总之只有一个成功)\\n\\n## 边沿触发 - 不必要的唤醒且饿死\\n\\n第一种没看懂\\n\\n第二种，达不到负载均衡效果\\n\\n1. 内核收到两个连接，同时有两个线程A和B，由于是边沿触发，只有一个线程被唤醒，假定A\\n2. 线程A结束`epoll_wait`且accept成功\\n3. 内核收到第三个连接，但是socket状态从readable到readable，因为是边沿触发，所以内核不会发起调度！\\n4. 线程A必须accept，期望EAGAIN，但是又得到一个socket\\n5. 内核收到第四个连接，线程A必须accept，期望EAGAIN，但又得到一个socket\\n\\n以上过程中socket只发生了一次从non-readable到readable的切换，因此内核只唤醒一次，导致永远在线程A。\\n\\n正确的解决办法\\n\\n有两种，最好的方式是用电平触发并加上EPOLLEXCLUSIVE标志(必须4.5内核后)，或者用边沿模式配合EPOLLONESHOT\\n\\n1. 内核收到两个连接，线程A和B在等待，由于边沿模式只触发一次，假定线程A被唤醒\\n2. 结束`epoll_wait`并调用accept，成功\\n3. 线程A执行`epoll_ctl(EPOLL_CTL_MOD)`，由于会重置EPOLLONESHOT标志，得以re-arm这个socket\\n\\n结论就是你必须理解EPOLLONESHOT和EPOLLEXCLUSIVE(还得内核足够新)。\\n\\n说下kqueue的接口语义和epoll的差异：\\n\\nepoll和kqueue都会创建一个监听句柄，但是epoll是直接把多个FD放入这个epoll句柄中，但是kqueue却多引入了一个kevent结构，FD通过kevent接口(是的，同名的)和kevent实例以及读写、添加删除等动作先关联，再将这样的一个或多个kevent放入kqueue中。FD和监听句柄中隔了一层。"}'));jctx.push(JSON.parse('{"id": "170829", "tag": "protocol", "text": "# Bitcoin中三种哈希的区别与关联\\n\\n区块链的不可篡改性是基于哈希函数的特性，Bitcoin中有3个地方用到了哈希的特性(都是SHA256)，分别是区块的哈希、区块的merkler树的哈希、每个交易的哈希。\\n\\n比特币实现区块链的数组结构比较简单，区块构成单向链表，区块结构的整体概貌：\\n<pre>\\nstruct Block {\\n  uint32 blockSize;\\n  struct BlockMeta; //80 bytes\\n  varint transactionCount;\\n  struct Transaction* transaction;\\n};\\n</pre>\\n每个区块含有一到N个交易，是个可变长结构，但不能无限增大，目前代码中人为地把区块大小限制在1M(分叉的BCC是8M)。这里还看不出哈希，接下来看看BlockMeta，这里面包含了两个Hash。\\n\\n<pre>\\nstruct BlockMeta {\\n  uint32 version;  // 最初是1，12年11月更新到2，最晚在17年已更新到0x20000002(隔离见证BIP141)，还有些0x20000012(BIP141和BIP91)。\\n  uint256 parentHash;// 指向前一个区块，以0x000000开头(至少八个0，工作量证明)，Genesis块这个位置全为0。\\n  uint256 merklerRoot;// 该块中所有交易通过构造merkler树生成的计算和，DoubleSHA256。\\n  uint32 timestamp;\\n  uint32 difficulty;//每2016块重新计算一次，早期都是1，直到第16个更新周期，即高度32256时第一次变化到1.18，后面一直在增加\\n  uint32 nonce;\\n};\\n</pre>\\nparentHash是把区块形成区块链的关键字段，计算这个Hash值异常困难，需要数亿次(甚至更多)地变换nonce值，进而使算出的Hash值小于difficulty。这也构成了Bitcoin共识机制PoW的基础，谁能算出这个值，网络上所有节点就承认TA挖到了这个块，从而获得了coinbase的奖励。但是区块并不保存自身的Hash值，因为一旦尝试出了nonce使得本区块符合链的条件，只要向全网广播这个刚算出的区块，其它所有看到这个广播的矿工都会保存这个区块的哈希。\\n\\nmerklerRoot也是SHA256，不过这个计算就没区块哈希这么变态了。区块只是个容器，重要的还是其中的交易，merkler树就是记录所有交易生成的摘要，使得不论多少笔交易，都只需要很少且恒定的数据，就能证明交易的存在。它也是SPV的验证基础，这部分内容还没看明白，以后再补充。如果区块只包含一笔交易(即coinbase交易)，merklerRoot就等于这个coinbase交易的ID(哈希)，如果有两笔以上交易ID，则两两作字符串拼接，并通过Double SHA256反复循环直到算出根值。\\n\\n每笔交易都是可变长结构，包含的输入和输入数量至少为1，无上限。\\n<pre>\\nstruct Transaction {\\n  uint32 version;\\n  varint tx_in;\\n  void* in;\\n  varint tx_out;\\n  void* out;\\n  uint32 locktime;  // 0指立即执行，1~5亿指到这个区块高度为止，5亿以上指时间戳(但4字节能表示的时间范围有限，难道不是问题吗？)\\n};\\n</pre>\\n\\n交易结构并不包含哈希，只有输入才包含哈希。\\n<pre>\\nstruct tx_in {\\n    uint256 pre_txhash;   //指向前一个交易的哈希\\n    uint32 pre_txout_index;// 定位到该交易的第几个output，必须是UTXO，否则会因余额不足而校验失败。\\n    varint scriptLen;\\n    void* script;    // 解锁脚本,signature+pubkey\\n    uint32 sequence;\\n};\\n\\nstruct tx_out{\\n    uint64 value;\\n    varint scriptLen;\\n    void* script;  // 锁定脚本\\n};\\n</pre>\\n由于Bitcoin没有账户的概念，只有UTXO，可以理解成一张支票吧。如果想交易，即证明有合法的input，就要向前找到一个或多个可用(未花费)的output，输入的哈希就用于寻找这个output。但交易可能不止一个output，所以还需要index来标识是第几个output，有了这两个值，就能惟一确定到UTXO，各节点也能验证余额是否足够。\\n\\n上面说了Bitcoin的结构，接下来对比下Bitshares的区块结构。Bitshares只有区块摘要的哈希算法用了SHA256，而区块ID、交易ID和MerklerRoot用的都是RIPEMD160。计算Merkler时的策略也有细微不同，Bitcoin在计算奇数个叶子节点时，会把最后一个节点复制一份，且每两个叶节点在向上计算上一级摘要用的是Double SHA256；而BitShares是直接把最后一个孤立节点放到下一轮计算，只用了Single SHA256，少了一半计算量。"}'));jctx.push(JSON.parse('{"id": "170831", "tag": "security", "text": "# SHA家族的哈希算法\\n\\n由于MD5早就被证明存在碰撞攻击，安全性在严肃场合肯定是不够的，SHA-1(160bit)作为替代品已被越来越多的观点认可，但是MD5有一个理论上的优点，计算长度无上限，而SHA家族的长度会限定在2^64-1或2^128-1内。SHA是一个很大的哈希算法家族，到目前共有0、1、2、3这四类。\\n\\n* SHA-0：这个很少提及，原因是MD5被成功碰撞后，几乎同时SHA-0也被碰撞，所以没有实际应用\\n* SHA-1：只有SHA160一种，不过目前在理论会产生碰撞，17年初Google发了paper声称找到了碰撞方法，git在计算对象摘要时用了SHA-1，但git用它作为完整性校验，并不在意碰撞。\\n* SHA-2：共有SHA-224/SHA-256/SHA-384/SHA-256这四种细分类型，224和384分别是256和512的截短版本，至少我还没有看到可靠的质疑的消息，Bitcoin计算交易哈希、MerklerRoot时，用的就是SHA-256算法\\n* SHA-3：虽然SHA-2没有明确的证据证明不安全，但NIST(美国国家标准技术研究所，也发布AES、若干种椭圆曲线等其它加密技术)还是未雨绸缪地于2007年开始征集新的下一代密码Hash算法，最终在2012年10月2日，Keccak被选为NIST竞赛的胜利者，对外称为SHA-3，Keccak和SHA-2在设计上存在极大差别(海绵结构 VS Merkle-Damgard)，支持256，384，512多种长度的输出。以太坊出现时间在SHA-3之后，用的是SHA-3算法\\n\\n## HMAC与HASH\\n\\nGo语言规整地把计算HASH的方法统一定义成hash.Hash接口，hmac.New(hash.Hash, []byte) hash.Hash。可以任意组合，不需要为每种HMAC增加特定方法。"}'));jctx.push(JSON.parse('{"id": "170905", "tag": "lang", "text": "# 给应届生出题看指针的易错点\\n\\n上周领到给18届毕业生出题目，我被分到OS方面的基本题和两道编程题，基本题不能简单考能查到的题目，最后出了几个Linux偏操作的题目。两道编程题中有一题，在自己实现时遇到了两个指针方面易错点。\\n\\n题目是这样：N个人排队，每个人都有个编号（数字），要求排序后让这些编号连在一起之后组成的那个整数最小\\n比如 14  78  132  56  8，排列后的顺序是132 14 56 78 8。这道题目难点并不在排序算法，主要是看能不能读懂排序比较函数，比较两个字符串，首字母小的认为小，如果前N个字母一样，先结束的认为小。\\n\\n我在提供标准答案时，直接用C语言的qsort函数，原型是这样 `void qsort( void *buf, size_t num, size_t size, int (*compare)(const void *, const void *) );`\\n\\n第一个参数显然要对数组排序，因此排序`*`后，void就要换成元素的真实类型，比如这道题目是`char*`，第二、三元素很好理解，重点在第四个函数指针的原型，刚才已经分析过，真实元素类型是void，对比函数原型是`void*`，说明函数参数要多一重指针，即`char*`传到比较函数时时`char**`，这个开始没发觉，反复调试并才意识到错误。\\n\\n再就是比较函数，这道题是比单个字符，如果两个字符串是`char *p1, *p2`，开始我用了`p1-p2`，并误以为是字符串首字母比较，其实从类型看到，相减的是`char*`即指针地址，这样比较结果不会影响数组排序，原因就是比较指针地址当然不可能影响排序，所以比较要用`*p1-*p2`才能得到想要的结果。"}'));jctx.push(JSON.parse('{"id": "170908", "tag": "lang", "text": "# 面向对象中的类与应用场景\\n\\n记得我刚学`C++`的时候，第一眼记住的特性就是引入了class关键字，但是由于一直以来的工作，更多是以C语言为主，自己编码也很少用到类，只能把我的理解记录下来，希望未来能有更好的认识。\\n\\n程序的基本元素是数据和函数，类的出现意味着数据和函数的绑定，类的构造函数会产生对象，而所有同一个类的对象共同持有相同的函数，即只有数据是对象的核心，面向对象就是面向数据的风格，从编码上看，数据拥有了自己的行为，这种方式很符合人的思维习惯，或者说面向对象就是以数据为轴心的思考方式，一个对象就是一个状态机，随着行为而不停地引起内在数据(状态)的变迁。类的特性一旦确定，那么适用于围绕数据的场合，就适合按类建模。但是以数据为中心，在并发环境下一定会遇到锁的问题，很难做到并发。\\n\\n来到数据的另一边，以函数为主体，数据只是构建结果的一部分，并不是核心要素，比如统计学等需要大量数据的情况下，如果围绕最终数据结果，可以是对象，但过程中那些海量的数据，并不适合作为对象来理解。\\n\\n映射到比特币和以太坊，似乎正是这两种思维的差异。以太坊的账户体系是典型的面向对象思维，每个人都有各自的账户，并针对账户操作，是集中式的。而比特并没有一个归总的数据，全是分散在各处的UTXO，每次UTXO操作完，就生成新的UTXO，以交易(操作为中心)，数据只是附带的产出物。\\n\\n是否类就是面向对象的惟一呢？由于`C++`/Java这些面向对象语言非常流行，导致绝大多数人把类和OO合一，从分类角度看，面向对象至少分为class-based和object-based两大类(其实还有些小的分类，还不熟悉先不介绍)。目前主流语言中最有名的object-based的是JavaScript，千万不要因为ES6导入了class关键字就认为JavaScript是class-based语言，它的核心仍然是object-based语言。更准确的说JavaScript是object-based分类中的prototype这个分类，还有一种称为closure的分类。\\n\\nprototype类型下又细分了embed和delegate两种，它们之间的区别是method的存储模型，把method放在对象内的，称为embed，而存储在对象外，用到的时候临时去找的方式，就是delegate了。"}'));jctx.push(JSON.parse('{"id": "170914", "tag": "lang", "text": "# C语言的类型长度\\n\\n## long类型该多长\\n\\nC语言的规范没有规定long必须是多长，只要求不小于int就可以。从我看到的情况int都是4字节，但long就有32/64两种长度。典型的像VC把long当成32字节，而Linux的GCC则把long当成64字节。\\n\\n造成这个差异的根本原因其实并不是编译器，因为今天意外地发现GCC在windows平台上是把long当成32字节，说明long长度不仅仅和编译器相关，那么为什么windows的long会是32字节呢？\\n\\n恰好昨天提交一个头文件，修改结构体定义BITMAPINFOHEADER中四个long类型为uint32，我查了下BITMAP的要求，明确说MUST BE 40bytes。但是这个结构体有10个字段，6个INT和4个LONG，而这个定义又是抄自windows.h的定义，说明当时在微软定义头文件的这个哥们就是把LONG当成UINT来用。没有看过所有头文件，也许那时所有人都认为32位已经足够用了。然而时至今日出现了64位，如果这时把LONG定义成64位，BITMAP头文件就不能和真实的文件匹配上了，必须让LONG保留32位，而且不仅微软自家编译器，是所有跑在windows平台的编译器都必须按32位来对待long。在Linux平台没有和文件格式强绑定的头文件定义，因此GCC就把long当成64位来处理了。\\n\\n由此可见头文件的定义，一旦落了地影响就无比深远，远到当初定下这个结构的人，都不曾预料到会演变成今天的情景。\\n\\n## int类型该多长\\n\\n历史上，不是所有计算机都是一个字节 8 个 bit 的。只是由于一系列优势 (比如刚好能容纳下 ASCII 码 + 1 位校验位)，所以 8 bit 的计算机成功吃鸡，成为了今天最常见的架构。\\n\\n如果你仔细的话，会发现 C 语言标准头文件 <limits.h> 中规定了一个宏 CHAR_BIT，用以表示字节位数。这个宏就像历史文物一样向今天的我们诉说历史的沧桑。我们今天写代码时，如果要计算一个 int 有几位，三流程序员可能直接返回 32。但是大家都知道，直接返回 32 的代码，没有考虑到标准中并没有承诺 int 就是 4 个字节，所以兼容性是要大打折扣的。一般人会返回 sizeof(int) * 8，但是这同样有问题。正如上面所说，不是所有计算机都是一个字节 8 位。所以正解应当是 sizeof(int) * CHAR_BIT。尽管在今天，99.99% 的情况下 CHAR_BIT 被 define 为了 8，但在有些特殊领域，仍要考虑到非 8 位的特殊情况。\\n\\n了解了这些，站在当年的角度思考这个问题，有些机器的硬件，是没法原生支持 int8_t, int16_t 等等的 (因为它们的整型位数就不是 8 的整数倍)。更别提就算是 8 的整数倍的 16 位的计算机都没法原生支持 int32_t, int64_t (超过它们的最大字节数了)。\\n\\nPDP-10，后期命名为 DECSystem 10 的字长是 36 位，字节是 9 位，一个机器字内可以有许多种不同的打包（Packing）方式，这机器的一个 CHAR_BIT 就是 9。\\n\\n对于 PDP-10 存储字符，还有其他的打包方式：\\n\\n* 六个 DEC Radix-50 字符打包进 32 位中，剩下 4 位留空\\n* 六个 6 位的字符（DEC SixBit，ASCII 0x20——0x5F 这一段）\\n* 五个 7 位 ASCII，1 位留空\\n* 四个 9 位字符（Multics 约定）\\n"}'));jctx.push(JSON.parse('{"id": "170920", "tag": "os", "text": "# 动态链接库与符号表\\n\\n起因是前天向吴惠敏请教gprofile的时候，这个工具要用.a库，不要用.so否则程序会挂掉，原因是gprofile的设计思想在20年前就已固化，而动态加载的重定位细节又经常变化，所以干脆gprofile就只支持静态库了。本篇不说gprofile，单说说动态链接库。内容并不会超出《程序员的自我修养》这本书，更多的还是个读书和操作记录。\\n\\n现在的Linux默认都用动态库，比如我最常用的CentOS，/lib/目录下几乎看不见.a库，gcc默认也找的是动态库(真实选项-Bdynamic)，除非用-static选项告诉ld只用静态库。(不过MinGW的gcc即使用了-Bdynamic，在静态和动态都存在的情况下依然会用静态库，原因不详)\\n\\n加载动态库是一段专门的程序，它和系统用的C语言库强关联，在不同的系统表现形式也不一样\\n\\n* CentOS(也是绝大多数Linux)：/lib/ld-2.xx.so 和 /lib/ld-linux-xx.so.2\\n* Alphine(一个轻量级的Linux)：因为库体积的原因，使用了musl这个C库(libc.musl-xxx.so)，动态加载库和libc是合二为一都指向/lib/ld-musl-xxx.so.1\\n* Aboriginal(一个更轻量的Linux)：使用uClibc库，动态链接/lib/ld-uClibc.so.0，从版本号看，libc、libm、libdl、libnsl、librt、libpthread、libcrypt、libresolv、libutil都在uClibc库的范围内\\n* FreeBSD：/libexec/ld-elf.so\\n* OpenBSD：/usr/libexec/ld.so\\n\\n其实Cent下ld-linux只是个指向ld.so的软链接，只是因为历史上ld.so处理a.out格式，ld-linux处理ELF格式，为了兼容名字一直保留到今天，其实程序是同一个。从FreeBSD的名字也可以看出，最初的名字叫ld.so，出现elf格式后，FreeBSD不再保留ld.so，全换成ld-elf.so了，但OpenBSD依然沿用。ld.so文件名在Linux中保留了版本号，我猜测这正是它和libc库强关联的证据，即根据编译时链接的libc库版本号，换算成对应的ld.so程序名，进而执行动态加载。\\n\\n动态加载必然涉及从遍历目录的过程，这必然涉及配置和更新目录集，虽然不同的系统配置名字不一样，Linux用ld.so.conf，而FreeBSD用libmap.conf，但最终都要通过ldconfig程序将配置转换成更高效率的格式，ldconfig和ldd最早都出现于SunOS 4.0，所以现在大家依然沿用这个名字。\\n\\n## 符号表\\n\\nso文件有.symtab和.dynsym两种符号表，dynsym看名字就知道是动态，而symtab是normal又称regular符号。用strip只能去掉symtab，但是dynsym不能被删。\\n\\nnm默认找symtab，如果被strip会提示no symbol，加-D能显示。objdump的-T是同样功能。\\n\\n## 动态库的版本规则\\n\\n使用GNU Autotools编译动态库会用到libtool工具，是对不同平台和编译器的封装，在编译前要指定三段式版本：current:revision:age。第一次发布时为0:0:0。这3个字段的变动规则是\\n\\n1. 只要源码有变动，revision加1\\n2. 如果是兼容性扩充，current和age加1，revision归0\\n3. 如果不兼容改动，current加1，age和revision归0\\n\\n最终生成的版本号：(current-age).age.revision\\n\\n编译出的动态库通常有3个文件\\n\\n1. libxx.so: 软链接，编译时用到\\n2. libxx.so.major: 软链接，运行时寻找so一般都会锁死major，这个值不匹配会报加载失败\\n3. libxx.so.major.age.fix: 按以上规则生成的完整版本号，age表示接口有过多少次兼容性增加，fix表示代码修改次数\\n\\n有时虽然major能匹配，但如果用到的是age更大的版本才加入的接口，虽然加载能成功，但运行过程中还是有可能报错。\\n"}'));jctx.push(JSON.parse('{"id": "171010", "tag": "lang", "text": "# 两个嵌入式JS引擎的介绍\\n\\n最近在开发一个协议转换工作，脚本决定使用JavaScript。JS的实现非常得多，除了浏览器里那些重型武器，还有非常多小型的实现版本，大多都实现了ES5.1的特性，这些之中我用了MuJS和Duktape，这两个接口风格和Lua很像，基于引擎按栈式操作，Duk速度比MuJS明显要快得多，也支持部分ES6的特性，但缺点就是接口也较多，掌握起来更难一些。以下逐一说明。\\n\\n我先用的是MuJS库，引擎类型是`js_State`完全和Lua一样，感觉是Lua出现后照着Lua的接口抄的，来看和C的交互接口(顺便对比Lua的定义)\\n\\n```\\ntypedef void (*js_CFunction)(js_State *J);\\ntypedef int (*lua_CFunction) (lua_State *L);\\n```\\n\\n惟一的差异在于不需要返回值，这个差异也是JS不支持multi-return导致的，规范(至少5.1)要求必须且只能返回一个值，在实现时哪怕没有值也要push undefined才能返回。(但是Duk有返回值，正文再述)\\n\\n再说说函数的执行，记得在call之前一定要压入this，这也是JS语言导致的，因为Function就是自带call/constructor方法的Object，执行后一定要记得弹出压入的返回值。\\n\\nMuJS在执行出错后直接abort非常不友好，因为abort会导致栈丢失，用GDB的bt无法追溯，这里我修改了jsrun.c改为exit，并在jsstate.c打印了调用栈，出了问题很容易回溯。\\n\\n它的值类型和Lua几乎一样，tag value风格，标记GC的字段。由于JS语言的特性，每个值对象还多出prototype和properties字段。以及配合ES5对象的extensible/seal/frozen特性的extensible字段。\\n\\nDuktape的函数声明和Lua一样\\n\\n`typedef duk_ret_t (*duk_c_function)(duk_context *ctx);`\\n\\n返回值有四种情况\\n\\n* 1 正常情况，向栈内压入一个值并返回\\n* 0 由Duk引擎自动压入undefined，感觉和1差别不大，不需要多此一举\\n* 小于0 相当于抛Error异常，并列举了几种Error的值。从完整性角度来看是有必要的，JS毕竟是门显式支持异常的语言，没有<0就强制剥夺了这个特性\\n* 大于1 预留，为了以后支持multi-return做的预留\\n\\n还是Duktape考虑得更全面。\\n\\nDuktape有多种编译脚本，比如命令行模式，会额外包含print, console, module, log共4个模块，因为这些接口在某些平台并不存在。甚至还有debug接口。\\n\\n## 和C语言的交互\\n\\n两种都是用了lua的语义，总体差不多。各种pushXXX和pop接口，但duk的接口比较冗余，比如pop竟然有4个接口，有`duk_pop_2`和`duk_pop_3`这样特化的接口，完全想不出有什么必要。\\n\\n在C语言执行JS函数也表现出duk的冗余，不仅区分了call和pcall，call还有自身,`call_method`和`call_prop`，后两个需要显示指定执行时的this，call没有指定，因此这个函数内了不要调用this。\\n\\n## 编码格式\\n\\njs标准规定字符串内部以Unicode保存，这两种实现都只支持外部输入UTF8，甚至外部输入带BOM的Unicode也会报转码失败，考虑到多语言编码的复杂性，可以接受。\\n\\n## MuJS裁剪\\n\\n首先Date和Math库是最没有依赖的，删除后完全不影响编译。\\n\\n接下来Regex就有点麻烦，因为gc中要释放regex，string的match,split,replace都依赖正则。\\n\\n删除URI相关的4个global函数。去掉ES5追加的extensible属性，大约300行代码左右，非核心。"}'));jctx.push(JSON.parse('{"id": "171110", "tag": "lang", "text": "# 比较词法分析和语法分析\\n\\n词法分析是一种单向的状态机。最简单的词法分析，只要不停的吞入字符并和状态表中的可选项进行匹配，并把匹配上的字符挑选出来就可以了。稍微复杂一点的则可以加入把匹配项里面的部分字符退回，但这个状态更多的像是一种人为的操纵，而不影响状态机的本质。另外在比较的时候有一个很简单的判断，就是称之为最长判断，但这种判断也不会造成过多的选择负担。\\n\\n由于输入的数据始终只有一种状态，所以不需要保存过去的数据，当然也不存在栈溢出问题。\\n\\n语法分析相比起来就要复杂很多，是一个带有栈的，且栈深度是可伸长的状态机。因为一个不带栈的语法分析器，比如LR(0)，能够分析的语法是非常少的。要想达到可用，至少要保存向前看的一个数据。另外归约时要根据向前看的数据进行选择，也要把一段时间内未归约的数据保存下来，这就需要栈，当归约的语法太复杂，或者歧义太多，保存在栈上的数据过多，就可能导致栈溢出的问题。\\n\\n从我查到的文献看，1965年的ACM就刊载了TMG compiler compiler语法分析文章，这个工具在70年代初移植到了最早版本的unix，但在用TMG给B语言扩展特性时却很困难，因此才基于LR解析理论重写了yacc（yet another就是针对TMG而言），并随着version 3 unix一起发布。而lex虽然更简单，但资源很少，只查到1975年lex论文发布（同年yacc论文也发表了）。由于年代久远，二者都是不可重入的。随着线程的出现就出现了可重入的需求，lex可以使用%option reentrant生成可重入代码，如果比较会发现和非重入版的代码差异极大，yacc也能生成可重入代码，而更新的语法生成工具如lemon，生成的都是可重入代码。"}'));jctx.push(JSON.parse('{"id": "171129", "tag": "data", "text": "# MySQL和Redis备忘\\n\\n## 连接与数据格式\\n\\nMySQL远程的访问，支持Unix的域套接字、Windows的共享内存和命名管道模式以及应用最广的TCP。TCP协议的首字节是版本号，官方文档可查最早是版本9，自3.21.0开始切换到10以后没再变过。这份协议格式符合GPL。\\n\\n连接要配置用户名(最多16个字符)，用`mysql -uxxx -pxxx`的方式登陆，注意`-u`和用户名中间没有空格，和一般的软件习惯有些不同。标准语句外，额外支持show,desc,use指令。\\n\\n数据格式比SQLite要细分得多，在SQLite里字符串就是TEXT类型，但MySQL的TEXT表示65535以内的字符串，如果需要更大的空间，要换成MEDIUMTEXT或LONGTEXT。编码支持多种，创建table时要注意指定，或者用`alter table xxx character set utf8`修改。varchar的长度只限制了取出，如果超过范围仍能写入，但取出会被截断。\\n\\n空有两种表示方法，NULL或者\'\'。在MySQL中，NULL会占用额外空间，MyISAM是1个bit，且不能被索引，所以关键字段如果用NULL会影响检索效率，而\'\'完全不占用空间。好比NULL是空气，看起来没有实则还是有的，\'\'是真空。用CHAR_LENGTH对这两种取值，NULL返回还是NULL，而\'\'返回是0。所以建议所有的字段都设置为NOT NULL。即使设置成NOT NULL，插入时如果不指定，CHAR默认是\'\'，而DATETIME默认是全0。\\n\\n## 数据存储\\n\\nMySQL的数据保存在datadir指定的目录（默认是data），生产部署时会把datadir指向单独分区，方便数据整盘迁移或调优。data目录的每个子目录对应一个数据库，因此数据库不能指定存储引擎，只有表需要引擎参数。\\n\\n不过把整个目录直接移到另一个MySQL，虽然可以看到这个目录和表，却不能进行操作，可能在其它地方还有记录库和表的关系吧，也因此迁移数据不能简单地移动文件。库目录一定有db.opt文件，通常用来指定创建新表用的character和collation。\\n\\n当第一次安装完成，会自带mysql目录，这个库里会有db/func/user等保存元信息的表。另有`information_schema`库，该库的机制是视图，所以没有外部文件。更高版本的MySQL还有`performance_schema`库，了解不深。\\n\\n### MyISAM引擎\\n\\n每张表对应3个文件，后缀分别是frm,MYD,MYI。\\n\\n* frm: 描述了表的结构\\n* MYD: 保存了表的数据记录，以行为单位记录数据，每写入一条数据，都会在文件大小上，精确到字节地反映出大小变化。\\n* MYI: 保存表的索引\\n\\n### Inno引擎\\n\\nwindows下，每张表有frm和ibd两个个文件存放数据（是否有ibd文件取决于 `innodb_file_per_table` 是否打开，低版本默认关闭就只能看到frm文件）。ibd在创建空表后就有96K，插入单条数据只能看到ibd文件时间有更新，但看不到大小变化，只有累积到一定数量（疑似16K）才会增长。和数据库目录平级的目录下，有ib_logfilex,ibdatax和若干个文件夹。ib文件记录了redo日志和inno引擎的事务消息。\\n\\n## 启动方式\\n\\n启动日志报各种奇怪的错，数据库不存在，InnoDB起不来。mariadb会默认装在/usr/var/lib/mysql/目录。\\n\\n1. 删掉三个文件：ibdata，ib_logfile0和1\\n2. mysql_install_db --user=mysql --basedir --ldata\\n\\n### mysqld_safe\\n\\n把my.cnf文件放到默认位置（通过mysqld --verbose --help查看），再执行mysqld就能启动监听，可能会报错，但似乎不影响执行。\\n\\n```\\n[mysqld]\\nuser = xx\\nbasedir = /pathto/mysql\\ndatadir = /pathto/mysql/data\\nport=3306\\nserver-id = 1\\n\\n[client-server]\\nsocket = /var/run/mysql.sock\\n```\\n\\n除了原始的mysqld命令，用safe脚本会多做以下几件事\\n\\n1. 从多个目录寻找mysqld，并配置额外参数（malloc、PRELOAD_LIB）\\n2. 对信号进行trap捕获，防止意外退出，配置日志目录\\n\\n### 用户机制\\n\\nuser表记录所有的用户密码和权限，似乎做了SHA1，另外MySQL5换过保存方式，不过手头没有版本4，也无从察看。因此安装包通常会告诉你初始密码是什么，否则没法登陆了。可以用mysqladmin工具修改密码，如果忘记密码就要让mysqld进行无授权模式启动，在my.ini的`[mysqld]`配置`skip-grant-tables`，这时就可以免密码登陆，然后再用`use mysql; update user set password=password(\'123456\') where user=\'root\' and host=\'localhost\';`语句修改mysql库的user表，退出后去掉免授权模式，重启mysqld就可以用新密码登陆了。\\n\\n要注意user表是host和user双字段联合主键，同样的用户名从不同地方登陆可以设置不同密码和权限。又比如常见的root用户不能远程登陆就是因为user表没有host为%的记录，不存在从任意主机连接过来的root用户，当然就会报错了。host是localhost代表unix socket，而127.0.0.1代表berkley socket。\\n\\n创建或修改用户密码\\n\\n使用`mysqld_safe --skip-grant-tables&`跳过检查（mariad的11.3不再支持），然后一定要`flush privileges;`，否则mariadb会报不能执行权限类操作。\\n\\n* mysql5.5: `update user set password=password(\'root\') where user=\'root\' and host = \'%\'; flush privileges;`\\n* mariadb: 从10.4版本开始，user表已变成视图，不能修改。要用`alter user user@\'%\' identified by \'user\'`，或者添加用户`create user user@\'%\' identified by \'user\'`。\\n\\n## binlog\\n\\n在项目中遇到数据库连接和表都在，但其中一张表的大量数据丢失，虽然到最后数据都没能恢复出来，但binlog和备份的重要性再一次刺激了我。\\n\\n命令行工具叫mysqlbinlog，但是变量命名是`log_bin`，因为日志除了bin，还有error、syslog等多种。binlog在主从同步时起关键作用，因此是数据库级别，不能针对某张表开启，因此binlog可以用 show master logs。\\n\\n最简单的用法：mysqlbinlog --no-defaults mysql-bin.00000x 就可以显示所有的执行日志。\\n\\n## 数据库备份\\n\\n* 备份整个库: mysqldump -h xx -uxx -pxx --databases db1 db2 > back.sql\\n* 备份表: mysqldump -h xx -uxx -pxx dbname tbl1 tbl2 > back.sql\\n\\n以上命令可以用--no-data方式只备份结构。除了表之外，默认只转储触发器，不会转储事件和过程，要加上-E(事件)或-R(过程)。视图无法导出，要备份视图定义的frm文件，导入后再次恢复。\\n\\n## Redis记录\\n\\n总计有1314099条时，占用内存近12G，平均下来一条9K，远超实际长度。设置 maxmemory防止无限增长。\\n\\n认证命令auth，不过只是一个很弱的安全措施。可以用config get requirepass查看。"}'));jctx.push(JSON.parse('{"id": "171201", "tag": "security", "text": "# 一个加密协议定义不仔细的教训\\n\\n前天下午NetSDK组反馈在AES加密时数据，客户端和服务端对正文的padding采用了不一样的加密方式，导致无法解密。当时就觉得很蹊跷明明已经调试通过的功能，为什么这么久了还报问题。昨天下午花了两个半小时才把问题解决，现在想来都觉得是我接手协议以来遇到最屈辱的一次遭遇。\\n\\nAES加密是一种块加密，当数据不足一个块时需要填充，和RSA不一样的是，填充内容都常不在算法实现，而是由构造加密数据的人来填充。换句话说AES的API并不体现padding参数，而RSA是明确地预留了padding参数并给出了5种宏定义，这也是当初定协议时遗漏的诱因。\\n\\n于是想当然地，AES加密时不足部分就填了0x00。可是服务端在实现时从安全产品线得到一份文档，要求采用PKCS7方式填充，但并没有同步给其他团队。为什么需要PKCS7这种方式呢？要从填0x00有什么缺陷来考虑。AES块加密的特性决定了加密后的内容长度一定是16的整数倍，但源数据往往不是16的整数倍，因此接收方得到数据并解密后，需要把最后的padding数据排除掉。如果源数据是字符串，使用0x00来padding没什么关系，都能正确地解析，但如果源数据是二进制数，还用0x00做padding就没法界定源数据的边界。解决的思路就让padding数据自表示哪些是无效的，比如在所有数据的最后一个字节，表示有多少是被padding出来的。举例来说，明文数据是120字节，加密后变成128，多了8字节，加密前就在在明文数据后补上8个字节的0x08（或者补上7个0x00和1个0x08），解密后根据最后的0x08就能丢弃无用的padding字段。\\n\\n说完原因再说问题，服务端按PKCS7方式处理数据，而客户端根据0x00填充，在源数据长度不是16整数倍的情况下，填充若干个0，而服务端又根据数据最后一个字节向前回退0个字节的偏移（这里处理不严谨，按PKCS7的定义不允许出现尾字节是0的情况，一定是0x01到0x10之间的某个数），由于是0相当于把整段数据交给上层应用。目前协议是用json传输，多几个0没有关系。但当原始数据是16的整数倍时，没有做padding，但是由于json库实现的一些瑕疵，会在最后的\'}\'后带上\'\\\\n\'即0x10，在这种情况下服务端把数据回退10，导致上层得到的json数据缺失无法解析。数据长度恰好是16整数倍是个随机概率，测试时也很难发现，导致事情过了3个月才暴露。\\n\\n整个事故反思下来，教训有三条\\n\\n1. 制定加密协议时遗留了细节，导致出现流程上的盲点，还是需要自己加强知识学习\\n2. 多部门间未同步到位，致使关键信息没有同步\\n3. 服务端实现时未考虑异常情况，不是根据收到数据包来解析数据，而是预设条件导致错误解析"}'));jctx.push(JSON.parse('{"id": "171205", "tag": "os", "text": "# 几个安卓ROM的体验报告\\n\\n因为手欠把flyme的stk.apk(SIM程序)删除之后，一直报com.android.phone停止运行，加上flyme用了两年也有些厌倦，TCL M2M这款机型各路网上爱好者做了很多ROM适配，故得以把几大主流厂商的ROM都体验一遍。机型为4.4，各ROM普遍是15年的版本，不新但能体验出很多差异。\\n\\nFlyme用得最久的系统，界面小清新风格比较对我的胃口，悬浮球是大特色，不过用起来总感觉会误触，还是关了。操作比较方便，各种UI设计都很赏心悦目(我的感受)，用得最久反而没什么想说的。\\n\\n锤子桌面，只用了桌面没有适配的ROM，桌面第一眼感觉很新鲜，很有设计感。九宫格布局但不能换壁纸只能换背景配色，用下来最大的不便就是非常耗内存，1G内存会经常出现回到桌面时要等待2到3秒的场景，2G的话会好很多，偶尔也会要等待不到1秒，可能3G内存会杜绝，但没有这样的手机，无法实测。操作上重于点选，对滑动支持很差，新鲜劲过去就不怎么样了。\\n\\n华为系统，EMUI桌面朴素得没法看，不知道算不算理工男的设计，总之和锤子桌面完全不具备可比性，系统功能也很理工化，但对我来说很贴心，各种流量控制、锁屏提示都很到位，内存管理不错，用了很久之后，清理任务后的内存占用和开机时是一样的，这点其它几个系统都做不到。\\n\\nOPPO的ColorOS系统，桌面中规中矩，最大的亮点是突出了音乐和拍照。桌面左划就是音乐界面，有个一键HiFi的按钮，开起后声场变大，没有具体的音效设置。打开相机甚至还有相机商店，可以下载自拍相机、慢动作相机等，不过我对相机不感兴趣，看看就好。设置界面划分成3个tab页，声音和显示各占一个，可以算是最日常的功能吧，这种划分对日常使用向的用户来说挺友好的。但开机时内存有1.1G剩余，用到后来不管怎么清理任务栏都只有700M左右的空余。一些小功能屏幕边角向中间划切换为单手模式，比如自带FTP方便的传数据，插入USB口后切换模式直接在通知栏完成，甚至可以选择仅照片模式，都是力求做到对普通用户友好。\\n\\nViVo的funtouchOS，我是和OPPO进行比较，毕竟这两个品牌的定位比较近似，但实际用下来总体感觉不如OPPO的思路清晰，系统设置的菜单做了些调整，但没有突出重点，把蓝牙藏得很深，也可能这是版本关系，至少从今年看蓝牙耳机非常普遍，因为做为一级菜单。开发者选项只能在拨号盘输入`*#*#7777#*#*`来临时打开一次，每次都要输入如此冗长的一段，不知道意图的是什么。音乐自带了BBE音效，回想起大学时买iRiver的MP3就以BBE为卖点，现在再看这种音效不过尔尔，不过其它系统都没有，也算是在音乐上做了优化。相机可以切换普通模式和专业模式，开放ISO、曝光时间，但是这些参数想来普通用户并不会买账吧。ViVo的桌面可以由用户自己创作，称之为情景桌面，完全看不到图标，只是一幅风景画，但新鲜感过后，还是用图标来得实在，对我来说手机终究是用的，不是看的。\\n\\n嘉域系统，因为ROM做得比较简洁，没有额外附加的程序，这是我用的第一个设置中直接集成ROOT开关的，可以配置每个程序是否可以访问su，定制度不高，缺少流量管理软件，真正用起来的时候后台程序流量控制不住。只能用原生的流量限制功能，限制流量的坐标轴滑条使用安卓原生，按对数增长，0～100M的操作区间很宽，越往上过渡得越快，比线性数轴要好。不过其它ROM也都一样，不算嘉域的亮点，作为原生系统的亮点也要写出来。\\n\\n联想ViBeUI系统，本来还有点期待，结果装上后彻底失望，制作者甚至都没有集成输入法，在常规的设置之外另有Tab页，但却都是些快捷操作，比如熄屏时双击home键拍照，甩手机锁屏之类。就是些奇技淫巧但又要单独出来，仿佛只有小聪明却找不到重心。开发者选项被阉割得连关闭动画的选项都没有了，每次新手机我都会把动画效果关闭，联想虽然不隐藏这个入口，却直接把功能删了，更加可恶。只用了一个下午，就决定不再使用了。\\n\\n金立Amigo系统，是西班牙语朋友的意思，起初我是不看好的，但可能是ROM制作者的用心，调整妥当后非常地好用，流量控制、后台关流量、也很省内存，是第一个原生支持修改字体的系统，缺点是铃声居然不能设置，只能按root方式直接修改系统文件夹，自带的相机程序无法使用(装第三方就行，不算问题)，另外开发者选项单单把进程统计给删除，不知何故。\\n\\n大可乐系统本身没什么要说的，制作者集成了xposed，故还在使用中\\n\\n另外小米系统最初也装过，不过时间久了没什么印象，这次就不再写报告了。\\n\\n总结下来一共8个系统加1个桌面，flyme的画风最好，OPPO的系统最友好，华为最理性，锤子桌面比较注重设计感，剩下的都没什么特色，甚至联想还要打负分。"}'));jctx.push(JSON.parse('{"id": "171222", "tag": "protocol", "text": "# 音频与声道的一些基本概念\\n\\n起因从一个对讲的bug说起。客户端在语音对讲时，一直发送的是双声道的音频文件，设备管理也按双声道解码，结果最近一款设备却实现成了只能解码单声道，最后非得客户端兼容才算把问题解决。\\n\\n所谓声道就是一个独立的可以播放的声音，对应的硬件可以简单的认为是个普通的民用麦克，采集人的声音并进行编码，这就是一个声道。虽然人只有一张嘴，却有两只耳朵，如果通过耳机播放一个声道的声音，就会出现仅单边有声单边静音的违和感，为了让听起来来自然，就把这个从麦克采集到的单声道声音复制一份，并按LRLR顺序按帧排列发送到对方，听起来就是两边有声音了。经过这样处理的声音就是双声道，尽管这两个声音是完全一样的。前文提到的那款设备，在解码时没有进行声道的处理，把每帧音频都送给同一个播放单元输出，因此造成了设备端回放声音的混乱。\\n\\n如果说对讲因为比较简单所以可以复制声道，音乐就不能这样做了，尤其是大型交响乐，舞台左右的乐器是不一样的，为了形成声音的方位感，在录制的时候会在舞台的多个点采集声音，并经过后期的调整叠加最终混合成左右两路声道，这两个声道的声音是同一首曲子，但不同的乐器会在响度和方位上的差异，给听者带来的感受就是能区分开各种乐器的方位，听起来声音就有了立体感，因此一般双声道的音乐又被称为立体声。\\n\\n家庭中常见的尤其是PC配备的2.1音箱和2声道又是什么关系呢？这个.1指的是低音单元，声音是有高中低频的(其实是连续的频谱)，一个音箱由于物理上的限制，无法完全地还原各个频段的声音，于是就有人想出把低频的声音通过低音单元放送，中高音则通过两个音箱播放。但是这就引出一个问题，音箱有3个，声道是2个还是3个？对民用产品来说，2.1音箱上播放的还是2声道声音，只是软件在播放前会把两个声道中低频部分通过低通滤波器过滤并送到低音炮播放，中高音部分送两个音箱播放，只是这种分离的做法有点生硬，所以讲究点的音乐爱好者会选择2.0的音箱，宁可牺牲低音效果，也要听到未被分离的声音。\\n\\n除了2.1，影院级的5.1或更高端的7.1就不再使用低通滤波器硬生生分离出来的声道，而是在采集的时候就额外采集一路单独的低音声道，这时就有6声道或8声道，这样播放的声音还原度、立体感也更强。"}'));jctx.push(JSON.parse('{"id": "180101", "tag": "web", "text": "# 使用DroidScript开发安卓程序\\n\\n本来是想用ionic在手机上做些开发，安装失败后，发现DroidScript安卓程序，可以在PC端浏览器连接手机，并在浏览器上进行编码调试。支持HTML和App两种开发模式，从通用性来说肯定是HTML好，App支持的插件丰富一些。\\n\\n支持很多特性，但Reference没有写只能从Demo去看。写好的程序可以打包成apk，Img目录如果有和工程同名的png文件，则该文件会作为apk的图标。支持debug和release签名。如果是release方式需要先生成私有的keystore文件，以后输入密码就可以打包了。\\n\\n## 网络请求\\n\\nHTML模式本质上是原生程序中内嵌了web页面，布局在四边稍有些空白，可以访问完整的window对象。虽然具备XMLHttpRequest，但可能是受限于跨域，另外提供了HttpRequest方法进行网络通信，可以向任意地址请求，HTTP头也没有Origin字段。至少支持get/post/put/delete方式(其它几乎没有使用，不测了)。参数只能以URL Encode方式编码，也就不能像jQuery那样写成json并由jQuery去转换，略有些不便。更坑的是分隔符居然用`|`而不是标准的`&`，如果用`&`程序会强行转码导致PHP上无法从`$_POST`找到希望的key。使用get或delete时，参数只能通过url方式携带，而post或put则一定在request body中。\\n\\n比如发起这样一个请求`httpAjax(\\"delete\\", \\"/index.php?t=3\\", \\"id=1|name=jojo\\", handleParam);`，抓包可以看到变成了`index.php?t=3?id=1&name=jojo`，强行把url和参数用?符号连接起来，导致后台如果用PHP解析，把`3?id=1`当作t的值。\\n\\n## 多字节字符\\n\\n支持很差，界面上无法输入中文，甚至复制中文后就不能再输入了，只能尽量用英文。导致一个更不方便的问题，写的中文日记无法提交，只能先将中文用JS的encodeURI转码再附到提交数据上，但这样和PC端Web上提交的内容不同。比如**看**字，PC端抓包是`%E7%9C%8B`；而经过encodeURI转码后的看字，抓包则是`%25E7%259C%258B`，两者比较前者9字节后者15字节。重复的部分就是`%`后面的字符要怎么解释，encodeURI相当于%要转译两次，因此负载密度很低。通过base64解决这个问题，但base64的结果会有=，建议用encodeURIComponent方法把=也进行转码。而encodeURI不对+=等特殊字符转码。\\n\\n## WebServer\\n\\n支持创建服务端，并能上传和下载文件，但是上传功能并不明显，通过自带demo发现，当在CreateWebServer的option指定Upload，就能以POST方式发起upload请求，形如`curl -F \\"DB=@a.db\\" -F \\"DB1=@b.db\\" ip:port/upload`，其中-F后面的字段可以随意指定，会自动创建同名文件夹。"}'));jctx.push(JSON.parse('{"id": "180112", "tag": "os", "text": "# 安卓root原理小记\\n\\n最重要的两个分区system和data，这两分区默认只读，因此不能删除预装程序。要设法把su写到system分区，最好还要有daemonsu（守护的目的还不清楚），magisk能在不改动system分区的状态下实现root功能。data会做加密，具体原理不明。\\n\\n但并是不是把su写入system分区就完成了。这涉及安卓程序的启动顺序，系统是由boot加载的，如果boot内记录了出厂时system分区的签名值，就会拒绝启动写入su的系统，导致系统会halt住。所以锁机的型号一定要最先做unlock，使boot不再校验system分区是否和出厂一致，这样写入su才有意义。Nexus和杂牌不会锁机，像小米或华为的部分机型，需要在官网提交申请才能解锁。\\n\\n现在问题归结为怎么使system分区可写，有两种途径\\n\\n1. 利用运行期漏洞提权，重新mount system使它可写\\n2. 启动时将system分区加载为读写方式并写入su\\n\\n第一种方式常见的形态是一键root软件（安卓版或PC版），会根据系统版本选择合适的漏洞。\\n\\n第二种方式比如重新线刷boot.img，因为启动信息是以RamDisk方式打包在boot.img里，只能重新生成一个boot程序替换，强制引导为读写方式，如果没有好心人去编译对应硬件的boot，就只有等待了。Magisk就可以针对原始的boot.img打patch生成新的boot.img，将这个patch的boot.img重新写入bootloader就能达到root的效果(理论上，未试出来)。可以从厂商提供的线刷包提取，某些recovery也提供boot分区备份，也能得到boot.img。\\n\\nfastboot命令可以向flash烧写boot，但有两个前提：电脑上安装手机的驱动，使adb能识别出手机；手机要处在解锁状态，才能在adb reboot-bootloader后，再fastboot flash boot patchboot.img写入，否则进入bootloader会无限循环。\\n\\n## boot.img的内容\\n\\n文件解压得到kernel和ramdisk.gz两个文件，奇怪的是ramdisk用了多种解压软件都没辙。封包格式是安卓自定义格式，前8字节是`ANDROID!`，接着是kernel和ramdisk大小，board name/签名等一系列内容。\\n\\n## 启动流程\\n\\n通常开机到进入桌面会经历下面3个阶段（recovery模式不确定要不要经过boot.img）\\n\\n```\\nfastboot/bootloader -> boot.img -> system/data\\n```\\n\\n结合magisk的systemless做法和必须要给boot.img打补丁，大概率是在boot.img做了手脚，从而能旁路system的只读保护。但仍然需要解开BL锁，才能写入boot.img。"}'));jctx.push(JSON.parse('{"id": "180129", "tag": "os", "text": "# 小鲜4刷机反思\\n\\n上周买了一个安卓机，事先查好各种资料确定可以刷机才下的订单。然后到手后足足用了5天才线刷成功。\\n\\n第一天徒劳无功地反复操作软件、装驱动各种瞎折腾没有任何收获，虽然当天快12点换了win10系统，但仍然不成功。但大概知道原因出在数字驱动签名。\\n\\n第二天查阅数字驱动的关闭方法，按照网上最多的说明通过重启方式进入，但因为系统原因找不到这个菜单，仍然是换win10可以，即使这样也没有进展。倒是知道还能通过组策略gpedit方式关闭，不过并没有任何帮助。这一天至少刷机时MTK的红色刷机条能走完，查看了资料知道是一个叫Download Agent的程序写入CPU的RAM，但是数据还是无法写入Flash。\\n\\n连续两天折腾下来也比较心累了，估摸着换win7会好一点，第三天没有刷。\\n\\n第四天找到一台win7电脑，装驱动的时候确实提示无视数字签名，感觉离成功近了一点，但最后仍然提示驱动安装失败，仍然无果。\\n\\n第五天，既然三个系统都试过，只好静下心来反思每个步骤，在安装驱动的最后失败界面，系统提示文件无法找到。以前从来不在意这个提示，走投无路之下用这个作为关键字搜索，竟有意外收获，网上有一篇很详细的介绍，还附带了两个安装包。其中一个显示是win7用，安装失败，但另一个成功了，结果到了最后一步还是提示缺少inf文件。介绍文章也用的是win8，和我的一样，有些气馁。但想想都走到这一步了，不妨再试试win10，竟然非常顺利地插上线就开始写Flash了！问题找到就是驱动不对。5分钟后刷机成功，系统得到root权限。\\n\\n反思这个问题，如果第二天结束的时候能仔细留心提示的错误信息，用搜索引擎显然是能找到正确的解法的，只怪当时没有沉下心来找原因，只想着换系统，直到山穷水尽才发现其实路早已在那里。不过可惜的是主力机win8一直都不能成功，可能和系统文件有缺失有一定关系，刷机已结束，教训也有了，就不再尝试了。\\n\\n4月补记，拿到一台xplay3s，root过程也不平坦。\\n\\n先用教程一的方式，用PC端工具写入recovery，再导入root.apk包，这个包含有su和授权管理程序。但不知道是fastboot未解锁或其它原因，recovery没有写入，可想而知用官方recovery写入root.apk遇到签名失败问题，此路不通。\\n\\n教程二提供了adb的命令行方式写入recovery方式，但执行过程遇到无法找到su错误。再看教程介绍，要先用一键root工具。结果工具root不成，反而装上了kingroot和另一个垃圾软件，而且这两个垃圾软件还不能卸载！说明安卓一定有机制允许未root设备向只读分区写文件，又有一种可能就是su被暂时写入tmp分区，从而实现apk写入只读分区。其实当时我并没有想到这个问题，只是抱着试一试的心态又点击了一次adb写recovery。重新进入recovery模式后，发现居然已经烧写成功了，而且大量的垃圾软件已删除一空，包括kingroot也没有了，但另一个附带的垃圾软件还驻留着。\\n\\n到这一步毕竟比出厂情况要好太多，接下来就是下载第三方已经集成好root的安装包，重新完整写入就获得干净的系统了。"}'));jctx.push(JSON.parse('{"id": "180219", "tag": "web", "text": "# PHP的一些语言特性\\n\\n## 程序辨析\\n\\nphp包装好后，会有php和php-cgi两个很容易混淆的程序（php-fpm单开一篇讲），这和php最早就是作为web开发语言有关。其它的脚本语言，主要都是运行在cli下，通过一些库也能运行http程序，但不是程序核心部分。虽然我没有证据，但初版的php语言可以认为只有php-cgi。在这种模式下，输出要服务于html，因此所有的文字都会包裹上适当的html标签。随着php的发展，也有人把它用于终端开发，这时就有了php程序，此时的输出就是纯粹的文本。\\n\\n## ini默认配置\\n\\n启动时会读入php.ini配置文件，虽然不读也可以，但鉴于常用选项太多，最好还是配置一下。因为有些扩展，如果不在ini文件中指定是不会加载，虽然可以通过dl手动加载，但毕竟没有ini直接指定来得方便。其它语言虽然也有类似机制，但远没有像PHP这么重视启动加载文件。\\n\\n## 动态性\\n\\nPHP的动态特性让人印象深刻。\\n\\n首先是字符串可以在一定程度表示函数。比如`spl_autoload_register`函数传入的参数是string，实际对应的是同名函数。\\n另一个例子是构造一个对象$obj，再定义一个字符串变量$foo=\'bar\'，用$obj->{$foo}()的方式就可以调用$obj实例的bar方法。\\n\\n从字符串推导出函数就是反射，对动态语言来说并不是独一无二的能力，但PHP把字符串直接映射函数这个特性，结合到部分特性的上下文，做成了很好用的语法糖。\\n\\n所有语言动态能力的源头都是eval，PHP/JS/Lua都有这个函数(Lua对应load)，比如eval(\'$abc=123;\')执行后，$abc就可以使用了。JS的书中对eval的闭包有很详细的解释，eval最重要的参数是环境，不填有可能是当前环境或根环境，不同语言偏好不同。\\n\\n再说说观察者模式和语言的结合，PHP支持SplObserver和SplSubject。在Ruby中也有类似的observer模块。差异是PHP的notify时是把SplSubject整个对象传给SplObserver对象，而Ruby可以传递任意个数的参数，多少也体现了Ruby语言的灵活。\\n\\n相对路径是程序中很容易引起混淆的地方，比如`__DIR__`或`__FILE__`变量，单独执行时很容易理解，但从另一个文件载入这个文件时，值并不会变化。原因是这个变量是从属于被执行的文件，并不会随着调用方而变化。\\n\\n## 自动加载\\n\\n要使用composer生成的自动加载代码，除了在调用端和源端按规范使用命名空间外，最重要也最容易忽视的，就是要配置好composer.json和生成加载代码。\\n\\n假设项目目录是这样\\n```\\nProject\\n|__composer.json\\n|__main.php\\n|__lib/\\n    |__A.php\\n|__vendor/\\n    |__autoload.php\\n```\\n\\n假如代码在lib目录下，务必在项目顶级的composer.json加上\\n```\\n    \\"autoload\\": {\\n        \\"psr-4\\": {\\n            \\"your-namespace\\\\\\\\\\": \\"lib/\\"\\n        }\\n    }\\n```\\n之所以显得有些啰嗦，是因为还存在psr-0和files方式，所以必须在autoload节点下再嵌套一层。\\n\\n然后在main.php使用`use your-namespace\\\\A`，而在A.php中定义`namespace your-namespace`。\\n\\n到这一步还不够，必须要手动执行一次`composer dump-autoload -o/-a`，-a表示一旦找不到就不再查找，而-o还会尝试按psr4方式再找一次。至此加载器才能正常工作。说明加载器并不是全自动的，而必须要手工介入，且最顶级的命名空间，是用配置绑定，并不要求命名体现在文件系统上。\\n\\n看过vendor/autoload.php的源代码就可以知道，所有加载类的路径，都是事先在代码中保存在一个array变量classMap里，并不是运行时拼接路径加载，所以运行前执行一次dump-autoload就好理解了。\\n\\n简单解释一下autoload的源码，vendor下的autoload.php只是一个入口，先加载autoload\\\\_real.php，虽然名字带了real，并不是真正的加载函数，还要依赖ClassLoader.php和autoload\\\\_static.php，这两个类各有分工，ClassLoader负责调用spl_autoload_register，而static则提供classMap，这两个类在调用链上经过Closure::bind被绑定到一起。\\n\\n## stdClass\\n\\n用`json_decode`函数，却不能直接用[\\"name\\"]取值，原因是返回的是类型为stdClass的值，既然是对象，就要按对象的语法`->{\\"str\\"}`取值。\\n\\nstdClass有点像Java的Object味道，当然它是类不是对象。也可以new stdClass()创建一个什么都没有的空对象。\\n\\n对象和array看起来很像，能表达的内容也差不多，目前所知最大的差异就是在赋值时，array会把所有元素的值全拷贝一遍，而new得到的对象，赋值后只是一个引用，拷贝对象是几乎没有开销的。\\n\\n从语言历史来看，array在PHP4时代就出现了，而完整的对象语义直到PHP5才成形。而引用也是相对高级的特性，因此和对象关联在一起也就好理解了。\\n\\n## 源码结构与SPL\\n\\n最主要的3个目录，Zend/ext/sapi。Zend编译虚拟机，ext是标准库和常用扩展库，如PDO/XML等等，sapi则是最外层的接口。三个层次非常清晰。\\n\\nPHP的`file_get_contents/fopen`可以直接打开url，即直接获取网页内容。这些接口虽然简单，但一来灵活性低，另外只能阻塞没有超时设置标志，因此还有一种层次更基础的fsockopen，是socket的封装，且可以控制超时时间。如果要通过fsockopen来获取HTML页面，要自己封装请求，HTTP1.1需要至少3个字段，除了方法还必须Host和Connection才能取得网页。\\n\\n做C++开发的人都知道STL，对于PHP来说对应的就是SPL(Standard PHP Library)了。这是从PHP5时代开始发展并成熟起来的技术。所有SPL的函数以`spl_`开头，除了函数还有若干窗口类的接口，比如SplHeap、SplStack等，另外就是迭代器和异常。\\n\\nURL的禁则：`+`号是要转码的，但是奇怪的是form中如果输入空格，空格会转成`+`。而真正的`+`会用%转码。PHP有个函数叫parse_url，能把url拆成path和query，但是又不做转码。"}'));jctx.push(JSON.parse('{"id": "180316", "tag": "lang", "text": "# AndroLua记录\\n\\n一个在Android用lua开发程序的应用，利用了JNI技术。JNI的交互是在java中定义若干个native方式的接口，通过javah导出头文件。在C函数中实现这些导出头文件对应的函数。这是java调用C的流程。想从C调用java，就要借助传给C语言JNIEnv变量并保存下来，后续用这个变量找class和method，并通过JNIEnv来调用。利用lua、C、Java三者之间两两互通，最终实现lua和java的互操作。\\n\\n最初的想法来自Lua的Kepler项目中luajava这个子项目。代码分为C和Java两部分，先看C语言部分。\\n\\n1.1版本就luajava.c一个文件。前半部分定义了5个lua操作java对象的函数，new/newInstance/bindClass/createProxy/loadLib。4.0版本又增加了多个函数，为简化起见先学习这5个。\\n\\n这5个函数肯定放入lua的table，并以字符串和C函数的关系绑定。这个L保存在CPtr.java定义的private long peer;成员变量。\\n\\nlua中会以newuserdata方式创建JNIEnv类型变量，并命名为`__JNIEnv`保存到`LUA_REGISTRYINDEX`里。每当这个userdata被触发gc时，会找JNIEnv并用DeleteGlobalRef方式对jobject的引用计数减1。\\n\\nluajava.c的后半部分定义了107个JNI的C实现，注册5个函数是在LuaState.java中定义为native方式的名为`luajava_open`的函数，由于javah的转换,到了C语言中函数名会稍有不同，但还是能看出来。C语言中实现了5大函数的注册。而在java的LuaState构造函数中，实现了`luajava_open`的调用。\\n\\n如果是通过java的console方式，会在Console.java的main函数构造LuaState，实现5大函数在lua的注册，接下来就可以在lua中调用java了。\\n\\n每次在abstract的JavaFunction调用LuaState.pushJavaFunction，就会在lua中创建新的userdata，再创建一个table，并设置`__call`域，执行函数调用int execute()签名函数。所有的入参在lua栈上，出参会压入栈上，返回的int就表示出参个数。\\n\\n## 开发安卓程序\\n\\n利用布局器交互式地添加几个简单的控件，.aly文件会依次出现这些控件，然后加上id=\\"xx\\"之后，就可以在代码中操作这些控件。布局器只要一个LuaWebView，剩下的就是web开发和打包。"}'));jctx.push(JSON.parse('{"id": "180320", "tag": "os", "text": "# 安卓APK内容分析\\n\\n## 压缩包的文件构成\\n\\n最小的apk会有classes.dex/AndroidManifest.xml/resources.arsc文件和assets/META-INF(数字签名，记录了所有文件的SHA-1结果)/res目录，换句话说是由Java编译的字节码、资源文件原生库以及辅助文件(如编译说明、签名)共同打成的zip包。\\n\\n不同apk之间是依靠记录在AndroidManifest.xml的包名和数字签名共同来进行区分的。\\n\\n## 执行代码说明\\n\\nclasses.dex文件是Dalvik字节码，也是主执行代码。java把每个源文件编译成class，而apk中只有一个dex，有点jar的味道。\\n\\n用户安装在/data目录下的apk，通常都包含dex。/system目录下的apk内没有dex，替代的是外部的odex文件。在真正执行前，会将dex做进一步优化，分Dalvik或ART优化，版本4.4以前使用dexopt生成odex文件，版本5之后使用dex2oat生成用于ART的oat格式(可能也是.dex的扩展名)。dex是跨平台的，odex/oat是平台依赖的，存放odex/oat位置就是dalvik-cache。\\n\\n## 文件内容\\n\\n每个apk会在/data/data/目录下存放文件（小米会创建/data/usr/0/别名）。这个目录下的文件夹比较固定，至少有 files, shared\\\\_prefs, cache, code\\\\_cache。有些还会有databases, lib, app\\\\_XXX这样的目录。"}'));jctx.push(JSON.parse('{"id": "180401", "tag": "lang", "text": "# 《JS语言精粹》学习记录\\n\\n知乎上看的，融合了自己的理解。\\n\\n## 第一章 精华\\n\\nJavaScript有很多优秀的想法也有糟粕；\\n优秀的想法在于：弱类型，函数，动态对象和富有想象的对象字面量表示法。\\n糟粕在于：基于全局变量的编程模型。\\n\\nJavaScript的函数是主要基于词法作用域（lexical scoping）的顶级对象.\\n\\n原型继承是JavaScript一个有争议的特性。JavaScript有一个无类型的对象系统。在这个系统中，对象直接从其他对象继承属性。\\n始终用一个method方法定义新方法：\\n\\n```\\nFunction.prototype.method = function ( name , func){\\nthis.prototype[ name] = func ;\\nReturn this;\\n}\\n```\\n\\n## 第二章 语法\\n\\nNaN表示一个数值，是一个不能产生正常结果的运算结果。不等于任何值，包括他自己。Infinity可以表示无穷大。数字拥有方法，有一个对象Math，包含一套用于数字的方法。\\n\\n字符串：可以在” ” , ’ ‘里面。\\\\ 是转义字符。有一个length属性，表示长度。可以用 + 连接字符串，字符串也有一些方法。\\n\\n语句：每个`<script>`提供一个被编译且立即执行的编译单元。JavaScript把他们添加到一个全局的名字空间里面去。\\n\\nVar在函数内部，定义的是私有变量。代码块在{ } 中，不会创建新的作用域。\\n\\nSwitch，while，do，for允许有一个可选的标签。可以配合break;\\n\\n被判断为 假 的值：False ; null ; undifined ;空字符串 ； 数字0 ； 数字NaN\\n\\nFor in 语句枚举对象里的所有属性\\n\\n如果throw在一个try代码块中，那么控制流会跳转到catch从句中。如果throw语句在函数中，则该函数调用被放弃，控制流跳转到调用该函数的catch中。\\n\\nThrow语句的表达式通常是一个对象字面量。通常包含一个message和name。异常捕获器可以利用这些信息知道做什么。\\n\\n表达式：最简单的表达式是字面量值，变量，内置的值，new开头的表达式，delete开头提取属性，（...）,前置运算符，三元，函数调用，属性提取....\\n\\ntypeof判断类型。\\n\\n字面量：对象字面量是一种可以方便的按照指定的规格创建新对象的方法。\\n\\n函数：函数字面量定义了函数值。\\n\\n## 第三章 对象\\n\\nJavaScript简单的数据类型包括：数字，字符串，布尔类型，null，undifined。除此以外的所有类型都是对象。数字，字符串，布尔值也类似对象，他们有方法，但是他们不可变。\\n\\n对象是可变的键值对的组合。数组，函数，正则表达式都是对象。对象是属性的容器，属性都有名字和值。值不可是undifined。对象是无类型的，对象中可以包含对象。\\n\\n对象字面量：方便的创建对象。语法有点特殊，只有在等号或圆括号内的花括号才认为是创建对象。\\n\\n“||” 可以填充默认值，\\n\\n“&&”可以避免typeerror错误，由于在不存在的属性取值产生的。\\n\\n更新： 赋值语句，存在则更新；不存在则扩充。\\n\\n引用：对象通过引用传递，永远不会被复制。\\n\\n比较JS和Lua对象，两种语言的实现都有GC和union的值类型，JS会多出两个特殊的字段，properties和prototype。\\n\\n先说原型（prototype）：每个新建对象都连接到一个原型对象，并且可以从其中继承属性。所有通过字面量创建的对象都连接到Object.prototype,他是js中的标配对象。看MuJS的实现，所有的类型像Object/Array/Function/Date有prototype。七种错误Error/EvalError/RangeError/ReferenceError/SyntaxError/TypeError/URIError也有各自的prototype。\\n\\n每次构造新对象，都会把新创建的类型的prototype指向预设的原型。原型连接在更新时候不起作用，对对象改变不触及原型。\\n\\n原型链的任何属性都会产生值 typeof fight .toString -> ‘ function’\\n\\n有两种方法丢掉不需要属性：\\n\\n1. 程序检查并丢掉值为函数的属性。\\n\\n1. 使用hasOwnProperty 方法，如果对象有独立属性，返回true。它不会检查原型链。\\n\\n再说property，比Lua要丰富一些，具备一些内在属性，READONLY/DONTENUM/DONTCONF。三者可以任意组合。\\n普通的属性可以枚举：for in 遍历一个对象中非ENUM的属性名包括原型中的属性。属性出现无序，可以使用数组避免这种情况。\\n\\nCONF和Frozen相关(ES5特性)。\\n\\n删除：删除对象的属性可能会让原型链中的属性透露出来。\\n\\n减少全局变量污染：只创建一个全局变量作为容器这样都在一个名称空间下，减少与其他程序的冲突。\\n\\n## 第四章 函数\\n\\n函数对象：函数是对象。创建时连接到Function.ptototype。每个函数对象在创建的时候配一个prototype属性。其有一个constructor属性且值为函数。\\n\\n函数字面量：函数通过函数字面量来创建。\\n\\n```\\nVar add = function ( a , b ){\\nreturn a + b ;\\n}\\n```\\n\\n函数没有名字，如上就叫匿名函数。\\n\\n函数字面量可以在任何表达式可以出现的地方。也可以在函数中，就是嵌套函数。里层的函数可以调用他上一层的函数的变量。通过函数字面量创建的函数可以连接到他的外部上下文这叫，闭包。\\n\\n调用：除了函数定义的形式参数以外函数还有两个自带的参数。this 和 argument，this的值取决于调用模式：\\n\\n函数有4中调用模式：\\n\\n1. 方法调用模式：\\n\\n函数在对象中保存为属性的时候，为方法。此时this绑定到该对象。通过this可以取值或对对象进行修改。通过this取得对象上下文的方法称为公共方法。\\n\\n1. 函数调用模式：\\n\\n当函数不是属性的时候，此时当做一个函数来调用。此时this指向了全局变量。这使得函数中的内部函数不能为外部函数服务。解决的办法：在外部函数里让this赋值给一个变量。\\n\\n1. 构造器调用模式：\\n\\nJs提供一套和基于类的语言类似的对象构建语法。如果在函数前面添加new来调用，那么会在背地里创建一个连接到这个函数的prototype的新对象，this会绑定到这个新对象。一个函数，构建的目的是希望结合new来用，就是构造器函数。\\n\\n1. Apply调用模式\\n\\n函数可以拥有很多方法。Apply方法允许我们传递一个数组参数给函数。其接受两个参数，第一个为this的值，第二个就为参数数组。\\n\\n参数：参数有一个附加的对象，argument对象，类似数组，没有数组的属性。函数可以通过这个对象，访问传过来的参数列表。\\n\\n返回：return\\n\\n异常：throw语句判断函数的执行。会抛出一个exception对象，其中包含异常类型name，以及异常的描述message。一个try语句只会跟随一个捕获所有异常的catch。\\n\\n函数的闭包使得具备静态词法作用域，但this的存在又允许动态地打开作用域，兼有动态作用域的效果，很灵活很强大。# 《JS语言精粹》学习记录\\n\\n知乎上看的，融合了自己的理解。\\n\\n## 第一章 精华\\n\\nJavaScript有很多优秀的想法也有糟粕；\\n优秀的想法在于：弱类型，函数，动态对象和富有想象的对象字面量表示法。\\n糟粕在于：基于全局变量的编程模型。\\n\\nJavaScript的函数是主要基于词法作用域（lexical scoping）的顶级对象.\\n\\n原型继承是JavaScript一个有争议的特性。JavaScript有一个无类型的对象系统。在这个系统中，对象直接从其他对象继承属性。\\n始终用一个method方法定义新方法：\\n\\n```\\nFunction.prototype.method = function ( name , func){\\nthis.prototype[ name] = func ;\\nReturn this;\\n}\\n```\\n\\n## 第二章 语法\\n\\nNaN表示一个数值，是一个不能产生正常结果的运算结果。不等于任何值，包括他自己。Infinity可以表示无穷大。数字拥有方法，有一个对象Math，包含一套用于数字的方法。\\n\\n字符串：可以在” ” , ’ ‘里面。\\\\ 是转义字符。有一个length属性，表示长度。可以用 + 连接字符串，字符串也有一些方法。\\n\\n语句：每个`<script>`提供一个被编译且立即执行的编译单元。JavaScript把他们添加到一个全局的名字空间里面去。\\n\\nVar在函数内部，定义的是私有变量。代码块在{ } 中，不会创建新的作用域。\\n\\nSwitch，while，do，for允许有一个可选的标签。可以配合break;\\n\\n被判断为 假 的值：False ; null ; undifined ;空字符串 ； 数字0 ； 数字NaN\\n\\nFor in 语句枚举对象里的所有属性\\n\\n如果throw在一个try代码块中，那么控制流会跳转到catch从句中。如果throw语句在函数中，则该函数调用被放弃，控制流跳转到调用该函数的catch中。\\n\\nThrow语句的表达式通常是一个对象字面量。通常包含一个message和name。异常捕获器可以利用这些信息知道做什么。\\n\\n表达式：最简单的表达式是字面量值，变量，内置的值，new开头的表达式，delete开头提取属性，（...）,前置运算符，三元，函数调用，属性提取....\\n\\ntypeof判断类型。\\n\\n字面量：对象字面量是一种可以方便的按照指定的规格创建新对象的方法。\\n\\n函数：函数字面量定义了函数值。\\n\\n## 第三章 对象\\n\\nJavaScript简单的数据类型包括：数字，字符串，布尔类型，null，undifined。除此以外的所有类型都是对象。数字，字符串，布尔值也类似对象，他们有方法，但是他们不可变。\\n\\n对象是可变的键值对的组合。数组，函数，正则表达式都是对象。对象是属性的容器，属性都有名字和值。值不可是undifined。对象是无类型的，对象中可以包含对象。\\n\\n对象字面量：方便的创建对象。语法有点特殊，只有在等号或圆括号内的花括号才认为是创建对象。\\n\\n“||” 可以填充默认值，\\n\\n“&&”可以避免typeerror错误，由于在不存在的属性取值产生的。\\n\\n更新： 赋值语句，存在则更新；不存在则扩充。\\n\\n引用：对象通过引用传递，永远不会被复制。\\n\\n比较JS和Lua对象，两种语言的实现都有GC和union的值类型，JS会多出两个特殊的字段，properties和prototype。\\n\\n先说原型（prototype）：每个新建对象都连接到一个原型对象，并且可以从其中继承属性。所有通过字面量创建的对象都连接到Object.prototype,他是js中的标配对象。看MuJS的实现，所有的类型像Object/Array/Function/Date有prototype。七种错误Error/EvalError/RangeError/ReferenceError/SyntaxError/TypeError/URIError也有各自的prototype。\\n\\n每次构造新对象，都会把新创建的类型的prototype指向预设的原型。原型连接在更新时候不起作用，对对象改变不触及原型。\\n\\n原型链的任何属性都会产生值 typeof fight .toString -> ‘ function’\\n\\n有两种方法丢掉不需要属性：\\n\\n1. 程序检查并丢掉值为函数的属性。\\n\\n1. 使用hasOwnProperty 方法，如果对象有独立属性，返回true。它不会检查原型链。\\n\\n再说property，比Lua要丰富一些，具备一些内在属性，READONLY/DONTENUM/DONTCONF。三者可以任意组合。\\n普通的属性可以枚举：for in 遍历一个对象中非ENUM的属性名包括原型中的属性。属性出现无序，可以使用数组避免这种情况。\\n\\nCONF和Frozen相关(ES5特性)。\\n\\n删除：删除对象的属性可能会让原型链中的属性透露出来。\\n\\n减少全局变量污染：只创建一个全局变量作为容器这样都在一个名称空间下，减少与其他程序的冲突。\\n\\n## 第四章 函数\\n\\n函数对象：函数是对象。创建时连接到Function.ptototype。每个函数对象在创建的时候配一个prototype属性。其有一个constructor属性且值为函数。\\n\\n函数字面量：函数通过函数字面量来创建。\\n\\n```\\nVar add = function ( a , b ){\\nreturn a + b ;\\n}\\n```\\n\\n函数没有名字，如上就叫匿名函数。\\n\\n函数字面量可以在任何表达式可以出现的地方。也可以在函数中，就是嵌套函数。里层的函数可以调用他上一层的函数的变量。通过函数字面量创建的函数可以连接到他的外部上下文这叫，闭包。\\n\\n调用：除了函数定义的形式参数以外函数还有两个自带的参数。this 和 argument，this的值取决于调用模式：\\n\\n函数有4中调用模式：\\n\\n1. 方法调用模式：\\n\\n函数在对象中保存为属性的时候，为方法。此时this绑定到该对象。通过this可以取值或对对象进行修改。通过this取得对象上下文的方法称为公共方法。\\n\\n1. 函数调用模式：\\n\\n当函数不是属性的时候，此时当做一个函数来调用。此时this指向了全局变量。这使得函数中的内部函数不能为外部函数服务。解决的办法：在外部函数里让this赋值给一个变量。\\n\\n1. 构造器调用模式：\\n\\nJs提供一套和基于类的语言类似的对象构建语法。如果在函数前面添加new来调用，那么会在背地里创建一个连接到这个函数的prototype的新对象，this会绑定到这个新对象。一个函数，构建的目的是希望结合new来用，就是构造器函数。\\n\\n1. Apply调用模式\\n\\n函数可以拥有很多方法。Apply方法允许我们传递一个数组参数给函数。其接受两个参数，第一个为this的值，第二个就为参数数组。\\n\\n参数：参数有一个附加的对象，argument对象，类似数组，没有数组的属性。函数可以通过这个对象，访问传过来的参数列表。\\n\\n返回：return\\n\\n异常：throw语句判断函数的执行。会抛出一个exception对象，其中包含异常类型name，以及异常的描述message。一个try语句只会跟随一个捕获所有异常的catch。\\n\\n函数的闭包使得具备静态词法作用域，但this的存在又允许动态地打开作用域，兼有动态作用域的效果，很灵活很强大。"}'));jctx.push(JSON.parse('{"id": "180402", "tag": "lang", "text": "# 接口与集合论\\n\\nhttps://bartoszmilewski.com/2014/10/28/category-theory-for-programmers-the-preface/\\n\\njava 的接口是个余积（Coproduct，可以简单地看作是范畴化的不交并）。Java 里面没有能很好表达积（Product）的概念（泛型是瘸的），而这个对偶却很好用。通俗化地理解，余积通俗理解，就是C语言的联合体，把若干不相关的类型合并。\\n\\nFP 领域就正好反过来，他们很喜欢积（Forall 量化以至于 DT 的 Pi），而几乎不碰余积（Existential 量化）。在 FP 的多态里面，返回具体类型X_1,X_2,...,X_N的函数（态射）可以被改写成一个返回多态类型\\\\prod_N{X_N}的函数外加一些实例化函数\\\\pi_1, \\\\pi_2,...,\\\\pi_N的复合。类型里的积也是两种：\\n\\n* 有限的，表现为元组（Tuple）或者记录（Record）\\n* 无限的，就是参数多态（Parametric Polymorphism）\\n\\n分析历史源流的话可以发现：OOP 得以被发扬光大，糅合了大量传统命令式语言的内容。在它们眼里，类型是一个集合，无穷个子集组成的不交并（余积）比较好理解，也好实现。但无穷个子集组成的直积（范畴积）就十分令人困惑了；FP 语言则因为和逻辑学的关系，大量使用逻辑学术语，范畴积在那边是逻辑学里非常普遍的\\\\forall符号，而余积则是只有高阶逻辑中才会出现的大\\\\Sigma算符。\\n\\nOOP 语言是追随着传统工业编程语言的路径走来的 -> 发扬光大的时候才追传统语言，但是这过程没引入什么新特性。Simula Smalltalk Flavor Self CLOS(meta object protocol)这些语言都跟工业界没啥关系，但对OOP语言的发展远远比Java高\\n\\n至于interface（in general，不是对java），parametric polymorphism，我不喜欢把他们看作infinite product/coproduct，因为有特性没有被capture到（比如interface应该隐藏实现，coproduct做不到，比如parametricity）。parametricity 是那些 π 函数干的事情（从一个 product 中「取」需要的版本）；「隐藏细节」是针对惟一的 f 说的，它不依赖 X_n 的细节，只关心接口本身。\\n\\nCategorical Abstract Machine 1985, 比Haskell的monad早\\n不一定要靠monad，Dana Scott的denotational semantic paper早就有副作用的数学建模（尽管不是纯函数的）\\n带副作用的FP看两部分\\n\\n* 一部分是纯的，生成不纯的语言的代码\\n* 一部分是不纯语言的副作用-而这部分没理由必须monadic\\n"}'));jctx.push(JSON.parse('{"id": "180405", "tag": "web", "text": "# YXcms和CanPHP的结合\\n\\n以前写过一篇URL路由，提到YXcms的解析思路，分析整体代码的思路。\\n\\nCanPHP的结构很清晰，分core/lib/ext三个目录，lib是官方功能扩展，ext是第三方扩展。core的顶级只有1017行代码，算上cache和db目录的各种不同实现共2千行。lib包括鉴权、图片等常用功能共5292行。ext有邮件和IP地址共1015行。\\n\\ncore目录有如下文件，cpApp加载入口，cpModel/cpCache数据库相关，cpTemplate/cpHtmlCache页面展示，cpConfig/cpError辅助功能。对于框架来说一定要提供M和V，而C天然是应用层要做的事，CanPHP做到了。\\n\\nYXcms会在它的体系中包含这些文件，cpModel被model使用，cpCache在cpModel内部包含，不需要显式使用。cpTemplate被controller和commonController使用，cpHtmlCache被baseController使用。cpConfig和cpError直接在YXcms的入口文件core使用。cpApp的入口功能被core重写，所以没有被使用。从中可以看出，CanPHP最核心的功能一个不落地被YXcms引用了。\\n\\nYXcms具有完整的MVC，C的代表controller，构造时会创建model，其view函数会创建cpTemplate进而渲染视图。V是一堆含有待替换值的HTML页面。"}'));jctx.push(JSON.parse('{"id": "180406", "tag": "lang", "text": "# 冯东的Lua\\n\\nLua vs. Python\\n\\n在《 Programming in Lua 》系列里谈了 Lua 的 stackless 实现。说到 stackless 设计，难免和 Python 的 stackful 实现比较一下。\\n\\n以前总有一个疑惑。为什么 Python 既要采用 native thread，又要用 great-lock 将其变成实质上的协作式 thread。像 Lua 这样的 coroutine 不好么？现在知道了，非不为，不能也。既要尽量保证虚拟机的可移植性，又采用了非常依赖 CRT stack 的 stackful 设计，语言本身没有 synchronous primitive，不能应付真正的 preemptive 多线程。这种情况下，多线程加 big-lock 是唯一的折衷了。由此也知道了 Python 的 generator 为什么只允许在第一层函数中 yield，因为 stackful 设计不允许保存 call stack (说老实话，只允许在第一层函数中 yield 的 coroutine 不过是两个函数调来调去，在 C 里实现起来也不难)。Python 3.3 开始支持更宽松的 yields，不过实现的方式和 Lua 的 yields-in-C 差不多，作为基于虚拟机的语言是比较原始的手段。\\n\\n拿 Lua 和 Python 做比较令人恍惚感觉正在比较 Objective-C 和 C++。Lua/Python 和 Objective-C/C++ 都是在共同基础上发展出来：后者扩展 C 语言；前者用 C 语言实现基于 byte-code 的虚拟机。它们都有理想的「标杆」：Objective-C/C++ 的标杆是 Smalltalk/Simula 等面向对象语言先驱；Lua/Python 是 Lisp 这样的高级动态语言先驱。努力的方向都是降低「标杆」过大的性能开销和简化「标杆」过于复杂 (或者过于精简) 的概念。Python 和 C++ 相对较早的尝试，都采用了比较低级的机制：C++ 用函数指针模拟成员函数；Python 依赖 CRT stack 直接实现 byte-code stack。这些「第一次」都没能「do things right」。后来的第二次尝试才作出了更妥当的取舍。\\n\\n在《 The Art of UNIX Programming 》里指出了系统设计的「第二系统综合症 (second-system effect)」。乔布斯也提到过「第二个产品」的问题。在一个成功的系统上衍生的第二个系统有时会因为没有理解第一个系统成功的真正原因而失败。但是，如果还有机会的话，由此衍生的「第三系统」往往会做得更好。对于上面所说的语言发展来说，它们的基础 (C 语言) 和「标杆」是「第一系统」，第一次改进的尝试毁誉参半，而后来的「第三系统」更加出色。\\n\\n2013/05/13\\t Leave a reply\\nProgramming in Lua（五）－ Coroutine, Lua Stack\\n\\n在《 Programming in Lua（三）－ Yields in C 》里讨论了 Lua 虚拟机对 yields-in-C 及其 stack 的处理。当时还未读 Lua 虚拟机的实际代码，只根据语言的行为来推测，有些术语也不符合通常用法。最近从 Lua stack 的实现入手，发现了一些以前没想过的问题：为什么 resumes-in-C 从来不是问题？为什么有 lua_yieldk() 而没有对应的 lua_resumek() ？\\n\\n首先从术语的标准化说起。《 Programming in Lua（三）－ Yields in C 》里有多处这样的描述：\\n\\n「stack 上 ⋯⋯ 的执行层次」；\\n「virtual stack 上的 Lua 部分的 stack」；\\n「Lua stack 段」。\\n其中「执行层次」、「部分」、「段」这样的字眼应该替换为「stack frame」这个更常用的术语。线程运行时，stack 呈现两层意义。一是后入先出的简单线性结构；二是把此线性结构划分成与函数调用层次一一对应的若干段，这样的一段就被称为一个 stack frame。大多数语言的 runtime 或虚拟机中，stack frame 并无单独的数据结构表示。在 64-bit x86 的 C runtime (CRT) 中，每个 stack frame 的首项是上一层 stack frame 的最低地址 (base)，称为 stored frame pointer (SFP)，最顶层 stack frame base 存储在 %ebp 寄存器中 。即每次生成新的 stack frame 时，首先将 %ebp 寄存器入栈形成 SFP，然后把当前的 %esp 赋给 %ebp。通过这种方式让需要解析 stack frame 的程序 (比如 debugger) 得到所需信息。(SFP 并非一定存在，臭名昭著的 omit-frame-pointer 编译器优化会去掉 SFP，这时 debugger 只能借助额外存储的 symbols 来解析 stack frame。)\\n\\n就需求本身来说，Lua stack 要解决的问题比 C 复杂的多，甚至比同为动态语言的 Python 更复杂。基于虚拟机的语言的 call stack 有两种可能的设计：一是借用虚拟机本身的 CRT stack。Byte-code 的函数调用指令对应虚拟机本身 native 代码的函数调用，虚拟机的 CRT stack 随 byte-code 函数调用的层次增加而增长。二是由虚拟机维护额外的 call stack 数据结构。Byte-code 的函数调用指令和其它指令一样，在虚拟机的同一个循环中完成，虚拟机的 CRT stack 不体现 byte-code 函数的调用层次。后者通常被称为 stackless 方案，前者暂且对应称为 stackful 方案。\\n\\nLua 是 embedded/extension 语言，byte code 的运行总会夹杂 C 函数。这些 C 函数的 call stack 在逻辑上是 byte-code 运行状态的一部分，实际上则间杂在 Lua 虚拟机的 CRT stack 中 (在涉及 Lua 的情况下讨论 CRT stack 时，要始终说明是虚拟机的 CRT stack 还是 C 函数的 call stack)。从这个角度来说，embedded/extension 语言更倾向于选择 stackful 设计。但 stackful 设计的固有缺陷在于 stack 结构是平台相关的，很难用跨平台的方式实现诸多功能，比如协作式多任务 (cooperative multi-threading)，跟踪垃圾回收 (tracing-GC)，lexical closure。尽管不是全部原因，Python 缺少诸多高级特性与其 stackful 实现有很大关系。\\n\\n为了遵守 ANSI C 的跨平台性和更好的实现高级动态功能，Lua 采用了 stackless 实现。这给处理 C 代码的 call stack 带来了一些挑战。Lua 的 stack 存储在 struct lua_State 的 stack field 中，是一个 TValue* 的数组。其内容包括：\\n\\n函数指针。Proto* (Lua 函数) 或者 lua_CFunction (C 函数)。注意函数指针不是函数的返回地址。\\n函数的参数和返回值。包括 Lua 和 C 函数之间传递的参数和返回值。\\nLua 函数的局部变量。\\n在这个 stack 上缺少一些属于 call stack 的东西：\\n\\nC 代码本身的 call stack。\\n函数的返回地址。\\nStack frame 信息，类似 SFP。\\n这是因为 Lua 采用了双 stack 结构。对应的 stack frame 信息存储在一个 struct CallInfo 链表中，每个节点对应一个 stack frame，它对 TValue* 数组 stack 的描述如下：\\n\\nField func 表示 stack frame 在 TValue* 数组上的起始位置 (之所以用 func 作为 field 名称是因为在 TValue* 数组上这个位置永远是函数指针)，field top 表示结束位置。\\nField union u 存储和函数类型相关的信息。Lua 函数信息存储在 u.l 中，C 函数在 u.c 中。\\nu.l.savedpc 表示函数的返回地址。这个值仅当 Lua 函数作为 caller 的情况有效。C 函数作为 caller 时，返回地址在 CRT stack 中。\\n当 C 函数中发生 yield 时，CRT stack 被破坏，该 coroutine 下次被 resume 的执行地址由 u.c.k 来承担。详见《 Programming in Lua（三）－ Yields in C 》。\\n这里值得多说一句，为什么在 C 函数中执行 yield 会破坏 CRT stack？上文说过，Lua 的设计主要是 stackless 方式，其具体实现是通过 luaV_execute() 中的循环执行 byte code，通过额外数据结构 (其实是双数据结构) 而非 CRT stack 来维护 call stack。但在 resume coroutine 时，luaV_execute() 间接地递归调用自己并在 callee 的循环中执行 resumed coroutine。也就是说由 CRT stack 来维护 coroutine 上下文切换。Yields 的机制是 longjmp 回到 luaV_execute() 函数递归调用自身的下一条指令 (虚拟机的 native 指令而非 byte-code 指令)，同时把 CRT stack 恢复到 resume 前的状态。所以 yields-in-C 会破坏 C 函数的 call stack。\\n\\n尽管 coroutine 涉及了对 CRT stack 的操作，但是和 error 一样，仅限于 ANSI C 支持的 longjmp，不会破坏 Lua 虚拟机的跨平台性。问题是，为什么 Lua 要在总体的 stackless 设计中制造这个 stackful 例外？首先退一步说，即使采用 stackless 方式实现 coroutine 切换，仅仅能避免在 yields-in-byte-code 中使用 longjmp，仍然无法避免在 yields-in-C 中使用 longjmp。这是因为，虽然不再有必要 longjmp 回到最近一次 resume 之处，但是仍然需要从 yield 之处回到最近的 Lua 虚拟机代码。不仅如此，stackless 方式还要给 resumes-in-C 引入类似的 longjmp (因为不再利用 CRT stack，所以 resumes-in-C 也必须立即回到 Lua 虚拟机代码)，破坏调用 resume 的 C 函数的 call stack，给 resumes-in-C 加上同现在的 yields-in-C 一样的局限性。而现在的 stackful 方法则完全没有这方面的问题。这正是无需 lua_resumek() 的原因。Stackful coroutine 是一个非常巧妙的设计。\\n\\n2013/05/09\\t Leave a reply\\nProgramming in Lua（四）－ Nil 和 List\\n\\n粗浅地看，Lua 的 nil 很容易被等同于「无」。如下面这段代码：\\n\\nfunction r_nil()\\n    return nil\\nend\\n\\nfunction r()\\n    return\\nend\\n\\na = r_nil()\\nb = r()\\n\\nprint(a .. \\", \\" .. b)  -->  nil, nil\\n尽管函数 r_nil() 和 r() 的返回语句分别带有和不带有 nil，接受它们返回值的变量 a 和 b 的值都是 nil。另一个例子是 nil 对 table 的作用。\\n\\ntab_v = { attr1 = 1, attr2 = 2 }\\nfor k,v in pairs(tab_v) do\\n    print(k .. \\", \\" .. v)\\nend  -->  attr1, 1\\n     -->  attr2, 2\\n\\ntab_v.attr1 = nil\\nfor k,v in pairs(tab_v) do\\n    print(k .. \\", \\" .. v)\\nend  -->  attr2, 2\\n将 table 的一个 field 赋值为 nil 不仅仅改变其值，而是让这个 field 本身消失了 (这个例子中是 field attr1)。\\n\\n分析 nil 的实际含义可以从 Lua 的另一个比较特殊的概念 —— list 入手。List 的特殊性在于它不是 first-class 类型。「First-class」是动态语言中常被提及的概念。编程语言有越多的构成元素符合 first-class 标准，其概念模型就越一致、越简单。Lua 的基本数据类型 (包括 nil) 和函数都符合 first-class。满足 first-class 标准通常有四个要求：\\n\\n可以被赋值给变量；\\n可以作为参数；\\n可以作为返回值；\\n可以作为数据结构的构成部分。( 注意 nil 并不完全符合这个要求，但是可以通过某个 field 的缺失来表示 nil。)\\n在《Programming in Lua, 2ed》的第 5.1 节提到 list 只能用于四种情形：\\n\\nThese lists appear in four constructions in Lua: multiple assignments, arguments to function calls, table constructors, and return statements.\\n\\nList 有两种具体的表现形式，一种是用逗号分割的一组表达式，表示一个具体长度的 list；另一种是三个点构成的省略号 (...)，表示其长度和内容不定。第二种表示方式不能用在 multiple assignments 的等号左方，也不能创建新 list，只能从函数的形式参数列表中获得。由此可以看出，list 不符合 first-class 标准：\\n\\n它的部分内容可以赋给几个变量，但本身不能作为整体赋给变量；\\n它是参数列表的全部或一部分，但不是任何参数 (注意两者的区别)；\\n它不能作为数据结构的构成部分。注意，「...」不能作为 closure 的 upvalue。用 first-class function 存储 list 的方式行不通。\\n作为非 first-class 类型，list 无法被生命周期较长的数据结构存储。短期的完整传递 list 的内容只能利用函数调用/返回的方式：\\n\\nfunction f_outer(...) -- important: f_out() must accept\\n                      -- \\"...\\".\\nend\\n\\nf_outer(f_inner())\\n-- pass the list returned by f_inner() to\\n-- f_outer() as the latter\'s argument list\\n\\nf_outer(1, 2, f_inner())\\n-- pass f_outer() a new list, which is \\"1, 2\\" appended\\n-- by f_inner()\'s returned list\\n\\nfunction f_caller(...)\\n   f_callee(...) -- pass argument list of f_caller()\\n                 -- to f_callee()\\n\\n   return f()    -- pass list returned by f() to one\\n                 -- level up\\nend\\n另外还有一些反例：\\n\\nfunction f_caller(...)\\n   a, b = ...   -- not pass a list, \\"a, b\\" is\\n                -- a different list of two elements\\n                -- obtained by adjusting the \\"...\\",\\n                -- and this list is very short-live,\\n                -- existing in this line only\\n\\n   tab = {...}  -- not pass a list, tab won\'t\\n                -- have fields for nils in the \\"...\\"\\n\\n   local function test(a, b)\\n   end\\n   test(...)    -- not pass a list, test()\'s\\n                -- argument list accepts only the first\\n                -- two items of \\"...\\"\\n\\n   for i in ... do  -- the \\"for\\" uses only the first\\n                    -- three elements in \\"...\\"\\n                    -- (two accepted by for internally,\\n                    -- and one received by i)\\n   end\\nend\\nList 会成为 Lua 中为数不多的非 first-class 类型是因为它实际代表了 stack 上的一段数据。一般只有动态分配的数据能作为 first-class 类型，操纵 stack 上的数据则只能通过函数调用的参数和返回值等有限的方式进行 (这也是因为 stack 在一定程度上代表了程序的 continuation)。不过在其它语言中，stack 的内容并没有被抽象为类似 list 这样可以被操作 (尽管不能像 first-class 类型那样自由地操作) 的概念。因为 Lua 提供了多返回值，鼓励可变参数以及参数/返回值和 table 的互相转化，特别是它著名的 C 接口就以 stack 为中心来设计，所以它有了独特的 list 概念来操作 stack。\\n\\n如果在 Lua 中一定要将 list 和 first-class 混用怎么办呢？比如说，一个函数返回的 list 通常还是要存储在变量中，或者应用在某个表达式中。这是上面的反例代码中已经提及的机制 —— adjustment。Adjustment 并不是真的传递一个 list 的内容，而是用一个 list 的内容构建另一个新的 list。当新 list 的长度小于原 list，多余的值被丢弃，当新 list 长度大于原 list，就用 nil 补齐。\\n\\nLua 的 nil 担当了三种角色：\\n\\n一般的数据类型，通常标志某种特殊情况 (应用或算法本身的特殊情况，而非语言的特殊情况)。\\nTable field 的删除器。\\nList adjustment 的补全值。\\nLua 的 nil 不代表「无」，反而恰恰起到了「有」的作用。在应用 adjustment 的情况下，我们往往用新 list 末尾的 nil 来判断原 list 的「无」。这个做法有一个缺陷：无法辩别原 list 末尾本来就确实含有的 nil。如果需要区别对待 list 结束和 list 本身含有 nil 这两种情况，既可以自行编写 C 代码来检测 stack，也可以使用 Lua 现成的 API select()。回到第一个例子，稍加修改就可以区别两种情况：\\n\\nfunction r_nil()\\n    return nil\\nend\\n\\nfunction r()\\n    return\\nend\\n\\na = select(\\"#\\", r_nil())\\nb = select(\\"#\\", r())\\n\\nprint(a .. \\", \\" .. b)  -->  1, 0\\n下面是精确区别 list 结束的一个实际例子 —— 关于 stack 的递归终止条件。若希望一个函数对它的 argument list 中的每个参数执行 op() 操作：\\n\\nfunction map_list(op, ...)\\n    if select(\\"#\\", ...) == 0 then\\n        return\\n    else\\n        local a = ...\\n        return op(a), map_list(op,\\n                               sub_list(...))\\n    end\\nend\\n函数 sub_list() 返回的 list 是其接受的 argument list 去掉第一个元素。这个函数的实现如下 (如果用 C 语言来实现会更简单)。如果 op() 允许接受 nil 并且在此情况下返回有意义的值，或者 map_list() 接受的 list 在中间含有 nil，那么 map_list() 的递归终止条件就必须基于 select() 而不可以基于对 nil 的判断。\\n\\nfunction sub_list(...)\\n    local list_start\\n    function list_start(start, ...)\\n        if start > select(\\"#\\", ...) then\\n            return\\n        else\\n            return select(start, ...),\\n                   list_start(start + 1, ...)\\n        end\\n    end\\n    return list_start(2, ...)\\nend\\nList 是 Lua 中最不符合 first-class 的数据类型。但由于其不能作为变量但可以被函数的返回值构建的特性，List 反而可能是 Lua 中最纯粹的 functional programming  元素。放弃 table 而完全用 list 来编写 Lua 程序也许是把 Lua 转化为一种 FP 语言最简单的手段。\\n\\n2012/12/22\\t Leave a reply\\nProgramming in Lua（三）－ Yields in C\\n\\nHandling Yields in C 是 Lua 5.2 的重大改进之一，最早从 blog《Lua 5.2 如何实现 C 调用中的 Continuation》了解到。这些资料围绕新 API lua_yieldk，lua_callk，和 lua_pcallk 来介绍这个新特性，自然有很多关于新增加的 continuation 参数的讨论。其实以 continuation 参数作为切入点介绍 yields-in-C 容易混淆问题的实质。首先回顾一下《Programming in Lua, 2ed》(中文版) 中的一段话 (第 30.1 章)：\\n\\nThe only way for a C function to yield is when returning, so that it actually does not suspend itself, but its caller — which should be a Lua function.\\n\\n这段话针对 Lua 5.1 而写，当时尚无 continuation 参数。严格地说这会误导读者。根据描述本身，可以理解为 Lua 无法在 C 代码中 yield (包括被 C 代码再次调用的第二层 Lua 代码以及之后的 stack 上更深的执行层次) 是因为无法纪录这种情况下 resume 所需的信息 —— C 代码的 stack 和 program counter。这种解释的推论是，在 C 代码即将返回 Lua 前，由于 C stack 已经恢复为调用前的状态 (可以称为「空 stack」)，program counter 也处于即将进入 Lua 代码的状态，所以可以调用 lua_yield。原理上这个结论可以推广到 lua_call/lua_pcall。如果程序在 Lua 和 C  代码之间调用切换多次，整个 virtual stack 上的 Lua 部分的 stack 会被 C 代码分割成若干段。不过只要这三个 API 总是在 C 代码即将返回 Lua 前被调用，那么这些 C stack 都是空 stack，Lua VM 只需知道 C 代码在 Lua stack 段间的位置，不需要实际纪录 C stack/program counter 本身的内容。「在多于一层 C/Lua 切换的情形下 yield」应该正常工作。\\n\\n问题是 Lua 5.1 不支持「在多于一层 C/Lua 切换的情形下 yield」！\\n\\n根据上面的分析，这个限制并非 Lua 语言或 C API 本身的设计所固有，它是一个纯粹的 VM 实现问题。也就是说，即便 Lua 在 5.1 之后不引入 continuation 参数，保留「lua_yield (以及 lua_call/lua_pcall) 只能在即将返回到 Lua 之前调用」这个限制，也还是可以支持从 C 或者从第二层及以上的 Lua 代码中 yield。\\n\\nLua 5.2 实现了「在多于一层 C/Lua 切换的情形下 yield」，这是一个 VM 内部改进，仅仅为此并无必要引入 continuation 参数。 Continuation 参数解决的是另一个问题 ——「Lua 无法跟踪程序在 C 代码中的 stack 和 program counter」，但仍保留诸多限制：首先，它无法解决纪录 C stack 的问题，所以，仍然不允许在 C stack 上有多于一层 C 函数时调用新 API；其次，它也无法纪录 program counter，编写 C 代码时必须手工把可能发生 yield 之后的 C 代码 factor 到一个单独的 C 函数中，通过函数分割这种变通方式部分的模拟 yield 时的 program counter。由于没有真正的管理 C stack，充当 continuation 参数的 C 函数在运行中不能依赖 caller 的 C stack (实际上这个问题不大，因为它只能接受一个 lua_State 结构)。最后，仿照某些评测给 Lua 5.2 的新特性做一个「优雅 / 有待改进 / 丑陋」的总结：\\n\\n优雅\\n\\n实现了「在多于一层 C/Lua 切换的情形下 yield」。对于「Lua 无法跟踪程序在 C 代码中的 stack 和 program counter」这个问题的剪裁得当，既扩大了支持的应用场景，放松了对 C 代码的限制。同时避免了编程接口过分复杂化，和使用底层 C runtime 机制破坏 VM 的跨平台性。\\n\\n有待改进\\n\\n文档没有分别说明两个问题，混淆了 VM 内部实现的改进和 API 改变的原因。\\n\\n丑陋\\n\\n新 API 在 continuation 参数为 NULL 时沿袭旧 API 的限制 —— 禁止在多于一层 C/Lua 切换的情形下 yield。这是不必要的，也是混淆两个独立问题的误解最大的来源。现在，对于那些已经在「即将返回 Lua 之前」被调用的 lua_yieldk/lua_callk/lua_pcalk，也必须传入一个 no-op 的 continuation 函数。不过，Lua 5.2 的发布已经有段时日，估计这个 API 上的小问题也不会再未来更改了。\\n\\nProgramming in Lua（二）－ 异常与错误码\\n\\n我不喜欢编程语言用「异常处理 (exception handling) 」的方式处理错误。从以往经历看，先有 C++ 创造了最差的异常实现 —— 没有 GC 帮助内存管理，扰乱 C 的二进制接口 (Application Binary Interface, ABI)。为了绕过这个拖累，维护 C++ 代码往往要花费双重开销来完成没有异常的语言可以免费获得的东西：code review 必须保证代码的「异常安全 (exception-safty)」[1]，同时不写会抛出异常的新代码。\\n\\nJava 提供了 GC，解决了安全实现异常处理最大的的先决条件。不过凡事皆 checked-exception 的方式令人毫无好感 [2]。Objective-C/Cocoa 中没有跨越 block 的异常机制，基本上采取传统的返回错误码方式，让我舒了一口气。但是接下来，Lua 通过 longjmp 实现跨函数的类似异常处理。一方面，让我怀疑 Lua 以简洁著称的设计是否在这点上采取了错误方式；另一方面，longjmp 并未实际引起麻烦，让我好奇异常处理是否也有某些价值。\\n\\n异常处理和传统的返回错误码 (error code) 两种处理错误的方式是一场持久的争论。就在最近，围绕 Go 语言完全抛弃异常处理的语言特性，《Why I’m not leaving Python for Go》的作者表了极大失望。\\n\\nRuss Cox 针对上文为 Go 语言进行了辩护。其中提到了 Raymond Chen 两篇旧日的 blog：\\n\\n《Cleaner, more elegant, and wrong》\\n《Cleaner, more elegant, and harder to recognize》\\nRaymond Chen 用严密的逻辑和实例说明了编写正确异常处理的代码 [3] 非常非常困难。特别要注意 (但不限于) 以下两点：\\n\\n正确管理资源，特别是资源的回收；\\n关键数据的修改尽可能滞后。在中间可能抛出异常的步骤中，随时保证数据处于一致 (integral) 的合法状态。\\n关注第一点也许会令人假定，如果程序不涉及内存以外的资源，并有成熟的内存管理机制，就足以保证写出正确的异常处理代码。毕竟把异常处理放到 feature list 中的语言无不首先重视提供 GC 机制。由于需要根据异常的 stack unwinding 情形考虑内存回收，这些语言一般采用 root-tracing GC 而非 ref-counting [4]。但是，将资源管理局限于内存并不足以对第二条豁免，比如复杂的图结构 (graph structure)，或者更常见的情形：对象需要向多个相互关联的全局表注册自身的引用。而且话说回来，「纯」内存数据操作除了内存用尽 (out of memory) 之外又有什么值得担忧的错误需要处理呢？归根结底异常处理是一个主要面向 I/O 问题的机制。\\n\\n在「纯」内存无 I/O 的环境下，能体现异常处理价值的领域并不多，仅存的适用领域之一是语言虚拟机。这正是 Lua 采用 longjmp 类似异常处理的原因，主要用于类型检查和数组越界等语言虚拟机问题。而且这时处理的错误往往不是最终产品代码 (production code) 期待的行为，并不真正用来弥补错误，只是起一些辅助作用，比如揭示 bug 和收集诊断信息，防止应用完全退出，在多文档应用中让用户有机会保存其它信息，或者让应用以 reset 之后的状态接受其它请求。类似于 Go 中的 panic 机制和 Java 中的 runtime-exception (unchecked excpetion)。\\n\\nGC 虽然是实现安全的异常处理机制的先决条件之一，但只是朝向最终解决问题的很小一步。因为真正能体现异常处理价值的地方是 I/O 密集程序。有哪些 I/O 机制目前可以做到「关键数据的修改尽可能滞后。在中间可能抛出异常的步骤中，随时保证数据处于一致的合法状态」呢？作为 naive 的尝试，C++ 提出了 RAII。但是很遗憾，异常安全的需求明显超出了 RAII 的能力。除了关系型数据库事务处理 (RDBMS transaction) 的二步式提交 (two-phase commit)，我不知道还有什么 I/O 机制满足这个要求。也就是说，在日常需要的软件工具中包括图形化窗口化 UI，网络，打印等等常见 I/O 操作中，只有纯粹的数据库 CRUD 系统这个特殊领域适于异常处理机制。正因为如此，非数据库的 I/O API 的错误处理都应该采取返回错误码形式。特别是，以异常处理文件访问错误的 API 都是失败的设计 [5]。Java 正是被鼓吹适合数据库 CRUD 领域，所以其异常处理机制获得了一些正面评价。但是当其野心不限于此时，将仅限于数据库领域用的还不错的异常处理机制匆忙的推广到其它问题就招致了恶名。\\n\\n某些系统通过异常处理或者类似异常处理的机制来解决某些问题，而且解决得还不错。这是它们的设计者针对一些能体现异常处理价值的特定领域选择的方案。这些成功案例并不能简单地推广。保守地说，要采用异常处理，必须保证所有资源置于二步式提交的事务管理之下；或者限于虚拟机内部对类型检查等非 I/O 操作的「粗粒度」错误处理。「粗粒度」表示一旦发生错误，系统采取的应对策略是放弃整个粒度较大的操作，异常处理仅仅保证程序不退出，收集 bug 诊断信息，或者保留机会处理其它请求，而不是去弥补刚发生的错误。特别是对于 Lua，这个问题还有一层含义。Lua 允许用 C 编写扩展。这种情况下要把基于 longjmp 的异常处理部分限于开始的参数类型检查，置于触及关键数据和 I/O 操作之前，一旦 C 代码涉及了实质的数据和 I/O 操作，错误处理方式就必须变为返回错误码机制。Lua 支持多返回值特性正是为返回错误码方式的应用提供便利。显然，Lua 的可扩展性也是其基于 longjmp 的机制彰显天下的原因，对于 Java 来说，虚拟机内部的具体实现和使用它的程序员是毫不相关的。\\n\\n脚注：\\n\\nC++ 中所谓的「异常安全」也不过就是尽量使用 on-stack 对象 (以及基于 on-stack 对象的「智能」指针) 和 RAII (下文还有涉及) 而已。\\n错误处理有经常被人混淆的两个方面。一是如何保证程序员不忽略可能的错误；二是在程序员意识到可能的错误时，如何编写正确的处理代码。本文只讨论第二个方面。因为，如何「不忽略可能的错误」属于程序员掌控应用逻辑的问题，已经超出了编程语言的能力。Java 的 checked-exception 试图用语言解决这个问题，但是即便是 checked-exception，也允许程序员相当容易的把异常遗留给上层 caller。其结果是，越多的错误集中在一处处理，而且远离错误发生的地点，这段异常处理代码的正确性就越难保证 (或者这段代码除了 crash/quit 无法做任何其它有意义的工作)。也许，这正是没有任何其它语言借鉴 checked-exception 机制的原因。\\n注意这里的「异常处理的代码」指程序员用具备异常处理机制的语言编写处理实际错误的代码，不要和异常机制本身的实现混淆。\\nObjective-C/Cocoa 舍弃异常处理的可能原因之一。另一方面，如果在 stack unwinding 时进行特定的处理，也可以用 ref-counting GC 配合异常。比如 C++ 调用 destructor 以及由此衍生的「智能」指针，还有 Python 的机制。但是我不喜欢这种将 unwinding 复杂化的机制。\\n导致每行一个 try-catch block。\\n"}'));jctx.push(JSON.parse('{"id": "180410", "tag": "lang", "text": "# JS和AWK语言的new和delete\\n\\n## new\\n\\n在JavaScript中，使用new关键字后，意味着做了如下四件事情：\\n\\n1. 创建一个新的对象，这个对象的类型是object；\\n2. 设置这个新的对象的内部、可访问性和prototype属性为构造函数（指prototype.construtor所指向的构造函数）中设置的；\\n3. 执行构造函数，当this关键字被提及的时候，使用新创建的对象的属性；\\n4. 返回新创建的对象（除非构造方法中返回的是‘无原型’）。\\n在创建新对象成功之后，如果调用一个新对象没有的属性的时候，JavaScript会延原型链向止逐层查找对应的内容。这类似于传统的‘类继承’。\\n\\n注意：在第二点中所说的有关prototype属性，只有在一个对象被创建的时候起作用，比如使用new关键字、使用Object.create、基于字面意义的（函数默认为Function.prototype，数字默认为Number.prototype等）。它只能被Object.getPrototypeOf(someObject)所读取。没有其他任何方式来设置或读取这个值。\\n\\nLua也是基于原型的语言，虽然它并没有自带new关键字，但可以从第三方库看到模拟。比如loop库的实现，就执行了 `setmetatable(object or {}, class)`，使用一个现有或创建新对象，并将这个对象的元表指向另一个表，关键特性和JS一样。\\n\\n由此可以看明显看出和基于原型和基于类的构造差异。比如C\\\\+\\\\+的new，第一步类似，开辟一段新的空间存放对象，不可能有第二步设置原型指向动作，直接把这块新的空间作为this指针执行构造函数，最后返回对象相同。\\n\\n## delete\\n\\n带有垃圾回收的语言，很大的好处分配对象不需要手动考虑回收的问题。但JS和AWK的关联数组对象，允许用delete语法手动删除某个指定元素，GNU的AWK扩展还允许用delete obj;这种语法把obj内的所有key value对一次性全部删除。\\n\\n须知GC的运作要依赖对象的可达性或计数值，但不论是哪种，关联数组内的成员的生命周期都受外层变量的控制，无法单独的让GC去释放。类似的问题还出现在函数的upvalue上，只是因为upvalue是匿名的，而且和函数模拟的对象有密不可分的关系，因此只针对关联数组提供了delete语法。\\n\\n之所以会想到这个问题，是因为lua5.4的work1版有个很大争议的改动：table中nil到底是什么语义。到5.3版本为止nil是相当于delete语法的作用，但这就产生了另一个不一致，nil作为基本类型却无法放入table中。这种不一致让语言的作者觉得是个必须要解决的问题。\\n\\n比较两种语言的使用方式，这大概就是delete存在的意义吧。\\n\\n## 附：AWK语言\\n\\n在shell中诸多工具中，AWK是相对功能最丰富的工具，只有它可以创建函数。整体代码结构由复数个awk rule和可选的函数定义组成，每个rule由pattern和action两部分构成。pattern可以省略，默认捕获整行，action就是要做的动作。最常用的pattern是匹配一行中某部分的内容；另外有两个特殊的pattern，分别是BEGIN和END。如果只有BEGIN块，AWK会跳过读文件步骤，此时相当于执行脚本自身，可以利用这个特性，执行一些略复杂的逻辑。但如果除了BEGIN外还有END块，awk会默认附加一条打印输入行的行为，执行后会停留在读stdin阶段。\\n\\n整个脚本会编译两次，先找出函数定义，再编译awk rule（和JS有点类似）。所以函数块可以放在任何位置，为了不遮挡主体逻辑，建议把函数块放最后。示例如下\\n\\n```\\npattern {\\n   action\\n}\\nfunction xxx() {\\n}\\n\\npattern := BEGIN | END | /regex/\\n```\\n"}'));jctx.push(JSON.parse('{"id": "180413", "tag": "lang", "text": "# C++类的访问控制符与引用\\n\\n`C++`类的public/private是范围式的，从一个声明符直到下一个声明符之间的所有变量、函数的可访问性是一样的。而Java是针对每个函数需要显式写出访问控制符。初看之下似乎两者没有大的区别，甚至`C++`的范围式控制还可以少打几个字，直到最近我才意识到`C++`的控制方式在隐藏信息上存在的缺陷。\\n\\n比如声明一个接口类，通常来说最先思考的肯定是类的对外可以提供的功能，即public区域的函数。定义好这些函数后，就开始着手实现。但是在实现的过程中，如果公开函数的语义包含的操作较多，肯定会进行拆分，这些被拆分出的函数当然是private级的。但是当你在cpp文件进行函数拆分后，却会遇到代码无法编译通过的问题，原因就是在类声明中没有定义这个private函数，于是一方面，你要切换到.h去声明这个仅仅为了可读性而提炼出来的函数，而且可能因为函数命名比较随意，直接暴露出去又不是本意。\\n\\n为什么在编译器层面，不能省略声明呢？还是由class的特性引起的。由于对OO特性的理解：封装、继承、多态，这3大特性被语言级别地支持了。封装就体现在public/private上。如果一个函数没有声明就直接实现函数体，编译器不能也不敢随意地给这个函数确定可访问性，于是这个问题被抛回给了代码编写者。因此类的每一个细节就必须在头文件中暴露出来。这也是为什么`Effective C++`这么推崇pImpl法则的原因。\\n\\n所以`C++`的访问控制只是阻止了人为的调用，但无法阻止人看到内部函数。要想完全地隐藏细节，必须先声明一个只有public的函数，然后在实现时，继承这个类，把私有函数在继承类中声明，这个继承类不公开，如此才能做到细节的隐藏。\\n\\n反观Java，由于访问性是函数级别，完全可以在实现时直接把这个被拆分的子函数声明为private。话说Java好像也没有头文件和实现分离这回事。\\n\\n## 引用\\n\\n「引用」是被 operator overload 逼出来的。在 operator overload 出现之前，Bjarne Stroustrup 从来，从来没有想过要引入「引用」。因为引用的所有用途都可以被指针代替。\\n\\n而且 Bjarne 是最烦增加新元素的。像 C++14 里那个「= delete」我以前都没想到这辈子能在 C++ 里出现。因为 Bjarne 当年死认为把 constructor 放到 private 就行了。\\n\\n「引用」也不能防止空指针。大型代码动辄传递指针引用好几层，其中完全可以有一层是空的。具体代码我就不放了。\\n\\n自从 Bjarne 铁了心要做 operator overload 之后，一个问题就是像 「=」，「+=」这样的自修改操作怎么传参。你要不要写成：\\n\\nA a;\\n&a += 1;\\n这哪行？（上面这种代码是 Bjarne 论证引用的必要性的时候自己在书里写的。）\\n\\n所以就有了引用。\\n\\n至于其它用法都是废物利用吧。"}'));jctx.push(JSON.parse('{"id": "180421", "tag": "protocol", "text": "# 浏览器对文件的处理\\n\\n协议工作经常遇到Web开发问及如何处理二进制数据的问题，查了资料并记录。\\n\\n最早的HTML浏览器实现，是李在1990年实做的，IETF在93年中发布了相关草案，在95年11月24日发布的HTML2.0规范RFC1866，这份规范的内容非常简洁，只有77页。它定义了HTML的MIME类型、基本元素，紧接着在次日，发布了名为《HTML中基于表单的文件上传》的1867。后来的RFC1942又扩充了table的表示法。\\n\\n1866的HTML表单规范为INPUT元素的TYPE属性定义了八种可能的值，分别是：CHECKBOX, HIDDEN, IMAGE, PASSWORD, RADIO, RESET, SUBMIT, TEXT。另外，当表单采用POST方式的时候，表单默认的具有\\"application/x-www-form-urlencoded\\" 的ENCTYPE属性。1867则建议对HTML做出了两处修改：\\n\\n1. 为INPUT元素的TYPE属性增加了一个FILE选项。\\n2. INPUT标记可以具有ACCEPT属性，该属性能够指定可被上传的文件类型或文件格式列表。\\n\\n另外，本建议还定义了一种新的MIME类型：multipart/form-data（因为urlencoded效率太低了），以及当处理一个带有\\nENCTYPE=\\"multipart/form-data\\" 并且/或含有`<INPUT type=\\"file\\">`的标记的表单时所应该\\n采取的行为。\\n\\n由于ENCTYPE不同，每个文件都必须配备一个单独的表单。不能和文本类的form共用一个表单。\\n\\n随着HTML的发展，IETF也就是RFC的责任方决定将它交给W3C组织专门维护，也就没有RFC来记载HTML的描述了。\\n\\n## 上传\\n\\n时间来到了HTML5标准，file元素配合FileReader对象，有了更多的变化。通过getElementById拿到这个file对象后，一个files的数组(虽然我没见过支持多文件选择，也许是为了以后扩展吧)，取`files[0]`就是文件对象，这个对象可以传到FileReader.readAsXXX。由于JS的异步属性，读取到的内容惯用法是在回调函数中返回\\n\\n```\\nreader=new FileReader;\\nreader.readAsDataURL(files[0]);\\nreader.onload = function(){ this.result;// this指向reader，读取成功onload，不考虑成功失败，用onloadend也行}\\n```\\n\\n奇怪的是即使用二进制读出图片数据，再用base64转换得到的长度始终有问题，只能用DataURL获取图片，原因未知。\\n\\n## 下载\\n\\n静态方式的下载用href标签可以实现`<a href=http://www.xx.com/xx.zip>点击下载</a>`，但是问题不少，用PHP实现，核心代码\\n\\n```\\n  header(\\"Content-Type: application/octet-stream\\");\\n  header(\\"Content-Length: \\".$fsize);\\n  header(\\"Content-Disposition: attachment; filename=xx.zip\\" );\\n  @ob_clean();\\n  flush();\\n  readfile($f);\\n  exit;\\n```\\n\\n把文件类型改成octet，然后用readfile函数把文件写入标准输出流，由于PHP的stdout已经绑定到HTTP连接，客户端就能得到完整的文件。通常Content-Length是规范要求必须有的，没有的话浏览器也会兼容，但下载过程中无法显示总长度和当前进度。标准中这个字段表示传输过程中的长度，嚼字眼的话说明不是文本的原始长度，比如开启了gzip压缩，传输长度和实体长度就不一样，如果PHP外面的nginx又套了gzip，由于nginx无法事先知道要代理的内容长度，干脆全部用chunk方式传输，此时Content-Length会被chunk遮蔽，也不会有问题。"}'));jctx.push(JSON.parse('{"id": "180423", "tag": "net", "text": "# TCP的状态与nc的理解\\n\\nTCP的状态多达11个，4个连接7个关闭。之所以会这么复杂，是因为TCP作为双向全双工协议，读写端是完全独立的，建立连接的过程不区分，所以相对简洁一些，一旦连接建立后，分化出读写两个管道，要关闭这两个独立的管道，会经历不同的状态，显然复杂度会翻倍。调用close()只能主动关闭写管道，读端会被动一些。\\n\\n| 写关闭状态 | 说明 | 读关闭状态 | 说明 |\\n| --- | --- | --- | --- |\\n| FIN_WAIT1 | 发送FIN给对端，关闭写道道 | CLOSE_WAIT | 收到FIN，关闭读通道 |\\n| FIN_WAIT2 | 收到对方的ACK，但还没收到对方的FIN | LAST_ACK | 读端Only，收到FIN后自动触发close进入该状态，并等待ACK，网络中断时才会出现 |\\n| TIME_WAIT | 收到对方的FIN | | |\\n\\n还有两个状态是读写端都会有\\n\\n* CLOSING  本该收到对端ACK却收到FIN，发ACK给对方，就会进入最终的CLOSED\\n* CLOSED  收到FIN后再过2个MSL才可以彻底关闭\\n\\n说完TCP的双工性，来看看nc，从它的简述`Concatenate and redirect sockets`能看出，nc也是利用了socket的双工性再连接了shell的stdin/stdout，实现了像反弹shell这样的魔法。"}'));jctx.push(JSON.parse('{"id": "180501", "tag": "lang", "text": "# JS模块化历史\\n\\n在2009年1月，Mozilla的程序员Kevin Dangoor发起了名为ServerJS动议，这是最早的模块规范。同年8月更名为CommonJS。为了适应浏览器环境，慢慢发展出了异步加载的AMD规范，最初是被挂在CommonJS下面，后来因为两个环境差异实在太大，最终分道扬镳。Dojo库率先实现了这个规范。最晚到2011年10月中旬已经有多个库支持AMD规范。\\n\\nCommonJS定义了require和exports，而AMD定义了define。\\n\\n## node\\n\\nnode诞生于2009年5月27日，ES6的标准化则迟至2015年6月，由于node出现在前，发展出一套自己的require加载语法，不能和ES6的语法混用。\\n\\n假设Y是路径，X是文件名或目录名，当 Nodejs 遇到 require(Y+X) 时，按照下面的顺序处理：\\n\\n1. 如果 X 是核心模块（例如：require(\\"http\\"), path, buffer）\\n\\n\u3000\u3000a.返回该模块\\n\\n\u3000\u3000b.不再继续执行\\n\\n2. 如果Y是以“./”、“/”或“../”开头\\n\\n\u3000\u3000a.把X当成文件，从指定路径开始，依次查找下面文件：X、X.js、X.json、X.node，只要其中一个存在，就返回该文件，不再继续执行\\n\\n\u3000\u3000b.把X当成目录，从指定路径开始，依次查找下面文件：X/package.json(main字段)、X/index.js、X/index.json、X/index.node，只要其中一个存在，就返回该文件，不再继续执行\\n\\n3. 如果 X 不是核心模块，也没有以“./”、“/”或“../”开头，则Nodejs会从当前模块的父目录开始，尝试从它的 /node_module 目录里加载模块，如果还是没有找到，则移动到再上一层父目录，直到文件系统的根目录\\n\\n4. 抛出“not found”\\n\\n通过debug/inspect模式会发现执行文件的语句，在node内部变成一个立即函数调用，像这样\\n\\n```\\n(function (exports, require, module, __filename, __dirname) {your code}\\n```\\n\\n这就很好理解，为什么每个脚本都会有5个预定义变量了。同一个文件直接运行和被require时，module对象被解释成不同的含义。比如test.js，运行node test.js，module.parent的值是null。而node -e \\"require(./test.js)\\"，module.parent的值就指向另一个module，这个module是命令运行产生的，id是`[eval]`，如果不用-e，会打印对应的文件名。\\n\\n## ES6\\n\\n使用export(注意不是exports)和import关键字。\\n\\n## 差异\\n\\nnode的require是动态加载，用if (x>1) else可以加载不同的模块，而ES6的import则不行。\\n\\nnode加载的是值，即使模块的值变化了，不会影响node中已加载的地方。而ES6是引用加载，会受模块影响。"}'));jctx.push(JSON.parse('{"id": "180510", "tag": "lang", "text": "# 实战flex和lemon要点\\n\\n以前写过flex和bison的实战，这两个工具出现在70年代，bison生成的主函数入口名只能是int yyparse(),内部强制调用yylex函数，语法驱动词法，传递数据使用全局变量的形式，从代码美学角度看相当令人不快。最近学习了SQLite项目下的lemon，从语法分析上来说比bison更简洁一些。PHP开发组在10年曾发起动议用lemon替换bison，不过后来不知何故不了了之。使用lemon配合flex可以直观地解决重入问题，bison也可以，但略复杂。\\n\\n先说flex生成可重入代码的方式，使用`flex -R`或者用%option reentrant都能达到效果。生成的函数原型变为`int yylex (yyscan_t yyscanner);`。通过yyget_text(yyscanner)和yyget_leng(yyscanner)的调用方式，取代了以往全局变量yytext和yyleng的使用方式。\\n\\n在使用前后要分别调用`yylex_init`和`yylex_destroy`。如果要指定输入文件，用`yyset_in`函数(非重入版也有这个函数)。和lemon配合时，flex是驱动者，每条规则匹配的执行动作不需要return，而是在执行动作中从yyscanner提取token，处理并交给lemon进行解析。\\n\\nlemon只是生成解析函数，被词法驱动调用，函数原型如下，函数名可以自定义。\\n\\n```\\nvoid Parse(\\n  void *yyp,                   /* The parser */\\n  int yymajor,                 /* The major token code number */\\n  ParseTOKENTYPE yyminor       /* The value for the token */\\n  ParseARG_PDECL               /* Optional %extra_argument parameter */\\n)\\n```\\n\\nmajor表示符号类型，所以固定为int就够了。相应的minor是该符号的值，需要自定义union才行。minor主要用在shift和报错时用。\\n\\n用%name xyz指令可以替换Parse成你想要的函数名，一共会导出7个函数，其它都是以static约束并以`yy_`开头的内部函数。这7个函数只有主函数和Alloc及Free必须使用，Init和Finalize似乎不应该暴露，还有两个Trace和StackPeak是辅助用途。\\n\\n类似%name这样的指令共有23个\\n\\n```\\nname\\ninclude\\ncode\\ntoken_destructor\\ndefault_destructor\\ntoken_prefix\\nsyntax_error\\nparse_accept\\nparse_failure\\nstack_overflow\\nextra_argument\\ntoken_type\\ndefault_type\\nstack_size\\nstart_symbol\\nleft\\nright\\nnonassoc\\ndestructor\\ntype\\nfallback\\nwildcard\\ntoken_class\\n```\\n\\n改为可重入后，很多函数声明被改变，但工具并没有自动生成对应的接口申明，必须手工补齐，是个不足。\\n\\nflex和bison配合的时候，每当识别到一个符号动作的最后，都会return该符号对应的枚举。但和lemon配合时，如果在词法动作中执行lemon的Parse函数，就不需要return。因为lex函数内有个while循环，只要不return就会不停地找下一个符号。不考虑初始化和结束动作，只要调用yylex();Parse();就是解析的全部了。\\n\\nlemon内部也有while循环，其目的是收到新的符号后，可能会反复的shift或reduce。直到出现错误或者栈溢出结束循环。\\n\\nlemon在计算规则时会计算shift、reduce和shiftreduce的范围。shift的最小值是0，只定义最大值，另外两个既有最大也有最小值。\\n\\n解析函数根据计算的act的区间范围，调用shift(shiftreduce也算shift)或reduce。因为Parse内有循环，只要正常一定会reduce到accept状态，都不属于只能是错误。\\n\\nlemon在解析y文件时，有22种分支，包括自动机状态，出错和特殊符号的处理。\\n\\nlemon不允许开始符出现在规则右侧，因此一定要为开始符定义一条专门的规则，从生成的代码可以看到，开始符的规则在default分支，是最特殊的，这条规则通常什么也不会做。如果一条产生式有多种写法，不需要写`|`，把不同的产生式分开写出来，lemon会负责合并这些规则。因为每个语句最终都对应到一个case，这样考虑的话分开写反而更自然。\\n\\n`token_type`标识lex的终结符，而`type`标识lemon内的非终结符。\\n\\n除了用指令，有3个宏可以控制lemon的Parser结构。分别是水位警示、错误回退和栈增长控制。reduce需要用栈暂存数据，bison默认深度是200，lemon是100，但是可以定义宏为负值做到自增长，如果不定义宏，到100就报错退出了。产生式的每个符号，以最右边为0，向左依次-1并在栈上可以找到。\\n\\n## lemon阅读\\n\\nlemon生成后的代码大多数是表驱动，虽然大的结构能看懂，但怎么得到表却要看本体才能明白。\\n\\n程序有几个结构要关注，除了最大的lemon，就是rule、action、symbol最为重要。从入口来看，先确定终结符的最大个数，然后构造First集和Follow集。lemon的目的是得到一个语法分析器，但它自身又必须有词法分析，否则y文件都不能解析。\\n\\n整个流程是如下几个步骤\\n\\n1. 计算First集\\n2. 计算LR(0)状态机，次复杂\\n3. 计算Follow集（包含一个前置的FindLinks 不知道该怎么翻译）\\n4. 计算并压缩Action表，其中压缩可以通过命令行选项控制。此步已经是LALR\\n5. 生成LALR分析器，最复杂\\n\\n计算First集要考虑空规则"}'));jctx.push(JSON.parse('{"id": "180601", "tag": "lang", "text": "# 继承和原型\\n\\nThe History of Object Oriented Programming\\n\\n最初，人们并不知道“继承”究竟应该是什么。对这种新生事物，要求人们一下子就在头脑里有个清晰图景显然是不可能的。\\n\\n关于面向对象，一直以来就有两个主要派别：Class-based vs prototype-based\\n\\n后来的其他各种流派，都离不开这两个派别的核心思路，只是具体细节上略有不同而已。\\n\\n其中，前者认为，面向对象就是个分类问题；既然是分类问题，那么更靠“上”更“抽象”的大类自然就更基础，它所有的东西理所当然应该被继续细化的“子”类“继承”——圆形是个图形，方形也是个图形，所以圆形和方形都应该从“图形”这个类继承。\\n\\n类似的，蝙蝠既是可以飞行的动物，也是哺乳动物，所以它就应该从“可飞行动物类”和“哺乳动物类”继承——这样才可以“既能飞行又能哺乳”。\\n\\n换句话说，Class-based这个思路很容易直接导向一个误区，那就是不假思索的引入“继承”，并且还总是把“继承”看得过重。\\n\\n但是如此一来，就不可避免的导致很多含糊不清的问题。其中表现最严重的就是多重继承。比如，蝙蝠究竟是用飞行动物的嘴吃饭呢，还是用哺乳动物的嘴吃饭？吃下的饭，是给哺乳动物的胃消化呢，还是给飞行动物的胃消化？（熟悉编程的朋友恐怕马上就要想到未初始化、未重置、访问错误的内存区域等等“恶心而又可怕”的东西了）\\n\\n有的人可能不假思索的说“没关系没关系，C++的虚继承了解下！似乎只要在语言中提供个机制，把来自飞行动物和来自哺乳动物的嘴巴、胃等等合并起来就够了。你看，现在不存在歧义了吧？\\n\\n嗯……我现在有个需求，我们知道，汽车过去都是内燃机车，后来有了电动车；但是电动车充电慢电池容量小，所以又有了混动车。请问，当我的混动车同时从内燃机车和电动车多重继承后，你会不会自作主张把两个不同的动力基类合并？你要合并了，我这程序还怎么写？我的车上的的确确有两个不同的发动机！但倘若你不合并……你看，菱形继承的二义性就又来了。\\n\\nC++和Java都是class-based派别的支持者。这是因为，乍看之下，class-based这个思路很好很解决问题；所以Object C、C++甚至后来的Java全都选择了这条路。\\n\\n但是，它“默认让派生类取得基类所有遗产”的行为还是造成了很多很多的问题——这种行为不可避免的导致派生类和基类代码产生耦合；尤其在多继承时，尤其是菱形继承这种最恶劣的情况下，你甚至都不知道它会和基类的哪段代码/哪些数据结构产生耦合！\\n\\n理所当然的，基于C系语言一贯的、对程序员的无条件信任，C++选择了支持多继承，虽然这个东西已经暴露出来很多很多的问题，但它毕竟在某些时候还是有用的；而Java则禁止了多继承——毕竟它已经暴露了太多太多的问题，禁用它至多也就是实现繁琐一些、性能差一些而已。\\n\\n长期实践下来，prototype-based派别的观点就在实践中越发显示出了它的正确性——相比之下，class-based派就有点像缺乏考虑、就着比喻做设计的一群大老粗了：只是比喻总是比学术语言更生动、更容易流行，这才让它一度占据上风而已。\\n\\nprototype-based派别认为，面向对象其实就是一组实现了特定协议（或者叫接口）的object——在它里面压根就不存在类，只有prototype和object。\\n\\n按照这一派的思路发展下去，我们真正应该关心的是“对象可以提供什么样的服务（或者说，像XXX一样的服务）”：重要的是接口！压根就不需要考虑/支持继承这种矫揉造作的东西！\\n\\n分类？呵呵，正方形是长方形吗？在想清楚前别说话！\\n\\n这就绕开了class-based需要面对的、棘手的“正方形是不是一种长方形”问题——程序语言里面的class并不是日常语言中的“类”，它的精确表述是“is-a”，和口语的“类”八竿子打不着（事实上，自从class-based派同意“类不是类而是is-a”开始，他们已经向prototype派投降了：你可以自己想想这是为什么）。\\n\\n和外行的想象相反，class-based和prototype-based并没有因此而打得头破血流。\\n\\n事实上，几乎从最初的几个版本开始，C++/Java就引入了prototype流派的思想，这就是所谓的“interface”，或者说，其实严格来说并不是继承的“接口继承”——当然，基于一贯的、对程序员的信任，C++允许你的interface里面存在实现代码甚至数据成员：只要你确切知道它会被如何使用。这种做法就使得接口继承里面的继承二字又找回了一定的存在感，然后就把多重继承之类问题又找回来了。\\n\\n不过，class-based思路真正的问题还在于继承带来的强耦合，以及“鼓吹继承”给它的程序员甚至设计者所带来的思想包袱（想想本来已经通过interface解决、但又被随意“魔改”的interface找回的菱形继承问题吧）。\\n\\n为什么prototype-based派可以绕开继承带来的诸多副作用呢？很简单，因为prototype派压根就不存在继承。它就是声明自己支持某个“协议/接口/prototype（反正就这意思，你叫它什么都可以）”，然后想办法真的去支持这个协议就完了。\\n\\n如何支持呢？你可以自己从头写；但也完全可以在自己的object中隐藏一个支持该协议的、来自系统或第三方的object，然后把相关调用转发给它（这个转发在相关语言里，常常可以通过显式声明自动完成：换句话说，继承在这种语言里不过是个语法糖而已；而且这种语法糖思路确保你不可能弄出多继承来）。\\n\\n既然prototype只是允许一个对象声明它兼容某个prototype而已，并不会越俎代庖的把这个prototype的默认实现/标准基类等等东西塞进你的代码——那么，这个prototype究竟是怎么搞出来的，当然就由你完全控制了：哪怕你往里面塞一万个同样支持这个prototype的object进去，只要你自己头脑清醒、知道什么时候应该把调用转给这一万个object中的哪一个，它就是完全合法并且井井有条的。\\n\\n换句话说，既然prototype-based放弃了自动从“父类”拿到“祖传代码”这点实惠，那么它自然就绕开了“继承父类代码”带来的诸多弊端（注意这个多余的“自动”。经常的，把一个项目搅乱、把一个问题复杂化的根本原因，就是因为有人做了看似很棒很好用然而整体上却是多余的事，导致某个局部甚至整体陷入“水多了加面面多了加水”的窘境。然后就把参与者全都带歪了）。\\n\\nprototype扔掉“通过class继承拿到的祖传代码”，这看似是个绝大的浪费；但事实上，你仍然可以通过“把拉来的订单转交给父亲/母亲开的公司”、从而不浪费可以从父母那里拿来的好处——这个转交过程是完全可控的，绝不存在任何含糊之处。\\n\\n与之相比，class based鼓吹的继承就麻烦多了——你必须理解父/母亲开的公司的运作机制，不然就很容易在“继承”时搞错；更可怕的，当你同时从父母那里继承两家公司时，你喊“会计，记账”，你并不知道哪家公司的会计会把账务记到哪本帐上。\\n\\n你说我可以虚继承，把两家公司的会计团队合并起来？\\n倘若两家都是同样性质的公司，那的确没什么问题……\\n但倘若你得到的是一家房地产公司和一家IT企业，让你搞出了个X氏企业集团，同时支持房地产业务和IT业务——两者内部管理逻辑截然不同；强行把帐做到一起给你个“统一的管理接口”？我看你还怎么管理这个混账团队！\\n\\n醒醒吧。你真正需要的，是把这两家公司当两家公司经营，并不是通过什么神秘的巫术仪式合并它们：一旦两家公司有各自使用各自基类数据的理由/特殊逻辑，合并就成了混账！\\n\\n换句话说，既然语言允许，那么子类和父类当然就可能存在深度耦合；然后，当孙类从两个子类多重继承时，它们的共同父类就可能成了某种“合并不是，不合并也不是”的尴尬存在。\\n\\n千万不要以为编程语言提供的什么东西真就那么智能。\\n除非你完全明白自己在做什么、而且也确信接手自己代码的人也知道你在做什么、或者让你接手别人代码时你也总能头脑清醒的把每一个流程的来龙去脉都搞清楚……否则，还是离这类含糊/微妙的东西越远越好。\\n否则，并不是“多重继承搞出了二义性、咱只要闭着眼睛通过算法把二义性消除了就一定能解决问题”：你真正需要思考需要解决的问题实在太多了；在这种领域，语言越“智能”，你和你的团队需要理解和理顺的规则/逻辑就越多，反而越容易出错。\\n\\n多重继承的确可以很方便的解决一些问题；但为了这个方便，付出的代价往往过于高昂。\\n\\nprototype就是“不去支持继承这种含糊不明的、多余的东西，从而把语言逻辑搞简单”的典范：这种思路使得“如何组合使用object、如何对外提供prototype抽象”等诸多细节完全由程序员控制，再不存在任何含糊之处。\\n当然，它也因此再也不能像C++那样，通过“变多重继承魔术”神奇的得到某些功能了——现在你得自己明确写出来。\\n\\n这个思想一旦被引入class-based学派，就成了“优先使用组合而不是继承”。至于晚近出现的一些语言，比如go，直接就走了prototype-based的道路。\\n\\n就这样，通过引入interface，C++/Java就允许了程序员们把这种语言变成“看似class-based，实质是一堆空壳子”的存在，从而暗地里实现语言向prototype的转化（与之同时，头脑清晰的程序员仍然可以利用“继承”带来的“自动化”能力，却不至于受“就着比喻做设计”之害——越是觉得“继承”没用的，反而越是可以从语言提供的继承相关设施上得利；而越是觉得继承无与伦比无可替代的，越是会受到继承阴暗面的伤害）。\\n\\n换句话说，一旦通过prototype规避掉“实现继承”，“实现继承”带来的坏处自然就烟消云散了：多重继承这种由“实现继承”发展而的“恶性肿瘤”，自然也就失去了存在基础。\\n\\n当然，前提是，千万不要把interface又搞得像个类一样。\\n"}'));jctx.push(JSON.parse('{"id": "180609", "tag": "protocol", "text": "# 论RESTFul特性\\n\\n产生RESTFul的领域，似乎不能涵盖API风格。要求URL以名词性单词结尾，典型的比如心跳，要作为什么样的资源呢？也许可以强作令牌，但其它需求未必有适合的名词。\\n\\n再提一点很现实的问题，浏览器的GET不能携带body。RFC7231说明payload是no semantic的，XMLHttpRequest的实现会不允许发出，PUT/POST/DELETE可以。这就导致复杂的查询请求只能用POST来实现，已然破坏了获取语义。\\n\\n再说点XHR作为本地页面，会把PUT和DELETE作为OPTION发出，内容不变，这就涉及到浏览器跨域场景中额外加入的preflight特性，POST如果Content Type改了也会遇到，GET似乎不会。\\n\\n转载一个观点，带来几个问题：\\n\\n数据定制的问题：我们的应用数据现在越来越丰富，已经不是10年前可以相比的了，也就是说数据的返回可能很丰富，非常大，而我这次可能只要其中一小部分，比如说我请求一个用户的数据/user/1，我只要他的名字和头像，而并不需要他几千个好友。传统的Rest，你可以加个Mask参数，例如/user/1?friend=false 这种方式无疑增大了前后端的代码复杂度，增加了开发的强度，而且也不够灵活，难道我要给每个字段都加个Mask？后端要依赖各种可能的Mask组合来生成查询也是个麻烦事儿，这种代码写出来也是难维护。\\n\\n多次请求的问题：类似上面提到的灵活性问题，上面说我们要少要点数据，那我们这次想多要些数据。比如说我想要一个用户的所有好友，还没完，再加上每一个好友的所有好友。这在传统Rest里面，往往我们就使用多次的请求，拿到1度好友的列表，然后写个循环，依次拿到所有2度好友。这当然不够优化，于是可能你会再设计一个专门的API去一次性拿到所有2度好友。同样的问题，这增大了前后端的代码复杂度，不够灵活，万一下次我要3度好友呢？\\n\\n异常处理的问题：这个很多朋友都会有自己的办法，有些朋友会返回特定的http response code: 4XX, 5XX，有些朋友可能会返回特定的Json消息。比如说/get/user/8527, 如果这个用户不存在，你可以返回404，你也可以返回自定义消息｛msg：“user not found”｝。这很多时候也不是问题，但我觉得如果使用更结构化的异常处理方式，应该会好些。\\n\\n发出一个请求，我不知道会得到啥：结合上面几点，其实你会发现，如果你请求一个资源，例如/user/1，你并不知道结果里具体会有什么，你可能需要查阅文档，但文档可能已经过期。你可以自己实验，但你不知道是否覆盖了全部可能的情况。这是一个很痛苦的过程。\\nPUT和DELETE也是个坑：这需要前后端框架的支持，如果不支持怎么办？其实我也不知道，我这么多年一直尽量避免使用PUT和DELETE来设计API。\\n\\n每个resource都有自己的一组end point或者说URL，这会带来管理和维护的麻烦。\\n安全问题：Rest难以避免的从URL上接受各种参数（parameter），不严格的使用Get等都会造成安全的隐患。有些问题GraphQL上也有，而且我不是这方面的专家，就不细说了。"}'));jctx.push(JSON.parse('{"id": "180612", "tag": "os", "text": "# 写文件的一些特性\\n\\n先创建一个分区，方式如下\\n\\n* `dd if=/dev/zero of=./dummy count=204800` 创建一个普通文件，用file看类型是data\\n* `mkfs.ext4 ./dummy` 会提示不是个block special device，是否要继续。选Y继续。将普通文件用ext4的方式格式化，进而可以挂载。block大小1K，每个inode管理约4个block。预留5%的block给root用户，journal占4096block。文件变成了filesystem data类型\\n* `mount ./dummy /tmp/` 将block文件挂到指定目录\\n\\n磁盘满有空间满和inode用完两种情况。inode用完主要是小文件过多导致，此时空间是还有剩余的。一般跑服务器程序不会有这么多小文件，重点关注磁盘剩余空间。\\n\\n分别用fwrite和write测试连续256次写入一些数据。\\n\\n* 4K粒度，每次用3到9us，隔20次左右会突然有次达到30us，最大44us。\\n* 8K粒度，每次用5到9us，但隔10次左右就会耗时增加，大约20略大us，最大78us。\\n* 16K粒度，开始5us，到最后几次达到20us，突变时约30us，但有一次特别大，达到25ms。\\n* 32K粒度，每次最少20us，后来到达150us。突变峰值32ms。\\n\\n当空间快占满时，写4K的速度几乎没有变化，10us左右，波动仍是30us。当写完后，每次写的时间仍然差不多，但100多次才出现2、3倍的小波动。\\n\\n用df看磁盘空间，当avail显示是0时，root仍然能继续写入一定量的数据，普通用户如果是0那就真不能写了。写空间从有到没有的一瞬间，会出现写入耗时的峰值，约是10us到10ms放大1000倍，在那之后写入速度基本就是个2到3us的恒定值。\\n\\n## df和du查看磁盘区别\\n\\n这两个命令都能统计分区大小，原理不一样。df读磁盘的superblock分析空间和文件系统属性，而du是用stat系统调用遍历每个文件或目录，最后得到总和。因此速度要慢很多。"}'));jctx.push(JSON.parse('{"id": "180618", "tag": "lang", "text": "# 【译】Eiffel之路\\n\\n这是一篇开放式地讨论SP和OO的文章(a free ranging discussion, the reader should view it as a promenade on the border road between SP and OO)。\\n\\n作者赞成Bottom up甚于Top down设计。不该忘记程序构造的基石，对变化的适应，对复用的追求。(The main flaw of Top down,however,is that they neglect fundamental aspects of software: the need for change, and the need for reuse )。自顶向下设计得到的是对应需求的产品，而这些无法适应未来。类似的观点在On lisp的开篇也做了浓墨重彩的描述。重点是向上。与其实现一个最好的解决办法，不如实现一个好的，但适应未来的物件。\\n\\nThe particular choice of  set facilities and of their sequencing is the least committing decision of system design; because it is bound to be the first to change, it should be made last. 反映在Eiffel上就是缺少main程序概念，只是一堆class的组合，其中一个被指定为root或执行的种子。变更root则是最简单的事。\\n\\nnot to find fault with their authors, this excise is as easy as it is vain. This discussion aims to generate light than heat.\\n\\n## OO的原则和技巧\\n\\n显式重定义类\\n\\n作者认为这是OO之所以优雅的关键。a key factor behind the elegance of OO.\\n\\n多态是种开放的机制，相比起Pascal/Ada用record来固化选择which freezes the list of choices.我倒觉得两者适用场景不同，无高下之分。\\n\\n静态类型和动态绑定相结合，静态绑定保证了至少有一种选择，而动态绑定则在有多种选择时，有机会选择最好的。\\n\\n重命名机制使得多继承的接口冲突得到了解决。\\n\\nGeneralization，尚不清楚是个什么样的方式，但对于以行来计价的程序而言，泛化的价值并不大，只有长期维护的软件才值得这么做。\\n\\nlifecycle，定义cluster model，对应的就是一个目录。把整个系统级的度量，缩小到目录级别，因而更具伸缩性。由于cluster粒度更小，呼应了前文的对变化的适应和对复用的追求。\\n\\n管理者不要人为地在设计和实现中设置屏障，他应该对最关键的部分负责。"}'));jctx.push(JSON.parse('{"id": "180621", "tag": "net", "text": "# 网络协议与socket\\n\\n## IP协议族的历史\\n\\nTCP/IP这套基于包交换理念的协议族最早构思于1974年5月，并在同年12月发布了如何控制传输的RFC675（这个时期还只是一个大的单体程序，没有做分层）。到1980年1月发布了层次化的RFC760标准，82年3月美国国防部钦定用于军事系统。随后在1982年用于SATNET，紧接着在1983年1月用于ARPANET。\\n\\nTCP和UDP只支持单一特性，出现在2000年的SCTP协议，能够同时支持严格有序传输（像TCP），部分有序传输（像per-stream）和无序传输（像UDP）。贴段说明：\\n\\n> 作为一个传输层协议，SCTP兼有TCP及UDP两者的特点。SCTP可以称为是TCP的改进协议，但他们之间仍然存在着较大的差别。\\n> 首先SCTP和TCP之间的最大区别是SCTP的连接可以是多宿主连接的，TCP则一般是单地址连接的。\\n> 在进行SCTP建立连接时，双方均可声明若干IP地址（IPv4，Ipv6或主机名）通知对方本端所有的地址。\\n> 若当前连接失效，则协议可切换到另一个地址，而不需要重新建立连接。\\n> 其次SCTP是基于消息流，而TCP则是基于字节流。\\n> 所谓基于消息流，是指发送数据和应答数据的最小单位是消息包(chunk)。一个SCTP连接（Association）同时可以支持多个流(stream)，\\n> 每个流包含一系列用户所需的消息数据(chunk)。而TCP则只能支持一个流。\\n> 在网络安全方面，SCTP增加了防止恶意攻击的措施。SCTP连接采用四次握手机制，有效的防止了类似于SYN Flooding的防范拒绝服务攻击。\\n> SCTP主要的贡献是对多重联外线路的支持，一个端点可以由多于一个IP地址组成，使得传输可在主机间或网卡间做到透明的网络容错备援。\\n\\n## Socket的历史\\n\\n光有协议还不够，必须有编程接口，Berkeley socket于1983年随着BSD4.2系统发布，但直到1989年才和AT&T达成诉讼和解并真正成为众人公认的网络编程接口。\\n\\nsocket函数声明传入3个值，依次是domain/type/protocol。域最大，然后是类型，比如连接/无连接/原始等，最后是协议种类如TCP或UDP。经过这么多年的洗礼，历史上曾经繁多的domain类型，比如X25,IPX,AppleTalk,NetBEUI不能尽数，可对如今很多人来说，只知道IP。协议也只剩下TCP或UDP这两种了。网络之外，还有红外`AF_IRDA`、蓝牙`AF_BLUETOOTH`的socket可以使用。\\n\\n现在一提到连接，就是TCP，一说数据包就是UDP，一般用如下两种方式：\\n\\n* UDP socket(AF_INET, SOCK_DGRAM, IPPROTO_UDP);\\n* TPC socket(AF_INET, SOCK_STREAM, IPPROTO_TCP);\\n\\n如果DGRAM配合TCP或反之，函数返回-1，errno显示原因是`EPROTONOSUPPORT`，表示协议不支持。还有一种`IPPROTO_UDPLITE`类型，去掉了UDP的checksum，配合音视频流的时候，尤其VoIP效果更好。"}'));jctx.push(JSON.parse('{"id": "180702", "tag": "lang", "text": "# Lisp文章读后感\\n\\nRethinkDB作者的理解，从XML，C语言宏等角度作了比喻。\\n\\nXML是一种数据表示，但Ant中可以表示行为。如果把尖括号和属性(只是为了少打字的节点的一种简写，非必须的特性)做变换，最终呈现的就是Lisp的多重括号。\\n\\n用C宏和元编程做比较，日常有太多的boilerplate代码要写，宏是理所当然的选择，但如果能用host语言来无缝处理显然更好。\\n\\n## Henry G Baker的实现思路\\n\\n把Scheme转成C用到CPS变换，常见的思路是trampline，但这种方式会慢2-3倍。提出了一种永远不return，不停地让栈生长，内存分配都实现在栈上，使栈堆合一简化分配。当栈达到极限，用Cheney的GC方法进行收集。\\n\\nC语言禁止嵌套函数，目的就是阻止free变量的引用。只允许toplevel函数，free变量惟一的可能只有全局变量，编译器会维护一个环境指针，可以找到这些全局变量。Pascal允许嵌套定义函数，不清楚怎么解决。\\n\\n## 自己的体会\\n\\nsymbol是为了区分函数求值和数值表示。最初存在Mexp和Sexp两种，最后以quote的形式把Mexp给去掉了。所以只能说数据和函数同构，但不是相同。在lisp体系中完整体现了外部表示->符号->值的两次转换，没有quote符号，不过是换一种语法的lua。\\n\\nsymbol不仅能表示简单的变量，也能表示list，因此具备树状结构，而string只是字符线性排列。换句话说，string能看起来无缝地表示成symbol，部分symbol变成string后就大不相同了。让我们混淆的是自表示symbol，比如数字1，当eval作用在结构的symbol上，求值就变得统一了。\\n\\n写宏的时候，\\\\`把sexp标识成数据，而`,`则起到了局部eval的效果。\\n\\n反过来想，PHP/JSP这些语言的默认标识成数据，用了`<?`就把进行求值演算。只是PHP缺少数据和程序互操作的能力，而Lisp打通了两者的边界。\\n\\n既然函数和字符串本质都是一段二进制值序列，只是类型不同，所以计算时对这个值的eval也不同。环境是若干个frame构成的list，闭包是带env的函数，而类不过是生成对象的函数模板（let over lambda）。所以说在静态作用域出现之后，闭包和对象的界限才被打破。\\n\\nR5RS中，pair和vector是两种最基本的数据结构(procedure)。hash是一种高效的实现，但本质上可以用list实现。最简单的做法是单向链表，但是红黑树一样可以用list来表示，此时就不能以car来取值，而要针对树的list结构定义专门的函数，如果要用bucket方式，则会用到vector，元素是list。\\n\\ncontinuation在1964年由Wijingaarden首次提出，有点ES6的Promise味道，到72年广为人知。Kamal Abdali在会议上发表论文，把Algol60转为untype lambda计算。提交第一届ACM符号被拒。他在74年完成他的毕设。他的推荐人提到，将语言转为\\"pure\\" lambda，比如赋值就modeled by substitution，而不是内存，地址，存取操作。\\n\\n推演时，把k代表的符合消去，就能看出在current时间点，要做的是什么，再把参数找到，因此要做两次推导，所以显得复杂。\\n"}'));jctx.push(JSON.parse('{"id": "180706", "tag": "lang", "text": "# Shell编程说明\\n\\n## 解析顺序与转义\\n\\n和函数调用类似，一条命令行的多个部分会在不同阶段解析。先判断整行是简单命令还是复合命令，每条简单命令的参数会先解析，像glob、变量替换、重定向都是参数解析阶段的重头戏，然后作为主命令参数执行。\\n\\n单双引号可以防止转义，双引号保留$和\\\\n等扩展语义，单引号完全不做转义。但是`$\'\'`语法支持有限转义。比如$\'\\\\u4f60\'会转义成汉字\'你\'，如果没有$，则原样输出。\\n\\n## 类型\\n\\n解析时默认都是字符串类型，所以不需要特意标记双引号或单引号，有两种情况要特意加引号：1-空串，2-\\\\*之类会被扩展的特殊字符。\\n\\n在值的比较上，颇有些强类型的感觉，字符串的比较和整形的比较要用不同的操作符。\\n\\n## 变量与赋值\\n\\n赋值的`=`两端一定不能有空格。因为在sh的体系里，空格并不是可有可无的，在语法解析时扮演重要的角色，因此一定要注意。用set或readonly可以看到当前已设置的变量。\\n\\n环境变量是带有特殊属性的变量，export把变量提升到环境级别，但这个变量依然是变量，可以用unset删除，之后在环境中就没有这个变量了。用env看到的变量比set会少一些，除了前面提到的提升的变量外，set还能看到函数的定义。\\n\\n位置变量是对函数调用特有的，有个很少人知道的特性，`set -- a b c`可以实现把位置参数替换成a b c这3个值（把--后面的值，赋给隐式的$@，如果--后面无参数，则$@被清空），如果想实现追加在前或后的效果，用`set -- $@ a b c`实现追加到尾部。再配合shift命令，看起来不能修改的位置参数，也能随意操控。\\n\\n除了=还有:=表示未设置才赋值，:-未设置就替换。像这样`PS1=$\'${ local e=$?\\\\n((e)) && REPLY+=\\"$e|\\"\\\\nreturn $e\\\\n}${PWD:30} \'`表示先计算上一条命令的返回值，如果有错误就赋值给REPLY，并把当前路径重新计算一次，丢弃前30个符号。重点是return，如果没有的话，显示的路径就不会变化。这句话在非bash环境，以迂回方式实现了显示当前路径。\\n\\n等号`=`和圆括号`()`与`$`三者间构成3种不同含义的功能\\n\\n* =($xx)  把带空格的字符串赋值给左侧\\n* =$(ls)  把圆括号内的内容作为命令执行，执行结果赋值给左侧\\n* =$((1+2)) 把双圆括号内的内容作为数学计算，计算结果赋值给左侧\\n\\n值的截取和替换\\n\\n* ${#var} 取变量的长度\\n\\n* ${var:=word}\\t如果变量 var 已被删除(unset)或为空，那么返回 word，并将 var 的值设置为 word。\\n* ${var:-word}\\t和=类似，区别是但不改变 var 的值，理解为-是一半的=，所以效果也只有一半。\\n* ${var:+word}\\t和-相反，如果变量 var 被定义，那么返回 word，但不改变 var 的值。\\n* ${var:?message}\\t如果变量 var 为空或已被删除(unset)，那么将消息 message 送到标准错误输出，并停止脚本的执行。用来检测 var 是否被赋值。\\n\\n以上4种替换法，可以想像成{}内的三元表达式，比如${var:=word}可以理解为`isnull(var)?word:var`。以上几种替换法，都可以省略:，区别在于isnull的判断逻辑，变量声明为空串，有:时，空串的isnull为真，无:时，空串的isnull为假。比如`A=;${A=abc}`，因为A已经定义了，值是空串，判断为真，输出前半部分，即仍是空串。\\n\\n* ${var#expr} 从变量头开始，按匹配expr的表达式删除，支持glob。比如${var#?}表示删除第一个字符，和${var:1}是一样的。如果两个#则启用贪婪匹配\\n* ${var%expr} 从变量尾开始，按匹配expr的表达式删除，类似的%%启用贪婪。记忆窍门：删除方向取决于在$的哪侧，#在$左侧，而%在$右侧。\\n* ${var/obj/rep} 把变量中obj替换成rep，obj支持glob。只替换一次，如果要想替换多次，写作`${var//obj/rep}`\\n\\n$变量的展开和命令解析有一定的顺序，比如要执行`foo 1>/dev/null`命令，但遇到问题时，希望把输出到控制台，如果用`DF=1\\\\>/dev/null`来控制，用`foo $DF`会报错，大意是`1>/dev/null`参数无法识别。猜测是因为$DF触发了替换后，就直接被当成参数来用了，而1>/dev/null重定向需要一次特殊的解析，但被$替换后，就错过了这种解析。办法是eval \\"foo $DF\\"才能既展开变量，又能触发重定向。\\n\\n## 函数\\n\\n函数定义有`function name{}`和`name() {}`两种风格，function是bash扩展的，带上后可以不写括号（function或括号都是告诉shell，现在开始定义函数了），如果是busybox的ash，只能用不带function的格式。函数内声明变量最好用declare(字符串类型)或者`-i`(整型)，相当于是内部变量，否则就会在全局空间创建这个变量，typeset是declare的同义词。也可以用declare来看已定义的变量和函数。\\n\\n函数可以返回unsigned char，但是不能直接把返回值赋值给变量，直接在`=`后带函数名，函数名会退化成字符串。必须先执行，再用$?赋值。\\n\\n函数调用不需要括号或逗号，用foo $a \\"var\\"方式将函数和参数以空格平铺开就算执行了。\\n\\n`$*`和`$#`都表示所有参数，区别是`$*`是字符串形式，`$#`是数组形式。在传参给执行程序时没区别，遍历用`$#`会方便很多，如下\\n\\n## 数组和遍历(仅bash支持)\\n\\n用圆括号和空格定义，arr=(1 2 3 4 5)，定义后可以用arr+=(6 7)向末尾追加元素。也可以这样\\n\\n```\\ndeclare -a array\\narray[0]=\\"a\\"\\narray[1]=\\"b\\"\\narray[2]=\\"c\\"\\n```\\n\\n遍历（For循环法）：\\n\\n```\\nfor var in ${arr[@]};\\ndo\\n  echo $var\\ndone\\n```\\n\\n遍历（带数组下标）：\\n\\n```\\nfor i in \\"${!arr[@]}\\"\\ndo\\n  printf \\"%s\\\\t%s\\\\n\\" \\"$i\\" \\"${arr[$i]}\\"\\ndone\\n```\\n\\n遍历（While循环法）：\\n\\n```\\ni=0\\nwhile [ $i -lt ${#array[@]} ]\\ndo\\n  echo ${array[$i]}\\n  let i++\\ndone\\n```\\n\\n获取数组的length（数组中有几个元素） ${#array[@]} 。解释一下 @ 是数组展开，#取长度，$把值取出来。对函数内的参数而言，简化成$#就是数组长度。\\n\\n## 向函数传递数组\\n\\n由于Shell对数组的支持并不好，所以这是一个比较麻烦的问题。除了全局变量外，无完美解法。提供一个变通的思路，在调用函数前，将数组转化为字符串。在函数中，读取字符串，并且分为数组，达到目的。\\n\\n```\\nfun() {\\nlocal _arr=(`echo $1 | cut -d \\" \\" --output-delimiter=\\" \\" -f 1-`)\\nlocal _n_arr=${#_arr[@]}\\nfor((i=0;i<$_n_arr;i++));\\ndo\\n  elem=${_arr[$i]}\\n  echo \\"$i : $elem\\"\\ndone;\\n}\\n\\narray=(a b c)\\nfun \\"$(echo ${array[@]})\\"\\n```\\n\\n## 条件判断\\n\\nif语句\\n\\n```\\nif [ \\"$0\\" -eq/= \\"$1\\" ]; then\\n  statement1\\nelse\\n  statement2\\nfi\\n```\\n\\n本质上讲，if 检测的是命令的退出状态，所以then前面必须有;，用;让if做完求值。\\n\\n**在 test 中使用变量用双引号包围起来**。想判断当前文件夹为空，捕获ls的输出后，一定要用[ -n \\"$out\\" ]才正确。如果没双引号判断不准，这个过程将变量 $str1 替换的细节如下：\\n\\n* 如果 $str1 是一个正常的字符串，比如 abc123，那么替换后的效果就是test -z abc123，执行形式相当于main(\\"-z abc123\\")。test 命令后面附带的所有选项和参数会被看成一个整体，并作为实参传递进函数，正常执行。\\n* 如果 $str1 是一个空字符串，那么替换后的效果就是test -z，执行形式相当于main(\\"-z \\")，这就比较奇怪了，因为-z选项没有和参数成对出现，执行时就会出现意想不到的情况(对于-n和-z的执行结果都是错误，导致if的评估结果一样)。如果给 $str1 变量加上双引号，当 $str1 是空字符串时，test -z \\"$str1\\"就会被替换为test -z \\"\\"，调用形式就是main(\\"-z \\\\\\"\\\\\\"\\")，显然这样 main() 在分析时就不会出错了。正因为此，经常会看到x = x$var的写法，也是为解决空串问题。\\n\\nswitch格式\\n\\n```\\ncase \\"$1\\" in\\n  start)\\ncommand1\\n;;\\n  stop)\\ncommand2\\n;;\\n  *)\\ncommand\\n;;\\nesac\\n```\\n\\n前面提到过，默认的类型是变量，在条件间断时有一些有趣的现象，比如[ \\"x\\" = x$empty ]的结果是true($empty是空串)。case后的条件建议加双引号，原因同前，分支语句有没有双引号都没关系，反而想同时捕获error或errors时，必须用不加引号的error\\\\*才行，加上引号会适得其反。\\n\\n## heredoc\\n\\n第一行可以跟参数，说明EOF代表文件名\\n\\n## 执行子命令\\n\\n$()与 backquote(反引号)效果是一样的，优劣如下\\n\\n* $() bash扩展命令，可以嵌套，似乎busybox也能支持，由于带了$，可以放在=的右侧，命令的运行结果可以赋值到=左边\\n* backquote是posix规范，嵌套时内部的反引号要加转义\\n\\n另外$(())是用于整数计算，同样可以放在=右侧，不要和$()搞混了。\\n\\n## 字面值还是文件名\\n\\n严格来说，这并不是shell的特性，而是各个程序的特点，比如echo的参数当作字面量，而cat或ls的值则作为文件名来解析。有一个操作符`<()`，会把执行的结果作为文件内容，<()作为一个文件的占位符，等效于匿名文件，有点类似lambda的感觉。\\n"}'));jctx.push(JSON.parse('{"id": "180714", "tag": "lang", "text": "# Lisp的宏\\n\\n都说Lisp的宏很强大，其最大的特征仍然是字符串展开和替换，只是在替换的过程中，可以结合环境进行适合的绑定，加之程序和数据的同构，才使它异常强大。本文以s7的传统宏实现来理解宏。\\n\\n我最初最大的困惑，在一个宏定义的开始，要不要加\\\\`？以一个最简单的宏来做实验。\\n\\n```\\n1. (define-macro (print arg) (display arg))\\n2. (define-macro (print arg) `(display ,arg))\\n3. (define-macro (print arg) `(display arg))\\n```\\n\\n* 情况1，不加\\\\`。在宏展开后，就进行运算，并得到最终结果。展开的结果类型是表达式的返回值。没有\\\\`也就不能用\\\\,，参数无法求值，即使是未绑定的值，只是作为一个symbol来用，未绑定的值并不会报错。比如(print ar)会输出ar，甚至ar有定义时，也只是输出ar。这种宏展开，只是最单纯的展开，没有求值替换，和C的宏能力等价。\\n\\n* 情况2，加\\\\`。宏展开的类型就固定是pair，仅仅宏展开并不求得最终值。只有把宏展开的结果，再用于eval才能得到宏最终的结果。宏变量也会成为宏展开时环境的一部分，再传入无意义的变量会报错。\\n\\n* 情况3，加\\\\`但忘记用,求值。宏展开期间参数没有用，eval时只能从当时的全局环境找绑定，不确定性很大，有点类似动态作用域的效果，不建议用。\\n\\n所以调用宏，相当于展开宏并把展开结果绑定到一个匿名变量，展开前会把参数作为新的frame插入环境中，如果出现求值，再用eval对这个匿名绑定求值两个步骤。有时看起来加\\\\`和不加效果相同，是因为不加\\\\`相当于宏展开后已经是个self evaluating值，再做eval看不出变化罢了。要注意：加了\\\\`但没有把参数用,进行求值，则这个参数就会在eval阶段引用全局的同名参数。\\n\\n由于scheme是strict语言，只要遇到表达式就求值(但set!的第一个参数和宏的参数在宏展开前是不求值的)。"}'));jctx.push(JSON.parse('{"id": "180801", "tag": "protocol", "text": "# 电话协议的发展\\n\\n写这篇的起因，是确定了SIP协议更直观的翻译应该叫电话初始化协议。Session在IT领域是个很宽泛的词，只表示两者之间持续的一段互动。而话音业务却有很多的特殊性：\\n\\n1. 双向交互。光这一条就干趴下当前互联网界最常用的HTTP/1.1，一个只能单向通信的协议。\\n2. 兼具信令和媒体流，而且媒体流非常在意实时性。\\n\\n很多业务虽然非常复杂，难于拆解，但承载的协议却非常简单，往往HTTP就足够。但话音业务却是业务非常容易理解，也不复杂，但对协议的要求却非常得高。\\n\\n贝尔(AT&T成立的贝尔实验室就是纪念他)在1876年发明了电话，从此话音业务就渐渐成为了很大的市场。从模拟线路时代以来，以1975年为分界点，之前是In-Band协议，最后一代是SS5(Signaling System 5)，在那之后发展出了Out-Band，并最终进化并定格在SS7。直到IP时代到来，SIP协议产生于1996年。也是沿着Out-Band的脉络发展。\\n\\nIn-Band时代，只有一条承载话音的模拟线路，为了解决在语音通道上发送号码，贝尔实验室在二战后发明了MF多频技术，定义5个频率，每次同时发出两种频率，一共能组成10种组合对应十个数字。基于MF，在1963年发展出了DTMF，至今仍在使用。在那之前的电话都是转盘式拨号，之后就是现在常见的按键式拨号。MF包括R2 Signaling，R1(仅北美)，SS5。由于把控制信号在语音通道上传输，1960年代，phone phreaking发明了blue box，最大的好处可以免费打长途电话。为了防御这种攻击，加上数字技术的成熟，Out-Band开始登上历史舞台。\\n\\nSIP使用了很多HTTP和SMTP的元素，形式上也非常相似。SIP首先从Internet发展起来，并被IETF承认，H.323系也是话音业务。两者从大的功能上都服务于电话，但设计思路却并不同，且H323兼容电信网络更好，所以ITU更偏好。"}'));jctx.push(JSON.parse('{"id": "180809", "tag": "os", "text": "# 操作系统启动器的故事\\n\\n看看几大主流操作系统的启动区别。\\n\\n## 启动顺序的差异\\n\\nWindows是先认硬盘，再从硬盘分辨分区，其中系统分区中找到ntldr并引导。\\n\\nLinux要先有根文件系统，由于还没有读硬盘，必然在内存中建立根目录，有了根目录硬盘才能挂载。抛开硬盘后，有UBoot(BIOS)、内核、内存文件系统和init进程等关键元素。如果用mount命令查看，`/`的类型并不是rootfs，像我的Cent7虚拟机是xfs，Alpine则是ext4。看不到rootfs不代表没有，它确实存在过，只因为rootfs是ramfs的一个空实例，挂载后大部分系统会把硬盘上真正的文件系统替代rootfs，所以用mount就看不到了。但是在硬盘被挂载前，rootfs基于的ramfs使内核有栖身之处，显然是有意义的。\\n\\nLinux启动的三大部分，boot/kernel/rootfs，常见组合是BIOS把控制权交给grub，grub显示启动菜单，并把用户选择的kernel即vmlinuz文件加载到内存。内核自带虚拟文件系统，由于只管调度并提供调用接口，要让用户使用，必须在内存中安装根目录，initramfs.img就负责干这个。它的前身叫initrd，两者的区别是initrd把内存模拟成硬盘，制作时要关联到loop back device，再mount后才能找到init。而ramfs方案直接把内存模拟成文件系统，一步到位。把initramfs.img解压到根目录（又叫rootfs），这个initramfs.img其实是个`gzip+cpio`的文件，用gunzip加cpio -idv <file的方式能看到内容，包含/bin/,/usr/这些文件夹。开始是只读，只要挂载完校验完整性通过，才会改成可写方式。加载完并有了init后，就可以彻底进入用户态加载各种服务了。\\n\\n## Unix系的init\\n\\n### Linux\\n\\ninit是最初启动的程序，必然是静态程序，用ldd不会看到有关联的动态库。其它的程序都是由它fork之后运行的。Linux的0号进程是Idle，不过ps不会显示它。传统Unix系PID为1的程序是/sbin/init，也可以是个指向其它程序的软链接，到了Linux则支持向内核传参来改变启动程序。随着开机启动服务越来越多，出于对速度的追求,init也演化出了很多派别（我的cent7启动耗时为2.098s kernel + 7.568s initrd + 15.753s userspace 总计 25.420s）。wiki把归于Service Management，有两大类：\\n\\n1. 可移植实现：目前还活跃开发的只有OpenRC（Gentoo主导），其它runit和initng似乎已经停止很久了。\\n2. 系统专属实现：Linux有Systemd和Upstart，Mac是lauchd\\n\\nVoid使用runit\\n\\ninit指向runit-init，负责启动器，还自带简单的一套sv/runsv服务管理程序。\\n\\nAlpine 使用OpenRC\\n\\n> init是指向busybox的软链接，而后由openrc-run程序引导，可见两者是分离的，是为可移植。/etc/init.d/目录下平铺着所有的服务，3.7版的AlpineLinux，会偶现启动时chrony非常耗时问题，要禁止chronyd，直接把文件移走就可以了。程序运行稳定后，用pgrep无法找出openrc相关的进程，不确定是不是运行完就退出了。\\n\\nCentOS 7.x 使用Systemd。（6.x及以前使用传统的/sbin/init）\\n\\n> init指向/usr/lib/systemd/systemd，同时也控制启动服务的顺序和依赖关系，是结合式的。而/etc/init.d/目录指向rc.d/init.d，又根据runlevel分了数个目录，要复杂得多。\\n\\nPID从2开始的前几个程序都是kthreadd/ksoftirqd/kworker/migration/md/watchdog/crypto等，都是Linux必须要启动的服务。\\n\\nLinux和FreeBSD的ps都会把无法获取args的进程（通常是内核线程）标记上方括号，用ps auxfc可以看到这些进程间的父子关系。而OpenBSD不会显示带括号的进程。\\n\\n### OpenBSD\\n\\nBSD系的init都是独立的可执行程序，大小分别是1M和300K，启动脚本都在/etc/rc.d，没看到init.d。但也有不同，比如FreeBSD，PID为0的进程叫kernel，Idle是11号，2之后的进程名也是内核进程，而OpenBSD却看不到2之后的进程。\\n\\nBSD风格的init和传统的Unix风格或者叫SysV不一样，最显式的差异在于读的文件是/etc/rc文件，传统的SysV读取/etc/inittab文件，现在Linux中用的比较多的是systemd方式，不过这个程序使用了cgroup和fanotify方式，导致无法迁移到BSD系统。\\n\\n程序只有一个C语言文件，非常干净。真正业务开始是个非常有趣的循环\\n\\n```\\ntransition(state_t s)\\n{\\n\\tfor (;;)\\n\\t\\ts = (*state_funcs[s])();\\n}\\n```\\n\\n通过给定一个s的初始值，确定一个初始函数，通过这个函数返回下一个状态，又会进入下一个函数，如果反复恰如完整的状态机在运转。\\n\\n默认的循环共有三重，`runcom->read_ttys->multi_user`，第一个runcom就是读入/etc/rc脚本，这也是rc这个文件名的由来。\\n\\n最后一个multiuser阶段就是做了waitpid操作,对每个waitpid返回的进程号，会尝试从RB树中找对应的session，因为unix有远程登陆概念，登陆的上岸点则是tty，每次的登陆就是一个session。如果没有就结束了，如果还有session需要清空会话的日志并从RB树中去掉这个节点。login/logout是BSD的系统函数，会操作/var/log/wtmp和var/run/utmp文件，并记录登陆的用户名。还会用到utmp.h的头文件，根据man的描述，是用于login record。正因为有这些文件，用who命令才能实现。\\n\\ninit的程序体现了很多login/logout/tty的概念，因为Unix在出现的时代就是用于远程访问的，只是当时访问的介质不是网线，而是电传打字的设备。因为只是介质不同，和网络访问的概念是相通的。程序本身是静态的，一旦运行起来就要归属到session，通过login/logout来创建和销毁session。常规的login一定是由物理硬件发起，这个硬件就被抽象成tty。除了远程登陆的session，也存在fork出的程序，这些程序可以在同一个session，也可以另起一个会话，如果要新建会话，就用setsid()函数。init程序所属的会话，并没有谁主动来login，只能通过setlogin(\\"root\\")方式手动指定会话所属用户。每个会话只能有一个login name。"}'));jctx.push(JSON.parse('{"id": "180813", "tag": "net", "text": "# UDP和相关操作\\n\\nTCP属于有连接协议，所以一定需要有bind操作。服务端显式bind，客户端在connect时会内OS隐式bind。一直不确定UDP要不要bind，正好有同事问起组播和单播如果监听同一个端口，如何区分。查看代码才知道UDP的bind在这种场景就有意义了。\\n\\n先说广播，把0xFFFFFFFF通过bind和UDP的socket绑定，最好再用setsockopt(SOL_SOCKET, SO_BROADCAST)配置。\\n\\n如果是组播的D类地址段，范围是[0xE0000000, 0xF0000000)，在这个区间内，绑定后用setsockopt(IPPROTO_IP, IP_ADD_MEMBERSHIP)方式加到组播组。\\n\\n单播的socket和网卡的IP地址用bind关联。\\n\\n如果是一张网卡要同时收UDP的单播和组播，对这两个socket都做一次setsockopt(SOL_SOCKET, SO_BINDTODEVICE)。把地址和eth0这样的网卡名关联上。\\n\\n顺便再谈谈选项分类。可以看到有SOL_XXX和IPPROTO_XXX这两大分类。上面没有列出的，还有SOL_IP、IPPROTO_TCP等。SOL的层级比IP和TCP都高，广播数据直到UDP才会被处理，和在IP层处理的组播不同，因此选项前缀也不一样。\\n\\n广播的地址有4种，工作中我只用到了全为1的受限广播，只有主机号全为1的广播地址没有接触过。"}'));jctx.push(JSON.parse('{"id": "180819", "tag": "tool", "text": "# 消息队列理解\\n\\n为了实现观察者模式提供的一种中间件，串接起生产者和消费者两端。不同的场景要选择合适的实现。RabbitMQ有6种工作模式，也有Exchange,Binding,Queue,RouteKey等很多概念，适用于业务复杂场景。Kafka只有topic和partition，因此吞吐量大，但业务就需要使用者手动处理。\\n\\n## RabbitMQ的模式\\n\\n6种模式分别为Hello world、Work queues（工作队列）、Publish/Subscribe（发布订阅）、Routing（路由）、Topics（主题）、RPC（远程调用）。除了RPC模式外，其余的模式都是从简单的使用到更为灵活的使用。\\n\\nHello world和Work queues比较简。消费者声明一个队列（Queue）才能收消息，增加队列一方面可以把多个消费者合并，另外能多些特性，比如消息要不要持久化，要不要做排它性。\\n\\n最简单的投递，有了Queue消息就能贯通了。这种模式的Q和设备侧的事件定义很像，生产者指明要发给这个Q，不关心谁来收，需要这个Q的消费者去响应并做逻辑就行。\\n\\nPublish/Subscribe、Routing、Topics这几个模式都依赖Exchange，源于RabbitMQ遵循的AMQP规范不允许直接向Q投递，而引入的概念。Exchange有3种类型fanout,direct,topic,header，很像UDP的广播，单播，组播。\\n\\n* Publish/Subscribe模式: 对应fanout型exchange。最粗暴，全发送\\n* Routing模式: 对应direct型exchange，必须严格匹配，简单的分类器\\n* Topics模式: 对应topic型exchange，可以用通配符模糊地表示关联关系\\n\\n前两种直接发给Q的模式，用了名字是空串\\"\\"的一个特殊Exchange，后三种则必须指定Exchange名字。\\n\\nBinding是很简单的，虽然存在但很无脑。只有通配匹配，绑定的算法才变得重要起来。绑定是Exchange给消费者的提示，生产者需要给出RouteKey。所以即使同一个Exchange，投递的消费者可以千差万别，它的数量级也是最少的。\\n\\n## RabbitMQ使用\\n\\n默认启动会有epmd监听4369端口和beam的25672。启用web插件后，只能用guest用户，再添加admin后，就能用15672端口进入web控制台。\\n\\n```\\nrabbitmq-plugins enable rabbitmq_management\\nrabbitmq-server\\nrabbitmqctl add_user admin admin\\nrabbitmqctl set_user_tags admin administrator\\nrabbitmqctl set_permissions -p \\"/\\" admin \\".*\\" \\".*\\" \\".*\\"\\nrabbitmqctl shutdown\\n```\\n\\n## RabbitMQ和Kafka的比较\\n\\nRabbitMQ的劣势\\n\\n1. 在消息投递时必须由客户端指明IP，这就给无感横向扩展带来不便\\n2. 默认没有分区机制，虽然官方有个sharding插件，但似乎用得不多\\n3. 只有主备，类似副本机制\\n\\nKafka的劣势\\n\\n1. 由于Kafka每条消息都会写磁盘，当topic数量变多后，并发多进程的随机写入会导致性能会急剧下降，RabbitMQ大多数情况把消息保存在内存，不会有此问题\\n\\n为了从MQ迁移到kafka，在MQ协议中引入了分区概念。MQ的exchange和kafka的topic似乎对标，都必须手动创建，否则消息不能流转。MQ的队列从属于exchange，消费者可以随意创建\\n"}'));jctx.push(JSON.parse('{"id": "180829", "tag": "tool", "text": "# 一次反汇编的崩溃定位\\n\\n将设备搜索功能从子节点迁移到管理节点，虽然程序没有变动，但会出现启动就崩溃问题，重启后不会崩溃。\\n\\nGDB跟踪发现是死在第三方的so库，直观的解释是free的内存被破坏。可是重启后没问题，开始就没往这方面去想。第二天，同事说怀疑是否网卡数量过多引起，原来子节点没有很多网卡，重启是因为主备切换导致虚网卡消失，所以就不会重启了。加上这个第三方库做设备搜索工作，确实很有可能在绑定网卡时出了什么问题。\\n\\n于是开始研究反汇编代码，发现存在一个大循环，跳转前有`addw 0x01, -2(%rbp);cmpq 0x00 -10(%rbp);`。后一句cmpq还原成代码，是`p==NULL`，前一句则是计数，等循环结束就能知道一共有多少张网卡。看来很可能是由于没有控制好网卡上限，导致内存溢出。\\n\\n再回到函数开头，查阅了x64的汇编调用规则，第一个参数在rdi，第二个参数在rsi，第三个参数rdx（展开说一下，这个规则随着位数、编译器不同，VC用的寄存器就不同，而32位默认全放在堆栈，除非开启fastcall模式才会用寄存器传参）。可以看到rdi被放了一段内存。之后又高了另一个so的库也分配了内存，去掉malloc在分配前的16字节cookie（取决于实现），发现刚好是挨着的。在最后执行free的时候，cookie部分被前面所写坏，导致free时abort退出。最后又找到了进入函数前的hardcode的分配0x75C内存的new操作，基本可以定论不换so的情况下，只能依赖限制网卡数来规避问题了。\\n\\n限于汇编能力不足，具体是哪一行写坏内存仍不可考，但利用这些点，算是把问题给交代了。"}'));jctx.push(JSON.parse('{"id": "180901", "tag": "protocol", "text": "# GB28181理解\\n\\n全称由3个词组合，安全防范，视频监控，联网系统。视频监控领域的通用标准，用了信令SIP和媒体RTP/RTCP的模型。选用SIP是有多重原因\\n\\n1. 视频监控有大量的视频数据要传输，而建立起这样一个视频会话，最现成的就是RTSP或者电话的SIP协议。\\n2. RTSP虽然是专为视频业务设计的协议，却基于一个前提，必须知道流源的地址。在中心化分发场景，多个客户端向一个流源请求视频是非常合适的。但是视频监控反过来，往往只有很少的客户端，却有大量潜在的摄像头，因此RTSP出局。\\n3. 要收集散落在各处的摄像头，需要向一个中心节点主动报备，恰巧SIP就有这个功能。\\n\\n综上三点，SIP就奠定了在整个体系中的基础地位。\\n\\n核心的SIP指令只有6条，INVITE、BYE、REGISTER、CANCEL、ACK、OPTIONS，相比H323简单很多。但SIP毕竟是用于建立电话的协议，视频监控还有很多的需求，好在有INFO和MESSAGE两个扩展，有了信令控制的基础，INFO具备改变会话的能力，典型应用是DTMF，即在电话中点击数字，所以用于回放控制是很自然的。而MESSAGE并不构成一次SIP的dialog，所以用在设备控制上，类似短连接语义。\\n\\n除了请求应答模型，SIP还支持SUBSCRIBE/NOTIFY/PUBLISH模型，可以推送消息，甚至还有基于SIP的IM协议。\\n\\n控制协议分请求和应答，请求有3种，Control, Query, Notify。应答是Response。体现在XML的最外层结构。\\n\\n统一编码有A和B两种规范，前者20位，后者18位。我只见过A。编码即能表示设备又能表示用户。存储设备被称为前端主设备，而相机被称为前端外围设备。\\n\\n目录概念解释\\n\\n分设备目录和文件目录。设备目录包含3种:设备，区域，系统。文件只有1种:录像。每种都用一个complexType定义对象语义。业务上经常会订阅目录，发生变化后下级推送。\\n\\n查录像协议很有特点，一个请求会有若干次的返回。一方面，MESSAGE请求本身就有应答，另外UDP受限于MTU无法携带大量消息，必须要分段传输。大华网关实现查目录，默认一次返回1条，可以配置一次返回5条。"}'));jctx.push(JSON.parse('{"id": "180905", "tag": "lang", "text": "# 词法语法之后\\n\\n以前写过3篇词法语法工具使用的记录，对完整的编译过程来说，后面的代码生成和执行却一直忽略了。\\n\\n如果只是写计算器，到语法生成勉强还够用。但要想支持分支，函数定义、调用等，\\n复杂性就真正体现出来了。\\n\\n为了引入函数，必须把解析分为定义态和执行态。从函数定义开始到结束，要做代码生成。其它情况则取指令执行，是两个完全不同的处理，可以加标志位控制，也可以决定是否允许嵌套函数定义，简单起见可以先禁止。\\n\\n要保存函数定义，就要有一套指令码和虚拟机来执行。指令可以不必多，但基本的Load/Save/Cmp/Jmp/Call是不可少的。从Load/Save又可以分为基于栈和基于寄存器两大流派。\\n\\n构建指令集，先确定用定长或变长，基于栈还是寄存器。以定长寄存器为例：将若干bit位解码为指令，指令一旦确定，剩下bit位的操作数的解析方式就随之确定了。不同指令需要的数是不同的，1到3个都有可能，所以操作数的解析并不固定。使用拉掩码方式分别提取对应位数构成数据。\\n\\n指令集除了表示做什么外，寄存器和立即数都是用索引号代替，所有的寄存器用栈形式分配，立即数要有常量池来存储和索引。如果不允许函数内嵌套定义函数，指令集+常量池这种模式就足以表示了。如果允许嵌套定义，要函数原型内递归地存储，难的是要处理upvalue。反观C语言，既不允许嵌套定义，最外层只能是main函数为入口，实现就相对简单而纯粹了。\\n\\n有了指令集，还必须记住当前的指令执行位置，IP指针，在Lua中用savedpc变量保存。取指令用`*(savedpc++)`，执行当前指令时，IP指针已经向前走了一步。IP指针和函数在全局栈上的位置共同构成一个函数的必备元素。\\n\\n指令通常顺序执行，加上比较和跳转后，就能实现分支和循环，跳转步数需要一些技巧获得。\\n\\n指令，变量环境，常量环境，这3者构成函数原型的全部，运行时再将常量加载到变量。也可以将常量全部做成伪变量，只是写代码会非常繁琐。"}'));jctx.push(JSON.parse('{"id": "180920", "tag": "lang", "text": "# 指针的三种面貌\\n\\n起因是同事发了一段C语言的汇编代码，理解不透，代码如下\\n\\n```\\nifAddrSt = ifAddrSt->ifa_next;\\n\\n0x00000000004006a5 <+221>:  mov  -0x10(%rbp),%rax\\n0x00000000004006a9 <+225>:  mov  (%rax),%rax\\n0x00000000004006ac <+228>:  mov  %rax,-0x10(%rbp)\\n```\\n\\n能看出把rbp-10位置上的值做了一通操作后赋值回自身，但是为什么是两次取地址非常迷惑。\\n\\n在分析汇编之前，先想明白指针的几种表示和对应的汇编形式。先说普通的变量，比如最简单的`int i=1;`这条语句，i就有两种形式，i和&i。&i是i这个变量的地址，对应rbp加减一定的偏移量。实际代码中很少会用到&i，大多数时候都是用i，也就是&i地址存放的值，这个值对应的汇编就是(%rbp)。\\n\\n说完普通变量，再看指针。指针除了上述两种形式，还多了提领`*`操作。因此对于`char* p;`，rbp就对应&p，(rbp)才是p。`p->next`的操作可以等价为`*p.next`，因此才有了刚才汇编中的前两句，对rbp做了两次取址操作就好理解了。\\n\\n1. 第一句(%rbp)将ifAddrSt放到%rax寄存器\\n2. 第二句等效的C语言是`*ifAddrSt->offset 0`，所以(%rax)就够了，不需要偏移\\n3. 第三句将值重新写回ifAddrSt，此时不用提领%rax，值写入(%rbp)。"}'));jctx.push(JSON.parse('{"id": "180923", "tag": "lang", "text": "# 自制编程语言的历程\\n\\n尽管还存在缺陷，即便如此从9月16号开始重新启程，已经比过往强得太多。大约从2009年便有实现一门语言的想法，如今看到希望，虽然很简陋，却也算原型完备，令心结解开，不再纠结于要不要学习新的语言。\\n\\n词法和语法都是工具生成，不在此文罗列，主要从归约出生成语法后的事。\\n\\n## 转译到字节码\\n\\n除了从源码执行，还可以从字节码执行，而源码又能输出成字节码（反之也可以，但那更多是破解用）。字节码通常不能无脑序列化，会有个非常简单的重组过程，三者构成如下关系。\\n\\n```\\nSource-----|\\n         VM(IR)---Run\\nSerial-----|\\n```\\n\\n最初是雄心勃勃想按二进制定长方式指令，但发现融合常量池的实现周期太长，为了验证可行性，还是全部用可打印字符，便于调试。格式很简洁，一字节指令加上用逗号分割的指令数，最后用分号结尾。如果是顺序指令，将每条连在一起就构成完整指令。\\n\\n顺序其实不值一提，函数、分支、循环才是三个最难的部分。理论上循环可以由分支和尾调用替代，从字节码实现看，确有相似性。\\n\\n先说函数，这是十年前最让我头疼的难关，甚至在想明白用字节码做为间接层后，仍为返回值该放哪里思考良久。函数必不可少的成分有二，指令和环境。指令永远不变而环境可链表，递归处理时要做好保护和复原。指令可以持久化而环境不需要，这两个阶段用不同的结构会更好，而在传递中指令最好能做到所有权转移。\\n\\n环境除了保存局部变量，还要保存入参。每次调用相当于两个环境间的数据复制。我现在的做法，得到指令码还捆绑一个环境的做法是错误的。\\n\\n## 转译到另一种语言\\n\\n业界对此有专门的叫法transpiler，比较难的点是对嵌套结构的处理，自然地统一用cons/car/cdr方式来表达，在实现时为求简单，把值也保存在cons。cons看似简单，其实可以表示树和链表结构（不使用car就是单链表）。\\n\\nC语言在表示链表移动时，要分配内存和链表移动放一起，否则很容易引起内存分配了，但链表没有指向新分配的内存。"}'));jctx.push(JSON.parse('{"id": "181021", "tag": "web", "text": "# 【转】对PHP的分析\\n\\n我不考虑可以用封装库解决的问题，比如不考虑 JSON api，in_array 默认 == 等等\\n我不考虑各种 VM 实现的问题，比如 C 扩展常驻内存\\n\\n我不考虑 PHP 文档的问题，不考虑 PHP 历史上的问题，比如 5.3 中不能 parse $cb()()\\n我不考虑 parser 的报错信息难读问题\\n\\n文章内容目录：\\n\\n* FP：set! 和 defun 是不一样的，但是 PHP 连 set! 都不如\\n* MP: MP 不是 toString 或者 any -> String， 而是 Expr -> Expr 和 Expr -> Q\\n* OO: The big idea is messaging.\\n\\neechen 说我们可以使用 $func来在 PHP 中实现 FP，但是这是不可行的。让我们考虑最简单的 fib\\n```\\n$fib = function ($x) use ($fib) {\\n  if ($x == 0) {\\n    return 1;\\n  }\\n  return $x* call_user_func_array($fib, [$x-1]);\\n};\\nvar_dump($fibs(10));\\n或者\\n\\n$fib = function ($x) {\\n  if ($x == 0) {\\n    return 1;\\n  }\\n  return $x* call_user_func_array($fib, [$x-1]);\\n};\\nvar_dump($fibs(10));\\n```\\n二者皆会报错，第一个说找不到 $fib，第二个说 $fib 是没有定义的 NULL。\\n\\n继而我们猜测这只是 PHP 解释器的一个小 bug，我们只需要把 closure 的位置在 AST 往下压一层之后 use 就能找到了，比如\\n```\\nfunction id($x) {return $x;)\\n$fib = id(function ($x) use ($fib) {\\n  if ($x == 0) {\\n    return 1;\\n  }\\n  return $x* call_user_func_array($fib, [$x-1]);\\n});\\nvar_dump($fibs(10));\\n```\\n依然是找不到 $fib。\\n\\n\\n可能这时候我们只是认为 use 之前需要声明，只是一个 php 解释器上实现的一个小 bug，比如\\n```\\n$fib = NULL;\\n$fib = function ($x) use ($fib) {\\n  if ($x == 0) {\\n    return 1;\\n  }\\n  return $x* call_user_func_array($fib, [$x-1]);\\n};\\nvar_dump($fibs(10));\\n```\\n结果是 $fib 在 closure 中对应的值 NULL，无法被访问。\\n\\n这就是我们说 PHP 既不支持函数作为第一成员又没有 scope 的原因。scope 是作用域内 symbol 和 value 的绑定。PHP 并不存在一个正常的讲上层 scope 的某个 symbol 映射放到 closure 中的方法，PHP 的所谓的 use 只是即时地在 closure 中插入一个 $fib = NULL ，而并非是将对 $fib 的访问转移到上层 scope 的访问中。\\n\\n简单来讲，**PHP 所谓的 scope 不是 scope，而只是一个解释求值的 barrier，你不可能访问上层 scope 的 symbol。而 php 的 closure 也不是 closure，php 的 closure 只能绑定 value 而不能绑定 symbol。**\\n\\n如果说要强行 $func 来实现自指递归或者互指递归也不是不可以，那么你需要这么写\\n```\\n$scope = [];\\n$scope[\'fib\'] = function ($x) use ($scope) {\\n  if ($x == 0) {\\n    return 1;\\n  }\\n  return $x* call_user_func_array($scope[\'fib\'], [$x-1]);\\n};\\n$fib = $scope[\'fib\'];\\n\\n或者更加规范的，默认使用的 scope 入口和 defun\\n\\nfunction createDefun($scope) {\\n   return function($fname, $definition) use ($scope) {\\n       $scope[$fname] = function () use ($scope, $fname, $definition) {\\n          $args = func_get_args();\\n          $scope[$fname] = call_user_func_array($definition, array_merge([$scope], $args));\\n       };\\n   };\\n};\\n\\n$sp = [];\\n$defun = createDefun($sp);\\n$defun(\'fib\', function($scope, $x) {\\n  if ($x == 0) {\\n    return 1;\\n  }\\n  return $x* call_user_func_array($scope[\'fib\'], [$x-1]);\\n});\\n$fib = $sp[\'fib\'];\\n```\\n我只是觉得，「一个语言支持 FP 范式」和「一个语言需要自行实现 scope 然后就可以通过手动注入 scope 然后就可以 FP 了」应该是完全不同的两个意思吧？\\n\\n这也是我们说 「PHP 不是一门支持 FP 的语言」时和说「JS，Py 等等可以写 FP，但是毕竟不是一门 FP 语言」的不同。如果我们有其他语言的经验，（无论这语言是 Py2/Py3，JS，Perl5，还是利用 operation() 当作 function 的旧 CPP，甚至是他喵的 MatLab），我们可以看到他们访问上层 scope 中的 symbol 是自然而然的；而 PHP 我们要么自己实现一个 scope 和 defun，要么就是使用 array(__NAMESPACE__ . \'\\\\\' . $className, $funcName) 和 static 这种并非设计为 FP 的 ugly hack。所以我们可以安全地宣称，PHP 是不支持 FP 的。\\n\\nPS：在本节末尾指出来一下， eechen 原文误以为「PHP 变量可以绑定类」，实际上 PHP 变量只能被赋值为类的实例而不能绑定类。这种不能绑定类特性的缺乏导致了没法实现 immutable-js BaseRecord = Record({...}) 之类的基于函数的类派生，也对实现利用 cache 来加速 immutable 变量的生成增添了很多不必要的 boilerplate code\\n\\nMP: MP 不是 toString 或者 any -> String， 而是 Expr -> Expr 和 Expr -> Q\\n\\n一个语言是否具有 MP 的能力并不是其是否有一个叫做 XXXRefection 的方法，实际上 PHP 的 reflection 只是一系列拿到源码的 toString；这类方法在其他语言中也是常见，比如 ES3 时代就有了 Function.prototype.toString这样的方法\\n```\\nfunction hasContent() {/*\\n    Line 1\\n    Line 2\\n    Line 3\\n  */}\\nvar content = hasContent.toString.split(\'\\\\n\').slice(1, -1).join(\'\\\\n\')\\n```\\n如果我说 ES3 时代就实现了 MP，我觉得我会被 JSer 打死。甚至 ES5 时代 styled-component 通过了 Tagged templates 实现了 JS 中解析运行 CSS，JSers 也没有吹什么 「JS 是一个支持了 MP」的语言（虽然我明年准备看看能不能借用 tagged template 可以访问 js obj 的特性来实现一些简单的可访问 JS 变量的 DSL，当然这只能说能有一点 MP 技巧；和真正利用 MP 做 code gen 离得很远）\\n\\n\\nMP 是利用已知代码进行 code generaation 的手段。比如 Julia 如果不想多次写 dimension 可以（免责声明：自转行后大概有一年没写 Julia 了，所以下面可能会有简单的语法错误或者漏写 global 或者 quote）\\n\\nconst c = @cmm( squeeze(sum(mean(a,3),2))) ## cmm stands for common math macros\\n\\n扩展成如下代码以避免写两次 dimension\\n\\nconst c = squeeze(sum(mean(a,3),2)), (2,3))\\n\\n同样我们可以轻松地在处理 NaN 的时候利用 macro 来做替换\\n\\nconst c = @cmm( periodic(mean(x,2, isNaN=false)))\\n\\n替换成这样的形式，也就是我们在没有提供 isNaN 接口的时候，一定程度上可以类似用写 R 的方式处理数据\\n\\nconst c =  periodic(nonNaNMean(x,2))\\n\\n甚至可以模拟一下 typeclass，下面是利用 MP 将 svd, eof, 等等方法从 Array{Float, 2} 扩展到 Array{Float64, n} 的一种 macro 示例\\n\\n```\\nconst (eofs, pcs) = fuck2D(\\n  quote\\n    global SST // SST is a 3D array of lat * lon * time\\n    describe(SST, 3) // 3 is the timal dimension;\\n    return svd(SST)\\n  end\\n)\\n这将扩展成现将 SST 转成 2D array， 然后将 分析后的 1D array 转回 2D 的方法\\n\\nconst (eofs, pcs) = do\\n   global SST\\n   SST_config_#1 = create_Dconfig({timal_dims: 3})\\n   (SST2D_#1, from_1D_to_sp, from_1D_to_timal) = decompose(SST, SST_config_#1);\\n   (eofs1D_#1,pc1D_#1) = svd(SST2D_#1)\\n   eofs_#1 = intercept_1D(eofs1D_#1, from_1D_to_sp)\\n   pcs_#1  = intercept_1D(pcs1D_#1, from_1D_to_timal)\\n   return (eofs_#1, pcs_#1)\\nend\\n```\\n\\n这类宏生成代码节省了大量手动写 adapter 的时间，实现了类似 type class 的效果。另外一类常用的 MP 做法是将任何一个需要埋点的函数\\n```\\nfunction func(a,b,c) {\\n     return func(a\', b\', c\')\\n}\\n这类代码转换成类似\\n\\nfunction func_effect(f, a, b, c) {\\n      call_effect(f, a\', b\', c\')\\n}\\n```\\n这样我们可以在 call_effect 中使用统一的 effect 处理和上下文传递等等。\\n\\n首先PHPer 看不懂 MP 但是又说 PHP 支持 MP 难道是我的错么？\\n这里只是展现一下为什么 MP 的实践需要 AST；在这类需求中，文本替换然后 eval 显然是不安全而且不够灵活的。不在 AST 上 walk 一下还能怎么办呢，难道拿头锤 regex 做替换？\\n\\n一个 PHPer 可能会争论说其实这类 MP 实践在 PHP 中是可以做到的；然后他可能会举出类似于 Roave/BetterReflection这样的库；显然，在看过这种库之后，即使不懂 MP 也能发现很明显的风险：\\n\\n其 parser 库并非是 php 解释器自己的 parser，而是另一种 PHP 实现的 https://github.com/nikic/PHP-Parser ；也就是任何 PHP-Parser 和 php 解释器 parser 的不一致都会影响到结果 （而且难以 debug）\\nPHP 并没有 eval(Expr) 的手段，对于变换后的 AST，需要使用 PHP-Parser 来 write string，然后执行转写的 string。这不仅仅依赖于 PHP-parser 的正确性，而且任何 php 的报错都会在 eval 这一行，eval（string） 永远是危险的呀\\n\\n而且不可避免的，这样的 parser 实践还会导致所有含有副作用的语言中 MP 共同要面对的问题：副作用跟踪。考虑到我们在某个文件中元编程两次\\n\\neval(AST2String(expr1))\\n\\neval(AST2String(expr2))\\n\\n如果在 expr1 中含有了\\n\\nfunction foo {...}\\nbar_effect = ...；\\n然后 expr2 含有了\\n\\nfunction foo {...}\\nbar_effect = ...;\\n然后 expr1 的部分结果就有被 expr2 覆盖的风险。\\n\\n在 Julia 中，macroexpand 直接会分析上下文并且在变量后面加上 `_#number` 这样的后缀防止覆写变量；而且很多 lisp 系语言中，eval 本身是 lexical scope 下在一个新的 scope 进行的。\\n\\nOOP：三原则或者四圣谛只是 90 年代类似 Java 语言对于 OOP 的一种实现手段而已\\n\\n本来我以为我这里不需要解释一下 extends 的问题，可以直接讨论层次复杂度和静态检查的关系。我发现我还是必须引用一下 Alan Kay 的名言 [The big idea is \\"messaging\\"](http://wiki.c2.com/?AlanKayOnMessaging)\\n\\n只要我们能够实现层次划分和父子 components 之间的 messaging 传递，那么 OOP 所需要的 divide and conquer 是自然而然的，而且会便利实现 testable module （类似于为了测试方便， database 仅仅被实现为获得值和更新值的一种特例，而非必要的 backend）。\\n\\n而旧时代的 java 以及其所代码的三原则，实际上很容易出现两个很讨厌的事情，一者是子类对父类的副作用污染，另外一种是只要一个香蕉但是拿到了香蕉加猴子加森林。\\n\\n当然 data class 和 sub typing 本身就是很讨厌的强行 binding 数据和方法的手段，但是如果不得不这么做了，实际上我们更常委托的方式而非 extends 的方式处理父类和子类的关系。当然，把大部分所需要的方法重新写一遍是很讨厌的 repeat yourself 行为。所以对于动态语言，我们常常依赖约定自动推导 b -> f a -> f b 或者 (a-> b) -> f a -> f b 来压缩类的层次。Java 等等静态语言虽然不能使用这种方法，但是静态分析可以保证在使用工厂或者其他委托方法时候代码的正确性。\\n\\n然后 PHP 学 Java 了，但是问题是 PHP 能够用静态分析保证委托足够复杂时的正确性，PHP 行么？没有静态分析学 java 就像猪学鸟跳出飞机一样。\\n\\n尾声\\n\\n如果你不会 FP，不懂 FP，也没写过 FP，那么就不要说别人「无脑黑 PHP 不支持 FP」\\n如果你不会 MP，不懂 MP，也没写过 MP，那么就不要说别人「无脑黑 PHP 不支持 MP」\\n如果你对 OO 的理解只停留在三原则上....算了，对于这种 ill-defined 的东西你开心就好\\n如果你只会 PHP，或者只会用 PHP 的方式写很多副作用满天飞的语言... 就不要讲什么「好的程序只和程序员有关，和程序语言无关」；这类编程经验不能教人「什么是好的程序」\\n\\n其实说句实话，作者还真不是了解 php，起码一些基础不行，简单的问题复杂化了，或者是 JavaScript 给你了一些固定的思维方式。明显就是作用域问题，至于为什么 use 继承不了，考虑考虑操作符优先级。\\n\\n```\\n$fib = function ($x) { \\n  global $fib;\\n if ($x == 0) { return 1; }\\n return $x * $fib($x-1);\\n};\\n```\\nvar_dump($fib(10))"}'));jctx.push(JSON.parse('{"id": "181025", "tag": "tool", "text": "# Graphviz使用说明\\n\\n## 命令说明\\n\\ndot(官方命名gv格式)是最核心的语法格式，渲染引擎有多种，比如dot/neato/fdp/twopi，暂时来看dot画的图最符合直觉，其它没有想到应用场景。\\n\\n除渲染命令外，还有一些和dot配合的检测或统计工具。\\n\\n* acyclic: 计算是否存在循环图\\n* gc: 类似wc，统计dot图的点、边、子图数量\\n* edgepaint: 有交叉边时增加色彩区分\\n* gvgen: 生成内置的若干形状，作为画图的参考\\n* nop: 格式化dot源文件，试用后发现会丢弃注释，且排列顺序也不符合预期\\n* unflatten: 调整图的比例，适用于一些孤立点很多的图\\n\\n## 包含常用元素的示例\\n\\n中文用UTF8编码，但不能首字母用中文，前缀用空格规避。\\n\\n```\\ndigraph abc {\\n  rankdir=LR\\n  graph [bgcolor=\\"gray\\"]\\n  node [shape=box, fontname=\\"simsun\\"]\\n  edge [color=\\"darkgreen\\", fontname=\\"Microsoft YaHei\\"];\\n\\n  box1 [shape=record, label=\\" 中文1\\", fontname=\\"simhei\\"]\\n  box2 [shape=record, label=\\"abc | def\\", color=\\"gold1\\", fontname=\\"simhei\\"]\\n  box3 [label=\\"{json | {bson|cpkg} }\\"]\\n\\n  box1 -> box2 [weight=10]\\n  box2 -> box3 [label=eval, color=deeppink]\\n\\n  subgraph {}\\n}\\n```\\n"}'));jctx.push(JSON.parse('{"id": "181027", "tag": "web", "text": "# 跨域和同源策略\\n\\n浏览器的三大线程\\n\\n1. javascript引擎线程(GUI渲染也在这个线程)\\n2. 浏览器事件触发线程\\n3. HTTP请求线程\\n\\n问题是这样：在localhost页面用XHR发起请求，始终回调error函数。\\n\\n原因：首先这是个跨域的请求，而规范定义XHR不允许跨域请求。出于安全考虑，所有的JS请求都不能跨域，但为了使用CDN的多个源加载机制，对script或img标签的src属性开了个口子，允许跨域，但为了防止被滥用，只支持GET方式，对于CDN分发来说已经足够了。所以就有人基于此开发了JSONP机制。\\n\\n我需要POST，所以JSONP不通。为求简单用了同步方式，同步请求规定withCredentials属性必须false，跨域却必须是true。因此要想跨域，只能用异步方式。\\n```\\nxhr.withCredentials = true;\\nxhr.open(method, dst, true);\\n```\\nJS不能跨域展开一下，浏览器并不会拦截跨域请求(不严谨，如果content-type有值还是会会改动，下述)，抓包能看到浏览器发出了数据，但是在收数据后，会对数据做校验，不符合规范就不把收到的数据给JS。\\n\\n网上很多说通过响应header增加`Access-Control-Allow-Origin: *`来解决，但都没有细说是在哪个server端增加。来分析一下跨域定义：访问A页面，这其中有一段JS脚本向B页面请求数据，虽然跨域，浏览器还是会向B请求数据，请求的头中会加上来自A站的标识`Origin: http://localhost` 。直到发现有刚才那段申明，才把数据给JS，否则就不给JS。从字面意思也好理解，对B来说，Origin指的是A。只有B允许A（或`*`所有人）来请求数据，浏览器看到既然B都特地声明数据开放给A了，才会把给JS。如果B没有说这句话，默认是不给JS的。\\n\\n再说说跨域的高级变化，又称为preflight机制。只有简单请求能够直接发出去，而复杂请求浏览器会修改XHR发出的请求。简单请求包括HEAD/GET/POST，且不允许设置Content-Type等若干头部。一旦发现违反，就会把方法改成Options向服务器探探路，只有应答带了`Access-Control-Allow-Origin: *`等若干字段，才允许重发真正的请求，且即使这样，仍有些头是不允许带的。\\n\\n如果HTTP的请求头中有特殊字段，同样会触发浏览的preflight机制，必须在响应端增加`Access-Control-Allow-Headers: *`，否则浏览器也会不予显示。\\n\\n而表单不受同源限制，因为表单一旦发出，整个页面就切换了，原页面拿不到新页面的内容。所以说同源策略的本质是，一个域名的 JS ，在未经允许的情况下，不得读取另一个域名的内容。但浏览器并不阻止你向另一个域名发送请求。\\n\\n用异步就一定会涉及回调，看看MDN上关于回调的写法\\n```\\nvar xhr = XMLHttpRequest();\\nxhr.onreadystatechange = function () {\\n    switch(xhr.readyState){\\n      case 1://OPENED\\n        break;\\n      case 2://HEADERS_RECEIVED\\n        break;\\n      case 3://LOADING\\n        break;\\n      case 4://DONE\\n        xhr.response; //do something\\n        break;\\n    }}\\n```\\n我最疑惑的就是function中的xhr表示谁？函数无参也无定义，xhr只能链式地向上查找，回调这个函数的主体是xhr，所以向上找的时候，一定能找到xhr变量。但我觉得更好的写法还是`switch(this.readyState)`，引入一个同名变量太容易引起混淆。\\n\\n上述写法是早期xhr的推荐做法，现在新的浏览器还可以用onload和onerror方法，看起来更简洁\\n```\\nreturn new Promise(function (resolve, reject) {\\n    var xhr = new XMLHttpRequest();\\n    xhr.open(method, url);\\n    xhr.onload = resolve;\\n    xhr.onerror = reject;\\n    xhr.send(...)  // POST has string body\\n}\\n```\\n\\n这两个方法回调时的惟一参数是ProgressEvent类型，target.response就是对端返回的内容。target是其父事件Event的属性，ProgressEvent继承得到target属性，表示这个事件被分派的对象，此处代表XHR对象。"}'));jctx.push(JSON.parse('{"id": "181028", "tag": "protocol", "text": "# 视频的封装格式\\n\\nES（Elementary Stream）流是基本码流，包含音频、视频、数据的连续码流。编码器输出的都是这种类型。\\n\\nPES（Packet Elementary Stream）流是打包的基本码流，是将ES根据需要打包成长度不等的数据包并加上包头就形成了打包的基本码流PES。\\n\\nTS（Transport Stream）流，也叫传输流。是由固定长度的188字节的包组成。含有独立是一个或者多个program,一个program又可以包含多个视频，音频和文字信息的ES流。每个ES流会有不同的PID标示。为了分析这些ES流，TS有些固定的PID来间隔发送Program和ES信息表格：PAT表和PMT表。\\n\\n(在MPEG-2系统中,由视频, 音频的ES流和辅助数据复接生成的用于实际传输的标准信息流称为MPEG-2传送流)\\n\\n封装 : 就是捆绑打包, 将画面视频文件和音轨文件打包在一起, 并按照一定规则建立排序和索引, 便于播放器或播放软件来索引播放. 包括AVI / PS(Program Stream)/ TS（Transport Stream）/ MKV（Matroska）等.\\n\\nPS是节目流编码器出来的是TS流，传输接口为asi口，编码器整个作用过程是把模拟信号变成ES，再打包成PES，再打包成TS流输出。\\n复用器是把多路单节目或多节目TS流合称1路多节目TS流，再给调制器。\\n数字卫星接收机出来的是TS流，也是asi接口，可能包含一路或多路节目，有的还同时有一路模拟信号视音频输出。\\n模拟卫星接收机出来的是模拟视音频信号。，PS流与TS流的区别在于，PS流的包结构是可变长度的，而TS流的包结构是固定长度的.\\n\\nTS流的解码过程-ES-PES-DTS-PTS-PCR\\n\\nTS 流解码过程:\\n\\n1. 获取TS中的PAT\\n\\n2. 获取TS中的PMT\\n\\n3. 根据PMT可以知道当前网络中传输的视频（音频）类型（H264），相应的PID，PCR的PID等信息。\\n\\n4. 设置demux 模块的视频Filter 为相应视频的PID和stream type等。\\n\\n5. 从视频Demux Filter 后得到的TS数据包中的payload 数据就是 one piece of PES，在TS header中有一些关于此 payload属于哪个 PES的 第多少个数据包。 因此软件中应该将此payload中的数据copy到PES的buffer中，用于拼接一个PES包。\\n\\n6. 拼接好的PES包的包头会有 PTS，DTS信息，去掉PES的header就是 ES。\\n\\n7. 直接将 被拔掉 PES包头的ES包送给decoder就可以进行解码。解码出来的数据就是一帧一帧的视频数据，这些数据至少应当与PES中的PTS关联一下，以便进行视音频同步。\\n\\n8. I，B，B，P 信息是在ES中的。\\n\\nES 是直接从编码器出来的数据流，可以是编码过的视频数据流，音频数据流，或其他编码数据流的统称。 ES 流经过 PES 打包器之后，被转换成 PES 包。 PES 包由包头和 payload 组成.\\n\\n在 PES 层，主要是在 PES 包头信息中加入 PTS( 显示时间标签 ) 和 DTS （解码时间标签）用于视频、音频同步。 其实， Mpeg-2 用于视音频同步以及系统时钟恢复的时间标签分别在 ES ， PES 和 TS 这 3 个层次中。在 ES 层，与同步有关的主要是视频缓冲验证 VBV （ Video Buffer Verifier ），用以防止解码器的缓冲器出现上溢或下溢；在 PES 层，主要是在 PES 头信息里出现的显示时间标签 PTS （ Presentation Time Stamp ）和解码时间标签 DTS （ Decoding Time Stamp ）；在 TS 层中， TS 头信息包含了节目时钟参考 PCR （ Program Clock Reference ），用于恢复出与编码端一致的系统时序时钟 STC （ System Time Clock ）。\\n\\n基本流程如下：首先 MPEG-2 压缩编码得到的 ES 基本流，这个数据流很大，并且只是 I ， P ， B 的这些视频帧或音频取样信息，然后加入一些同步信息，打包成长度可变长度的数据包 PES ，原来是流的格式，现在成了数据包的分割形式。同时要注意的是， ES 是只包含一种内容的数据流，如只含视频，或只含音频等，打包之后的 PES 也是只含一种性质的 ES, 如只含视频 ES 的 PES, 只含音频 ES 的 PES 等。可以知道， ES 是编码视频数据流或音频数据流，每个 ES 都由若干个存取单元（ AU ）组成，每个视频 AU 或音频 AU 都是由头部和编码数据两部分组成， 1 个 AU 相当于编码的 1 幅视频图像或 1 个音频帧，也可以说，每个 AU 实际上是编码数据流的显示单元，即相当于解码的 1 幅视频图像或 1 个音频帧的取样。 MPEG-2 对视频的压缩产生 I 帧、 P 帧、 B 帧。把帧顺序 I1,P4,B2,B3,P7,B5,B6 帧的编码 ES ，通过打包并在每个帧中插入 PTS/DTS 标志，变成 PES 。在插入 PTS/DTS 标志时，由于在 B 帧 PTS 和 DTS 相等，所以无须在 B 帧多插入 DTS 。而对于 I 帧 和 P 帧，由于经过复用后数据包的顺序会发生变化，显示前一定要存储于视频解码器的重新排序缓存器中，经过从新排序后再显示，所以一定要同时插入 PTS 和 DTS 作为重新排序的依据。\\n\\n其中，有否 PTS/DTS 标志，是解决视音频同步显示、防止解码器输入缓存器上溢或下溢的关键所在。 PTS 表明显示单元出现在系统目标解码器（ STD- System Target Decoder ）的时间 , DTS 表明将存取单元全部字节从 STD 的 ES 解码缓存器移走的时刻。 视频编码图像帧次序为 I1,P4,B2,B3,P7,B5,B6,I10,B8,B9 的 ES ，加入 PTS/DTS 后，打包成一个个视频 PES 包。每个 PES 包都有一个包头，用于定义 PES 内的数据内容，提供定时资料。每个 I 、 P 、 B帧的包头都有一个 PTS 和 DTS ，但 PTS 与 DTS 对 B 帧都是一样的，无须标出 B 帧的 DTS 。对 I 帧和 P 帧，显示前一定要存储于视频解码器的重新排序缓存器中，经过延迟（重新排序）后再显示，一定要分别标明 PTS 和 DTS 。例如，解码器输入的图像帧次序为 I1,P4,B2,B3,P7,B5,B6,I10,B8,B9 ，依解码器输出的帧次序，应该 P4 比 B2 、 B3 在先，但显示时 P4 一定要比 B2 、 B3 在后，即 P4 要在提前插入数据流中的时间标志指引下，经过缓存器重新排序，以重建编码前视频帧次序 I1,B2,B3,P4,B5,B6,P7,B8,B9,I10 。显然， PTS/DTS 标志表明对确定事件或确定信息解码的专用时标的存在，依靠专用时标解码器，可知道该确定事件或确定信息开始解码或显示的时刻。例如， PTS/DTS 标志可用于确定编码、多路复用、解码、重建的时间。\\n\\nPCR\\n\\nPCR 是 TS 里面的，即 TS packet 的 header 里面可能会有，他用来指定所期望的该 ts packet 到达 decoder 的时间，他的作用于 SCR 类似。\\n\\nDTS, PTS\\n\\n对于一个 ES 来说，比如视频，他有许多 I,P,B 帧，而 P, B 帧都是以 I ， P 帧作为参考。由于 B 帧是前向后向参考，因此要对 B 帧作 decode 的话，就必须先 decode 该 B 帧后面的 帧（ P, 或者 I 帧），于是， decode 的时间与帧的真正的 present 的时间就不一致了，按照 DTS 一次对各个帧进行 decode ，然后再按照 PTS 对各个帧进行展现。\\n\\n有时候 PES 包头里面也会有 DTS ， PTS ，对于 PTS 来说，他代表了这个 PES 包得 payload 里面的第一个完整地 audio access unit 或者 video access unit 的 PTS 时间（并不是每个 audio/video access unit 都带有 PTS/DTS ，因此，你可以在 PES 里面指定一个，作为开始）。\\n\\nPES 包头的 DTS 也是这个原理，需要注意的是：对于 video 来说他的 DTS 和 PTS 是可以不一样的，因为 B 帧的存在使其顺序可以倒置。而对于 audio 来说， audio 没有双向的预测，他的 DTS 和 PTS 可以看成是一个顺序的，因此可一直采用一个，即只用 PTS。"}'));jctx.push(JSON.parse('{"id": "181101", "tag": "web", "text": "# Web单页和跳转\\n\\n思考开放平台的网页呈现方式，基于已经有若干md文件，怎么去呈现。基本的想法是目录中放html文件，以静态方式来获取，完全不需要一行代码，但是开发似乎已经不知道还有上古技术了。单页配合后台按路径读数据也足够简单，定下大致思路。期间想到文档间需要跳转，如果按md内相对路径的写法，编译成chm没有任何障碍，但到了单页应用就会面临被跳转到其它页面的问题。\\n\\n经前端开发提醒，href除了绝对路径和相对路径外，还支持哈希方式，就是以#为记号的页面内跳转。简单测了下，规则大致是这样\\n\\n1. 如果发现是`scheme://`开头，且scheme可以识别，就直接向外发起链接，页面也转移走了。\\n2. 如果首字母是`#`，进行页面内定位，仍留在当前页。\\n3. 除以上情况外，就以这个页面为根，在服务器的目录进行间接寻址。比如当前页面请求的路径是`/www`，如果name是ha，就向/www/ha发请求同时页面会跳转。\\n\\n可以看出，只有#路径的点击可以驻留，可以说是SPA的最佳搭档，同时会回调onhashchange函数，只要能进入JS，拿到#后面的数据，重新请求数据就是自然而然的事情，接下来就是编码的工作了。\\n\\n再看图片。如果用img标签，src是不会触发JS的(可以跨域的属性，当然不能随便加载JS)。这就要求必须能定位到这个SPA页面的根地址，再以跟地址进行相对路径的编写，理论上也是可以找到图片的。还没验证，先记录一下。\\n\\n最坏情况下，还能把图片先base64编码再嵌入页面，像这样`<img src=\\"data:image/png;base64,agEna13==\\">`。"}'));jctx.push(JSON.parse('{"id": "181110", "tag": "web", "text": "# 论为什么CSS难学\\n\\n很多人以为CSS是给DOM元素设置属性（attribute），其实CSS规定的并不是属性，而是行为（behavior），DOM里的每个元素都可以看成是一个独立的物体，按照CSS规定的方式运动，最后稳定下来的结果就是最终布局的结果。所以有人说CSS不正交，它当然不是正交的，因为它的设计就是要求协变，要求在其他元素做出调整的时候，即便本元素的样式没有发生任何变化，也可以跟着调整位置和大小，以适应新的内容，维持设计风格。\\n\\n为什么CSS要设计成基于选择器和多种各异的behavior，而不像其他框架那样直接将显示样式绑定到每个元素呢？恰恰是因为正交性，因为CSS和DOM是正交的，这样DOM内容变化时，CSS可以规定一组不变的特性，从而以灵活的方式适应内容的改变。传统的GUI通常每个元素都有固定的位置和大小，要实现根据内容动态调整，就必须针对各种情况（如视口大小改变，内容改变）专门编写代码；WPF则有网格、流式、绝对三种不同的定位方式，与CSS有不少共同点，但是自适应的功能少了不少，也没有选择器的功能，这样动态生成的内容就需要更多的代码来调整。而CSS只要将DOM组织成特定的格式，就会自动启用相应的样式。WPF制作的界面毕竟变化比较少，大部分元素仍然是固定的，而网页通常要求更高的灵活性。\\n\\n前期准备：首先理解 HTML的一些常用的基本元素和常用样式属性的约束定义\\n\\n基本元素\\ndiv, span, a, p, input, textarea, select, ul, li, h1-h6, hr\\n\\n常用样式\\ndisplay\\nmargin\\npadding\\nborder\\nbackground\\ncolor\\nwidth\\nheight\\nposition\\nfloat\\n\\n基础：把以下几个常用的CSS样式，记熟\\n\\n1. 固定长宽的圆角有边框的头像\\n2. 三角形， span (这个前端面试特别喜欢考\\n3. 横向的导航条，像知乎网页版导航条\\n4. 竖的的菜单栏，比如gitbook章节列表\\n5. 同时纵向和横向都居中对齐（暂时没想到其他的\\n6. 进阶：前端排版布局练习\\n\\nhttps://github.com/dodoru/40LayoutExercise\\n专门做的40个排版练习的演练，前端排版布局都还挺轻松。主要训练，float display position"}'));jctx.push(JSON.parse('{"id": "181111", "tag": "tool", "text": "# 字体名\\n\\nAdobe 有一份文档就是专门讲这个的: 5149.OTFname_Tutorial.pdf\\n\\n字库中有关于字体信息的数据都储存在 name table 中, 每条数据有 4 个标识符:\\nnameID,platformID,platEncID,langID - 名称,平台,编码,语言\\n(其中 platformID 将会影响后两项的取值).\\n\\n其中, 与字库名称有关的 nameID 如下, 以 Adobe 黑体中的对应名称作为参照:\\n```\\n1. Family - Adobe Heiti Std R\\n2. Style - Regular\\n4. Full - Adobe Heiti Std R\\n6. PostScript - AdobeHeitiStd-Regular\\n16. Preferred Family - Adobe Heiti Std\\n17. Preferred Subfamily - R\\n18. Mac Compatible Full - (无)\\n20. (未命名) - AdobeHeitiStd-Regular-GBpc-EUC-H\\n```\\n\\n通过 4 个标识符, 可以组合出不同平台不同语言下的不同名称, 如:\\n1,1,0,0 - Family,Macintosh,Roman,English\\n(如果不特意指定除 nameID 外的其它 3 个标识符, 将默认为 \\"1,0,0\\", 即西文字体大都如此).\\n1,1,2,19 - Family,Macintosh,Big5,繁体中文\\n1,3,1,2052 - Family,Microsoft,Unicode,简体中文\\n\\n现在常用的 Opentype 字体的命名是通过里面的 name 表组成。name 表项由语言、名称类型以及名称值组成。在名称类型里有 Family、Style 和 Preferred Family、Preferred Style 两组。因为历史原因，Family+Style 不能支持超过四个 Style（而很多字体，比如 Adobe 的那些经常 6 个宽度），Preferred Family+Preferred Style 则可以支持很多的小 style 甚至是非标准的 Style（比如 Hiranigo 里面就用 W3、W6），而这就产生了问题。\\n\\nWindows 的字体预览会采用你目前的系统语言对应的 Preferred Family 作为命名，如果此项缺失则会用系统语言 Family、英语 Preferred Family、英语 Family。\\n\\n对浏览器来说不同浏览器的处理策略是不一样的，比如 IE9 和 FF4 支持按照 Preferred Family 选字而 Chrome 只按照 Family（Opentype 规范里的 [name] 表项目）搜索。\\n\\n下面是「Adobe 黑体」的名称表：\\n\\n[name] 表：\\n2052（中文）Fullname：Adobe 黑体 Std R\\n2052 Preferred Family：Adobe 黑体 Std\\n2052 Preferred Style：R\\n1033（英语）Family：Adobe Heiti Std\\n1033 Subfamily(style)：Regular\\n1033 Fullname：AdobeHeitiStd-Regular\\n1033 Preferred Family：Adobe Heiti Std\\n1033 Preferred Style：R\\n65536 CID findfont Name：AdobeHeitiStd-Regular-GBpc-EUC-H\\n\\nPostscript 特有名称（仅限 CFF OTF）：\\nPostscript Name：AdobeHeitiStd-Regular\\nPostscript Family：Adobe Heiti Standard Opentype\\nPostscript Name For Humans：Adobe Heiti Standard Opentype Regular\\n"}'));jctx.push(JSON.parse('{"id": "181116", "tag": "net", "text": "# C语言的HTTP请求\\n\\n在windows上写HTTP请求，遇到问题很多。\\n\\n头文件要用winsock2.h，且必须调用WSAStartup，另外还要链接`ws2_32`库。\\n\\nPHP Server会分两次发送头和payload。\\n\\n收到的数据，win7似乎是1013，大于这个数量，puts或printf的输入就会被截断。但win10至少在2200左右无问题。更大未知。\\n\\n发送的接口要把数据拆成3块，否则很难灵活组合。\\n\\n遇到过对端不断连接，导致流程下不去，变通办法是对recv加超时参数。奇怪的是用`SO_RCVTIMEO`在某些情况下导致程序异常中止，命令行无法打印，GUI直接崩溃。\\n\\n换用select，返回有3种情况，>0表示事件发生，0表示超时，<0是select函数本身有问题。这3种状态即使在跨平台上也依然适用。\\n\\n读写集`fd_set`在win10配64位gcc的大小是520字节。第一个字节，所有的手册都说是最大的fd+1，看到一种说法是OS要给监听fd分配连续的内存，最小的fd是0，为了容纳从0到最大fd的范围，因此填值是fd+1。而windows上这个参数是无意义的，因为windows的fd并不是从3开始，而且连续两个fd的差也不是1，所以最大值+1规则不适用。当fd数量过多，超过`FD_SETSIZE`，其实就是超过`fd_set`容纳的范围时，就不能再用select。换句话说select不能应对海量连接。\\n\\nreadset表示可读，或者说read操作不会堵塞，这时进行recv一定有数据或者EOF，对于socekt就是连接被断开。\\n\\n超时虽然有秒和微秒两个值，但实测windows下必须在秒以上，少于1秒的值会破坏堆栈导致崩溃。\\n\\n使用HTTP/1.0短连接，关闭联接时又遇到语义不一致的坑，由于是服务端主动断开，主动断开方会变成`TIME_WAIT`。这个socket在windows客户端用close会被置成`CLOSE_WAIT`状态。说明windows的close函数只是释放句柄，不处理TCP协议，必须先调用shutdown或换成closesocket(对TCP/UDP都适用)才行。除非要半关闭，通常用closesocket就行。\\n\\n语义不一致的原因，猜测大概是由于，fd的维护和socket状态是分开的，windows没有把这二者绑定。\\n\\nTCP状态机有5个标识过渡到CLOSED的中间状态，超过所有状况的一半。要仔细理解。\\n\\nhttp库和国标网关调试时，会遇上登陆流程卡住不往下走的问题，才分析出原因。\\n\\n代码中用recv收数据，之前遇到过和某些服务器请求，对端会在1分钟后才关连接，所以recv就会阻塞1分钟，所以把请求改为HTTP/1.0且显式声明是close，期待对端来关闭连接。但是国标网关的程序并不理会close指示，不会断开连接，所以就一直停在recv不往下走。查询手册知道用setsockopt设置fd的超时时间，recv就不会永远等待，先这样规避该问题。\\n\\nuv的多线程。只提供了4个线程接口，没有cancel这种语义复杂的接口，对我来说够用。多线程同时从tty读入，是否会抢占？从实验来看，两个线程如果都调用scanf，先被触发的会锁住tty，直到输入完成才会放开tty，让另一个线程去读，因此是安全的。但是在读的过程中，似乎可以输出。"}'));jctx.push(JSON.parse('{"id": "181117", "tag": "tool", "text": "# FLTK编译历程\\n\\n为了跨平台，Windows用了GDI，Mac用Quartz，Unix用X11。Fl::scheme可以简单地设置风格，效果一般。\\n\\n要想编译后的程序没有背景的cmd窗口，编译选项要增加`-Wl,--subsystem,windows -mwindows`。\\n\\n> the effect of -mwindows is to\\nadd -lgdi32 and -lcomdlg32 to the list of default libraries (the uwin\\ntarget also adds -luser32), and to pass --subsystem windows to the linker.\\n\\n说明subsystem是无用的，以防万一记录在此。按带cmd方式编译出来的程序，不论是从命令行启动还是界面点击，都会有IO输出。而按windows编译，即使从命令行启动，也不会有输出。\\n\\n链接时，除了fltk和mwindows附带的两个库，还要额外的库`-lole32 -lcomctl32 -luuid`，所以一共是5个windows库。第一个对应dnd，第二个对应TrackMouseMove，网上很多人说user32，可惜是错的，uuid是IUnknown需要的库。\\n\\n窗口函数的运行一定基于事件，风格就是main函数的最后return Fl::run();锁住。实现很简单，判断如果有窗口widget，就开启无尽wait，否则直接结束。windows版实现wait时，会从`ws2_32`库找select函数并等待，具体时间还没看懂，似乎是0.5秒？一旦被唤醒，执行PeekMessageW寻找是否有窗口事件或超时发生。\\n\\n如果要搭配libuv，可以再启动一个线程比如叫`run_layout`，在layout线程中画出布局并Fl::run，layout线程会一直阻塞。主线程join这个layout线线程，就能结合了。\\n\\nGUI必然依赖回调，为避免代码太长显得混乱，套路化的做法是将布局函数layout放在main文件，结构体放在cbfunc.h，回调定义放在cbfunc.cpp。\\n\\n```\\ncbfunc.h\\nstruct stXXX {\\n};\\n\\ncbfunc.cpp\\nstatic void gf_cbdosth(Fl_Widget* fw, void* w){}\\n\\nmain.cpp\\nstatic stXXX sv_xxx;\\n在layout()中对sv_xxx赋值并作为参入传给gf_cbdosth\\n```\\n\\n在布局创建控件后，`widget->callback(sf_dosth, &sv_xxx);`\\n\\n既然是图形程序，配上图标会好看得多，图标等资源的源文件后缀是rc，猜测是resource compile，再用`windres -i xx.rc -o xx.res -O coff`编译成res后缀文件，不指定COFF格式的话无法链接。最后用gcc把res和o文件一起链接成可执行程序。rc是文本文件，格式如下，因为只有一个图标，nameID这栏随便指定没关系。还可以通过rc加上版本号和其它附加信息。\\n\\n```\\nnameID BITMAP filename\\n2  ICON  xx.ico\\n1  VERSIONINFO\\n\\tFILEVERSION     2,3,3,3\\n\\tPRODUCTVERSION  2,3,3,3\\n\\tFILEOS 0x4L\\n\\tBEGIN\\n\\tBLOCK \\"StringFileInfo\\"\\n\\tBEGIN\\n\\t\\tBLOCK \\"080404E4\\"\\n\\t\\tBEGIN\\n\\t\\tVALUE \\"CompanyName\\", \\"NKUCodingCat Co.Ltd\\"\\n\\t\\tVALUE \\"FileDescription\\", \\"NKU-SSS-in-One Project General Launcher\\"\\n\\t\\tVALUE \\"FileVersion\\", \\"1.0\\"\\n\\t\\tVALUE \\"InternalName\\", \\"Launcher on Windows\\"\\n\\t\\tVALUE \\"LegalCopyright\\", \\"GPLv2\\"\\n\\t\\tVALUE \\"OriginalFilename\\", \\"小心使用，谨防水表\\"\\n\\t\\tVALUE \\"ProductName\\", \\"NKU-SSS-in-One\\"\\n\\t\\tVALUE \\"ProductVersion\\", \\"2.3.3 build 42\\"\\n\\t\\tVALUE \\"Comments\\", \\"一群渣渣\\"\\n\\t\\tEND\\n\\tEND\\n\\n\\tBLOCK \\"VarFileInfo\\"\\n\\tBEGIN\\n\\t\\tVALUE \\"Translation\\", 0x0804, 1252\\n\\tEND\\n\\tEND\\n```\\n\\n整体布局会用到Double Window这个类，是Window类的子类，有onscreen和offscreen两个buffer，flush的时候把offscreen copy出来。\\n\\n如果想更灵活地回调，就要继承widget并覆写handle方法"}'));jctx.push(JSON.parse('{"id": "181120", "tag": "tool", "text": "# 音视频解码器的特性\\n\\n音频解码有指标\\n\\n* 比特率范围\\n* 输入通道\\n\\n比特率范围，典型如MP3是8k到320k，FLAC会有1到2^31全覆盖。\\n\\n通道数大抵越低端，用于通信的越少，音乐则多。AMRNB, G711是1个，MP3是2，AAC是6可以5.1声道，Vorbis是8可以7.1声道。FLAC某实现是30(但另一个实现编码只有2通道)。\\n\\n视频解码指标\\n\\n* 帧速率\\n* 比特率范围\\n* 对齐宽高\\n* 支持宽高\\n\\n帧速率大多是1到240全覆盖，也有mpeg4只有12到60。VP8和9是0到960。\\n\\n对齐宽高不论编解绝大多都是2，H263是解4(编码是16)\\n\\n别名3gpp的音频是AMRNB，视频是H263。mp3是mpeg，mpeg4是mp4v-es，aac是mp4a-latm。"}'));jctx.push(JSON.parse('{"id": "190103", "tag": "net", "text": "# 网络层的交换与路由\\n\\n## 网段定义\\n\\n对于私网地址的规范，在RFC 1918 - Address Allocation for Private Internets里有完整的规范定义。其中A类，B类，C类网段各取了一部分：\\n\\n* 10.0.0.0/8 (255.0.0.0)\\n* 172.16.0.0/12 (255.240.0.0)\\n* 192.168.0.0/16 (255.255.0.0)\\n\\n192的私有网段只能放下255^2即6万多台主机，家庭当然够用，但大企业可能就不够。所以大公司内网会用10或172网段。\\n\\n可能最早的路由是用192.168.0.1，从最小的0开始合理，后来随着小区有了网络，为了避免和外级网络冲突，用了192.168.1.1，好比现在的无线网络用192.168.2.1，原理是类似的。\\n\\n最后一位不能用0。原理大概是这样，0和255都是广播地址，**关于0到底是广播还是主机号，此处存疑，但不用肯定没错**。0不能被主机使用，255可以。但如果用255会被用作广播的收端，尽量避免。有些特殊会用254，所以也有路由器用253地址。\\n\\n倒数第二位用0虽然理论上很正确，在早期的路由器中，0段子网在没有子网掩码的情况下会与它的网络号相同而产生路由上的混乱，古老的路由协议RIP在路由时就不考虑子网掩码的问题，所以在cisco的设备上才有 ip subnet-zero这个命令来打开对 0段子网的支持。可能出于规避目的，用192.168.1.1。当然现代的路由器应该不需要考虑这些问题了。\\n\\n## 交换和路由的区别\\n\\n简单的说，同一个网段内叫交换（二层），不同网段之间叫路由（三层）。现实中也有三层交换，属于特例。\\n\\n早于IP网络的电话交换机，可以理解为一层交换。对电话来说独占一条物理电线，不存在IP分包的概念，直接对物理介质做交换控制，所以是一层。\\n\\n路由路径在二层和三层的路径是不同的。二层用ARP协议，从IP反查MAC直接物理层就找过去了。三层就全是IP寻路，通过网关出去，并由网关往后一级的网关传递，最终找到目的地。\\n\\n有两个常被忽略的属性，dev和scope。dev相对于对gateway的一个更小的约束。同样起到约束作用的还有scope。Scope是一个更小程度的约束，指明了该路由在什么场景下才有效。也是用于约束目的地址的。例如不指定网关的二层路由，通常对应的scope类型是scope link。scope link的意义就是说明在同一个二层。这个意义与网关不指定的效果是呼应的。\\n\\n四种scope\\n\\n1. global是在任何的场景下都有效，link是在链路上才有效，这个链路是指同一个端口，也就是说接收和发送都是走的同一个端口的时候，这条路由才会生效（也就是说在同一个二层）。Global则可以转发，例如从一个端口收到的包，可以查询global的路由条目，如果目的地址在另外一个网卡，那么该路由条目可以匹配转发的要求，进行路由转发。\\n2. link的scope路由条目是不会转发任何匹配的数据包到其他的硬件网口的。\\n3. host表示这是一条本地路由，典型的是回环端口，loopback设备使用这种路由条目，该路由条目比link类型的还要严格，约定了都是本机内部的转发，不可能转发到外部。\\n4. site是ipv6专用的路由scope。\\n\\n## route命令\\n\\nWindows和Linux的参数不完全一样，网上找文章时要注意。route命令除了添加了删除，还能屏蔽某种路由路径。route命令除了支持inet协议，还能支持ax25、ipx、netrom等数种二层协议，不过由于/proc/net/下没有对应的文件，所以没有使用。\\n\\n## 路由协议和preference\\n\\n到某主机有多条路可选，会挑选优先级高的。比较方式先匹配掩码长度，再比较管理距离(比如metric)。掩码长的高于掩码短的，所以3种路由顺序如下\\n\\n1. 主机路由，直接指明某台主机，/etc/hosts\\n2. 网络路由，指明某类网络怎么走\\n3. 默认路由，也叫默认网关，一般是目标地址为0.0.0.0的那条\\n\\n路由器往往支持多路由协议，这就有一个多种路由的选择和配合问题。为了解决这个问题，在路由的参数中引入了优先级（preference）的概念。各路由协议一般来说都定一个固定的preference值，preference值越小，协议对应的路由的优先级越高。以下是业务标准的路由协议：\\n\\n* 直接路由  0\\n* OSPF路由  10\\n* IS-IS的level 1的路由  15\\n* IS-IS的level 2的路由  18\\n* RIP路由（Berkeley）  100\\n* BGP路由 170\\n* EGP路由（已被BGP淘汰） 200\\n\\nRIP是最简单的协议，只告诉近邻，距离目标有几跳，且当目标之间距离变长后，并不会更新，因此网络收敛非常慢。RIP协议规定跳数上限是16，因此17可以认为是目标不可达。\\n\\nOSPF/ISIS比RIP高明的地方，RIP只知道邻居选择告诉自己的消息。OSPF/ISIS邻居不会隐瞒任何消息，会毫不保留地将消息传递给整个参与OSPF/ISIS网络里的任何一台路由器。因为信息同步是OSPF/ISIS能够正常工作的前提。如果不同步，OSPF/ISIS有网络环路的可能。OSPF内划分一个或多个Area，规模小的话只要一个Area0就行。由于OSPF/ISIS分享的信息过多，只适合运行在一个AS（Autonomous system 自治系统）内部，自治系统可以是一个公司，或一个校园网，也可以是一家运营商。每个AS会有个独立编号，公安网内部号段6xxxx和7xxxx。\\n\\nRIP、OSFP都属于内网路由，但规模不能太大，如果是非常大的AS，或者AS之间，就要引入BGP协议。\\n\\nBGP路由最复杂，主要用作不同AS间的边界网关，也是互联网惟一的协议。可以配置路由的颗粒度。颗粒度是由路由前缀的长短决定的，比如17.0.0.0/8的颗粒度很粗，17.1.0.0/16就会稍细，当然17.1.1.0/24颗粒度会更细。但是颗粒度太细，又会造成路由表的臃肿不堪。当前对颗粒度的要求是，路由前缀的长度，要≤21。\\n\\nBGP是唯一使用TCP作为传输层的路由协议（端口179），其他的路由协议可能都还到不了传输层。TCP连接的窗口是65K字节，也就是说TCP连接允许在没有确认包的情况下，连续发送65K的数据。而其他的路由协议，例如EIGRP和OSPF的窗口只有一个数据包，也就是说前一个数据包收到确认包之后，才会发送下一个数据包。当网络规模巨大时，需要传输的数据也相应变大，这样效率是非常低的。这也是它们不适合大规模网络的原因。而正是由于TCP可以可靠的传输大量数据，使得BGP适合大规模网络环境。\\n\\nBGP不同算法对收敛速度影响不同，比较快的有BFD，FRR算法。\\n\\n## 路由metric的含义\\n\\n需要区别的是路由开销（metric）和路由优先级（preference）这两个概念。metric是针对同一种路由协议而言，对不同的协议，由于代表的含义不同，比较不同协议的metric是无意义的，所以要在两条不同协议的同信宿路由中作出选择，只能比较路由的优先级。相反，preference是针对不同协议而言，同协议的路由的优先级是一般情况下一样的，metric这时是在两条同信宿路由中作出选择的标准。"}'));jctx.push(JSON.parse('{"id": "190108", "tag": "os", "text": "# 环境变量的继承\\n\\n操作系统有一片空间保存环境变量，我猜测这只是一片只读空间，每次用户登陆会创建一个会话，这个会话首先继承了全局的全局变量，如果脚本中export了某些环境变量，会作用到这个环境，但是其它用户登陆后，完全不受影响。\\n\\n典型的同一个账号，先export A=123，另一个会话也指定export A=456，不会影响前一个会话，这是两个完全隔离的会话。export的效力仅及于该此登陆操作。\\n\\n再看看同一个会话中启动一个shell进程会如何。每个shell创建的进程，除了argc, argv 就是env了，父子间的env到底能不能打通呢？事实表示，父改了，子会受影响；但子改了，父是感知不到的。\\n\\n如果不考虑fork子进程，仅仅当前环境使用的话，不需要export，仅使用 A=123 就会在当前环境创建变量，只是子进程无法看到这个变量罢了。\\n\\n综上export不是定义环境变量必须的语法，只是为了让子shell能感知到，将环境变量**提升**到可被子shell感知到的区域。\\n\\n说了shell顺便说说tty和terminal这两个概念。远古时代的计算机需要穿孔打印机和纸带进行操作，自从有了电传打字机，打字机输入，输出会打到纸上，虽然有些费纸，但已经比纸带有了巨大的进步。大型机体积巨大，但多人需要使用，所以每个人看到的就是terminal，tty算是最原始的终端形态。\\n\\n打印到纸上也勉强能算，毕竟不方便，随着70年代末出现的CRT显示器，terminal更多地被用于video terminal的简写。至于现在的软tty，包括各种stdin, stdout只是保留这个概念，形式上已经差别很大了。"}'));jctx.push(JSON.parse('{"id": "190110", "tag": "protocol", "text": "# 视频取流协议\\n\\n## RTSP\\n\\nRTSP支持RTP/AVP, RTP/AVP/TCP两种传输模式的，前者也可以写作RTP/AVP/UDP，这种模式因为是UDP传输，客户端会携带自己的端口，通常是两个，音频和视频。而TCP是RTP over RTSP over TCP方式，复用连接并不需要传递端口。\\n\\nVLC向StreamApp请求，发送SETUP时指定RTP/AVP。由于库本身的问题，只能支持TCP，回复455表示不支持，于是VLC发起OPTION尝试，但响应中又携带了SETUP，于是VLC就不知道该如何执行下去。\\n\\n看起来似乎RTSP缺少一种更灵活的协商机制，但是考虑到TCP和UPD特性对视频的影响，如果协商变成由服务端来决定，显然并不符合客户的本意，这个SSL的协商在业务领域是不同的。虽说也可以做成SETUP时交换能力，在PLAY时指定方式，似乎和SDP的阶段又有冲突，也许是它的不足吧。\\n\\n## 浏览器无插件视频播放\\n\\n看了IPC的浏览器播放，速度很快体验很好，抓包看实现，网络协议用 RTSP over WebSocket，用HTTP的upgrade部分切换，要注意的是必须先F12打开开发工具，再进入视频页面，这样才能在Network页签看到网络数据。\\n\\n可以看H265视频，组合了多种技术\\n\\n首先解码部分单独跑在worker里，音频和视频各一个，解码部分用了FFMpeg，这块估计是用了WebAssembly实现的，但不能实证。既然播放H265那就肯定不是用video标签，用的是canvas呈现，将视频解码并转成图片画上去的。虽然能播放H265，但是码流太高还是非常卡，实测在3M码流时已经掉帧严重，几秒后自动切入辅码流模式。\\n\\n## HLS\\n\\nHLS是HTTP Streaming传输视频的一种，由Apple提出，另外3GPP，微软和Adobe也有类似的技术，由于iPhone太强势，使得HLS几乎无人不知。\\n\\nURL对应的索引文件，就是M3U8，8代表UTF8。格式像这样\\n\\n```\\n#EXTM3U\\n#EXT-X-VERSION:3\\n#EXT-X-ALLOW-CACHE:YES\\n#EXT-X-MEDIA-SEQUENCE:0\\n#EXT-X-TARGETDURATION:1\\n#EXTINF:0.998, no desc\\nhttp://media.com/seg1.ts\\n#EXT-X-ENDLIST\\n```\\n\\nhtml5的video标签本来只支持3种封装格式，mp4/ogg/webm，这几种格式似乎都偏向点播。而Apple在safari的实现中额外支持了ts，为什么要用 TS 而不是 MP4，这是因为两个 TS 片段可以无缝拼接，播放器能连续播放，而 MP4 文件由于编码方式的原因，两段 MP4 不能无缝拼接，播放器连续播放两个 MP4 文件会出现破音和画面间断，影响用户体验。这就是Living的意思。最简单的方式是video.src"}'));jctx.push(JSON.parse('{"id": "190111", "tag": "lang", "text": "# Lisp与静态类型\\n\\n别的不说罢，你跟我说 Common Lisp 的类型系统是宏？没有融入语言核心？SBCL 等实现的 static type declaration 不需要编译器层面的支持？可去您的罢。SBCL 这种还不够静态？没办法 OOP 这玩意总归得用些动态类型特性，那我们限制在一个比较小的语言标准， barak/stalin 能通过分析整个程序推导静态类型直接免除运行时的动态分发，用的就是标准的 R4RS，不需要任何额外的类型声明。\\n\\n啥，要的是那种 type as specification 的类型系统，那种 tc 过后就 strip 掉的东西不用 preprocessing 实现还能用啥？\\n\\n啥，要 Lisp semantic 的支持，讲道理本质上是 untyped lambda/predict logic 的玩意要怎么加。\\n\\n用 ADT 有啥问题么，搞得和 Lisp 就不是 ADT 了一样\\n\\n```\\ndata Lisp = Symbol String\\n          | Nil\\n          | Cons Lisp Lisp\\n\\nexample :: Lisp\\nexample = (Cons (Symbol \\"defun\\")\\n           (Cons (Symbol \\"id\\")\\n            (Cons (Cons (Symbol \\"x\\") Nil)\\n              (Cons (Symbol \\"x\\") Nil))))\\n```\\n\\n还 list 换 lazy stream，lazy stream 本质上就是个给定上一个输出给出下一个输出的函数，有啥花头的，CLtL2 Appendix A 就有 Series 了，Appendix B 就是 Generator 了。\\n\\nReferences\\n\\nCLtL2 by Guy Steele 顺便一说，81-86讨论语言方向，86到94年才最终定稿。\\n\\nInterpreting Lisp by Gary Knott\\n\\n这里应该有一本用 ML/Haskell 写 Lisp 解释器的书，然而我忘了具体哪本了\\n\\nProgramming Languages and Lambda Calculi by Matthias Felleisen & Matthew Flatt\\n"}'));jctx.push(JSON.parse('{"id": "190121", "tag": "data", "text": "# SQLite分析\\n\\nSQLite指针是个很大的结构，包含vfs和Db结构。允许attach特性，可以同时有多个数据库，因此DB成员是数组，每个DB的最关键结构是BTree，最终读写OS上的磁盘页。\\n\\n使用Btree是针对磁盘的惯用法，m阶B树表示每个节点最多有m个出度，又叫分叉。因为m很大所以深度就浅了，相当于用内存多查几次换磁盘IO。B树另一个特点是至少有m/2个出度，原因同样是保持树尽可能浅，让树每一级承载的信息多一些。不取更高是考虑到有插入，太满的话旋转次数过多，因此要折衷。作者曾试图换成LSM Tree开发v4版，但最终停掉这个计划，大概是因为LSM太占内存，而在小型化场景一方面没有这么多内存，另外保障数据尽可能快地写入磁盘也是很重要的，结合来看B-Tree仍是最好的选择。\\n\\n管理每个存储数据的是pager，每个节点称为page，page大小一致，新数据库可设置，一旦持久化就不能改变。一定是2的幂，界于512到65536之间（在17和18字节表示，1表示65536）。\\n\\n第一页比较特殊，前100字节格式包含Magic Number，页大小，版本等。创建一个只有表定义，但没有数据的库，占2K，共2页，第一页是`sqlite_master`。\\n\\n表用B+树，数据只存在叶子上。索引用B树，所有页都有数据。展开一下，如果数据用B树保存，在条件检索时，结果数据会分布在不同层级，这就导致很多的磁盘随机访问，对机械硬盘非常不友好，SSD稍好，但仍然是连续访问优于随机访问。因此最终选择了B+树。页内最小单元是cell，每页头部是指针，尾部是内容，中间全为0，添加数据直接用中间区域，速度很快。\\n\\n## 扩展机制\\n\\nSQLite的基本单元是table及配套的view和index，如果要扩展功能就要使用virtual table机制，常见的有Full Text Search，Json和CSV等。virtual table只是概念，要实现需要module，看`sqlite3_create_module_v2`函数实现。通过`sqlite3_compileoption_get`函数可以看到使用版本中被编译了的模块。\\n\\n要关注的类型就int64,double,text,blob这4种，还有个null类型，但是以前看过一本书强烈地批判了SQL规范中纳入null这种不严谨类型的坏处，所以我想还是尽量少用为妙。\\n\\nSQLite最晚在3.15版引入了json扩展函数，但至少3.6版是没有的，也许SQLite的演化就是加入这种新功能吧。不过虽然代码有，默认是不编译的，需要定义宏才能把这些特性编译进来。创建一张表的时候，可以在最后用\\n`primary key(a_key, b_key)`这种方式指定两列为联合主键。\\n\\n如果就用gcc sqlite.c编译，通过`sqlite3_compileoption_get`只能看到3个选项：\\nCOMPILER、SYSTEM_MALLOC和THREADSAFE=1。其它高级特性都需要定制宏打开。\\n看的方法很简单，打开SQLite输入`select sqlite_compileoption_get(n)`就能看到。\\n\\n### 全文检索机制\\n\\n`CREATE VIRTUAL TABLE memo USING fts5(col1, col2, tokenize = \'porter ascii\');`fts5是module名，被创建的虚表用USING来继承一个已经实现的module，\\n这个virtual table就有了fts5这个module的全文检索能力，使用MATCH关键词的匹配速度快很多。\\n\\n全文检索最核心的要素是分词器，即tokenize指定的值，不指定则默认simple，不过至少要用icu才能处理中文。这种方式创建出的表，如果用.schema去看，会对应另外3到5张普通的table，3张是fts3和fts4共有，加了content、segdir、segments后缀的表。fts4则多两张start和docsize表，称之为Shadow Table。可惜中文分词必须引入ICU，这个库在windows并不具备，不实用。\\n\\n全文检索表除了用like，更多的是match，由于是全文检索，所以match前面通常是表名，不用列名。支持几种语法，但必须记得开头。fts5用倒排索引构建`full-text index`，支持prefix match，所以只能后面跟`*`，不能用在前面。\\n\\n1. match \'abc*\' 搜索abc开头的分词，但不能搜索12abcd(因为不是独立的词)\\n2. match \'ab* + cd*\' 搜索ab开头后面跟cd开头的词\\n3. neargroup: match NEAR(ab cd) 注意NEAR必须大写，ab和cd顺序随意，只要中间间隔词数量少于默认10，如果想更长，match \'NEAR(\\"a b\\", 20)\'\\n4. 支持 AND OR NOT，用\\"a b\\"指定a和b严格排序\\n\\n全文检索使用前缀索引，所以不能用`*a`语法。\\n\\n## lua与sqlite整合\\n\\n依赖userdata，因此一定配合newmetatable函数，元表关联ud实现在lua中无缝使用的体验。引申一句，通过newmetatable创建的表内部仍是通过newtable创建，只是这个表一定有名字，且名字会被保存在表的`__name`字段。另外元表也会记录在C的`LUA_REGISTRYINDEX`大表中。\\n\\n动态库入口创建4个元表，分别是对db的操作，对prepare产生的vm的操作，对context的操作，以及backup操作(需要两个db实例)。然后用`register_lib`创建动态库，这个库除了查版本外，就是创建db。\\n\\n## 不同语言的封装比较\\n\\npy和lua在执行DML操作时，py默认不会提交，需要手动执行commit，可以在connect时加上`isolation_level=None`。而lua的封装只有自动commit一种模式。大概是py要考虑多种DB的兼容性吧。\\n\\n## 测试数据\\n\\n* 5万条: 查整数的耗时只有5毫秒左右，定长31字符串的LIKE查询在15毫秒上下。\\n* 10万条: 查整数不超过15毫秒，字符串LIKE查询30毫秒。\\n* 30万条: 查整数不过30毫秒，字符串LIKE查询80毫秒。\\n* 150万条: 查整数140毫秒，字符串540毫秒。一旦开启索引，查整数5毫秒。\\n\\n索引占空间的大小取决于类型，150万条100M左右的库，整数索引增加16%，字符串索引增加95%（由于数据主体是字符串，可以认为翻倍）。\\n\\n即使做了字符串索引，似乎效果也不好，完全匹配的速度并没有提升，一旦用LIKE的后置%，速度降低到1/10。如果前后都有%，**索引完全不起作用**，耗时变为2.5倍。\\n\\n字符串建索引，对第一次不生效，但似乎会对结果做缓存，第一次查字符串，会耗时300毫秒，同样条件再查询不再耗时。作为对比，不开索引的库，始终耗时200毫秒。\\n\\n无索引查字符串，第1条0毫秒，中间第75万100毫秒，最后的150万200毫秒，非常严格地符合线性关系（要加limit 1，否则会全遍历耗时是一样的）。"}'));jctx.push(JSON.parse('{"id": "190209", "tag": "tool", "text": "# vim的概念和配置\\n\\n## 编译遇到的问题\\n\\n在cent6上遇到Python无法编译出动态库，只有.a库，这时编译vim的选项 ./configure --with-features=huge  --enable-python3interp=yes --enable-luainterp --enable-multibyte --enable-sniff --enable-fontset\\n\\n如果能编译出Python的so库，可以--enable-python3interp=dynamic，这种情况下vim的版本会显示python3/dyn，vim也会去找so库，对提高加载速度有一定帮助。虽然编译出来，但运行中还是报错undefine symbol `PyByteArray_Type`，网上找到解决方法export LDFLAGS=\\"-rdynamic\\"方式解决的。\\n\\n## 模式\\n\\nvim最大的特色就是模式，也是和emacs比较时不能直接对比的地方。基础模式有7种，只不过像Select/Ex模式很少会用，最常用的有normal、insert、command。插入模式没什么特别，normal模式堪称移动的最佳实践，而command模式（或者说ex模式）则是真正进阶vim高手的必经之路，一切高级的批量处理，或是函数与脚本都是这个模式的扩展，至于快捷键，只不过是把ex模式的动作做了映射。在配置键绑定或命令时，要区分不同的模式。部分模式还有子模式，insert模式有Ctrl-X的自动补全子模式。\\n\\nnormal模式下有一种特殊的operator，包括原生的cdy和自定义命令，后面必须跟motion（更高级的叫法是文本对象，同样可以定制），使我们可以对文本进行任意操作。\\n\\nvim启动会依赖$VIM、$VIMRUNTIME、$HOME变量，其中$VIMRUNTIME默认是$VIM/vim{version}，而$VIM在unix是share/目录，在windows则是安装vim的目录。然后按某个顺序从这些变量指定的目录寻找.vimrc，这个文件可以不直接写内容，而是加载.vimrc.before和.vimrc.bundles脚本将不同用途脚本归类。\\n\\n## 目录作用\\n\\nVIM的行为，受配置参数的调整。或者统称为plugin(Vim script file)。整个plugin体系的入口，就是.vimrc相当于C语言的main函数，或者脚本的主文件，.vim目录下的各个子目录，可以认为在一定条件下，通过require方式导入的。遇到比较多的目录有\\n\\n* plugin 相当于全局的加载，只要有文件就会加载\\n* ftplugin 和文件类型相关的加载方式，需要filetype命令来打开\\n* syntax 和语法相关的加载，需要syntax命令来打开\\n* indent 缩进相关，也可以放在ftplugin，单独放只是为了更清晰\\n\\n这样看下来，这些目录的分类并不是vim强制要求，更像是社区的一种自发行为。对Vim来说就像个脚本解析器，以.vimrc为入口不断地导入关联的其它脚本，并运行在全局空间或Local Buffer上，进而达到高效编辑的效果。所以要相深入理解就必须明白Vim的脚本语法和内置规则。\\n\\n## 概念和区别\\n\\nVIM的概念很多，要能清楚这些概念的使用场景和区分。\\n\\n值类型的概念\\n\\n* 变量: 有10种类型，用let/unlet定义和删除变量，*弱类型、强作用域、无块作用域*。有多个命名空间控制变量的作用域，通过前缀来区分。比如脚本的静态变量用s:name，VIM自定义的变量用v:name，局部缓冲用b:name，窗口用w:name，全局用g:name，函数参数用a:name引用等等。而函数的变长参数更可以用a:1，a:2的方式表示第一个和第二个参数。如果在函数scope外用l:varible会报错。由于源出ex，和shell类似，变量没有块作用域，意味着在条件判断中创建的变量，出了判断块依赖可以使用。\\n* 选项: 有3种类型，VIM内置的一类特殊内部变量，刚学习的用户从修改选项开始。8.1版本的帮助手册显示有403个选项，不过有些选项如果编译时没有打开开关，是不能访问的，比如编译时用的python是3.6版本，而你电脑上是3.8版，就可以修改pythondll选项来适配。用set修改，用set filetype?/set syntax?查看，set syntax&恢复默认。也能用let &syntax=c方式来修改。\\n\\n动作类型的概念\\n\\n* 函数: 用function定义的一段功能，执行需要用call或eval方式调用，主要是作为插件的组成部分，如果要映射到按键，要用:call <funcname>。\\n* 命令: 用command定义并可以在Ex模式下直接触发，通用是插件开放给用户的接口形式，可以用map映射到按键，最终还是调用函数。\\n\\n其它\\n\\n* 事件: 还不了解\\n* 组: 还不了解\\n\\n如果在终端显示乱码，可以尝试将lang目录改名甚至删除，将只显示英文不会有显示乱码的问题。\\n\\n## 帮助系统\\n\\n有时某个查询的关键字会在多个分类下出现，比如@@既是一种操作，也是一个变量，直接:h @@只会出现操作的含义，这时就要:h variables再从这页单独查找。类似的options和内建函数也是类似做法。\\n\\n## 缓存和窗口\\n\\n两者相近却大不相同，buf是真正具备文字内容的对象，而window只是展示buf的容器。所以两者的属性也不一样，比如localdir是挂在窗口，而非缓存，两者也不绑定，用:ls看到的是缓存列表，其中有隐藏的缓存，需要的时候开个窗口并用b<buf-number>来关联这个缓存；也有些虽然只是一个缓存，却在多个窗口同时打开时。\\n\\n缓存有多种类型，默认是文件，不保存甚至不能正常退出，很多时候我们打开一个临时缓存只是作为展示，所以需要设置属性成nofile，除此之外还有很多别的有趣的类型。\\n\\n窗口同样有多种类型，不同类型的窗口可以同时存在，不同类型窗口在打开新内容时，会替换成新的buf。\\n\\n* 常规编辑窗口\\n* 帮助窗口 :h命令显示内容的窗口\\n* quickfix窗口 :copen打开的用于显示错误的窗口"}'));jctx.push(JSON.parse('{"id": "190215", "tag": "os", "text": "# Android安装Linux环境\\n\\n15年时试用过kbox，毕竟是个半成品，到2019年2月，安卓跑终端已经很成熟了。和Linux比，安卓的模拟环境是单用户且用户名已预置，在4.2以前，用户名就是个序号，4.2之后扩充形成类似`u0_a99`的命名方式，但本质还是单用户，且没有密码。home目录下不会再有子目录，自然不能创建新用户。\\n\\n已经root可以用linux deploy。这个软件会在/dev/block/loop0（或loop1）块设备上创建rootfs，并安装完整操作系统，因此，从体验上最接近完整系统。\\n\\n没有root的机器，根据安卓不同版本，选择不同的软件。\\n\\n* 安卓5.0及以上，用Termux或UbuntuForAndroid\\n* 安卓4.4及以下，用GNURoot\\n\\n## Termux\\n\\n由于文件系统无法遵循FHS规范，加上依赖的C库是bionic，所以不能直接拿其它发行版的二进制程序来用，需要单独编译。除了基础的库依赖/system/lib/下的libc.so、libm.so、libdl.so之外，其它动态库都在Termux的lib目录内，因此也可以说不是个自完备的系统。相比bionic的libc.so，glibc则命名为lib-2.32.so，再用libc.so.6软链接过去。\\n\\n包管理器是dpkg和apt，又用shell封装了简单的pkg前端。初始化安装后有大约65个包，ca-certificates包只有一个文件，记录了可信任的CA，提供者是curl的作者，可见CA的基础性。在一次升级过程中遇到依赖的libandroid-support无法升级，甚至用`-o APT::Force-LoopBreak=yes install libxxx` 命令还导致所有程序全部被清空的惨剧。据说是用了改版的apt，使升级策略变成了滚动升级。重装之后提示仓库版本和本地不同，我选择D看差异却导致再也无法继续，只能再次重装时只敢选N(保留我的配置)，折腾3次才重新装上。\\n\\n如果更换源，要先执行`apt-get update`更新缓存才能执行进一步操作。\\n\\n默认bash，用chsh可以换sh，原理是把默认shell写入$HOME/.termux/shell。login不能作为默认shell。bash有700多K，而dash仅130K。bash提供了很多交互上方便的特性，典型的像通过改变PS1变量更换提示符，还有个内建钩子函数`command_not_found_handle`，当执行一个不存在的命令，会用一个外部程序给出更好的提示，比如用pkg安装某个对应包。\\n\\n用atilo可以安装完整的linux，原理是先启动基于proot打了patch后的termux-chroot构造假的root环境，从lxc-images下载基础镜像，再以proot方式启动。包括取消LD\\\\_PRELOAD环境变量，用`env -i`加载空的环境，设置PROOT_NO_SECCOMP=1关闭可信计算。同时也说明这类镜像只依赖内核的syscall，辅以合适的根目录，就能运行。\\n\\n在termux上编译软件要注意，因为默认的/usr/local路径不可用，必须用 ./configure --prefix=$PREFIX/stow/xx-1.0 方式显示指定安装路径。安装后，进入stow目录，执行stow xx-1.0就能用了，执行stow -D xx-1.0则删除该软件。\\n\\n## UbuntuForAndroid\\n\\n自带ssh，装上就能用。源比debian要少太多，先安装software-properties-common再用add-apt-repository ppa:添加相应的源才能安装。在换国内源时遇到若干问题\\n\\n1. 先确保安装了*ca-certificates*\\n2. 网上换源的文章都只适用于x86系，如果是arm的话，要把url的ubuntu换成ubuntu-ports\\n3. apt-get update会提示签名不通过，改成`deb [trusted=yes] http:...`。注意如果没有装第1步提到的包，即使加了trusted也没用\\n\\n## GNURoot Gentoo\\n\\n可以安装debian jessie，理论上可以换源逐步升级到最新版本。不过在5.0不让装。\\n\\n又试了Gentoo，依然遇到sshd问题。首先是没有公私钥对，用`ssh-keygen -t rsa -f ssh_host_rsa_key`生成，还是会断开，通过修改配置项`UsePrivilegeSeparation no`后能登陆。这个选项在7.5版本后废弃，强制yes，但在安卓系统下，可能是exec机制不同，必须no才能连接。如果sshd不管怎么配置都不能用，可以换dropbear，因为只用一个进程，免去了exec的麻烦。默认没有公钥的话，用dropbearkey -t rsa  -f dropbear_rsa_host_key。由于Gentoo的portage机制导致小文过多，同步后直接把inode用完（至少13万个），导致系统无法使用。这可能也和手机版本4.2，默认只有19万inode，而另一台6.0上的inode有64万多，可惜无法尝试了。\\n\\n由于ebuild不能用，只能源码编译，没有自带解压zip的软件，网上找到的unzip源码竟然是2010年最后更新的6.0版本，看起来也不会再更新了。支持非常多的操作系统，以致于根目录下没有Makefile，看了帮助才知道要自己从相应的目录复制Makefile，在那个操作系统百花齐放年代的软件，风格和如今大为不同。可能是太常用也太古老的关系，busybox也整合了unzip功能，倒不一定非得使用原始的unzip。顺便说下unzip和zip分属两个包，版本号也完全不同，有点难以想象。\\n\\n应用市场能下载和GNURoot配套的镜像都比较旧，可用lxc制作的发行包(https://images.linuxcontainers.org/images/), arch或alpine也有独立发布的arm包(选armhf，不支持aarch64)。下载发行包后，按以下顺序操作\\n\\n1. 进入/host-rootfs/data/data/champion.gnuroot/app_install目录，有roots/support/versions 共3个文件夹。versions不用管，在roots和support下创建同名文件，名字随便取以后会显示在下拉框。roots包含的是发行版的rootfs，support是proot和busybox。由此看出GNURoot的流程大概就是busybox内用proot加载rootfs，达到模拟操作系统的目的。\\n2. 创建host-rootfs目录，如果没有/etc/resolv.conf也复制一份。\\n\\n做完以上两步，再打开GNURoot的下拉框，就可以看到刚安装的发行版了。\\n\\n* 不成功案例1: 先安装GNURoot的aboriginal包，然后不另建目录，直接把发行版的rootfs覆盖上去，再次打开会退出，可见必须另建新目录。在覆盖时遇到一个有趣的问题，原有的bin/目录是指向usr/bin/的软链接，这时一定要用`rm -rf bin`，不可以在bin后面加/，否则会把指向的目录删掉。因为软链接是文件，不加末尾的/，rm只删除这个软链，而加了/的话，会被作为目录删除导致悲剧。\\n* 不成功案例2: 在安卓5上可以安装GNURoot，但安装dropbear后，ssh输入密码成功后，提示`client_loop: send disconnect: Broken pipe`，然后断开。可见终究还是不能用。\\n\\n## GNURoot Aboriginal\\n\\n有台配置极差的老机只能装这个版本，sshd也不能用，好在上传busybox1.31通过telnetd可以使用。如果遇到telnetd可以连接但无法创建tty，可以用`busybox nc -lkp 4444 -e /bin/sh`创建简单的登陆方式，虽然没有高亮或补全，但可以救急。busybox还能挂httpd，真是个神奇的程序。\\n\\n## GNURoot Debian Jessie\\n\\n可以逐个版本地滚动升级上来\\n\\n```\\napt-get update\\napt-get upgrade\\napt-get dist-upgrade\\nsed -i \'s/jessie/stretch/g\' /etc/apt/sources.list\\n```\\n\\n之后再重复以上3升级步骤，此时要多一条\\n\\n```\\napt-get autoremove\\n```\\n\\n这样就彻底向上跳了一个版本，后续版本的更新类似。不过在一台未root的手机上操作，最终却因为libc无法更新停在了half-install状态，此时尝试装file，会提示需要libc >= 1.20，但是jessie的版本是1.19，只有stretch是1.24，无法安装新的软件，导致这个版本等于是废了。"}'));jctx.push(JSON.parse('{"id": "190220", "tag": "lang", "text": "# 程序语言的依赖包管理\\n\\n没有人可以写从到尾写完一个程序，除了内核这种项目，多都需要依赖其它库或源码，解决依赖也成了各种语言的基本功。又细分了两个需求：全局的包管理和项目级的包管理，不同的语言支持程度各不相同。\\n\\n## JS\\n\\nnpm是Node.js的首选模块依赖管理工具，仓库npm config get/set registry修改成国内的镜像http://registry.npm.taobao.org/。有本地和全局两种安装模式。\\n\\n* 本地模式: 在当前目录创建 package.json 文件来描述模块的依赖，在这个文件里你可以定义你的应用名称( name )、应用描述( description )、关键字( keywords )、版本号( version )等。npm会下载当前项目依赖模块到项目中一个叫做node_modules的文件夹内。\\n* 全局模式: 惟一的区别就是 install 命令后多了 -g 选项。安装到 prefix 目录的node_modules文件夹。但有一点不同，全局安装的依赖在主入口目录内，而本地则是平铺开。举个例子\\n\\nnpm的2.x版本采用嵌套式依赖方案，适合某个依赖在一个项目中多版本并存的问题，比如node；而3.x则换成扁平化的方式，更适合前端。npm的依赖可以指定版本区间，锁定，任意版本都支持。\\n\\n安装A库，A依赖B。如果是本地安装，node_modules下有 A 和 B 两个目录。但是如果是全局安装，node_modules只有A目录，A目录内又有node_modules，在这个嵌套子目录内会有B目录。\\n\\n对node来说，require的参数如果是核心模块，不会搜索磁盘目录直接加载核心模块，如果不在核心列表内，就会在路径后依次用找package.json的main字段/.js/.json/.node方式寻找，找到第一个文件停止搜索，且npm还有缓存机制，如果在缓存中就不会重复加载。\\n\\n与maven/gradle不同的是，maven最终会分析依赖树，把相同的软件默认扁平化取最高版本。而npm支持nested dependency tree。nested dependency tree是每个模块依赖自己目录下node_modules中的模块，这样能避免了依赖冲突, 但耗费了更多的空间和时间。由于Javascript是源码发布，所以开发态与运行态的依赖都是基于npm，优先从自己的node_modules搜索依赖的模块。\\n\\n## Lua\\n\\nrocks安装时要指定属于全局、个人或项目。\\n\\n## Python\\n\\npip只有全局模式，不支持项目级别定制包。默认放在python的lib/site-package目录，两个目录或是一个文件加一个目录（一个是执行模块或包，一个是描述元数据）。比如安装jedi包，成功后会有一个名为jedi的目录，还有一个jedi-0.16.0.dist-info目录。jedi目录放py代码，而带版本号的目录则放requires.txt、SOURCE.txt、PKG-INFO等元数据文件，依赖关系就记录在requires.txt里。将这两个文件以zip方式压缩，就是wheel包。\\n\\n## PHP\\n\\n出现较早的pear只支持全局下载包，后出现composer称自己是依赖管理器（也支持pear的包模式），可以在全局或项目中管理包更新，另外还自带PSR4的加载规范。\\n\\n## Java\\n\\n没有全局包的概念，只能在项目层面用pom.xml来控制版本，指定的版本号必须精确匹配，又走到了另一个极端。如果仓库没有想要的版本，就失败了不能模糊匹配。\\n\\n开发态，可以通过maven和gradle工具编辑依赖清单列表/脚本，指定依赖库的位置/版本等信息，这些可以帮助你在合适的时间将项目固化到一个可随时随地重复编译发布的状态。这些工具对我来说已经足够优雅有效。但maven中也有不同依赖库的内部依赖版本冲突等令人心烦的问题。尤其是在大型项目中的依赖传递问题，若团队成员对maven机制没有足够了解下，依赖scope的滥用，会让整个项目工程的依赖树变得特别的巨大而每次编译效率低下。运行态，目前Java也没有很好的依赖管理机制，虽有classloader可以做一定的隔离，但像OSGi那种严格的版本管理，会让使用者陷入多版本相互冲突的泥潭。\\n\\n展开说说maven，可以理解为Makefile的网络版，得益于java原生的网络支持，远程仓库的jar包和本地/lib下的so在软件层面等效。lifecycle由多个阶段(插件)构成，类似的也有clean, test, compile等目标，不同的是只能输出一种目标，package输出到当前工程，install进一步写入本地仓库，可以给其它工程链接，deploy多一步发布到远程仓库，给其他人用。\\n\\n## C语言\\n\\n最多的还是Makefile，但和其它语言比，只能说是半残。接口头文件和库之间没法校验匹配性，也不容易指定库的版本。链接时通常是指定库名称，到底指向哪个库，只能听由操作系统的软链接。所以现在的发行版在.so后面还会跟一个数字，形成类似.so.2这样的文件名，如果出现重大不兼容，可以指定大版本。\\n\\n## 语义化semver\\n\\n开源产品的迭代难免引入不兼容修改，通过目前社区都认同的语义化版本方案，依赖时必须要限定版本号，否则大版本升级就无可挽回了。npm有`~`和`^`两种标识符，比较体现版本依赖的思想。\\n\\n* `~`，tilde range。只接收bugfix，不会改功能版本，可以理解为约等号。比如`~1.2.0`，即使上游开发了1.3或1.4，仍停留在1.2.z的最后一个版本。是早期npm的默认策略，也是比较稳健的策略。\\n* `^`，caret range。只要保证兼容性，尽量往新了更，会保证左侧第一个非零值不动。比如`^1.2.0`会追踪上游的1.3.x，但是`^0.2.0`则会停留在0.2.x，因为左侧第一个非零是2，必须保证不变。这大概是语义化版本对0的理解有不稳定的意思，所以稳妥起见遇到0选择跳过。\\n\\n我倒觉得都用`1.*`这种方式表达依赖，更少学习成本，也更直观。"}'));jctx.push(JSON.parse('{"id": "190221", "tag": "lang", "text": "# Lisp与Haskel比较\\n\\n这两门语言从不同的角度去解决了一个共同的问题：如何减少重复代码，如何提高抽象。\\n\\n首先两门语言都是建立在lamdba演算之上，都提供了first class的函数支持，所以在这两门语言里函数都是构建计算的基本单元，而不是c系语言的statement。\\n\\n但是即使是书写函数，人们依然希望获得更加高级的抽象，来减少重复，举几个具体的例子：\\n\\n解析文本这个过程，前进buffer >> 判断是否符合当前的语法结构 >> 失败了？报错 >> 成功了继续重复（重复的代码：判断）\\n渲染模版的过程，计算一个模版片段 >> 计算下一个模版片段 >> 把模版片段相连 >> 继续重复 （重复的代码：相连）\\n设计一个状态机的过程，拿到上一个计算之后的状态值 >> 基于这个值运行状态机，产生新的状态和可能的计算结果 >> 继续重复 （重复的过程：状态传递）\\n我们看到这个时候依赖人工书写这些代码会出现大量重复的情况，LISP的思路基于语法结构，LISP巧妙的利用lamdba的基本书写形式 (lamapp variables)，构建了模版(marco)，这意味着只要是一段代码具有相同的语法结构，比如重复地进行判断，你都可以把它抽象为模版，由编译器或者解释器来替你做语法层面的替换，自动生产重复的代码。需要注意的是LISP的模版抽象是基于语法树(AST)而不是字符串的，同时LISP的AST非常简单，这意味着书写构建AST的模版也非常简单。\\n\\n\\n而Haskell的思路是建立在类型类多态的基础上的，haskell里构建大规模计算的类型类是Monad，它定义了一个多态的连接函数bind，aka. >>= 。 这个函数的作用是连接上下两段相同类型的运算。在这个连接的过程中，你可以通过定义判断，或者相连，或者传递状态等等，来实现不同的计算语义，这个类型类是haskell减少代码重复的关键。而这个构建计算的框架和haskell的强类型系统非常契合。\\n\\n\\n当然LISP也可以实现一个untyped的monad模版，haskell也支持template haskell，所以在LISP里monad这是众多模版中的一个，而在Haskell中，LISP的AST也只是众多语法结构里比较底层的一个。但是这些并不意味着谁比谁更加强大，这只是两个语言解决问题的思路不同。\\n\\n\\n所以无论如何，如果可以，请把这两门语言都认真的学习一番，即使你可能不在实践中使用它们，它们都会给你带去很不一样的编程思路。\\n"}'));jctx.push(JSON.parse('{"id": "190223", "tag": "protocol", "text": "# Unicode的若干概念\\n\\n可以把Unicode想成一本字典，规定了每个文字的映射(严格的说有些带声调的文字是组合出来的)。ASCII的删除键DEL编码是0x7F，在打孔机时代把字母全部重置，如果没见过纸带怕是理解不了的。\\n\\n欧洲文字ISO8859定义了16个分部，但是要混打德文和俄文就不行了，于是2022规范引入了ESC转义规则，这套规则后来也被用在JIS和GB上。\\n\\n截止1999年前，CJK统一汉字的范围是4E00-9FA5，用了基本面的20901个符号。后来又补充了若干编码，大多在基本面，少量在0x20000面，都是很少见的字。不严谨地说，用4E00-9FA5是足够用的。\\n\\n首先每个字符是不是等宽，于是就有了宽字节和多字节的区分。宽字节的好处是查找统计反转方便，而多字节由于是变长，保存拉丁字母会省空间。因此宽内存多用于内存中的计算，而多字节用于存储或传输。Windows的API就是宽字节版。\\n\\nBMP之前的宽字节方案，就称为UCS2，多字节编码是UTF8。随着UCS2不得换为更大集合，出现了UCS4方案，Windows为了保持和UCS2的兼容性，于是有了UTF16编码。它选取了UCS2一段不用的编码段来标识。而这个段的范围是1024x1024。这个范围等于17x65536，也就是现在字符集范围的来历。\\n\\n## 正则匹配\\n\\npcre库为适应Unicode，加入了`\\\\p`选项，支持pUnicode类名和p{Unicode}文字名两种模式。比如想匹配广义的数字，用`/\\\\pN+/`，想匹配中文，用`\\\\p{Han}`不用指定编码区间，全部交给底层文字引擎就可以了。\\n\\n## 代理项对sorrogate pair\\n\\n最初的1.0版本定义65536的集合大小，称为BMP。但是2006年中国要求所有软件支持GB18030，这个范围就不够了。这时就从BMP中把D800~DFFF这段区间保留下来不单独表示任何字符，专门用于转义扩展。这个区间又叫S区，共2048个字符。\\n\\n转义时，D800到DBFF表示高10bit，DC00到DFFF表示低10bit，于是又能多表示16x65536个字符，再加上BMP。整个Unicode范围17个位面就是这么来的。"}'));jctx.push(JSON.parse('{"id": "190301", "tag": "os", "text": "# 多线程中锁的介绍\\n\\n自旋锁（spinlock）很好理解。对自旋锁加锁的操作，你可以认为是类似这样的：\\n\\n```\\nwhile (抢锁(lock) == 没抢到) {\\n}\\n```\\n只要没有锁上，就不断重试。显然，如果别的线程长期持有该锁，那么你这个线程就一直在 while while while 地检查是否能够加锁，浪费 CPU 做无用功。\\n\\n仔细想想，其实没有必要一直去尝试加锁，因为只要锁的持有状态没有改变，加锁操作就肯定是失败的。所以，抢锁失败后只要锁的持有状态一直没有改变，那就让出 CPU 给别的线程先执行好了。这就是互斥器（mutex）也就是题目里的互斥锁（不过个人觉得既然英语里本来就不带 lock，就不要称作锁了吧）。对互斥器加锁的操作你可以认为是类似这样的：\\n\\n```\\nwhile (抢锁(lock) == 没抢到) {\\n    本线程先去睡了请在这把锁的状态发生改变时再唤醒(lock);\\n}\\n```\\n\\n操作系统负责线程调度，为了实现「锁的状态发生改变时再唤醒」就需要把锁也交给操作系统管理。所以互斥器的加锁操作通常都需要涉及到上下文切换，操作花销也就会比自旋锁要大。\\n\\n以上两者的作用是加锁互斥，保证能够排它地访问被锁保护的资源。\\n\\n不过并不是所有场景下我们都希望能够独占某个资源，很快你可能就会不得不写出这样的代码：\\n\\n```\\n// 这是「生产者消费者问题」中的消费者的部分逻辑\\n// 等待队列非空，再从队列中取走元素进行处理\\n\\n加锁(lock);  // lock 保护对 queue 的操作\\nwhile (queue.isEmpty()) {  // 队列为空时等待\\n    解锁(lock);\\n    // 这里让出锁，让生产者有机会往 queue 里安放数据\\n    加锁(lock);\\n}\\ndata = queue.pop();  // 至此肯定非空，所以能对资源进行操作\\n解锁(lock);\\n消费(data);  // 在临界区外做其它处理\\n```\\n\\n你看那个 while，这不就是自己又搞了一个自旋锁么？区别在于这次你不是在 while 一个抽象资源是否可用，而是在 while 某个被锁保护的具体的条件是否达成。\\n\\n有了前面自旋锁、互斥器的经验就不难想到：「只要条件没有发生改变，while 里就没有必要再去加锁、判断、条件不成立、解锁，完全可以让出 CPU 给别的线程」。不过由于「条件是否达成」属于业务逻辑，操作系统没法管理，需要让能够作出这一改变的代码来手动「通知」，比如上面的例子里就需要在生产者往 queue 里 push 后「通知」!queue.isEmpty() 成立。\\n\\n也就是说，我们希望把上面例子中的 while 循环变成这样：\\n\\n```\\nwhile (queue.isEmpty()) {\\n    解锁后等待通知唤醒再加锁(用来收发通知的东西, lock);\\n}\\n```\\n\\n生产者只需在往 queue 中 push 数据后这样，就可以完成协作：\\n\\n触发通知(用来收发通知的东西);\\n\\n// 一般有两种方式：\\n//   通知所有在等待的（notifyAll / broadcast）\\n//   通知一个在等待的（notifyOne / signal）\\n```\\n这就是条件变量（condition variable），也就是问题里的条件锁。它解决的问题不是「互斥」，而是「等待」。\\n\\n至于读写锁（readers-writer lock），看英文可以顾名思义，在执行加锁操作时需要额外表明读写意图，复数读者之间并不互斥，而写者则要求与任何人互斥。读写锁不需要特殊支持就可以直接用之前提到的几个东西实现，比如可以直接用两个 spinlock 或者两个 mutex 实现：\\n\\n```\\nvoid 以读者身份加锁(rwlock) {\\n    加锁(rwlock.保护当前读者数量的锁);\\n    rwlock.当前读者数量 += 1;\\n    if (rwlock.当前读者数量 == 1) {\\n        加锁(rwlock.保护写操作的锁);\\n    }\\n    解锁(rwlock.保护当前读者数量的锁);\\n}\\n\\nvoid 以读者身份解锁(rwlock) {\\n    加锁(rwlock.保护当前读者数量的锁);\\n    rwlock.当前读者数量 -= 1;\\n    if (rwlock.当前读者数量 == 0) {\\n        解锁(rwlock.保护写操作的锁);\\n    }\\n    解锁(rwlock.保护当前读者数量的锁);\\n}\\n\\nvoid 以写者身份加锁(rwlock) {\\n    加锁(rwlock.保护写操作的锁);\\n}\\n\\nvoid 以写者身份解锁(rwlock) {\\n    解锁(rwlock.保护写操作的锁);\\n}\\n```\\n\\n如果整个场景中只有一个读者、一个写者，那么其实可以等价于直接使用互斥器。不过由于读写锁需要额外记录读者数量，花销要大一点。\\n\\n你可以认为读写锁是针对某种特定情景的「优化」。但个人还是建议忘掉读写锁，直接用互斥器。\\n\\n额外补充\\n\\nspinlock 不涉及操作系统，就是等价于 while 的俩汇编指令。mutex 虽然经典实现会引起 context switch，但是现在的具体实现不一定，比如 Linux 下可以利用用户空间的 futex。回答里的那个「本线程先去睡了请在这把锁的状态发生改变时再唤醒」不涉及条件变量，可以认为是个系统调用。\\n\\n读写锁内部是至少需要用一把锁来保护当前读者数的，所以，如果你的临界区很小，读写锁相比一般的锁并不能带来很大的优势，甚至可能性能更低。\\n\\n\\n另一方面，读写锁要真正发挥效能，条件也比较麻烦。比如实际的读写锁通常不用例子里两把锁的实现，而是用一把锁、一个条件变量来实现，好处是可以缓解写者饥饿的情况（一旦有写者在等锁，后续读者都需要等写者离开后才能继续），但这样一来，如果读者的临界区没有明显小于写者的临界区，阻塞情况可能会变得比较不理想……\\n\\n\\n不是说不要用读写锁，而是读写锁往往没有看上去那么理想。个人建议是可以优先用 mutex，如果遇到瓶颈后可以选择替换为读写锁，看看能否带来性能提升。\\n\\n通常是用信号量（semaphore）来实现锁，而不是用锁来实现信号量。至于如何保证线程安全，可以理解为有专门的机器指令来保证原子操作。\\n\\n请教一下，为什么“以读者身份加锁”那里，加写锁的条件为什么是“rwlock.当前读者数量 == 1”？\\n\\n第一个到达的读者负责抢写锁，确保写者等待；最后一个离开的读者负责归还。如果你把把所有读者看成一个整体的写者，可能更方便理解为什么这么抢。\\n\\n一个进程获得锁资源进入临界区后，很可能在锁没有释放前被调度走，而其他进程在等待锁资源，这样就会发生死锁。我知道通常spinlock会关中断，所以用spinlock锁定后进程不会被调度走。那么其他几种锁会允许获得锁后被调度吗？\\n\\n如果我的理解没错的话，你说得这种情况是正常情况，还是可以调度回来的，不是死锁。如果是两把及以上的锁，各个线程上锁顺序不一致，才会出现你说的死锁问题。\\n\\n答主，请教下 前两个例子： 我感觉自旋锁和互斥锁都会引起上下文切换，假设一个单核cpu 分配时间片给多个线程竞争相同自旋锁，其中只有一个拿到锁，然后时间片结束切换到其他线程但它还持有锁，那么其他线程获得cpu 分片但没获得锁进入自旋，cpu 分片结束还是会引起上下文切换，这样跟互斥锁的主动上下文切换似乎是一样的。那它自旋的意义何在呢？因为从这里看起来你进入自旋一定获取不了锁。\\n\\n单核「进入自旋一定获取不了锁」是不对的，因为还会被操作系统切换回来，只不过是浪费时间片。自旋锁本意是给多核/处理器场景用的，除了你举的例子里浪费时间片的问题，如果是在单核非抢占式上用经典自旋锁，那么铁定死锁。多核/处理器的场景下，自旋锁的意义在于优化一些短时间的锁（比如一些自旋等待的时间几乎始终会比互斥锁让线程睡眠&唤醒操作的时间要短的情况）。现代操作系统在实现自旋锁、互斥锁时，一般都会做优化，比如可能会让互斥锁先自旋一小会儿；可能会在自旋锁自旋超过一定时间后强制切换上下文；也可能会在单核非抢占式上让自旋锁什么都不干……不过这些「优化」我们编程时通常都不需要了解，按照经典实现去理解就足够了。\\n\\n您好，问一个问题， mutex 的lock后，unlock应该是要同一个线程才能执行的，但像上面的读写锁， 解锁（rwlock.保护写操作的锁） 的时候不一定是加锁的那个线程怎么办啊....\\n\\n如果你真的想要用两个 mutex 实现的话，需要看你用的 mutex 接口的具体情况，比如 C++17 的 std::shared_mutex 是支持不同线程解锁的。当然你也可以把 mutex 换成 semaphore。\\n"}'));jctx.push(JSON.parse('{"id": "190310", "tag": "os", "text": "# Preempt机制\\n\\nPreempt是一个32位的整数，每一个CPU有一个。虽然是一个简单的整数，但是作用非常大。一个当前运行的线程能不能被抢占，全靠判断这个整数是否是0。这里的线程包括了用户空间的进程的概念，在内核中对应的也是一个线程。当这个整数为0的时候，当前线程就能被抢占，否则不能。\\n\\n软中断是一个普通的内核线程，与其他的内核线程一样，都参与内核线程的统一调度。软中断的实现是每一个CPU对应一个内核线程ksoftirqd，所以，有多少个CPU就会有多少个ksoftirqd内核线程。\\n\\nSoftirq依赖一个softirq_vec数组执行软中断。每一个数组内容对应一个Action，相当于一个中断向量（仿照硬中断进行的设计）。虽然所有的核共享这个数组，但不是每个核都要执行这个数组里的所有任务，每个核都有一个本地数据，用来指明当前核所需要承担的软中断任务。由于是共享一个softirq_vec，理论同一个任务都可以被所有的核对应的ksoftirq内核线程所执行。\\n\\n由于软中断的内部是用户可以注册的任意的软中断函数，在这内部用户的行为一定程度是不可控的。所以软中断系统在调用每一个软中断的action的时候，都会保存preempt的值，在执行结束后复原这个值。这个值的作用很大，一个CPU一个值，如果非0，就代表这个CPU不能发生抢占，只有这个值是0的时候，当前的线程才能被抢占。也就是说，当我不希望被别人抢占的时候，只需要将这个数设置为非0即可。一般调用一下preempt_count_inc就可以将这个数自增1来达到目的。设置的就是当前CPU的计数器。对其他CPU并不影响。\\n\\nTasklet是基于Softirq功能进行实现的，实现的方法就是在一个特定的数组位置定义了一个action，仅此而已。但是由于Tasklet在内部进行了中断和抢占的设置，会显然Tasklet与其他的Softirq行为上不太一样。Tasklet相当于在Softirq之上多了一层保证，两个相同的Tasklet不会同时执行。也就是说不存在软中断上下文重入的问题。除此之外，Tasklet就是个普通的软中断的一个action而已。内核中的Timer也是软中断的一种。同一个软中断是可以在不同的核上同时执行的（但是不能在同一个核上重入），而同一个tasklet不可以同时在不同的核上执行，显然也不能在一个核上重入。\\n\\n由于一个软中断只是一个普通的内核线程，所以它和其他的内核线程一样参与内核的进程调度。只是软中断的内部动不动就会操作抢占和软中断的使能函数，所以显得软中断会比较特殊。更特殊的是，软中断的入口函数是__do_softirq，这个函数在一开始就会把本核的preempt关掉，也就是说，软中断在执行的过程中，不允许在本核被抢占。那么带来的结果就是，如果在软中断里面阻塞了，将永远阻塞。就是完全死锁。这也是软中断的难度之一。\\n\\n假设有一个软中断的函数和一个用户上下文的函数操作同一个自旋锁（这在内核模块的编程中很常见），用户空间锁了这个自旋锁之后，软中断打断了用户空间对应的内核模块函数的执行，软中断继续来加锁，就会导致用户空间的锁永远不能释放，软中断就会永久死锁。所以一般在这种情况的用户上下文需要先把软中断关掉才能进行加锁。这个情况最典型的是用户空间上下文和软中断上下文要操作同一个自旋锁的时候。也正是因为软中断在进入的时候关闭了preempt，禁止了抢占，所以在软中断内部禁止调用可以阻塞或者睡眠的函数，因为这会导致软中断被调度出当前的CPU，其他的内核线程被调度来执行。而这个时候，preempt已经关闭，这样就相当于了所有的内核线程都是在禁止抢占的环境下执行的，这显然会带来严重的问题。所以软中断是绝对禁止调用阻塞式的函数的。\\n\\n另外，软中断和preempt计数器的关系是很巧妙的设计。每一个CPU核对应的preempt计数器都是一个32位的整数。软中断和硬中断在进入的时候都会禁止抢占，而他们禁止的时候设置的位是不一样的。我们知道这个整数只要是非0就不可以被抢占。内核为了区分当前到底是谁在禁止抢占，在这32位的整数上做了很多文章。对这个整数进行了位空间的划分。不同类型的抢占对应不同的位。这样就可以区分不同的专用抢占了。所以软中断和硬中断在禁止抢占的时候，并不是简单的调用自增，而是调用一个增加函数，增加的值就是他们对应的位。例如软中断是__local_bh_disable_ip(_RET_IP_, SOFTIRQ_OFFSET); 这个SOFTIRQ_OFFSET对应的就是软中断的位偏移。\\n\\n如果需要local_bh_disable()来保护进程的临界区。比如，进程A和某个tasklet都会访问一个共享数据结构，semaphore和mutex不行，因为tasklet有可能运行中中断上下文。 spinlock也不行。\\n\\n如果进程A先获得spinlock, 然后被tasklet打断，在tasklet也去获取同义把spinlock, 就会死锁。这时就需要在进程A中调local_bh_disable()，在临界区结束时调local_bh_enable()。这样保证在临界区中，不会被tasklet所打断。\\n\\n实际代码中，一般都是spin_lock_bh()，相当于local_bh_disable()加spin_lock()。关键的代码是软中断的入口处的代码，如下：\\n\\n```\\nasmlinkage __visible void do_softirq(void)\\n{\\n__u32 pending;\\nunsigned long flags;\\nif (in_interrupt())\\nreturn;\\nlocal_irq_save(flags);\\npending = local_softirq_pending(); \\nif (pending && !ksoftirqd_running())\\ndo_softirq_own_stack();\\nlocal_irq_restore(flags);\\n}\\n```\\n\\n实际的软中断的执行之前，都会调用一个in_interrupt的判断，字面意义是如果发现自己已经在软中断内部了，就不再执行软中断。所以，同一个CPU的软中断是不可能被另外一个软中断抢占的。in_interrupt函数仅仅是一个查看当前preempt整数对应的中断的位有没有被设置的判断（包括硬中断和软中断），所以关闭软中断的操作就会很简单：\\n\\n```\\nstatic __always_inline void __local_bh_disable_ip(unsigned long ip, unsigned int cnt) \\n{ \\npreempt_count_add(cnt); \\nbarrier(); \\n}\\n\\nstatic inline void local_bh_disable(void) \\n{ \\n__local_bh_disable_ip(_THIS_IP_, SOFTIRQ_DISABLE_OFFSET); \\n}\\n```\\n\\n只是是一个简单的设置这个preempt整数的操作，使得当前CPU处于一个中断上下文中。而，这个函数不止是中断处理程序才会调用，用户自己写的模块也可以调用。\\n\\n也就是说，用户的内核模块，在用户进程上下文的时候，想要与软中断上下文争夺一个自旋锁的时候，就需要在用户进程上下文对应的内核模块函数中将软中断关掉。关闭软中断在软中断本身看来就是有其他的软中断在运行。所以实际上，这个操作是欺骗软中断系统有其他的软中断在运行了，你就不能运行了。这也是软中断不能同时运行抢占的原因。\\n\\n由于用户在这个CPU上调用 local_bh_disable的时候，一定是一轮的软中断已经运行结束的时候，所以当前关闭软中断就不会和ksoftirqd冲突。一轮的软中断执行会遍历当前CPU pending的所有软中断，直到执行结束，软中断才会让出CPU。出现pending就一定是硬中断的干的，因为硬中断才是负责源源不断的给软中断输出内容的机制。也就只有硬中断能够抢占软中断。\\n\\n这里面就有一个尴尬的问题。如果硬中断可以打断软中断，那么在硬中断退出的时候，怎么保证CPU的上下文是交还给软中断，而不是被调度引擎调度给用户进程了？如果这个得不到保证，软中断的所有不可被抢占的保证都白费了，因为这就相当于间接的允许被抢占。\\n\\n为了解决这个问题，硬中断退出的时候有一个专门的操作：\\n\\n```\\nvoid irq_exit(void) \\n{ \\n#ifndef __ARCH_IRQ_EXIT_IRQS_DISABLED \\nlocal_irq_disable(); \\n#else \\nWARN_ON_ONCE(!irqs_disabled()); \\n#endif \\naccount_irq_exit_time(current); \\npreempt_count_sub(HARDIRQ_OFFSET); \\nif (!in_interrupt() && local_softirq_pending()) \\ninvoke_softirq(); \\ntick_irq_exit(); \\nrcu_irq_exit(); \\ntrace_hardirq_exit(); /* must be last! */ \\n}\\n```\\n\\n可以看到，在硬中断结束的时候，会检查当前CPU的软中断是否被挂起，如果挂起了，就主动的调度软中断。这一步是不把调度交给调度引擎的，而是直接在硬中断中强制调度。也就是说，虽然硬中断可以打断当前的软中断的执行，但是当硬中断执行结束的时候，必须要把CPU交还给被硬中断挂起的软中断。从而就解决了这个可能被间接抢占的问题。\\n\\n这个把preempt按位区分功能的做法有一个很特殊的效果，就是有的功能是可以同时设置多个功能对应的位的。例如NMI也对应preempt整数的一些位，但是当进入NMI硬件中断的时候，它会同时设置NMI对应的位和硬件中断对应的位。\\n\\n```\\n#define nmi_enter() \\\\\\ndo { \\\\\\nprintk_nmi_enter(); \\\\\\nlockdep_off(); \\\\ \\nftrace_nmi_enter(); \\\\ \\nBUG_ON(in_nmi()); \\\\\\npreempt_count_add(NMI_OFFSET + HARDIRQ_OFFSET); \\\\\\nrcu_nmi_enter(); \\\\\\ntrace_hardirq_enter(); \\\\\\n} while (0)\\n```\\n\\n设置的位越多，从效果上看，也就意味着权限越高。因为首先硬件中断对应的抢占位是只能由硬件中断来恢复的，NMI这种硬件中断做到了，即使其他的硬件中断恢复了硬件中断抢占位，其他人还是不能抢占当前的NMI上下文。因为还有一个NMI_OFFSET对应的抢占位没有被清0，而只要这个值不是零，就不能被抢占。这就意味着当发生NMI的时候，任何其他的硬件中断都不能将其抢占。这也就奠定了NMI在硬件中断中的最高优先级的地位。所以，NMI的全称叫做：NMI(non-maskable interrupt)，不可屏蔽中断。这从另外一个层面说明了屏蔽硬件中断的操作是将preempt的 HARDIRQ_OFFSET置位，而不会去操作NMI_OFFSET 。也就是说明了NMI的实现原理还是在这个32位整数上做文章，就是规定了硬件中断以外的位来作为抢占的开关。\\n\\n在硬中断快要结束的时候，硬中断会在硬中断的函数栈内调用一次软中断的执行函数。这个时候，硬中断已经打开了硬中断，所以允许被抢占。这个上下文属于中断的BH，但是还不属于ksoftirqd的软中断内核线程的上下文。\\n\\n由于硬中断进入这个BH的条件是当前没有处于中断中，这个中断包括了软中断，硬中断和不可屏蔽中断三种情况，处于任何一种情况下，这个硬中断BH下都不会进入软中断的处理逻辑。所以这部分的软中断逻辑运行是不会同时允许多个的。只要该CPU当当前有在这个BH逻辑中，其他的硬中断就不会进入。\\n\\n这个逻辑的设计使得同一个软中断同时具备两个执行的环境。一个是在硬中断执行结束退出的时候，直接调用软中断执行，这个时候已经将硬中断打开。另外一个是在ksoftirqd中运行一个软中断，这个软中断执行的时候，是处于内核线程的上下文，接受内核线程调度的过程。一个简单的区别是，如果在ksoftirq中写一个死循环，该CPU是仍然可以执行其他的逻辑的，只是该CPU上的软中断逻辑会被永远卡住。但是如果在硬中断的BH执行了软中断，那么硬中断只可以被硬中断打断，但是打断之后又会回来软中断的执行，所以该CPU将会永久阻塞。\\n\\n硬中断结束的时候调用软中断这个设计，使得当系统负载很低的时候，大部分的软中断都可以直接在硬中断结束的时候完成，而不需要进入ksoftirqd的软中断内核线程进行执行。省去了软中断的内核线程运行开销就节省了一定的性能。\\n\\n但是有个矛盾的问题是，这种硬中断直接能处理玩的软中断的情况只会发生在资源占用率很低的情况。但是这种情况下，对资源的这点程度的节省又意义不大。所以在涉及到中断的性能的时候，仍然是需要关注ksoftirqd的性能，而是BH的性能。\\n\\n内核对于这个preempt一个小小的整数所设计的复杂的机制，可谓精妙绝伦。\\n\\n## 链接原理\\n\\n符号重定位是编译过程和运行过程都要发生的动作。在编译的过程中，如果所有的代码都写到一个单独的文件，由于编译器以文件为单位进行编译，所以可以一次性的拿到所有的函数，那么就可以就地处理所有的符号。显然这样是编译器最喜闻乐见的事情。但是由于有外部库和工程组织的需要，不可能所有的代码都在一个文件中，编译器是用来满足开发人员的需要的，不是反过来。所以编译器就要想办法解决不同文件之间的链接问题。\\n\\n编译器在编译一个文件的时候，会生成一个段的划分。这个划分通常名字大同小异（当然可以通过写link脚本改变段的命名和排布），但是.text, .data这种常用的代码段和数据段基本没有人会有其他想法。每个文件编译的时候生成了同样的.text段，链接器用来处理多个编译单元的（也就是.o文件），将这些文件链接在一起的时候，链接器的主要工作就是将同样的段进行合并。这个操作看起来简单，但是不断.o文件互相调用的情况该怎么解决呢？例如A文件调用了B文件的test函数，在编译A的时候看不到B中test函数的定义，那么这个A里面的B的test函数的地址该如何填充？链接器在进行链接的时候又该如何修正？\\n\\n首先可以确定的是A里面在链接发生之前是肯定不能知道B中test的地址的，但是A里面的汇编结果的call指令的目的地址总需要填充个值。这个值就是0，就是在编译A的时候，发现A调用了别人的test函数，编译器会直接在call的A函数的位置填call 0地址，然后同时，在A的目标文件的一个.rel.text和.rel.data。这两个表叫做重定向表，用于在链接的时候组装不同的目标文件，一个是函数重定向，一个是数据重定向。里面存储的信息就是在A的某某偏移位置调用了test函数。当链接发生的时候，链接器查看A的重定向标发现A需要test的地址，然后在B的函数定义中查找test的定义和地址（是A和B的.text合并之后的地址），然后用这个地址去修改A对应的偏移里面的call指令。这样就完成了链接时的重定位。\\n\\n这个重定位发生在所有的静态链接的时候，包括静态链接库的时候和链接自己的代码文件的时候。\\n\\n但是我们知道还有一个很常见的应用是动态链接。动态链接的时候，符号的位置要在运行的过程中才会解析。编译的时候分为PIC的编译方式和非PIC的传统编译方式（现在大部分库都是使用PIC的方式）。两个的区别在于能不能在内存中重用库的代码。非PIC的传统编译方式需要在加载库的时候就重新设置所有的符号。例如liba.so里面调用了libb.so里面的一个函数test，那么按照静态链接的思路liba.so需要暴露一个段里面存放需要重定位的符号（也就是 call test的偏移），在加载libb.so的时候就要立刻解析条虫liba.so里面的call指令对应的test函数的地址。这种情况相当于liba.so的.text段的内容在加载的时候被修改了。也就是说liba.so的.text的位置在不同的程序里面是不一样的（因为libb.so在不同的进程不一定在同样的位置）。所以liba.so在内存中不能复用，也就是每个进程都要在内存中加载一份liba.so的.text，liba.so使用了多少次就需要加载多少份。\\n\\n这样有问题吗？除了内存里有多份liba.so外，并没有什么问题。有一个特点是加载的时候需要解析全部的符号，即使没有用到的，这样加载的速度相对慢一些。\\n\\n动态链接用到了.rel.dyn和.rel.plt（PLT：过程链接表）。前者是数据重定向，后者是函数重定向。两个段的功能与静态链接的重定向表是一样的。这一切都显得那么轻松。\\n\\n但是毕竟程序员是追求完美的，针对这两个问题，追求完美的程序员想出了PIC模式。所谓的PIC模式就是位置无关，就是想办法让liba.so的.text在所有使用liba.so的进程之间复用。这样只依赖.rel.dyn和.rel.plt可能就做不到了。因为使用这两个表是需要修改.text段的内容的。所以又添加了.got和.got.plt两个表，同样的，前者对应数据，后者对应函数。这两个段就是PIC的实现方法了。\\n\\n所谓的PIC就是在编译liba.so的call test函数的时候，不是在test函数的地址位置填充0，而是填充liba.so的.got.plt段的test地址。在编译的时候.got.plt中的test的地址是空的，显然是不能寻址的，但是call test指令却是直接固定的调用.got.plt的表的test函数的（虽然这个函数还不知道在哪定义）。.got.plt相当于一个桩子，call test就是调用了这里的桩子函数。由于.got.plt不是位于.text里面，所以在解析的时候只需要修改.got.plt里面的test的定义地址就可以找到真实的定义，无论libb.so加载到内存的什么位置，都是只需要找到它，然后填充liba.so的.got.plt的test函数条目即可。如此.text就可以实现复用了。第一个问题解决。\\n\\n第二个问题就是延迟绑定的技术。这个技术是为了防止加载的时候解析所有的符号，而是让用的时候才解析。所需要的技术在应用了PIC之后几乎是现成的。就是.got.plt中的内容不是加载的时候填充，而是用到的时候填充。这一切由运行时的链接器完成（interpreter）。\\n"}'));jctx.push(JSON.parse('{"id": "190326", "tag": "lang", "text": "# Java程序的演变\\n\\n编译后的class类似lua的luac文件，jvm去加载并从指定的类开始跑。不过从一开始，java就支持导入和打包，尤其是打包，引申出很多内容。\\n\\n最早出现的jar包，把多个class集中到一起，作为库或执行程序来发布。jar包的顶层目录结构包含META-INF目录，其中有MANIFEST.mf文件，如果是可执行程序，就要指定Main-Class作为入口。后来sun出了servlet规范，类似python的WSGI，都是语言专属规范，按servlet写好的类，不用考虑底层的网络处理。当年不选择CGI，是因为它和HTTP强绑定，而Java想做通用网络规范。HttpServlet就是语言专属的特化规范。\\n\\n为了配合tomcat这个网络层的运行时，显然需要配置文件，类似于nginx的location语句，这些配置文件一起被打到jar包，为了体现差异，就把后缀改成war。多了一个和META-INF并列的WEB-INF目录，后来的springboot则用BOOT-INF命名目录。\\n\\nwar包流行了至少十多年，慢慢地微服务的概念起来，服务变小再用tomcat加载就很啰嗦，于是springboot把所有的库和资源，包括嵌入式tomcat打到一个包，拿着1个文件，随便往哪一丢，连命令行参数都不用指定就跑起来了，于是war又回归了flat jar(实质是jar in jar的二重封装)。这种包的Main-Class是org.springframework.boot.loader.JarLauncher，Start-Class才是你写的类。\\n\\n顺带说句tomcat实现servlet规范，比较适合阻塞式的模型，追求非阻塞的服务，网络层甚至都不再用tomcat了。\\n\\nflat太大，依赖的lib通常不会更新，可以瘦身。先正常编译，并把BOOT-INF/lib解压出来。修改pom.xml，在configuration、ZIP后加入\\n```\\n<includes>\\n    <include>\\n          <groupId>nothing</groupId>\\n          <artifactId>nothing</artifactId>\\n     </include>\\n</includes>\\n```\\n就能打出没有lib的包。用java -Dloader.path=/path/to/lib -jar /path/to/springboot.jar 运行。\\n\\n## bean\\n\\n最早为了配合IDE开发GUI出现的概念，变成了大家共同遵守的约定，随着加入越来越多的需求，变成EJB，事情过了头又被spring的bean替代，解决的问题，无非是数据的包装和生命周期管理，惟此GC才能正常工作。\\n\\n## maven\\n\\n既然上面给了配置片断，就展开讲讲pom要怎么理解。每个project由groupId(推荐用域名)和artifactId(对应jar名)标识出来，另外vertion当然是必备的。\\n\\n## 组织和标准委员会\\n\\n1998年成立的JCP组织，community process是运作委员会，而每个提案则以JSR，specification request经过多轮讨论，只有到final阶段才算发布。\\n\\n## 使用体会\\n\\n以HTTP发送JSON为例子。解析和序列化是个很繁复的工作，每种JSON都必须先定义一个类，运行中由反射出来的信息，根据类的scheme进行解析，完全不是随心所欲地写节点。要用这种重器，必须先想清楚结构，才能下笔。于是登陆就拆成3个类，1个行为加2个结构类。倘若换在C里，也是如此拆分，但不可能为结构体单开一个文件。\\n\\n再说异常，这恐怕和C的差别就更大，似乎风气导向，出现问题抛异常并在最后统一处理，往好了说是把正常和异常代码各划各片，但新语言如go仍反对异常，只能说语言倾向和手法不同。\\n\\n说说编译，稍微有点功能的程序，依赖包必不可少，`-classpath .;../lib/xx.jar`非常重要。其中的点号一定要有，每个用到的jar包都要写进来，编译和运行都如是。\\n\\n## 远程调试\\n\\n支持多种connector，不过最常用的还是socket。shmem仅局限于windiws，不看也罢。\\n\\n客户端用 jdb -connect com.sun.jdi.SocketAttach:hostname=192.168.101.72,port=8899\\n\\n服务端启动脚本：\\n\\nJAVA_OPTS=\\"$JAVA_OPTS -agentlib:transport=dt_socket,address=127.0.0.1:8000,suspend=y,server=y\\"\\n如果是调试jar包，指令：\\n\\njava -Xdebug -Xrunjdwp:transport=dt_socket,address=127.0.0.1:8000,suspend=y -jar remoting-debug.jar"}'));jctx.push(JSON.parse('{"id": "190408", "tag": "web", "text": "# 网站项目教训\\n\\n## MySQL\\n\\n用service 启动MySQL后，会发现进程有两个，mysqld_save和mysqld，save是个shell脚本，做些资源守护。记得开binlog，\\n\\n遇到启动不了updating without PID的情况，居然简单地mv /etc/my.cnf /etc/my.cnf.old就解决了。原因是支持无配置文件的启动，用mysqld --verbose --help |grep -A 1 \'Default options\'察看读取的配置文件。\\n\\n本地无法连接，先改配置skip-grant-tables并重启，update mysql.user  set authentication_string=password(\'newpasswd\') where user=\'root\'更新密码。事后发现是密码置空所以登陆不进。\\n\\n远程无法连接，可能是限制了root的来源，use mysql; select host from user;看是否为localhost，并改为%。改完如果不想重启mysql，执行 flush privileges;相当于刷新权限表。\\n\\n## nginx\\n\\n命令行参数很简洁，修改配置后用-t验证，重启用-s，而启动前可以用-p, -c, -g指定预加载路径、配置名称和额外的全局变量。\\n\\n重定位原理，如果是root配合index指令，浏览器的请求一定要以/结尾，这样才能配合index指令找到文件。可以理解为访问站页，用的就是`/`路径，返回index.html。\\n\\n`location ~* /js/.*/\\\\.js`\\n\\n* 以 = 开头，表示精确匹配；如只匹配根目录结尾的请求，后面不能带任何字符串。\\n* 以^~ 开头，表示uri以某个常规字符串开头，不是正则匹配\\n* 以~ 开头，表示区分大小写的正则匹配;\\n* 以~* 开头，表示不区分大小写的正则匹配\\n* 以/ 开头，通用匹配, 如果没有其它匹配,任何请求都会匹配到\\n\\nlocation和proxy_pass配合有个奇怪的特性，路径如果最后带/与否对结果影响很大，比如location /openeco，请求/openeco/user的话，转发后会剥掉匹配部分，实体只会收到/user请求，而location /openeco/，转发就会收到完整的/openeco/user。\\n\\n再举个例子，想达到访问首页跳转到某个子文件夹，利用rewrite指令，这条指令的格式是这样\\n\\n* rewrite  capture-regex  dst-path  flag;  flag可选，但我试了不填效果不确定，建议填上\\n\\n对flag的选择不同会有少许区别。一种是用redirect或permanent返回给浏览器新地址，由浏览器重新请求，另一种用last或break由nginx在内部完成地址重写。前者适合网站域名迁移，通过HTTP 301/302通知搜索引擎进行域名更新。如果只是网站内的地址重写，最好还是用last或break。要理解这两者的区别，要明白地址重写后，并不会立刻进入下一阶段，而是把重写后的地址，作为源，继续匹配别的location，直到没有可以匹配的时候，才进入下一阶段。break的作用，就是提前终止并立刻进入下一阶段，而last会继续匹配location。感觉last这个叫法不够直观。\\n\\n如果是首页重定向，匹配式必须写成`^/$`，完整匹配根路径，这样下次重新匹配时才不会又匹配上。\\n\\n访问限制\\n\\n使用allow和deny指令，要注意的是如果只想限制某些IP可以访问，用allow列举了所有可以访问的IP后，要加一句deny all;才行。另外deny all;和allow all;都加上的话，生效的还是deny。"}'));jctx.push(JSON.parse('{"id": "190413", "tag": "web", "text": "# 网站性能测试\\n\\n14年5月我用PHP做了个公司网页，查询协议文档。今天用ab测了性能简直掉了下巴。\\n\\nlinux配置4核4G，Xeon E5-2680v3 2.5G。windows配置4核4G，i5-6500 3.2G。\\n\\n* 首页\\n\\n| 命令 | linux-qps | windows-qps |\\n| ---- | ---- | ---- |\\n|ab -n500 -c5 | 1340 | 194 |\\n|ab -n500 -c1 | 381 | 111 |\\n\\n* 单表查询一条关键字\\n\\n| 命令 | linux-qps | windows-qps |\\n| ---- | ---- | ---- |\\n|ab -n500 -c5| 802 | 69 |\\n|ab -n500 -c1| 155 | 46 |\\n\\n* 多表查询一条关键字\\n\\n| 命令 | linux-qps | windows-qps |\\n| ---- | ---- | ---- |\\n|ab -n500 -c5| 117 | 15 |\\n|ab -n500 -c1| 31 | 14 |\\n\\n从上表数据看，先不谈语言或OS，讨论qps如果不说并发数是不严谨的。不过即使再上量，对这台linux的极限无法超过1500。"}'));jctx.push(JSON.parse('{"id": "190420", "tag": "web", "text": "# 浏览器的网络请求发展史\\n\\n偶然间推论出的历史脉络\\n\\nHTTP0.9版只有GET，加上当时浏览器最初的定位就是互相看文档，初代只是个能在地址栏发起GET的图形程序。\\n\\n慢慢地应用开始丰富起来，估计和CGI同时代，要从浏览器提交数据到后台，于是出现了form表单。这时表单传输数据的格式和GET一样，后来者总会借鉴前面的标准。随着上传文件功能被纳入标准，表单加入了multipart格式，具有独立的特性，至少从数据支撑来说，已经是完整了。\\n\\n但表单数据会导致整页刷新，并不适用所有场合，微软开发了XHR的前身，各厂商发现这是个好东西，标准化之后有人整出了AJAX概念。到这时既然可以更新数据无跳转，那就干脆更进一步，整个应用都驻留在一个页面，SPA和前后端分离的理念才发扬光大。\\n\\n网络层面的问题解决了，但响应数据如何与视图层绑定仍是大问题，直接操作DOM便产生了jq这样的面条代码，于是三大框架响应人心，不约而同地实现了双向绑定。\\n\\n后人看来很自然的开发方式，其实是由多个独立的节点渐渐地串起来。"}'));jctx.push(JSON.parse('{"id": "190429", "tag": "os", "text": "# 网络文件系统机制\\n\\n几种常见的NAS协议，FTP无法挂载到路径，AFS只有Apple用，几乎遇不到，只有Samba(smb又叫CIFS)和nfs方式好用\\n\\n## Samba\\n\\n有1和2两个版本，在win10上比较方便，但win7怎么都试不出来。win10要用smb版本2，需要注意。\\n命令是sudo mount -t cifs -o username=\\"administrator\\",password=\\"1\\" //winip/code/ /mnt/win -o vers=2.0\\n\\n如果linux当服务端，要用`smbpasswd`另外设置密码才能访问。\\n\\n## nfs\\n\\n有1~4版本，前3个版本是Sun设计，4是IETF主导，机制上改动很大。目前多见的是3和4版本，v3监听UDP的111端口，但真正RPC通信端口是后续协商出来的，而v4则只监听TCP/UDP的2049，配置防火墙更简单。\\n\\nwindow作为服务端，linux作客户端时，高版本windows带了v4版本，或者用第三方hane nfs server开启服务，配置 `D:\\\\code -public`就可以共享指定目录了。linux端下载nfs-utils。用 showmount -e ip 查看开放的共享目录，用 sudo mount -t nfs ip:/d/code /mnt/win 就可以挂载目录了。默认用UDP可能不太稳定，可以在mount加上 -o proto=tcp -o nolock。如果用v4版，mount命令改为-t nfs4。\\n\\n如果linux作服务端，步骤稍多一些，必须root身份\\n\\n1. 安装nfs-utils和rpcbind（也叫portmap）\\n2. 编辑/etc/exports文件，执行`exportfs -rv`，启用nfs目录共享\\n3. 启动rpcbind，也叫portmapper服务，在cent上的包叫rpcbind\\n4. 启动rpc.mountd和rpc.nfsd服务\\n\\nv3和v4版本都要用 exportfs 命令设置 NFS 导出目录。exportfs 有两种操作模式：\\n\\n1. 读取 /etc/exports 以及 /etc/exports.d/\\\\*\\n2. 从命令行参数获得导出目录设置\\n\\n两种模式下，exportfs 都会通过 /proc/net/rpc/nfsd.export/channel 往 Linux 内核写一份（很像 Plan 9），并且更新 /var/lib/nfs/etab 文件。\\n\\nnfs采用了 C/S 架构，但是NFS的Client/Server只负责和文件系统交互，而不提供任何 TCP/IP 数据传输功能，需要配合RPC服务器才能实现数据传输（其实也好理解，Sun利用RPC开发了很多服务，NFS只是其中的一个应用，从分层角度看，自然不会包含网络协议）。因此nfs的v3版共有4个服务才能完成完整的功能\\n\\n1. rpcbind服务(portmapper)，监听111端口，有点像 DNS server，它把 PROGRAM ID 翻译成服务真正的 IP 和 PORT(不知道 IP 是否可以是其它机器），每个 RPC service 启动时都要向  注册自己的 PROGRAM ID。可以用rpcinfo -p ip来查看注册了哪些服务。注意这个命令是查注册命令，不一定运行，所以netstat可能看不到这些端口\\n2. rpc.mountd服务，监听20048端口，应该是负责文件系统交互的服务\\n3. rpc.statd服务，有IN和OUT端口要监听\\n4. rpc.nfsd服务，监听2049端口，如果没启动，客户端在mount时会提示RPC程序未注册\\n\\nv4版简化了上述流程，只需要nfsd监听2049就可以了，简化了防火墙的配置难度，但需要额外向/proc/fs/写内容。"}'));jctx.push(JSON.parse('{"id": "190501", "tag": "os", "text": "# Linux的软件包管理软件说明\\n\\n不同发行版有独特的包管理软件，分为打包软件和包管理两块，相对来说打包软件定义包的格式，而包管理要解决的问题要复杂得多。\\n\\n1. 添加软件时，要记录所有依赖的库和执行程序，且依赖项的引用计数要加1\\n2. 删除库时，所有依赖这个库的执行程序都要连带删除\\n3. 删除执行程序时，对其依赖的库的引用计数要减1，如果减到0了，要提醒用户，但并不删除，比如apt autoremove就是用于删除引用计数为0的库和执行程序\\n4. 更新软件时，对依赖项有变动的，要更新引用计数，并按上面提到的策略给用户以提示\\n5. 列举已安装软件时，apt做得很清晰。如果是被连带安装，会标注automatic，如果引用计数到0了，会提示auto-removable。对被连带安装的软件，如果手动安装一次，其auto标记会被清除，以后就不再提示auto-removable了。\\n\\n## CentOS\\n\\n可以更新系统内核版本。\\n\\n* yum clean all\\n* yum update\\n\\n时间取决于和最新版本的差距，我从7.3到7.6约用了10分钟。为了让新安装的内核成为默认启动选项，你需要如下修改 GRUB 配置,打开并编辑 /etc/default/grub 并设置 GRUB_DEFAULT=0.意思是 GRUB 初始化页面的第一个内核将作为默认内核。不过这条我没用到。\\n\\n升级后不同版本会遗留很多的垃圾，要清理。先找出冗余内核\\n\\nrpm -qa | grep kernel\\n\\n对不是当前在用的，复制名字并删除。\\n\\nyum remove xxx  yyy\\n\\nyum不会升级内核版本，elrepo.org 专门负责有内核升级需求的人。命令如下\\n\\n* rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org\\n* rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm  //适当调整\\n\\n仓库启用后，你可以使用下面的命令列出可用的系统内核相关包:\\n* yum --disablerepo=\\"*\\" --enablerepo=\\"elrepo-kernel\\" list available\\n\\n接下来，安装最新的主线稳定内核:\\n* yum --enablerepo=elrepo-kernel install kernel-ml\\n\\n外番：rpm的命令围绕-q, -i, -e展开，选项不能随意搭配，但顺序随意。有些只用于-q查询，有些只用于-i安装。奇怪的是-R只在man能看到，帮助没有显示。\\n\\n## AlpineLinux\\n\\n首先编辑/etc/apk/repository，到你想要的版本号，执行\\n\\n* apk update   ; 更新repo的index\\n* apk upgrade  ; 更新程序实体\\n* sync;reboot  ; 保证落盘重启生效\\n\\n## Debian\\n\\n版本7(wheezy)以前是apt-get和apt-cache分离，版本8(jessie)增加了统一入口apt。apt-get负责下载软件和仓库索引，而apt-cache是查询，初始干净的版本是没有仓库索引的，这时用apt-cache搜索没有结果，是正常现象，apt-get update后就能正常使用了。\\n\\n## Gentoo\\n\\n衍生自BSD系的portage，全部由python/bash构成。和其它二进制方式管理包不同，仓库同保存的各种软件的元信息，以目录形式保存描述，倾向于源码编译。\\n\\n所有的命令都以e开头，核心命令是emerge，支持5种安装格式。意寓把某个软件合并到portage树，最常用的world是一个set的别名。另外还有ebuild，emaint等。\\n\\n由于从源码编译，有几个很独特的概念\\n\\n* USE: 类似编译开关，选择是否取消某些连带项，而arch就做不到，只能取决于维护者的个人喜好\\n* mask: 对包做的标记，如果前提不满足，无法安装\\n* EAPI: ebuild的格式版本，隔一段时间会更新，如果达不到上游的要求不能安装软件\\n\\n## Arch\\n\\npacman的命令风格格式全部以`-[DQRSU]`开头，接下来是选项，如果是单字选项可以直接跟在命令后面。比如-Qv命令显示同步源和所有已安装的包，比如我的版本有5个文件，大小从4K到5M不等，每个文件是gz压缩的纯文本。所有已安装的包也以独立目录的形式存在，每个包的描述、文件详情都能很方便得看到。\\n\\npacman的包没有.deb或.rpm这样特殊的后缀，而是很朴实地用了.tar.xz名（也可以配置为.tar.gz）。包的内容通常是建立在/usr目录下的各个文件，还有.BUILDINFO, .MTREE, .PKGINFO三个元数据文件。制作包也很朴实，写好PKGBUILD文件，再用makepkg就能打包。\\n\\n### pacman在其它发行版上的尝试\\n\\n起因是装了Gentoo但是磁盘空间不够，第一步emerg-webrsync就失败了，无法下载软件的系统是没有意义，于是想既然Linux的内核一致，能否从别的发行版移植包管理器来用。\\n\\n最流行的当然是apt，但这几天刚好在用ArchLinux的pacman，而且从不足2小时的了解来看，pacman非常简明，且源码只有3M，感觉比较容易，这是我第一次尝试编译包管理系统。pacman依赖并不多，在这个2015年左右的Gentoo上，只缺少libarchive的3.0版本，另外bash版本稍低，最终决定编译pacman的5.1.3。(5.2版本要求bash版本4.4以上)。遇到`clock_gettime`函数不存在，好在代码里用宏给了另一种实现，把相关3行代码换一下手动编译过。配置通过/etc/pacman.conf就够了，可以配置repo位置、arch、哪些包不更新、使用curl/wget下载等。\\n\\npacman的思路，所有的软件信息保存在本地的sync和local两个目录，sync是全部软件的索引，local是已安装的软件。-S操作sync，-Q操作local。所以搜索也区分全部搜索的-Ss和本地搜索的-Qs。一旦理解其设计思路，命令就能说通了。\\n\\n安装和配置完成后，先尝试安装locate包(几乎没有依赖)，然后提示需要更新filesystem、glibc、tzdata等若干个包，但是下载后又提示glibc:  exists in filesystem并拒绝安装。我猜原因是这些包不在pacman的记录中，且对应位置已经有文件，为防止潜在的冲突，就停止安装。加了--overwrite \\\\*选项后大部分错误都屏蔽了(这个选项正常情况下尽量避免)，只有filesystem提示一些目录无法覆盖。于是我尝试把另一个版本DB Path下local目录的filesystem内容复制过来，果然骗过了pacman更新了glibc等库并装上了locate。但是悲剧的是执行ls会提示glibc相关的错误，而且ssh也连接不上。\\n\\n分析挂掉的原因，对每个发行版来说，最根本的rootfs一定包含基础工具(哪怕是busybox)和libc，而我只更新libc却瞒过filesystem，导致两者不能配套，最终使得整个系统挂掉。可以至少对pacman来说，由于它管理了rootfs，当安装到其它发行版时，会出现不配套问题。\\n\\nArch没有固定版本(但是filesystem的日期勉强可以算版本)，因此不可能有锚定的rootfs，基础库和工具一定是不停更新的，这也是和debian/cent系最大的区别。"}'));jctx.push(JSON.parse('{"id": "190504", "tag": "web", "text": "# 博客网站功能扩展记录\\n\\n## 调试\\n\\n一直以来对Web开发调试都没有好的办法，知道了`error_log`函数可以记日志。记录的文件名通过php.ini来设置`error_log = php_errors.log`\\n\\n这种相对路径的方式把日志保存到index.php同一个目录下。除了写文件还支持发邮件等格式，对网管来说很实用。如果是php-fpm还支持slowlog，在php-fpm.conf加上\\n\\n```\\nrequest_slowlog_timeout = 5s\\nslowlog = /var/log/php-fpm-slowlog.log\\nrequest_terminate_timeout = 10s\\n```\\n\\n## 账号切换\\n\\n账号就是对session和cookie的控制，通过增加切换账号的页面，让同一个cookie在不同时间段对应不同的session。原有的auth机制没有做成通用，最初的修改甚至直接导致鉴权之后回到主页，而主页又鉴权的死循环。cookie保存的是PHP计算的哈希值，持久化的session文件记录的是数据库名，并不会记录密码，不过目前版本还没有做切换账号时的密码加密，也没有做cookie防劫持。\\n\\n账号切换按钮做了个简单的隐藏，只有登陆过或者芝麻开门方式才会显现出来，不算很高明。\\n\\n随着多账号的实现，以文件方式缓存首页也调整为数据库方式，却因SQL语句少了右括号浪费了半个小时才看错误，PDO错误通过errorInfo方式返回数组，错误码由ANSI定义。另一个缺陷是原来以文件方式保存，用include导入即完成代码到变量执行，换成数据库后要显示执行eval，无法避免失败的情况，需要继续想办法。\\n\\n将鉴权函数从全局函数修改为类的static函数，好处就是可以利用类的自动加载机制，省去了显式加载auth文件的步骤，另外将密码映射表移到类内部，减少暴露的数据。\\n\\n## 单页化\\n\\n在安卓上写程序久了，渐渐萌生了把博客网站也做成前后分离，不再依赖后台模板的想法。\\n\\n改为SPA后，有以下几个点很不同\\n\\n1. 首页会变大。因为用后台模板时，需要切换页面时才会请求，并进入新的页面。而用SPA方式只有数据流，所有的布局在一开始就已全部加载到浏览器上，如果页面很多，首页加载速度多少会有点影响。\\n2. css样式写法变化。原来多个页面时，每个页面对应的css是直接写body、p的样式，显然要合并成一个，并用都按类的方式重写。\\n3. 所有的表单请求，换成用ajax并将内容绑定到DOM\\n4. 生成DOM树的元素，手写`<br/>`，真正到了浏览器却变成了`<br>`，难怪都说前端坑多。\\n\\n分离后JS得到的都是JSON数据，除了把静态内容渲染到DOM，还有一块就是要构造带有交互功能的按钮。\\n\\n## 支持标签\\n\\n首先数据库要支持增加列，使用`alter table blog add column tag text default \'\';`语句增加一列。\\n\\n由于数据从一列变为两列，返回到页面的格式就不能再用字符串，比如用json。在PHP侧把array用`json_encode`转换输出，虽然是json但网络传输的还是字符串，所以js得到的数据不能按json操作，好像版本3的时候还没有纳入规范，直到版本5才正式成为规范。有个通用的技巧直接用eval(string)就可以转成对象，还有种说法是用eval(\'(\'+str+\')\')格式，似乎前面简单的做法就够了，不清楚两者的差异。\\n\\n总的来看多个数据在浏览器和服务器之间的交互格式是不同的，请求要按照URL规范，因为也只有这个规范，加上PHP天然就很好地支持这种格式，所以是最佳选择，回复因为是给js解析，所以用json无疑就是最好的格式。\\n\\n还有个问题，在赋值时究竟用innerText/innerHTML/value的哪一种？\\n\\n1. innerText是id为object的闭合标签内的文本,输入输出的是转义文本(字符串);(label控件用innerText有效)\\n2. innerHtml是`<div>`标签内的文本,输入输出到该DOM内部纯HTML代码(流);(获得td、div等html元素时候,它们是没有value或是text属性,只能用innerHtml)\\n3. value是表单元素特有的属性,输入输出的是转义文本(字符串);(Button、CheckBox、Radio)随表单一起发送的值;(Reset、Submit)标签;(Text、Hidden)默认值;(File、Password)(注: Text控件用value有效)\\n\\n其实对textarea标签，也就是多行文本编辑框，innerHTML和value还有更大的区别\\n\\n1. innerHTML 仅在 textarea 初始化的时候对 value 有影响，value 的内容就是从 innerHTML 来的；除此之外，innerHTML 和 value 没有任何关系，修改 value 不影响 innerHTML，修改innerHTML 不影响 value；\\n2. 界面上呈现的永远是 value 的值，而不是 innerHTML，比如通过代码修改 innerHTML 之后，界面上 textarea 里面的内容还是 value 的值；\\n获取文本框的内容，自始至终都应该读取 value；\\n3. value 获取的是原始内容，innerHTML 获取的内容会自动将 `<` 和 `>` 这2个符号转义；\\n4. 初始化 textarea 的内容只能写在 `<textarea>` 和 `</textarea>` 的中间，不能像 input 那样写在 value 属性上面；\\n\\n所以 value 一般用于一些表单元素的获取值，input，select 等，textarea 也算表单元素，而 innerHTML 用于 div, span, td 等其他元素。总之切记 表单元素别用 innerHTML！\\n\\n## 回归静态与CGI by23.01\\n\\n因为外网穿透失灵兼PHP程序不知为何不能用，从22年10月断断续续改了多次，开始用sdf提供的web服务，做成用lua动态渲染markdown，但访问速度实在太慢。后来知道了frp还是决定用回自己的主机，但免费的frp偶尔会断，加上lua渲染不支持表格，干脆用python预生成HTML回归纯静态展示，还能部署到github page，对主机没有要求。动态部分只保留CGI编辑，支持电脑和手机端多端同步。\\n\\n## 纯静态且支持搜索 by24.05\\n\\n最近玩客云硬件不能用，迁移的手机功能非常受限，编辑后的文件上传sdf非常痛苦。又怀念起全静态部署的好处来。加上以前曾开发过mytid但过于忧虑流量没有用起来。\\n\\n前提和假设\\n\\n1. 公开的博客，纯静态html部署（不一定是单文件）\\n2. 私有的笔记，基于数据库的CGI接口，通过电脑或手机编辑\\n3. 依赖尽可能少\\n\\n实现路径\\n\\n1. 博客内容基于md维护，通过mytid脚本转html，同步到公开的代码仓库\\n2. 闪念笔记，保存在1个数据库，通过电脑或CGI编辑\\n3. 静态服务： frp+busybox 尽可能低门槛；CGI：pb 只要有编译器，依赖也比较少；生产端： python3+markdown\\n\\n### 尝试algernon\\n\\n动态化是绕不过去的功能，而我又很想要易部署。[[使用algernon开发web]]便捷程度不输busybox，既如此不妨一试。\\n\\n## https建站 by24.06\\n\\n申请https证书还算简单，证书授权方会要求在域名服务商处配置一个指定的CNAME，证明你拥有该域名。过几分钟就能下载压缩包，里面除了公私钥pem文件，还有一个chain.pem，似乎没用先不管了。除证书外，frp隧道也要重新创建https类型才算是全链路打通。\\n"}'));jctx.push(JSON.parse('{"id": "190506", "tag": "security", "text": "# 对称加密实践\\n\\n所有对称加密的核心是XOR运算，因为XOR运算有一个非常神奇的特性A\\\\*B\\\\*B=A。也就是说A与B进行XOR运算之后的结果再和B运算就能复原A。A是明文，B是密钥，就是所有对称加密的基础。主流的AES采用块式加密，每次固定加密128位，密钥不能短于块长度（奇怪的是DES的密钥比块要短），当原文比块要长时，显然要迭代进行，如何迭代就分化出ECB，CBC，GCM等众多模式，而AES我的理解是如何把加密块和密钥进行XOR的方式，两者的阶段不同，所以合称AES-GCM。\\n\\n## AES填充\\n\\n* PKCS5 : java原生和PHP的默认行为\\n* PKCS7 : java需要导入bouncy包，PHP的`OPENSSL_RAW_DATA`\\n\\n这两种按文档说明是没有差别的，实测下来不同的pad的输出大部分一样，但有差异。而且解密时如果选错pad会解密失败。\\n\\n## AEAD\\n\\n全称Authenticated Encryption with Associated Data。是一种同时具备保密性，完整性和可认证性的加密形式。\\n\\nAEAD 产生的原因很简单，单纯的对称加密算法，其解密步骤是无法确认密钥是否正确的。也就是说，加密后的数据可以用任何密钥执行解密运算，得到一组疑似原始数据，而不知道密钥是否是正确的，也不知道解密出来的原始数据是否正确。因此，需要在单纯的加密算法之上，加上一层验证手段，来确认解密步骤是否正确。\\n\\nAEAD的实现方式可以是单纯的CBC和SHA1组合而成，也可以是AES-GCM，AES-CCM，chacha20-poly1305（chacha对称加密，poly是MAC验证）等直接完成。TLS1.2引入AEAD后，1.3就只允许这种算法了，可见安全界的认可。\\n\\nGCM本质上是AES的CTR模式加上GMAC（又叫GHASH）进行哈希计算的一种组合模式。GCM来自于AES的CTR模式，CTR是指计数器模式。GCM是利用GMAC（基于伽罗华域的MAC）和AES的CTR模式的组合。GMAC比普通的MAC算法快（毕竟冠以伽罗华之名），GCM模式与CBC的一个最大的区别是GCM模式不再把上一个数据块的计算结果输入到下一个数据块的计算，而是在分好的数据块中任意位置开始计算，由一个计数器和一个不变的IV值（nounce）来控制每一次计算的随机性。由于下一次的计算并不依赖于上一次的结果，所以GCM模式可以实现大规模的并行化，并且Intel还专门推出了clmul指令用于加速GCM的运算速度，可见其应用之广。纯软实现的chacha比aes有4倍的优势，但随着硬件指令加持AES-GCM有一统天下的趋势，也确定了AEAD的演进方向。\\n\\nGCM是一种加密范式，不是一种特定的加密算法，在AES中可以应用GCM范式，在Camellia中也可以。除了这种范式外，CCM是另一种广泛应用在Wi-Fi上的范式。"}'));jctx.push(JSON.parse('{"id": "190520", "tag": "net", "text": "# 域名和DNS的事\\n\\n自从2016年5月注册免费的DDNS域名，一直用却从未深究过其中原理。网上提供免费域名的服务商不少，几个知名的直接在路由器内嵌支持，如果不支持，通常服务商会提供客户端程序和DDNS服务器通信来达到解析效果，客户端有些从C语言编译，有些就是一行脚本。如果有一台低功率主机，也方便。\\n\\n以公云3322.org为例，不充钱的账号只能开通一个账号。而且登陆管理员的账号密码和域名保活的密码并不相同，一定要分开。\\n\\n域名的完整名称是Fully Qualified Domain Name,(FQDN)，由hostname+domain name组合而成。域名服务器并不限制FQDN，有些局域网只输入hostname也能找到服务器，这个hostname又称Partially qualified domain name。域名只能包含数字，字母和连字符(减号)。域名有顶级域名和壳域名，顶级域名有组织管理，个人要用必须要购买，而免费域名一定是壳域名，通常是公司买下顶级域名，并开放了其二级域名吸引用户去用，所以才会免费。如果有域名和静态IP，可以用dnspod.cn配置绑定。\\n\\nDNS是1985年出现的，在那之前ARPANET就有了host.txt方式记录IP和名字的对应关系，随着主机数量日渐增多，文本方式成为辅助，但仍在操作系统中存在。\\n\\n## 域名解析\\n\\n查域名函数是gethostbyname，无论是宿主机或是k8s集群，DNS解析会依赖 /etc/host.conf 、 /etc/hosts 和 /etc/resolv.conf 这三个文件，查询顺序通过/etc/nsswtich.conf控制，由solaris发明，被linux继承，以libnss库的形式存在。简单讲解一下/etc/resolv.conf配置，每行都会以一个关键字开头，然后跟配置参数。在k8s集群中主要用到的关键词有3个。\\n\\n* nameserver   #定义 DNS 服务器的 IP 地址\\n* search       #定义域名的搜索列表，当查询的域名中包含的 . 的数量少于 options.ndots 的值时，会依次匹配列表中的每个值\\n* options      #定义域名查找时的配置信息\\n\\n## DNS记录\\n\\n称为Resource Record(RR)，有如下几种类型\\n\\n* NS记录：Name Server，表示这个域名由谁来解析，通常买域名的厂商就是NS，当然也可以改成dnspod或cloudflare之类。\\n* A记录： 域名到IP的映射关系，A表示Address。如果要映射到IPv6，称为AAAA记录\\n* CNAME： 域名到域名的映射\\n* MX记录：邮件交换记录，邮件服务器会用到\\n* PTR：和A记录相反，从IP获取域名\\n\\nDNS是一棵庞大无比的树，具体实现时某一段子树往往归为一个DNS Zone。\\n\\n一个域名可以对应多条A记录，使用场景一是IP的负载均衡，二是不同运营商间智能匹配最佳线路。不过DNS不会检测IP存活，需要额外的检测和更新机制配合。\\n\\n## CNAME绑定\\n\\n比如阿里云的域名指定了CNAME到3322，就行了。但想转到github pages却不能成功，必须在pages的repo增加CNAME文件，里面写上阿里云的域名，才能实现域名跳转。\\n\\n上述虽然要双向配置，但毕竟能在浏览器直接打开。而冰雪提供的绑定CNAME只能用于绑定，直接打开显示的永远是同一个首页。可能是虚机的缘故，靠入口域名做映射，这种情况显然单向绑定是不够的。\\n\\n## WHOIS和IANA\\n\\n通过whois可以查到域名在哪个分销商注册的。全球的域名分销商都会向IANA机构注册，并被分配一个IANA数字编号，见过292-1479范围的。每个分销商通常会有多个域名解析服务器地址，数量在2-8个不等。\\n\\nWHOIS只能查到一级分销商，看不到个人或企业的详细信息。"}'));jctx.push(JSON.parse('{"id": "190524", "tag": "tool", "text": "# 远程文件传输说明\\n\\n由于安全性的关系，很多新系统默认不提供FTP功能，要交互文件就需要别的方式，好在SSH整合了SFTP子系统。不用额外启动守护，只要`sshd_config`配置中增加一项`Subsystem  sftp  /bin/sftp-server`，就能使用了。要注意的是，有些发行版把sshd和sftp分成两个包，如果出现校验密码成功但连接被断开的错误，很可能要单独安装sftp。\\n\\nsftp利用SSH加密通道进行文件传输，它借用了FTP的指令，但基础是SSH加密，严格地说并不算FTP协议。\\n\\n另一种叫FTPS，类似HTTPS，本质是FTP over TLS的方式，使用的指令和FTP完全相同，不过支持的软件（服务端和客户端）都比较少。\\n\\n除了FTP模式，用scp传输文件更通用，出现过winscp用FTP和SFTP始终无法连接上，但用scp模式成功的情况。scp本身不常驻后台，监听的还是sshd，但是当外部连接到来后，sshd会调用scp完成文件传输，所以当SFTP不可用但ssh可以连上时，不妨用scp来传文件。\\n\\nscp和ssh同属一个包，但scp是基于rcp程序改写的，因此选项风格很不一样。比如指定远程端口，ssh是-p而scp是-P(大小写是反的)。指定远程用户，ssh用-l，而scp却是username@hostname:fileposition这种格式。另外scp不仅要求本机有scp，对端也必须有scp才能完成传输，否则在验证结束后，会报`sh: scp: not found`错误，之后连接就断开了(lost connection)。\\n\\n如果没有装scp，winscp可以浏览文件夹但不能复制，说明scp没有浏览命令，必须和ssh配合使用，从复制文件的角度看，scp更纯粹，当然功能也更弱，不支持断点续传。而sftp是完整的文件传输方案。有独立的浏览命令，支持断点续传。openssh实现的scp，从8.8版本开始，默认使用sftp协议，但是如果服务端不支持，也可以用`scp -O`回退到scp协议复制文件。\\n\\n如果连scp也没有，rsync -e \\"ssh -l user\\"能达到相同效果(未验证)。\\n\\n## rsync使用说明\\n\\n作为远程同步工具，支持ssh和rsync两种协议，如果是rsync协议，客户端使用`rsync -av ip::archive/img/ img`，值得一说的是`::archive`这段，::表示使用rsync协议，archive则指代服务端的一个module，可以用`rsync ip::`查看远端所有的module列表，如果有module，使用`rsync ip::modname`查看，并可递归查看mod下的文件夹。服务端先配置好/etc/rsyncd.conf后，再rsync --daemon会监听873端口。配置rsyncd.conf的module时，除了path外，如果遇到无权限问题，再加上uid=0和gid=0就可以解决。\\n\\n如果对端机器不是默认22端口的话，同步时候要加上 -e \\"ssh -p port\\"，rsync -avzP -s \\"ssh -p 22\\" /tmp/ itv@ip:/home/itv/"}'));jctx.push(JSON.parse('{"id": "190526", "tag": "protocol", "text": "# HTTP的认证方式\\n\\nHTTP初衷是定义为无状态协议，但随着使用日渐广泛，认证也纳入了RFC7235的定义。客户端如果请求一个不被允许的资源，服务端返回401或407，消息头带上WWW-Authenticate，并告知认证算法和域信息。客户端再根据这些信息，计算出一个签名，填到Authorization字段，后面用一个词表示认证算法，申请新的算法要向IANA提交申请并经IETF审核，已入标准的有Basic、Digest、Bearer、HOBA约10种。也可以是私有扩展，后面必须有一个空格，然后是签名值。如此这样交互下来，服务器才会认可这次访问是合法的。\\n\\n示例\\n\\nServer\\n\\n```\\nWWW-Authenticate: Basic Realm=XYZ\\n```\\n\\nClient\\n\\n```\\nAuthorization: Basic ABC=\\n```\\n\\n上述是服务端对客户端要求的单向认证，另外还有RFC8121双向认证，使用了离散对数或椭圆曲线算法的Key Agreement Mechanism 3机制。\\n\\n为解决SSO问题，HTTP扩展了 Negotiation 认证，也叫SPNEGO(Simple and Protected GSSAPI Negotiation Mechanism)。 Windows 支持两种 Negotiation认证方案：NTLM和Kerberos。Linux上的实现一般不支持NTLM，只支持Kerberos。\\n\\n## OAuth流程\\n\\n每个带统计或权限的应用系统，肯定会希望有用户体系，但现实是用户往往不愿意注册，这种场景下，就要依赖向另一个管理帐号的系统(简称U)请求认证，并依赖U的校验结果去鉴定用户。\\n\\n要解决的第一个问题，不能触碰用户输入密码的环节，所以U一定要提供一个完全的登陆框，但这就安全固然解决，可是登陆后要去干什么呢？所以这个登陆页的参数一定要有个callback，如果登陆成功，把cb的值用302方式回复浏览器，这时还要带一个code，表示登陆成功，这个code在一段时间内，就可以证明，用户在U系统上是存在的。\\n\\n到此，用户是否存在(真实性)的问题就解决了，如果还想知道到用户是谁，要做进一步动作。用code再一次向U的网页发起请求，用户在页面上选同意的话，返回token，最终用token去请求资源，也只有token换资源这一步，不会弹出网页。"}'));jctx.push(JSON.parse('{"id": "190528", "tag": "lang", "text": "# 批处理的用法\\n\\n## 语法篇\\n\\n### 条件判断\\n\\n字符串比较，一定要两侧加双引号。\\n\\n```\\nif \\"%1\\" == \\"\\" (\\n  command\\n) else if %1 equ 5 (\\n  command\\n)\\n```\\n\\n批处理似乎没有参数个数`$#`语法，可以用`\\"%*\\" == \\"\\"`区分没有参数的情况，但无法判断更复杂的场景\\n\\n变量捕获\\n\\n网上说通过重定向到文件再`set /P a=<xx` 方式读取回来，一则看上去不优雅，更麻烦的是前一步写入的文件在此时经常会读不到，原因不明。最好的方式还是用`for /f`语句。\\n\\n```\\nfor /f \\"delims=#\\" %%A in (\'your commad %*\') do (\\n  set VAR=%%A\\n)\\n```\\n\\n只有for的/f选项才能在SET中执行命令，否则只会当作字面量或文件名来解析，其次command要用单引号包围，其中的%参数会正常解析，最后变量一定要写两个%（只有在cmd直接输入允许一个%）。/f后面的选项可以为空，默认会按空格会Tab对内容进行切分，如果希望不切分，找一个不会在内容中出现的字符作为切分键，但无法用\\\\n，因为会被识别为\\\\和n两个字符。另外for语句支持嵌套。整个语句看下来，将输出先按行切分，再进行行内切分，值赋给一个变量，接下来用这个变量，用法有一点像awk的getline函数，甚至连选项名f都和awk一样。\\n\\n### 函数用法\\n\\n```\\ncall :add1 1 ret\\necho %ret%\\ngoto :eof\\n\\n:add1\\nset /a ret = %~1 + 1\\nset \\"%~2=%ret%\\"\\ngoto :eof\\n```\\n\\n用标签来模拟函数，但毕竟算不上函数，所以在第一个函数定义前，用goto方式结束。这也说明批处理是先编译再执行。\\n\\n这种看起来古怪的语法，原因是批处理只能按规定执行(顺序或跳转)，不具备全局哈希表，无法把一个块从执行流中摘出来。所以一定要把所有函数定义放在最后，主执行流程写在开头。\\n\\n这种做法能行得通，多亏批处理有call机制，函数执行完，能接着上一句call继续走下去。\\n\\n从中可以得知，函数最朴素的实现，便是开始标记、结束标记、执行后的返回地址。和汇编指令没有区别。\\n\\n从命令行交互使用set /p var=[prompt]方式，之后用%var%就能得到用户输入。\\n\\n### 特殊命令\\n\\n* cd /d xx: 如果不带/d，切换路径不能换盘\\n* start: 类似fork，会新开窗口，不阻塞当前脚本继续执行。也可以用/wait选项等待\\n* exit /b: 退出函数，但不关闭cmd窗口\\n\\n### 误区\\n\\n* echo后面的双引号和单引号，也会被输出，所以不要写\\n* sed对中文处理有异常，但也可能是sed版本原因\\n* 批处理内调另一个批处理命令，必须用call，不能直接调\\n\\n### 嵌入其它脚本\\n\\n通用法\\n\\n1. @more +1 %~f0 | script_engine & exit /b   # 一行代码，利用more打印第2行以后内容，缺点是不能传参，但可以交互式\\n\\n适用于python\\n\\n1. @SETLOCAL ENABLEDELAYEDEXPANSION & python -x \\"%~f0\\" %*  # 利用了-x选项来跳过第1行，如果语言支持同样功能也可以。甚至我感觉前面的SETLOCAL都没用\\n1. 不是一行式，且比较难懂，由于这段代码同时符合bat和py，技巧上很高明，但实用价值没有上一条高\\n\\n```\\n1>2# : ^\\n\'\'\'\\n@echo off\\npython \\"%~f0\\" %*\\nexit /b\\nrem ^\\n\'\'\'\\nimport os\\nimport sys\\n1. python code to compute the time elapsed\\nprint(sys.argv)\\n```\\n\\n## 用法示例\\n\\nruby的gem.bat写成这样 `ruby.bat \\"%~dpn0\\" %*`\\n\\n%在windows批处理中相当于shell中的$表示变量，\\\\~是必要的前缀否则会把后面的dpn当成变量名，有了\\\\~以后dpn就可以各自表示对应的意思。有一系列的修饰符，d表示盘符，p表示路径，n表示文件名，x表示扩展名，详细文档可以用for /?看到。还原到上面这个例子%~dp指向gem所在的路径，n就对应了gem(没有扩展名，也不需要)。整句话解释下来，就是ruby.bat gem %*。而gem刚好是ruby的源文件，因此gem就被执行到了。\\n\\n`%~dp0`符号分开解读。最初的原型是函数参数引用语法，`%~0`的%后面\\\\~符加数字，表示对变量参照进行扩展替换，等于$0，代表执行命令本身。利用`%~dp0`可以实现一个小技巧，一个文件夹下有a.exe文件，想利用批处理调用它，又想这个批处理能做到可迁移，写作`%~dp0\\\\a.exe`就能达到此效果。\\n\\n## 与Windows上其它功能的联动\\n\\n### WSH和COM\\n\\nWSH的全称是Windows Script Host，win95时代研发，win98起成为标配的自动化工具。对应cscript.exe和wscript.exe两个Host程序，但这俩只是壳，最终要根据脚本的后缀加载不同的dll。比如.js就加载jscript.dll，官方只有vbs和js，如果安装了ActivePerl这类包可以加载perl.dll并用perl语法写脚本。\\n\\n随着微软自身的演进，WSH还封装了COM技术，从OLE1.0 -> COM OLE2.0 ActiveX。比如在js中用new ActiveXObject可以获取COM对像，进而操作宿主中的Office对象，这也体现了COM底座的价值。\\n\\nWSH环境自带了14个对象，而Wscript则是root对象，其它对象都要通过Wscript.CreateObject()才能实例化。有4个一级对象\\n\\n* WshShell: 主要负责程序的本地运行, 处理注册表项, 创建快捷方式, 获取系统文件夹信息, 处理环境变量等，存在wshom.ocx文件，通过CreateObject(\\"Wscript.Shell\\")得到，该对象的Run方法可以执行命令\\n* WshArguments: 作用是获取全部的命令行变量\\n* WshNetwork: 作用是开放或关闭网络共享, 连接或断开网络打印机, 映射或取消网络中的共享, 获取当前登陆用户的信息\\n* WshController: 创建一个远程脚本对象\\n\\n### 图形化\\n\\n利用hta方式，实现所有平台的图形化开发一致。加上hta可以利用WScript，于是就打通了和批处理的双向调用，示例如下\\n\\n```\\n// bat_file: 和hta同目录的批处理文件，返回运行结果\\nfunction popen(bat_file){\\n\\tvar ws = new ActiveXObject(\\"WScript.Shell\\");\\n\\tvar s_name = document.location.pathname;\\n\\tvar pos = s_name.lastIndexOf(\\"\\\\\\\\\\")\\n\\tvar ro = ws.exec(s_name.substring(0, pos+1)+bat_file);\\n\\treturn ro.stdout.readall()\\n}\\n```"}'));jctx.push(JSON.parse('{"id": "190601", "tag": "lang", "text": "# Lisp的语法真的是括号吗\\n\\n1. Common Lisp 己经有 package 和 gensym 两个机制防变量捕捉，除了麻煩点并无硬伤，且有向旧的 Lisp Machine Lisp 等兼容的考量。\\n\\n2. 提 hygienic macro 的，无非说的是这个，也是 Scheme 用的那个 sytanx\\n\\nThe original algorithm (KFFD algorithm) for a hygienic macro system was presented by Kohlbecker\\n\\n先加点私货说 Scheme，先学 Scheme 的大多有个通病，老是想著用 list，因為 R6RS 里并沒有 struct 嘛，毕竟搞理论的人用的。用 struct 有什么好的呢？或者说以实用标榜自已的 CL 有什么高见吗？ Lisp Machine Manual 有讲：\\n\\n*The contract from ship to its callers only speaks about what happens if the caller calls these functions. The contract makes no guarantees at all about what would happen if the caller were to start poking around on his own using aref. A caller who does so is in error;*\\n\\nCL 的核心是 CLOS，在 OOP 中，object 是有 contract 的，尽管一个 object 本质可能是个 array or list，但还是要用 contract 提供的 accessor，用 nth or aref 就是 violation。这就是 CL 和 Scheme 的思想区別了。\\n\\n学 Lisp，尤其 CL 要有一个概念牢記，我们写的 (defun foo (x) ...) 等等，都不是表达式，而是由 reader 读成名为 list 的数据结构，编绎器直接 compile 的是数据结构。实际上数据结构是不是真的 list 都不重要，只要 hack 下 eval，用 array 以致 class 表示代码都可以。CL macro 的思想，就是直接通过语言自身处理因为灵活性可能出現的各种数据结构。可能这个只有熟練 CL 了以后才能体会，但我以為，這就是 CL 所代表的 Lisp 本貭。在进一步，以後写 CL 都不需要用文本，代码項目直接保存为数据结构。\\n\\n而 Scheme 的 syntax，就有了个 assumption，就是代碼只能是 List，只能限于 S-exp，不然就要 heavily hack 它的 syntax 的系統，而在 CL 中一用 defstruct 各種 handler 就定义好了，不用特別为用 macro 实現个什麼東西。同理其他比如 Rust Clojure 的 hygienic macro，都用的是 pattern match，包括 Scheme 在內，它們在设计時都还停留把代碼當表达式的层次。\\n"}'));jctx.push(JSON.parse('{"id": "190607", "tag": "tool", "text": "# 网页链接\\n\\nOCaml和SML比较\\nhttp://adam.chlipala.net/mlcomp/\\n\\n目前还在使用中的 Standard ML 实现有4个：经典的 SML/NJ（只有32位版本）、Moscow ML、Poly/ML 和 MLton。其中 SML/NJ 的地位相当于参考实现和标准库，其他所有实现都向它看齐。Moscow ML 的性能比较差，但功能丰富；Poly/ML 性能高，主要用来编译定理证明器；MLton 性能最高但没有交互界面。 \u200b\u200b\u200b\\n\\nPython字节码\\nhttp://knuth.luther.edu/~leekent/CoCo/\\n\\nLispMachineManual\\nhttp://hanshuebner.github.io/lmman/frontpage.html\\n\\n从错误提示学Rust\\nhttps://rust-unofficial.github.io/too-many-lists/index.html\\n\\n编译器课程\\nhttps://www.cis.upenn.edu/~cis341/current/\\n\\nhttp://existentialtype.wordpress.com/2011/03/19/dynamic-languages-are-static-languages/\\n\\n## 收藏夹\\n\\n[vim教程](https://github.com/vim-china/hello-vim)\\n\\nhttp://tushare.org/\\n\\nhttps://plfa.github.io/\\n\\nhttps://coq-zh.github.io/SF-zh/plf-current/toc.html\\n\\nhttps://bartoszmilewski.com/2014/10/28/category-theory-for-programmers-the-preface/\\n\\n2017学区 https://www.19lou.com/forum-263-thread-6631457491565752-1-1.html\\n\\n初中学区 https://www.19lou.com/forum-15-thread-7011427707348977-1-1.html\\n\\nhttp://weakyon.com/"}'));jctx.push(JSON.parse('{"id": "190613", "tag": "tool", "text": "# TeX学习笔记\\n\\n到现在TeX还有价值的至少有3块\\n\\n1. box-and-glue model\\n1. hyphenation algorithm\\n1. line-breaking algorithm\\n\\n要分清几个概念\\n\\n* 引擎: 执行程序，用得最多的是 pdftex(越南人写的)，最近比较新的有 xetex, luatex，这些都符合TeX标准。\\n* 格式: 后缀 .fmt，是一组经常用的宏包，往往编译后把内存的dump出来，下次直接加载减少启动时间\\n* 宏包: 文本格式的宏指令集，没到通用的程度，但各种类型的文档多少会用到\\n* 编辑器: 比如WinEdt之类包装引擎的输入工具\\n\\ntexlive包含的文件至少8000个以上，为了快速寻找文件，引入kpathsearch库，依赖 texmf.cnf 文件。\\n\\nTeX本身很基础，所有的功能都依赖宏包。文件分为三类：run files, doc files, src files。其中 run files 是编译时使用的文件（包括宏包的 .sty, .cls 等，字体的 .tfm, .pfb 等）；doc files 是说明文档；src files 是源代码（如宏包的 .dtx-生成文档, .ins-真正的代码 等，字体的 .mf 文件等）。文档和源代码部分在安装 TeX Live 的时候是可以选择不安装以节省空间的。\\n\\n记录一个网上看到的问题，常见于「插图」，一些宏包（比如 hyperref 和 geometry）也有影响。不同的生成 PDF 文件的路径，会用到不同的工具（我们称之为「驱动」）。这里给一个简单的列表：\\n\\n* DVI - PS - PDF：LaTeX -> dvips -> ps2pdf，要用到 dvips 这个驱动\\n* DVI - PDF: LaTeX -> DVIPDFMx，要用到 DVIPDFMx 这个驱动PDF (Directly): \\n* pdfLaTeX，驱动就是它自己（pdfTeX）\\n* xDV - PDF: XeLaTeX -> xDVIPDFMx，驱动是 xDVIPDFMx（默认自动调用）\\n\\n常见的编译方式，至少涉及到 dvips、DVIPDFMx、pdfTeX、xDVIPDFMx 四种驱动。这四种驱动对插图、PDF 书签、页面纸张大小等内容进行处理的时候，语法有细微的差别。为了让驱动正常工作，在 (pdf/Xe)LaTeX 编译的时候，就必须让相应的宏包按照驱动的要求工作。\\n\\n现在的问题是，宏包怎么知道应当怎么工作？如果你有注意到，就会发现，对于 pdfLaTeX 和 XeLaTeX 来说，能使用的驱动就只有一种情况；但是对于 LaTeX 来说，可以选择 dvips 和 DVIPDFMx 两种驱动。因此，如果用户选择 pdfLaTeX 或者 XeLaTeX 编译，那么宏包是可以自己检测到的，此时不需要进行特别的设置。但是，如果用户选择 LaTeX 编译，那么宏包就不知道应该怎么工作了。为了简化代码（也由于历史原因），这些宏包在用户使用 LaTeX 编译的时候，「默认使用」dvips 这个驱动；而如果希望使用 DVIPDFMx 的话，就需要在加载宏包的时候以宏包选项的方式给出说明。\\n\\n总结一下：LaTeX - dvips：默认情况，可以不给驱动选项，也可以给驱动选项 dvipsLaTeX - DVIPDFMx：无法自动检测，必须手工给出驱动选项 dvipdfm 或者 dvipdfmx （详情查阅相应宏包文档）pdfLaTeX：可以自动检测，因此可以不给驱动选项，也可以给驱动选项 pdftexXeLaTeX：可以自动检测，因此可以不给驱动选项，也可以给驱动选项 xetex4那么什么时候会出错呢？其实很简单：当实际使用的驱动和宏包的工作模式（取决于驱动选项）不一致的时候，就会出错。比如，如果使用 \\\\usepackage[pdftex]{graphicx} 载入 graphicx 宏包，那么就只能使用 pdfLaTeX 编译。此时使用 LaTeX 或者 XeLaTeX 都会报错。又比如，如果使用 \\\\usepackage[dvipdfmx]{hyperref} 载入 hyperref 宏包，那么就只能使用 LaTeX - DVIPDFMx 的方式编译。此时使用 pdfLaTeX、XeLaTeX 或者 LaTeX - dvips 的话就会报错。更有甚者，如果是这样子：\\\\usepackage[pdftex]{graphicx}\\n\\\\usepackage[dvipdfmx]{hyperref}两个宏包使用的驱动选项不一致，那么不管怎么编译，都会报错。\\n\\n喜欢「抄代码」的新手，经常遇到这样的问题：东抄抄西抄抄，结果两个作者没商量好，写出来的代码一个需要 pdfLaTeX 编译，另一个需要 LaTeX - DVIPDFMx 编译，于是就坑死了新手。所以：代码自己写，不要抄代码。题主说 LaTeX - DVIPDFMx 方式可以正确编译。这也就是说，启用了宏包选项 dvipdfmx。这时候题主尝试用 LaTeX - dvips - ps2pdf 的方式编译，自然就会报错了。\\n"}'));jctx.push(JSON.parse('{"id": "190615", "tag": "web", "text": "# nginx工作流与模块\\n\\n## 工作流\\n\\nmaster-worker的流程如下\\n\\n![flow](/img/ngx-master-worker.jpg)\\n\\n当worker被意外终止时，master会启动一个新的，且work-id不变，保持逻辑一贯性。即使master挂掉，worker会正常工作，这也是resty的工作原理。只是worker再挂掉就没有进程拉起了。\\n\\n每次的请求都会随机分配给一个worker处理，通过 accept_mutex 指令防止惊群。这是一个加在accept上的一把互斥锁。即每个 worker 进程在执行 accept 之前都需要先获取锁，获取不到就放弃执行 accept()。有了这把锁之后，同一时刻，就只会有一个进程去 accpet()，这样就不会有惊群问题了。accept_mutex 是一个可控选项，默认打开，可以显示地关掉。\\n\\n解决这个问题还有一种办法，1.9.1版本引入套接字共享选项，listen 80 reuseport; 这种方式和accept_mutex互斥，所有worker都在监听，但不需要worker抢锁，而是由内核来分配，但需要Linux在3.9以上才支持。\\n\\n## 模块\\n\\n要对Nginx做扩展，都是在nginx.conf里通过命令调用来完成的。这些命令是归属到某个module中的。命令本身不会显式支持命名空间，\\n还是要写扩展的人按照良好的习惯对命令命名，Nginx的风格是C式的蛇式命名。但是也不一定。比如echo命令就是echo这个module，但是`content_by_lua`又属于`ngx_lua`模块，我猜大概是Nginx的作者在设计之初并没有想过有一天会这么受欢迎吧。\\n\\n从语法上看，模块至少要包含context和directives两个最核心的定义(其余版本、类型简单)。\\n比如`ngx_module_t`的context对应`ngx_http_module_t`，directives则对应`ngx_command_t`。\\n\\n以上是针对Nginx module的定义包含context和directives，还有一种http module定义，\\n主要定义的是create/init main/server/location configuration的函数定义。\\n因为每个command在运行前势必要得到其所在的上下文，对应就是上面说的configuration的创建。如果命令所在的阶段不同，定义也不一样。这些定义都是嵌套在`ngx_module_t`里的。\\n\\n## 问题排查记录\\n\\n1. 访问报403无权限: 检查目标目录权限755，nginx的启动用户root都没有问题。网页文件在root目录下，尝试移到/var目录，保持权限755终于可以访问（644仍提示无权限）\\n"}'));jctx.push(JSON.parse('{"id": "190618", "tag": "os", "text": "# 性能监测工具选项备忘\\n\\n## top\\n\\n默认显示Task数量，用 top -H 切换到线程模式，显示Thread的数量。也可以 top -H -p xxx 仅显示某进程的线程。top -a按内存使用排序。\\n\\n## ps\\n\\n-T或-L 看到线程，又叫 lwp 或 spid 或 tid。默认不建议启用，只在确定某个进程有问题，且存在多个线程时，再打开线程观察，要注意的是打开线程时，内存占用是一样的（因为共享），CPU占用要加总。默认查看/proc目录时，用getdents(2)，并不显示线程。 -o %cpu= 只看cpu占用\\n\\n## pstree\\n\\n-p才显示进程号，似乎内容也会变多\\n\\n## strace\\n\\nstrace的原理是先给目标进程发暂停信号，attach上去后再发SIGCONT信号，所以开始时会显示 `restart_syscall(< resuming interrupted nanosleep >)`\\n\\n系统级别的进程用strace观察多线程的始末是个很好的方式，trace内容定向到stderr，大概是不想影响被观察程序的正常输出吧。多线程的主线程join的系统调用对应的是futex，这个动作会提示unfinished，直到所有子线程退出，退出时子线程会调用futex(FUTEX_WAKE_PRIVATE)，主线程的futex才会resume。\\n\\nLinux x86_64的ABI要求系统调用至多只能接受6个参数，strace跟踪的参数列表是有限的。\\n\\n同步的进程间通过mmap共享一段内存，futex变量就位于这段共享 的内存中且操作是原子的，当进程尝试进入互斥区或者退出互斥区的时候，先去查看共享内存中的futex变量，如果没有竞争发生，则只修改futex,而不用再执行系统调用了。如果futex变量告诉进程有竞争发生，则执行系统调用去完成相应的处理(wait 或者 wake up)。\\n\\n所有逻辑结束后，主线程会close 012三个默认句柄，munmap内存，最终exit_group退出进程组结束整个程序。\\n\\n常用选项\\n\\n* -c : 以统计形式(理解为Group By)显示哪个系统调用耗时，一般用于排查一次性任务，还可以和-S配合结果显示时的顺序\\n* -s 128 : 默认打印输出字符串的前32个字符（文件名不属于字符串），此选项打印更多字符\\n* -vT : v打印环境变量和结构体等更多信息，T打印syscall的耗时\\n* -f : 默认只跟踪进程，此选项追踪线程\\n* -t : 显示每条调用的发生时刻，可以tt甚至ttt，提升精度\\n* -e expr : -e trace=!file,process,network,signal,ipc,memory 只跟踪某类系统调用，反向时记得用backslash修饰!\\n\\n## ltrace\\n\\n跟踪动态库调用，默认输出很少，可以用-S打印系统调用，不过速度比strace慢\\n\\n## pidstat\\n\\n* -u显示的%wait表示 得不到运行的时长/期望运行的时长。比如2核机器运行8个任务，等待率是75%\\n* -w显示上下文切换，包括自愿和非自愿。说明内存或CPU存在瓶颈\\n\\n## time\\n\\n既有bash内建也有独立命令，一般用bash内建的time -p输出POSIX格式时间。real包括CPU和IO的所有耗时，等于秒表计时时间，而user和sys都只代表CPU时间且多核会一并计入，所以对多核优化得好的程序，会出现`real<user+sys`的情况。在`/proc/<pid>/stat`文件的14和15列分别表示进程运行在用户态和内核态的tick周期数，tick代表多少时间不是固定，大多数是10ms，可以用以下程序测出来。\\n\\n```\\n#include <signal.h>\\n#include <unistd.h>\\n#include <stdio.h>\\n#include <stdlib.h>\\n#include <string.h>\\n#include <sys/time.h>\\n\\n#define USECREQ 100000\\n#define LOOPS 3\\n\\nchar cmd[64];\\n\\nvoid event_handler(int signum)\\n{\\n    static unsigned long cnt = 0;\\n    cnt++;\\n    if (cnt >= LOOPS)\\n    {\\n        system(cmd);\\n        exit(0);\\n    }\\n}\\n\\nint main(int argc, char **argv)\\n{\\n    struct sigaction sa;\\n    struct itimerval timer;\\n    int pid;\\n    pid = getpid();\\n    sprintf(cmd, \\"cat /proc/%d/stat\\", pid);\\n    memset(&sa, 0, sizeof(sa));\\n    sa.sa_handler = &event_handler;\\n    sigaction(SIGVTALRM, &sa, NULL);//SIGALRM\\n    timer.it_value.tv_sec = 0;\\n    timer.it_value.tv_usec = USECREQ;  // timer can\'t precise to 1us, let it be normal\\n    timer.it_interval.tv_sec = 0;\\n    timer.it_interval.tv_usec = USECREQ;\\n    setitimer(ITIMER_VIRTUAL , &timer, NULL);//REAL\\n    while (1) ;\\n}\\n```\\n\\n原理就是利用while(1)让进程跑满用户态，同时再用setitimer机制让程序在固定时间后退出，计算用户态运行时间除以tick，就能得出tick代表的真实值。但是有一点要注意，定时周期似乎不能小于tick本身，否则程序运行时间会比期望时间长，可能是itimer定时器的精度问题，计算得到的tick值误差也会更大，但大体还是准的。\\n"}'));jctx.push(JSON.parse('{"id": "190620", "tag": "tool", "text": "# 编辑器的扩展机制\\n\\n如今的编辑器没有插件机制都不好意思出来见人，像Emacs，所有的操作都可以对应函数，再用Elisp把已有的函数和数据结合起来，本体和扩展混然一体，非常流畅。什么是真正好的机制？\\n\\n## notepad++的插件机制\\n\\nnotepad++插件很多，执行程序集成了scintilla库，另外还有个独立的SciLexer.dll库，做词法分析。原理是dll开发，一定要实现5个函数，另外有个isUnicode选择实现，一般是返回TRUE就好。这5个函数说明如下\\n\\n1. getName : 给插件选个好名字，不需要和dll名相同，在插件菜单就靠这个名字找插件\\n1. setInfo : 初始化阶段会被npp调用，传入3个句柄，分别是npp本身，scintilla的main和second handle(分别对应编辑区的两个视图)\\n1. getFuncsArray : 在setInfo之后被npp调用，获取这个插件的条目，因为功能可能依赖setInfo传入的句柄，所以时序上严格晚于setInfo，返回条目数量和函数指针\\n1. beNotified : 产生npp专属事件时会回调\\n1. messageProc : 通用的windows消息回调\\n\\n通过记录宏发现端倪。npp的操作对应的是消息，利用记录宏保存在shortcut.xml文件的信息，就可以反窥出这个动作要怎么表示，再在插件中发起这个消息，也可以达到融合的效果。这是一个宏的记录\\n\\n```\\n<Macro name=\\"Trim Trailing and save\\" Ctrl=\\"no\\" Alt=\\"yes\\" Shift=\\"yes\\" Key=\\"83\\">\\n    <Action type=\\"1\\" message=\\"2170\\" wParam=\\"0\\" lParam=\\"0\\" sParam=\\" \\" />\\n</Macro>\\n```\\n\\n猜测action type 0 is for Scintilla commands with numerical params, type 1 is for commands with string parameter, 2 is for Notepad++ commands.\\n\\n### npp的脚本化插件\\n\\n如果只能开发dll插件成本还是太高，LuaScript提供SendEditor/MenuCommand等函数，可以发送所有的SCI消息给编辑器，消息的枚举要查看scintilla.iface。或者执行菜单命令，具备了相当程度的整合能力。\\n\\n## EditPlus的扩展机制\\n\\n不提供内嵌语言方式的扩展，只能通过filter钩子来实现一些基于文本的动作，可以替换也可以执行一些其它指令，但不能获取到编辑器的内部状态，因此觉得算不上插件，但也算是一种很简便的和外部程序的协同。\\n\\nfilter的原理是逐行从stdin读入，处理后写到stdout，写出的内容按指令替换或打开新的文本。\\n\\n## 一些小众编辑器\\n\\n也许工作中不会用到这些编辑器，但是看到有趣就记录下来。\\n\\njed，取名是作者名字的3个字母，扩展语言称为SLang。快捷键默认和emacs一样，记住ctrl X ctrl C退出，Alt X执行命令。如果在site.sl中加载vi.sl插件，再执行`command_mode`命令，就能用反引号（注意不是ESC键）进入vi模式。\\n\\njasppa，一个MicroEmacs的发布版。\\n\\nvile，全名是vi like emacs，非常轻量似乎也有扩展模式。\\n\\n要具备IDE功能的编辑器是越来越难，具备语义的自动补全，跳转和跳回，和编译链的结合性。只有深厚积淀的编辑器才能承载前行。"}'));jctx.push(JSON.parse('{"id": "190621", "tag": "tool", "text": "# 编辑器内部细节\\n\\n大致分为源代码编辑器和富文本两种.\\n\\n源代码编辑器为了省事可以设置相同的行高方便计算, 不过现在多数支持变化行高了可以从富文本编辑器开始做.\\n\\n首先, 挑一个 GUI 框架\\n\\n跨平台的 GUI 通常很吸引人, 例如 Fox, FLTK, Tk, GTK+, Qt, WxWidgets 等, 大部分都有一个编辑源代码的控件, 而这个控件基本是 Scintilla 之上的包装 (再研究 Scintilla 你会发现其实各种 GUI 框架的编程模型包装都不需要, 按照 Scintilla 的设计去用就可以了). 学习下来你会发现各个 GUI 框架都自带一个特别的观感: Fox 的光标是个不可改变的巨型铁轨截面, wxWidgets 尽量模仿原生组件 (E-texteditor 就是用 wxWidgets 做的), GTK 就尽量自己画... 其编程模式实质差异并不大, 因为都是 C 和 C++ ... 最惨的是在 Windows 看着还可以, 一放到 Mac 就觉得丑爆了. 做了其他语言的绑定还是感觉在写 C 和 C++. 当然也有做得不一样的:\\nTcl/Tk 最简洁\\nREBOL view 最 fancy\\nPaul Graham 最推崇 Arc\\n\\n另一大类 GUI 框架是 XUL. 写个 XML 界面, 然后在 XML 界面上画东西. XHTML+JavaScript 就是一种 XUL 方案. Sun, 很小很柔软, 摸斯拉 等等大公司都推过自家的 XUL 方案. 然而 XML 根本就不适合人类编写, 作为 model 格式也过于巨大不好维护. 最初魔兽世界的插件也是推荐 XML 写界面然后绑定 lua 的动作, 但由于太不灵活也没有一个拖控件的界面, 所以玩家开发了 Ace 系列的 UI lib, 完全不用 XML 纯用 lua 写了. 拖拽式画界面只能骗骗小朋友, PaintCode 也比 XML 解释器性能更好, 所以现在 XUL 基本绝迹, 连直接用 HTML 写界面都不时髦了.\\n\\n如果不跨平台, 用图形操作系统的 GUI 框架会更能解决很多实际问题, 性能也有保证. Win32API, MFC, ATL, WinForms, WPF, Carbon, Cocoa, CGContext, CoreText ... 就是操作系统商人心狠手辣变幻无常, 一心搞个大新闻还处处夹带私货, 一路学来也是挺累人的. 另一方面嘛 X11 这种更难学, 我就卡在了 motif ...\\n\\n虽然跨平台的 GUI 框架在慢慢衰亡, 但 OpenGL 这类更接近底层硬件的图形库给人类提供了新的希望. 利用 OpenGL 的成功案例就有 Sublime Text. 我觉得 Cairo, SDL 这种半 GUI 框架的高性能图形库是比较适合的, 就是用的人少了点.\\n\\n鉴于图形化界面的巨坑... 何不写个纯命令行的编辑器呢? 这时候我们有各种行编辑库可以用: readline, libedit, termcap, Antirez 的轻量 linenoise ... 再用脚本语言的话, 由于内建正则语法和一些字符串处理函数, 很容易在一两万行内写个功能齐全的编辑器解决战斗, 例如 Daikonos.\\n\\n就算用 C, 如果只实现最简单的功能, 1024 行以内也是可以的: Writing an editor in less than 1000 lines of code, just for fun\\n\\n纯字符界面缺点也很多, 平滑滚动没有, 动画高亮没有, 文字显示揪细点想调个 kerning 啊 ligature 啊也没办法. 那就自己做一个图形框架? Eclipse 就自掘巨坑组合 C++ 和 Awt 搞出个 SWT. 其实 Awt 和 Swing (NetBeans, IntJ 都是基于 Swing) 处理 Unicode 都有大量的坑, 我都不喜欢... 曾经有个我关注的编辑器 Redcar, 最初用 GTK 编写, 后来转成了 Swing, 然后逐渐就做不动了... jEdit 作者弃编辑器坑, 后来挖了个基于栈的语言新坑 Factor. 后来? 后来也不搞了...\\n\\n现在 GUI 基本被 ES 的大流统治. 用 Web 做编辑器可以做出一些非常棒的用户体验, 现在浏览器引擎也优化得比几年前好太多. Atom, Monaco Code Editor 都是在 Web 上做的成功案例. 为了容易上手估计 ES 是首选. 缺点是某些细的 UX 不好实现, 正经的优化会花掉更多时间 (例如 Monaco 为了分析性能点连 IR Hydra 都用上了).\\n\\n介绍两个 Helloworld, GUI 框架 + Scintilla 实现常见一个编辑框\\n基于 FxRuby 的:\\n\\nrequire \'fox16\'\\n\\ninclude Fox\\n\\napp = FXApp.new\\nwindow = FXMainWindow.new app,\\n  \\"My Editor\\",\\n  nil, nil, DECOR_ALL, 100, 100, 710, 550\\n\\nsci = FXScintilla.new window,\\n  nil, 0, LAYOUT_FILL_X|LAYOUT_FILL_Y\\n\\napp.create\\nwindow.show\\napp.run\\n\\n基于我自己写的 GUI 框架的就更简单了 (谁不年少轻狂造过几个 GUI 框架轮子?)\\n\\nrequire \'cici\'\\napp = Cici.app \'scintilla\'\\nc = app.paint [600, 600], Cici::ZoomLayout\\nc.scintilla [500, 500]\\napp.message_loop\\n\\n其实还有各种 GUI 框架的编辑器 hello world 都差不多, 但用框架就是跟着别人走, 很难做出更好的用户体验.\\n\\n如果从更底层点的地方开始, 例如 Win32API 和 Carbon, 站稳脚跟学习图形界面编程, 前面的道路会... 更狭窄 (公司刚裁了很多桌面程序员并对 Web 产品加大投入...). 不过你理解事件模型的实现和常见优化手段以后, 就算编辑器不成功, 也可以自己写个游戏引擎玩玩嘛.\\n\\n然后, 挑一个 text storage 数据结构\\n\\n例如 Cocoa 就自己提供了一个 NSTextStorage, 自己造大约有几个主流选项:\\n\\nGap buffer: 例子有 Emacs. 很简单的数据结构, 光标前一个 buffer, 光标后一个 buffer. 能极大的减少 buffer 重新分配次数. 扩展一下变成 multi-gap buffer, 多光标编辑也很流畅.\\nChain of lines: 例子有 TextMate. 每行一个 buffer, 一行不拆散. 对压缩的文件高亮时会比较卡. 但是可以和功能强大的正则引擎 Oniguruma 完美集成.\\nCell buffer: 例子有 Scintilla. Cell 大小固定, 如果一行超出 Cell 的固定大小, 就分拆成多个 Cell. 用过 Scite 或者 Code::Blocks 或者 Notepad++ 等会发现, 打开大文件, 高亮都还流畅, 因为 Scintilla 的 Cell buffer 和重绘计算的效率很高. 但由于拆行, 只能集成 input driven 的功能较弱的正则引擎或者 lexer, 而这会对实现很多功能带来麻烦.\\nZipper: Immutable 的数据结构, 如果用 Haskell 做后端会非常适合. 同时还能顺便实现树形历史.\\n"}'));jctx.push(JSON.parse('{"id": "190623", "tag": "os", "text": "# perf使用\\n\\n包含二十多个命令的合集入口\\n\\n序号\\t命令\\t作用\\n1.\\tannotate\\t解析perf record生成的perf.data文件，显示被注释的代码。\\n2.\\tarchive\\t根据数据文件记录的build-id，将所有被采样到的elf文件打包。利用此压缩包，可以再任何机器上分析数据文件中记录的采样数据。\\n3.\\tbench\\tperf中内置的benchmark，目前包括两套针对调度器和内存管理子系统的benchmark。\\n4.\\tbuildid-cache\\t管理perf的buildid缓存，每个elf文件都有一个独一无二的buildid。buildid被perf用来关联性能数据与elf文件。\\n5.\\tbuildid-list\\t列出数据文件中记录的所有buildid。\\n6.\\tdiff\\t对比两个数据文件的差异。能够给出每个符号（函数）在热点分析上的具体差异。\\n7.\\tevlist\\t列出数据文件perf.data中所有性能事件。\\n8.\\tinject\\t该工具读取perf record工具记录的事件流，并将其定向到标准输出。在被分析代码中的任何一点，都可以向事件流中注入其它事件。\\n9.\\tkmem\\t针对内核内存（slab）子系统进行追踪测量的工具\\n10.\\tkvm\\t用来追踪测试运行在KVM虚拟机上的Guest OS。\\n11.\\tlist\\t列出当前系统支持的所有性能事件。包括硬件性能事件、软件性能事件以及检查点。\\n12.\\tlock\\t分析内核中的锁信息，包括锁的争用情况，等待延迟等。\\n13.\\tmem\\t内存存取情况\\n14.\\trecord\\t收集采样信息，并将其记录在数据文件中。随后可通过其它工具对数据文件进行分析。\\n15.\\treport\\t读取perf record创建的数据文件，并给出热点分析结果。\\n16.\\tsched\\t针对调度器子系统的分析工具。\\n17.\\tscript\\t执行perl或python写的功能扩展脚本、生成脚本框架、读取数据文件中的数据信息等。\\n18.\\tstat\\t执行某个命令，收集特定进程的性能概况，包括CPI、Cache丢失率等。\\n19.\\ttest\\tperf对当前软硬件平台进行健全性测试，可用此工具测试当前的软硬件平台是否能支持perf的所有功能。\\n20.\\ttimechart\\t针对测试期间系统行为进行可视化的工具\\n21.\\ttop\\t类似于linux的top命令，对系统性能进行实时分析。\\n22.\\ttrace\\t关于syscall的工具。\\n23.\\tprobe\\t用于定义动态检查点。\\n\\n全局性概况：\\n\\n* perf list查看当前系统支持的性能事件；\\n* perf bench对系统性能进行摸底；\\n* perf test对系统进行健全性测试；\\n* perf stat对全局性能进行统计；\\n\\n全局细节：\\n\\n* perf top可以实时查看当前系统进程函数占用率情况；\\n* perf probe可以自定义动态事件；\\n\\n特定功能分析：\\n\\n* perf kmem针对slab子系统性能分析；\\n* perf kvm针对kvm虚拟化分析；\\n* perf lock分析锁性能；\\n* perf mem分析内存slab性能；\\n* perf sched分析内核调度器性能；\\n* perf trace记录系统调用轨迹；\\n\\n最常用功能perf stat/record，先定性地看一个进程问题在哪，再详细记录调用情况。尤其stat结果的第一条task-clock能很明确地告诉你CPU占用率是多少，比如写一个无聊的lua脚本只做个打印，发现整个程序的CPU占用率是39%，即打印操作占了61%，还是IO占的时间更多。（越接近1表明CPU Bounded）\\n\\n* pref record记录信息到perf.data；\\n* perf report生成报告；\\n* perf diff对两个记录进行diff；\\n* perf evlist列出记录的性能事件；\\n* perf annotate显示perf.data函数代码；\\n* perf archive将相关符号打包，方便在其它机器进行分析；\\n* perf script将perf.data输出可读性文本；\\n\\n可视化工具perf timechart\\n\\n* perf timechart record记录事件；\\n* perf timechart生成output.svg文档；\\n\\n比如要监听某后台程序的性能，先用ps获取pid。这里我犯了个错误，其实ps出来的第一列就是pid，我却错找成后面的数字了，要注意。然后这样输\\n\\n* perf record -e cs -a -g -p xxx\\n\\n-e表示记录所有cs事件(事件名从perf list获取),-a表示记录所有CPU行为,-g表示记录call graph，而最后的-p就是指明pid。\\n然后perf就开始监听直到按下Ctrl-C才会停止。停止后会自动生成perf.data文件，\\n再用perf script(用于显示跟踪输出，而perf report命令也会自动读取perf.data并生成profile，火焰图需要的是跟踪输出，所以是script命令)。命令如下\\n\\n* perf script | stackcollapse-perf.pl | flamegraph.pl >perf.svg\\n\\n中间两个perl脚本从[这里](https://github.com/brendangregg/FlameGraph)下载。最早版本的stackcollapse是从DTrace来的，后来发展出各种工具的适配版，perf是其中之一。\\n\\n不仅用户态有线程和栈，内核的调度也以线程为单位，同样线程也有栈。硬件中断的处理就很典型，中断程序分为上下两个半部分，上半部分响应很及时，但是此时处理器处在中断禁止模式，所以必须尽快地完成重新开放中断。如果业务太多处理不完，只有交给下半部分，下半部分就和应用态类似tasklet，由线程管理器统一调度。\\n\\n像nodejs也追加了对perf的支持(V8支持)，像这样运行`node --perf-basic-prof xxx.js`就会生成/tmp/perf-pid.map文件，用`perf record -F 99 -p \\\\`pgrep -n node\\\\` -g -- sleep 30`记录运行数据就可以了。但是生成的map文件会不停增长，可以用`--perf-basic-prof-only-functions`来延缓map文件增长速度。java据说8u60版本后，打开`-XX:+PreserveFramePointer`也能和perf协同。"}'));jctx.push(JSON.parse('{"id": "190625", "tag": "tool", "text": "# 如何学习emacs\\n\\n## 写在前面\\n\\narm版的emacs的安装包35M，vim是20M，虽然大一些但还是同一量级，执行体emacs约4.7M，而vim约2.2M。之所以emacs给人感觉很大是其自带3K多个el文件，而vim自带插件数量远没有这么多。runemacs是专为图形界面做的外可覆程序(不会出现控制台)，支持emacs所有的命令行选项，还可以通过修改环境变量比如HOME来调整加载文件。配置文件全部放到.emacs.d/目录，原来的.emacs文件建议转移到.emacs.d/init.el，只有一个目录会比较整洁。\\n\\n## 概念\\n\\n由于没有像vim般众多的模式，emacs的概念比较纯粹，所有的行为都是elisp函数，加上(interactive)的函数又被称为命令，可以通过M-x调用。而快捷键就是对函数的绑定。没有行的概念，就是把文本放到buffer并显示出来，通过fill-column变量还控制在屏幕上的折行位置。\\n\\n## 帮助系统\\n\\n除了退出`C-x C-c`和取消`C-g`外，最需要熟练运用的就是帮助系统，\\n\\n* C-h f 查看函数的帮助信息， F 查看命令的帮助\\n* C-h v 查看变量的帮助信息，包含当前值和默认值\\n* C-h k 查看快捷键对应的函数名称和功能，c在minibuffer展示摘要\\n* C-h w 在minibuffer展示命令摘要及是否有快捷键， a功能类似支持正则\\n\\n写elisp时候想要验证某个函数，有时C-x C-e会不管用，可以换成M-x ielm 打开elisp的REPL试验。\\n\\n## 插件\\n\\n用spaceemacs如果觉得速度慢，改成国内镜像，到 .spacemacs 的 dotspacemacs/user-init() 添加\\n\\n```\\n(setq configuration-layer--elpa-archives\\n    \'((\\"melpa-cn\\" . \\"http://elpa.emacs-china.org/melpa/\\")\\n      (\\"org-cn\\"   . \\"http://elpa.emacs-china.org/org/\\")\\n      (\\"gnu-cn\\"   . \\"http://elpa.emacs-china.org/gnu/\\")))\\n```\\n\\n## Elsip\\n\\nquote和list的区别，用quote创造的对象，只要值一样，永远是同一个引用；而list是每次都创建一个新的对象并返回这个对象的引用。"}'));jctx.push(JSON.parse('{"id": "190703", "tag": "os", "text": "# Linux上的虚拟化\\n\\n## 容器化\\n\\n为了实现弹性计算和灵活迁移，把一台机器跑出尽可能多的实例，且实例间做到隔离，容器化相比虚拟机，省去了kernel的模拟，没有驱动方面的困扰，启动也更快。由于不能更换kernel，容器环境很可能没有/boot/目录(取决于chroot时有没有屏蔽)，容器环境的rootfs会额外挂载，比如在debian上启动cent的环境。\\n\\n容器化通过四个主要组件工作：名称空间（namespaces），控制组（cgroups），映像（images）和用户空间工具例如Docker或Podman。它们都基于内核的namespace，cgroup，unionFS机制，剩下的images和用户空间工具为了更好的封装。\\n\\n## namespace\\n\\nnamespace有多种类型 (mnt, net, ipc, user, pid, uts, cgroup, time)，没有namespace之前，所有`task_struct`共享一些全局属性，引入namespace特性后，task结构中增加了struct nsproxy *nsproxy;指针，以下是稍早期版本的结构体，没有user和time两种类型。\\n\\n```\\nstruct nsproxy {\\n  atomic_t count;\\n  struct uts_namespace *uts_ns;\\n  struct ipc_namespace *ipc_ns;\\n  struct mnt_namespace *mnt_ns;\\n  struct pid_namespace *pid_ns_for_children;\\n  struct net       *net_ns;\\n  struct cgroup_namespace *cgroup_ns;\\n};\\n```\\n\\n这些变量在/proc/pid/ns/目录下都有对应的文件。\\n\\nuts来源于uname(2)依赖的结构体 struct utsname，而这个结构体的名字源自于\\"UNIX Time-sharing System\\"。似乎只影响hostname和domainname。\\n\\n网络namespace包括网卡，回环设备，路由表，iptables规则。\\n\\n总的来说，namespace的本质就是把原来所有进程全局共享的资源拆分成了很多个一组一组进程共享的资源\\n\\n* 当一个namespace里面的所有进程都退出时，namespace也会被销毁，所以抛开进程谈namespace没有意义\\n* UTS namespace就是进程的一个属性，属性值相同的一组进程就属于同一个namespace，跟这组进程之间有没有亲戚关系无关\\n* clone和unshare都有创建并加入新的namespace的功能，他们的主要区别是：\\n\\n> unshare是使当前进程加入新创建的namespace\\n\\n> clone是创建一个新的子进程，然后让子进程加入新的namespace\\n\\n* UTS namespace没有嵌套关系，即不存在说一个namespace是另一个namespace的父namespace\\n\\n## cgroup\\n\\ngoogle工程师为了解决系统资源无法隔离的问题，于2006年提出此方案，并最终合并到2.6内核。\\n\\n物理机或虚拟机享有全部的资源，查看 /proc/[pid]/cgroup 列出的内容没有值，而容器的话会随着不同的实现方式输出不同，有kubepods/docker/machine-rkt等多种。利用这个特性，也可以检测到是否在容器环境。\\n\\n## unionFS\\n\\n在一台宿主机上跑几十上百个容器时，这些容器镜像的基础层往往是一样的，如果使用传统的chroot方式，势必造成极大的空间浪费，因此就有了多个容器共用一些基础目录的需求。每个容器又各自有其特有的内容，这些目录要和基础目录共同构建成应用看来统一的目录结构。\\n\\n为实现这个目的，把不同的目录的内容，联合放到同一目录内（如果有同名文件，只会看到一个），这便是unionFS技术。严格讲不能算虚拟化技术，因为早在使用CD作为Linux发行版介质时，就有类似的需求，union mount point的理念更是在1995就出现在BSD系统。随着容器技术的发展，人们发现uinonFS非常匹配，于是这种文件系统被更多的人所知。\\n\\nunionFS有多种实现，Docker最初使用的AUFS是2006年基于unionFS全新开发的，RedHat觉得AUFS基于文件的机制性能不好，开发了DeviceMapper。随着这个需求越来越普遍，2010年开发并被用在OpenWRT上的OverlayFS，在经过4年的讨论后，终于被合并入Linux内核的3.18版本。OverlayFS的思路和AUFS类似且又做了很多优化，目前已成为容器文件系统的主流。\\n\\n## QEMU虚拟机\\n\\n过程是将目标机的体系翻译成中间语言，再将中间语言翻译成宿主机的过程。主启动程序是qemu-system-xxx，支持x86、arm、mips等多种架构，不同架构有不同的执行程序。虽然都是一套软件，但支持力度却不同，X86(包括X64)最方便，只要配置好硬盘和内存参数就可以启动，而arm就要-M指定模拟的机器，-bios指定启动器（甚至还要自己上网找bios），这和arm只规定指令集，不包含外围引导也有关系。\\n\\nQEMU是纯软实现，不会利用硬件本身的虚拟化特性，速度非常慢。但支持-enable-kvm加速，可惜我用的是手机，无法体验kvm的效果。\\n\\narm版本启动后，无法进入引导，可能是bios没有选择正确。默认会开vnc，但对arm版来说，只会进入qemu的控制台，没什么用。相反x64的问题就少很多。但x64也存在只认某些ISO镜像的问题。\\n\\n除了虚拟机执行器本身，还有些外围程序，最常用的是qemu-image，用于创建、查看、管理虚拟机镜像。推荐用qcow2格式的镜像，支持把其它虚拟机的镜像格式转换，还能查看已有镜像的大小和其它属性。"}'));jctx.push(JSON.parse('{"id": "190705", "tag": "lang", "text": "# Go语言学习笔记\\n\\n## 语言特性\\n\\nGOROOT指定了Go的工具、库和源码的存放路径。\\n\\nJSON库要求struct的成员必须是大写字母开头，否则无法导出，可见性渗透到很多地方。\\n\\nstring和[]byte在二进制层面是一样的数据，但类型不同，原因是string被设计为不可变，保证多线程安全，而[]byte就是一块内存区域。当函数需要的参数和实际类型不匹配时，二者间要做类型转换，不可避免地会引入内存复制开销，如果想避免开销，就一定要自己保证内存安全。\\n\\ngo可以认为是启动了新线程（较创建原生线程开销较小），goroutine是不可控的线程操作，原生带了channel用于通信，对channel的读写是阻塞的（否则执行序不可控的多个go程就无法协作了）。而coroutine其实是严格串行执行，基于共享内存通信无妨，并不需要channel，用yield和resume显示控制。\\n\\n每个包可以定义init函数，会先于main执行，多个包的init顺序不可控。\\n\\n严格地说go的函数参数传递只有一种：**值传递**。因此对复杂struct变量，用指针方式减少复制的开销。但有一种说法，在特定的场合值会比指针开销少，原因是逃逸分析。\\n\\n## 编译与构建\\n\\n在工程源码的根目录执行go build即可。仔细看build过程，先生成一个中间过程的importcfg.link文件，内容是用packagefile指定了若干运行相关的参数，比如cpu、字节运算方式、math/sys库，并用go的link工具加载这些参数生成可执行文件a.out，然后改名成包相同的名字。\\n\\nimport时指定的是目录名称，导入同时会解析目录下的包名称，所以真正调用的时候以包名称引用（目录名和包名称不强制一样，但目录内的package包必须统一）。另外包名只有一级，不支持点号，所以不管import的目录名有多长，但真正起作用的，就是最后一个目录内实际的包名，而且当包名重复时，编译也会报错。所以在命名时，可以在package名中加入下划线适当增加长度，但也不需要太过冗长。导入包重命名机制一定程度上解决命名空间只有一层的简陋。\\n\\ngo build -tags \\"abc xyz\\"会启动条件编译，只有代码首行指定了`//+build abc`的文件会被编译。似乎充斥着这种打补丁似的语法，大约是实际的需求和理想化简约之间的冲突吧。\\n\\nrun指令可以带多个文件列表，顺序可以任意，甚至用\\\\*.go，否则main函数调用的其它文件没有被引入会报错，不需要像C语言把被依赖的文件放在最前面。main包平铺拆成多个文件也是最简单的项目拆分方式，如果想形成多目录，就要用replace指令，对新手来说难度会大很多。\\n\\n### 代码目录结构的变迁（go.mod）\\n\\n以下仅仅是历史，了解就行\\n\\n>  Go的1.11版本以前，代码必须在GOPATH环境变量指定的目录，背后的原因可能是Google所有的代码在同一个repo下，微缩后变成了GOPATH。固定 bin/pkg/src 三个目录，在src下建立目录比如xyz，进入这个目录下编写代码，最后用go build就会自动编译。强行指定文件名固然可以，但并不推荐。\\n\\n1.11引入Module机制，可以不限制在GOPATH路径。从1.13开始module成为默认行为，不再要求在GOPATH目录编译，而是鼓励在当前或父目录添加go.mod文件使这个目录成为go的模块，同时也不再限制必须有src目录。配置 `go env -w GOPROXY=https://goproxy.cn,direct` ，下载依赖包也变得非常方便。\\n\\n以一个简单的go.mod示例来解释构建过程\\n\\n```\\nmodule me.local/user/tdi\\ngo 1.19\\n```\\n\\n第二行版本限定并不是必须的，其实可以精简到只有module一行。后面的模块名必须以域名开头，不用担心域名是否存在，只要遵循规范就好。最后一段会默认作为go build的结果文件名。\\n\\n稍微复杂的工程肯定会导入本地目录，如果有个lib目录，import时写成me.local/user/tdi/lib（module名后跟目录名），就会在源码目录找包。\\n\\n以前还记了一种方法，似乎也用不上了。在go.mod中添加require xxx v0.0.0和replace xxx v0.0.0 => ./xxx，关键是用replace指向本地目录，go就不会去网上找这个包了。\\n\\n### 包和模块\\n\\n一个目录就是一个包package，通过这个目录下的每个源文件开头申明相同的package xx表示属于一个包。取名为main的包比较特殊，通常会定义main函数作为总的入口。同一个包内的函数和类型可以互相引用，不需要申明为大写。多个包构成一个模块，通过在顶级目录添加go.mod声明是一个module。\\n\\ngo get下载的包会放在GOMODCACHE环境变量指向的目录。\\n\\n包可以被编译成.a库。解压后虽然也是.o，但和C语言不同，是混合了字符和二进制的特定形式。不过Go提倡按源文件编译，即使提供了.a库机制，似乎用处不大。\\n\\n### GUI程序\\n\\nwindows平台的图形化程序，链接过程必须有.syso文件才行。可以用rsrc编译manifest，或windres编译rc（内部要有RT_MANIFEST指令）都可以。go build -ldflags=\\"-H windowsgui\\"就不会带命令行小窗口。\\n\\n## 测试与调试\\n\\n单元测试要函数名以 `Test[A-Z]` 方式开头，如果是小写字母则不会运行。在GOPATH下直接运行go test package，虽然能运行用例，但正常的例子不会输出到stdout，而进到package的目录直接运行go test，会输出stdout。Example开头的函数，要增加 `//output:` 才会输出。\\n\\n用GDB调试，build命令可以加两个参数\\n\\n1. 使用go build -ldflags \\"-s -w\\"减少生成文件的体积。-s: 去掉符号信息，-w: 去掉DWARF调试信息。\\n2. 传递-gcflags \\"-N -l\\" 参数，这样可以忽略Go内部做的一些优化，聚合变量和函数等优化，这样对于GDB调试来说非常困难，所以在编译的时候加入这两个参数避免这些优化。另外-m会在编译期打印逃逸分析结果。\\n"}'));jctx.push(JSON.parse('{"id": "190720", "tag": "lang", "text": "# LispMachine\\n\\n1. Lisp Machine 用 Lisp 做汇编指令纯属误传，虽然编译器能将 Lisp 编译成机器指令，也可以将机器转回人可读的 Lisp 代码，从某种角度来说，Lisp 处于直接和机器指令之间转换的层次，和现在常见的计算机的汇编是类似的。但说 Lisp Machin 用 Lisp 做汇编是不严谨的，因为 Lisp Machine 也有自己的汇编语言。\\n\\n2. Lisp Machine 出现的背景是 16 位处理器向 32 位的迁移，主流 32 位处理器上运行的 Lisp 实现性能不理想，才有了 Lisp Machine 这一构想。当时的 Lisp Machine 有两大派系，MIT 和 Xerox ，分别对应当时两大主流方言 MacLisp 和 INTERLISP。我对 Xerox Lisp Machin 了解不多，以下主要基于 MIT Lisp Machine 的设计。\\n\\n3. (MIT) Lisp Machine 的处理器实际就是个栈机器，Lisp 代码依次转化为栈操作执行：参数先依次压入栈，供计算指令调用，执行结果输出到返回栈。函数内部的函数调用就是建立一个新的栈帧，压入参数，输出结果到返回栈。一些特殊的函数直接实现成机器指令，从 destination 接受参数直接输出到返回栈。\\n\\n4. Lisp Machine 设计成熟时期，用 Lisp Machine 做数值运算比在当时 32 位处理器上的 Fortran 还快。最大的特色其实是支持大屏图形界面和鼠标。\\n\\n5. 很显然这种微处理器是复杂指令集设计，在现代已经过气了。后来基本等于免费分发的 Unix 配合摩托罗拉之类的廉价硬件平台很快取代了几十万美元一台的 Lisp Machine，导致本就经营不善的最大 Lisp Machine 公司之一 Symbolics 挂了，对业界又造成了打击。\\n\\n6. 说 Lisp Machine 没有进程，Lisp 不适合用来描述操作系统云云，至少对于后期的 Lisp Machin 来说是错误的。Symbolics Lisp Machine 用物件导向设计操作系统，包括进程在内几乎所有系统构建抽象成物件，Lisp Machine Manual 的原句就是进程相当于虚拟 CPU。Unix 的一切皆文件就是一种弱层次的物件导向设计，Mach 微内核更是大量采用了物件导向设计，就连 Linux 都不可避免引入了 C艹，明显同时具有高级抽象和底层硬件的 Lisp Machin Lisp 是很合适的，而内核态和用户态的访问直接由定义方法来控制，这些问题在 Lisp Machine 还没过气之前都已经解决了。\\n\\n7. 两个时代硬件的比较，Lisp Machine 晚期在 DEC Alpha 工作站上用虚拟机运行 Lisp Machine，做一次内存整理花费约 40 分钟，将同样的虚拟机移植到 Linux 后在 Core i7 四核上运行做相同操作，只要不到一分钟。\\n\\nReferences:\\n\\n[1] Guy Steele and Richard Gabriel, The Evolution of Lisp\\n\\n[2] Richard Stallman, Daniel Weinreb and David Moon, Lisp Machine Manual, 6th Edition\\n"}'));jctx.push(JSON.parse('{"id": "190801", "tag": "data", "text": "# 数据库和数仓的历史\\n\\n数据库是计算机最早的应用系统，阿波罗计划时就有了数据库原型，这便是1968年的IBM ICS系统，69年改名为IMS/360（层次型数据库）。70年，IBM的研究员Codd提出了关系型模型，虽然关系型理论是IBM提出的，但出于产品惯性IBM没有及时跟进，反而是1983年Oracle率先向市场推广，虽然同年稍晚IBM也发布了DB2产品，但在市场上显然是Oracle胜了。\\n\\n和数据库相关但又有区别的数据仓库（Data Warehouse），概念早在1970年代就有探讨，Inmon在Kimball分别在1992和1996年出版关于数仓的专著，可以认为数仓正式成型。Inmon定义数仓是一个面向主题的（Subject Oriented）、集成的（Integrate）、相对稳定的（Non-Volatile）、反映历史变化（Time Variant）的数据集合，用于支持管理决策。或者说就是建立围绕主题，并最终要挖掘出主题间关系的库。落地到具体行业，一定要对行业关心的主题建立好模型。支持构建完整数仓的技术有：清洗、集成、OLAP。\\n\\n* OLTP: 联机事务处理， 关系型数据库(Oracle、MySQL)多属于此类，擅长记录发生的业务内容，多小批量写入，要保证事务性。设计时强调三范式，表结构紧凑，避免冗余\\n* OLAP: 联机分析处理，随着OLTP的数据越来越多，如何快速地分析这些数据就变得重要起来，这个概念是Codd在1993年提出的，在设计上和OLTP不同，往往把多张表JOIN成宽表，保留一定的冗余，来提升分析和处理速度，并不在意事务能力。分析使用的技术，多为统计学或机器学习方法。\\n\\n数据仓库的来源分为非结构化和结构化数据。非结构化数据要先经NLP提取变为结构化，结构化数据可以用机器学习的方式做分类、聚类，又或者按统计学的方式进行提取。\\n\\n数仓的建模方式有多种，国内主流的是阿里推崇的维度建模(kimball)，有星形模型(一个事实表和多个维表，没有二级维表)和雪花模型(在星形基础上允许二级甚至更多级维表)。\\n\\n## MPP与SQL on Hadoop\\n\\n支撑数仓的软件有很多，其中一个大类统称MPP，比较商业的产品是金融领域的TeraData，但价格太贵，多见的是GreenPlum，是基于Postgre开发的主从式分布数据库，master负责调度segment负责执行。引申一句GP最初是EMC开发的，买存储送GP，配合EMC的存储和售后，在银行领域很有竞争力。\\n\\nMPP的代表产品有：Vertica/Redshift(Paracel，被Amazon买下了源码的license后变成Redshift)/Greenplum。仔细观察不难发现，这三者其实有非常很多相同点：\\n\\n1. 全部基于PostgreSQL\\n2. 都是基于列的存储(Columnar Storage)\\n3. 操作都是以Scan为基础，依赖Compression来提供性能的优化\\n\\nMPP为了速度，需要将数据导入做一定处理，整理成优化的格式以便加速。这样做的后果就是，它们的存储类似一个黑盒，数据进去之后很难被别的系统直接读取。\\n\\n还有另一类统称SQL on Hadoop，实现有Impala，Hive，SparkSQL，Presto等。这类方案不负责存储，或者说是存算分离，计算基于MapReduce/RDD机制，水平扩展性很强。但是这种方案是多种系统共用一个HDFS存储空间，不可能做非常彻底的优化时优化，典型的就是CBO优化程度会弱一些。\\n\\nSQL-on-Hadoop架构可以分为两类：\\n\\n1. SQL over Processing Framework：例如SparkSQL，Drill/Datameer，Presto，Impala\\n2. OLAP over Hadoop：例如Kylin，Druid，AtScale，Kyvos\\n\\nSQL over Processing Framework系统的共同特点是“Hadoop通用计算框架+SQL解析引擎”，存储层、执行引擎层、SQL解析层三者分离，可以方便替换执行引擎，对使用者而言，同一份数据可以采用不同并行执行引擎来分析。优点是灵活性高，支持细粒度容错，集群扩展性好，缺点是效率无法保证。\\n\\nOLAP over Hadoop系统的共同特点是预计算，即数据都以时间序列的方式进入系统并经过数据预聚合和建立索引，因为是预计算，所以应对多维查询时速度非常快（计算时间复杂度O(1)）且稳定，支持高并发，支持集群扩展。缺点是灵活性较差。\\n\\nMPP原理朴素上说就是分治思想，均分task。\\n然后每个worker/segment上做的都是同样的sub-task，pipeline方式执行，理想情况下性能是非常优异的。\\n但是很容易受到慢worker（它是最长路径）和interconnect的影响，所以scalability不佳，集群规模在十几个节点后就没有性能提升了（甚至还可能下降）。\\n\\nHADOOP原理更类似batch processing，更细粒度切分task，worker能者多劳（每个worker上执行的任务可以是不平均，不一致的）。\\n单独worker看，性能不及MPP，但是胜在scalability优异，几百个节点是没问题的，在集群性上远胜MPP。\\n\\nMPP和SQL on Hadoop的最大区别在于，MPP架构是Full-SQL compatiable的，实现不局限于将Query分解为一连串的job去执行。并且由于每一列的数据类型进行了特定的压缩和编码(比如run-length/delta/bytecoding)，能做的优化要比单纯的MapReduce多很多，效率自然也要高不少。相较于SQL on Hadoop，MPP更适合做interactive ad-hoc analysis，前者则更适用于对于海量数据做批处理或者需要使用UDF(自定义函数)的场景。"}'));jctx.push(JSON.parse('{"id": "190808", "tag": "data", "text": "# SQL语言梳理\\n\\n## 历史脉络\\n\\n首先说一下这帮人当时都在IBM，大概因为大规模的数据应用主要的受众是商业公司，刚好和IBM主业匹配。Codd在1970年发表了关系代数论文，引发IBM在1973年立项System R来研究可行性，然后Donald Chamberlin和Raymond Boyce于1974年发表了SEQUEL语言，但因命名重复所以改名为SQL，Boyce在发表论文后不久死于动脉瘤，后来的荣誉都给了Chamberlin。在这期间Jim Gray确立了事务机制、粒度锁系统和隔离级别。差不多时间，Berkeley的Stonebraker开发的Ingres系统用的是QUEL语言，直到后来他的学生开发Postgres后才换成SQL语言。以上这些人中，除了SQL论文的成色稍次，其他3人都获得了图灵奖。在之后的1975年，台湾的Peter陈品山，发表了虽然不是基于关系模型，但对业界影响很大的ER模型论文。\\n\\n## 理论依据\\n\\nSQL背后的理论支撑是集合论、关系代数和一阶谓词逻辑（Codd的原始论文曾设想二阶谓词，因太复杂放弃了）。操作的结果是封闭的，即输入和输出都是关系，这也是查询的结果可以作为插入动作的输入的原因。在时间的发展上，关系是在层次模型和网络模型之后提出的，它的目标就是避免出现地址概念，达到彻底的逻辑和物理分离。因此SQL语言没有变量（地址）的概念，AS只能表达不可变引用。\\n\\n由于关系代数是三值逻辑，SQL继承三值逻辑后，计算中就必然会存在NULL（严格地说是NULL有未知和不适用两种含义，最原始的也是四值逻辑，但后来被合并，所以仍是三值）。NULL并不是值，只是一个用于填充的标记，所以对它做比较是无意义的，只能IS NULL判断。NULL在计算时会引发propagate，甚至NULL/0也是NULL。AND和OR等短路运算时，NULL的优先级介于TRUE和FALSE中间，即TRUE OR NULL = TRUE；FALSE AND NULL = FALSE。\\n\\n虽然很多时候都提倡用NOT NULL，但由于NULL的概念根植于SQL的底层，在外连接或CUBE/ROLLUP的GROUP BY时，还是会不经意间引入NULL。\\n\\nSQL基于的关系代数，严格的说是Relation Bag Algebra，并不是Codd最原始的Set定义，差异在于Bag允许关系数据重复，而Set的数据必须唯一，所以有DISTINCT和ALL这类关键词来指定结果要set或bag。但是SQL和关系代数有几个很不一致的地方，比如SQL的SELECT对应的关系代数是PROJECT，SQL的WHERE和HAVING才对应关系代数的SELECT。\\n\\n关系代数的核心操作只有5种，分别是并、差、积、选择、投影，操作的都是元组。所有的SQL语句最后都能用这5种操作组合完成。比如一个嵌套子查询可以等价转换成一个连接（join）操作。UPDATE操作看起来是对字段(Attribute)的修改，但严格来说，是用一条记录替换掉原来的记录，本质还是行级。\\n\\n## 功能分类\\n\\nSQL规范定义了几种不同领域的操作，使用的指令不同。虽然最常见的是增删改查，但从完整的BNF方法列表来看，其它几种分类占的比重更大。\\n\\n* DDL - 数据定义语言(CREATE，ALTER，DROP，DECLARE)\\n* DML - 数据操纵语言(SELECT，DELETE，UPDATE，INSERT)\\n* DCL - 数据控制语言(GRANT，REVOKE，COMMIT，ROLLBACK)\\n\\n对语法有疑问时，查BNF定义是最好的，比如查询语句后面如果是子查询必须有别名，但如果是关联就不需要别名，似乎也没什么理由，就是文法这么规定的。\\n\\n## 表达式类型\\n\\n* 表表达式：对表的操作，FROM、WHERE、GROUP BY、HAVING\\n* 条件表达式：专门用在WHERE表达式，有AND、OR、IN、LIKE\\n* 标题表达式：如各种算术运算符、CASE\\n\\n## 值语法和类型\\n\\n所有的值都是用圆括号`()`包起，可以出现在很多位置，比如VALUES后的字面量，或是FROM后的子查询，甚至在SELECT、WHERE等出现变量名的位置。值有两种类型，标量和集合。\\n\\n## 查询的顺序\\n\\nSELECT查询涉及众多关键字，最核心的有3个：JOIN、WHERE、GROUP BY。执行顺序并不是从前到后，正确的顺序如下\\n\\n* 7 SELECT 8 DISTINCT 10 TOP NUMBER\\n* 1 FROM 3 JOIN\\n* 2 ON 4 WHERE\\n* 5 GROUP BY 6 HAVING\\n* 9 ORDER BY\\n\\n在不影响结果的前提下，优化器对顺序会做微调，比如 FROM a LEFT JOIN b ON a.x=b.x WHERE a.name=x and b.age=x，WHERE的a语句会先执行，再做JOIN，最后再做WHERE的b语句，术语叫Predicate Pushdown Filter。因为对LEFT JOIN来说，将右表的过滤放到JOIN前，不会影响JOIN的条数，这就和WHERE原始的后置语义不同，因此不会被优化；如果想优化也很简单，将WHERE中对右表的过滤，放到ON条件来做。\\n\\n## 横向与纵向操作\\n\\nSQL是对关系的操作，这种操作有两个方向，横向的代表是JOIN，而纵向的代表是GROUP BY。JOIN内容太多，单开一篇讲。\\n\\n## GROUP BY 层级和阶\\n\\n引入了谓词逻辑中阶(order)的概念，最明显体现在GROUP BY上。一但用了GROUP BY，操作对象就由0阶的行，变为1阶的集合，不同的阶需要用不同的谓词去操作。典型的WHERE操作0阶的行，而HAVING操作1阶的集合，其背后是有严格的理论支撑的。\\n\\nGROUP BY后可跟一到多个关键字，将集合按这些关键字形成子集，每个子集内只含一种这些关键字值的组合，此时其它值也在，但因为阶变了，不能显示地查看其它值明细（换句话说，其它值都在子集内，但不能直接查看），但是部分数据库提供了`group_concat`函数，将所有明细值表示成一个字符串，相当于把明细值做了聚合。\\n\\n除了JOIN和GROUP外，IN子查询用在嵌套树状查找很有用\\n\\n### 高级分组cube和rollup\\n\\n先看这个语句`GROUP BY a,b GROUPING SETS ( (a,b),a)`，怎么理解？相当于`GROUP BY a,b UNION GROUP BY a`。在这个基础上，再来看cube和rollup。\\n\\n`GROUP BY a,b WITH CUBE`等效于GROUPING SETS( (a,b), a, b, ())，会严重膨胀。\\n\\n`GROUP BY a,b WITH ROLLUP`等效于GROUPING SETS( (a,b), a, ())，从左向右下钻。\\n\\n## NULL的比较与排序\\n\\n排序时如果有多个字段，可以为每个字段分别指定ASC或DESC，默认升序ASC。原理上NULL是不能排序的，在max/min函数也会忽视NULL值（除非数据全部是NULL），甚至count如果指定列名，而这里面如果有NULL值，也不会计入总数。但是ORDER BY的时候，NULL值会在结果里显示出来。排序的结果是实现相关，主流的几种数据库行为分为两派\\n\\n* NULL比任何值都小： 包括MySQL、SQLServer、SQLite，表现出的行为是，ASC时，NULL值最前，DESC时NULL值最后\\n* NULL比任何值都大： 包括Oracle和PostgresQL\\n\\n为弥补未定义NULL排序的缺失，SQL规范增补了NULLS FIRST或NULLS LAST关键字，通过放在ASC或DESC后来改变行为，遗憾的是只有Oracle、PG以及3.30版本后的SQLite支持。\\n\\n## 索引\\n\\nwhere条件如果是OR，索引不起作用。联合索引符合最左原则，即索引是A,B,C时，支持A或AB或ABC，其它没有作用。\\n\\n## 窗口函数\\n\\nSQL99规范定义了窗口函数，反而最常见的MySQL直到8.0版本才支持。窗口函数有点类似GROUP BY，但由于它是函数，并不会改变结果的阶，因此可以作用在每一行上。\\n\\n窗口函数有两大类：聚合函数和排序函数，聚合函数和GROUP BY类似，也是SUM、MAX这些，但可以添加到每一行上。\\n\\n排序函数用得比较多，有ROW_NUMBER、RANK、DENSE_RANK，结合分组能知道在每个分组内的顺序，进而做一些分析操作，这是GROUP BY不具备的。\\n\\n## UDTF与侧视\\n\\nSQL处理二维表，意味着列只能是标量。但如果列就是矢量，或者想作为向量用，就引入了UDTF和与之配套的LATERAL VIEW语法。\\n\\n设想一条记录，主键是身份证，接着一列手机号，该列的定义是逗号隔开的字符串，怎么转换成每行一个手机号呢？\\n\\n首先用split把逗号拼接的字符串向量化成array，但这时还是在一行里，要进一步用explode把这行炸开，但是UDTF炸开后的值是个Table，不能用select，所以就要用如下语法\\n\\n```\\nfrom t\\nlateral view explode(split(col1, \';\')) table_identify as col11\\nlateral view explode(split(col2, \',\')) table_identify as col22\\n```\\n\\n直观解释一下，对一张表t，选择其中若干行炸开，所以取名lateral横向view关键字，紧接着跟一个UDTF函数产生的临时表，带一个临时表别名，这个表别名的可见范围只在lateral view这行，多行可以取一样的别名，因为最终要的还是列，所以要as一个列名，给最外层的SELECT用。每次炸开都会触发一次行级别的笛卡尔积，炸开列越多性能越差。\\n"}'));jctx.push(JSON.parse('{"id": "190817", "tag": "os", "text": "# 协程剖析\\n\\n一句话定义：协程是可以被中止和恢复的函数。协程的历史很早，随着非阻塞(NonBlock)操作的日渐普遍，每一次非阻塞指令都配套回调，代码可读性很差，于是协程就重新被人捡起。\\n\\n协程可以从有栈/无栈，以及对称/非对称角度划分为四象限\\n\\n* 有栈/无栈: 区别在于是否有自己的调用栈来进行函数调用等操作，一般来说无栈性能好，有栈易用\\n* 对称/非对称: 区别在于是否能自由的转换控制权。非对称易理解、好用，对称灵活但心智负担会高一些\\n\\n## 有栈和无栈\\n\\n有栈协程可以随意的切换, 因为所有状态都在协程内部, 并且可以并行 , 存在中间状态比如寄存器的计算结果啥的, 切换要很小心, 但是粒度更细。无栈协程只能手动切换, 不过效率要高, 不用管复杂的寄存器状态, 切换的控制权也在用户手中\\n\\ncoroutine是个很宽泛的概念，async/await也属于coroutine的一种。但是问题是拿async/await和stackful coroutine比较。所谓stackful是指每个coroutine有独立的运行栈，比如每个goroutine会分配一个4k的内存来做为运行栈，切换goroutine的时候运行栈也会切换。stackful的好处在于这种coroutine是完整的，coroutine可以嵌套、循环。\\n\\n与stackful对应的是stackless coroutine，比如generator,continuation，这类coroutine不需要分配单独的栈空间，coroutine状态保存在闭包里，但缺点是功能比较弱，不能被嵌套调用，也没办法和异步函数配合使用进行控制流的调度，所以基本上没办法跟stackful coroutine做比较。\\n\\n但是async/await的出现，实现了基于stackless coroutine的完整coroutine。在特性上已经非常接近stackful coroutine了，不但可以嵌套使用也可以支持try catch。所以是不是可以认为async/await是一个更好的方案？\\n\\n有个匿名用户在纠结并发需要多线程，这里我统一做个回复。很多人是从多核时代入行的，看到的异步框架都是使用了线程池，所以想当然的认为并发必须依赖多线程去处理，更有人连[[并发和并行]]的概念都搞混，认为单核CPU就不能并发了。实际上并发这个概念在没有多核CPU甚至没有线程的年代（早期的Linux是没有线程的）就有了。并发经常与IO联用，IO是独立于CPU的设备，IO设备通常远远慢于CPU，所以引入了并发的概念，让CPU可以一次性发起多个IO操作而不用等待IO设备做完一个操作再做令一个。怎么实现呢？原理就是非阻塞操作+事件通知，在核心态非阻塞操作对应的是读写端口和DMA，而事件通知则有专门的术语叫中断响应。过程有2种\\n\\n1. IO设备发起中断，告诉CPU现在可以进行IO操作，然后CPU进行相应的操作\\n1. CPU先发起IO操作，然后IO设备完成处理后发起中断告诉CPU操作完成\\n\\n核心态是不存在多线程这种概念的，一切都是异步的事件驱动（中断响应），线程是核心给用户态提供的高层概念，线程本身也依赖中断来进行调度。早期的用户态IO并发处理是用poll(select)模型去轮询IO状态，然后发起相应的IO操作，称之为事件响应式的异步模型，这种方式并不容易使用，所以又发展出了阻塞式IO操作，让逻辑挂起并等待IO完成，为了让阻塞式IO能够并发就必须依赖多线程或者多进程模型来实现。但是线程的开销是非常大的，当遇到大规模并发的时候多线程模型就无法胜任了。所以大规模并发时我们又退回去使用事件响应，epoll在本质上还是poll模型，只是在算法上优化了实现，此时只用单线程就可以处理上万的并发请求了。\\n\\n直到多核CPU的出现，我们发现只用一个线程无法发挥多核CPU的威力，所以再次引入线程池来分摊IO操作的CPU消耗，甚至CPU的中断响应也可以由多个核来分摊执行，此时的线程数量是大致等于CPU的核心数而远小于并发IO数的（这时CPU能处理百万级的并发），线程的引入完全是为了负载均衡而跟并发没有关系。所以不管是用select/epoll/iocp在逻辑层都绕不开基于事件响应的异步操作，面对异步逻辑本身的复杂性，我们才引入了async/await以及coroutine来降低复杂性。\\n\\n### 有栈协程\\n\\n有栈协程要保存堆栈, 一般来说有俩种做法:\\n\\n1. 采用操作系统提供的api 类似 ucontext 或者 setjump longjump\\n1. 用汇编操控寄存器保存状态\\n\\n从上面例子看出，用了OS自带函数做所有寄存器(EIP)和栈上变量的保存恢复，故名有栈协议。 下面给一个C语言实现的模拟操作\\n\\n```\\nvoid coro_func(int& step) {\\n  switch (step) {\\n    case -1:\\n      if (step) {\\n      terminate_coroutine:\\n        step = -1;\\n        goto bail_out_of_coroutine;\\n      bail_out_of_coroutine:\\n        break;\\n      }\\n      else\\n    case 0:\\n      worker(1);\\n      for (step = 1; ;) {\\n        if (step == 0) {\\n    case 1:\\n      break;\\n        }\\n        goto bail_out_of_coroutine;\\n      }\\n      worker(2);\\n      for (step = 2; ;) {\\n        if (step == 0) {\\n    case 2:\\n      break;\\n        }\\n        goto bail_out_of_coroutine;\\n      }\\n  }\\n}\\n```\\n\\n可以看出，把阻塞操作拆成两步，在执行完NonBlock后更新步进值并退出，下次自然就能回到上次的点继续。不依赖系统调用。\\n\\n### 无栈协程\\n\\n无栈协程的实现, 要几个条件:\\n\\n1. 栈帧内保存的不是状态而是指向状态的指针\\n1. 所有帧的状态保存在堆上\\n\\n为什么说第二点比较重要, 因为理解了第二点就发现, 其实根本不需要上下文切换, 因为全局的上下文就没变过, 改变他们的调用关系就行(栈)\\n\\n## 对称和非对称\\n\\n用yield/resume风格实现流程切换，叫非对称协程。在让出运行权后并不知道接下来是谁运行。\\n\\n对称协程，类似 `f() { core.transfer(g) }`，在函数f运行过程中直接切换到函数g上，但是这种方式写出的代码破坏了模块性，要关心外部的运行流程很难维护。因此目前能见到的协程实现都是非对称。\\n\\n最后可以比较下[[进程线程和协程的切换开销]]"}'));jctx.push(JSON.parse('{"id": "190820", "tag": "lang", "text": "# 类型理论\\n\\n## 变量类型\\n\\n对变量来说有几个属性：类型，可变性，作用域\\n\\n1. 类型，动态语言不需要事先声明，所以这一点是没有的。C或Java需要，(C++11的auto看似做了简化，其实只是给编译器的一个提示，还是会转变成真实的类型再编译)\\n\\n2. 可变性，纯函数式比如Haskell是不可变的，也就不需要这个修饰。但大量其它语言还是需要的，比较多见的是const/volatile关键字，ES6也引入const了，Lua5.4引入const，Scala是用var和val来区分变量是可更改还是恒定性\\n\\n3. 作用域，Lua语言在声明一个变量时，是可以指定local的，表示这是一个位于当前chunk的变量，如果没有，则变量被声明到了全局空间，语义上对应js中的var关键字。\\n\\nlocal和当前函数的作用域在一起，因此访问速度也最快，全局变量则要依次向上查询，速度显然要慢一些。所以很多Lua代码，都会在开始处用local方式把全局重新定义一遍，目的就是为了提高速度。对于默认声明变量都不在局部域这点，我很不理解，为什么可以在一个函数内部声明一个外部的变量？而且显示调用local声明变量的方式，还可以声明一个变量但不使用。因为这本质上只是预留了一块空间，无非是空间的位置在哪里而已。\\n\\nRnRS中有这样一句：对变量的每一次使用都对应于该变量在词法上的一个明显的绑定，因此只声明变量而不使用的行为，在Scheme中是不允许的。\\n\\n纯函数式理论上是不是需要声明变量的，一切都在计算中传递。但冯诺依曼的计算机模型却让变量成为了计算的基础。另外全部做成在计算中传递也比较难以书写，于是Scheme中也保留了局部的变量绑定语法，就是let系。它的作用域就是局部的，可以认为是必须放在函数开头处，且必须显示声明绑定关系的local语句。个人以为这种规定比js中随意放置var声明要严谨得多。\\n\\n再提一点RnRS对define的定义是Top Level Definition，而let系是Internal Definition。我用TinyScheme测试，是可以在lambda内部使用define语句，但kawa就通不过。考虑到Tiny毕竟是一个极小的实现，对一些限制也不严格，因此对define的使用还是在全局较好。\\n\\nnull最好是提升到类型级别，而不是作为特殊值，编译器会推导保证类型正确，而值只能在runtime时直接崩溃。\\n\\nRust 错误处理本质上还是基于返回值的，很多基于返回值做错误处理的语言是将错误直接硬编码到正确值上，或者返回两个值，前者例如 C 在很多时候都是直接把正常情况永远不会出现的值作为错误值，后者例如 Go 同时返回两个值来进行错误处理。而 Rust 则将两个可能的值用 enum 类型表示，enum 是和类型(sum type)，表示两个可能的值一次只能取一个。\\n\\n## ADT\\n\\n函数式语言的代数数据类型ADT(algebraic data type)，简单的说就是组合类型。不要和抽象类型abstract data type混淆。\\n\\nsum type是tagged union(值域是每种field的sum)，product type典型例子是tuple或struct(值域是每种field的cartesian product)。\\n\\ntuple强调不可变，python用tuple作为函数的出入参，利用的就是immutable，而且因为不可变，一定程度上就具备hashable特质。\\n\\n拓展:思考元组、函数参数、函数返回值，命名参数和 Record 以及 list 的关系(比如像 SML 那样设计)\\n\\n## symbol和string\\n\\n在lisp中符号的历史比字符串更加久远，在LISP 1.5中SYMBOL 和 CONS是最重要的数据类型。\\n\\n> 数字是一种特殊的符号。——摘自《LISP 1.5 Programmer\'s Manual》\\n\\n而字符串是后来加上的。用来表示字符序列的概念，至此，再用SYMBOL的NAME来表示字符序列已然成为不好的行为了。\\n\\n举个例子`\'abc`作为一个原子（atom），不可以拆开；而`\\"abc\\"`是复合数据，可以提取出\\"a\\"。因此symbol的存在大大扩充了原子世界，以便于写符号计算和元编程。\\n\\n字符串是无结构的，符号是有结构的，符号中的数字类型也不是以字符串形式储存的而是单纯的数字，原子的符号受到标识符规则的限制而字符串没有。\\n\\n换句话来说不是任意一段字符串都可以找到相对应的符号。"}'));jctx.push(JSON.parse('{"id": "190821", "tag": "os", "text": "# BIOS启动地址0x7C00的来源\\n\\n这要追溯到1981年的IBM PC 5150，这货的内存是32KB。\\n\\n那个年代，内存是个金贵的东西，要省着用，当时的程序员，可比今天的码农牛逼，为了省点儿资源，各种奇技淫巧。我一直觉得，那个年代的程序员，才有资格叫程序员。\\n\\n0x7C00其实就是32K内存的倒数1024个字节。\\n\\nMBR大小是硬盘的一个扇区，也就是512字节，从0x7C00开始的1024个字节中，前512字节就是用来供BIOS加载MBR的，剩下的后512字节，用来存放MBR执行时产生的数据。\\n\\n等于是MBR的专属内存。\\n\\n为什么要放在最后，这是为了减少内存碎片，给操作系统留下更多空间。\\n\\n偷偷告诉你，其实最后这1024字节，在系统启动后，还是会被操作系统用到的。\\n\\n为什么？因为MBR加载完操作系统后，就再也用不到了。\\n"}'));jctx.push(JSON.parse('{"id": "190901", "tag": "net", "text": "# traceroute原理和ICMP\\n\\n项目中遇到ping返回time to live exceeded，即TTL超出，展开讲讲。\\n\\nping是基于ICMP协议，它是附在IP协议的数据段的一种应用协议，可以类比为HTTP之于TCP，由于是二层协议所以没有端口。IP协议共20字节，专门留了1个字节表示TTL，源端在发出时会预设一个值，比如64或128，每过一跳就减1，归零时如果还没到dst就会报ICMP错（不管请求的是TCP或UPD甚至就是ICMP协议）。目的是防止IP在路由的过程中遇到环，通过这种方式阻断循环路由。\\n\\nIP层的典型协议编码\\n\\n* ICMP: 1\\n* TCP:  6\\n* UDP:  17\\n\\nICMP有8字节头，如果是request再多32(windows)或48(android)字节的无意义数据。\\n\\n利用IP的TTL特性，可以检测到dst的所有节点。原理就是依次从源端向dst发出TTL只有1、2、3...的ICMP包，TTL为1的包在第一个转发节点会回复ICMP错，TTL为2的包在第二个转发节点回复ICMP错，直到最后一个成功到达的包，通过这种方式就能得到dst的完整链路。\\n\\n额外说下，正常要发送ICMP要用`SOCK_RAW`，但apple的系统要用`socket(AF_INET, SOCK_DGRAM, IPPROTO_ICMP);`。\\n\\n## 实战连接github\\n\\n在Alpine的虚拟机中，git clone失败，问题分析后记录如下。\\n\\n最开始怀疑是路由错误，但包可以下载说明不是这个问题。又尝试ping 163仍然失败，看来是DNS问题，虚拟机的路由 /etc/resolv.conf 改为家中路由的地址，可以ping通163，但github仍失败。\\n\\n浏览器可以上github，说明没被墙，用独立的域名解析网站分析，对应多个IP，逐个尝试发现部分可以部分会超时。说明浏览器会尝试多次，而命令行只试第一个。\\n\\n在/etc/hosts手动加入条目解决。"}'));jctx.push(JSON.parse('{"id": "190902", "tag": "os", "text": "# Fushsia：一次对操作系统的重构\\n\\nFushsia是对Windows操作系统的一次重构。\\n\\nObject的组织方式已经深深的刻进了Windows的骨髓里，同为微内核设计的Fushsia毫不避讳的继承了这个设计。\\n\\n操作系统的发展过程就是Windows和Linux不断的从不同的角度发现自己的局限性，并且从各自的角度出发来试图解决这些局限性的过程。在这个发展的过程，无数的弥补措施和新机制被发明，但是Windows和Linux都要兼容老的东西。Windows演进的过程积累下来的最重要的经验就是微内核应该怎么设计，Linux演进的过程积累下来的主要是稳定性和隔离行等容器化的要求，这一方面Windows也在不断的跟进。Android在内核之外设计了一个大型的操作系统组件，Android与Linux的配合是如此的丑陋，因为Android相当于想在应用层做掉一个内核不该做的事情。\\n\\n每一个操作系统都在痛苦的迭代，各自面临着自己的痛点。Linux的世界对于权限和隔离性非常重视，但是apparmor，selinux，cgroup等后来逐渐添加的机制又与最初的设计那么的不相符。安全方面既然发现ACL的优势，为何还要用户的权限概念？隔离性记性不同的资源可以分组隔离，为什么还要统一的fork继承？Windows以图形见长，窗口和游戏性是Windows的公认优势，那他的优势又是如何塑造的？又如何打造一个类似的呢？简单的说是因为驱动闭源，但是深层原因还是比较复杂。\\n\\nAndroid像是一个试验性系统，他希望达到Windows在图形方面（宽泛的说是硬件支持）上的优势，同时又羡慕Linux的富功能集。他从一开始就知道自己不会长期依赖Linux，否则java这种架构就不会被采纳。如果我要评价Android，就是Android更多的是一个架构层面的DEMO，验证的是操作系统的架构设计思想。至于实现，差不多能支撑这个架构设计就好了。验证这个过程，他的内核只能采用Linux，没有更好的选择。但是谷歌一直认为Linux做了太多不该他做的事情了（很多人都这么认为），其实根本原因还是认为过度的开源协议妨碍其他人赚钱了。\\n\\nFushsia一出手就是一个Android的下层替换。但是这个替换并不是代码上的，而是架构层面的。谷歌在战略方向比较少走废棋，他希望能在各个领域进行推进的同时，大家都尽可能的朝向同一个大目标前进。这个目标，就是一个开源形式的垄断Windows。在整个开源世界里，谷歌希望上下游通吃。这种做法必须要各个细分领域都要有谷歌的拳头开源产品，互相依促，互相借鉴，互相帮扶，共同前进。\\n\\n首选第一个选择是微内核还是宏内核。这个基本没有任何争议。作为一个公司之间的玩具，互相解耦是第一位的。想要快速产业化，允许参与者独立变更，微内核几乎是唯一选择。宏内核在Linus之前，没有人敢想到能成功。直到今天，这个宏内核能走多远，也没有人能把握。宏内核需要一个独裁者，他提纲挈领，乾纲独断。在你走偏的时候，能直接把你的路封掉。整个Linux世界，离开Linus本身，没有任何人有这种威信（想象一下皇帝驾崩三个儿子怎么治理国家）。\\n\\n部门之间，公司之间，都是微内核更合理。微内核是一种社会性的内核，宏内核是一个技术性的内核。要说性能，微内核无论如何也不可能击败宏内核，因为宏内核相当于任何一个细分变更都需要整合测试。任何一个细分都在整体的框架内变更，包括架构风格甚至编码风格。\\n\\n所以很容易想到的理想操作系统的样子是Android的设计架构+微内核。这个微内核就直接借鉴Windows的成功经验就好，Windows的设计代表目前商业操作系统的最高水平，没有产品层面经久不衰的成功经验的任何团队，都不会敢在微内核的设计上抛弃Windows的设计，最多是先学习，后想办法超越。包括现在的鸿蒙，其微内核的架构也一定是类似的。\\n\\nWindows的典型微内核架构是Object设计。内核管理的资源都是一个一个的Object，打开每个Object都有对应的Handle。微内核中还必须要组织进程线程之类的调度单元，这种操作系统一路发展下来沉淀出来的架构不可能被一个新系统直接抛弃，除非他想像IBM 360一样的下场。安全性是附加在Object上的。微内核包括的要保证是必须要包括并且只能被包括的，典型的是ring 3的特权代码。为了达到所有ring3代码在微内核运行的目标，很多周边架构就必须要设计进内核。比如进程线程等是CPU的直接资源使用单元，调度这个事情到底是设计到用户空间还是内核空间？这个并不一定有确定的答案，但是Fushsia选择了放在内核，那么就代表了进程间的通信机制也必须要在内核里面。Windows已经增加用户空间的调度接口，但是也并不意味着微内核就撒手不管了。操作系统是一个在安全性，易用性和符合社会组织方式的发展过程中一起动态变化的一个过程。\\n\\nWindows下一个非常精彩的设计是Event，Linux下类似的设计是signal。两个可以说完全不一样，但是从哲学层面又有很多相似的地方。谷歌经过深入的思考和实践，认为两者是可以结合的。状态，事件，信号这三个东西，本身可以抽象为Object和Signal，Event三种互相结合的模型。每个Object都有32个信号集，Event也是一个Object，可以说是最简单的Object，他里面只有32个信号集。所以的Object的信号集的变化就代表他们状态的变化。也就是说，信号与状态协调成一个概念，就是一个Object所持有的信号集，信号的发生就可以是事件的发生，几个不同的设计被谷歌经过精简和联动设计，提取他们的核心本质，保留他们的各自优点，就形成了Fushsia的Object和Signal模型。\\n\\nWindows下的安全也是Object的属性，Fushsia在微内核层次完全抛弃了Linux的用户权限概念，改为了Windows的Object权限。甚至更激进的让整个虚拟化建立在Object权限之上（更确切的说是Object对应的HANDLE）。Linux下的最大抽象是一切皆文件，微内核的经验是一切皆Object，包括进程这个单位。很多Fushsia的系统调用都要传入一个进程的HANDLE，这个HANDLE就决定了这个系统调用有没有权限继续下去。Windows最新的成果是虚拟化和沙箱技术的重度迭代，Fushsia从设计层面就直接做到了。所以说Fushsia更像是一个没有包袱的Windows系统的重构，保留了Windows的大部分优点。\\n\\nFushsia在很多地方有不同的想法。例如Windows中饱受诟病的进程间互写内核成为很多安全问题的摇篮。但是进程间互相传递HANDLE又是Windows下一个很好用的资源传递的功能。在Linux下一个被打开的资源想要传递给另外一个进程，早期除了fork是没有方法的，后面出现了SCM技术，就是通过Unix Domain Socket来直接传递fd。因为你不能默认需要传递资源的环境都是父子进程关系。Linux一个很大的设计问题就是太过依赖父子关系，Windows的问题又是因为太过不依赖父子关系，导致进程间缺乏有效的组织。近期的Windows版本已经很注重进程间关系的组织，或多或少的引入Linux下的进程关系树模型。双方在靠拢的过程中，都有一些逐渐的对原生设计的一些违背。导致整个操作系统看起来不太和谐。这个问题在Android系统中被谷歌刻意的放大了。因为Android系统重度的依赖Binder，Binder是一个试图让各个进程可以很方便的通信交换资源的设计，这个设计对Linux来说是强人所难。对Linux的要求有点过于激烈。Linux对于资源的进程隔离一直是一个很重要的发展方向，Android反其道而行，要求进程之间大门敞开。阅读Binder的代码就能很容易的知道这个系统做的是多么的艰难。反而Binder在Windows上就很容易实现，LPC是如此的高效，进程间可以方便的把自己的HANDLE写入到另外一个进程的内存，资源的传递几乎是没有什么成本的。但是直接写对面进程的内核对于权限和并发又带来了复杂性。所以Fushsia既然是Android架构的落地，自然重度的依赖这个特点。于是Fushsia直接将Golang中成功实践的Channel的思想在Fushsia中落地。传递HANDLE，只需要把HANDLE放进Channel中，原进程自动失去该资源，Channel对面的进程自动获得该资源。\\n\\n这里面就有一个问题，就是内核块本身也是资源，也是可以有HANDLE的。Linux下这种哲学几乎没有体现，Android为了落实他的架构，非常艰难的设计了ashmem，用内存文件系统生硬的设计了带有handle的内核块。Windows的底层内存管理是带有HANDLE的，叫做Section，一个Section是64KB的大块。但是Windows在往上层暴露的时候，仍然没有选择直接把section直接给用户用，而是进行了封装。但是微内核中就是section和其对应的HANDLE的方式。该方式被证明了可以同时管理内存块和文件映射，还可以向上提供更高层的内存分配机制。对于Android对HANDLE资源转移的渴求，没有理由不去学习Windows的Section机制。Fushsia比Windows走的还远，并没有直接采用Windows的section，而是创造性的设计了pager和VMO，VMAR这几种对象。同样是基于对象的，将连续内存和页更灵活的进行了对象的抽象，克服了Windows下的granulary固定的问题（默认64KB）。正是因为更机制化的对象化，整个设计中没有添加策略属性，所以就可以把策略上升到微内核之外。也就是说，操作系统的服务部分应该去负责整个的内存管理，但是内存的颗粒度对应的是内核中的硬件Object。这又是一个对于Windows下内存问题的一个巨大的改善设计。\\n\\nWindows下对任务的组织采用job，进程，线程，纤程四个维度。这一点也是完胜Linux下绕口的Session组，进程组，线程对应内核进程等一大堆看起来非常别扭的添砖加瓦。Fushsia同样是在Windows的基础上进行增强。进程组织成job，进程下有线程。\\n\\nWindows下还有一个让人印象深刻的设计，就是Completion Port。当有大量的事件发生的时候，Completion Port将其抽象为对一个HANDLE的发送数据包消息。对比Linux，类似的事情使用epoll，ppoll等事件集合机制，Completion Port在设计上非常的干净。同样的思想直接被Fushsia采用，并且进行了“本土化”实现。\\n\\n在锁这件事情上，从Linux环境工作久了再切换到Windows，会明显的感觉Windows的设计非常差。Linux作为一个服务端市场占有率第一的操作系统，其对并发问题的处理是非常好的。这里是指技术层面，而不是架构层面。一个最大的优势是Linux把所有的锁实现都抽象成一个对futex系统调用的依赖。Futex的实际意义其实跟锁没有任何关系，只是一个等待条件并且唤醒对应的线程的机制，也就是一个单纯的线程的同步机制。Linux成功的做到让各种各样的锁都依赖一个简单的同步机制来达到实现目的。如此好的抽象正式Fushsia要学习和借鉴的。而Windows下，Mutex，CriticalSection，RWLOCK等使用过程，跨进程还是进程内，不同的性能表现，全部是黑盒并且各自独立的。这显然不是一个微内核该有的样子。但是Windows的微内核是否提供类似futex的机制支撑上层锁的实现，这个我不清楚，没有逆向看过。反正我对Windows下的锁设计是不太喜欢的。\\n\\n调度算法上，操作系统产业界都逐渐的往Fair Scheduling过度，尤其是Linux。Fushsia不能参考Windows的，因为细节没人知道，Linux长期的工程实践已经证明可行性。要知道，早期的Linux调度是动不动就被挨骂的。走到现在积累下来的经验不容易。\\n\\n隔离，是现在Windows和Linux都在面临的一个问题，服务端先对隔离性发起重度需求，需求来的猛烈程度，可以用革命性需求来形容。一时间，Linux虚拟化技术雨后春笋，蓬勃发展。因为Linux先于Windows几年支持了这件事情。一切竟然归因为机缘巧合下Linux一个一度被认为没有什么意义的LXC虚拟化技术的产品化创意。你可以说出一大堆的Linux发展虚拟化的优势，但是没有LXC这种被嫌弃的技术作为铺垫，很可能第一个Docker都没有勇气发布，也就没有之后的春天。Windows近年来奋起直追，试图追赶并超越Linux在虚拟化上的优势，同时伴随自己的UWP技术对隔离性的强烈需求，Windows创造了属于自己的隔离化，并且试图侵蚀Linux的阵地。WSL技术的发展也不遗余力。Fushsia看到了虚拟化的威力，Android的经验已经告诉了谷歌，不但是服务端，客户端对隔离性的要求指挥更强，因为Fushsia的隔离性是一个深入骨髓的设计，体现的非常彻底的整个架构的隔离性重构。典型的，连我们熟知的操作系统级别的文件系统都没有，没有根目录，每个进程为单位只能看到自己的私有目录。完整的去掉了Fork，这一点连Windows都要对之敬畏。Windows还是允许Object在进程创造之间进行继承的，所以说Windows是对fork概念的选择性支持，但是远远没有Linux的全量继承那么过分。Linux下的子进程要对父进程进行减法，一些变动会导致减法经常的没有减到位，就会有很多的安全问题。Fork的设计就不是为了隔离性而设计的，相反，他是完全共享数据甚至逻辑通道的。是一个完全的反隔离设计。Fushsia对此进行了完全的重新设计，新建的进程是干干静静的容器。类似Windows的新技术UWP，完全的沙箱，从底层杜绝了逃逸的可能。Windows也会非常羡慕Fushsia可以没有历史包袱直接进行非常激进纯粹的沙箱设计。\\n\\n其他的类似的领域还有TLS，DMA，日志，中断等。都在在以Linux和Windows，Android使用过程中的一系列需求和他们蹩脚的满足方式找到一个使用和架构的最佳平衡进行的重新设计。可以说Fushsia的Zircon微内核是一个最能匹配当前所有场景应用的架构设计。系统调用数量非常少，Linux一直在精简，但是历史包袱严重，Windows的微内核让人无法区别系统调用的层次，导致API非常混乱。Zircon开了一个好头，提供了系统调用集，但是又把大量的工作交给了服务。服务也是Windows上落地非常好的一个概念，是微内核的必备的匹配组件。Android的架构设计了大量的服务，例如SurfaceFlinger，Zygo等，Linux下缺乏对服务的有效表达。因为宏内核的很多本应该是服务的逻辑单位被做成了内核线程，但是又做的不全。Linux的宏内核自己做了大量的服务，但是又做的不够全，也不可能全，还是需要用户空间的服务来补全。例如systemd等试图统一的把Linux的服务组织起来，但是各种target和启动流程，服务管理，依赖关系，把整个系统搞的无比复杂。我个人对Linux的服务面的设计一直是嗤之以鼻，因为一直有个Windows的对比在。不过Windows的服务也不能说没有问题。很多流氓软件利用服务做了很多影响体验的事情，苹果在这一方面就控制的非常好。可以说Windows是一个设计和实现在架构层面都非常优秀的系统，但是反应速度太慢，远不如Linux的适应性。而且微软公司本身对这个系统的控制性不强，导致有时候用户被流氓软件控制了。而苹果就太强，所有人都感觉被苹果控制了。Android的设计是一个平衡，隔离性，控制性都刚刚好。它可以由一个OEM进行强控制，也可以通用性的完全不控制。是一个很灵活的社会化设计。反观Windows类似概念的企业版，组织能控制的东西非常有限，并且基本上应用也只是公司的内部。类似的组织交付能力，微软不愿意给任何人，所以过度开放。不过近期有所收紧。苹果也是不愿意给任何人，所以采取了过度收紧。\\n\\n谷歌畅想的，是一个能屈能伸，能开源，能赚钱，能让自己赚钱，能让别人赚钱的大社会型架构。谷歌非常深刻的知道开源模式的力量，也知道闭源世界的强大影响力。更多的社会属性是让谷歌脱颖而出的最重要因素。因为他“接地气”。\\n\\n在驱动层面，Zircon甚至开放了用户程序中断处理的系统调用，内核层面相当于直接对驱动进行应用层委派，但是又不是给应用程序，而是给DDK，一个专门的允许闭源闭源驱动存在的框架。Android给谷歌带来的一个最大的收益，是对驱动世界的深入了解。DDK就是这种提取升华，然后重新落地的设计。我一直认为Windows是Zircon的架构学习对象，Linux是一个很好的验证算法逻辑的对象，也是一个不错的教材。Android则是一次尝试，一次架构设计的验证和社会性的学习积累。目标都是最后的大一统设计。整个Fushsia的核心IPC调用接口是FIDL (or \\"Fuchsia Interface Definition Language\\") ，这种描述性的IPC表达方式简直与binder如出一辙。Component，capbility和manifest的概念也正是Android验证的开发模式（capbility这个说不清楚有没有参考Linux）。随着Flutter的逐步推广，Fushsia的模型有效性正在由Android和Windows一步一步的验证。文件系统这个点是Linux和Windows都称不上是做好的。Fushsia有自己的设计，但是是否足够好，我无法评价。恐怕要等实际的落地才能知道。IO这个点，Windows无数败笔，Linux的电梯和缓存设计也称不上是优良，Fushsia一定可以做得更好，毕竟重新设计，完整参考。但是能好到哪里去，我觉得得后面再看。比如Android用到的ashmem，在Windows下同样功能要模拟会痛不欲生，在Linux下也是依赖已有的tmp文件系统来的。Fushsia就直接出现了MemFS这种量身打造的文件系统。Volume Manager这个在Linux上实现的非常好，但是在Windows上又惨不忍睹。Fushsia也进行了重新设计。Mount的挂载概念是Linux上的一个基本功能，这个设计是如此的优秀，现在的Windows也开始学习，Windows在进入虚拟化领域的时候发现把一个文件系统挂载到别的磁盘的目录的必要性，也产生的对应的技术。这种被一个系统发明（也不能说是Linux发明的），被Windows都采纳了的设计，Fushsia自然也不会错过。网络文件系统在Linux和Windows中实现的都不算好，但是又各有千秋，WSL中对9P协议的应用被谷歌注意到了，但是9P的落地又变成了一个延迟很高的纸上谈兵。Fushsia类似的发展路线，用了现在Windows和Android都有的描述性接口和建立连接的概念进行IO设计，效果如何有待评价。我是十分担忧会重走9P的覆辙。Windows和谷歌内部有很多过于重视架构完备性的理想主义工程师，已经做出来很多“神奇的”作品了。其架构水准之高很多时候都可以掩盖实现之丑陋。但是在性能层面，却是掩盖不了的。性能过程，大部分情况下，就是一个不断破坏架构优美的破坏性过程。我是做性能的，这句话我是真的深有体会。\\n\\n显示是Linux领域的一个最大败笔，好在有Android挽回一些，但是也是付出了巨大的努力。Windows引以为傲的显示是从Directx到驱动，从软件到硬件的深度定制合作产生的。这种通常都有非常大的商业动机。Linux本身不具备这种动机，手机具备。Fushsia对于这种决定生死的领域自然是非常看重，在Android积累的大量渲染经验，让Fushsia充分意识到渲染部分的独立性。Android对SurfaceFlinger的设计和游戏本体渲染的隔离，让传统的单线程渲染非常笨重。这种架构天然是过渡期的产品，Vulkan和Directx12本身就是对这种架构的抛弃。渲染子系统本身就要负责任务的调度和内存的管理，这是现代渲染架构都已经认清的问题了。从架构层面或者操作系统过多的干预渲染过程，坏处远远大于好处，因为渲染是一个性能第一的领域，你的架构再优美，在性能面前也有强烈的放弃动机。在Vulkan和Directx12这种命令队列缓存和任务调度，内存管理高度策略化的发展浪潮下，Fushsia作为一个新时代的操作系统自觉的对渲染作出让步。让渲染子系统能够承担越来越多的自主性工作。不但如此，Direct Compute等显卡计算技术，已经让CPU调度层面认识到计算方面的不足，计算在未来也会可以预见的更多的交给渲染管线。CPU本身和GPU之争，在软件层面出现了第一次的控制权让步。\\n\\nFushsia是一个新时代的操作系统，他的诞生几乎是建立在Windows和Linux的痛苦的基础之上的。变化的是需求，架构能不能更好的适应快速变化的需求是一个操作系统长期发展的重要保证。现在Linux和Windows都已经老态龙钟，但却仍然在坚持更新，不断的一次一次的创新和突破满足社会的需求。Windows和Linux像两个兄弟，社会对操作系统的需求Windows扛不住的时候Linux顶，Linux顶不住的地方Windows顶。双方在迭代的过程中终于逐渐的在领域层进行了划分。与其说是Linux更适合服务端，Windows更适合客户端，不如说是Linux在满足需求的过程中选择了去优先满足服务端，甚至把嵌入式都快丢掉了。Windows在选择满足需求的过程中选择了优先去满足客户端。两个都看着对方的地盘不肯放弃希望。\\n\\nFushsia建立在两个操作系统发展，定位的过程中，博采两家所长，进行的站在巨人的肩膀上的重新设计。这次，不是DEMO，用的也不是java。这次，谷歌的目标是终极。他想要在此终结操作系统的争论。我相信鸿蒙的设计不可能超脱Fushsia之外，要是天天吼着脱离时代的吊打那显然不是这个时代的人。没有人能超脱时代而存在，技术的演进必须要在已有的技术基础之上进行哲学层面，设计层面，实现层面的创新。如果说Fushsia是对Windows和Linux的创新，我相信鸿蒙应该是在Fushsia的哲学基础之上进行创新。因为没有理由谷歌的总结，实验和发现得到的优质财产鸿蒙不去继承。在这个基础之上进行修改才是合理的选择。凭空而出的不同架构，完全重写。我个人不在赞成也不太相信。等他开源看吧。\\n"}'));jctx.push(JSON.parse('{"id": "190907", "tag": "data", "text": "# SQL的行转列与列转行\\n\\n## 行转列\\n\\n指把键值关系表（如从BerkleyDB导入的数据），变成围绕一个中心元素的详细表（列通常会很多）。就从原始的很多行的KV数据，变成行数很少（因为有重复）但很宽的形式，所以叫行转列。case when和group by是典型写法\\n\\n```\\nselect name,\\n  max(case course when \'math\' then score else 0 end) math,\\n  max(case course when \'phy\' then score else 0 end) physical\\nfrom rel_score\\ngroup by name;\\n```\\n\\ncourse列被case多次，从而实现从窄表变成宽表。我把这种一个列变成多个列称为影分身，行转列一定伴随着影分身。\\n\\n### 利用Hive的map类型实现 up 23.05.06\\n\\n需求是从轨迹表，计算出每个实体在每通道的每小时出现总次数。\\n\\n第一步先得到行表： `GROUP BY id, channel, from_unixtimestamp(captime, \'yyyy-MM-dd HH\')` 。注意GROUP BY只能支持expr，不能用alias，所以最后的udf结果不能as，需要在SELECT时候重新写一遍再as hh，不确定会不会优化掉。\\n\\n第二步对第一步的行表再做一次 `GROUP BY id, channel, substr(hh, 1, 10)` 接着在SELECT中，使用collect_list(substr(hh, -2) || cnt)把小时标记，和每个小时的次数拼接成array。接着再用str_to_map(concat_ws(array))把array变成标量的map值。得到包含 id, channel, map 的行表，此时的map有最小1个最多24个kv对，已经基本达成目的了。\\n\\n最后一步就是从map分别取出24小时，再用nvl将不存在的值转成0。\\n\\n整个过程中，最难想到但也最妙的自然就是第二步，利用collect_list这个UDAF函数再结合map类型，将每个分组的内容放在一行内，使一维行表具备更高维度的内容（但似乎也破坏了范式？），从而为最后一步平铺准备好了素材。不过这个方法强依赖引擎，像SQLite只能支持group_concat一种UDAF，并且没有map类型。勉强能用group_concat构造出json，也能凑合实现，但不如Hive这么方便。\\n\\n## 列转行\\n\\n指把定义很宽的表（即列很多），变成每行只有A、B键值对的形式。经过这样的转换，行的数量会大大变多，所以叫列转行。union是典型写法\\n\\n```\\nselect name, \'math\' course, math as score from lika\\nunion\\nselect name, \'phy\' course, physical as score from lika\\norder by name, course;\\n```\\n"}'));jctx.push(JSON.parse('{"id": "190912", "tag": "security", "text": "# SASL、GSSAPI和Kerberos的理解\\n\\n## SASL\\n\\n网络协议和认证虽然是不同的领域，二者往往会结合使用。在SASL出现前，两者的组合是乘积关系，SASL使两者解耦，组合的数量变为和的关系。由于SASL的目的是解耦，所以并不包含网络功能，并不承担数据传输功能，只有得到数据后才开始进行处理。同时它又不负责具体的认证，所以种种认证实现都是是SASL插件的方式存在。\\n\\n使用最广的SASL实现是Cyrus版本（翻译过来是古波斯的居鲁士大帝），从库分布也能看出，主体框架是libsasl2.so，而各种具体实现libcrammd5.so、libdigestmd5.so放在插件目录下。\\n\\n支持的验证机制包括但不限于：getpwent、kerberos、pam、rimap、shadow、ldap\\n\\n## GSSAPI\\n\\n作用和SASL接近，适用场景有些不同。对LDAP来说，两者都适合，但对HTTP认证来说，SASL的流程有些啰嗦，使用和GSSAPI一脉的SPNEGO就更合适。由于GSSAPI产生得比较早，因此和Kerberos结合地更密切（甚至可以说是唯一的实现机制），其中GSSAPI定义开发语言的API，而Kerberos负责具体网络通信和加密过程。\\n\\n## Kerberos\\n\\n实现用得最多MIT的版本（Heimdal有，微软有个非兼容版本SSPI，而AD则是KDC和LDAP的结合体），协议在RFC定义。理念和用途与TLS不一样，krb用于多点间协同，全部使用对称加密算法，依赖参与者依赖中心点KDC，而TLS依赖非对称加密和数字证书，解决两点间通信问题。\\n\\n微软的NTLM据说是对标，用在域控管理密码和认证。但没有c和s间的互动。\\n\\n由于kerberos的实现有多种，接口不统一，GSSAPI的C语言接口定义有RFC背书，且`libgssapi_krb5.so`，即对kerberos的封装，也是我所见仅有的实现绑定，所以两者可以认为是一样的。而适配到SASL会稍麻烦。\\n\\nKerberos的认证过程可细分为三个阶段：初始验证、获取服务票据和服务验证。第一阶段：客户端向KDC中的AS发送用户信息，请求TGT，请求内容会用客户端的密钥做对称加密，由于KDC有客户端的密钥（可以是KDC给客户端，也可以是客户端告诉KDC，总之kerberos的理念就是必须信任并且把密码让KDC知道）。第二阶段：客户端拿着之前获得的TGT向KDC中的TGS请求访问某个服务的票据。第三阶段：拿到票据（Ticket）后再到该服务的提供端验证身份，然后使用建立的加密通道与服务通信。\\n\\n* KDC：Key分发中心（key distribution center），是一个提供票据（tickets）和临时会话密钥（session keys）的网络服务。KDC服务作为客户端和服务器端信赖的第三方，为其提供初始票据（initial ticket）服务和票据授予票据（ticket-granting ticket）服务，前半部分有时被称为AS，后半部分有时则被称为TGS。\\n* AS：认证服务器（Authentication Server），KDC的一部分。通常会维护一个包含安全个体及其秘钥的数据库，用于身份认证，保证客户端确实存在于KDC的密码库中。\\n* TGS：许可证服务器（Ticket Granting Server），KDC的一部分，根据客户端传来的TGT发放访问对应服务的票据\\n\\n由于KDC机制严重依赖与密钥，所以自带数据库管理工具krb5\\\\_util和kadmin。\\n\\n目前主流的中心式密钥分发，一个是Kerberos认证，像windows域控制器认证方式；另一个是Cisco GetVPN，KDC被用于分发TEK（Traffic Encryption Key)。\\n\\n## 认证流程\\n\\n1. AS认证：\\n\\n员工Alice首先到认证中心KDC报道，KDC给了Alice两只信封，一只信封A装的是Alice-KDC session key ，以及Alice ID、IP、时间戳相关信息，用KDC的密码加密，Alice不能打开，待会转交给TGS就够了。\\n另外一只信封B是用Alice的密码经过Hash做了加密，里面装着临时密钥Alice-KDC session key ，Alice用自己的密码，解密得到Alice-KDC session key。如果Alice是假冒的，自然打不开信封B，无法访问网络资源。\\n\\n2. TGS认证：\\n\\n当Alice想访问服务器S，要向TGS出示两个证件：\\n信封A和信封C。其中，信封C里面装有Alice ID、服务器S等信息，用Alice-KDC session key 加密。\\nKDC用自己的密码解开信封A（因为AS和TGS在一起），获得Alice-KDC session key，用它解开信封C。KDC检验证件合格，于是准备出票。\\n\\nKDC把票递给Alice，是两个信封：\\n信封D，里面装有Alice-S session key、Alice-TGS session key，用服务器S的密码加密，Alice不能打开，待会转给服务S。\\n信封E，里面装有Alice-S session key信息，用Alice-KDC session key加密\\n\\n3. Service认证：\\n\\nAlice解开信封E，得到Alice-S session key，并用它生成信封F，里面包含Alice ID和时间戳，来到服务器S 的面前，出示信封D、F。\\n服务器S用自己的密码解开信封D，得到Alice-S session key，然后再用它去解密打开信封F，获得信封里的Alice ID等认证信息，认证通过后，Alice访问服务器资源就用Alice-S session key了。\\n\\n## 协议交互\\n\\n程序分为C和S端，S端又分工具类和守护类。工具类有kadmin.local, `kdb5_util`等负责管理用户。注意kadmin可以让管理员在KDC之外的主机远程操作，不过最好还是在KDC上用kadmin.local。数据库以BerkeleyDB方式保存。守护类有kadmind，krb5kdc，这两个必须都启动才能正常工作。kadmind监听749和464端口，749负责admin，464负责修改密码。krb5kdc监听88端口。\\n\\nC端调用kinit principal，会找pricipal对应的KDC并获取initial credentials和TGT，服务端返回加密报文后，命令行会提示输入密码，如果正确的话，klist就能看到，退出用kdestroy。\\n\\nkinit的交互信令通过UDP发给KDC的AS，端口88。含AS-REQ和AS-REP两个报文。REQ包含标明身份的明文client name和realm，以及请求的server name(默认krbtgt)。\\n\\n输入密码只适用于交互，如果要程序化必须利用keytab方式，就是在KDC侧用kadmin.local的xst指令把某个principal的密钥导出并发给客户机，kinit用-kt选项就免去输入密码这步。默认导出了keytab后，用户密码会变，相当于以后就只能用keytab登陆了。\\n\\n## 身份标识\\n\\nprincipal标识惟一身份，格式是 `<username>/<group>@<REALM>`，比如root/Admins@HOME.COM。username也叫primary，是必填项，可以是linux下的用户名；group也叫instance，用户可以不填，服务必须有；realm可以不填，会从krb5.conf查找默认的域，如果有多个域就必须要写上。每个 realm 可以有私有配置，包括 KDC 的地址和加密的算法，都可以独立存在。有些大型公司会创建一个独立的 realm 来分发管理员的权限。\\n\\nKeytab 是一个包含了（若干）principals 和一个加密了的 principal key的文件。一个 Keytab 文件每个 host 都是唯一的，因为 principal 的定义了包含了 hostname 。这个文件可以用来认证，而不需要传递公开的密码，只要有这个 Keytab 就可以代表这个 principal 来操作。"}'));jctx.push(JSON.parse('{"id": "190913", "tag": "data", "text": "# PostgreSQL备忘\\n\\n其前身是由Stonebraker创造的ingres（1974）和postgres（1986），Postgres和ingres在90年代之前都不支持SQL，而是用的自己的QUEL语言。他的几个学生在1996年改写了postgres来支持SQL，和他没有直接关系。Stonebraker因为前两个系统对于数据库的贡献得了图灵奖。\\n\\nPostgreSQL功能完备但速度稍慢，国内一直不流行。1997年发布6.0版，之后大约每5年更新大版本，到2017年的版本10开始每年更新一次大版本。\\n\\n## 启动和命令工具\\n\\n后台命令是`pg_ctl`，是postgre或postmaster(采用多进程模型，主进程叫master，不过现在合一后，都叫postgre了)的封装，postgre用-C并指定选项名可以查看配置。启动停止状态监控都是它。创建数据库用环境变量指定PGDATA或者参数指定，比如~/pgdata且必须是空目录，接着用`pg_ctl init`或initdb初始化这个目录。会创建若干子目录和默认配置文件，模板和结构定义，有39M（版本不同稍有差异），默认创建名为postgres的数据库。\\n\\n使用`pg_ctl start`会启动监听TCP和Unix Domain两种方式，如果不想用PGDATA环境变量，就用-D指定数据库位置。默认只能在同一台主机上用psql访问 ，要想跨主机访问，要修改postgresql.conf的listen\\\\_address改为`\'*\'`和pg\\\\_hba.conf的IPv4地址改为\'0.0.0.0/0\'。初看这种启动时指定目录的方式有点不习惯，但细想可以在一台机器上启动多个完全不干扰的库，非常灵活。\\n\\n客户端连接用 psql -d postgres，如果不指定数据库，会使用登陆用户名作数据库名。\\n\\n## 概念和特色\\n\\n库-模式(schema)-对象3级结构组织。对象包括表、视图、序列、函数等。由于连接数据库时，会有默认名为public的schema，不注意的话会误以为库下面是表。\\n\\n特有的表空间TABLESPACE概念。默认有`pg_default`和`pg_global`两个表空间。分别保存在$PGDATA目录下的base和global目录，base占了初始空间的一半还多。表空间用于描述表在物理介质的存储方案，创建数据库时可以指定属于哪个表空间。\\n\\n安装完成会有3个初始库，template1, postgres, template0，其中template1是最源头的模板，另两个是从它复制得到的。因为template1允许用户修改，所以增加只读的template0表示纯净的数据库。这3个库分别对应PGDATA/base/下的3个目录，每次新增数据库，如果用默认表空间，就会在base目录下新增一个目录，目录名是oid数字，通过`select datname, oid from pg_database`能查出映射关系。\\n\\n创建一个空的数据库，目录内会初始创建数百个数字命名的文件，可以用`select relname, relfilenode from pg_class`查看每个文件的表名。有些数字文件会以fsm或vm结尾，分别对应free space map和visibility map。同样这个语句，如果加上`where relfilenode=0`会展示全局的表名。\\n\\n命令行叫createuser，但psql中是role，似乎是等价的。修改用户密码`ALTER USER postgres WITH PASSWORD \'postgres\';`"}'));jctx.push(JSON.parse('{"id": "190918", "tag": "os", "text": "# 进程线程和协程的切换开销\\n\\n测试Context Switch time(进程上下文切换时间) ，创建两个进程(实时进程)并在它们之间传送一个令牌，如此往返传送一定的次数。其中一个进程在读取令牌时就会引起阻塞。另一个进程发送令牌后等待其返回时也处于阻塞状态。发送令牌带来的开销与上下文切换带来的开销相比，可以忽略不计。 (利用管道传递令牌)\\n\\n## 测试程序(1)\\n\\n```\\n#include <stdio.h>\\n#include <stdlib.h>\\n#include <sys/time.h>\\n#include <time.h>\\n#include <sched.h>\\n#include <sys/types.h>\\n#include <unistd.h>      //pipe()\\n\\nint main()\\n{\\n    int x, i, fd[2], p[2];\\n    char send    = \'s\';\\n    char receive;\\n    pipe(fd);\\n    pipe(p);\\n    struct timeval tv;\\n    struct sched_param param;\\n    param.sched_priority = 0;\\n\\n    while ((x = fork()) == -1);\\n    if (x==0) {\\n        sched_setscheduler(getpid(), SCHED_FIFO, &param);\\n        gettimeofday(&tv, NULL);\\n        printf(\\"Before Context Switch Time %u us\\\\n\\", tv.tv_usec);\\n        for (i = 0; i < 10000; i++) {\\n            read(fd[0], &receive, 1);\\n            write(p[1], &send, 1);\\n        }\\n        exit(0);\\n    }\\n    else {\\n        sched_setscheduler(getpid(), SCHED_FIFO, &param);\\n        for (i = 0; i < 10000; i++) {\\n            write(fd[1], &send, 1);\\n            read(p[0], &receive, 1);\\n        }\\n        gettimeofday(&tv, NULL);\\n        printf(\\"After Context SWitch Time %u us\\\\n\\", tv.tv_usec);\\n    }\\n    return 0;\\n}\\n```\\n\\n测试结果(进程切换时间不超过5us)\\n\\n```\\nBefore Context Switch Time 617087 us\\nAfter Context SWitch Time 702420 us\\n\\n702420us - 617087us = 85333 us\\n85333us / 20000    = 4.26665 us\\n\\n进程切换时间为4.26665 us\\n\\n注： cpu MHz         : 2801.042\\n```\\n\\n## 测试程序(2) 使用rdtsc()获取当前时间\\n\\n```\\n#include <stdio.h>\\n#include <stdlib.h>\\n#include <sched.h>\\n#include <sys/types.h>\\n#include <unistd.h>\\n\\nlong long rdtsc()\\n{\\n    __asm(\\"rdtsc\\");\\n}\\n\\nint main()\\n{\\n    int x, i, fd[2], p[2];\\n    char send    = \'s\';\\n    char receive;\\n    pipe(fd);\\n    pipe(p);\\n    struct sched_param param;\\n    param.sched_priority = 0;\\n\\n    while ((x = fork()) == -1);\\n    if (x==0) {\\n        sched_setscheduler(getpid(), SCHED_FIFO, &param);\\n        printf(\\"Before Context Switch Time %lld\\\\n\\", rdtsc());\\n        for (i = 0; i < 10000; i++) {\\n            read(fd[0], &receive, 1);\\n            write(p[1], &send, 1);\\n        }\\n        exit(0);\\n    }\\n    else {\\n        sched_setscheduler(getpid(), SCHED_FIFO, &param);\\n        for (i = 0; i < 10000; i++) {\\n            write(fd[1], &send, 1);\\n            read(p[0], &receive, 1);\\n        }\\n        printf(\\"After Context Switch Time %lld\\\\n\\", rdtsc());\\n    }\\n    return 0;\\n}\\n```\\n\\n测试结果(进程切换时间不超过5us)\\n\\n```\\nBefore Context Switch Time 16208184381648\\nAfter Context Switch Time 16208424333213\\n\\n16208424333213 - 16208184381648 = 239951565(clock cycle)\\n239951565      * 0.357009998 ns = 85665107.74074687 ns\\n85665107.74074687 ns / 20000    = 4283.255387037 ns = 4.283255387037 us\\n\\n注： cpu MHz  : 2 801 042 000Hz\\nclock cycle = 1 000 000 000 ns / 2 801 042 000 = 0.357009998ns\\n```\\n\\n## 测试程序(3) 可直接获得进程上下文切换时间\\n\\n```\\n#include <stdio.h>\\n#include <stdlib.h>        //drand48()\\n#include <sched.h>\\n#include <sys/types.h>\\n#include <unistd.h>\\n#include <sys/time.h>      //gettimeofday()\\n#include <time.h>\\n\\ntypedef unsigned long long u64;\\ndouble clockCycleTimeS,clockRateHZ;\\n\\n/* 获取当前时间，返回秒 */\\ndouble second() {\\n    struct timeval tv;\\n    gettimeofday(&tv,0);\\n    return tv.tv_sec + 1e-6 * tv.tv_usec;\\n}\\n\\n/* 获取当前时间，返回clock cycle */\\nu64 rdtsc() {\\n    u64 tsc;\\n    __asm__ __volatile__(\\"rdtsc\\" : \\"=A\\" (tsc));\\n    return tsc;\\n}\\n\\n/* 睡眠us微秒 */\\nvoid selectsleep(unsigned us) {\\n    struct timeval tv;\\n    tv.tv_sec = 0;\\n    tv.tv_usec = us;\\n    select(0, 0, 0, 0, &tv);\\n}\\n\\n/* 计算当前CPU的工作频率 */\\nvoid calibrate() {\\n    double sumx = 0;\\n    double sumy = 0;\\n    double sumxx = 0;\\n    double sumxy = 0;\\n    double slope;\\n    const unsigned n = 30;\\n    unsigned i;\\n\\n    for (i=0; i<n; i++) {\\n        double breal,real,ticks;\\n        u64 bticks;\\n\\n        breal = second();\\n        bticks = rdtsc();\\n        selectsleep((unsigned)(10000 + drand48() * 200000));\\n        ticks = rdtsc() - bticks;\\n        real = second() - breal;\\n\\n        sumx += real;\\n        sumxx += real * real;\\n        sumxy += real * ticks;\\n        sumy += ticks;\\n    }\\n    slope = ( (sumxy - (sumx*sumy) / n) /\\n              (sumxx - (sumx*sumx) / n) );\\n    clockRateHZ = slope;\\n    clockCycleTimeS = 1.0 / slope;\\n    printf(\\"%3.3f MHz\\\\n\\", clockRateHZ*1e-6);\\n}\\n\\nint main()\\n{\\n    calibrate();\\n\\n    int x, i, p1[2], p2[2], time[2];\\n    char send    = \'s\';\\n    char receive;\\n    u64 old_time;\\n    pipe(p1);\\n    pipe(p2);\\n    pipe(time);\\n    struct sched_param param;\\n    param.sched_priority = 0;\\n\\n    while ((x = fork()) == -1);\\n    if (x==0)\\n    {\\n        sched_setscheduler(getpid(), SCHED_FIFO, &param);\\n        old_time = rdtsc();\\n        write(time[1], &old_time, sizeof(old_time));\\n        for (i = 0; i < 10000; i++) {\\n            read(p1[0], &receive, 1);\\n            write(p2[1], &send, 1);\\n        }\\n        exit(0);\\n    }\\n    else\\n    {\\n        u64 new_time;\\n        sched_setscheduler(getpid(), SCHED_FIFO, &param);\\n        for (i = 0; i < 10000; i++) {\\n            write(p1[1], &send, 1);\\n            read(p2[0], &receive, 1);\\n        }\\n        new_time = rdtsc();\\n        read(time[0], &old_time, sizeof(old_time));\\n        printf(\\"Latency time = %3.3f us\\\\n\\",\\n                1e6 * (new_time - old_time) * clockCycleTimeS / 20000);\\n    }\\n    return 0;\\n}\\n```\\n\\n测试结果(Linux-2.6.21 + RealTime Patch) Latency time = 8.129 us\\n\\n2801.226 MHz\\n\\n## 协议的意义和测试\\n\\n前面用实验的方式验证了Linux进程和线程的上下文切换开销，大约是3-15us之间（）。这个开销确实不算大，但是海量互联网服务端和一般的计算机程序相比，特点是：\\n\\n* 高并发：每秒钟需要处理成千上万的用户请求\\n* 周期短：每个用户处理耗时越短越好，经常是ms级别的\\n* 高网络IO：经常需要从其它机器上进行网络IO、如Redis、Mysql等等\\n* 低计算：一般CPU密集型的计算操作并不多\\n\\n即使3-15us的开销，如果上下文切换量特别大的话，也仍然会显得是有那么一些性能低下。例如之前的Web Server之Apache，就是这种模型下的软件产品。（其实当时Linux操作系统在设计的时候，目标是一个通用的操作系统，并不是专门针对服务端高并发来设计的）\\n\\n为了避免频繁的上下文切换，还有一种异步非阻塞的开发模型。那就是用一个进程或线程去接收一大堆用户的请求，然后通过IO多路复用的方式来提高性能（进程或线程不阻塞，省去了上下文切换的开销）。Nginx和Node Js就是这种模型的典型代表产品。平心而论，从程序运行效率上来，这种模型最为机器友好，运行效率是最高的（比下面提到的协程开发模型要好）。所以Nginx已经取代了Apache成为了Web Server里的首选。但是这种编程模型的问题在于开发不友好，说白了就是过于机器化，离进程概念被抽象出来的初衷背道而驰。人类正常的线性思维被打乱，应用层开发们被逼得以非人类的思维去编写代码，代码调试也变得异常困难。\\n\\n于是就有一些聪明的脑袋们继续在应用层又动起了主意，设计出了不需要进程/线程上下文切换的“线程”，协程。用协程去处理高并发的应用场景，既能够符合进程涉及的初衷，让开发者们用人类正常的线性的思维去处理自己的业务，也同样能够省去昂贵的进程/线程上下文切换的开销。因此可以说，协程就是Linux处理海量请求应用场景里的进程模型的一个很好的的补丁。\\n\\n背景介绍完了，那么我想说的是，毕竟协程的封装虽然轻量，但是毕竟还是需要引入了一些额外的代价的。那么我们来看看这些额外的代价具体多小吧。\\n\\n协程切换CPU开销测试，测试过程是不断在协程之间让出CPU。Go代码如下。\\n\\n```\\nfunc cal()  {\\n    for i :=0 ; i<1000000 ;i++{\\n        runtime.Gosched()\\n    }\\n}\\n\\nfunc main() {\\n    runtime.GOMAXPROCS(1)\\n\\n    currentTime:=time.Now()\\n    fmt.Println(currentTime)\\n\\n    go cal()\\n    for i :=0 ; i<1000000 ;i++{\\n        runtime.Gosched()\\n    }\\n\\n    currentTime=time.Now()\\n    fmt.Println(currentTime)\\n}\\n```\\n\\n总的来说线程切换的时间和协程的比值约是**几十倍**，线程切换在10us级别，协程在1us以下。"}'));jctx.push(JSON.parse('{"id": "190921", "tag": "lang", "text": "# JS的单线程和运行时\\n\\nJS的单线程特性(eventloop)在浏览器和node都有体现，所以别的语言常见的sleep函数，在JS都必须要用setTimeout配合Promise迂回实现。\\n\\n运行中遇到回调，会根据类型放到两种不同的回调队列。\\n\\n1. 脚本主体逻辑，创建Promise，设置定时器，又叫宏任务\\n2. Promise回调，process.nextTick，DOM变化，又叫微任务\\n\\n宏队列至多执行一个任务，就去检查微队列，直到微队列空了，事件循环会判断并做UI重绘。重绘后回到宏任务继续执行一次，如此循环。node没有UI，但同样遵守微任务批量宏任务单个的原则。\\n\\n应用最广的是Promise/A规范，属于Promise，又隶属于CommonJS。构造Promise对象传入1个两参函数，形如 Promise(function(resolve, reject))，resolve和reject都是单参函数。构造Promise时必须要执行完executero才会返回，所以new Promise动作是阻塞的，ES7增加的await则把构造Promise对象的阻塞动作给异步化。\\n\\nPromise初看起来是callback的语法糖，但最本质的区别是解耦数据的生产和消费。因为callback方式，必须在发送请求时就指定要执行的动作，而Promise的构造返回的值是代理对象，这个过程中只产生数据（如发送ajax请求），怎么处理等后续挂上then或catch方法，在then或catch方法中处理。then 方法中的回调是**异步执行**的，典型的实现方式是prototype.then的实现中，用\\n\\n```\\ntimer = setInterval(()=>{ if (this._state == \'full|reject\') { clearInterval(timer) } }\\n, 0)\\n```\\n\\n的方式不停地循环检测state状态，直到改变就执行resolve或reject方法。状态只能从pending变成fullfiled或reject，一旦状态改变后，定时器就会取消，也不会再触发回调。\\n\\nES2016正式引入Promise，随后的2017引入async/await。通过async关键字，把普通函数用Promise包装起来，如果直接调用async函数，得到的当然是Promise对象，如果用await方式调用，就能得到Promise之后的值。\\n\\nPython3.7引入async/await关键字，核心要点\\n\\n1. await只能写在async函数体内，否则语法错误\\n2. async函数可以直接调用，会返回coroutine对象（对标Promise），但会有告警\\n3. async函数正确的执行方法是`asyncio.run(a_foo())`，asyncio模块显示模拟了js的eventloop。\\n"}'));jctx.push(JSON.parse('{"id": "190926", "tag": "security", "text": "# SSL和SSH比较\\n\\n两者都是常见的安全术语，安全包含四层含义\\n\\n* 数据加密，即抓包不可读，看上去是乱码，这个最好理解，也最直观\\n* 数据完整性，这是第二个层次，即数据虽然被加密了，但万一被人篡改了怎么办？又或者数据没有收发完整怎么办？数据完整性解决的就是这类问题\\n* 身份验证，这是第三个层次，刚接触安全的话也许不会注意。虽然数据加密了，也有完整性校验了，但怎么知道发消息给你的人，就是你期望的人？直白的说类似证明**你妈是你妈**，比喻可能不太合适，但目的是一样的。\\n* 不可抵赖性，A做过的承诺，只要做了数字签名，就无法反悔。\\n\\n二者都能很好地完成前两层，但只能SSL可以实现身份验证。由于ssh自身没有认证，所以ssh和Kerberos的结合就是顺理成章的事了。Kerberos用于解决一套大系统内的身份识别、数据加密。因此在使用场景上存在很大差异。\\n\\n## 协议背景\\n\\n从名字就可以看出使用了不同的协议。解决的是两点间的加密防窥、互信。SSL和SSH都是基于公钥认证，SSL的出发点是让客户端确保服务端是可信的，而SSH反过来，让服务端确保客户端可信。尽管理论上SSL也扩展了互相认证的机制，但实际中我还没有见过SSL这方面的应用。\\n\\nSSL是会话层协议，其上可以承载各种其它协议，典型的比如HTTPS，我在公司做过一个私有协议全链路加密也是over SSL的。SSL的版本有V2、V3(V1版本因为存在重大安全缺陷，并没有公开过)。后续则更名为TLS，从V1.0->V1.1->V1.2->V1.3。因为SSLv3的漏洞被证明不再具备安全性，至少也是从TLS起使用比较好。SSLv2版本的协议和v3之后的格式上有很大不同，因此OpenSSL代码里特地有一种称为v23的方法，就是使用v3可以回落到v2。至于v3到TLS则沿用同样的总体结构(采用TLV格式)，版本号也一脉相承地从0x0300到0x0304。\\n\\nSSH是个特定应用的协议，就我所知仅远程终端操作，隧道和文件传输功能。仅有v1和v2两个版本，而且v1已经几乎绝迹。我想不明白为什么SSL的版本一直在演进而SSH却不动了。\\n\\n## 交互流程\\n\\nSSL采用客户端主动发起模式，交互采用Client-Hello、Server-Hello、Change-Cipher等过程。\\n\\nSSH在TCP连接建立后，Server端和Client端互发一段明文字符串消息SSH-2.0-xxx，xxx代表软件名字，不规定发送顺序。接着Client Key Exchange Init的流程。SSH在交互开始，服务端会把自己的公钥（注意：不是证书）给客户端，客户端工具会提示用户，第一次客户只能选择相信，如果想长期使用，就写入`known_host`文件，所以客户端不具备认证服务端的能力，只能识别变化。使用的工具和版本不同，协商算法不同，指纹也会不同，比较新的版本会协商出ssh-ed25519，老版本是ssh-rsa，dsa或ecdsa。算法生成的公私钥长度从大到小顺序RSA > DSA > ECDSA > ED25519（严格的说，RSA私钥比DSA长但公钥短，另两个全方位得短）。不管哪种都表示成MD5或SHA256值，很难记住。ssh-keyscan专门用于探测公钥，也是ssh2e协议但message code略有不同。\\n\\nssh协议在进入加密传输阶段后(ssh-keyscan得到公钥就结束，不会进入这个环节)，每个包结尾都会带上mac验证数据，带宽无法百分百的用于传输，但为了校验完整性，这点损失只能接受。\\n\\n## 身份验证\\n\\nSSL为了证明服务器是真实可信，需要给出服务器一些信息才行，便是经常听到的数字证书。直观的可以这么理解，你去拜访某个大佬，但又不知道是不是被人乔装，于是你向面前这位大佬采集了指纹，接着把指纹发到公安局，询问是否是本人，公安局如果给出肯定的答复，就可以放心地聊下去了。\\n\\n证书包含公钥和一些持有者的信息（比如域名、公司名等），与之对应的必然有一个私钥文件。两者构成了SSL服务端的必备文件。如果用OpenSSL工具生成的话，后缀名是.pem。pem可以通过普通的文本编辑器打开，是RFC1421定义的一种格式，首行和尾行是标示文件类型，中间部分是经过Base64之后的数据，因为这个特性，可以通过cat命令把多个证书文件串在一起也是可以使用的。解码后的二进制数据是符合规范，通过OpenSSL的对应命令字可以看内容。比如\\n\\n* openssl x509 -in 公钥名.pem -noout -text\\n\\n可以看到数字证书的公钥、签发者等信息，把x509换成rsa，再打开私钥文件则可以看到RSA的公私钥和计算因子。\\n\\nssh不具备证书功能，因此ssh-keygen只能生成公私钥对。openssl和ssh-keygen生成的私钥格式一样，但公钥格式差别很大，好在ssh-keygen可以把openssl的格式转换成ssh的，详细看ssh-keygen的-m选项。\\n\\n## TLS密钥的来源\\n\\n文件内容是对称加密，其密钥采用会话加密机制，不会重用。这个密钥的生成机制有3步\\n\\n1. premaster key。客户端生成随机数，用服务端的RSA公钥加密后传回服务端（先不考虑DH方式）。这里还有个要点，premaster的前两位是TLS的协商版本，一旦服务端解密后发现这个版本比client hello的版本高，说明会话被劫持，可以拒绝协商，防止降级攻击。\\n2. master key。联合premaster key和客户端、服务端互换的随机数，一共3个随机数，生成固定长度的密钥。（猜测是用hash机制）\\n3. session key。以master key为种子，通过密钥衍生算法，生成最终的加密密钥。"}'));jctx.push(JSON.parse('{"id": "191020", "tag": "protocol", "text": "# HTTP协议历史与细节\\n\\n## 来源\\n\\nLee在1980年时，便在CERN构建ENQUIRE系统，构建这个系统的经历，促使他在1989年3月开发了HTTP最早的版本0.9，当时还只是Lee在CERN的试验产品，直到1997年才发布了如今使用最广的1.1版本。巧合的是CGI版本也在同年正式归档RFC并发布1.1版（CGI起草于1993年，由于其目的就是解决HTTP的动态能力不足，当然晚于HTTP）。\\n\\n和WWW万维网有一定相似性的Gopher协议诞生于1991年，可以说和HTTP的历史相当，技术上两者区别很大：Gopher使用分层结构，而HTTP则使用链接系统。\\n\\nHTTP协议诞生时，也有其它协议，比如邮件、FTP、新闻组等协议，但这些协议都无法承载链接系统，因此Lee最终决定开发新的HTTP协议。正因为HTTP是小字辈，因此body内容的类型是从邮件标准抄的，形式上用/划分大小类别。历史上邮件发展要早得多，发送附件的需求也更迫切。\\n\\n重定向3XX至少有5个值，广泛接受的是301和302。\\n\\n* 301: 永久重定向，会影响爬虫，浏览器书签的行为，将域名改为新地址，节省下次访问时间\\n* 302: 暂时重定向，暗示会恢复，可用于临时性关闭服务\\n\\nRange头可以跳过并只传输一部分，但前提是服务器首先要在响应里用Accept-Range:\\nByte 表示支持。一旦开启会用206表示Range响应。\\n\\n语义规定在一个连接上前一个请求没完成后面的请求不会被处理，所以有了多连接，最早的RFC规定只有2个连接，但浏览器都不遵守，后来RFC只好从事实去掉了连接上限。\\n\\n## HTTPS代理\\n\\n直连的HTTPS肯定是全部加密，但如果中间要经过代理，代理就没法转发了，有两种模式\\n\\n1. CONNECT报文\\n\\n客户端发现目标网址是HTTPS且要经过代理，就会先发送CONNECT请求，并带上host和port，当对端连接上后，返回HTTP/1.1 200 Connection Established，注意不是200 OK。紧接着，代理端会尝试去连目的端，成功后代理就会建立HTTP隧道，这个隧道中流转着代理将收到的请求消息原模原样发往目的端的数据。代理除了知道目标地址外，不会获取其它内容。\\n\\n2. SSL之SNI\\n\\n利用TLS/SSL握手的第一个Client Hello报文中的扩展地址SNI (Server Name Indication)来获取。这种模式不会出现CONNECT请求，隐蔽性更好。"}'));jctx.push(JSON.parse('{"id": "191021", "tag": "lang", "text": "# 从openresty谈到rust\\n\\n大概是2015年，我开始关注nginx，在这之前，我一直从事C++的网络开发工作（通信网的信令协议栈研发，还有CORBA框架的实现），大概有七八年吧，都沉浸在C++的世界里，没有接触过什么更高级更现代的语言。开眼看世界也是最近三四年的事情，惭愧。\\n\\n接触到nginx，很自然注意到了openresty，觉得很不错。nginx代码我拜读过，觉得实现得很优化，例如http解析就用了2000多行来做，充分考虑了时空性能。当时候nginx是声名在外。openresty引入了lua，封装了cosocket，使得能在nginx的基础上很简单地做二次开发，并且因为luajit，二次开发的性能代价很小。总而言之，当时候觉得openresty十分得惊艳，进而也膜拜章亦春大神。\\n\\n当时工作有点乏味，然后也有点心思想跳槽，但是想到自己这七年来都是独孤一味地钻研C++相关的底层项目，感觉自己缺乏竞争力，所以很想学点东西，于是想到可不可以我也写一个http框架呢？luajit本身的ffi很厉害，不需要codegen就可以动态加载并访问任何C库函数，它的jit性能也很高，luajit的作者，Mike Pall也是编译器的翘楚，所以我想，可否我连nginx本身也用lua来重写呢？同时我对上提供openresty一样的api，这样所有*-resty的第三方库就可以直接拿来用了。这种思路类似于linus当年编写linux内核一样，对内重写，对外兼容POSIX，使得app可以直接拿来重用，例如bash。\\n\\n重写的工作很有趣，有很多挑战，例如我要用纯luajit来实现cosocket。openresty的cosocket，非阻塞和select都在nginx的C层面，所以每次陷入阻塞读写的时候，会先yield到C层面。另外，openresty的协程是有父子关系的，表现在一次http请求由一个父协程来处理，它生成的其他协程（一般用来访问外部资源，例如redis），则是其子协程。父协程可以等待（或者同时等待多个）子协程，而父协程退出后，子协程也会退出。纯luajit没有C的承托，所以只能通过lua的exception来做，通过特殊的异常抛出和捕获来实现openresty的cosocket。还有一个有趣的地方，就是nginx的热重启，是通过保留文件描述符并且通过父子进程的环境变量来透传重现的，用纯lua来做，并且还考虑linux的信号处理，则要费了一点心思了，但最后还是做出来了，当时候心情很愉悦。\\n\\n这个重写最终发布的开源项目就是 http://luajit.io ，这个名字也很有意思，一方面，这是一个我申请的io后缀的域名，另一方面它也是项目的名字，io框架嘛，一语双关。各种实现细节肯定不如nginx这般精致，所以性能不会达到nginx这么好，有80%就足够了，做出来后也符合我的预期。用20%的性能换取更简单的代码实现，我觉得已经很有意义了。试想，nginx和openresty的C代码加起来这么多，而我用lua重写，只有区区5000多行代码。\\n\\n发布后，收到了不少关注。不过，我也就是当一个玩具工程来练手罢了。我后来再反思，其实cosocket虽然惊艳，但是并非一枝独秀，golang就完整实现了协程化，不仅仅socket，文件访问和cpu密集型任务都可以融入到协程里面来做，所以golang具有更完整意义的cosocket。\\n\\nopenresty受欢迎，我觉得很大程度得益于它站在了巨人的肩膀上，那就是nginx和luajit。但是更好的事物都有时代的局限性。我这里展开来说一些它们的缺点。\\n\\n先说nginx吧，nginx是多进程架构，每个worker进程（单线程）公平地去抢夺进来的tcp连接，独立处理每个tcp连接上的http请求。socket读写非阻塞，每个worker进程都有一个selector来select所有socket。处理一个http请求没有进程间切换意味着更好的性能。但多进程也有弊端：\\n\\n在接受连接后就只能固定在一个进程里面，如果恰好该进程所处理的连接里面的http请求很多很繁忙，那么它也无法委托给其他进程来代劳，即便其他进程是空闲的，对于http2而言，我觉得这一缺点尤为突出。\\n多进程之间无法安全地共享资源。nginx的方案是放数据在共享内存里面，例如openresty的queue就是放里面的，并且通过放在共享内存里面的pthread mutex来同步。但是弊端很明显，对共享内存的操作不是原子的，例如上锁后，要对共享内存里面的红黑树做remove操作，那么对应的C代码就不少，对应到共享内存上，就有很多步操作，那么如果进行操作的进程异常退出，那么就会留下一个无法收拾的局面。例如，上锁后退出，资源就一直处于加锁状态，其他进程无法获取继续访问，这个还比较容易观察和调试出来。一般多进程系统都需要一个父进程来清理残局，但nginx没有这样做。\\nworker进程是单线程，无法用它来做CPU密集型任务或者磁盘IO任务，nginx为了解决这个问题，引入worker thread pool，但openresty很难利用这个新特性，因为受限于lua虚拟机只能支持单线程的事实，如果利用，线程间交互以及数据拷贝是很大问题。\\nnginx本身只是一个平台，一个特定的平台，起来一个http server给你让你处理http请求，并且能做的实现依赖于nginx导出了什么api给你，所以有时候你很难施展拳脚去适配自己的项目，例如我访问kafka，要作为它的consumer，那么就没法做了，因为没法作为server给kafka调用。\\n而且nginx最著名的特点：性能，也并非一枝独秀，目前rust就完全可以追上它，我后面会提到。\\n\\n好了，再来说一下luajit，作者确实是一个天才，我那段时间看了很多他写的文章，他的各种理论都是如此高深莫测，他的dynasm可谓解放了汇编开发的生产力，而luajit更是让人佩服。用lua来写业务逻辑，很自然会担心性能，相比官方原生的lua的解释器性能和C不是一个等级，luajit的jit弥补了这一点，使得你既可以用lua很高兴很轻松写代码，又不必过分担心性能代价。但是，有如下问题：\\n\\n最大的问题是lua版本的分裂，自lua5.2后，很多地方不再和官方lua兼容，并且长期停留在5.1上，作者没有意愿去改变这个局面。\\n源码实现太复杂，几乎只有Mike Pall自己才能维护它，但作者近几年来的开发活跃度很低，几年来都没发布2.1的正式版本，长期停留在beta，不知道他在忙什么。Mike Pall似乎早就说过要找接班人，但好像一直找不到。\\n你写的lua代码要极力去适配luajit的脾胃，才能让luajit给你实现编译，才能真的达到高性能，先不说如何调试适配是多么痛苦的事情，就说你适配了，你的代码有时候也变得很丑陋很怪异，例如要用tail call去替代循环。我写 http://luajit.io 的时候就深有体会。没错，如果jit得好，那么甚至有时候会比C更快，之所以更快，你可以认为是经过了profile适配（PGO）的C比普通的C快。但是你要极力去优化，使得有很高的编译通过率才行，这一点就不是每个人都能做到，是一个明显的心智负担。尤其对于大型项目而言，留心费神去优化每一行代码是不现实的。说白了吧，普通的C写出来有80%的好性能，但普通的lua写出来不调优，就只能有50%甚至更低的性能（虽然luajit的解释器也很快，但再快比C还是差了一大截）。所以jit，很多时候只是镜花水月而已。\\n终于说到openresty了。作者章亦春也是一个大神，它的coscoket在当时来说还是很前卫的概念。我就冒昧来谈谈它的缺点：\\n\\nopenresty的所有功能源自nginx，也就受限于nginx。而nginx只是一个特定平台，不是一门语言，所以可扩展性是有局限性的。再进一步说，nginx是用C写的，扩展模块也要用C写，openresty之后就要用lua来写的（openresty就是为了提高生产力出现的），但lua本身是一个极其简单的嵌入式语言，没有自己的生态链，其功能完全依赖于宿主系统，在这里宿主就是openresty，也就是说，你能通过lua来做的完全取决于openresty提供多少api给你，没有给你的，你做不了，举个例子，我想开一个线程来做CPU密集的加密任务，没办法，因为没API给你。但如果是一门语言，那么你想做什么就做什么。\\n你不能调用阻塞的lua api或者C函数，或者做一些CPU密集型的任务，或者大量读写文件，因为这样会阻塞nginx的worker进程的单线程，使得性能大幅度下降，而且很容易出现一些让开发者痛苦的事情，例如发现访问redis超时了，明明通过tcpdump看到redis的响应包及时到了，但就是超时，很矛盾很纠结，结果经过一番折腾后发现原来是因为做了一些阻塞的事情，使得nginx的selector在处理io事件之前先处理了timer事件，使得socket明明有数据也被openresty的api报告超时。\\nlua和C之间的数据转换是一个overhead。由于lua的数据结构和C那么的不同，所以交换数据要互相拷贝。这一点对于http请求承载大量数据的应用来说很痛苦。例如我在K公司实现文件服务器的功能，这个文件服务器不能直接委托给nginx的file send，因为要对原始文件数据做处理，例如md5校验。这也是为什么openresty后面慢慢提供一些通过luajit ffi来实现的api接口，就是为了减少拷贝，提高性能。\\n无法实现高性能的缓存，因为luajit的string interning很死板，对每个字符串，不管是常量还是动态生成的变量，都统一经过内部的哈希表来存放和去重，其目的就是为了使得用字符串作为table的key时，加快查找速度，因为比对是否同一个gcobject即可。但对缓存逻辑是一个噩梦，因为每生成一个字符串都需要哈希操作，而缓存恰好会生成很多字符串，luajit的interning哈希表在海量字符串的量级下性能很差。我在k公司做的项目对此有很深的体会。\\n在我看来，openresty相比rust，最大的好处就是lua代码能被动态更新和替换，对于静态编译语言来说是不可能的（dynamic load可以，但dynamic unload是不行的，因为符号之间的引用关联实在没法很轻易解耦）。\\n\\n我2017年去K公司的时候，发现K公司很钟情openresty，很多项目都基于openresty来做，甚至公司还向openresty捐助过一笔小钱。但K公司的人是滥用openresty，在不知道其原理机制的前提下做了很多错事，很多项目其实不应该用openresty但也用。正如后来我去到E公司发现很钟情springboot一样，我觉得现在的公司很喜欢用一些品牌项目作为基础，或因其名气，或因其简单易入门，而不是具体问题具体分析，按项目实际需要来选型。\\n\\n我曾一度觉得golang是openresty更好的选择，但golang的http性能确实不好。直到最近这半年我对rust的研究，觉得rust才是未来。\\n\\ngolang的语言设计很简陋，而相比之下，rust很美很优雅。这里不展开解释。我只说一点，那就是golang从无到有自己实现一门语言，包括编译器完全自己来做，甚至连C库都抛开，直接封装系统调用，这是我最不喜欢的，为什么呢？\\n\\n无法充分利用这十几年来的社区成果，例如gcc和llvm，所以优化度很低，例如llvm的simd，它就无法享用。\\n和C互通代价太大，但很多时候C库是避不开的。\\n不兼容目前经典的调试器，例如gdb、valgrind、systemtap，而它自带的调试器功能相对简陋。\\n而rust呢？在语言特性上非常先进，例如通过ownership解决了C/C++的问题，还不需要付出gc的代价。并且充分利用社区成果，做好语言层面就好了，生成代码和链接代码就交给更专业的llvm，这样一来既专注在语言层面，提供更多更好的特性给用户（例如最近的await），和C互通又很低成本，因为它没有绕开C库。\\n\\ngolang的协程，在rust里面就是通过futrure/async/await来做，开发效率是一样的，运行效率更是胜于golang，因为rust的协程是在编译阶段解析生成的，所有栈数据是用heap上的struct/enum来包装，并且在所有suspend点做了drop，使得内存不需要像golang的协程栈那样在运行时增量分配，也不需要gc来干扰。\\n\\n我这两三年一直做golang的开发，尤其在K公司。例如这是我最近发布的开源项目，大家有空关注一下：\\n\\nkingluo/pgcat\\n\u200b\\ngithub.com\\n\\n但是我现在觉得rust才是未来，在我接下来的技术生涯里面我会phase out掉golang。\\n\\n最后，我给一个小例子来验证一下rust的性能。这是http server和hello world。\\n\\ngolang的实现：\\n\\n```\\npackage main\\n\\nimport (\\n    \\"net/http\\"\\n)\\n\\nfunc main() {\\n    http.HandleFunc(\\"/\\", HelloServer)\\n    http.ListenAndServe(\\":8080\\", nil)\\n}\\n\\nvar str = []byte(\\"hello\\")\\n\\nfunc HelloServer(w http.ResponseWriter, r *http.Request) {\\n    w.Write(str)\\n}\\n```\\n\\nopenresty的实现：\\n\\n```\\nworker_processes auto;\\nerror_log logs/error.log;\\nevents {\\n    worker_connections 1024;\\n}\\nhttp {\\n    access_log off;\\n    server {\\n        listen 8080;\\n        location / {\\n            default_type \'text/plain; charset=utf-8\';\\n            content_by_lua_block {\\n                ngx.print(\\"hello\\")\\n            }\\n        }\\n    }\\n}\\n```\\n\\nrust hyper：\\n\\n```\\nuse hyper::service::{make_service_fn, service_fn};\\nuse hyper::{Body, Request, Response, Server};\\n\\nasync fn hello(_: Request<Body>) -> Result<Response<Body>, Infallible> {\\n    let mut res = Response::new(Body::from(\\"hello\\"));\\n    res.headers_mut().insert(\\n        \\"Content-Type\\",\\n        HeaderValue::from_static(\\"text/plain; charset=utf-8\\"),\\n    );\\n    Ok(res)\\n}\\n\\nasync fn run_server() -> Result<(), Box<dyn std::error::Error + Send + Sync>> {\\n    pretty_env_logger::init();\\n\\n    let make_svc = make_service_fn(|_conn| async { Ok::<_, Infallible>(service_fn(hello)) });\\n    let addr = ([0, 0, 0, 0], 8080).into();\\n    let server = Server::bind(&addr).serve(make_svc);\\n\\n    println!(\\"Listening on http://{}\\", addr);\\n\\n    server.await?;\\n\\n    Ok(())\\n}\\n\\nfn main() {\\n    let rt = tokio::runtime::Builder::new().build().unwrap();\\n    rt.block_on(run_server()).unwrap();\\n}\\n```\\n\\nrust actix-web：\\n```\\nuse actix_web::{web, App, HttpRequest, HttpServer, Responder};\\n\\nfn greet(_: HttpRequest) -> impl Responder {\\n    \\"hello\\"\\n}\\n\\nfn main() {\\n    HttpServer::new(|| App::new().route(\\"/\\", web::get().to(greet)))\\n        .bind(\\"0.0.0.0:8080\\")\\n        .expect(\\"Can not bind to port 8080\\")\\n        .run()\\n        .unwrap();\\n}\\n```\\n\\n服务端运行在一个双核的服务器上，在同一局域网段的另一个双核服务器上运行wrk作为客户端来压测：wrk -c100 -d60s http://testserver:8080\\n\\n结果如下，从好到坏排列：\\n\\n1. rust actix-web\\n```\\n  2 threads and 100 connections\\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\\n    Latency   654.26us  226.01us  13.21ms   97.09%\\n    Req/Sec    73.74k     9.06k  123.48k    41.13%\\n  8810858 requests in 1.00m, 0.99GB read\\nRequests/sec: 146603.79\\nTransfer/sec:     16.92MB\\n```\\n2. rust hyper\\n```\\n  2 threads and 100 connections\\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\\n    Latency   786.47us  273.89us  16.47ms   92.97%\\n    Req/Sec    63.19k     2.39k   70.41k    67.67%\\n  7544745 requests in 1.00m, 0.85GB read\\nRequests/sec: 125738.24\\nTransfer/sec:     14.51MB\\n```\\n3. openresty\\n```\\n  2 threads and 100 connections\\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\\n    Latency   801.19us  353.80us  20.29ms   97.67%\\n    Req/Sec    62.05k     2.20k   67.38k    66.08%\\n  7409230 requests in 1.00m, 1.32GB read\\nRequests/sec: 123460.63\\nTransfer/sec:     22.60MB\\n```\\n4. golang\\n```\\n  2 threads and 100 connections\\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\\n    Latency     1.33ms  652.90us  22.42ms   68.23%\\n    Req/Sec    37.89k   712.77    41.19k    76.00%\\n  4523628 requests in 1.00m, 522.00MB read\\nRequests/sec:  75392.66\\nTransfer/sec:      8.70MB\\n```\\n\\n虽然这个小例子不算严谨，但性能结果之间的比例还是可以参考的。rust的actix-web最好，这个跟网上对actix-web的赞誉是一致的，但它唯一的缺点是在代码上还没过渡到async/await。而rust的hyper也不错，跟openresty的性能差不多，这已经让我觉得很舒服。golang性能最差，这符合我一直以来对它的性能预期。\\n"}'));jctx.push(JSON.parse('{"id": "191101", "tag": "os", "text": "# 子进程执行和信号\\n\\nsystem(2)调用子进程非常方便，返回类型int，但不是脚本真正的返回值，对待这个返回值，要先用WIFEXITED是否非0，非0表示成功，再用WEXITSTATUS取返回值。从命名上看，表示只有EXIT了，才能取STATUS。从数值角度看，返回值由低8位和高24位构成。我只见过低8位全0的情况，不知道什么情况下低8位不是0。\\n\\n有个类似的函数族execve，也是执行命令，但它会放弃当前进程空间数据，切换到待执行的进程，因此exec必须在fork出的子进程执行，好处就是不会阻塞，这也是shell下执行命令的机制。\\n\\n要想让执行中的进程停止，可以用信号量，kill如果不带参数，发的是TERM信号，不是KILL。TERM可以通过TRAP或函数方式捕捉，进而在被信号触发后做一些保存工作再退出，而KILL不能被捕捉，一旦收到必须退出，因此在关进程时，优先用kill，迫不得已再用kill -9。\\n\\n并不是所有信号都会使进程退出，像SIGSTOP和SIGCONT则是使进程暂停和继续，在STOP状态的进程只是暂停，不算异常，因此system还有个判断状态函数WIFSIGNALED表示非EXITED且非STOP才是被信号了。也可以用trap命令修改信号对应的行为（再强调一次，不能捕获KILL）。\\n\\n而termux有个bug，SEGV不一定能捕捉到，有时要第二或第三次才会退出。\\n\\nHUP信号，所有网上教程都说后台进程在终端退出时会被杀掉，所以要加nohup命令。实际测试并不是这样，不管是exit/logout或者直接断掉终端并不会使后台退出，只有手动kill掉这个会话的sshd进程，才会导致后台退出。实际中几乎没有人会刻意地找出这个sshd的pid，所以只进后台不用nohup在绝大部分场景下都没有问题。用`&`进入后台的进程，TTY编号会变成和前台不同但仍会绑定一个，exit的后台进程才会显示`?`。\\n\\n要解释这个问题，要从基本概念说起\\n\\n* terminal，简称tty，DEV号5,0。包裹着shell提供输入输出，可以有多个，类似电视的遥控器。有个系统函数`char* ttyname(int fd)`，会返回句柄所绑定的tty，实测0, 1, 2这几个标准句柄对应的tty是相同的（不确定是否有方式修改）。\\n* console，DEV号5,1。最早的主机在启动完成前不能接入terminal，在启动和关闭阶段的日志会在console上显示，可以是一些灯或磁碟机，至多一个，类似电视的面板按钮\\n* pty，虚拟终端，ssh就是网络化的pty。之所以会有这个概念，是因为terminal会在设备驱动和系统读写函数间，有一个内部的转换层，但网络化缺少了这层。为了保持一致性，将网络源也抽象为终端，像串口的波特率概念还保留，比如我测试结果输入输出的波特率都是38400。pty映射到软件上的实体是pts，unix特性，linux内核的2.1.93版正式支持该特性。对应devpts文件系统，一般挂在/dev/pts下。是个主从结构，主只有1个，名字固定为/dev/ptmx，DEV号5,2。从的名字从主获取，`df=open(\\"/dev/ptmx\\") or getpt();ptsname(df);`。从的名字格式是/dev/pts/xx，每增加一个虚拟终端就增加一个。\\n\\nhangup的原意是挂断电传打字tty，引申后就是pts即ssh，所以用exit只是退出shell，并没有关闭外覆的sshd，不触发HUP信号的原因就在于此。\\n\\n在安卓6上遇到ssh登陆后提示`PTY allocation request failed on channel 0`错误，可能是关闭了ptmx所致。这就会出现ssh连接成功后，只有bash内置命令(pwd)能显示出来，其它即便执行也看不到结果。\\n\\n## 容器化的应对\\n\\n容器鼓励只有1个进程，而普通的shell进程并不能转发信号，有两种做法\\n\\n1. 用exec把作为entrypoint的shell进程替换为真正的程序，适合redis/mysql用途单一的容器\\n2. 用dumb-init或tini等专有的容器化1号进程作为启动，代替系统级的1号进程init\\n"}'));jctx.push(JSON.parse('{"id": "191105", "tag": "os", "text": "# docker和OCI规范\\n\\n容器技术最初由Docker这个产品为大众所了解，Docker这个词是公司名，容器技术和工程化的混合。工程化上一个app一个容器是最大的创新，容器化技术最初被linus嘲笑50行脚本就能完成。随着使用日渐广泛，2015年6月，Docker、CoreOS等公司制定了OCI（Open Container Initiative）开放容器计划来规范标准。\\n\\n还有一个概念CRI和OCI很接近，这个概念源于k8s，因为调度系统最直接打交道的就是容器，所以必然也会对容器有约束，所以在2016年12月发布CRI规范，但从使用角度来看，可以认为两者是相同的。\\n\\n## 规范与层级\\n\\n* 镜像image: 一般是写dockerfile后制作得到，以文件形式存储在硬盘上，包含应用软件及依赖的运行时，做得好应该尽量小。从沙盒角度看，对java有一定替代性，且从最小依赖上说，C/Go语言才能保证镜像不引入无用的依赖。\\n\\n* 运行时container: 是镜像的运行实例，实例好比是类，容器则是对象。在做镜像的dockerfile里不会限制CPU、内存、网络等条件，在运行期指定外部的资源参数。运行时又分高层运行时和低层运行时。\\n\\n高层运行时包括我们熟知的Docker外，还有Containerd和CRI-O，随着k8s的1.24版本正式删除dockershim层，可以预见Containerd将会在未来成为主流的高层运行时。\\n\\n低层实现的参考实现是runC，是由Docker用Go实现并捐给社区的，其实在Docker之前，Linux社区是有lxc方案的，但因种种原因没有流行起来。runC从2016年的1.0-rc1版，直到2021年才发布1.0正式版，期间主要的特性是增加了cgroup v2的支持，并修复了多个CVE严重漏洞。\\n\\nDocker的本质是设置了namespace和cgroup参数的进程。是沙盒概念在linux上的具体实现，安卓上运行的每个app都是类似于Docker（底座换成dalvik）的实例。Docker公司将containerd和runc捐出后，剩下的只是命令行工具的使用接口。随后开始了从沙盒技术向hyper-v虚拟化转变。\\n\\n不同的docker子命令适用于不同的层级，要区分。rmi是删除image，而rm则是删除container。\\n\\n## 工具与运行\\n\\n采用C/S架构，dockerd是后台守护，docker负责向后台发命令，包括管理镜像，打新包，提交。守护进程会依次拉起多个程序，dockerd -> dockerd-current -> docker-containerd-current -> docker-containerd-shim。运行容器则依靠docker-runc。\\n\\n配置文件在/etc/docker/，采用json格式保存，大约和开发者比较新有关系。\\n\\n## 核心概念\\n\\n1. repo 仓库。为了分发的方便，在hub大市场里存放了很多仓库，每个仓库有多个tag版本，提供相同功能。不同tag间有区别和演进\\n2. image 镜像。仓库的某个具化的tag就是镜像，对应到磁盘上的一套文件结构，是静态概念\\n3. container 容器。镜像作为进程的底座被运行起来，此时整个进程就称为容器，是动态概念\\n\\n### 命令行操作\\n\\n* pull : docker pull xyz -> docker pull repo.addr/library/xyz:latest # 仓库域名不能有http://前缀，域名后面跟固定的library\\n* run : docker run -it 。创建并执行容器。pull拉下来的镜像，可能不是local，run命令会自动把远程镜像再同步到local\\n* start : run -it的镜像，有时在容器中执行exit会导致进程退出。但是container ID还在，用 start containerID 就能重新拉起\\n* exec : 已经start的容器不能用run，要用exec才能挂载到运行中的容器\\n* stop/rm : 停止然后删除容器\\n* save/export : 将镜像保存成tar文件，差别是save会带上一些元信息，而export则是纯粹的二进制文件\\n* load : 将tar形式的镜像加载到docker的本地仓库，在images列表中能看到\\n* commit : 将容器保存为新的镜像，不是每次操作都会产生新的层，具体原理不清楚\\n* history : 按时间序从上到下显示镜像层\\n* network : 查看，操作，销毁容器宿主网络\\n\\n## 镜像\\n\\n一个save的镜像解包后是这样的（docker24.0.5），如果是export，则对应layer.tar\\n\\n```\\nsha256_folder_layerN/          # 镜像由几层构成，目录就有几个\\nsha256_folder_layerN/VERSION   # 1.0\\nsha256_folder_layerN/json\\nsha256_folder_layerN/layer.tar # 这一层更新/删除的二进制文件\\nconfig_sha256.json\\nmanifest.json\\nrepositories  # 镜像、标签以及sha256_folder名，似乎只有一层镜像才有\\n```\\n\\n如果删除某个文件，在解压开的layer层体现为内容为空的隐藏文件 `.wh.<rmfile>` 记录，wh猜测是write hidden的缩写。\\n\\n## 网络\\n\\n服务端启动后，会创建名为docker0的网桥接口，用brctl show查看这个网桥的所有interface，通常启动几个容器就有几个veth网卡，同主机之间的veth是互通的。宿主机看不到这些veth的IP4地址，要进入容器才能看。\\n\\n## 磁盘卷\\n\\ndocker volume create your_name 创建一个卷，其实就是一个目录。在启动容器时，用 `docker run -v vol_name:/some/path` 指定后，容器里对/some/path的读写就不在unionFS，而落在宿主机的目录，实现持久化。\\n\\n## harbor\\n\\n为了存储镜像和相关产物，诞生了harbor项目。Harbor 2.0 成为符合 OCI（Open Container Initiatives）规范的开源镜像仓库，能够存储多种云原生工件（Artifacts），例如，容器镜像、Helm Chart、OPA、Singularity 等等，这些统称artifacts。\\n\\n## helm\\n\\n为了将多个docker镜像编排成一个大的应用，产生了helm。通过 Helm3 可将 Helm Chart 推送到 Harbor。 在 Harbor 2.0 中，Helm Chart 不再存储于 ChartMuseum 中，而是与容器镜像一样存放在artifacts中。"}'));jctx.push(JSON.parse('{"id": "191107", "tag": "protocol", "text": "# 目录服务和NetBIOS协议\\n\\n目录代表实体，可以是一个文件或某个人的信息，通常这些信息以树状形式保存，类似目录树。目录服务是按照树状信息组织模式，实现信息管理和服务接口的一种方法。目录服务系统一般由两部分组成：第一部分是数据库（一般是分布式数据库），且拥有一个描述数据的规划；第二部分则是访问和处理数据库有关的详细的访问协议。\\n\\n目录服务与关系型数据库不同的是，读非常快，但写比较慢，也缺少事务机制，是针对特定场景的特化机制。目录不支持批量更新所需要的事务处理功能，目录一般只执行简单的更新操作，适合于进行大量数据的检索；目录具有广泛复制信息的能力，从而在缩短响应时间的同时，提高了可用性和可靠性。目录服务技术的国际标准有两个，即较早的X.500标准和近年迅速发展的LDAP标准。\\n\\n## X.500协议族\\n\\nX.500不是一个单一协议，它是由一个协议族组成：\\n\\n* X.501模型强调目录服务基本模型和概念\\n* X.509认证框架是如何在X.500中处理目录客户和服务器的认证\\n* X.511 抽象服务定义X.500被要求提供的功能性服务\\n* X.518 分布式操作过程表明如何跨越多台服务器处理目录服务\\n* X.519 协议规范即是X.500协议，包括目录访问协议DAP、目录系统协议DSP、目录操作绑定协议DOP和目录信息Shadowing协议DISP\\n* X.520 选定的属性类型要求是X.500自己使用的属性类型\\n* X.521选定的对象类即为X.500自己使用的对象类\\n* X.525复制是如何在目录服务器之间复制目录内容\\n\\n这些X.500标准中主要定义有多种内容。一个信息模型：确定目录中信息的格式和字符集，如何在项中表示目录信息(定义对象类、属性等模式)；一个命名空间：确定对信息进行的组织和引用，如何组织和命名项——目录信息树DIT和层次命名模型；一个功能模型：确定可以在信息上执行的操作；一个认证框架：保证目录中信息的安全，如何实现目录中信息的授权保护——访问控制模型；一个分布操作模型：确定数据如何进行分布和如何对分布数据执行操作，如何将全局目录树划分为管理域进行管理——目录管理模型，客户端与服务器通信的协议—目录访问协议DAP，将用户请求在服务器之间进行链接所需的目录系统协议DSP，将选定的信息在服务器之间进行复制所需的目录信息映像协议DISP，用于自动在服务器之间协商连接配置的目录操作绑定协议DOP。\\n\\nX.500虽然是一个完整的目录服务协议，但在实际应用的过程中，却存在着不少障碍。由于目录访问协议DAP这种应用层协议是严格遵照复杂的ISO七层协议模型制定的，对相关层协议环境要求过多，主要运行在UNIX机器上，在许多小系统上，如PC和Macintosh上无法使用，因此没有多少人按照DAP开发应用程序，TCP/IP协议体系的普及，更使得这种协议越来越不适应需要。\\n\\n## LDAP协议族\\n\\nLDAP协议从1993年批准，产生了LDAP V1版本，随后于1997年发布了第三个版本LDAP V3，它的出现是LDAP协议发展的一个里程碑性标志，它使LDAP协议不仅仅作为X.500的简化版，同时提供了LDAP协议许多自有的特性，使LDAP协议功能更为完备，具有了更大的生命力。\\n\\nLDAP典型应用是保存用户名和账号，并用于大型系统的认证。协议自身是明文的，所以v3版本加入了SASL支持，结合kerberos可以对整个通信过程做到加密。\\n\\nLDAP V3协议也不是一个协议，同样是一个协议族。\\n\\n* RFC 2251——LDAP V3核心协议，定义了LDAP V3协议的基本模型和基本操作\\n* RFC 2252——定义了LDAP V3中的基本数据模式（Schema）（包括语法、匹配规则、属性类型和对象类）以及标准的系统数据模式\\n* RFC 2253——定义了LDAP V3中的分辨名（DN）表达方式\\n* RFC 2254——定义了LDAP V3中的过滤器的表达方式\\n* RFC 2255——LDAP统一资源地址的格式\\n* RFC 2256——在LDAP V3中使用X.500的Schema列表\\n* RFC 2829——定义了LDAP V3中的认证方式\\n* RFC 2830——定义了如何通过扩展使用TLS服务\\n* RFC 1823——定义了C的LDAP客户端API开发接口\\n* RFC 2847——定义了LDAP数据导入、导出文件接口LDIF\\n\\n这些协议主要定义了LDAP的内容，同时主要定义了一个信息模型：确定LDAP目录中信息的格式和字符集，如何表示目录信息(定义对象类、属性、匹配规则和语法等模式)；一个命名空间：确定对信息进行的组织方式——目录信息树DIT，以DN和RDN为基础的命名方式，以及LDAP信息的Internet表示方式；一个功能模型：确定可以在信息上执行的操作的通讯协议以及在客户端进行这些操作的API接口；一个安全框架：保证目录中信息的安全，匿名、用户名/密码、SASL等多种认证方式，以及与TLS结合的通讯保护框架；一个分布式操作模型：基于Referral方式的分布式操作框架；一个LDAP扩展框架：基于控制和扩展操作的LDAP扩展框架 。\\n\\n但在LDAP协议中尚未定义通用的访问控制模型和复制协议（对应X.500的映射协议DISP），尽管不同的LDAP厂商均实现了自己的控制模型和复制机制，但是LDAP标准的发展正集中在访问控制模型、复制协议（DUP）以及扩展操作上，这些扩展操作包括查询的分页和排序、语言标签、动态目录、LDAP服务发现等。\\n\\n## NetBIOS\\n\\n起因是有机器被人格式化，定位到某IP但未能锁定是谁。得知nbtstat可以反查并确认工号。\\n\\n此协议是IBM在1983年发布，微软85年实现，比较多见确实在win系统。仅适合用于局域网且不支持域名。最初的时候跑在网络切换，虽然后来也做了over ip但依然改变不了不能路由问题\\n\\n有自定义的帧头格式，和TCPIP更类似平级关系。\\n"}'));jctx.push(JSON.parse('{"id": "191206", "tag": "lang", "text": "# 编程语言的字符串内部表示\\n\\n最近在做中文字符校验，结合几种语言的使用，做个总结。除了ASCII字符集以外，其它文字普遍有定义和外部展示的区分，即使不考虑各国定义的标准外，也还存在Unicode和UTF8两种要区分。编程语言接收的输入一定是外部展示，然后在处理时再变成内部表示。\\n\\n## JS\\n\\n因为是内嵌在浏览器，文字的编码方式不需要JS操心，浏览器会把各种编码转成Unicode再给JS。但是JS发明的时候，Unicode还只有BMP，所以内部单元都是UCS2方式，包括String.fromCharCode会截断，比如0x20041返回的是0x41。超过BMP的字符在内部以代理对(surrogate pairs)方式表示，length取得的长度是2。\\n\\n好在新标准定义了String.fromCodePoint方法能识别代理对，能正确识别0x20041。另外对字符串变量str，用`const i = str[Symbol.iterator]()`得到的i，可以用next()方法每次迭代一个CodePoint，利用这个方法，可以构造另一套支持全Unicode的方法。也算在无奈之下的补偿方式了。\\n\\n## PHP\\n\\n没有语言规范层的定义，实际中可以用`mb_internal_encoding`获取内部编码方式。如果在`mb_`系列方法中编码和输入源不匹配，得到的错误结果要使用者自己承担。有点C语言的哲学。\\n\\n## Python\\n\\n由于出现断代变迁，2和3有较大差异。2.x内部是ASCII，3.x内部是Unicode。前者无法支持多语言，后者不是通用的外部表示（因为主流是UTF-8，在那之前则是各国不同的编码标准），因此2个版本的输入文件都有文件编码参数（可以显式指定，或跟随操作系统），如果读入的字符和指定的参数有冲突会报错。\\n\\n2.x的文字只是字节的序列，类型是str(等价于3.x的bytes)。可以加u前缀保存成Unicode，比如u\'文字\'，类型变成unicode。到了3.x时代，str升级成unicode，bytes表示字节序列。在2.x里经常要对一个str类型变量用decode(\\"utf-8\\")方法，到了3.x会调用失败，因为str已经是unicode类型，只有encode成某种编码的序列；反之byte类型才有decode方法，将一段字节流按指定的格式解码成unicode形式。\\n\\npython的base64解码，由于返回值不能保证内容是unicode可编码，所以只能是bytes类型。如果想要以str方式使用，要decode(\\"utf-8\\")后再使用。\\n\\n## Golang\\n\\n规范要求输入必须是UTF8。string类型是byte sequence，用`[]`的下标处理时，操作到每个字节。对string用range方法每次返回一个rune类型的值，以Unicode表示的一个字符，长度不定，由于语言出现得比较晚，避免了JS的坑，能表示全部范围。"}'));jctx.push(JSON.parse('{"id": "191212", "tag": "lang", "text": "# Promise的中立性\\n\\n## 原文\\n\\nPromise 产生的问题影响了 JS 的整个生态系统，本文将对其中一些问题进行阐述。上面这句话可能让你认为我被 Promise 折磨得心情极差，对着电脑骂脏话，于是打算在网上发泄一通。实际上并不是的，我今早刚泡好咖啡，就有人在 Twitter 上问我对 Promise 的看法，我才写下了这篇文章。我当时一遍喝咖啡一遍思考，然后向他回复了几条微博。一些人回复说最好能写成博客，于是就有了这篇文章。\\n\\nPromise 的主要目的是表示一个终将会得到的值（下文简称最终值）。这个值可能会在下一个 event loop 中得到，也可能会在几分钟后得到。还有很多其他原语可以达到相同的目的，比如回调、C# 中的任务、Scala 中的 Future，RxJS 中的 Observable 等。JS 中的 Promise 只是这些原语中的一个而已。\\n\\n虽然这些原语都能实现这个目的，但是 JS 的 Promise 是一个太过 opinionated （译注：opinionated 是主观臆断的意思，这里表示不恰当的、强加观点的）的方案，它造成了很多奇怪的问题。这些问题又会引发 JS 语法和生态系统中的其他问题。我认为 Promise 不够中立，其 opinionated 表现在下面四个地方：\\n\\n1. 立即执行而不是延迟执行\\n1. 不可中断\\n1. 无法同步执行\\n1. then() 其实是 map() 和 flatMap() 的混合体\\n\\n### 立即执行，而不是延迟执行\\n\\n当你创建一个 Promise 实例的时候，任务就已经开始执行了，比如下面代码：\\n\\n```\\nconsole.log(\'before\');\\nconst promise = new Promise(function fn(resolve, reject) {\\n  console.log(\'hello\');\\n});\\nconsole.log(\'after\');\\n```\\n\\n你会在控制台里依次看到 before、hello 和 after。这是因为你传递给 Promise 的函数 fn 是被立即执行的。我把 fn 单独拧出来你可能就看得更清晰一些了：\\n\\n```\\nfunction fn(resolve, reject) {\\n  console.log(\'hello\');\\n}\\n\\nconsole.log(\'before\');\\nconst promise = new Promise(fn); // fn 是立即执行的！\\nconsole.log(\'after\');\\n```\\n\\n所以说 Promise 会立即执行它的任务。注意在上面的代码中，我们甚至还没使用这个 Promise 实例，也就是没有使用过 promise.then() 或 promise 的其他 API。仅仅是创建 Promise 实例就会立即执行 Promise 里的任务。理解这一点很重要，因为有的时候你不想 Promise 里的任务立刻开始执行。有时候你会想要一个可复用的异步任务，但是 Promise 却只会执行一次任务，因此一旦 Promise 实例被创建，你就没法复用它了。\\n\\n通常解决这个问题的办法就是把  Promise 实例化的过程写在一个函数里：\\n\\n```\\nfunction fn(resolve, reject) {\\n  console.log(\'hello\');\\n}\\n\\nconsole.log(\'before\');\\nconst promiseGetter = () => new Promise(fn); // fn 没有立即执行\\nconsole.log(\'after\');\\n```\\n\\n由于函数是可以在后面调用的，所以用一个「返回 Promise 实例的函数」（下文简称为 Promise Getter）就解决了我们的问题。但是另一个问题来了，我们不能简单地用 .then() 把这些 Promise Getter 连起来（译注：原文说得不够清晰，我不太理解作者的意图）。为了解决这个问题，大家的做法一般是给 Promise Getter 写一个类似 .then() 的方法，殊不知这就是在解决 Promise 的复用性问题和链式调用问题。比如下面代码：\\n\\n```\\n// getUserAge 是一个 Promise Getter\\nfunction getUserAge() {\\n  // fetch 也是一个 Promise Getter\\n  return fetch(\'https://my.api.lol/user/295712\')\\n    .then(res => res.json())\\n    .then(user => user.age);\\n}\\n```\\n\\n所以说 Promise Getter 其实更利于组合和复用。这是因为 Promise Getter 可以延迟执行。如果 Promise 一开始就设计成延迟执行的，我们就不用这么麻烦了：\\n\\n```\\nconst getUserAge = betterFetch(\'https://my.api.lol/user/295712\')\\n  .then(res => res.json())\\n  .then(user => user.age);\\n```\\n\\n（译者注：也上面代码执行完了之后，fetch 任务还没开始）我们可以调用 getUserAge.run(cb) 来让任务执行（译注：很像 Rx.js）。如果你多次调用 getUserAge.run，多个任务就都会执行，最后你会得到多个最终值。不错！这样一来我们既能复用 Promise，又能做到链式调用。（译注：这是针对 Promise Getter 说的，因为 Promise Getter 能复用，却不能链式调用）\\n延迟执行比立即执行更通用，因为立即执行无法重复调用，而延迟执行却可以多次调用。延迟执行对调用次数没有任何限制。所以我认为立即执行比延迟执行更 opinionated（译注：opinionated 是贬义词）。C# 中的 Task 跟 Promise 很像，只不过 C# 的 Task 是延迟执行的，而且 Task 有一个 .start() 方法，Promise 却没有。\\n\\n我打个比方吧，Promise 既是菜谱又是做出来的菜，你吃菜的时候必须把菜谱也吃掉，这不科学。\\n\\n### 不可中断\\n\\n一旦你创建了一个 Promise 实例，Promise 里的任务就会马上执行，更悲催的是，你无法阻止的执行。所以你现在还想创建一个 Promise 实例吗？这是一条不归路。\\n我认为 Promise 的「不可中断」跟它的「立即执行」特性密切相关。这里用一个不错的例子来说明：\\n\\n```\\nvar promiseA = someAsyncFn();\\nvar promiseB = promiseA.then(/* ... */);\\n```\\n\\n假设我们可以使用 promiseB.cancel() 来中断任务，请问 promiseA 的任务应该被中断吗？也许你认为可以中断，那就再看看下面这个例子：\\n\\n```\\nvar promiseA = someAsyncFn();\\nvar promiseB = promiseA.then(/* ... */);\\nvar promiseC = promiseA.then(/* ... */);\\n```\\n\\n这个时候如果我们可以用 promiseB.cancel() 来中断任务，promiseA 的任务就不应该被中断，因为 promiseC 依赖了 promiseA。\\n正是由于「立即执行」，Promise 任务中断的向上传播机制才变得复杂起来。一个可能的解决办法是引用计数，不过这种方案有很多边界情况甚至 bug。\\n如果 Promise 是延迟执行的，并提供 .run 方法，那么事情就变得简单了：\\nvar execution = promise.run();\\n\\n// 一段时间后\\nexecution.cancel();\\n\\npromise.run() 返回的 execution 就是任务的回溯链，链上的每一个任务都分别创建了自己的 execution。 如果我们调用 executionC.cancel()，那么 executionA.cancel() 就会被自动调用，而 executionB 有它自己的一个 executionA，跟 executionC 的 executionA 互不相干。所以可能同时有多个 A 任务在执行，这并不会造成什么问题。\\n如果你想避免多个 A 任务都在执行，你可以给 A 任务添加一个共享方法，也就是说我们可以「选择性地使用」引用计数，而不是「强制使用」引用计数。注意「选择性地使用」和「强制使用」的区别，如果一个行为是「选择性地使用」的，那么它就是中立的；如果一个行为是「强制使用」的，那么它就是 opinionated 的。\\n回到那个奇怪的菜谱的例子，假设你在一个餐厅点了一盘菜，但是一分钟后你又不想吃这盘菜了，Promise 的做法就是：不管你想不想吃，都会强行把菜塞进你的喉咙里。因为 Promise 认为你点了菜就必须吃（不可中断）。\\n\\n### 无法同步执行\\n\\nPromise 的设计策略中，允许最早的 resolve 时机是进入下一个 event loop 阶段之前（译注：请参考 process.nextTick），以方便解决同时创建多个 Promise 实例时产生的竞态问题。\\n\\n```\\nconsole.log(\'before\');\\nPromise.resolve(42).then(x => console.log(x));\\nconsole.log(\'after\');\\n```\\n\\n上面代码会依次打印出 \'before\' \'after\' 和 42。不管你如何构造这个 Promise 实例，你都没有办法使 then 里的函数在 \'after\' 之前打印 42。\\n最后的结果就是，你可以把同步代码写成 Promise，但是却没有办法把 Promise 改成同步代码。这是一个人为的限制，你看回调就没有这个限制，我们可以把同步代码写成回调，也可以把回调改成同步代码。以 forEach 为例：\\n\\n```\\nconsole.log(\'before\');\\n[42].forEach(x => console.log(x));\\nconsole.log(\'after\');\\n```\\n\\n这个代码会一次打印出 \'before\' 42 和 \'after\'。\\n由于我们不可能把  Promise 重新改写成同步代码，所以一旦我们在代码里使用了 Promise，就使得它周围的代码都变成了基于 Promise 的代码（译注：不是很理解这为什么就叫做基于 Promise 的代码），即使这样做没意义。\\n\\n我能理解异步代码让周围的代码也异步，但是 Promise 却强制让同步代码周围的代码也变成异步的。这就是 Promise 的又一个 opinionated 之处。一个中立的方案不应该强制数据的传递方式是同步或是异步。我认为 Promise 是一种「有损抽象」，类似于「有损压缩」，当你把东西放在 Promise 里，然后把东西从 Promise 里拿出来，这东西就跟以前不一样了。\\n\\n想象你在一个连锁快餐店里点了一个汉堡，服务员立即拿出一个做好的汉堡递给你，但是把手伸过去接却发现这个服务器死死地抓住这个汉堡不给你，他只是看着你，然后开始倒数 3 秒钟，然后他才松手。你拿到你的汉堡走出快餐店，想逃离这个诡异的地方。莫名其妙啊，他们就是想让你在拿餐之前等一会，还说是以防万一。\\n\\n### then() 其实是 map() 和 flatMap() 的混合体\\n\\n当传递一个回调给 then 的时候，你的回调函数可以返回一个常规的值，也可以返回一个 Promise 实例。有趣的是，两种写法的效果一模一样。\\n\\n```\\nPromise.resolve(42).then(x => x / 10);\\n// 效果跟下面这句话一致\\nPromise.resolve(42).then(x => Promise.resolve(x / 10));\\n```\\n\\n为了防止 Promise 套 Promise 的情况，then 内部遇到返回值是常规的值就转换成 Promise 实例（译注：这就是 map，参见 hax 对 map 的解释 Promise<T>.then(T => U): Promise< U >），遇到 Promise 实例就直接使用（译注：这就是 flatMap，Promise<T>.then(T => Promise< U >): Promise< U >）。\\n从某种程度上说，这么做对你是有帮助的，因为如果你对其中的细节不是很了解它会自动帮你搞定。假设 Promise 其实是可以提供 map、flatten 和 flatMap 方法的，我们却只能使用 then 方法来搞定所有需求。你看到 Promise 的限制了吗？我被限制只能使用 then，一个会做一些自动转换的简化版 API，我想做更多控制都是不可能的。\\n很久之前，Promise 刚被引入 JS 社区的时候，一些人有想过为 Promise 添加 map 和 flatMap 方法，详情你可以在这篇讨论里看到。不过参与语法制定的人以 category theory 和函数式编程等理由反驳了这些人。\\n\\n我不想在这篇文章里对函数式编程讨论太多，我只说一点：如果不遵循数学的话，就基本不可能创造出一个中立的编程原语。数学并不是一门与实际编程不相关的学科，数学里的概念都是有实际意义的，所以如果你不想你创造出来的东西出现自相矛盾的情况的话，也许你应该多了解一些数学。\\n\\n这篇讨论的主要焦点就是为什么不能让 Promise 有 map、flatMap 和 concat 这些方法。很多其他的原语都有这些方法，比如数组，另外如果你用过 ImmutableJS 你会发现它也有这些方法。map、flatMap 和 concat 真的很好用。\\n\\n想象一下，我们写代码的时候只管调用 map、flatMap 和 concat 即可，不用管它到底是什么原语，是不是很爽。只要输入源有这些方法即可。这样一来测试就会很方便，因为我可以直接把数组作为 mock 数据（译注：而不需要去构造一些 HTTP 请求）。如果代码中使用了 ImmutableJS 或生产环境中的异步 API，那么测试环境中只要用数组来模拟就够了。函数式编程中说的「泛型」「type class 编程」和 monad 等都有类似的意思，说的是我们可以给不同的原语以一批相同的方法名。如果一个原语的方法名是 concat 另一个原语的方法名是 concatenate，但是实质上它们做的是几乎相同的事情，就很令人讨厌了。\\n\\n所以为什么不把 Promise 理解成跟数组差不多的概念，有 concat、map 等方法。Promise 基本上可以被 map，所以就给 Promise 添加 map 方法吧；Promise 基本上可以被 chain，所以就给 Promise 添加上 flatMap 方法吧。\\n\\n不幸的是现实不是这样的，Promise 把 map  和 flatMap 挤到 then 里面，并加了一些自动转换逻辑。这么做只是因为 map 和 flapMap 看起来很类似，他们认为写成两个方法有点多此一举。\\n\\n## 总结\\n\\n好吧，Promise 也能工作，你可以用 Promise 搞定你的业务而且一切都运行良好。没必要惊慌。Promise 只是看起来有点怪异了，而且真不幸它还很 opinionated。他们强加给 Promise 一些在某些时候毫无意义的规则。这么做问题不大，因为我们可以很容易的绕过这些规则。\\nPromise 很难复用，没关系我们可以用额外的函数搞定；\\nPromise 不能被中断，没关系我们可以让那些本该中断的任务继续执行，不就是浪费了一些资源而已嘛。真烦人，我们总是要给 Promise 做一些修修补补；真烦人，现在新出的 API 都是基于 Promise 的，我们甚至给 Promise 发明了一个语法糖：async/await。\\n\\n所以接下来几年我们都要忍受 Promise 的这些怪异之处。如果我们一开始就把延迟执行考虑到 Promise 里，也许 Promise 就是另外一番光景了。\\n如果 Promise 的设计初期就是从数学角度思考会是什么样子？这里我给出两个例子：fun-task 和 avenir，这两个库都是延迟执行的，所以有很多共同点，不同点主要体现在命名和方法可访问性上。这两个库都比 Promise 更不 opinionated，因为它们：\\n\\n1. 延迟执行\\n1. 允许同步\\n1. 允许中断\\n\\n## 反驳\\n\\n本文就是要吐槽 Staltz 最近写的这篇文章《Promises are not neutral enough》。\\n\\nStaltz 作为 Cycle.js 的作者，也算是社区名人之一。最近他搞了一个大新闻叫 Callbag（Why we need Callbags），一看名字就是给 callback 招魂的。这篇我不打算吐槽 callbag（想看吐槽 callbag 的可移步：callbag和rxjs有什么区别？），就单吐槽一下 Staltz 对于 promise 的偏见。\\n\\nStaltz 说 promise 是“opinionated primitive that introduce a lot of weirdness”，并列了四点 opinion：\\n\\n1. Eager, not lazy\\n1. No cancellation\\n1. Never synchronous\\n1. then() is a mix of map() and flatMap()\\n\\n我一点点来说。\\n\\n第一点，promise 是 eager 立即求值而不是 lazy 延迟求值。\\n\\n其实这个事情是有点扯的。因为所有语言、库里的 promise 抽象（有些叫 future 或 deferred，语义上有些差别，但是在此问题上不重要，所以这里不展开说）都是如此。也就是说如果还需要用户主动调用 x.run() 来开始计算，那就不是 promise 了。那叫 task（或 fiber，或类似的 thunk）。\\n\\n（当然不排除世界上有些傻逼库硬是要做一个 lazy future 之类的东西。其实你既然要提供不同的抽象，安安心心的叫 task 就好了，不要把概念搞乱行不行。）\\n\\n到底 task 好还是 promise 好？这本身其实有点关公战秦琼。因为两者其实是不同的抽象。task 的抽象侧重于“执行（任务）”，而 promise 的抽象侧重于“（最终的）值”。这不同的抽象选择导致不一样的语义和 API，是一件非常自然的事情。若侧重于“执行”，那自然应该允许用户选择何时执行，也没有必要限制执行一定是同步的还是异步的，甚至无所谓是否在单独线程里跑 —— 直接抵达了 thread 的领域。而若侧重于“值”，那用户为什么要 care 这个值的运算过程？\\n\\n其实如果你需要控制执行（sometimes you don’t want the promise to start right away），或重用异步任务（you may want to have a reusable asynchronous task），直接写一个返回 promise 的函数，或者一个 async 函数就好了啊！函数就是用来表达执行的啊！如此简单而自然！\\n\\nStaltz 当然知道这一点，但他强词夺理说函数就不能用 then 来 chain 了。我擦，人家 promise 就是一个异步值的原语，then 方法只是为了在没有 async/await 的时代，提供你一个利用异步值的基础设施。（否则你压根没法用啊！）然而你为什么要让它去管函数链式调用？你如果要处理一般的函数链式调用，自己 compose 函数啊，或者等着 pipeline operator 啊！（在别的地方你倒知道吹 pipeline operator，怎么说起 promise 来就忘了？？）\\n\\n说什么“Eager is less general than lazy”，完全是胡说八道。你在一个 lazy 的语言比如 haskell 里这么说也就算了，你在一个明明全然是 eager 的语言里说“eager is less general”，颠倒黑白没有这么流利的吧？\\n\\n第二点，没有 cancellation。确实 promise 没有内置这能力（cancelable promise 提案因为各种原因被撤销了）。但是现在有 cancelation 提案（tc39/proposal-cancellation）啊，而且最新版浏览器已经支持了一个非常类似的方案（DOM Standard）！（当然dom规范里的 AbortController/AbortSignal 如何跟语言规范里的机制协调可能是个棘手问题，有待处理，不过大方向是没有问题的。）\\n\\nStaltz 说“I believe lack of cancellation is related to eagerness.”不好意思，全错。你后面提到的 cancel 在向上游传播时的问题，本质上在于向上传播本身就是概念混乱的产物，跟立即执行没有半毛钱关系。建议好好再学习一下 cancelation token 提案的 architechture 部分（tc39/proposal-cancellation#architecture）。\\n\\n比较神奇的是\\n\\nTry to pay attention to the words “opt-in”, “restriction”, “always”. When a behavior is opt-in, it is neutral. When a behavior is always forced, it is opinionated.\\n这段完全是稻草人攻击。实际上 cancellation 无论是当前提案还是 dom 规范里的设施，都是独立于 promise 的，所以必然是 opt-in 的。\\n\\n其实前面的 eager 问题也是。显然返回 promise 的 function 就提供了所谓 lazy，且 promise 和 function 是独立特性，所以我们可以说你所谓的 lazy 是 opt-in 的。但是你反过来说这是 restriction？？这双重标准是怎么玩的？？\\n\\n第三点，总是异步。这一点其实没有好多说的。node callback convention 也包含了这一点（只不过 callback 形式很难强制约束这一点，这是 callback 的缺陷之一）。对此有疑问的人建议再好好读 Isaac Z. Schlueter 多年前的经典文章：http://blog.izs.me/post/59142742143/designing-apis-for-asynchrony 。\\n\\n所以 forEach 的例子正说明问题。forEach 明确的告诉你这里是同步的。promise 则明确的告诉你这里是异步的。这是为什么 promise 必须总是异步，且你应该在所有处理异步的地方都使用 promise。这样就不会出现你看到一个 callback 但是搞不清它是同步还是异步了。\\n\\n为什么同步异步之分在 JS 里那么重要？因为 JS 不是 pure 函数式语言！JS 代码会依赖副作用，而副作用取决于代码的执行时序。JS 有 run-to-completion 语义，所以只要明确是同步还是异步，其执行时序是非常容易推断的。\\n\\n下面忍不住要逐段打脸。\\n\\n    The impossibility of going back to synchronous once you convert to Promise means that using Promises in a code base will force code around it to be Promise-based even when it doesn’t make sense.\\n\\nPromise 本来就是异步原语。异步当然不能被转换为同步啊！除非你用阻塞。而在 JS 里提供阻塞等于提供一把注定会打死你自己的枪。promise 也并没有把所有代码都变成基于 promise 的，传给 then 的回调完全可以是纯同步的代码啊！\\n\\n    I can understand why async code forces surrounding code to become async too, but Promises make this effect worse by forcing sync code to become async. That’s yet another opinion inserted into Promises.\\n\\n说来说去就是说异步的传染性。你要是依赖一个异步值，你的函数当然就得是异步的啊。但是你已经 await 到一个值之后所做的计算可以抽成一个纯同步的函数啊。自己模块化做不好，怪语言设施…… 再说你不是 observable 和 pipeline operator 玩得很溜嘛，又没说不许用。\\n\\n    A neutral stance would be to have the primitive make no claims whether the data will be delivered synchronously or asynchronously.\\n\\n同样的话也可以用来批评 haskell，你们搞什么 pure，搞什么 lazy，完全不“中立”！\\n\\n    Promises are what I call a “lossy abstraction”, similar to lossy compression, where you can put stuff in that container, but when you take it out of the container, it’s not quite the same as it was before.\\n\\n对“抽象”的理解简直一团屎。按照这说法，高级语言都是“lossy abstraction”，汇编才是无损纯真的代码！\\n\\n说了半天其实 Staltz 就是有意忽略一点，Promise 对 JS 来说就是异步原语，由此施加额外约束是应有之义。你所谓“中立”的结果无非是给程序员留坑。\\n\\n最后一点，Staltz 吐槽 then() 不是正宗原味 monad。这算整篇文章比较有技术含量的部分了。然而首先，map 和 flatMap 的签名是：\\n\\n```\\nM<T>.map(T => U): M<U>\\nM<T>.flatMap(T => M<U>): M<U>\\n```\\n\\n而 then 的签名是：\\n\\n```\\nPromise<T>.then(T => U): Promise<U>\\nPromise<T>.then(T => Promise<U>): Promise<U>\\n```\\n\\n易见，then 实际上是自动 overload 版的 map/flatMap。Staltz 吐槽点就是，干嘛不直接暴露 map/flatMap 呢？这样就可以跟其他 monad 小伙伴一起玩耍啦！\\n\\n我先不说你是不是真的有场景要统一操作异种 monad，我先把你提到的“马上就要到来的”Array.prototype.flatMap 拿出来看一下。\\n\\nArray<T>.flatMap(T => Array< U>): Array< U>\\n\\n理想上其签名应该是这样的，然而，JS 不是静态类型语言啊！谁确保传进来的回调是 T => Array< U> 呢？如果返回值不是 Array，那就等于传进来了 T => U 啊。\\n\\n于是你突然发现，Array.prototype.flatMap 明明跟 Promise.prototype.then 是一样的，自动 overload 了！\\n\\n所以，在动态类型语言里，只要你不打算做运行时检查类型扔 TypeError 这种事情，flatMap 对回调的结果进行自动 wrap（从而 overload 了 map）是必然的选择。\\n\\n所以 then 就是 flatMap。唯一的问题是为什么 promise 不像 array 一样提供单独的 map？\\n\\n为什么要提供？我先不说提供单独的 map 方法让你可以得到 Promise<Promise< U>> 有毛个意义。我们谈理论。\\n\\n在 monad 鼻祖的 haskell 那里，定义 monad 只需要 2 个操作：return 和 bind。return 就是 wrap/unit，即从 T => M<T>。而 bind 就是 flatMap。\\n\\n所以 Promise 从 Haskell 本源意义上说千真万确就是一个 monad。当然我们也可以用另一个方式定义 monad，使用 3 个操作：return、fmap 和 join。\\n\\nfmap 就是 map，join 则是 flatten，即将 M<M<T>> 打平为 M<T>。\\n\\n所以本来你就有两种方式定义 monad，一种用 flatMap，一种用 map + flatten。实际上很容易理解，有了 map 和 flatten 你就可以实现出 flatMap。但是，反过来说，有 flatMap 我们也可以实现出 map 和 flatten。\\n\\n```\\nfunction map(f) { return this.flatMap(x => wrap(f(x))) }\\nfunction flatten() { return this.flatMap(x => x) }\\n```\\n\\n所以 promise 本身不提供 map 和 flatten 方法并没有任何问题。当然你可以吐槽 JS 没有内置的 mixin 语法或 extensive methods（其实都有提案），使得统一接口比较麻烦，但无论如何吐槽不到 promise 。\\n\\n当然，promise 有特殊之处，比如 wrap 操作理论上不能直接用 Promise.resolve，因为 Promise.resolve(promise) 并不返回 Promise<Promise<T>>。实际上在 JavaScript 中是不可能产生 Promise<Promise<T>> 嵌套类型的。显而易见，这一限制是出于实际编程的考虑。但是 Staltz 直接否定了这一点。\\n\\nSo it’s better to recognize that Promises can practically be concatenated, so they should have the concat method.\\n问题是你不能简单的吹说“practically”，你得拿出真实 use cases 啊！嘴炮谁不会？你倒是真拿一个把 Promise 给 concat 起来的例子啊！\\n\\n### 结论部分。\\n\\n上面我已经把 Staltz 的各点批驳完毕。\\n\\n关键点在于，promise 的出发点是提供异步原语。有意无意的忽略这一点，所有论证就都乱来了。Promise 的设计总体上没有任何问题，Staltz 希望的：\\n\\n所谓 lazy\\n直接在 promise 接口上提供 cancel()\\nresolve 时而同步时而异步\\n提供无意义的 Promise<Promise<T>>\\n才是 weird、unfortunately opinionated 的。\\n\\n    Promises were invented, not discovered. The best primitives are discovered, because they are often neutral and we can’t argue against them. For instance, the circle is such a simple mathematical concept, that’s why people discovered it instead of inventing it. You often can’t “disagree” with a circle because there’s no opinion embedded in it, and it occurs often in nature and systems.\\n\\n说不清道理，就上比喻，文章里那无聊的 food 比喻我就不吐槽了，这里又拿圆形来比喻。一股浓郁的民科风。\\n\\n实际上，编程设施全都是发明出来的。从最基本的二进制补码整数类型、IEEE754浮点数、Unicode字符，到复杂的数据结构如红黑树、bloom filter乃至神经网络，无一不是发明出来的。各种语言的语法语义也都是发明出来的符号系统。包括monad。我们发明它们用来表达运算逻辑。（其实真正搞数学的人，会告诉你数学里也是如此，符号公理系统都是发明出来的。）\\n\\nPromise 是发明出来的，node callback conversion 或者 Staltz 自己搞的 callbag 显然也都是发明出来的。或者我们换个正常点的词，这些东西是为了一定目的被设计出来的。如果有人说我发现了某某，多数是谦辞，表示不是我牛逼，只是运气好而已。真正可以被发现的，只有客观存在。编程里有什么东西是真的发现出来的？估计只有 bug 吧。\\n"}'));jctx.push(JSON.parse('{"id": "200102", "tag": "tool", "text": "# 命令行工具用法探索\\n\\n## ls\\n\\n`--hide`可以隐藏不想看的目录\\n\\n## find和xargs\\n\\n最核心参数是path和expression，这两个参数都有默认值，path是当前目录，expression就-print，相当于只输入find和tree的效果类似。所有的expression一定是`-`号开头，find解析就以此为依据。\\n\\nwindows用 `dir <findname> /-n /b /s /a-d` 模拟。\\n\\nxargs和find同属于findutils包，xargs原本就是为find而开发的\\n\\nfind在文件扫描机制上更灵活。遇到一个问题：一个U盘的文件夹下大约放了50W张图片，ls没反应，cp \\\\* 报错argument too long。最后用`find | xargs -i cp {} dest/`才复制了一批图片出来，进而找到名字规律，再用find -name 规则对文件夹重新分桶才完成数据迁移。\\n\\n## pkill\\n\\n默认仅process匹配，-f变为command line匹配\\n\\n## info\\n\\nH 打开按键帮助\\n\\n{} 向前或向后查找上一次的关键字"}'));jctx.push(JSON.parse('{"id": "200105", "tag": "os", "text": "# 硬盘操作和文件系统散记\\n\\n## 硬盘操作\\n\\n首先要明确个概念，每块硬盘都有设备和分区这层概念，一块硬盘当然对应一个设备，但会有一到多个分区，util-linux包提供了多个操作硬盘的程序。\\n\\n* fdisk: 应该是最有名的程序了，fdisk -l显示当前总线上已经识别出的设备\\n* lsblk: 显示块设备、dev的major/minor号、挂载点等。关于lsblk命令查看分区和挂载目录的关系，其实mount也能看，但如果装过容器，mount会看不清楚，这时用lsblk就很方便\\n* blkid: 只会列出分区，但可以识别文件系统。比如/dev/sda被分成了sda1和sda2，用blkid看不到sda，只能看到sda1和sda2，行为和df命令一样。而lsblk既能看到设备也能看到分区\\n* hdparm: 只知道，不太会用\\n\\n以上这些命令都是针对硬盘，所以就算没有挂载，也可以看到硬盘。\\n\\nfile命令的-s选项可以查看块设备的特性，比如`file -s /dev/sda`能看到这块盘是GRUB启动程序，接着又是若干个分区。而直接`file -s /dev/sda1`就只显示分区信息，可见/dev/下面分开显示sda和sda1并不是无意义的。\\n\\n### 磁盘挂载失败记录\\n\\n服务器磁盘被拔，导致系统进入emergency模式，即使login所有服务也未启动。原因出在盘被拔，但/etc/fstab却没有修改，系统认为缺少盘所以进了应急模式。每块磁盘会有个UUID，fstab也是通过这个来找盘。用blkid命令可以看到所有盘的UUID。两相对比去掉不存在的盘就行。\\n\\n修改后不用重启，mount -a就能挂载。这时又出现新问题，报UUID重复错误，用mkfs.xfs -f /dev/sdx格式化硬盘，再挂载就没问题了。\\n\\n磁盘写入有两种模式\\n\\n* write through: 直写式，数据不做校验直接写入磁盘，写完后再读出来后写校验值。性能差，可靠性高？\\n* write back: 写回式，数据先写到cache，再用cache计算校验值，然后数据和校验一起定入磁盘，如果cache足够大且性能强，可以一直写入。有些RAID卡要开启这种模式，除了有cache，还要有电池，保证掉电后cache数据也能写入磁盘。\\n\\n## 文件系统\\n\\n安卓有`protect_f`和`protect_s`分区，s是f的备份，专门用来保存SIM ME LOCK数据，运营商专用机就是修改这份数据达到的。原来是保存在/data分区，为保证恢复出厂时不用重新生成，干脆做成独立分区。\\n\\n文件系统单个分区上限取决于单个簇大小和簇个数，比如ext3的簇个数是uint32，取常见的簇大小4K来算，分区上限就是16TB。（似乎ext3簇大小不可改，NTFS可以改成单簇64K使上限达到256T）\\n\\nZFS的默认簇是128K，在和PG数据库配合时，其默认记录大小是8K，如果数据库用于零散查询较多的场景，最好用`zfs set recordsize=8k zp1/data`也调整到8K效率更高。"}'));jctx.push(JSON.parse('{"id": "200108", "tag": "os", "text": "# shell的模式与选项\\n\\n起因是看到有人写脚本，用/bin/cp方式复制文件，说是因为cp在复制时如果文件名相同会提示是否覆盖，导致脚本会停住。这个行为是因为操作系统对root用户默认alias cp=\'cp -i\'导致的，所以用/bin/cp绕过，我于是想到为何不在脚本开头用unalias去掉cp的定义，后面直接写cp就方便了。\\n\\n验证时却发现会提示unalias cp not found。于是在终端下尝试，第一次成功，第二次提示同样错误，这就说明在fork出的shell环境下没有alias，不需要特意用/bin/sh。但是为什么子shell没有继承alias？又加了alias发现不仅cp没有继承，其它的都没有被继承。\\n\\n网上有人说这个特性只有交互模式才会打开，即bash --login才能用，又有人说要用shopt方式显示打开，可是试了似乎都不对。忽然想到alias是shell的buildin命令，说明是进程独有的功能，而fork子进程时，只能通过环境变量传递参数，既然alias不属于环境变量，也就无法自动地传递给子进程，只能显示地加载/etc/profile之类的文件才能使alias生效。\\n\\n## 交互与登陆模式\\n\\n交互模式 interactive，仅输入bash，也是最常见的模式，为交互模式。而参数中有文件名或-c方式调用语句，就是非交互模式。看`$-`有没有i来判断。由于不需要交互，.bashrc就不会读入(新版本才有的特性)，节约脚本执行时间。\\n\\n登陆模式 login，和交互模式是完全正交的。login指非常早期就启动的shell，会读入profile类文件，后面的用户在duplicate shell操作时，是fork了这个login shell，真实得到的是ono login但interac。前文提到的通过ssh触发的bash就是这种模式。登陆模式下可以用logout退出，用shopt 观察。登陆模式用于显示tips或欢迎信息，默认不打开，su的时候就比较静默，也可以强制su --login显示欢迎词。\\n\\n习惯上，non interactive, login是很罕见的，只在部分X程序会用。\\n\\n不同模式读入配置是不同的\\n\\n```\\n/etc/profile   交互模式读入，似乎有误，当为登陆模式\\n/etc/bashrc或bash.bashrc  似乎并不会被读，通用配置保存在这里\\n~/.bash_profile   login按序读以下3个，读到停止\\n~/.bash_login\\n~/.profile\\n~/.bashrc    non-login读\\nBASH_ENV   非交互模式使用\\n```\\n\\n## 选项\\n\\nPOSIX规范要求用set控制选项，bash增加了特有的shopt并在另一个命名空间保存这些选项。set不能影响shopt，但shopt用-o可以操作set空间。set空间以全大写的环境变量为主，而shopt都是小写。\\n\\n选项会对脚本的执行带来微秒的影响，有一次我不经意间引入了`set -e -u`，导致程序无法执行，看了帮助手册才明白这代表error exit，当命令退出状态是失败时，整个脚本就退出了。由于我原来的代码中会用grep判断tar包中是否有一个文件，当不存在时grep会以失败退出，如果不加-e选项，并不会引起问题，但当更严格的-e开启后，程序就不再继续执行。而-u则对$1这样的变量展开做了更严格限制，如果不存在就退出，$@和$\\\\*不受-u开启的影响。\\n\\n## 非阻塞同步\\n\\n后台方式调用其它脚本，紧接着用`$!`记录下进程号，最后用wait方式等待结束。"}'));jctx.push(JSON.parse('{"id": "200122", "tag": "tool", "text": "# putty的配置\\n\\nputty是个免费且方便的终端工具，其它像xshell等在按下Alt时会触发菜单栏，导致使用emacs时不好用，但是putty默认的配置不如xshell方便，列举如下\\n\\n首先在Connection菜单开启保活，keepalives设置为300，否则长期不用会断开远程连接。\\n\\n默认情况下字体很少，先勾上Appearance的Allow selection of variable-pitch fonts，就能选择Lucida Console，此后关掉这个选项还是可用，怀疑是个bug。\\n\\n配色，终端定义了文本、背景和8种ANSI颜色，每一种又可以叠加Bold属性。规范只定义了有这些选择，具体如何展示还取决于终端软件的设定甚至和显示器效果也有关系。putty默认文字颜色较暗且文件夹的蓝色和背景接近，很难看清，建设改为以下配色\\n\\n以下3个数字分别表示RGB\\n\\n* Default Foregroud: 230/230/230  网上很多方案推荐全用255，这样会和Bold Foregroud一样，不能区分两种信息，最好稍暗一点\\n* Blue: 30/140/240\\n* Blue Bold: 85/190/255\\n* Red: 200/0/0\\n* Magenta: 200/0/200\\n\\n还有一些ANSI控制码，如：nA (光标上移n行 )、nB(光标下移n行 )、nC(光标右移n行 )、nD (光标左移n行 )、2J(清屏)、K(清除从光标到行尾的内容)、s(保存光标位置)、u(恢复光标位置)、?25l(隐藏光标)、?25l(显示光标)。     其中 ，\'\\\\033[0m\'用于恢复默认的终端输出属性，否则会影响后续的输出。\\n\\n基于常用参数，可定义如下单一控制宏，用于printf系列语句：\\n```\\n#define NONE                 \\"\\\\e[0m\\"\\n#define BLACK                \\"\\\\e[0;30m\\"\\n#define L_BLACK              \\"\\\\e[1;30m\\"\\n#define RED                  \\"\\\\e[0;31m\\"\\n#define L_RED                \\"\\\\e[1;31m\\"\\n#define GREEN                \\"\\\\e[0;32m\\"\\n#define L_GREEN              \\"\\\\e[1;32m\\"\\n#define BROWN                \\"\\\\e[0;33m\\"\\n#define YELLOW               \\"\\\\e[1;33m\\"\\n#define BLUE                 \\"\\\\e[0;34m\\"\\n#define L_BLUE               \\"\\\\e[1;34m\\"\\n#define PURPLE               \\"\\\\e[0;35m\\"\\n#define L_PURPLE             \\"\\\\e[1;35m\\"\\n#define CYAN                 \\"\\\\e[0;36m\\"\\n#define L_CYAN               \\"\\\\e[1;36m\\"\\n#define GRAY                 \\"\\\\e[0;37m\\"\\n#define WHITE                \\"\\\\e[1;37m\\"\\n\\n#define BOLD                 \\"\\\\e[1m\\"\\n#define UNDERLINE            \\"\\\\e[4m\\"\\n#define BLINK                \\"\\\\e[5m\\"\\n#define REVERSE              \\"\\\\e[7m\\"\\n#define HIDE                 \\"\\\\e[8m\\"\\n#define CLEAR                \\"\\\\e[2J\\"\\n#define CLRLINE              \\"\\\\r\\\\e[K\\" //or \\"\\\\e[1K\\\\r\\"\\n```"}'));jctx.push(JSON.parse('{"id": "200125", "tag": "tool", "text": "# tags的说明和比较\\n\\n通用编辑软件用于代码有两个点，看时方便跳转和写时方便补全，跳转靠的就是tags。\\n\\ntags有两种主流实现ctags和etags。ctags诞生于BSD系统，是vim能原生识别的格式，而etags是emacs的附属品。两者生成的文件格式不同，但ctags能生成etags的格式，似乎ctags使用更广，emacs上有插件能识别ctags格式。\\n\\n不同语言的要素不同，ctags有相应的选项来识别，从而更好地跳转。默认什么都不加也能工作，显然加上会更精准。识别要素有3种类别\\n\\n1. kinds: 用--list-kinds=xx 显示默认会识别哪些元素，如果要调用，用--xx-kinds=+-yy 选项\\n2. fields: 比如 i 表示如果有继承，要标明父类； a 表示如果是类的成员，要标明其public/private属性； S 表示如果是函数，要标明函数的signature；\\n3. extra: 默认只包括函数的名字，不包括类名，用了--extra=+q会有类名\\n\\n早期的tags只包含definition，universal ctags已具备简单的reference功能，外围配套还不是非常成熟。\\n\\n## 文件格式\\n\\nctags是纯文本文件，每行是一条记录，原始的vi格式很简单，`{tagname}<Tab>{tagfile}<Tab>{tagaddress}`，定义标签名，所在文件，所在行的完整内容(ex模式)。当编辑器触发跳转定义时，从tags文件找到匹配的行，并解析出对应的文件名，再根据最后的模式精确定位到行，核心功能很好理解。vim对行格式做了增强，在原来行的末尾增加`;\\"<Tab>{tagfield}...`，其中`;\\"`会被vi识别成注释，保持兼容性。后续内容是type<tab>key:value，type是单字母形式，kv对可以有多个。\\n\\netags由多个section组成，每个section对应一个源文件。段间和段内含有少量不可打印字符，绝大多数仍是文本。段与段间由两行`<\\\\x0c>`分隔，然后是文件名和tag的字节数，接下来也是每行一个tag定义，`{tag_definition_text}<\\\\x7f>{tagname}<\\\\x01>{line_number},{byte_offset}`，和ctags相比，由于直接保存行号和偏移，在尺寸上etags要小很多，但是如果对一个在编辑中的工程来说，增加内容导致行号变化，会使etags失效，而ctags方式的按文本匹配会更健壮。"}'));jctx.push(JSON.parse('{"id": "200126", "tag": "os", "text": "# 安卓程序的构建与链接\\n\\n## configure的改造\\n\\n尝试在安卓编译python，保证PATH有gcc/ar/make，再改几行脚本就行。\\n\\n1. configure以及触发的config.sub和install-sh默认通过/bin/sh执行，要换成可以运行的sh路径。\\n2. configure中有CONFIG_SHELL变量默认指向/bin/sh，可以改脚步也可以通过export这个变量来修改，但必须export，只是在shell定义没用。因为configure会fork大量进程，只有export后子进程才能感知到\\n3. 手动修改configure的`__ANDROID_API__`为某个版本，怀疑可能个用的gcc有关，好在改完这行就能用了\\n\\n## linker\\n\\n在termux(android5 API21)编译的程序，放到4.2的机器上执行，报`line 1: syntax error: unexpected \\")\\"`无法执行，第1行出现/system/bin/linker字样，故有此文。\\n\\n在android 2.x及4.0或更远古时代，系统在执行一个elf文件时，这个elf文件是固定加载到某个内存位置的。而后来llvm的出现，使得编译出来的elf文件，可以加载到内存中的任意位置，这种就叫pie。5.0后的android系统强制要求只能加载pie的文件，也就是说，使用gcc编译的固定基址的elf文件就再也不能执行了(大概这也是termux只支持clang不支持gcc的原因？)。\\n\\nAndroid在启动一个新的进程的时候，调用execv函数族trap到内核，由kernel去检查和加载可执行文件；kernel做完可执行文件的加载的同时会加载/system/bin/linker，然后由linker去加载依赖的动态库，并调用可执行文件的入口函数，完成控制权的转移。linker还参与了调试的一些东西。通俗地说，它是一个elf文件的解释器。"}'));jctx.push(JSON.parse('{"id": "200203", "tag": "lang", "text": "# [翻译]funarg问题\\n\\n很多新的编程语言都支持function as first class特性，即函数可以像普通的值一样传入或传出。但函数和变量有个最大的区别，函数会引用变量，如何保证变量的生命周期就成了问题(因此称为function argument，即funarg问题)。具体的困难在于，定义函数的环境和执行函数的环境是不同的，标准的解决办法要么禁止这种引用，要么创建闭包。主流语言的实现方式简列如下\\n\\n这个问题细化又有两种分支，向上funarg(函数调用返回函数)和向下funarg(把函数作为参数传递给函数)。\\n\\n## 向上funarg\\n\\n总共有4种方式\\n\\n1. 一种简单的做法是把变量保存在堆上，然后用GC回收，一些scheme实现这么做。但这样效率不如在栈上，且显著地增加实现复杂度，对没有GC的语言非常困难。\\n2. 逃逸分析，在编译期做筛选，只对涉及向上funarg的创建堆上变量，其它就不用管。\\n3. 在创建闭包时把值复制到闭包，但这只适合不变的值，比如ML和Java就是这种方式，ML的变量全是constant，对java来说“引用”的东西必须是final的，否则被改了之后闭包里的值不会更新。\\n4. 显式指定引用的变量，把指定的扔堆上，比如php的use语句和object-c的\\\\_\\\\_block\\n\\n## 向下funarg\\n\\n这种情况由于上层的栈还在，引用通常不会造成问题。但对于tail-call和CPS风格的代码，会有额外的工作量。此时不能简单地完全把栈替换掉，否则会触发变量无法找到的问题。相比向上funarg，向下并不是什么难题，因此Pascal语言支持向下funarg，但不支持向上funarg。\\n"}'));jctx.push(JSON.parse('{"id": "200207", "tag": "tool", "text": "# 多终端打开软件用法\\n\\n## GNU screen\\n\\n修改默认的引导键C-a时，命令行启动时使用screen -e^tt绑定到C-t。前一个t表示自定义命令字符，相当于所有命令的触发按钮，后一个t表示转义字符，因为C-t被占用了，必须按C-t t才能被screen里面的程序理解为C-t，这个特性很少用。也可以在.screenrc中加上escape ^yy转义。\\n\\n离开screen环境的常用命令(以下用sr表示)\\n\\n* sr -ls 展示当前已有的会话，本质是列出已连接的socket(有几个连接，就在~/.screen/目录下有几个文件)，如果socket断开，会显示dead，这时用-wipe可以清除这些socket\\n* sr -r [pid] 恢复，如果只有一个不用输入pid\\n* sr -xRR 如果后台有一个现有的screen，则连上去，否则创建一个新的\\n\\n在screen内的快捷键(cmd表示映射的)\\n\\n* C-? A 修改窗口名称\\n* C-? \\" 展示所有窗口，进而切换\\n* C-? : 进入交互式命令行窗口，方便临时修改配置\\n\\n一些发行版(termux、alpine)在执行时，窗口大小会变化，手动改width会提示your termcap does not specify your terminal width。原因是那些发行版使用terminfo，需要转换后才能修改终端窗口。[这里](https://www.math.utah.edu/docs/info/screen_15.html)有完整的说明。\\n\\n进入screen默认没有任何显示，通过修改hardstatus来表示(hardware的意思，似乎这个是硬件内嵌吧)。\\n\\n## tmux\\n\\n配置文件.tmux.conf\\n\\n```\\n# Send prefix\\nset-option -g prefix C-a\\nunbind-key C-a\\nbind-key C-a send-prefix\\n\\n# Use Alt-arrow keys to switch panes\\nbind -n M-Left select-pane -L\\nbind -n M-Right select-pane -R\\nbind -n M-Up select-pane -U\\nbind -n M-Down select-pane -D\\n\\n# Shift arrow to switch windows\\nbind -n S-Left previous-window\\nbind -n S-Right next-window\\n\\n# Mouse mode\\nset -g mouse on\\n\\n# Set easier window split keys\\nbind-key v split-window -h\\nbind-key h split-window -v\\n\\n# Easy config reload\\nbind-key r source-file ~/.tmux.conf \\\\; display-message \\"tmux.conf reloaded\\"\\n```\\n\\nSend prefix\\n把prefix的ctrl+b变为了ctrl+a，因为这样按起来方便些。基本上用tmux的都改了这个。\\n\\nUse Alt-arrow keys to switch panes\\n不用按prefix，直接用alt+箭头在pane之间switch。实际用过之后才发现真是太方便了！\\n\\nShift arrow to switch windows\\n不用按prefix，直接用shift+箭头在window之间switch。太方便了！\\n\\nMouse mode\\n开启鼠标模式。用鼠标就能切换window，pane，还能调整pane的大小，方便！\\n\\nSet easier window split keys\\n这一部分是用来更方便切分pane的。prefix + v 代表竖着切，prefix + h 代表横着切。比起默认的切割方法不仅直观而且方便。\\n\\nEasy config reload\\n下一次如果修改了.tmux.conf的设置的话，不用关掉tmux。直接用prefix+r,就能重新加载设置。\\n\\n2 Panes\\n\\n分割pane\\n\\nprefix + % :水平分割pane\\nprefix + \\" : 竖直分割pane\\n退出\\n\\nexit ： 退出一个pane，直接在shell里输入即可，这个比快捷键方便\\n放大一个pane\\n\\nprefix + z : 把当前一个pane放大（zoom in)。比如在用ls查看output的时候，因为一个pane可能空间太小，所以把这个pane放大，你可以把注意力全放在这个pane里。回到之前的多pane状态的话只需要重复一遍命令即可(zoom out)\\n在pane之间switch\\n\\nprefix + 上下左右的箭头 :这个说实话还是不方便，之后会有设置的方法来用鼠标选择pane\\nresize the pane\\n\\nprefix + （ctrl）+上下左右箭头 : 与上面命令不同的是，ctrl + b按完之后，不要松开ctrl，一直按着，然后再按箭头来调整。不过因为在mac下ctrl+箭头是切换屏幕，所以还得在偏好设置->键盘->快捷键->Mission Control里把对应的快捷键取消掉。\\n3 Windows\\n创建window\\n\\nprefix + c : 创建一个新的window。最下面会多出window的编号。有*号所在的window就是当前正在操作的window。\\n在不同的window间移动\\n\\nprefix + 数字1，2，3 : 因为能看到不同window的数字编号，所以直接输入想去的window的数字编号即可\\n关闭window\\n\\nprefix + & ： 关闭当前window\\n重命名window：因为创建新的window后，下面除了数字编号不同外window名称都是一样的。所以为了知道每一个window是什么，最好重命名一下。\\n\\nprefix + , (逗号）：更改window名称。但是这里遇到一个问题。更名后，我随便使用ls或cd命令后，window名称会随着目录的不同而变化。google后发现这个是zsh下oh-my-zsh的特性。于是打开~/.zshrc, 讲DISABLE_AUTO_TITLE=\\"true\\"这一行反注释掉。source ~/.zshrc后，测试更改的名称，发现一切正常。\\n\\n5 Session\\n查看所有的session（在terminal输入）\\n\\ntmux ls : 这个命令是在terminal里输入的。当前正常运作中的tmux server会显示（attached）。没有的话就是已关闭，tmux server在后台运行。\\n更名session（tmux状态下输入）\\n\\nprefix + $ : 更名后好让自己知道每一个session是用来做什么的。通常一个session对应一个project\\n创建session的时候直接命名(在terminal输入）\\n\\ntmux new -s py35 : 新建一个名为py35的session\\n断开一个session(detached) （tmux状态下输入）\\n\\nprefix + d ：退出session。在只有一个window的状态下，直接输入exit也能退出\\n重新连接某一个session wich name（在terminal输入）\\n\\ntmux a -t py35 : 重新连接py35 session。这里的a是attach的意思\\n偷懒连接上一个session（在terminal输入）\\n\\ntmux a : 如果只有一个session的话，这个是最快的连接方法\\n删除session（在terminal输入）\\n\\ntmux kill-session -a -t py35 : 删除除了py35以外的所有session\\n\\n## 附录\\n\\nvim支持的终端库有5种：tinfo, ncurses, termlib, termcap, curses。应该只是实现不同，都有相同的函数。"}'));jctx.push(JSON.parse('{"id": "200314", "tag": "protocol", "text": "# 经度纬度和GeoHash\\n\\n对经纬度对应的长度，我一直有个错误的认识，经度共360度纬度180度，而地球又非常接近球形，意味着每1经度的距离只有纬度的一半。但是在看了GeoHash后发现在赤道上，1个经度或纬度的地理距离是一样的，每度约111.3km，每秒31米，换算成小数点后4位是10米，和民用GPS精度一致。有些项目要求到小数点后5位甚至6位，精度1米甚至0.1米，其实是不可能达到的。随着纬度越来越高，1个经度间的距离会逐渐减少，到北纬50只有71km，更往北则缩减得越快。\\n\\n经度是整个地球一周，此时纬度只需要标识出半周，两者结合就可以唯一定位一个点，因此纬度的范围是经度的一半，但每度是一样的。比方说从东经和西经可以区分中国和美国，但北纬却无法区分。\\n\\n网上文章说GeoHash5的分块，精度约为5km的正方形。由于到南北极点会收缩，其实每个分块是球面梯形。GeoHash5的纬度方向，严格的说只在赤道附近才是5km，北纬45度的边长只有3.93km（5km x pi x 45/360），而北纬45度以上的块，是个球面三角形，面积只有靠近赤道的1/3。当然附着切分越来越细，上下两条边的差距会变小，但始终不能认为相等。\\n\\nGeoHash有12级，因为每4级间相差1024倍，只要记4级就很快能推导出全部。每级相差8倍和4倍。\\n\\nGeoHash第1级划分是8x4个块（2纬3经），第2级则是4x8个块（3纬2经）。在编码层面，每层下探时矩阵会转置，对角值也会互换。\\n\\n以杭州为例，GeoHash5约横跨0.05个经纬度，GeoHash7跨0.0015个经纬度。"}'));jctx.push(JSON.parse('{"id": "200321", "tag": "data", "text": "# 数据库SQL优化原理\\n\\n粗略地说关系型数据库都是这几步，具体前后顺序根据不同dbms不同配置下略有小差\\n\\n1. 应用程序与数据库服务器建立链接\\n1. sql发送到数据库，数据库验证是否有执行的权限\\n1. 进入语法解析器，进行词法与语法分析\\n1. 进入优化器生成执行计划，部分dbms会检查是否有可重用的执行计划\\n1. 根据执行计划依次扫描相关表中的行，不在数据缓冲区的走io\\n1. 同时对于被扫描的行可能加锁，同时也可能会被其他sql阻塞\\n1. 扫描的行足够放入查询缓存则开始运算或直接返回，不够则生成临时表，可能消耗io\\n1. 对sql结果进行计算（可能）\\n1. 将计算完成的结果全部写入网络io（可能）\\n1. 如果事务完成则同步事务日志并释放锁，具体方式取决于dbms和当前配置\\n1. 关闭连接（可选）\\n\\n这么多步骤，每一步都有优化策略\\n\\n1. 应用程序与数据库服务器建立链接，引入数据库连接池，避免每次都与数据库建立连接，提高效率\\n1. sql发送到数据库，数据库验证是否有执行的权限。没撒好说的\\n1. 进入语法解析器，进行词法与语法分析。也没撒好说的，想要数据库在这里少用点资源就把sql写的简单点，但是差别不大\\n1. 进入优化器生成执行计划，部分dbms会检查是否有可重用的执行计划。最复杂的部分来了，任何数据库如何生成执行计划都可以写一本几百页的书。\\n\\n关系型数据库选择走什么执行计划都是基于消耗最小化的思路来的，简单来说就是走什么索引，按什么顺序走表，被扫到的数据行最少。如果你的表结构很复杂，有各种混搭的索引，你的join很多，那执行计划分析的时间就会拉长。所以sql对应的表索引简单，join或子查询少就快，复杂了优化器也会得选择困难症。\\n\\n1. 根据执行计划依次扫描相关表中的行，不在数据缓冲区的走io，存储引擎扫描表的性能消耗参考下面的list，消耗从大到小\\n\\n> 全表扫描>全索引扫描>部分索引扫描>索引查找>唯一索引/主键查找>常量/null\\n\\n要走索引对于sql语句也有要求，不能在谓词上作任何运算，扫描行数一般不能超过表的17%左右，这对你数据分布又有要求，比如你查select xxx from human where sex =\'man\'，五五开，还是走扫描。推荐一本书《Relational Database Index Design and the Optimizers》\\n\\n1. 同时对于被扫描的行可能加锁，同时也可能会被其他sql阻塞。如果扫描的行多，sql执行的时间长，被阻塞的概率就高，阻塞别人的概率也高，然后大家一起等，数据库就hung住了\\n1. 扫描的行足够放入查询缓存则开始运算或直接返回，不够则生成临时表，可能消耗io。一次取的尽量少，这不单指返回服务端的行数，应该从嵌套最深的一个子查询开始算\\n1. 对sql结果进行计算（可能）少用各种复杂的函数啊，count啊，order by啊等等\\n1. 将计算完成的结果全部写入网络io（可能），请尽量少返回一点数据，如果不行请多次分批\\n1. 如果事务完成则同步事务日志并释放锁，具体方式取决于dbms和当前配置。这里举两个代表性栗子:\\n\\nsql渣：\\n\\n```\\nfor i in (1-1000):\\nstart transaction;\\ninsert into table values (1);\\ncommit;\\nend for\\n```\\n\\nsql赞：\\n\\n```\\nstart transaction;\\nfor i in (1-1000):\\ninsert into table values (1);\\nend for\\ncommit;\\n```\\n\\nsql赞爆：\\n\\n`insert into table values (1)()...()(1000);`\\n\\n首先，sql语法是我临时自创的，这个不是关键，关键在sql渣先生是1000个事务插1000行，日志flush1000次。sql赞先生是一个事务插1000行，事务日志flush1次。sql赞爆最nice。这个例子我想表达的意思是如果你要用sql做一件事，那就要尽量让这件事占用的事务总时间最少。\\n\\n第二个例子\\nsql渣：\\n\\n`update table where id > 0 and id < 1000000;`\\n\\nsql赞:\\n\\n```\\nupdate table where id > 0 and id < 1000;\\nupdate table where id >= 1000 and id < 2000;\\nupdate table where id >＝ 2000 and id < 3000;\\n```\\n\\n这个例子我想表达的意思是如果你要用sql做一件很大的事，那就尽量让大事化成很多小事。两个例子好好体会下，一点不矛盾哦。补充一下，这里每个update都是单独事务\\n\\n1. 关闭连接（可选）。同1，别每次都关，关了也许还要重连。不关的话记得commit就好了，千万要记得commit啊！"}'));jctx.push(JSON.parse('{"id": "200327", "tag": "data", "text": "# 数据库计算理论笔记\\n\\n## 事务和隔离级别\\n\\nJim Gray于1970最早提出事务的ACID特性，虽然它们并列为四大特性，但重要程度并不同。\\n\\n* A 原子性，单机版已经很好地解决了这个问题，但分布式环境似乎仍然无解\\n* C 一致性，只描述了最终的效果，过于宏大也没有提出具体的措施，因此更像是个衍生结论\\n* I 隔离性，事务中最复杂的特性，分了多个隔离级别，较低的级别其实是在正确性上做了妥协，将异常结果抛给应用层解决，从而获得更好的性能\\n* D 持久性，它的核心思想是应对系统故障，由此衍生出诸如WAL日志、日志同步/半同步、共享等多种具体技术\\n\\n可以说事务模型的发展过程就是隔离性和性能之间平衡的历史，甚至可以说隔离性是事务核心。\\n\\nSQL92定义了4种隔离层级，不久后Jim Gray于1995年发表了经典论文《A Critique of ANSI SQL Isolation Levels》，正式提出了快照隔离的概念。同年Oracle很快就做出了回应，但它的First Update Win方案却不同于《批评》的First Commit Win方案。顺便说句PostgreSQL也和Oracle一样用了FUW方案。早期的MySQL存储引擎并不支持事务，InnoDB出现的时候，计划基于IBM的Aries算法做出MV2PL（多版本两阶段锁），但有学者在2009年基于此改造实现了快照隔离和串行快照隔离SSI，虽然如此但MySQL官方并不支持SI，只是做了可重复读RR。反倒是PG吸收了学界的成果，把SI和SSI合并到产品中。\\n\\nSQL92之所以不提快照隔离并不是想不到，而是因为当时的实现主要基于锁并发，而快照隔离的基础是MVCC。当然到了现代，MVCC已经成了一种底层技术，用来高效实现乐观或悲观并发控制。乐观和悲观的区别就如字面意义，通过两段简单的代码来展示区别\\n\\n乐观控制\\n\\n```\\nselect * from goods where id = 1   -- 不加锁读\\nbegin; -- 读之后开始事务\\nupdate goods set stock = stock - 1 where id = 1 and stock = cur_stock;  -- 更新时要注意 where 条件 “stock = cur_stock”，只有程序中获取到的库存量与数据库中的库存量相等才执行更新\\ncommit;\\n```\\n\\n悲观控制\\n\\n```\\nbegin;  -- 先打开事务\\nselect * from goods where id = 1 for update;  -- 读时用for update对数据加锁\\nupdate goods set stock = stock - 1 where id = 1;  -- 写时不再校验\\ncommit;\\n```\\n\\n可能是单机数据库的历史原因，也可能是应用层为了快速开发，占据主流还是悲观控制。\\n\\n## 一致性协议\\n\\n数据在多节点间的同步，应用较广的有这几种协议\\n\\n* 两阶段提交，即prepare和commit，要求所有节点都一致，高可用性不足\\n* paxos/raft，中心化广播协议，前者是论文的提法，后者则是后来另一篇论文给出的几乎完整实现。可以看作是复制协议的一种，属于多数共识算法，大部分节点可用即通过\\n* gossip协议，适用于P2P网络的同步协议，在节点非常多的时候，paxos负担会很重，这种场景用gossip更好\\n\\n## 分布式\\n\\nCAP三者只能选其二，也可以只求一个达到最大化，没有见过实际例子。\\n\\n* 取CA，又名强一致性 ACID，但是分布式系统必然要求P，所以可以把ACID和传统单机的数据库等同\\n* 取AP，又名弱一致性 BASE，从命名中也能看出舍弃了C，在不追求严格准确（或者说始终最新）的场景有一定应用\\n* 取CP，用得最广，似乎没有专门的一致性定义\\n\\nCAP和ACID的C，中文都叫一致性，但两者含义稍有不同。CAP的C指多副本、单操作的一致性，而ACID的C，在最初的论文定义中是指单副本、多操作的事务一致性。\\n\\n## 数据分片\\n\\n分片是单机分区机制在多副本的一种扩展，有两种\\n\\n* Hash分片，为做到适应扩容，都会用一致性Hash算法。这种做法平衡性好，但业务不敏感，扫描时必须全副本都执行，归纳起来就是写性能出众，但读性能较差\\n* Range分片，原生的分布式数据库多采用这种方案，多个分片间使用raft协议组成Group组，每个Group是最小的高可靠单元\\n\\nSort和Shuffle是MapReduce上最核心的操作，由于MR每一步都会写磁盘，因此任意节点都能恢复，同样的，只要做足checkpoint也能非常健壮。"}'));jctx.push(JSON.parse('{"id": "200330", "tag": "os", "text": "# 【考古】删除和退格键\\n\\n最初的Unix终端是Teletype ASR33，由纸带穿孔机以及纸带阅读机和键盘组成。Backspace和Delete并不属于该键盘上的按键\\n\\n在键入内容的时候如果出错，则需要按下^(ctrl)+H向teletype发送一个退格命令，使得穿孔机移回之前的位置，然后按下Rubout键再发送一个删除命令才能做到删除对应位置内容\\n\\n之后为了方便开始制造带有backspace按键的终端，同时完成退格和删除两个功能\\n\\n后来Rubout键被改名为Delete，一些Unix公司决定在键盘中加入Delete键（用于删除一个字符），这些公司决定用Delete代替^+H代表退格。因此，情况变成了一些键盘可以按下Backspace删除字符，另一些要按下Delete。\\n\\n对于现在的键盘来讲，实际情况是有Backspace键时按下后则会触发退格加删除两个操作，此时的Delete键的作用只对应删除这一个操作，因此Backspace键删除的都是光标之前的字符，Delete键删除的是光标之后的字符；如果没有Backspace键则用Delete键来代替（也是退格加删除两个操作）。\\n\\n对于一些文字（比如天城文）Backspace 会按“字母”逐个删除，Delete 则是删掉一个音节。不过这个和历史无关，也许是windows特有的做法。\\n"}'));jctx.push(JSON.parse('{"id": "200402", "tag": "lang", "text": "# 嵌套加载的目录查找方式比较\\n\\n动态语言的加载通常会有一个路径列表，加载时按列表顺序寻找。这个列表里大部分是绝对路径，但也会有当前相对路径，当嵌套加载时，相对路径如何定位就是个容易迷惑的问题。以下的目录结构为例\\n\\n```\\nmain.lang\\nutil/\\nlib/\\n    a.lang\\n    config.lang\\n```\\n\\n入口是main.lang，在main里导入包不会有歧义，但是在a.lang如何导入config就不那么明确了。下面列举不同语言的作法。\\n\\n## lua\\n\\n不管当前执行加载语句在哪个文件，相对路径查找的参考系，始终是入口执行文件。因此在a中加载config，只能写成require \'lib.config\'\\n\\n## python\\n\\nimport加载没见过绝对路径方式，默认的相对路径参考系，是入口执行文件，但可以通过`.`或`..`（但不能带`/`符）来改变相对路径所指向的目录。\\n\\n* 在a.py加载util，写成 import util，表示按main的路径来寻找\\n* 在a.py加载config.py，写成 import .config，通过.告诉解释器，以a.py的路径为相对路径，寻找包，此时config和a在同一目录下，因此.config能加载\\n\\n## php\\n\\ninclude或require语句的参数有3种形式\\n\\n1. 绝对路径，以`/`或`C:\\\\`等开头的文件，没什么好说的\\n2. 相对路径，以`./`或`../`开头的文件，始终以解释器执行入口的文件作为查找参考系，a加载config必须写作include \'./lib/config.php\'\\n3. 未确定路径，搜索路径包含`.`时，会从执行入口文件和当前嵌套加载的文件都查找一遍，在a加载config写成include \'config.php\'或include \'lib/config.php\'都可以，不愧是最强大的语言\\n\\n网上有说PHP的惯用法是在入口定义`__ROOT__`变量，其它模块文件都引用这个变量，并用绝对路径的方式加载。"}'));jctx.push(JSON.parse('{"id": "200411", "tag": "protocol", "text": "# 不可打印字符与转义序列\\n\\nplan9的老人们建过一个网站cat-v.org，影射cat命令加上-v选项是邪恶的。这个选项的作用是把不可打印的控制字符显示出来，低128用^，高128用M-前缀，在一些终端类软件上会用到这些符号。\\n\\nASCII的编码0到31，0对应^@，接下来是^A-^Z，从27到31依次是`[\\\\]^_`，127是^?。从128开始，显示的时候前面会有M-前缀，比如128对应0，显示为M-^@，依此类推。而从160开始，对位字符是可打印字符，在前面加上M-，比如33是!，则161显示为M-!。\\n\\n用cat -v显示的话，制表符和回车不会按^I和^J显示，要分别用-T和-E选项，-T会把Tab显示为^I，而-E会把回车显示为$，且实际上也会另起新行。用-A则是结合了vET这三个选项，显示所有不可打印字符。\\n\\n题外话：按下键盘上的回车键，相当于按下Ctrl+M，而Tab键则相当于Ctrl+I键。在bash中用bind -P查看按键映射，会发现自动补全的按键序列只显示Ctrl+I，一旦把Ctrl+I映射成其它功能，Tab键的功能也就跟着变了。\\n\\n## ASCII码中不可打印字符\\n\\n偶然间看OpenBSD开发的mandoc.db格式，提到用了3种格式，32位int和NUL结尾字符串都很普通，但第3种字符串列表的表述`lists of NUL-terminated strings, terminated by a second NUL character`，0是NUL，second NUL查看了ASCII表，对应的是2，含义是start of text。\\n\\nASCII的前32个是控制字符，用在电传打字时代，来看看相近的几个描述，1-SOH(start of headling), 2-STX(start of text), 3-ETX(end of text), 4-EOT(end of transmission)。可以看到1开始文章标题，然后是2文章正文，3文章结尾，到4结束传输之间可能还有些附录、索引要添加。包括其它的请求应答、回车制表换行等，不可打印字符在文章结构划分、控制版式上是有实实在在的作用的。\\n\\n## 转义序列\\n\\n开发出Unix最早版本的PDP系统，既没有光标也没有删除，更没有上下左右键，有兴趣的可以体验[模拟器](http://pdp11.aiju.de/)。更友好的显示肯定是刚需，于是各厂商就开发各种转义协议，让屏幕出现光标、重绘、颜色等特性，起初厂商间各自为战，好在美国人向来有搞标准的习惯，1978年的VT100便是符合这个标准最初的成功样本。\\n\\n规范规定，转义序列在带内传输，序列总长度不固定，但必须以ESC开头，后面再跟0x40-0x5F字符(`@A–Z[\\\\]^_`)。比较常见的有\\n\\n* \\\\033[ 终端显示色彩用的就是这个命令\\n* \\\\033] 操作系统命令\\n* \\\\033_ Application Program Command(APC)\\n* \\\\033\\\\\\\\ 字符串终止，可以用于APC的结束\\n\\n最早的颜色序列只有3位，共8种颜色，加上粗体被实现为亮色，只有4位。后来又逐步扩展出8位，而libvte库更是支持24位颜色(需要依赖X11，比如xterm等图形界面)。"}'));jctx.push(JSON.parse('{"id": "200427", "tag": "os", "text": "# Linux内核与PAM模块简记\\n\\n前因是容器中启动nfsd需要依赖内核加载ko模块，分读写记一下。\\n\\nlsmod命令，或查看/proc/modules看到内核当前加载的ko模块。\\n\\n/lib/modules/{ver}-{arch}/kernel 这里放的是所有可以加载的内核模块，以4.19为例，共有3559个，但初始启动加载的只有58个。ko文件之间有依赖关系，通过modinfo查看，查看原理也是从上述提到的内核路径中查找。\\n\\n所有的ko操作命令有6个，都是/bin/kmod的别名。\\n\\n## PAM模块\\n\\n类Unix系统的一套授权管理机制，Pluggable Authentication Modules，由SUN在1995年10月提出，并由ReaHat在1996年8月首次实现。典型的效果比如接ssh失败过多时，PAM会禁止登陆，ssh自身并不提供这种机制。\\n\\n`pam_tally`基于用户的计数，当次数达到则触发规则，同时还配有`pam_tally2`应用程序查看和清空次数，不过在1.5版本的pam去掉了这个程序并引入`faillock`替代。\\n\\nLinux将PAM分为4个阶段\\n\\n1. 用户模块，检查目标用户是否符合规则，比如用户是否过期，是否有权访问某个服务等\\n2. 认证模块，检查用户认证方式，也可以和keyring交互\\n3. 密码模块，确保密码符合规则，保证密码强度\\n4. 会话模块，确定此会话的边界和属性\\n\\n业界一直对pam不支持远程操作有争议，因为这导致了kerberos不兼容，后来又发展出SASL规范。"}'));jctx.push(JSON.parse('{"id": "200506", "tag": "os", "text": "# 用户态锁\\n\\nfutex不是个完整的锁，他是“支持实现userspace的锁的building block“。也就是说，如果你想实现一个mutex，但不想把整个mutex都弄到内核里面去，可以通过futex来实现。但futex本身主要就是俩系统调用futex_wait和futex_wake.\\n\\n关闭无图模式：我的 > 设置 > 无图模式\\n为了更好的解释这个问题，这里先梳理下锁本身是怎么工作的。\\n\\n一个完整的锁需要解决几个问题：\\n\\n争抢到一个内存，如果抢到了就算是得到了锁，可以继续干活；\\n如果没抢到，可以选择：\\n继续抢（spin）\\n调用某个系统调用把自己挂起来排队\\n别的线程释放锁后，会通知排队挂起来的一个或几个线程。醒过来的线程再去重复第一步。\\n早期的锁，所有这些步骤都是内核态的。但后来大家发现，步骤1用CAS在用户态就可以干了。而多线程大部分的时候抢锁都是没有竞争的，一抢就能抢到。一下子没抢到多抢几次大概率也能抢到了。\\n\\n因此后来的锁的设计都优化成了这样：\\n\\n1. 在用户态写一段代码来抢锁，典型的实现是用CAS把一个指定的变量从0变成1。如果抢到了就结束了。此时是用户态的。\\n\\n2. 如果抢不到，就看看是不是锁的持有者就是自己。如果是，也算是抢到了（当然要对变量做特殊的标记）。否则就spin几次重新抢。这也是用户态的。\\n\\n3. 如果实在抢不到，就意味着竞争发生了，此时调用futex_wait进入内核态，去把自己挂起+排队，等着被释放锁的线程futex_wake。\\n\\n所以只有3进入内核态了。考虑到大部分情况都不是竞争很激烈的情况下，3根本就不用做。这样的锁的设计避免了由于系统调用导致的上下文切换，无疑很大的提高了效率。\\n\\nOk, 回到Java。Java的synchronized用JVM的monitor实现。而monitor实现内部用到了pthread_mutex和pthread_cond。这俩是pthread标准接口，实现在glibc里。而这俩的内部实现在Linux上目前都用到了futex。所以整体可以理解为futex帮助Java在Linux上实现了sychronized，同时Java自己也实现了很多用户态的同步代码和优化（比如锁偏向一类的）。两块代码共同提供了完整的锁功能。\\n\\n顺便说一句，基于AQS实现的JUC的那些ReentrantLock，Semaphore等内部也是类似的。其LockSupport.park内部用的也是这套东西。\\n"}'));jctx.push(JSON.parse('{"id": "200509", "tag": "lang", "text": "# 代码写法中的状态与异常\\n\\n最近在做构造数据的工作，代码是另两人写的python，在改造过程中，修正了我以往对对象和异常的认识。\\n\\n以前写代码既不爱用类和对象，也不用异常捕获，这次造数据的代码全部是定义各种函数和调用，用法不复杂。但造数据的需求很多，从而就导致函数参数非常多，写起来代码非常啰嗦。参数多的另一个坏处是在多处调用时，不容易一致。\\n\\n## 有状态的执行体\\n\\n构造表数据需要带入参数，但是这个数据其实是和函数绑定的，完全可以合并到一起，用闭包或对象来表达。函数式推崇无状态，但我不确定闭包是否为函数式所接受，但在具体的工作中，带状态的可执行体是非常有用的。\\n\\n## 使用异常\\n\\n有些表数据的构造有依赖关系，如果前置表没有被构造，这张表就不应该被构造。这时有两个选择：\\n\\n1. 隐式构造被依赖项\\n2. 返回错误或抛异常\\n\\n开始想隐式构造，动态构造函数在main函数中被sys.argv给绑定了，于是转而返回错误，至少显示提示也不失为一种选择。如果返回错误，由于表很多，代码会显得非常啰嗦，所以想到用异常。异常有个好处，具备穿透性，不管层级多深，可以直接穿过多层直到被捕获的地方，另外异常还必须要能携带值，否则只有异常类型，捕获了也无法进一步处理。python3的异常语法和2不兼容，似乎只能带str类型的变量，于是通过这条路径，把缺失的表名用异常抛出来，在main函数中显式地补上。\\n\\n反思这次的代码修改，以往偏好理论派的东西其实在实际工作中并不能很好地应对。以我现在的状况，也不可能在理论上有太多的造诣，让更多实际的代码能写得优雅，利用好常见语言的特性，更为重要和实际。\\n\\n## 模拟的隐患\\n\\nPython的异常没有ruby的retry机制，为了模拟在try块的外围加了一层while循环，并在except里用count计数累加，保证重试N次后能退出。但过了一段时间，又加了一个种异常捕获，这里忘记对count累加，导致循环无法退出。模拟的方式终归只是权宜之计，最好的办法仍是以DSL配套完整的机制才可行。"}'));jctx.push(JSON.parse('{"id": "200606", "tag": "lang", "text": "# Python的包机制\\n\\n## 包的封装\\n\\npython的第三方包默认会安装到site-package目录，除了存放源码的目录，还有一个元数据目录类似这样`<name>-<ver>.dist-info`。包的封装机制有easy_install的egg和pip的wheel两种，dist-info表示wheel打包，egg-info说明是egg包，目录中包含的文件不同。另外anaconda有自己的conda方案，没有研究过。egg不仅是发行格式，也是运行时可以直接加载的格式；wheel只是发行格式，安装就是将文件解压到site-package的过程。通常都建议wheel，毕竟有PEP背书，特殊场合比如不想被直接看到代码，打包到一个文件更简洁。python由于版本不兼容原因，最好配合venv/virtualenv指定版本，否则依赖库会冲突。\\n\\n安装PyHive包，以tar包源码形式发布，执行setup.py之后在这台机器上可用，但去site-package目录下看到的却只有一个egg包，和pip方式安装得到的几个目录方式不同，直接复制这个egg包到其它目录后，会提示无法找到PyHive。直到用easy_install安装这个egg包，才明白要在site-package下的easy-install.pth文件里添加一行关于PyHive的版本说明，才能找到。大概原因是import机制会忽略带有连字符的包，而egg包一定有连字符，需要需要.pth文件做个牵引。\\n\\n## 自定义安装位置\\n\\n标准版本启动时会执行`import site`，而embed版本则没有此行为。标准版通过-S选项关闭此特性，embed版本则通过修改.pth文件来打开此特性。如果有-S选项，会反映在`sys.flags.no_site=1`。\\n\\nsite.py一旦被导入，会在builtins中增加help, copyright, credits, license变量。除此外可以额外添加两个加载包的路径，`USER_SITE`类似全局的位置，而`USER_BASE`默认指向当前用户的`~/.local`目录。第三方可以仅给某些用户安装，因此`USER_BASE`的价值就体现出来了。但要启用这个机制还有个前提，getuid和geteuid，getgid和getegid的返回必须相同，否则会认为是sudo行为，不予加载。\\n\\n## import过程\\n\\n结合q这个包和一些试验，看整个import xxx过程发生了什么。\\n\\n1. 先判断sys.modules[\'xxx\']是否存在，有值直接结束，没值则查找文件。注意：*不是判断当前上下文是否有xxx变量*。\\n2. 找到xxx.py并读取，在开始读取前，sys.modules[\'xxx\']已经被初始化，并且具有了`__name__`、`__doc__`等内置变量\\n3. 随着对xxx.py的解析，xxx模块定义的类、函数也会被添加到sys.modules[\'xxx\']\\n4. 结束对xxx.py解析，在当前上下文，新增xxx变量，并让xxx指向sys.modules[\'xxx\']。如果在import xxx之前已经有xxx变量，会覆盖xxx。\\n\\nq这个包就在第3步结束前，覆写了sys.modules[\'q\']变量，实现了import q后，q就能使用的魔术技法，同时也隐藏了q的实现类，非常巧妙。\\n\\n## 控制符号的导出\\n\\n`__all__`变量只对import \\\\*语法有作用，如果手动地导出一个确实存在的变量，`__all__`是不会阻拦的。从字面含义也好理解，all对应的是\\\\*，当然不影响手动导出符号，不过也可见这套机制的简陋。同样py文件中的函数也是这个道理，所有以_开头的函数，用import \\\\*都是看不到的，但是如果知道名字，仍然可以手动调用，所谓防君子不防小人是也。\\n\\n## Windows环境的包特性\\n\\nPython标准包有近百个目录和文件，在分布运行时非常不便，尽管可以把第三方包做成zip，但标准包却不行。因此官方针对Windows提供了embeddable方式的二进制包，把标准包也做成了zip包，而python程序在编译时加了特殊配置，直接加载标准zip包。\\n\\nembeddable方式会寻找`python3x._pth`文件，x是次版本号，找到后将`_pth`的每行加入搜索模块的路径。\\n\\n包的加载路径，如果存在site-packages目录，它会被加入sys.path；而如果根本没有这个目录，sys.path就不会去搜索这个目录。有些包会额外产生一个命令行程序，典型的比如pip。pip在更新自己时需要替换pip.exe，但由于Windows的机制不允许替换自己，现象是pip目录会被改名为\\\\~ip，再次执行会报找不到pip。解决办法就是把\\\\~ip改回pip就可以了，因此Windows上似乎只能删了重装pip。\\n\\n## venv机制\\n\\n官方提供的venv包会把一个目录做成相对独立的环境，具体过程不复杂\\n\\n1. 在该目录下建立bin/lib目录和pyvenv.cfg文件\\n2. 将venv目录的activate文件复制到bin\\n3. 使用标准库ensurepip安装一套独立pip/setuptools到bin和lib\\n\\nvenv初始化后，source bin/activate，会把当前目录放到PATH的开头。于是当前会话下的pip操作就会把要安装的新包放到这个独立目录（退出shell或执行deactive则仍旧用全局pip）。python复用全局命令，观察此时的sys.path，会发现site-package已经换成venv指定的目录了（其它标准目录不变）。\\n\\nvenv有个个人认为很重要但默认没有开启的选项--system-site-packages，但其实也可以编辑pyvenv.cfg将include-system-site-packages = false改为true就可以了。解析pyvenv.cfg的逻辑是写死在site.py中，只要包含了基础包即可，不依赖pip。引用原始py的包后，仍可以升级且不会破坏原始的包版本。升级后，虚拟环境中是新版本的包，而原始环境仍保留不变，两边各留一套互不影响。\\n\\n还有--without-pip选项，不过除了构建虚拟环境快以外，我想不出有什么使用场景。在venv中使用pip和原生使用的配置文件是一样的，意味着用同样的代理，这也好理解，毕竟venv的机制是对PATH做文章，而pip读配置是用户的HOME目录，两者没有交集。\\n\\n## 使用C/Cython写扩展并用setup.py安装\\n\\n官方早期提供的distutil包可以制作无依赖的安装包，为支持更复杂的场景，产生了第三方的setuptools，包制作仍然基于distutil，扩展了依赖包管理。但是distutil的文件比较混乱，而且setuptools都会完整地内嵌一份，到了3.10版本官方正式确定废弃distutil，全面改用setuptools。easy_install现在也是setuptools的一个子模块。\\n\\n最基本的扩展需要setup.py和xx.c两个文件，c文件要依次注册module和method集，以及具体的method wrap实现，最终通过注册函数在加载时导入python空间。这种方式显然非常复杂，可以换用cython语法写pyx，通过cythonize转化为C语言，一样能开发扩展且极大简化开发过程。注册示例\\n\\n```\\nfrom distutils.core import setup\\nfrom Cython.Build import cythonize\\nsetup(ext_modules=cythonize(\\"xxx.pyx\\", language_level=3))\\n```\\n\\n执行setup.py有多种子命令，bdist编译egg包，如果本地装了wheel，可以用python setup.py bdist_wheel指令打成wheel包。egg包放到pypi的仓库中，无法用pip安装，会提示no match version之类错误，但包名是包含了版本的，原因不明。\\n\\n存放代码的目录可以随意命名，distutils的setup函数有非常多参数，有一些概念要注意区分\\n\\n* name=\'abc\' 包的名字，只是一个宣传用的名字，对程序运行没有特别的作用，也不要求和import的包名一致。安装之后，包描述目录的METADATA文件会显示这个name\\n* packages=[] 包安装到site-package后的目录名，可以和包名不同，也可以有多个。一般一个包安装一个目录，但像cython就会装两个目录(cython和pyximport)\\n* package_dir={} 安装到site-package的目录名和源码目录的映射关系\\n* ext_modules = [ Extension(\'x\', sources=[\'x.c\'])] C语言写成的扩展模块\\n\\n上面packages两条，我觉得都是非常糟糕的设计，灵活到让初学者非常迷惑，比如import的包名，在pip freeze却很可能找不到对应的包名，甚至描述目录名都没有与之对应，直到找到了目录的MEATDATA文件才找到包名。但也可能是import用的名字会有很多人想要，于是允许不同的包名安装时用不同的名字（相当于pip注册时是不同的），但安装后用同一个目录名。如果真的产生冲突，那就由用户自己决定。\\n\\n有些包用pip安装后会触发C编译，如果头文件不在标准路径下会失败，用`pip install --global-option=build_ext --global-option=\\"-I/your/py/head/\\"`方式添加头文件路径可以正常编译。\\n"}'));jctx.push(JSON.parse('{"id": "200725", "tag": "data", "text": "# Spark学习手记\\n\\n## 组件构成\\n\\n作为一个分布式系统，物理节点分为master和worker节点，master调度，worker计算。\\n\\n运行职责，即进程级的分为driver（属于master）和executor（属于worker），另外还有类似接口协议的进程cluster Manager（和driver通信）。既然是接口，就有多种实现，常见的有spark clusterManager（standalone和local cluster两种运行模式）、yarn clusterManager（spark on yarn） 和mesos clusterManager（spark on mesos）。\\n\\ndriver端执行main函数，并创建SparkContext，这是Spark启动最重要的类，包含两个必须设置的属性：master和appName。Executor并行计算，是一个执行Task的容器，初始化程序要执行的上下文SparkEnv，解决应用程序需要运行时的jar包的依赖，加载类。SparkContext可以创建RDD。\\n\\n## RDD\\n\\n这是Spark中最早，也是最基础的计算元素，可以理解为元素无序的向量（数组）。由于不可变性，每个RDD在Spark会话中都会被赋予一个惟一ID，这些ID又构成计算的链路，在计算出错需要重算时可以方便地恢复。\\n\\nRDD所有元素的类型相同，分为2种值类型\\n\\n1. 单Value类型：存放简单类型，如int，string\\n2. Key-Value类型：整个值的类型称为Row，Row类型的第一列是key，剩下的是values，可以想象成lisp的list，key和value分别对应car和cdr操作。针对key可以进行lookup、join等运算。当value包含的内容很多时，为了更细粒度地操作，还可以把Row类型转换为DataFrame，就能对每一列单独指定操作方法。\\n\\nRDD的五大属性和若干种实现\\n\\n1. partitions(分区数量)\\n2. partitioner(分区方法，可以为None)\\n3. dependencies(依赖关系): 运算就是在多个RDD间的变换，如果一个父RDD变换后得到多个子RDD，就是宽依赖，也称为shuffle；一个父RDD只得到一个子RDD，则称为窄依赖。\\n4. compute(获取分区迭代列表)\\n5. preferedLocations(优先分配节点列表)\\n\\n## RDD的操作和任务执行过程\\n\\n大多数文章都把RDD的操作分为transform和action两类，trans还能再细分，这里采用细分后的4种类型。\\n\\n1. 创建操作（creation）：pyspark只提供了parallelize；scala还提供makeRDD\\n2. 转换操作（transformation）：从一个RDD得到另一个RDD，绝大部分都是此类操作\\n3. 控制操作（control）：persist和cache，优化性能\\n4. 行为操作（action）：将惰性计算进行求值，比如collect, count, take, save, foreach, reduce。特别要提的是，**reduce是行为，但reduceByKey是转换**，二者不可混为一谈。\\n\\n区分的依据是：trans不会马上执行，而是等到action才会触发计算。为什么trans不触发计算呢，因为计算的成本太高，计算过程要尽量合并，很多中间步骤，在不急于显示结果时，没必要计算。以groupByKey为例，分组不是最终目的，对分组做的聚合运算才是用户真正想要的。因此分组时，只需要把计算过程规划好，不必急于把计算任务派发到数据分区。\\n\\nRDD的分类，体现在任务运行粒度上，就分为大小两种，app(1个) > job > stage。每当代码中遇到transformation（意味着要创建新的RDD），会继续分析，直到遇到action类操作，就会产生一个job来真正执行所有的transfomation和这个action。job中如果有shuffle操作（trans和action都会产生shuffle），就会产生前后两个stage（HDFS读写文件是stage内的操作，不会产生切分）。也可以说每个stage内部是窄依赖，会做fusion优化，而stage之间则是宽依赖。每个stage处理的rdd数据，又会根据其有多少个 partition，运行相同个数的 task（每个task是一个线程），每个 task 只处理一个 partition 上的数据。所以一个stage也叫一个taskset。\\n\\n任务执行过程分4步\\n\\n1. 解析代码中的RDD操作，根据转换关系形成DAG图\\n2. 将DAG图交给DAGScheduler组件（包含在SparkContext中）进行逻辑拆分，具体做法是从最后一个RDD向前回溯，遇到action算子切分出一个job，每个job内根据shuffle类划分stage\\n3. 拆分后的stage链，交给TaskScheduler（包含在SparkContext中）做物理执行，分派到具有空闲资源的worker结点\\n4. work对收到的每个调度，启动一个线程执行task，结果结果返回给TaskScheduler，最终在driver端汇总\\n\\n### 分区的解释\\n\\nRDD是个逻辑概念，它的数据通常会分布在多个worker节点，拆分的个数由partition决定，partition数量既可以大于，也能小于worker数量，计算一个真实有数据的partition对应一个task任务。分区的数量，如果直接创建，可以在参数指定，如果是从HDFS读取，则由文件分块数量决定，最小是2，大的有十几甚至上百。题外话，正因为数据是分散在多个worker节点，如果想要看到全貌，要用collect()，方法命名非常到位。\\n\\nRDD实现类举例\\n\\n1. MapPartitionsRDD\\n2. ParalellCollectionRDD\\n2. ShuffledRDD\\n3. ReliableCheckpointRDD\\n\\n## 从RDD到DataFrame的转变\\n\\nSpark最初只有RDD做为通用的计算接口，也称为Spark Core，并没有SQL功能。因为无类型，导致性能优化遇到瓶颈，在1.3版本演化出了DataFrame，天然和SQL相近，此时整个项目的核心也迁移到Spark SQL。为了管理库和表元数据，在SparkContext基础上，加入SQLContext（是个InMemory实现，2.0版本还有一个外部源实现HiveContext），就变成了SparkSession。session类有个catalog成员可以查看映射的库和表。SQL也是经由DataFrame最后转成RDD才执行。2.0版本只能指定一个catalog，3.0版开始支持multiple catalog。\\n\\n## DataFrame\\n\\n是Row类型RDD被绑定schema后的性能优化版。RDD用.toDF转化为DF（简单类型的RDD不可以转化为DF），每个DF也可以通过.rdd属性得到对应的RDD实例，通过.schema得到结构。多说一句，RDD的toDF方法，其实是构建SparkSession的时候，硬塞在RDD上的猴子方法，最终调用的还是SparkSession.createDataFrame方法。由于是从RDD转化而来，分区数和RDD一致。\\n\\n运行DataFrame算子，还是会编译为RDD后才真正执行，因此RDD仍是Spark惟一的运行时，可以将DataFrame比作编译过程的中间代码优化器。对开发者来说想要手写出和DataFrame编译成的RDD相同性能的代码，困难且无必要，因此社区鼓励大家迁移到DataFrame。"}'));jctx.push(JSON.parse('{"id": "200727", "tag": "mine", "text": "# 神经网络来源与分类\\n\\n## 早期历史\\n\\n1956年麦卡锡和明斯基在达特茅斯召开了人工智能会议，算是元年，58年罗森布拉特发明了感知机（perceptron），包含有输入层、输出层和一个隐藏层，可以算是神经网络的前身。输入的特征向量通过隐藏层变换到达输出层，由输出层得到分类结果。早期的单层感知机存在一个严重的问题——它对稍微复杂一些的函数都无能为力（如异或操作），明斯基批评感知机没有异或能力，不看好连接主义，坚持符号派路线。15年后罗森布拉特死于航海，直到上世纪八十年代被Hinton、Rumelhart等人发明的结合反向传播算法的多层感知机克服，就是具有多层隐藏层的感知机。辛顿是乔治布尔的曾孙，家中颇多有建树的人。\\n\\n多层感知机可以摆脱早期离散传输函数的束缚，使用sigmoid或tanh等连续函数模拟神经元对激励的响应，在训练算法上则使用Werbos发明的反向传播BP算法。这就是现在所说的神经网络NN。\\n\\n神经网络的层数直接决定了它对现实的刻画能力——利用每层更少的神经元拟合更加复杂的函数。但问题出现了——随着神经网络层数的加深，优化函数越来越容易陷入局部最优解，并且这个\\"陷阱\\"越来越偏离真正的全局最优。利用有限数据训练的深层网络，性能还不如较浅层网络。同时，另一个不可忽略的问题是随着网络层数增加，\\"梯度消失\\"现象更加严重。（具体来说，我们常常使用sigmoid作为神经元的输入输出函数。对于幅度为1的信号，在BP反向传播梯度时，每传递一层，梯度衰减为原来的0.25。层数一多，梯度指数衰减后低层基本上接受不到有效的训练信号。）\\n\\n## 大发展与大突破\\n\\n在2010年代的后半程，图像和文本领域分别产生了堪称革命性的ResNet（深度残差网络）和Bert模型。\\n\\n图像领域一直沿着CNN的方向发展，最早取得突破的是Yann LeCun在1998年提出的LeNet，在32x32的小图片效果有突破，但不能处理大图片。但毕竟奠定了现代卷积神经网络的原型，即卷积，池化，全链接。\\n\\n在这之后CNN的锋芒开始被SVM等手工设计的特征盖过。随着ReLU和dropout的提出，以及GPU和大数据带来的历史机遇，CNN在2012年迎来了历史突破，这一年的ImageNet上AlexNet一举夺冠，开启了神经网络识图的时代。但AlexNet没有在方法论上给出方向，之后的VGG使用一系列大小为3x3的小尺寸卷积核和pooling层构造深度卷积神经网络，并取得了较好的效果。\\n\\n2014年的ImageNet冠军是GoogLeNet，它的主要特点是网络不仅有深度，还在横向上具有“宽度”。2015年ImageNet的冠军ResNet，更是将图像分类识别错误率降低到了3.6%，超过了正常人眼识别的精度。\\n\\n而文本领域由于前后相关性，起初都是基于RNN在做，但RNN存在串行缺陷，很难并行。文本领域的突破稍晚于图像，2017年Google提出Transform，这个模型由Encoder-Decoder组成，它的Self-Attention和Position Embedding可以替代RNN来做Seq2Seq任务。Attention是个精妙的词法袋（由Yoshua Bengio提出），但不能识别位置，配合上Position Embedding就完整地解决了机器翻译的问题。\\n\\n2018年出现的Bert也是以Transformer为基础，但只使用Decoder部分，因此只有Self-Attention，没有普通的Attention。\\n\\n2006年Hinton最早提出深度学习的概念，具体是利用预训练的方式缓解了局部最优解的问题，将隐藏层增加到了7层，实现了真正意义上的“深度”。LeCun、Hinton和Bengio一起因深度学习上的贡献获得了2018年图灵奖。\\n\\n## 各种网络的简单比较\\n\\n对主要的3种分类归纳如下：\\n\\n1. DNN：为了克服梯度消失，ReLU、maxout等传输函数代替了sigmoid，形成了如今DNN的基本形式。结构跟多层感知机一样。\\n2. RNN：DNN无法对时间序列上的变化进行建模，但时间顺序对于自然语言处理、语音识别、手写体识别等应用非常重要。为了适应这种需求，就出现了循环神经网络RNN。\\n3. CNN：图像中存在固有的局部模式（如人脸中的眼睛、鼻子、嘴巴等），所以将图像处理和神将网络结合引出卷积神经网络CNN。CNN是通过卷积核将上下层进行链接，同一个卷积核在所有图像中是共享的，图像通过卷积操作后仍然保留原先的位置关系。\\n\\n在普通的全连接网络或CNN中，每层神经元的信号只能向上一层传播，样本的处理在各个时刻独立，因此又被成为前向神经网络(Feed-forward Neural Networks)。而在RNN中，神经元的输出可以在下一个时间段直接作用到自身，即第i层神经元在m时刻的输入，除了(i-1)层神经元在该时刻的输出外，还包括其自身在(m-1)时刻的输出！表示成图就是这样的：\\n\\n为方便分析，按照时间段展开如下图所示：\\n\\n（t+1）时刻网络的最终结果O（t+1）是该时刻输入和所有历史共同作用的结果！这就达到了对时间序列建模的目的。RNN可以看成一个在时间上传递的神经网络，它的深度是时间的长度!正如我们上面所说，“梯度消失”现象又要出现了，只不过这次发生在时间轴上。\\n\\n所以RNN存在无法解决长时依赖的问题。为解决上述问题，提出了LSTM（长短时记忆单元），通过cell门开关实现时间上的记忆功能，并防止梯度消失。在序列信号分析中，如果能预知未来，对识别一定也是有所帮助的。因此就有了双向RNN、双向LSTM，同时利用历史和未来的信息。\\n\\n事实上，不论是哪种网络，他们在实际应用中常常都混合着使用，比如CNN和RNN在上层输出之前往往会接上全连接层，很难说某个网络到底属于哪个类别。不难想象随着深度学习热度的延续，更灵活的组合方式、更多的网络结构将被发展出来。\\n\\n简单总结如下：\\n\ufeff\\nCNN(卷积神经网络)、RNN(循环神经网络)、DNN(深度神经网络)的内部网络结构的区别\\n\\n先说DNN，从结构上来说他和传统意义上的NN（神经网络）没什么区别，但是神经网络发展时遇到了一些瓶颈问题。一开始的神经元不能表示异或运算，科学家通过增加网络层数，增加隐藏层可以表达。并发现神经网络的层数直接决定了它对现实的表达能力。但是随着层数的增加会出现局部函数越来越容易出现局部最优解的现象，用数据训练深层网络有时候还不如浅层网络，并会出现梯度消失的问题。\\n\\nCNN与RNN的比较\\n\\n相同点\\n\\n1. 传统神经网络的扩展。\\n2. 前向计算产生结果，反向计算模型更新。\\n3. 每层神经网络横向可以多个神经元共存,纵向可以有多层神经网络连接。\\n\\n不同点\\n\\n1. CNN空间扩展，神经元与特征卷积；RNN时间扩展，神经元与多个时间输出计算\\n2. RNN可以用于描述时间上连续状态的输出，有记忆功能，CNN用于静态输出\\n3. CNN可以达到1000+深度，RNN深度有限\\n\\nmidjourney底层是GAN，SD是diffusion，dalle是CLIP+VAE，原理不同"}'));jctx.push(JSON.parse('{"id": "200830", "tag": "os", "text": "# 多进程与进程间通信\\n\\n在linux中，fork和vfork的系统调用都是clone，当然标记是不同。\\n\\n* fork: CLONE_CHILD_CLEARTID|CLONE_CHILD_SETTID|SIGCHLD\\n* vfork: CLONE_VM|CLONE_VFORK\\n* pthread_create: CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID\\n\\n以目前的性能优化而言，两者的开销区别并不大，更大的区别在于执行流程和内存空间不同。fork执行后，父子进程一定会被执行到，规范没有规定执行顺序，一般都是同时开始调度。而vfork则一定是子进程先执行，而且**如果子进程没有调用\\\\_exit（不是exit）或exec函数的话，父进程不会被执行**。\\n\\nfork是COW，而vfork的子进程可以修改父进程的变量（纯share，没有copy），这也是为什么父进程必须等待子进程调用\\\\_exit后才会被执行的原因。\\n\\n用strace观察锁，绝大多数都是futex函数调用，且操作都是FUTEX_WAIT_PRIVATE，很难看出区别，只有一次触发了FUTEX_WAIT。看资料说现在的锁实现，大多是先自旋一定次数，如果还获取不到，再用户态等待，不会轻易进入内核态，毕竟futex的目的就是防止程序进入内核态。子线程结束调用exit，而主线程结束调用exit_group。\\n\\n创建线程的身份是tid，但由于操作系统的进程API在前，所以同一个主线程，不管创建多少子线程，这些子线程的pid都一样。\\n\\n## 僵尸状态\\n\\n为什么会有这个状态呢？我能想到的惟一原因是父进程要取得子进程的退出状态等信息。僵尸状态是每一个进程退出前的必经过程（只有init进程例外，因为不会退出）。僵尸态只记录一个整型状态，但不止一种信息，用wait.h的特殊宏可以解析出是exit还是stop，收到的信号量等等，而且处在僵尸态的进程，/proc/<pid>/目录的文件会的owner会变成root。但僵尸进程毕竟占用内核的pid资源，所以必须回收。\\n\\n结束僵尸态有几种方法\\n\\n1. 父进程调用wait()\\n2. 父进程显式忽略SIGCHLD信号，必须用SIG_IGN才能自动结束僵尸，其它注册函数没用\\n\\n另外好像用llvm编译的程序，虽然没有注册SIGCHLD，也不调用wait，子进程仍能结束不会变成僵尸。\\n\\n## 进程会话和作业\\n\\n多个进程间会进行分组，有几种分组方式。\\n\\n* session: 一般指shell session，一次登录sh导致的所有进程都在这个session下，而sh进程就称为session的领头进程，通过ps的SID列可以查到\\n* job: 最典型用管道符串起来的多个进程，称为一次job。第一个进程是job的领头进程，通过ps的PGID列可以查到\\n\\n## 7种进程间通信机制\\n\\n1. pipe 管道，最简单，对应syscall有pipe和pipe2两种，pipe2多支持几种选项，是linux在2.6.27才加入的接口\\n2. fifo 有名管道，对应syscall是mknodat，因为有名，且对应磁盘上的文件，因此用mknod方式创建。\\n3. mmap 文件映射共享IO，速度最快（原理：在内存开辟一片缓冲区，把文件映射到内存上，你直接去操作内存就可以了）。shell中的管道符用的就是这种，但不管输入端的内容有多大，都只调用两次mmap（必须有MAP_SHARED标记），大小都是128K。\\n4. 本地socket 最稳定\\n5. 信号 携带信息量最小的\\n6. 共享内存 开辟一块内存区域，大家都能访问，一个进程退出之后，这块内存还会给你保留下来，后来者还可以继续使用\\n7. 消息队列\\n\\n## 匿名管道\\n\\n先从匿名管道说起，在shell中执行 `ls | grep xx` 时，背后的流程是当前的sh为父进程，fork出两个子进程，分别exec执行ls和grep，而且这两个子进程之间会有匿名管道pipe()连接起来。由于两个子进程的父进程都是shell，因此存在亲缘关系，匿名管道以fd方式存在，通过fork方式被两个子进程共享，这就是匿名管道可以工作的原因。\\n\\n顺便说一句，读管道要用read语句，而读命令行输入则是$#一系，由于输入形式的不同，处理逻辑也不同。\\n\\n## 有名管道\\n\\n用读方式打开有名管道，默认是BLOCK模式，意味着当没有进程写入时，会一直堵塞。而一旦有数据写入，会源源不断地读到数据，即使没有数据写入，也不会阻塞读动作。因此对有名管道的读，每次读到空，就要关闭管道，并再次尝试打开，否则CPU会急剧升高。形如以下\\n\\n```\\nwhile true {\\n    fd = open(\'fifo\', \'r\')\\n    line = fd.read()\\n    fd.close()\\n}\\n```\\n\\n观察这两种管道的使用，会发现都使用`pipe_wait`系统调用，因此都叫管道。\\n\\n匿名管道因为使用形式的关系，数据流动是单向的。而有名管道形式上是文件，当然是双向，打开用读写方式。而且有名管道涉及进程间交互，往往是双向流动。如果A到B，B直接打印到终端，人眼看上去没有区别，程序是无法捕获这段打印，有点类似内核输出报警，你能看到却没有任何方式拦截并重定向它。\\n\\n引申一点，shell脚本中怎么判断是命令行启动，还是接在管道后？这两种情况下，stdin没有区分，这时就要再往前想一步，stdin这个逻辑概念指向谁？匿名管道模式，stdin指向的显然是管道，而命令行模式下，stdin指向的是终端，真实的终端叫tty，后来网络化后叫pts，但只是表示不同，终究有个对应的实体。tty命令就是打印stdin所对应的终端，如果stdin对应的是匿名管道，则会返回错误并提示`not a tty`。除了tty，用`[ -t 0 ]`也能判断0是否为tty。对应的C函数是isatty。\\n\\n## 文件锁\\n\\n文件锁用flock保证一个进程启动时独占"}'));jctx.push(JSON.parse('{"id": "200925", "tag": "lang", "text": "# Python进阶学习点滴\\n\\n## 迭代与惰性\\n\\niterator概念体现在很多地方，甚至str都可以迭代，list(\'abc\')会返回[\'a\',\'b\',\'c\']。具备迭代的函数又分eager和lazy两种，list是eager行为，enumerate/map则是lazy行为，返回一个可迭代对象，对这个对象用for循环或tuple/list进行求值。\\n\\nlazy对象一旦被求值，这个对象就成了空壳，因为lazy对象从语义上就不把值放在内存，可以理解为外部源的一个门户或代理，当真正的外部源被求值完毕，则lazy代理自然没有了内容来源。\\n\\n内建3大基础类型tuple/list/dict都具备对lazy迭代对象求值的能力，dict因为语义原因，每次迭代必须有两个值。\\n\\n求值是严格模式，要想实现惰性，由于缺少宏和编译期展开能力，能想到的办法只有foo(lambda: x)，然后在函数体内展开。\\n\\n## 多行lambda\\n\\n语法上要求返回一个expression，不能出现冒号和赋值（因为赋值是statement，可以用3.8后的:=assignment expression）。利用tuple和切片索引来打包多个独立行为，利用if的一行式来做简单的条件\\n\\n```\\ndef main(n):\\n    return lambda x: (\\n    print(x),\\n    x+1 if x > 0 else x-1,\\n    x + n)[1:]\\n```\\n\\n## 多线程\\n\\n拜臭名昭著的GIL所赐，多线程只在IO密集场景下有一战之力。即便只能用到一个核，锁还是必须的，但这个锁和OS的锁不同，是语言级别的锁，不会触发futex调研。有人解释说这种锁的获取和释放，会引起GIL的调度，暂时不能确定。另外py3新增了asyncio后，多线程的使用场景似乎更少了。\\n\\n## 多进程\\n\\n多进程库有两种构造进程的方式，Process（构造一个）和Pool（构造多个功能相同的进程）。从实际效果来看，每生成1个进程，实际会生成2个线程。以生产消费模型，结合队列来举例子。\\n\\n先说队列Queue，生产者用put方法，消费者用get方法，但是这里有个隐秘且反直觉的地方，调用put会将队列的计数加1，但get并不会减1，需要在get之后再调用task_done才行，背后的原因是get允许异步获取，所以必须消费者确认得到消息后，才能将队列次数减1。队列的次数可以通过empty方法得到。真实代码中，生产者会用队列的join方法，join会阻塞直到队列为空才执行下去。\\n\\n就产生了这样一种方式，消费者用with Pool结构，在这个结构内，用Process来创建生产者，生产者全部start()后，会挨个join()，直到每个生产者执行中，队列的join通过后，才会结束。*注意，这里有两个join，分别作用在队列和进程上，而进程的join又被队列的join所阻塞，最终等待消费者消费完所有消息，这就构成了完整的闭环*。当生成者结束后，with语句块的生命周期结束，调用Pool的`__exit__`方法，它又触发了Pool的terminate()，将所有消费进程强行停止，于是所有进程就都正常回收了。\\n\\n一开始我看这段还很疑惑，为什么while Tue循环里只有队列的get，看不到判断和退出，其它是用了with块的方式强行中止了进程，自然就不用判断队列。\\n\\nJoinableQueue objects should only be shared between processes through inheritance\\n\\nPool创建的进程，和Process没有继承关系。跟踪系统调用发现，都是用clone函数，无非用的标志位不同\\n\\n* CLONE_VM: VM shared between processes，内存共享，大约等于线程\\n* CLONE_CHILD_CLEARTID|CLONE_CHILD_SETTID:  Store child thread ID in child memory.Erase child thread ID in child memory space when child exits.\\n* CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID:\\n\\n## 进程池\\n\\n使用进程池Pool启动多进程建议用`apply_async`，这个方法默认不会阻塞，想要等待必须连用Pool的close和join方法，网上文章几乎不提为什么。看了源码才知道，Pool有4种状态，INIT，RUN，CLOSE，TERMINATE。构造进程池对象时，内部会经由INIT状态切到RUN状态。CLOSE状态是为了配合join使用，如果不切换到CLOSE状态，join动作会报错。join内部调用到的方法有wait，只是觉得都用join还是有些混淆。\\n\\n## 多进程的队列\\n\\n底层使用操作系统的pipe作为传输，但为了实现任意py对象的传输，在数据写队列前，会先用pickle序列化，读出的一方会先确认pipe内的消息长度，读出后再反序列化。复杂队列的实现，发送者每次发一条消息，会创建一个线程，由这个新的线程向pipe写数据。\\n\\n## defaultdict\\n\\n出人意料的是这个容器是builtin的，实现在`_collection`包中，不是一个独立的磁盘文件，而是和C语言实现打包在一起，可能对字典的操作需要极高的性能，因此无法用py实现吧。\\n\\n## namedtuple\\n\\n是一个函数返回一个用type方法动态构建的类\\n\\n## pickle序列化\\n\\n首字节固定0x80，然后跟1字节的版本号，截止3.8共有1-5的版本。\\n\\n每遇到新的复杂结构（tuple/list/dict），都会写入一个新的标记符，`EMPTY_XX`，然后跟着具体的值。\\n\\n结构内的字符串，以类型+长度+值的方式保存（典型的TLV格式）。\\n\\n字典内容都结束后，以一个\'s\'（SETITEM动作）把kv的pair对加入字典。\\n\\n最后以\'.\'结尾这个pickle。\\n\\n当然过程中会用MEMOIZE技术复用已保存的字符串，达到节约空间的效果。整个pickle不仅仅记录了值，更记录了从一片空白到完成所有对象的整个操作步骤，在构建过程中逐步还原出对象。\\n\\n## 魔术方法\\n\\n`__getitem__`作用于方括号下标，而`__getattr__`作用于对象的点式取值。还有要注意的是，这两个方法虽然是class上定义，但却只对实例后的对象生效。\\n\\n## 类型标注\\n\\n初看`Union[int, str]`语法会觉得很困惑，因为下标引用只能是1个值，但是换成Union(int, str)又会提示不是callable，说明只能是`__getitem__`方法，再自己实现后才明白原来[int, str]会被转换成[(int, str)]形式。\\n\\nOptional基于Union扩展，但做的时候偷了个懒只能传递单参数，因此实际用的时候往往会写成`Optional[Union[]]`形式。\\n\\n## 源码初读\\n\\n几个关键目录的目标\\n\\n* Object和Python: 定义对象的内存布局，核心的so要实现的编译及导入功能\\n* Lib: py实现的标准库\\n* Modules: py库会引入c实现的so(lib-dynload目录)，都在这里实现\\n* Parser和Grammar: 词法语法解析"}'));jctx.push(JSON.parse('{"id": "201009", "tag": "tool", "text": "# shell的历史和流派\\n\\n## 源起Bourne\\n\\n最初unix系统用的是ken thompson写的shell，不过这个只在贝尔实验室内部用，最早广泛流行的version 7 unix系统的shell是Bourne shell在1979年重写的，可以说Bourne的版本是最初的原型，已经具备了大多数结构化编程的功能。\\n\\n## csh\\n\\n1990到2000年代在BSD系统上比较多见，是Bill Joy写的另一种风格的shell，意图是加强交互性，但也被批评不适用于编程（比如不支持在脚本中定义函数）。后来FreeBSD又强化出了tcsh，由于使用习惯和Bourne版本差别较大，似乎只有FreeBSD把它作为root用户默认，普通用户不用csh，开发也不太活跃。\\n\\n## ksh\\n\\nDavid Korn基于Bourne的代码，又借鉴了csh的作业控制的改进版，加入了emacs和vi风格的编辑方式。ksh88是POSIX规范的蓝本，另有ksh93是另一个主要的版本。但其所属权一直归AT&T所有，不算开源软件。ksh的很多衍生版本用在商业Unix上，Android 4.0后默认的mksh也是ksh的后代（之前是ash）。\\n\\n## ash和dash\\n\\nBourne版本毕竟存在版权所属问题，Kenneth Almquist重新实现了一个版本，特点是执行速度很快且节约内存，相比ksh，少了行编辑和历史命令。后来debian基于它维护了dash（Debian Almquist shell），虽然行编辑和历史命令作为可选项支持了，但仍然不完全满足POSIX（缺少国际化和多字节）。也正是因为其精简，dash的0.3.8-5版本被busybox所集成，用在很多嵌入式系统上。\\n\\n## bash\\n\\nGNU组织开发了bash，是大多数Linux发行版的默认shell，功能非常丰富。但是由于GPL协议的关系，也受到不少非议，OS X的bash版本就长期停留在3.x，后来干脆换成zsh来规避GPL。\\n\\n试举一个特性，通过`PROMPT_COMMAND`环境变量来控制显示，和PS1的区别在于PS1只是显示字符串，而PROMPT会先执行后面的语句，把语句的结果作为提示符。这就是z.lua似乎没有特别地增加路径，却可以记录每次到过路径的原因。\\n\\ncomplete是可配置的选项，对特定命令丰富补全功能。\\n\\n## zsh和fish\\n\\n对bash的扩展仍然觉得不够，于是有了这两个版本，了解不多，先记一笔。"}'));jctx.push(JSON.parse('{"id": "201101", "tag": "net", "text": "# 二三层网络和MAC地址\\n\\n根据OSI的七层模型，二层协议包含PPP、ARP，而三层包含IP、IGMP。\\n\\n1. 不同网段（子网）的ip通信，需要经过三层网络。相同网段的ip通信，经过二层网络；\\n2. 二层网络仅仅通过MAC寻址即可实现通讯，但仅仅是同一个冲突域内；三层网络需要通过IP路由实现跨网段的通讯，可以跨多个冲突域；\\n3. 二层网络的组网能力非常有限，一般只是小局域网；三层网络则可以组大型的网络。\\n4. 二层网络基本上是一个安全域，也就是说在同一个二层网络内，终端的安全性从网络上讲基本上是一样的，除非有其它特殊的安全措施；三层网络则可以划分出相对独立的多个安全域。\\n\\n二层交换机实质就是一张大的查找表，记录MAC和IP的对应关系，因此有ARP协议也是很自然的事情。但是受限于交互机的内存以及以太网络的冲突，网络容量不会太大，这也是子网掩码大多都设置为255.255.255.0的原因。\\n\\n## MAC地址拾遗\\n\\n通常认为MAC地址是全球唯一，其实MAC地址的本意是保证在一个广播域内唯一，因为MAC是以太网下的概念，帧中继、ATM等通信方式都是没有MAC地址的。\\n\\nMAC地址的高24位被称为OUI，组织单位标识符，正规厂商需要花钱向IEEE购买之后才能使用。这就有一则历史趣闻，1990年代，steve deering在研究IP组播时，希望能拿到和组播IP地址相等数量的MAC地址，D类IP地址有效位数是28位，意味着需要购买2^4个OUI，当时一个OUI的售价是1000美金，steve的经理jon postel觉得1万6美金太贵，但是愿意在预算外再购买1个OUI，并分出其中一半给steve研究，于是MAC的组播地址就变成了OUI为01-00-5E，有效位数低23位的地址空间。进而导致组播时，IP地址只有后23位被映射到MAC，也就是说每32个组播IP地址共用同一个MAC地址的现状。"}'));jctx.push(JSON.parse('{"id": "201224", "tag": "os", "text": "# fork与exec考\\n\\nFork 最早可考的来历是 1962 年 Melvin E. Conway 的论文 A Multiprocessor System Design，这篇文章中 Conway 提出可两个原语：Fork 和 Join，Fork 用来分叉，Join 用来聚集。这篇文章用了 Process 这个词，但是和现在的「进程」完全不是一回事。后来，有个叫做 GENIE 的分时系统实现了这套处理逻辑。\\n\\nexec 的起源则是早期 Unix 中 Shell 的运行方式：Shell 启动用户程序的时候会直接把用户程序的代码覆盖 Shell 的代码并清空内存，等执行完了再用 exit() 把 Shell 代码重新初始化一遍。于是，在运行用户进程前后 Shell 几乎没法保留任何信息（这其实和 80 年代家用电脑挺像的，DOS 的 INT 21/4B 在处理 COM 的时候也差不多。）\\n\\n为了解决这个问题，最简单的办法就是把 Shell 整个内存空间给复制一遍再覆盖，Unix 于是借鉴了 GENIE 分时系统里面的 Fork 来做这个复制的活，这就是 fork-exec 二件套的来历了。\\n\\nDOS也是这个工作模式。最初大家都要挤占实模式下的640k运行内存，这块内存在DOS启动后会先被command.com占据，就是它提供了dos的shell；当用户敲了一个“外部命令”（也就是其它程序）时，这个“外部命令”就把目标应用加载进来、覆盖掉自己（exe和com还各有不同执行方式），只保留加载器所在的那一丁点内存；等用户程序执行结束、控制器返回加载器代码，这段代码就把重新加载回内存。\\n\\n有时候用户程序可能特别大，640k都不够用（其实刨去其它零碎也就600k不到能用）；那么用户还要自己搞个ovl文件，自己加载进来（并把自己之前占用的空间覆盖掉，所以叫“覆盖文件”；当然也会留下执行加载的那点代码不覆盖，不然就没得恢复了），然后跳转到ovl入口继续执行代码逻辑——有的程序可能需要载入N个不同的ovl才能完成自己的工作（有的大型软件一套几十张软盘，运行时需要依照提示在不同时刻插入不同的软盘）。\\n\\n再后来内存/磁盘越来越大，计算机运行起来就不再需要这么捉襟见肘了。\\n\\n但由于这个历史，各OS上的exec类系统调用都有一个“干掉发起调用的进程的副作用”这个“特性”就遗留至今。\\n\\n## 创建进程性能比较\\n\\nwindows没有fork这样快速“复制”一个进程的手段，导致每次启动进程都需要从头开始执行fork前的所有逻辑。因此，在Linux上普遍采用的、把进程当“稍微重一点的线程用”的设计方法，在Windows上性能消耗很大，所以类似架构就不太行得通。\\n\\n有一个windows/linux创建进程速度的对比评测：硬件平台为Core 2 Duo T5450 1.66GHz，1GB内存。操作系统为Windows XP SP3/Ubuntu 10.04\\n\\n被创建的子进程是另外一个立即退出的空进程，所以这里仅仅比较了创建进程本身的效率差异，并未利用到fork的优势。\\n\\n结论是：windows创建一个进程平均需要8ms（125个/秒），而Linux则需要0.28ms（3570个/秒）。\\n\\n这个实验并不严谨，使用的API也不都是效率最高的那种。不过基本上还是可以说明问题的。\\n\\n## 分离的原因\\n\\nMIT 的教学用操作系统 xv6 文档第 14 页给出了一个理由：\\n\\nNow it should be clear why it is helpful that fork and exec are separate calls: between the two, the shell has a chance to redirect the child’s I/O without disturbing the I/O setup of the main shell.\\n\\n和 Operating System:Three Easy Pieces 的观点是一致的：分离这两个函数，让 I/O redirection 的实现变得很容易。但这里重点是不会影响到 main shell 的 I\\\\O。如果你接着读下去，文档里提到了假如我们把这两个函数合并成 forkexec，的确可以在 fork 前重定向：\\n\\nThe shell could modify its own I/O setup before calling forkexec (and then un-do those modiﬁcations);\\n\\n合并两个接口最大的问题是，必须还原之前的设置。举个例子，比如想让子进程输出到某文件，父进程打印子进程的 pid 到 stdout：\\n\\n如果在 fork 之前重定向，需要做额外的还原：\\n\\n```\\nint main() {\\n  int stdout_dup = dup(1); // 存住 stdout，之后恢复\\n  close(1);\\n  open(\\"output2.txt\\", O_WRONLY);\\n\\n  if ((pid = fork()) == 0) {\\n    execvp(\\"echo\\", argv);\\n  } else {\\n    wait(NULL);\\n    dup2(stdout_dup, 1); // 还原设置，否则 pid 会被打印到 output2.txt\\n    printf(\\"%d\\\\n\\", pid);\\n  }\\n  return 0;\\n}\\n```\\n\\n很明显，这个额外的还原操作，让 I/O redirection 的代码变得复杂，也增加了程序员的心智负担。\\n\\n## 接口语义\\n\\nglibc里面有一个函数叫posix_spawn，类似于CreateProcess，其实现就是调用clone(vfork) + execve。\\n\\n这么设计原因就是让系统调用足够原子化。我们来看fork，做法是 1) 创建进程的内核对象(分配一块系统内存) 2) 复制内存映射表(只是标记为COW) 3) 复制线程环境(一组寄存器的值)。然后等着老进程新进程的线程竞争执行即可，其他什么都不用做了，甚至连调用堆栈都不用重新创建(只不过由于COW机制很快会触发另一个中断，这是另一回事)。\\n\\n然后来看exec，它做了 1)关闭部分系统资源(比如fd会关闭，shm不会关闭，取决于系统实现) 2) 清空内存映射表 3) 清空同进程下所有线程，仅留一个tid和pid相同的那个线程 4) mmap源文件和对应的interpretor，比如script就是sh，elf文件就是ld 5) 设置线程环境为interpretor的入口地址。然后和fork一样等着线程自行参与竞争即可，注意有些事情并不是在系统调用过程中做的，比方说加载exe依赖的动态库(如libc)，调用init(初始化全局变量)，调用main函数等，都是在interpretor里面做的。\\n\\n从两个系统调用的实现来看，已经相当精简，fork的语义仅有\\"创建进程\\"一事，没有大量的内存操作，速度飞快，exec的语义也被精简成\\"从头开始执行程序\\"，虽然在多任务linux系统中有涉及到进程(线程)操作，但在语义上并不涉及进程概念。这种语义上的精简对于上层软件开发提供了更大的灵活性。\\n\\n在fork和exec之间建立子进程的运行环境，包括但不限于：\\n\\n继承或不继承文件描述符，文件重定向，切换当前目录，设置环境变量，切换根目录，设置signal环境，建立进程会话，SUID/SGID，设置资源限制，建立调试环境，等等。\\n\\n这些事情由父进程做不合适，会污染父进程的环境，用api做，要怎么设计接口？Linux继承了Unix的fork/exec，再看win32的CreateProcess有多少参数，对比一下就能明白其设计理念。\\n\\n## 脚本并行执行\\n\\n使用`&`符/nohup/xargs/coproc可以实现非阻塞甚至并行跑多进程。循环启动多进程示例，把`&`放在{}后\\n\\n```\\nfor num in `seq 1 ${all_num}`\\ndo\\n{\\n\\tsleep 1\\n\\techo ${num}\\n} &\\ndone\\n```\\n\\nxargs的-P选项控制每次最大的并行数，资源有限场景可用\\n\\n```\\nseq 1 ${all_num} | xargs -I {} -P ${thread_num} sh -c \\"sleep 1;echo {}\\"\\n```\\n\\n使用`wait $!`等待子进程结束（$!表示上一个进程，可以不写。注意不要用$$，代表是当前进程）。用Ctrl-C停止主进程后，会把后台子进程也同时停掉，说明子进程并不是始终被1号进程托管。\\n\\ncoproc从手册描述上看是协程，但本质仍是一个预定义了输入输出文件描述符(COPROC[0]和COPROC[1])的后台进程。\\n\\n"}'));jctx.push(JSON.parse('{"id": "201225", "tag": "tool", "text": "# vim的自动补全\\n\\n自动补全有15种模式（:help ins-completion）。其中有两种的补全列表内容与另外两种相同，只是排序不同\\n\\n1. 文字编辑用的 3 种:\\n\\n* K 模式    （Vim 默认: CTRL-X CTRL-K） -- 字典补全，查找字典文件中的匹配单词，组成补全列表\\n* H 模式    （Vim 默认: CTRL-X CTRL-T） -- 分类补全，查找分类文件（thesaurus 文件）中的匹配单词，组成补全列表\\n* S 模式    （Vim 默认: CTRL-X s）        -- 拼写建议\\n\\n2. 自定义模式，通常要写函数的2种:\\n\\n* O 模式    （Vim 默认: CTRL-X CTRL-O） -- 全能补全，由一个自定义函数生成补全列表，又名omni-complete，和filetype绑定，在autoload路径下找{filetype}complete.vim文件并找到其中的补充函数，自带有10多种常见语言的补全实例。\\n* U 模式    （Vim 默认: CTRL-X CTRL-U） -- 自定义补全，也是由自定义函数生成补全列表\\n\\n3. 所有人都喜欢的4种:\\n\\n* n 模式    （Vim 默认: CTRL-N）        -- 关键字补全，查找 \'complete\' 选项指定文件中的匹配单词，组成补全列表\\n* N 模式    （Vim 默认: CTRL-X CTRL-N） -- 关键字补全，查找当前 buffer 里的匹配单词，组成补全列表\\n* 另外两种: p 模式与 P 模式，分别与 n 模式和 N 模式相同，只是补全列表中候选词的排序相反。\\n\\n4. 程序员用的3种:\\n\\n* T 模式    （Vim 默认: CTRL-X CTRL-]） -- tag 补全，查找 tag 中的匹配单词，组成补全列表\\n* I 模式    （Vim 默认: CTRL-X CTRL-I） -- 头文件补全，查找当前 buffer 和 include file 中的匹配单词，组成补全列表\\n* D 模式    （Vim 默认: CTRL-X CTRL-D） -- 定义补全，查找当前 buffer 与 include file 中匹配的名称定义，组成补全列表\\n\\n5. 特殊语境下专用的3种:\\n\\n* V 模式    （Vim 默认: CTRL-X CTRL-V） -- Vim 补全，查找 Vim 的命令名, 函数名等等，组成补全列表\\n* F 模式    （Vim 默认: CTRL-X CTRL-F） -- 文件名补全，查找匹配的路径或文件名，组成补全列表\\n* L 模式    （Vim 默认: CTRL-X CTRL-L） -- 整行补全，查找 \'complete\' 选项指定文件中匹配的整行内容，组成补全列表\\n\\n## 插件解析\\n\\n以easycomplete使用为例，不同的语言定义不同的completor、constructor、gotodefinition、command指令。\\n\\n## 问题\\n\\n遇到奇怪的问题，在vim环境下发现PATH变量和修改的路径一样，但是executable()只认原生的路径，最终仍要把程序移到标准目录才行。"}'));jctx.push(JSON.parse('{"id": "201227", "tag": "lang", "text": "# 实用的shell编程技巧\\n\\n* skill#0: 不可逆操作引用环境变量时用${var:?\\"undefined \'var\'\\"}\\n\\n比如:\\n\\n```\\nrm -fr ${dir}/ # 如果dir未定义, 则删除根目录.\\nrm -fr ${dir:?\\"undefined \'dir\'\\"} # 如果dir未定义, 报错. \\n```\\n\\n* skill#1: 脚本出错即停使用 set -e -o pipefail\\n\\n脚本开头第一句话, 写:\\n\\n```\\n#!/bin/bash\\nset -e -o pipefail\\n```\\n\\n如果出现单行或者单行管道命令出现错误, 脚本会停止执行并且报错.\\n\\n* skill#2: 获取basedir并且发起一个非util命令时使用绝对路径\\n\\n```\\nscript=$(basename ${BASH_SOURCE:-$0})\\nbasedir=$(cd $(readlink -f $(dirname ${BASH_SOURCE:-$0}));pwd)\\n${basedir}/bin/execuable\\n```\\n\\n用绝对路径的好处是用命令ps -C execuable可直接获得可执行程序的绝对路径. 不然的话, 需要查看/proc/${pid}/cwd 确定路径, 比较麻烦. 所以, 能省事就省事.\\n\\n* skill#3: 检查后台进程是否成功启动\\n\\n```\\nset -e -o pipefail\\nsleep 1000 &\\npid=$!\\nkill -0 ${pid} # kill -0 检查进程是否存活\\n```\\n\\n先要获取后台进程的pid, 然后用kill -0检查是否存活.\\n\\n* skill#4: 优雅退出时清理用trap\\n\\n```\\nmkdir /tmp/some.dir\\n\\nfinally(){\\n   local last_status=$? #最后一条命令的执行结果\\n   trap \\"\\" EXIT #避免执行finally嵌套调用死循环\\n   rm -fr /tmp/some.dir #清理工作\\n   exit ${last_status} #真正退出\\n}\\n\\ntrap finally EXIT\\n```\\n\\n用trap给EXIT事件注册一个处理函数finally, 进入finally首先要获取最后一条命令的执行结果, 然后重置EXIT事件的处理函数, 否则可能会发生嵌套调用死循环.注意: normal/abnormal exit都会调用EXIT的处理函数, 此不同于on_exit.\\n\\n* skill#5: 参数传递使用shift\\n\\n```\\nscript=$(basename ${BASH_SOURCE:-$0})\\nusage=\\"FORMAT: ${script} <srcdir> <dstdir>\\"\\nsrcdir=${1:?\\"undefined \'srcdir\', $usage\\"};shift\\ndstdir=${1:?\\"undefined \'dstdir\', $usage\\"};shift\\n```\\n\\n* skill#6: 通配符中含有$((表达式))时使用eval\\n\\n```\\nnum=100\\nfor i in $(eval \\"echo {0..$(($num-1))}\\");do echo $i; done   # 用eval可以构造特别复杂的序列\\n```\\n\\n* skill#7: eval可建立soft reference, 动态修改referenced对象\\n\\n```\\nname=10\\nname_ref=name\\necho $(eval \\"echo \\\\$$name_ref\\")\\n```\\n\\neval类似perl/python的eval, 能够在运行时, 把一段字符串, 当成代码执行, 并且可以读取和修改当前环境中绑定的变量. 具有元编程的能力, 可用于构造比较复杂的代码.\\n\\n* skill#8: 使用perl正则\\n\\nshell不够, perl来凑; perl的sysadmin功能远强于python. 推荐使用perl.\\n\\nperl正则简约统一, onelinar足以替换sed/awk/grep。推荐perl的另外一个原因是, perl提供了非常丰富的括号类型, 便于写脚本。\\n\\nsed/awk/grep的正则, 属于不同的dialect, 需要查看或者记忆三套规则, 容易混淆. 复杂的正则表达式, 拼正确往往需要化费一定时间. 简单场景, 比如搜索一个完整的单词, 用sed/awk/grep无妨, 复杂的正则表示, 建议用perl re.\\n\\nsed和perl的对应关系\\n\\n```\\n# E0表示最后一行\\nsed \'1,$!d\' dat.txt\\nperl -lne \'print if /1..E0/\'\\n\\n# re addr range\\nsed \'/begin/,/end/!d\' dat.txt\\nperl -lne \'print if /begin/../end/\'\\n\\n# substitution\\nsed \'/begin/,/end/s/foobar/Foobar/g\' dat.txt\\nperl -lpe \'s/foobar/Foobar/g if/begin/../end/\' dat.txt\\n\\n# in-place substitution\\n \\nsed -i \'/begin/,/end/s/foobar/Foobar/g\' dat.txt\\nperl -i -lpe \'s/foobar/Foobar/g if/begin/../end/\' dat.txt\\n```\\n\\nawk和perl的对应关系\\n\\n```\\nawk \'{print $1}\' dat.txt\\nperl -aF -lne \'print $F[0]\' dat.txt\\n\\nawk -F: \'{print $1}\' dat.txt\\nperl -aF: -lne \'print $F[0]\' dat.txt\\n\\nperl -aF\'[;,\\\\s]+\'  \'print $F[0]\' dat.txt #用正则/[;,\\\\s]+/分割字符串\\n```\\n\\ngrep和perl的对应关系\\n\\n```\\ngrep word dat.txt\\nperl -lne \'print if /word/\' dat.txt\\n\\ngrep -Rin foobar *\\nfind -type f |xargs -i perl -lne \'print if /foobar/i\' \'{}\'\\n```\\n\\nperl的其他举例\\n\\n提取email地址 `perl -lne \'print $1 if /\\\\b(\\\\S+\\\\@\\\\w+(\\\\.\\\\w+)*)/\' foobar.html`\\n\\n批量修改文件名\\n\\n```\\nfind -type f |perl -lne \'chomp;rename $_=>\\"$_.bak\\"\'\\nfind -name \\"*.bak\\" |perl -lne \'chomp;rename $_=>$1 if /^(.*)\\\\.bak$/\'\\n```\\n\\n批量替换字符串 `find -name \\"*.cpp\\" -type f |xargs -i perl -i.bak -lpe \'s/\\\\b0xdeadbeef\\\\b/0XDEADBEEF/g\' \'{}\' `\\n\\n* skill#9: 获取含特定关键字的java进程pid的数组\\n\\n```\\n# DataNode相关java进程pid存入positional variables\\nset -- $(ps h -C java -o pid,cmd | perl -ne \'print $1 if /^\\\\s+(\\\\d+).*DataNode/\')\\nfor p in $*;do\\n    echo $p\\ndone\\n```\\n\\n用positional variables捕获数组, 使用$* $@ $# $n shift操作数组, 比较方便.虽然declare -a也可定义数组, 但难以记忆, 容易出错.\\n\\n* skill#10: 统计日志中某些词出现的频率\\n\\n```\\n# 假设日志中包含包含\\"2018-10-08 12:00:00.345 [INFO/WARN/FATAL]...\\"信息, 统计INFO, WARN, FATAL的出现次数.\\nperl -lne \'$h{$1}++ if /^\\\\d{4}-\\\\d{2}-\\\\d{2}\\\\s+\\\\d{2}:\\\\d{2}:\\\\d{2}\\\\.\\\\d{3}\\\\s+\\\\[\\\\b(\\\\w+)\\\\b/}{print join \\"\\\\n\\", map{\\"$_:$h{$_}\\"} keys %h\' log\\n```\\n\\n* skill#11: here doc\\n\\n```\\n不允许{backslash\\\\, $variable, $(cmd), $((expr))} interpolation, 边界词DONE用单引号\\n\\ncat <<\'DONE\'\\n....\\nDONE\\n允许{backslash\\\\, $variable, $(cmd), $((expr))} interpolation, 边界词DONE用双引号或者裸词.\\n\\ncat <<\\"DONE\\"\\n....\\nDONE\\n\\ncat <<DONE\\n....\\nDONE\\ntrim每一行前置的空白符用<<-\\n\\ncat <<-DONE\\n  one\\n     two\\n       three\\nDONE\\n```\\n\\n* skill#12: 写函数其实很方便\\n\\nreturn 0/1表示执行成功/失败, 函数用标准输出流返回结果, 使用$()提取返回值.\\n\\n```\\n# 函数 abs_path\\nabs_path(){ #函数名字为abs_path\\n  usage=\\"abs_path <path>\\"\\n  # 参数传递用positional variables\\n  local p=${1:?\\"undefined \'path\': $usage\\"};shift #用local避免污染全局环境变量\\n  if [ -f $p ];then\\n    p=$(cd $(dirname $p);pwd)/$(basename $p)\\n  elif [ -d $p ];then\\n    p=$(cd $p;pwd)\\n  else\\n    # 错误返回1, 输出到标准错误流\\n    echo \\"error: \'$p\' is missing or is not a file/directory\\" >&2\\n    return 1\\n  fi\\n  # 成功返回0, 输出掉标准输出流\\n  echo $p \\n  return 0\\n}\\n\\n# 调用函数abs_path, 返回结果保存在cwd中.\\ncwd=$(abs_path .)\\n过程 add_bridge和del_bridge\\n\\nadd_bridge(){\\n  local usage=\\"add_bridge <bridge-name> <subnet>\\"\\n  local bridge=${1:?\\"undefined <bridge-name>: $usage\\"};shift\\n  local subnet=${1:?\\"undefined <subnet>: $usage\\"};shift\\n\\n  del_bridge $bridge\\n  ip link add $bridge type bridge\\n  ip link set dev $bridge up\\n  return 0\\n}\\n\\ndel_bridge(){\\n  local usage=\\"del_bridge <bridge-name>\\"\\n  local bridge=${1:?\\"undefined <bridge-name>:$usage\\"};shift\\n\\n  if ip link list | grep \\"\\\\<$bridge\\\\>\\" >/dev/null 2>&1;then\\n    ip link set dev $bridge down\\n    ip link delete dev $bridge\\n  fi  \\n  return 0\\n}\\n\\n使用source或者.将函数所在的脚本文件include到主脚本中.\\n\\n# assume that funtions.sh contains all your util funcitons\\nsource funtions.sh\\n. funtions.sh  \\n```\\n\\n* skill#13: 死循环用colon(:)\\n\\n```\\nwhile : ;do\\n  t=$(($RANDOM%10+1));\\n  echo sleep $t secs; \\n  sleep $t;\\ndone\\n```\\n\\n* skill#14: 字符串比较\\n\\n```\\n# 判断字符串是否为空\\n[ -z $s ] #错误\\n[ -z \\"$s\\" ] #正确\\n\\n# 判断字符串是否为不空\\n[ -n $s ] #错误\\n[ -n \\"$s\\" ] #正确\\n\\n# 判断字符串是否相等\\n[ $s = \\"OK\\" ] #错误\\n[ x$sx = \\"xOKx\\" ] #错误\\n[ \\"x${s}x = \\"xOKx\\" ] #正确\\n```\\n\\n* skill#15: 判断字符串是否为合法IP地址\\n\\n```\\nip=\\"192.168.1.1\\"\\nill_formed=$(echo $ip|perl -lne \'print \\"ill-formed\\" unless /^\\\\d{1,3}(\\\\.\\\\d{1,3}){3}$/\'\\nif [ -z \\"${ill_formed}\\" ];then\\n  echo \\"match\\"\\nelse\\n  echo \\"not match\\"\\nfi\\n```\\n\\n* skill#16: 判对一组token是否包含某一个词\\n\\n```\\n#!/bin/bash\\n\\ncontains(){\\n  local usage=\\"Usage: contains <w> <elm0> <elm1> ...\\"\\n  local w=${1:?\\"undefined \'w\', ${usage} \\"};shift\\n  if [ \\"$#\\" -eq 0 ];then \\n    echo \\"Error: missing arguments, ${usage}\\" >&2\\n    return 1\\n  fi  \\n  perl -e \\"@h{qw/$*/}=(1)x$#;print \\\\$h{qq/$w/}\\"\\n  return 0\\n}\\n\\ncontains $*\\n```\\n\\n* skill#17: 如果Shell嵌入Perl无法解决问题, 那么就用Perl嵌入Shell\\n\\n```\\n#!/usr/bin/perl\\nuse strict;\\nuse warnings;\\n...\\nmy stdout=`shell_cmd` or die \\"$!\\"; # backticks enclose shell cmd.\\n...\\nmy stdout=qx(shell_cmd) or die \\"$!\\"; # qx enclose shell cmd\\nskill#18: 打印Linux系统调用的标准errno和errmsg\\n\\nperl -le \'foreach(0..133){$!=$_;print \\"$_:$!\\"}\'\\n```\\n\\n* skill#19: 不用docker在本地搭建分布式系统\\n\\n```\\n# 创建网桥\\nip link add ${bridge} type bridge\\nip link set dev ${bridge} up\\n\\n# 创建一条ethernet网线\\nip link add ${eth} type veth peer name ${br_eth}\\n\\n# 把网线的一头接到网桥上\\nip link set dev ${br_eth} master ${bridge}\\nip link set dev ${br_eth} up\\n\\n# 创建网络命名空间\\nip netns add $netns\\n\\n# 把网线的另外一头接到新创建的网络命名空间上.\\nip link set ${eth} netns ${netns}\\n\\n# 设置命名空间中以太网卡的网络地址\\nip netns exec ${netns} ip link set dev ${eth} name \\"eth0\\"\\nip netns exec ${netns} ifconfig \\"eth0\\" ${ip} netmask 255.255.255.0 up\\nip netns exec $netns ifconfig \\"lo\\" up\\n\\n# 如此往复可以创建多条连接在同一个网桥上的网线, 网线的另外一头处于不同的网络命名空间.\\n\\n# 创建转发规则(Ubuntu 16.04, Manjaro可用)\\niptables -t nat -A POSTROUTING -s ${subnet}.0/24 ! -o ${bridge} -j MASQUERADE\\nsystemctl restart iptables\\n \\n# 用nc或者python -m SimpleHTTPServer测试网络: 略\\n\\n# 启动脚本start.sh, 使用独立的UTS, Mount命名空间.\\nunshare -u -m bash -x ./start.sh \\n\\n# 修改hostname\\nhostname ${hostname}\\n\\n# 挂载目录\\nmount -B ${dir} ${mount_point} # 挂载目录\\n\\n# 启动脚本start_server.sh, 使用独立的网络命名空间.\\n# 测试脚本中启动的服务, 拥有独立的UTS, mount和network命名空间.\\nip netns exec ${netns} ./start_server.sh \\n```\\n\\n* skill#20: 解决ssh远程执行nohup命令hang住问题\\n\\n如果不关闭nohup的标准{输入, 输出, 错误}文件, ssh远程执行nohup命令会hang住.\\n\\nssh localhost \\"nohup python -m http.server 2>&1  &\\" #hang\\n使用 exec fd <&- 关闭文件fd\\n\\nssh localhost \\"exec nohup python -m http.server 2<&- 1<&- 0<&-  &\\"\\nskill#21: 使用xargs逐行处理标准输出\\n\\n如果前一个命令的标准输出为文件列表, 逐个处理文件, 则可以用到xargs命令.\\n\\n比如替换一组文件中的某一个特定的字符串.\\n\\nag -G \'.*\\\\.(cc|cpp|c|C|hh|hpp|h|H)$\' \'stdio\\\\.h\' -l | xargs -i{} perl -i.bak -lpe \'s/stdio.h/cstdio/g\' \'{}\'\\nskill#22: 批量替换文件名\\n\\n当文件名中包含空格或者其他不可打印字符时, 使用perl rename函数, 而非mv.\\n\\n```\\n# 后缀.MD修改为.md\\nag -G \'.*\\\\.md$\' -l |perl -lne \'chomp;rename $_ => \\"$1.md\\" if -f && /(.*)\\\\.md$/\'\\n# 文件名后缀添加.bak\\nag -G \'.*\\\\.md$\' -l |perl -lne \'chomp;rename $_ => \\"$_.bak\\" if -f\'\\n# 去掉文件名后缀back\\nag -G \'.*\\\\.bak$\' -l |perl -lne \'chomp;rename $_=>$1 if /(.*)\\\\.bak$/\'\\n```\\n\\n* skill#23: 匹配除Windows Vista之外的其它Windows版本.\\n\\n```\\nperl -lne \'print if /^Windows\\\\s+(?!Vista)/i\' <<\'DONE\'\\nwindows vista\\nwindows xp\\nwindows 2003\\nwindows 95\\nDONE\\n```\\n\\n* skill#24: 平移copy, 将一个目录中所有文件平移到另外一个目录下.\\n\\n方法1: 使用cpio命令. 用户把 /root/gcc-5.4_prefix中的文件原封不动地平移到/usr下.\\n\\n```\\ncd /root/gcc-5.4_prefix\\nfind -type f |cpio -o > /root/gcc-5.4-bin.cpio\\ncd /usr\\ncpio -id < /root/gcc-5.4-bin.cpio\\n```\\n\\n方法2：分别操作目录和文件\\n\\n```\\ncd /root\\nfind gcc-5.4_prefix -type d |perl -lpe \'s{gcc-5.4_prefix}{/usr}g\'|xargs -i{} mkdir -p \'{}\'\\nfind gcc-5.4_prefix -type f |perl -lne \'$src=$_; s{gcc-5.4_prefix}{/usr}g; qx(cp \\"$src\\" \\"$_\\")\'\\n```\\n\\n* skill#25: bash中逻辑算符||和&&与C语言不同, 不具有优先级\\n\\n```\\n: || echo \\"OK1\\" && echo \\"OK2\\" && echo \\"OK3\\"\\n# 依然会输出 OK2 OK3\\n# 上述语句等价于\\n((: || echo \\"OK1\\") && echo \\"OK2\\" )&& echo \\"OK3\\"\\n\\n# 如果想获得和C一样的语意, 使用\\n: || (echo \\"OK1\\" && echo \\"OK2\\" && echo \\"OK3\\")\\n```\\n\\n* skill#26: 编写交互式工具 - 选择列表\\n\\n```\\nselectOption(){\\n  test $# -gt 0\\n  select opt in $*;do\\n    echo ${opt}\\n    break;\\n  done\\n}\\n\\n$a=$(selectOption \\"foobar\\" \\"bazz\\" \\"deadbeef\\")\\necho $a\\n\\n执行结果:\\n$ opt=$(selectOption \\"foobar\\" \\"bazz\\" \\"deadbeef\\")\\n1) foobar\\n2) bazz\\n3) deadbeef\\n#? 1\\n$ echo $opt\\nfoobar\\n```\\n\\n* skill#27: 编写交互式工具 - 确认yes/no\\n\\n```\\nconfirm(){\\n  echo -n \\"Are your sure[yes/no]: \\"\\n    while : ; do\\n      read input\\n      input=$(perl -e \\"print qq/\\\\L${input}\\\\E/\\")\\n      case ${input} in\\n        y|ye|yes)\\n          break\\n          ;;\\n        n|no)\\n          echo \\"operation is cancelled!!!\\"\\n          exit 0\\n          ;;\\n        *)\\n          echo -n \\"invalid choice, choose again!!! [yes|no]: \\"\\n          ;;\\n      esac\\n    done\\n}\\n```\\n\\n使用input=$(perl -e \\"print qq/\\\\L${input}\\\\E/\\")转小写，然后：\\n\\n输入匹配到yes的前缀, 则继续执行;\\n输入匹配到no的前缀, 则输出\\"operation is cancelled!!!\\", 并且退出脚本;\\n其他输入, 均非法, 继续提示输入.\\n\\n* skill#28: shell opt选项save和restore\\n\\n用在什么场景, 比如我们编写一个函数, 希望在这个函数局部地修改shell opt, 并且函数退出时, 恢复到原来的shell opt. 即函数的执行不影响整个脚本的shell opt.\\n\\n```\\n foobar(){\\n    local oldshopt=$(set +o)\\n    set -e -o pipefail\\n    ...\\n    set +vx;eval \\"${oldshopt}\\"\\n    echo ${result}\\n }\\n```\\n\\n使用set +o保存shell opt, 使用 set +vx; eval \\"${oldopt}\\"恢复老的opt.\\n\\n* skill#29: 通用的checkArgment函数\\n\\n```\\ncheckArgument(){\\n  local name=${1:?\\"missing \'name\'\\"};shift\\n  local arg=${1:?\\"missing \'arg\'\\"};shift\\n  local alternatives=${1:?\\"missing \'alternatives\'\\"};shift\\n\\n  if [ -z ${alternatives} ];then\\n    echo \\"ERROR: empty alternatives for \'${name}\', value=\'${arg}\'\\" >&2\\n    exit 1\\n  fi\\n\\n  if test x$(perl -e \\"print qq/${alternatives}/=~/^\\\\w+(?:\\\\|\\\\w+)*$/\\")x != x1x;then\\n    echo \\"ERROR: alternatives must be in format word1|word2|word3..., name=\'${name}\', value=\'${arg}\', alternatives=\'${alternatives}\\" >&2\\n    exit 2\\n  fi\\n\\n  if test x$(perl -e \\"print qq/$arg/=~/^(?:${alternatives})$/\\")x != x1x; then\\n    echo \\"ERROR: unmatched argument, name=\'${name}\', value=\'${arg}\', alternatives=\'${alternatives}\'\\" >&2\\n    exit 1\\n  fi\\n}\\n\\ncheckArgument \\"service\\" \\"master\\" \\"master|regionserver\\"\\n```\\n\\n* skill#30 date命令操作\\n\\n```\\ndate +\\"%s\\" #输出时间戳, 单位为秒\\ndate +\\"%Y%m%d_%H%M%S\\" #输出20190818_163017\\ndate +\\"%Y%m%d_%H%M%S\\" -d@1566116945 #时间戳1566116945转日期\\nperl -e \'print qx(date +\\"%s\\" -d \\"$1-$2-$3 $4:$5:$6\\") if qq(20190818_162905)=~/^(\\\\d{4})(\\\\d{2})(\\\\d{2})_(\\\\d{2})(\\\\d{2})(\\\\d{2})$/\' #日期转时间戳\\n\\nperl -e \'print time()\' #输出时间戳\\nperl -MPOSIX=strftime -e \'print strftime \\"%Y%m%d_%H%M%S\\", localtime(1566117946)\' #时间戳转日期\\nperl -MPOSIX=strftime -e \'print strftime \\"%Y%m%d_%H%M%S\\", localtime(time())\' #时间戳转日期\\nperl -MTime::Piece -e \'print Time::Piece->strptime(\\"20190818_164546\\", \\"%Y%m%d_%H%M%S\\")->strftime(\\"%s\\")\' #日期转时间戳\\n```\\n\\n* skill#31 彩色输出\\n\\nshell脚本中, 需要用不同的颜色对失败或者成功进行彩色高亮输出, 可以提高运维脚本的好用性.\\n\\n首先给出一个调色板, color_palette.pl.\\n\\n```\\n#!/usr/bin/perl\\nuse strict;\\nuse warnings;\\n\\nmy @fg=(31..37,90..97);\\nmy @bg=(40..47,100..106);\\nmy @ef=(0..8);\\n\\nfor (1..@fg*@bg*@ef) {\\n  my $i=($_-1)/(@bg*@ef);\\n  my $j=($_-1)%(@bg*@ef)/@ef;\\n  my $k=($_-1)%@ef;\\n  my $fg=$fg[$i];\\n  my $bg=$bg[$j];\\n  my $ef=$ef[$k];\\n  print \\"\\\\e[${fg};${bg};${ef}m \\\\\\\\e[${fg};${bg};${ef}m\\\\\\\\e[m\\\\e[m\\";\\n  if ($_%10==0){\\n    print \\"\\\\n\\";\\n  } else{\\n    print \\" \\";\\n  }\\n}\\n用户可以从调色板的输出结果中, 选择自己偏好的颜色.\\n\\n首先, term的颜色怎么编码呢? 使用三元组.\\n\\n前景色;背景上;特效\\n比如：\\"97;105;5\\",表色前景白色, 背景粉色，特效闪烁.\\n然后, 颜色作用的范围有起始标记, 被起始标记包围的文字会被彩色打印.\\n\\n开始标记: <ESC>[dd;dd;dm\\n\\n结束标记: <ESC>[m\\n\\n比如要用“前景白色, 背景粉色，特效闪烁”输出deadbeef, 则使用下列ascii串\\n\\n<ESC>[97;105;5mdeadbeef<ESC>[m\\n问题的关键是, 怎么转移后者输入<ESC>键呢?\\n\\nC语言风格的printf使用\\\\e表示<ESC>, perl语言的print/printf函数, shell的printf, echo -e命令和C保持兼容. 因此在这三种场景下,输出上述彩打foobar, 使用命令\\n\\nprintf \\"\\\\e[97;105;5mdeadbeef\\\\e[m\\" # shell\\nperl -e \'printf \\"\\\\e[97;105;5mdeadbeef\\\\e[m\\"\' # perl one-linar command\\necho -e  \\"\\\\e[97;105;5mdeadbeef\\\\e[m\\" # -e enable escape-char\\nshell的echo命令录入ESC略有不同, 使用<CTRL-V><ESC>按键输入<ESC>键, 终端一般显示为^[, 记住直接输入^[并不管用.\\n\\necho \\"^[[97;105;5mdeadbeef^[[m\\" #使用<CTRL-V><ESC>输入<ESC>\\necho -e  \\"\\\\e[97;105;5mdeadbeef\\\\e[m\\" #使用转义字符.\\n```\\n\\n写一个小脚本(colorprint.sh)使用一下彩打.\\n\\n```\\n#!/bin/bash\\nset -e -o pipefail\\nbasedir=$(cd $(dirname $(readlink -f ${BASH_SOURCE:-$0}));pwd);\\ncd ${basedir}\\narg=${1:?\\"^[[95;41;5mmissing \'arg\'^[[m\\"};shift\\nif [ \\"x${arg}x\\" = \\"xfoobarx\\" ];then\\n   echo -e \\"\\\\e[32;100;1mOK\\\\e[m: arg is foobar\\"\\nelse\\n   echo -e \\"\\\\e[31;100;1mERROR\\\\e[m: arg is not foobar\\"\\nfi\\n```\\n\\n* skill#32: 处理命令行参数\\n\\n使用perl处理命令行参数 下面是使用fio, 从并发度和iosize两个维度持续加压, 测试磁盘性能的脚本.\\n\\n```\\n#!/usr/bin/perl\\n\\nuse strict;\\nuse warnings;\\nuse Getopt::Long;\\n\\nour ($OPT_concurrencyInit, $OPT_concurrencyLinearVarying, $OPT_concurrencyExponentialVarying) = (1, 0, 2);\\nour ($OPT_ioSizeInit, $OPT_ioSizeLinearVarying, $OPT_ioSizeExponentialVarying) = (256, 0, 1);\\nour ($OPT_fileSize, $OPT_directory, $OPT_timeout, $OPT_stopOnSaturation) = (1*2**19, \\"/mnt/nefs/0/fiotest\\", 7200, \\"true\\");\\nour ($OPT_concurrencyMax, $OPT_ioSizeMax) = (500, 64*2**10);\\n\\nsub options(){ map {/^OPT_(\\\\w+)\\\\b$/; (\\"$1=s\\" => eval \\"*${_}{SCALAR}\\") } grep {/^OPT_\\\\w+\\\\b$/} keys %:: }\\n\\nsub usage(){\\n\\tmy $name = qx(basename $0); chomp $name;\\n\\t\\"USAGE:\\\\n\\\\t\\" . \\"$name \\" . join \\" \\", map{/^OPT_(\\\\w+)$/; \\"--$1\\"} grep {/^OPT_\\\\w+\\\\b$/} keys %::;\\n}\\nsub show(){\\n\\tprint join \\"\\\\n\\", map {/^OPT_(\\\\w+)\\\\b$/; (\\"--$1=\\" . eval \\"\\\\$$_\\" ) } grep {/^OPT_\\\\w+\\\\b$/} keys %::;\\n\\tprint \\"\\\\n\\";\\n}\\n\\nGetOptions(options()) or die usage();\\nshow();\\n\\nsub workloadGenerator{\\n\\tmy ($C, $C_lvary, $C_evary, $IO, $IO_lvary, $IO_evary) = @_;\\n\\tsub(){\\n\\t\\tmy ($c, $io) = ($C, $IO);\\n\\t\\t$C += $C_lvary;\\n\\t\\t$C *= $C_evary;\\n\\t\\t$IO += $IO_lvary;\\n\\t\\t$IO *= $IO_evary;\\n\\t\\t($c, $io);\\n\\t}\\n}\\n\\n\\nmy $startup = time();\\nsub since{my $start=shift; time()-$start}\\n\\nmy $WLGen = workloadGenerator(\\n\\t$OPT_concurrencyInit, $OPT_concurrencyLinearVarying, $OPT_concurrencyExponentialVarying,\\n\\t$OPT_ioSizeInit, $OPT_ioSizeLinearVarying, $OPT_ioSizeExponentialVarying,\\n);\\n=pod\\nfor (1..100){\\nmy @a=$WLGen->();\\nprint \\"@a\\\\n\\";\\n}\\n=cut\\n\\nsub normbw{\\n\\tmy ($num, $unit)=split \\",\\", shift;\\n\\tmy %conv=(\\"B\\"=>1, \\"KB\\"=>2**10, \\"MB\\"=>2**20, \\"GB\\"=>2**30);\\n\\t$num*$conv{$unit}/1024;\\n}\\nsub normlat{\\n\\tmy ($num, $unit)=split \\",\\", shift;\\n\\tmy %conv=(\\"usec\\"=>0.001, \\"msec\\"=>1, \\"sec\\"=>1000, \\"min\\"=>60000);\\n\\t$num*$conv{$unit};\\n}\\nqx(echo -n \'\' > result.dat);\\nqx(mkdir -p $OPT_directory);\\nmy $fio_args=\\"--ioengine=psync --sync=1 --direct=1 --group_reporting --unlink=1 --rw=write --directory=$OPT_directory\\";\\nmy $count=0;\\nwhile(1){\\n\\tif (since($startup) > $OPT_timeout) { print \\"timeout:\\\\n\\"; exit 0; }\\n\\tmy ($concurrency, $ioSize) = $WLGen->();\\n\\tif ($concurrency > $OPT_concurrencyMax || $ioSize > $OPT_ioSizeMax) { \\n\\t\\tprint \\"concurrency=$concurrency;ioSize=$ioSize\\\\n\\";\\n\\t\\texit 0;\\n\\t}\\n\\n\\tprint qq(fio $fio_args --numjobs=$concurrency --name=bs${ioSize}K --bs=${ioSize}K --size=${OPT_fileSize}K > stdout),\\"\\\\n\\";\\n\\tqx(fio $fio_args --numjobs=$concurrency --name=bs${ioSize}K --bs=${ioSize}K --size=${OPT_fileSize}K > stdout);\\n\\tdie $! if $?;\\n\\tqx(mv stdout stdout.${count});\\n\\n\\tmy $curr=\\"stdout.\\" . (${count}-0);\\n\\tmy $curr_bw_unit = qx(perl -ne \'print \\"\\\\$1,\\\\$2\\" if/^\\\\\\\\s+write:.*bw=\\\\\\\\b(\\\\\\\\d+(?:\\\\\\\\.\\\\\\\\d+)?)\\\\\\\\s*(\\\\\\\\w+)\\\\\\\\b/\' $curr);chomp $curr_bw_unit;\\n\\tmy $curr_bw=normbw($curr_bw_unit);\\n\\tmy $curr_iops = qx(perl -ne \'print \\"\\\\$1\\" if/^\\\\\\\\s+write:.*iops=\\\\\\\\b(\\\\\\\\d+)\\\\\\\\b/\' $curr);chomp $curr_iops;\\n\\tmy $curr_lat_unit= qx(perl -ne \'print \\"\\\\$2,\\\\$1\\" if/^\\\\\\\\s+lat\\\\\\\\s*\\\\\\\\((\\\\\\\\w+)\\\\\\\\).*avg=\\\\\\\\b(\\\\\\\\d+(\\\\\\\\.\\\\\\\\d+)?)\\\\\\\\b/\' $curr);chomp $curr_lat_unit;\\n\\tmy $curr_lat=normlat($curr_lat_unit);\\n\\tqx(echo \\"$concurrency\\\\t$ioSize\\\\t$curr_bw\\\\t$curr_iops\\\\t$curr_lat\\" >> result.dat);\\n\\tif ($OPT_stopOnSaturation eq \\"true\\" && $count > 0) {\\n\\t\\tmy $prev=\\"stdout.\\" . (${count}-1);\\n\\t\\tmy $prev_bw_unit = qx(perl -ne \'print \\"\\\\$1,\\\\$2\\" if/^\\\\\\\\s+write:.*bw=\\\\\\\\b(\\\\\\\\d+(?:\\\\\\\\.\\\\\\\\d+)?)\\\\\\\\s*(\\\\\\\\w+)\\\\\\\\b/\' $prev);chomp $prev_bw_unit;\\n\\t\\tmy $prev_bw=normbw($prev_bw_unit);\\n\\t\\tmy $prev_iops = qx(perl -ne \'print \\"\\\\$1\\" if/^\\\\\\\\s+write:.*iops=\\\\\\\\b(\\\\\\\\d+)\\\\\\\\b/\' $prev);chomp $prev_iops;\\n\\t\\tmy $prev_lat_unit= qx(perl -ne \'print \\"\\\\$2,\\\\$1\\" if/^\\\\\\\\s+lat\\\\\\\\s*\\\\\\\\((\\\\\\\\w+)\\\\\\\\).*avg=\\\\\\\\b(\\\\\\\\d+(\\\\\\\\.\\\\\\\\d+)?)\\\\\\\\b/\' $prev);chomp $prev_lat_unit;\\n\\t\\tmy $prev_lat = normlat($prev_lat_unit);\\n\\n\\t\\tmy $delta=abs(($curr_bw - $prev_bw)/$curr_bw);\\n\\t\\tif ($delta < 0.0005) {\\n\\t\\t\\tprint \\"curr_bw=$curr_bw; prev_bw=$prev_bw; delta=$delta\\\\n\\";\\n\\t\\t\\texit 0;\\n\\t\\t}\\n\\t}\\n\\t$count++;\\n}\\n```\\n\\n* skill#33: 删除日志目录中的文件, 只保留近期3个文件\\n\\n下面脚本是安全的，不会出现误删/或者～, 也不会出现多删除.\\n\\n```\\n#!/bin/bash\\nset -e -o pipefail\\nbasedir=$(cd $(dirname $(readlink -f ${BASH_SOURCE:-$0}));pwd)\\n\\ndir=${1:?\\"undefined \'dir\'\\"};shift\\ntest -d ${dir}\\ndir=$(cd ${dir};pwd)\\ntest ${dir} != \\"/\\"\\ntest ${dir} != \\"${HOME}\\"\\n\\ncd ${basedir}\\n\\necho \\"clean ${dir} ...\\"\\nfilenum=$(ls -rt ${dir}|wc -l)\\necho \\"${dir} has ${filenum} file(s)\\"\\nif [ ${filenum} -le 3 ];then\\n  exit 0\\nfi\\n\\nfor f in $(ls -rt ${dir}|head -n -3);do\\n  if [ ! -f ${dir}/${f} ];then\\n    echo ${dir}/${f} is not a file >&2\\n    continue\\n  fi\\n  echo rm ${dir:?\\"undefined \'dir\'\\"}/${f:?\\"undefined \'f\'\\"}\\n  rm ${dir:?\\"undefined \'dir\'\\"}/${f:?\\"undefined \'f\'\\"}\\ndone\\n```\\n\\n* skill#34: shell编程参考书推荐\\n\\n只推荐UNIX Shells by Example (4th Edition)，推荐理由：\\n\\n包括Unix/Linux系统启动后的初始化阶段的内容.\\n包括了bash, sh, ksh, tcsh四种shell方言.\\n讲解了shell中的pipe，redirection, fork, exec，dup的机制，可以结合APUE学习系统编程.\\n专门分章节讲解了sed/awk/grep的各种变种.\\n内容组织合理, 先给出了各种shell方言的不同，然后详细讲解了各种shell的细节\\n"}'));jctx.push(JSON.parse('{"id": "210106", "tag": "os", "text": "# 多核CPU之间的异同\\n\\nPower是标准的SMP架构，而X86则是NUMA。由于SMP访问内存速度一致，因此Power可以轻松上16socket，而NUMA对内存区别对待，访问别的核内存要通过QPI总线，所以很难上4socket。\\n\\nPower的每核线程数能到8甚至16，但X86只有2线程，还被大肆商业鼓吹。好在X86的单socket核数并不差，还略高一些。\\n\\nPower在负载很高甚至99%的情况下能持续运行几周甚至月（也许和CPU架构未必强相关），而X86就容易不稳定。尽管如此X86通过价格低廉，辅以外围集群技术的弥补，仍然成为主流。\\n\\n## 差异说明\\n\\nNUMA出现得晚（20世纪90年代），解除了SMP内存的bandwith限制，但需要软件优化。\\n\\n因为是对内存访问的差异，所以到底是NUMA好还是UMA好，是要看具体应用的。如果应用本身是每个CPU（或者CPU内部的单个核心）长时间持续运行一个线程，那么NUMA把这个线程用到的数据尽可能放到这个CPU的本地内存中当然会更有性能优势。如果是把大量的数据加载到内存中，根据外部请求创建不同的线程随机访问内存中的一部分数据，短时间的处理后线程结束，则是UMA的平均延迟会更低。一般来说，前者通常是一些运算量很大的应用；后者通常是各种服务器（例如网站、数据库等）。这也是为什么Linux内核允许配置为NUMA或者UMA两种模式，多路系统的BIOS通常允许配置为NUMA模式或者UMA模式的原因。\\n\\n从另一方面来说，现代的多核CPU，内部都有独立的1级缓存和2级缓存，也可以认为本质就是NUMA架构。但如果扩展到所有内核都有独立的内存控制器，则会导致成本过于高昂；此外也无法通过内存交错技术提升内存带宽。"}'));jctx.push(JSON.parse('{"id": "210120", "tag": "net", "text": "# 网络代理概念与区别\\n\\n## 模式\\n\\n* 全局模式 所有连接全从指定的端口转发出去，简单却不灵活\\n* PAC模式，全称代理自动配置，由网景公司在1996年在2.0版本的navigator上开发，是一段JS脚本。根据目的端地址选择不同的出口。在火狐浏览器上与全局模式是二选一关系，谷歌可以装插件单独设置PAC，但应该也是屏蔽全局模式\\n\\n## 类型\\n\\n* 正向代理: 比如内网通过网关访问互联网，在客户端侧显式设置\\n* 反向代理: 在集群最外侧做负载均衡，在服务端侧显式设置\\n\\n往往公司的正向代理会做行为管理，客户端感知不到它的存在。有几种模式，透明代理/匿名代理和中间人模式。透明代理是做包转发，而中间人模式取自中间人攻击，代理会和客户端先建立https连接，再由代理和目的端建立连接，没有隐秘性。\\n\\n## 代理协议\\n\\n连接到代理服务器也需要指定协议\\n\\n* http 对代理转发端来说最方便，但隐蔽性不够，即使用https也会因为代理多出一条CONNECT从而暴露目的，多用于企业或学校内网\\n* socks 专为代理设计的协议，定义足够简洁且历史悠久，支持的软件也很多\\n* shadow_sock 为解决socks加密和隐蔽性不够而开发的新协议，有变体，应用较多\\n* 各类VPN 这个工作在IP层，比以上的传输层代理更通用\\n\\n## socks应用\\n\\nsocks协议非常简单，有4，4a，5共3个版本。socks4只支持TCP，版本5增加了UDP，也成了当今代理界的事实标准。ssh的-D隧道就是在客户端启动的socks5代理。\\n\\n整个流程包含认证和确定目标两个阶段，最简单不作认证的情况下，两次交互以后的数据就是纯转发了。因为协议是明文且特征明显，很容易被识别出真正的目的地址，要用socks5穿墙是不可能的，往往是用在本地程序和本地加密代理间。\\n\\nshadowsocks的本地端就以socks5方式接受数据，之后把数据混淆后转给ss服务器，回复的数据最终以socks5方式给到应用程序。\\n\\nIE浏览器支持socks代理，但似乎只支持4，但要注意不能填http/ftp，只能填写socket那栏，socks代理才能生效。但是4不能承载dns协议，如果目的端是域名而不是IP，代理无法生效，此时用代理插件而不是系统代理就能解决。\\n\\n## 实现一个最简单的HTTP代理\\n\\n最简单的代理，得到HTML的主体内容并回复给请求者，以PHP为例，最简单的做法是用curl取得数据。要注意的是对于HTTPS，要关闭验证否则会得不到数据。另一种做法是用`file_get_contents`，在某些环境要配置签发CA的根证书，没有无法获取，且只能得到HTTP的body，header描述信息会丢失。\\n\\n不管是curl和file函数，获取到的网页主体HTML内容是一致的。但网页的复杂性在于HTML还包含了CSS和JS代码，需要额外下载。如果是绝对地址可能到不可达；相对地址在展开时，浏览器看到的是代理地址，所以会补全成代理的地址，这时显然就不能获取到资源文件了。所以代理的难点，就在于尽可能穷举各种URL的形式，并替换成指向源端的地址。"}'));jctx.push(JSON.parse('{"id": "210129", "tag": "os", "text": "# mount和文件路径改写\\n\\nmount的参数很多，关键概念就是将device挂到mountpoint。其它的参数是因为device必然涉及很多控制选项。\\n\\n有两个重要的关联文件\\n\\n* /etc/fstab 启动时要挂载哪些设备，用UUID标记部分磁盘分区，记录物理分区，注意整块盘没有UUID。使用systemd系统时，systemd接管了挂载/etc/fstab的任务。在系统启动的时候，systemd会读取/etc/fstab文件并通过systemd-fstab-generator工具将该文件转换为systemd unit来执行\\n* /etc/mtab 内核已挂载的文件系统，像proc、sys这类特殊的文件系统都会记录\\n\\n## proc下的3个mount文件解析\\n\\nmountinfo\\n\\n* mount ID\\n* 父mountID\\n* device主编号:子编号\\n* mount源路径\\n* mount目的路径\\n* mount属性，如ro/rw\\n* mount点share subtree的flag：shared:23，共享组ID；slave:24，master的组ID，直近の共有を継承しているシステムのマウントID；unbindable:不能被bind\\n* 文件系统名称\\n* 设备名（取决于`show_devname()`内容，否则和文件系统一样）\\n* 超级块的属性，比如ro/rw\\n* 超级块的选项（文件系统所属的`show_options()`内容）\\n\\nmounts\\n\\n* 设备名（取决于`show_devname()`）\\n* mount目的路径\\n* 文件系统名\\n* mount属性，如ro/rw\\n* 超级块option，我所见都是0\\n* mount options，我所见都是0\\n\\nmountstats\\n\\n* 内容较少，且条目数和mounts一样，不再介绍\\n\\n## proot\\n\\n沿着文件路径改写再往前想，如果把整个发行版的内容挂载到某个目录，并以此目录为根，我们就在一个系统内有了另一个子发行版。限制根目录访问是chroot系统调用，需要root权限，于是又产生了proot这个不需要特殊权限的应用程序。\\n\\n虽然都带root字样，但两者差别极大。chroot是系统函数，而proot则是基于ptrace接口的应用程序，p猜测是pseudo的简写。proot对fork的子进程做了ptrace挂钩，当子进程读写文件时，由父进程转成对/proc/pid/fd的读写，实现了子进程内对文件路径的改写。"}'));jctx.push(JSON.parse('{"id": "210202", "tag": "net", "text": "# 防火墙与iptables\\n\\n至少要两块网卡分别控制流进和流出，才能实现完整的防火功能，即使是纯软防火墙也要两张卡。\\n\\nLinux中起防火墙作用的是Netfilter，而iptables是管理控制netfilter的工具，可以使用它进行相关规则的制定以及其他的动作。iptables是用户层的程序，netfilter是内核空间的。\\n\\niptables有两个版本，legacy依赖getsockopt/set内核接口，功能上相对受限，新版本改为依赖`nf_tables`接口。从名字就能看出是对table的操作，每种table有不同类型的内置chain，每个chain又有条数不等的rule。\\n\\ntable有以下5种\\n\\n* filter 默认table，3种内置chain(INPUT/FORWARD/OUTPUT)\\n* nat 4种内置chain(PREROUTING/INPUT/OUTPUT/POSTROUTING)\\n* mangle 下面这3个没看到有效信息，先跳过\\n* raw \\n* security\\n\\n## 命令解释\\n\\niptables的命令，就是选哪个table(-t)，对链做哪些操作(-I/-R/-A/-D/-S)，最后的参数是rule。看例子 iptables -I FORWARD -o br0 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT\\n\\n首先没有-t表示默认filter，-I表示向FORWARD这条转发链添加动作，具体的rule包括转发目标接口br0，-m和-j是rule-specification，连起来表示转发到br0的包，只要匹配到连接跟踪时，则接受，复用该连接回到连接发起的地方。\\n\\n-j有3种特殊的jump动作: SNAT, DNAT, MASQUERADE\\n\\n### iptables-save\\n\\n把所有table打印出来，有:和-A两种链\\n\\n1. :INPUT ACCEPT [3:180]，:KUBE-SERVICES。表示chain名，有内置5种和用户自定义\\n2. -A OUTPUT或-A KUBE-SERVICES，后面跟具体的-d -j选项表示动作"}'));jctx.push(JSON.parse('{"id": "210205", "tag": "os", "text": "# Linux的权限与sudo辨析\\n\\n## 组\\n\\nid命令显示gid和groups输出，原因是每个用户只有一个初始组，但会加入多个组。当只有一个组时，这两个输出相同，加入多组就能看到区别。\\n\\n组也有密码，但很少用，实际中多用sudo来完成权限管控。\\n\\n## 权限\\n\\nlinux的权限管控主要体现在两方面：\\n\\n1、文件权限 2、进程权限\\n\\n文件权限包括五种：\\n\\n* r：可读取文件内容或目录结构\\n* w：可修改文件的内容或目录的结构（但不包括删除）\\n* x：文件可被系统执行或目录可被作文工作目录\\n* s：文件在执行阶段具有文件所有者的权限\\n* t：使一个目录既能够让任何用户写入文档，又不让用户删除这个目录下他人的文档\\n\\n一个文件拥有三组权限，所有者权限、所属组权限、其他人权限\\n\\n进程权限\\n\\n进程就是用户访问计算机资源的代理，用户执行的操作其实是带有用户身份信息的进程执行的操作。这里介绍两个最重要的进程权限id\\n\\nreaal user id(ruid)：执行进程者的 user id，一般情况下就是用户登录时的 user id effective user id(euid)：决定进程是否对某个文件有操作权限，默认为ruid\\n在文件权限和进程权限id里，s文件权限和euid权限id是sudo实现提升权限的根本。一个进程是否能操作某个文件，取决于进程的euid是否拥有这个文件的相应权限，而不是ruid。也就是说，如果想要让进程获得某个用户的权限，只要把进程的euid设置为该用户id就可以了。在具体一点，我们想要让进程拥有root用户的权限，我只要想办法把进程的euid设置成root的id：0就可以了。\\n\\nLinux提供了一个seteuid的函数，可以更改进程的euid。函数声明在头文件里。\\n\\nint seteuid(uid_t euid);\\n但是，如果一个进程本身没有root权限，也就是说euid不是0，是无法通过调用seteuid将进程的权限提升的，调用seteuid会出现错误。 那该怎么把进程的euid该为root的id：0呢？那就是通过s权限。\\n\\n如果一个文件拥有x权限，表示这个文件可以被执行。shell执行命令或程序的时候，先fork一个进程，再通过exec函数族执行这个命令或程序，这样的话，执行这个文件的进程的ruid和euid就是当前登入shell的用户id。\\n\\n当这个文件拥有x权限和s权限时，在shell进行fork后调动exec函数族执行这个文件的时候，这个进程的euid将被系统更改为这个文件的拥有者id。\\n\\n比如，一个文件的拥有者为user_1，权限为rwsr-xr-x，那么你用user_2的文件执行他的时候，执行这个文件的进程的ruid为user_2的id，euid为user_1的id。\\n\\n创建一个main.c文件，并写入如下代码：\\n\\n```\\n#include <stdio.h>\\n#include <unistd.h>\\n\\nint main(int argc, char* argv[])\\n{\\n        printf(\\"ruid: %d\\\\n\\",getuid());\\n        printf(\\"euid: %d\\\\n\\",geteuid());\\n        return 0;\\n}\\n```\\n\\n运行结果如下：\\n\\n```\\nruid: 1000\\neuid: 1000\\n```\\n\\n通过chmod和chown为文件更改拥有者和添加s权限\\n\\n```\\nsudo chown root ./main\\nsudo chmod +s ./main\\nruid: 1000\\neuid: 0\\n```\\n\\n此时由于文件的s权限，euid已经变为了root的id：0\\n\\n将代码修改如下：\\n\\n```\\n#include <stdio.h>\\n#include <unistd.h>\\n\\nint maind(int argc, char* argv[])\\n{\\n    printf(\\"ruid: %d\\\\n\\",getuid());\\n    printf(\\"euid: %d\\\\n\\",geteuid());\\n\\n    if(execvp(argv[1], argv+1) == -1){\\n        perror(\\"execvp error\\");\\n    };\\n    return 0;\\n}\\n```\\n\\n编译后执行\\n\\n```\\nsudo chown root ./main\\nsudo chmod +s ./main\\n./main apt update\\n```\\n\\n可以看到，已经成功运行apt并进行了软件列表的更新。查看sudo的权限，就是一个拥有者为root且拥有s权限的可执行文件。\\n\\n-rwsr-xr-x 1 root root\\n\\n实际的sudo实现要比这复杂的很多，比如检查配置文件，来决定哪些用户可以使用sudo，为了安全考虑sudo还要求验证ruid的用户密码等。\\n\\n## 记录用户登陆行为有3个文件\\n\\n* utmp: /var/run/utmp，记录当前正在登录系统的用户信息，默认由who和w记录当前登录用户的信息，uptime记录系统启动时间。u表示up\\n* wtmp: /var/log/wtmp，记录当前正在登录和历史登录系统的用户信息，默认由last命令查看。w表示when\\n* btmp: /var/log/btmp，记录失败的登录尝试信息，默认由lastb命令查看。b表示bad\\n\\n这3个命令据考证在1971年的Unix v1版本就出现了，当时文件记录在/tmp目录，所以这个有些随意的名字就一直沿用至今。文件是二进制格式，3个文件遵循相同的记录格式，解析参考/usr/include/utmp.h文件。\\n\\n## 文件隐藏权限\\n\\nOperation not permitted，用lsattr查到有i权限，用chattr去掉后通过。也可能文件本身没有问题，但归属的目录有问题，用lsattr -a查看目录并操作。\\n\\n文件属于e2fsprogs包。"}'));jctx.push(JSON.parse('{"id": "210211", "tag": "os", "text": "# 线程模型与调度\\n\\n共有3种线程模型，以x:y命名，即x个用户线程对应y个内核调度实体(Kernel Scheduling Entity，这个是内核分配CPU的对象单位)。\\n\\n1. 多对一(M:1)的用户级线程模型。似乎没有实现，缺点在于：多线程并发执行，如果一个线程执行阻塞的IO操作，内核接管这个操作，用户态的其他线程都会被阻塞，因为这些线程都对应同一个内核调度实体。这时内核不知道用户态有多线程，无法把它们调度到其他处理器，也无法通过优先级来调度。这种模型只在单核处理器上有一定意义。\\n2. 一对一(1:1)的内核级线程模型。典型的是POSIX的pthread，每个用户线程都对应各自的内核调度实体。由内核来调度的结果就是：线程的每次操作会在用户态和内核态切换，影响速度。另外如果出现大量线程，会在内核分配同等数量的线程调度实体，影响系统性能。\\n3. 多对多(M:N)的两级线程模型。典型的是golang的协程调度，结合了1：1和M：1的优点，每个线程可以拥有多个调度实体，也可以多个线程对应一个调度实体。但这种模型的线程调度，必须由内核态和用户态一起来实现，典型如go语言在1.2版本后内嵌支持了（1.1时代是1：1模型）。因为当多个对象操作一个资源时，肯定要有同步机制，用户态和内核态的分工合作导致实现该模型非常复杂。Linux的第二代模型NGPT用了多对多模型，但性能上仍输给了使用一对一模型的第三代NPTL。（其实NPTL曾经也想使用M:N，但因为太复杂，且要对内核进行大范围改动，最终还是用了一对一）。\\n\\n## golang调度\\n\\nGo的调度器内部有三个重要的结构：M，P，G\\n\\n* M是对内核级线程的封装，数量对应真实的CPU数，一个M就是一个线程，goroutine就是跑在M之上的；M是一个很大的结构，里面维护小对象内存cache（mcache）、当前执行的goroutine、随机数发生器等等非常多的信息\\n* P全称是Processor，它处理的是协程与队列，用于执行goroutine的。每个Processor对象都拥有一个LRQ（Local Run Queue），未分配的Goroutine对象保存在GRQ（Global Run Queue ）中，等待分配给某一个P的LRQ中，每个LRQ里面包含若干个用户创建的Goroutine对象。\\n* G代表一个goroutine，它有自己的栈，instruction pointer和其他信息（正在等待的channel等等），用于调度。\\n\\nGolang采用M:N线程模型，对系统线程（内核级线程）进行了封装，暴露了一个轻量级的协程goroutine（用户级线程）供用户使用，而用户级线程到内核级线程的调度由golang的runtime负责，调度逻辑对外透明。goroutine的优势在于上下文切换在完全用户态进行，无需像线程一样频繁在用户态与内核态之间切换，节约了资源消耗。\\n\\n这张图是正在运行中的状态，有2个物理线程M，每一个M被一个处理器P管理，每一个P也都有一个正在运行的goroutine（蓝色），灰色的那些goroutine并没有运行，而是处于等待被调度的ready就绪态。P维护着这个队列（称之为runqueue）。\\n\\n![go-runtime-state](img/gorun1.jpg)\\n\\nP的数量可以通过GOMAXPROCS()来设置，它其实也就代表了真正的并发度，即有多少个goroutine可以同时运行。Go语言里，启动一个goroutine很容易：go function 就行，所以每有一个go语句被执行，runqueue队列就在其末尾加入一个goroutine，在下一个调度点，就从runqueue中取出一个goroutine执行。\\n\\n当一个OS线程M0陷入阻塞时（如下图)，P转而在运行M1，图中的M1可能是正被创建，或者从线程缓存中取出。\\n\\n![go-runtime-block](img/gorun2.jpg)\\n\\n当MO返回时，它必须尝试取得一个P来运行goroutine，一般情况下，它会从其他的OS线程那里拿一个P过来，如果没有拿到的话，它就把goroutine放在一个global runqueue里，然后自己睡眠（放入线程缓存里）。所有的P也会周期性的检查global runqueue并运行其中的goroutine，否则global runqueue上的goroutine永远无法执行。\\n\\n另一种情况是P所分配的任务G很快就执行完了（分配不均），这就导致了这个处理器P很闲，但是其他的P还有任务，此时如果global runqueue没有任务G了，那么P不得不从其他的P里拿一些G来执行。一般来说，如果P从其他的P那里拿任务的话，会拿run queue的一半，这就确保了每个OS线程都能充分的使用，如下图：\\n\\n![go-runtime-schedule](img/gorun3.jpg)\\n\\n## MPG相关QA\\n\\n1. M和P的数量如何确定？何时会创建M和P？\\n\\n    a) P的数量由启动时环境变量$GOMAXPROCS或者是由runtime的方法GOMAXPROCS()决定（默认是1）。这意味着在程序执行的任意时刻都只有$GOMAXPROCS个goroutine在同时运行。\\n\\n    b) M的数量受go语言本身的限制，go程序启动时，会设置M的最大数量，默认10000.但是内核很难支持这么多的线程数，所以这个限制可以忽略。\\nruntime/debug中的SetMaxThreads函数，设置M的最大数量。一个M阻塞了，会创建新的M。\\n\\n    c) M与P的数量没有绝对关系，一个M阻塞，P就会去创建或者切换另一个M，所以，即使P的默认数量是1，也有可能会创建很多个M出来。\\n\\n    d) P何时创建：在确定了P的最大数量n后，运行时系统会根据这个数量创建n个P。\\n\\n    e) M何时创建：没有足够的M来关联P并运行其中的可运行的G。比如所有的M此时都阻塞住了，而P中还有很多就绪任务，就会去寻找空闲的M，而没有空闲的，就会去创建新的M。\\n\\n2. M选择哪一个P关联？什么时候会切换P与M的关联关系？\\n\\n    M会关联到创建了这个M的那个P。当M因系统调用而阻塞时（M上运行的G进入了系统调用的时候），M与P会分开，如果此时P的就绪队列中还有任务，P就会去关联一个空闲的M，或者创建一个M进行关联。（也就是说go不是像libtask一样处理IO阻塞的？不确定。）\\n\\n3. 就绪的G如何选择进入哪个P的就绪队列？\\n\\n    默认情况下：P的数量是1（M不一定是1），所以如果我们不改变GOMAXPROCS，无论我们在程序中用go语句创建多少个goroutine，它们都只会被塞入同一个P的就绪队列中。\\n\\n    有多个P的情况下：如果修改了GOMAXPROCS或者调用了runtime.GOMAXPROCS，运行时系统会把所有的G均匀的分布在各个P的就绪队列中。\\n\\n4. 如何保证每个P的就绪队列中都会有G\\n\\n    如果一个P的就绪队列所有任务都执行完了，那么P会尝试从其他P的就绪队列中取出一部分到自己的就绪队列中，保证每个P都有任务可以执行。\\n\\n## Erlang的调度\\n\\nBEAM的调度模式在2006从单线程切换到多线程（最早在1998年由一个硕士着手研究），有点类似go的MG模型，没有P。相比go的原生调度，由于BEAM是虚拟机形态，调度灵活程度更高。\\n\\n在BEAM中，除了process之外，还有3种调度单位：端口（ports）、链入式驱动（linkd-in drivers）和系统级活动（system level activities）。这三种特殊的任务形式主要用来进行IO操作和执行其他语言的代码等功能。\\n\\n## Go和Erlang的比较\\n\\ngo是协作式调度，除非进入内核阻塞态，协程一直运行，这和它native的实现有一定关系。而erlang是轮转调度，分了4个优先级，基于VM机制可以抢占。"}'));jctx.push(JSON.parse('{"id": "210216", "tag": "data", "text": "# hadoop体系理解\\n\\nhdfs师从gfs的设计理念，也是面向大数据量、高吞吐的场景设计，因此单个文件默认设置为64M。而过多的小文件也会给元数据管理带来极大的负担，甚至导致OOM。\\n\\nhadoop除了存储还包含了调度，在容器环境从上向下分了若干层\\n\\n* DataNode: 同时还执行NodeManager进程\\n* ResourceManager: 对应yarn，管理service和node两个维度。node看到datanode上的节点内存和vCore数量。\\n* NameNode: 存储了hdfs所有的元数据，hdfs命令也在这一层执行，同时hdfs还是很多daemon的执行入口。1.0时代存在单点问题，2.0支持主备模式，仅主节点提供读写，主备切换控制的ZKFailOver也运行在这里\\n* JournalNode: 为了支撑NameNode的主备切换，需要有共享存储层，业界不同厂商提出了多套方案，最后Cloudera的QJM方案被合入trunk，就是JN层。使用EditLog机制，用2N+1个副本保存数据，允许N个节点失效。当NameNode发生主备切换时，备机要从JN上同步完数据后才能工作\\n\\n## 配置文件\\n\\n分为core、hdfs、mapred、yarn四个核心xml配置，start-dfs和start-yarn命令可以启动服务。\\n\\n## hdfs元数据管理\\n\\nNamenode主要维护两个元数据文件\\n\\n* fsimage: 保存了最新的元数据检查点，包含了整个HDFS文件系统的所有目录和文件的信息。对于文件来说包括了数据块描述信息、修改时间、访问时间等；对于目录来说包括修改时间、访问权限控制信息(目录所属用户，所在组)等。简单的说，Fsimage就是在某一时刻，整个hdfs 的快照，就是这个时刻hdfs上所有的文件块和目录，分别的状态，位于哪些个datanode，各自的权限，各自的副本个数等。注意：Block的位置信息不会保存到fsimage，Block保存在哪个DataNode（由DataNode启动时上报）。\\n* editlog: 主要是在NameNode已经启动情况下对HDFS进行的各种更新操作进行记录，HDFS客户端执行所有的写操作都会被记录到editlog中。\\n\\n写入元数据： 在NameNode运行时会将内存中的元数据信息存储到所指定的文件，即${dfs.name.dir}/current目录下的fsimage文件，此外还会将另外一部分对NameNode更改的日志信息存储到${dfs.name.dir}/current目录下的edits文件中。fsimage文件和edits文件可以确定NameNode节点当前的状态，这样在NameNode节点由于突发原因崩溃时，可以根据这两个文件中的内容恢复到节点崩溃前的状态，所以对NameNode节点中内存元数据的每次修改都必须保存下来。如果每次都保存到fsimage，效率就特别低效，所以引入编辑日志edits，保存对元数据的修改信息，也就是fsimage文件保存NameNode节点中某一时刻内存中的元数据（即目录树），edits保存这一时刻之后的对元数据的更改信息。\\n\\n读取元数据： 启动NameNode节点时，从镜像和编辑日志中读取元数据。\\n\\n因此fsimage和editlog是互相配合，这又引申出另一个进程SecondaryNameNode，主要有两个作用，一是镜像备份（不是NN的备份，但可以做备份），二是日志与镜像的定期合并。\\n\\n## Yarn\\n\\n前身是1.x时代的JobTrack和TaskTrack，其中JobTrack是单点而且既管资源也管任务调度，职责过多，所以演化出了二代目Yarn，不仅做了水平拓展，还对功能做了拆解，Yarn最核心的组件是ResourceManager和NodeManager，通过yarn rmadmin -getAllService看到rm1和rm2两个节点的active/standby状态，因此不会有单点故障。\\n\\n任务提交流程\\n\\n1. 客户端向ResourceManager提交任务请求，如果条件具备，则返回一个JobID和临时的hdfs路径，状态NEW或NEW_SAVING\\n2. 客户端向hdfs路径上放好运行所需的资源，进行job正式提交，状态SUBMIT\\n3. RM将job请求转交给调度器，调度器确认客户端有队列权限且资源足够分配AppMaster，状态ACCEPT\\n4. ResourceManager在NodeManager中找一个物理节点，启动AppMaster（如spark的driver和flink的jobManager），状态RUNNING\\n5. AppMaster继续向RM申请资源，确保NM上可以创建任务；然后找NodeManager创建Container，并执行子节点任务\\n\\n注意第4步状态虽然是RUNNING，但只有AM在运行，分布式任务往往要启动更多子节点，但从YARN的角度无法知道子节点是否在运行，也因此会限制AM占用资源的上限，否则会出现AM互相等待而任务永远无法启动的窘境。\\n\\n因为都基于yarn执行任务的流程框架，所以spark和flink的运行过程是非常相似的。\\n\\n## Hive的数据分区\\n\\n对关系型数据库而言，随着数量的扩大，计算会越来越困难，这时将数据按一定规则拆分，减少每块的大小，从而提升速度。分区将数据切分，每个分区都是全部数据的一部分，整体构成全部数据。\\n\\n对hive而言，由于不能update，所以只能每次全量更新，这就导致离线计算特性，每天全量计算一遍数据，因此hive的分区是update的一种替代，更类似时序的概念，不同的分区对应hdfs不同的目录，只表示新旧，不会将数据切分，每个分区都是全量。"}'));jctx.push(JSON.parse('{"id": "210322", "tag": "data", "text": "# 对公有云上数仓的调研\\n\\nSnowflake的数仓产品在架构上分为三级，从下到上的功能分别是（以Amazon为例，这块有论文相对详细，MG两家没什么资料）\\n\\n1. DataStorage：基于Amazon S3，存储数仓数据。选型时在S3和自建HDFS间有过权衡，最终还是选择了S3，从经济上更合算，且关注点聚焦在应用层。\\n2. VirtualWarehouse：每个VW由数量不等的Amazon EC2弹性计算实例构成，在向用户销售时，使用S->M->L这种服务尺寸，用户看不到EC2的数量。由于计算规格的单价已经分档，后续的付费就是基于时间来计费，Snowflake还贴心地给用户提供了超过多少时间停用的选项，有点类似运营商流量套餐超限保护，避免按调用次数付费场景下，写出了烂SQL，结果账单爆表的问题。\\n3. CloudServices：这块是Snowflake的核心自研产物，包括SQL执行引擎（三大特性：列存、向量化、push方式，上游主动给下游推数据，据说能提高缓存效率，之前很多引擎，都是基于Volcano模型的pull方式）、表的元数据管理（KV形式存储）、并发控制和事务管理。\\n\\n计算存储分离\\n\\n业界有一种主流的架构称为Shared-Nothing，指对一个很大的表数据，系统把它按照某种规则拆分成N份，拆分之后由N个worker来分别处理其中的一个分区。这样的好处是架构比较简单，所有worker上的处理逻辑都一样，worker节点之间不共享任何数据，查询执行的过程中没有资源的争抢，效率很高，而且拆分之后普通的机器就可以计算很大的查询，不再需要什么特殊的高配机器。它最大的缺点是，把计算资源和存储资源捆绑在一起，引起以下问题：\\n\\n1.  当集群的节点数发生变化(升级，扩缩容等等)的时候，Shared-Nothing 需要对数据重新进行分布，而这个是需要消耗大量的计算资源的，在这期间用户在线查询的性能会受到影响。\\n2.  不同场景对于机器配置的要求不一样，一个对于数据导入很好的配置(IO intensive)对于复杂的在线查询(CPU-intensive)就不一定适合，而为了支持所有的场景，最后机器的配置要取个折中，从而无法达到最好的性价比。\\n3.  集群的软件版本有升级的需要。虽然理论上可以一个接着一个地升级，但是工程实现会很复杂。\\n\\n由于Snowflake把存储和计算分别部署在S3和EC2上，实现了分离。对前面提到的Shared-Nothing的几个问题，对于异构工作负载的问题，用户可以为不同的场景分配不同的计算层机器，用完了之后可以释放掉（这点和Snowflake的计费模式也有关）。又因为EC2和S3没有任何关系，在计算节点扩缩容时，当然不需要对数据进行重分布操作。\\n \\n技术特性问答\\n\\n* 如何解决存算分离带来的性能问题？\\n\\n每台Worker节点都配备了SSD，这个SSD并不保存原始数据，而是保存被之前查询请求过的热数据，做到在性能和成本间的平衡。为了提高缓存文件的磁盘命中率，Snowflake的查询优化器在调度TableScan的时候会根据表对应的底层文件名，以一致性hash的算法把数据加载的请求分到这些worker节点上，保证对同一个文件的请求可以尽量落到同一个worker节点上去，提高命中率。\\n因此从大的架构来看Snowflake做了计算和存储的分离，但是如果看缓存的设计，会发现计算和存储又绑定到一起了。只不过这个绑定不明显，而且只存储被查询的数据，不是全量数据。\\n\\n* 如何实现更新？\\n\\nSnowflake系统里面的数据文件都是只读的，当用户对数据进行更新的时候，系统会产生新的文件，把老的文件替换掉，但是每个文件本身是只读的，这样的模式特别适合S3的存储特性（只能覆盖写，不能追加写），同时也方便实现MVCC -- 只要让每个查询始终读查询开始时的对应的版本的文件就好了。\\n\\n* 如何实现事务？\\n\\n事务是通过 Snapshot Isolation的方式来实现的，所谓的Snapshot Isolation, 指的是一个查询能看的数据是这个查询开始时整个系统的一个快照，跟类似系统一样，Snowflake也是通过MVCC来实现Snapshot Isolation的。\\n\\n* 为什么不用索引？\\n\\n1. 索引依赖对文件随机读，而S3系统并不适合随机读取。\\n2. 索引会降低查询、加载的效率，数仓数据量都特别的大，降低了加载的效率在需要做数据恢复的时候是很大的问题。\\n3. 索引需要用户手动创建，会加重用户使用成本。\\n\\n* 索引的替换方案是什么？\\n\\n在每个数据文件上保存数据的min/max类统计数据，通过对这些元数据进行扫描可以判断是否要扫整个文件，避免扫描所有文件。这种方案在顺序大块数据时效果很好，对数据载入、查询优化、查询执行的影响也非常小。\\nSnowflake对半结构化的列也会生成min/max。除了静态剪枝，Snowflake还会运行期动态剪枝。例如在hash join时，Snowflake会在构建端统计join key的分布，再传到探测端用来过滤数据，甚至有机会跳过整个文件。\\n\\n* 如何做到数据加密？\\n\\n数据会在两个地方加密，一个是网络传输时，一个是磁盘写入时（如Amazon S3）。\\n存储数据的加密滚动策略：磁盘上保存数据用的加密key是一直在变化的，具体策略是定期创建新的key，之后旧的key只用来解密，不能再加密了。当确定一个key要被弃用后，用这个key加密的文件会被用新的key重新加密。"}'));jctx.push(JSON.parse('{"id": "210404", "tag": "data", "text": "# 数据库的执行优化\\n\\n现代数据库都基于成本做CBO优化，CBO的难点在评估不同规则组合的期望时间，这里就会有组合爆炸的问题，为此就有了两种模型：Volcano模型和Cascades模型。其中Calcite使用的是Volcano模型，而Orca使用的是Cascades模型。这两种模型的思想都基于成本最优假设，即局部最优化后即达到整体最优化，不同点在于Cascades模型并不是先Explore、后Build，而是边Explore边Build，从而进一步裁剪掉一些执行计划。\\n\\nVolcano模型是一种经典的基于行的流式迭代模型(Row-BasedStreaming Iterator Model)，主流的关系数据库Oracle，SQL Server, MySQL等都采用了这种模型。在Volcano模型中，所有的代数运算符(operator)都被看成是一个迭代器，它们都提供一组简单的接口：open() -> next() -> close()，查询计划树由一个个这样的关系运算符组成，每一次的next()调用，运算符就返回一行(Row)，每一个运算符的next()都有自己的流控逻辑，数据通过运算符自上而下的next()嵌套调用而被动的进行拉取。\\n\\n和Volcano的相对应，推送模型最早在一些流媒体计算中被使用，随着大数据时代的来临，在一些基于内存设计的OLAP数据库也被大量使用起来，例如HyPer、LegoBase等。\\n\\n![sql-pull-push](/img/sql-pull-push.jpg)"}'));jctx.push(JSON.parse('{"id": "210421", "tag": "tool", "text": "# vim的扩展与插件\\n\\n## 理念的区别\\n\\n扩展的最终目的，是把操作映射为脚本化的描述，说到这点不得不和EMACS做个对比。\\n\\nEMACS统一用函数表达，函数和变量在EMACS中体现得非常彻底，而vi由于其操作第一性，并不是每个操作都有对应的函数（比如说hjkl代表的移动，没有直接对应函数来表示这个行为，只能cursor间接实现）。VimL脚本实质是ex命令的集合，因为vi有多模式，操作要注意是在什么模式下进行（可以是normal或execute方式的动态化操作）。但是很多原来只是给人看的操作，通过`redir => var`方式，也能被变量捕获，进而获得一定程度的脚本化能力，这也是vim自身在演化过程做出的调整。\\n\\n因此VimL脚本的思路和EMACS不同，操作是交互式的，并不是所有操作都适应脚本化。比如移动窗口到下一个位置，对人有意义，但对精确的脚本作业就没有实质价值。VIM把所有的按键都赋予很高效的操作方式，脚本层面看起来就不一致甚至丑陋，而EMACS则在函数层面更一致，也导致经常要连续按多个按键才能触发一个动作。\\n\\n## 脚本与扩展\\n\\n前面提到vi逐渐演化成今天的样子，所以脚本中有多种方式来触发动作，典型有3种\\n\\n1. execute 动态执行ex模式的命令\\n2. call 执行指定函数\\n3. normal 输入操作指令\\n\\n扩展主要会用到以下3种方式\\n\\n1. 快捷键，最终触发函数或命令（含自定义和内建命令）\\n2. 命令，触发内建命令或函数\\n3. 操作宏，似乎更像Ad-Hoc操作\\n\\n函数是一系列操作的批量作用，两者结合达成最终目的。\\n\\n快捷键最终都是映射到命令，所以格式一定要用`:call xx<CR>`。即用冒号触发命令模式，再用回车结束。\\n\\n自定义命令即不需要冒号也不需要回车，前者是已经在命令模式，又因在命令模式一定会按回车，所以不用写回车。\\n\\n## 函数参数\\n\\n必须明确写出参数个数，否则运行时报错而不是静默地处理为NULL，可变参数a:000的类型是list，即使不传值也会构造一个空list，先用a:0取得长度，再取数。静态函数由于最终被展开为`<SNR_xx>`，不知道具体名字，所以特意引入<SID>相对表示。\\n\\n## 模拟的包机制\\n\\n官方只做了autoload加载，包机制是爱好者开发的，是沿着autoload的进一步封装。调用package#import函数，获得某个指定模块的字典对象，接下来就可以在这个字典对象上执行函数调用，看起来和常见的编程语言风格更接近。\\n\\n## 插件原理\\n\\n由于支持写扩展命令，某人把他写好的扩展命令，用vim和用户交互的接口，包括命令、函数、<plug>键映射、事件代码的方式开放给别人用，便是个插件。\\n\\n插件是一个具有特定结构的目录。其中最重要的一级子目录是plugin目录，如果整个目录在vim的rtp列表中，则这个目录的plugin子目录内的每个vim文件（不管多深）都会在启动时被加载，但不确保加载顺序。这种加载方式只适合互相之间没有关联的场景，且也不能做到懒加载。逐渐地衍生出了autoload目录，autoload内的vim文件，只有在其它文件出现call xyz#abc()函数调用时，才会去加载autoload/xyz.vim文件，进而调用abc函数。有了autoload机制后，现在的插件几乎都变成了plugin子目录下仅有1个vim文件，其它文件都移到autoload目录按需调用。\\n\\n有些插件希望自己的加载顺序靠后一些，因此目录下如果有after/plugin文件夹，则这个文件夹内的所有vim文件至少会在plugin后面加载。\\n\\nplug是个单体文件，放在**runtimepath简称rtp**的autoload目录，必须命名为plug.vim，*必须小写*否则会找不到（原因从前述机制可以明白）。用`echo &rtp`查看选项值，如果不包含插件目录，配置`rtp+=your-dir`。这个插件用法是先调用plug#begin()，然后用Plug命令加载各种插件目录，最后执行plug#end()。原理是#begin()时会初始化g:plugs字典，在Plug时把各种路径写入这个字典，到#end()时，会遍历g:plugs，并source每个目录的plugin/ftdetect/after等关键目录下的所有vim文件，从而实现插件加载。\\n\\n## 问题排查\\n\\n配置了若干插件，但是调整了一些文件后发现又失效了。现象是插件管理的Plug系命令有效，但Rainbow命令出不来，就要从插件的加载会依赖rtp路径，用echo &rtp发现我的配置路径并不在列表中，但Plug又是可用的，加载Plug之后rtp路径被修改了。由于最后加载的spf13.vim是抄的，搜索rtp没结果，再搜索runtimepath，果然用=把结果全部重置了，但并不影响已经载入的Plug命令。问题找到去掉赋值语句就行了。\\n\\n排查问题首先还是要对机制熟悉，再从现象反推各个环节。"}'));jctx.push(JSON.parse('{"id": "210611", "tag": "lang", "text": "# 理解shell的换行和打印\\n\\n写sh时想把一段文本的json变量传给程序，但因为带了换行符，总是失败。大概是因为sh面向终端操作，而换行符又是命令发起的标志，哪怕这个换行符被放在字符串中，也会认为是命令提前结束。因此要把文本中的换行去掉。\\n\\n网上说用cat xx | xarags可以实现，实测会把双引号也去掉，对于json来说不可接受，最终用sed的\':a;N;s/\\\\n//;ta;\'语句实现。\\n\\n带换行的文本\\"ab\\\\ncd\\"存入变量时，直接echo的话，换行会显示成空格，用echo -e才能显示换行，var=$(cat xx)把文件内容赋值，回车会真的转成空格，即使echo -e也还是显示空格。但是：文本最后不管多少个换行，只要换行后没有内容，都不会记入变量。\\n\\n## 动态更新已打印文本\\n\\n`printf \\"%s\\" abc;sleep 1;printf \\"\\\\r%s\\" def`\\n\\n这句语句会先显示abc，1秒钟后用def替换。奥妙有两处\\n\\n1. \\\\r回车来到开头打印，进而更新已打印出的内容\\n2. 用printf而不是echo，因为echo会默认在末尾追加换行，而回车只能回到这一行的开头，如果已经换行就再难回头，所以必须用printf才能实现动态刷新效果\\n\\n终端控制有个非常有名的软件包ncurses，6.2版本自带了1750种历史上曾经存在的终端序列描述，不过现在仍活跃的恐怕不超过10种了。这个包里最有用的命令也许是tput，`tput cup x y`可以自由地定位光标位置。准确地说参数所对应的位置，是PS1的首字符的位置，而光标位置则会被推到后面。\\n\\n## Excel的回车符读取和替换\\n\\nexcel导出的csv中，正常回车是0D 0A，单元格内的回车是0A。\\n\\nfread的r模式无法识别0D，严格说是连着0A起读，直接被吞了。只有rb模式才会逐个字节识别。换句话说，r模式fread(1,1)的次数比总字节数要少，rb才等于总字节数。\\n\\n## 光标控制\\n\\n编程语言用`\\\\`作为转义序列的起始符，而终端则选择了ESC（033或0x1B或\\\\e）作为转义序列的首字母，之所以只是首字母，是因为ESC后面还要跟二级转义符，范围是`@A–Z[\\\\]^_`，这32个中又以`ESC+[`这组称为Control Sequence Introducer（简写作CSI）至今仍广泛使用在光标控制和色彩显示上。"}'));jctx.push(JSON.parse('{"id": "210614", "tag": "lang", "text": "# erlang和其上的扩展语言\\n\\n## 程序组成和功能\\n\\ncent发行版拆得比较细，最核心的erts运行时单独成包，其它lib目录下的库，像compiler,debugger,edoc,kernel,stdlib都是独立的包。\\n\\n* erl: 负责启动模拟器并在终端执行命令，感觉更像个REPL。启动有很多的参数，和其它程序不一样的是选项风格，有`+`和`-`两种类型。erlexec负责加载EMU（现在都是beam了），由EMU负责真正的调度\\n* erlc: 负责将源码编译为beam字节码，和其它编程语言类似\\n* escript: 以解释（非编译）的方式执行源码。在很多其它解释型语言里，erl和escript是同一个程序，如果参数有源文件，就解释执行，否则就进入REPL，但erlang把这两个分开，因为escript的执行要求源码必须有main/1函数，更像C语言指定入口，而不是脚本语言遇到什么语句都会执行\\n* epmd: 严格说并不在PATH路径，也不需要手动启动，当调用erl带上-sname或-name xx@ip参数，会自动启动epmd。即使erl程序退出或崩溃，epmd依然在后台监听\\n\\n启动顺序\\n\\nrun_erl/to_erl（可选，准备有名管道和日志环境） -> erl -> erlexec（在erts目录） -> beam（或beam.smp，很早期是jam）\\n\\nerlang下载时标识的是OTP版本，这个版本也决定了不同节点的程序能否组成集群，非常重要。而运行erl会显示erts/eshell的版本，要区别这两个版本。\\n\\n## 文档\\n\\n安装包后没有文档，从官网下载man包，并放到erlang的根目录，用`erl -man xx`查看。\\n\\n## 类型分析\\n\\n属于扩展包，typer和dialyzer是最成功的两个包。对有标注过类型的源码进行分析，并找出潜在的错误。\\n\\n## lfe的编译\\n\\n由于lfe是shell脚本，源码发布时就在目录中，编译的目的只是为了生成所需的beam文件，用make方式，把erl源码编译为beam，再将一个c文件编译为可执行程序。\\n\\n执行命令前先配置ERL_LIBS路径，参数展开为`erl -user lfe_init -extra`执行。可见执行的底座仍是beam。"}'));jctx.push(JSON.parse('{"id": "210623", "tag": "lang", "text": "# JoeArmstrong看OO\\n\\n最初他认为Erlang不是OOP，而是FP，但是他的导师不同意。\\n\\n老爷子后来认为Erlang是OOP，但是这个OOP和其他人理解的不一样：\\n\\n常规认为OOP=封装+继承+多态。\\n老爷子认为OOP=消息传递 + 隔离 + 多态，其中消息传递最重要，隔离和多态都源自于消息传递。\\nSmalltalk的作者Alan Kay更是认为Messaging是唯一重要的事情。\\n从这个角度，Erlang非常OOP。所以老爷子其实是支持OOP的，但是他支持的不是题主要问的Java那种OOP。\\n\\n为了说清楚上面的问题，我下面把常规认为的OOP称为OOP-A（以早期Java、C#为代表），老爷子理解的OOP称为OOP-B（代表是Erlang）。\\n\\n首先OOP-A语言会非常淡化messaging这件事，或者它们已经把messaging的概念简化成方法调用。而messaging则要求必须有个mailbox，或者消息队列的概念，用来存储还没处理的消息。在OOP-A的语境下，带真正messaging的Object的形式被称为“Actor“，JVM生态下的代表作是Akka。但是Erlang一开始就是基于messaging的。\\n\\n如评论区里所说，smalltalk和ruby语言表达出了“messaging”的概念，本质上是一种方法动态调用的机制，与Erlang/Akka的messaging不同。\\nErlang虽然支持“继承”，但都没有将其看作为特别核心的概念。\\n\\n也许OOP-A里的“封装“和OOP-B里的“隔离”容易被理解为差不多的意思，但实际二者有很大的区别。OOP-A中强调的是“把状态隐藏在Object”内部，所以搞了public和private方法等。 (相关回答：大宽宽：既然Java反射可以访问和修改私有成员变量，那封装成private还有意义么？）\\n\\n但是OOP-B的隔离的目标很简单直接，即要求一个Object crash了其他Object可以不受影响。想象一下在Java程序里的如果有一个Object因为某种原因hang了，也许就会造成死锁，以至于整个程序都不能工作了。而在Erlang里会推崇“supervisor”模式：一个Object hang了，它的supervisor Object会侦测到并且做一些动作（比如杀掉hang的Object，然后新创建新的Object,），程序整体仍然可以跑。这个思路在Erlang里被称为let it crash。\\n\\n对比“隔离”，OOP-A的封装是一种“设计思维”，即在设计上让两个相互独立的东西可以分开，底层实现上有没有关联并不是其关注重点。OOP-B的隔离是从高可用出发的。并且Erlang要求一个Object运行在一个“进程“上（这里的进程是抽象概念，不特指操作系统进程），这样就顺带解决了并发中同步、互斥之类很恶心的问题。更进一步是，Erlang的Object隔离和消息传递可以跨机器。这个特性便利了如RabbitMQ这类系统的开发。有人提到过OOP不利于高并发，但是OOP-B明显是更加容易高并发。\\n\\nOOP-A和OOP-B都提到多态。实际上，OOP-A的多态是建立在“类型“的is-a的基础上的。比如一个Cat类是因为继承了Animal类，才能对“叫”这个方法进行多态的。但OOP-B可以不在意is-a关系。OOP-B的多态就是单纯的觉得任何Object，只要应该有某个能力，就可以“注入”进去。\\n\\n比如在Java写一个业务代码，比如有5种差异很大的产品，比如汽车零件、书、基金理财、手机和会员充值服务。在一个宣传界面上希望这5个产品都能有获取一行简单介绍、一行复杂介绍和一个图标的功能。对于OOP1语言，一定要将他们继承自某个基类，并override掉基类方法才行。你可以想象到它们虽然都是“产品”但是根本就是不同的东西，甚至是5个业务部门各自维护的东西，弄一个共同基类出来无比尴尬。即使弄出来了，单继承的限制也阻碍了这个需求的进一步变化的可行性。其实，这些“产品”仅仅是在展示这件事情上有共性而已，强行发明一个公共基类常常会得到反常识和不灵活的设计。\\n\\n对于OOP-B语言，多态被看作是不同的Object收到同样消息后行为不同。它们只要各自处理“展示”这个事件就行了。这样做自由度更高。\\n\\nBTW, 现在Java实现这种多态可以用interface实现的方式来做。\\n总结下。深入的讨论编程范式时，单纯的用是不是OO已经不能表达清楚的意思了。这就好像简单的说“川菜”好不好吃很模糊，细究下来必须用某家饭馆的某个大厨做的某道菜来细细的品评。我对OOP-A和OOP-B的个人理解是，OOP-B更加自洽，它的目标就是建立庞大但是能容错的程序，这就引发了采用messaging的方案，以及由于messaging得到隔离和多态。整个Erlang的体系都是围绕这个核心做的。当然这些特性并不一定适合你的场景。但我觉得这是一个值得推崇的分析问题-解决问题的思路和做事方式。\\n\\n相反，OOP-A把几个漂亮概念凑一起，对系统设计起到的作用过于宽泛以至于无法落地。比如封装怎么封，谁该和谁相互隐藏，这种并没有什么规则可以遵循，最终还是靠经验。所以有人会争论用不用private、到底是msg.send还是msgMgr.send(msg)这类问题。要解决的问题本身却得不到重点的关注。OOP-A折腾来折腾去就会发现，除了那些漂亮的名词和概念，已经很少关心软件开发本来要解决的问题，如管理软件复杂性、提高可维护性。开发时为了解决实际问题，还是得从业务角度出发思考，以及配合一些“设计模式”才能真的落地。也许在某些特定领域（比如GUI），OOP-A用起来比较贴切，但是整个业界或者培训界显然是过分强调了它们的优势，以至于到了其他OOP-A并不擅长的领域，带来大量设计和编码上的错误。而且很不幸一票编程语言按照OOP-A的思想被做了出来，开发者去跟一众并没有什么卵用的语言的特性较真，反过来却离“创造与解决问题的方案贴切的编程方式“越来越远。（相关回答：大宽宽：面向对象编程的弊端是什么？）\\n\\n最后再次强调下，上文中虽然写了OOP-A和OOP-B，这个仅用于解释Armstrong的原文的意思，这个提法并非是一般性概念。请特别留意：\\n\\n并非说世界上只有OOP-A和OOP-B。实际上C++的OOP，Java的OOP，Ruby的OOP，Erlang的OOP等等都多多少少有些区别。看看下文中老爷子的最后一句“You can try it and see it for yourself“. 即在了解别人的思路的同时，可以有自己的不同的理解。OOP是什么其实不重要，重要的是你看了之后有自己的思考和认识！\\n并非说OOP-B是OOP-A的升级。OOP-B也并不一定比OOP-A更加适合你的问题。此外也没有哪个比另外一个更“好”。我们无法精确的定义什么是“更好的”。比如评论区里有人并不喜欢let it crash这种方式。只有当问题相对确定了，我们才能搞清楚方法是不是“更适合”。\\n以下是老爷子的回答原文。\\n\\nIs Erlang Object Oriented?\\n\\nJoe Armstrong: Smalltalk got a lot of the things right. So if your question is about what I think about object oriented programming, I sort of changed my mind over that. I wrote a an article, a blog thing, years ago - Why object oriented programming is silly. I mainly wanted to provoke people with it. They had a quite interesting response to that and I managed to annoy a lot of people, which was part of the intention actually. I started wondering about what object oriented programming was and I thought Erlang wasn\'t object oriented, it was a functional programming language.\\n\\nThen, my thesis supervisor said \\"But you\'re wrong, Erlang is extremely object oriented\\". He said object oriented languages aren\'t object oriented. I might think, though I\'m not quite sure if I believe this or not, but Erlang might be the only object oriented language because the 3 tenets of object oriented programming are that it\'s based on message passing, that you have isolation between objects and have polymorphism.\\n\\nAlan Kay himself wrote this famous thing and said \\"The notion of object oriented programming is completely misunderstood. It\'s not about objects and classes, it\'s all about messages\\". He wrote that and he said that the initial reaction to object oriented programming was to overemphasize the classes and methods and under emphasize the messages and if we talk much more about messages then it would be a lot nicer. The original Smalltalk was always talking about objects and you sent messages to them and they responded by sending messages back.\\n\\nBut you don\'t really do that and you don\'t really have isolation which is one of the problems. Dan Ingalls said yesterday (I thought it was very nice) about messaging that once you got messaging, you don\'t have to care where the message came from. You don\'t really have to care, the runtime system has to organize the delivery of the message, we don\'t have to care about how it\'s processed. It sort of decouples the sender and the receiver in this kind of mutual way. That\'s why I love messaging.\\n\\nThe 3 things that object oriented programming has it\'s messaging, which is possibly the most important thing. The next thing is isolation and that\'s what I talked about earlier, that my program shouldn\'t crash your program, if the 2 things are isolated, then any mistakes I make in my program will not crash your program. This is certainly not true with Java. You cannot take 2 Java applications, bung them in the JVM and one of them still halts the machine and the other one will halt as well. You can crash somebody else\'s application, so they are not isolated.\\n\\nThe third thing you want is polymorphism. Polymorphism is especially regarding messaging, that\'s just there for the programmer\'s convenience. It\'s very nice to have for all objects or all processes or whatever you call them, to have a printMe method - \\"Go print yourself\\" and then they print themselves. That\'s because the programmers, if they all got different names, the programmer is never going to remember this, so it\'s a polymorphism. It just means \\"OK, all objects have a printMe method. All objects have a what\'s your size method or introspection method.\\"\\n\\nErlang has got all these things. It\'s got isolation, it\'s got polymorphism and it\'s got pure messaging. From that point of view, we might say it\'s the only object oriented language and perhaps I was a bit premature in saying that object oriented languages are about. You can try it and see it for yourself.\\n\\n原文见：Ralph Johnson, Joe Armstrong on the State of OOP\\n"}'));jctx.push(JSON.parse('{"id": "210703", "tag": "lang", "text": "# 并发编程模型\\n\\n说说两种内建在编程语言中的并发流派：Akka/Erlang的actor模型与Go语言的协程Goroutine与通道Channel代表的CSP(Communicating Sequential Processes)模型\\n\\n## Actor模型\\n\\n主角是Actor，类似一种worker，Actor彼此之间直接发送消息，不需要经过什么中介，消息是异步发送和处理的。Actor模型描述了一组为了避免并发编程的常见问题的公理:\\n\\n1. 所有Actor状态是Actor本地的，外部无法访问。\\n1. Actor必须只有通过消息传递进行通信。\u3000\u3000\\n1. 一个Actor可以响应消息:推出新Actor,改变其内部状态,或将消息发送到一个或多个其他参与者。\\n1. Actor可能会堵塞自己,但Actor不应该堵塞它运行的线程。\\n\\n## CSP模型\\n\\nworker之间不直接彼此联系，而是通过不同channel进行消息发布和侦听。消息的发送者和接收者之间通过Channel松耦合，发送者不知道自己消息被哪个接收者消费了，接收者也不知道是哪个发送者发送的消息。\\n\\nGo语言的CSP模型是由协程Goroutine与通道Channel实现：\\n\\n1. goroutine: 是一种轻量线程，它不是操作系统的线程，而是将一个操作系统线程分段使用，通过调度器实现协作式调度。是一种绿色线程，微线程，它与Coroutine协程也有区别，能够在发现堵塞后启动新的微线程。\\n1. channel: 类似Unix的Pipe，用于协程之间通讯和同步。协程之间虽然解耦，但是它们和Channel有着耦合。\\n\\n## Actor模型和CSP区别\\n\\nActor之间直接通讯，而CSP是通过Channel通讯，在耦合度上两者是有区别的，后者更加松耦合。同时，它们都是描述独立的流程通过消息传递进行通信。主要的区别在于：在CSP消息交换是同步的(即两个流程的执行\\"接触点\\"的，在此他们交换消息)，而Actor模型是完全解耦的，可以在任意的时间将消息发送给任何未经证实的接受者。由于Actor享有更大的相互独立,因为他可以根据自己的状态选择处理哪个传入消息。自主性更大些。\\n\\n在Go语言中为了不堵塞流程，程序员必须检查不同的传入消息，以便预见确保正确的顺序。CSP好处是Channel不需要缓冲消息，而Actor理论上需要一个无限大小的邮箱作为消息缓冲。\\n\\nActor是CSP的一个特例，CSP比Actor更加灵活。Erlang将Actor发挥到了极致，通过spawn_link/monitor机制，发展出了OTP框架；CSP比Actor更加灵活，Go目前还未有相似框架。\\n"}'));jctx.push(JSON.parse('{"id": "210721", "tag": "data", "text": "# PySpark分析\\n\\n## 执行过程\\n\\n常用的有local和yarn两种模式，写代码或调错阶段，无特殊情况用local，速度快很多。\\n\\npyspark和scala的spark不同在于，某些情况下数据会从jvm回传给py，这个回传的过程是怎么样的？首先，Spark会先把所有py文件放到此次任务driver端所在的节点，比如我的环境放在 /yarn/nodemanager/usercache/xxx/appcache/application_xx/container_xx_01/main.py 目录，启动py的命令是`path/bin/python main.py --arg=xx`。同时spark会在driver放一个pyspark.zip，解决Py与spark集群通信的问题。driver端任务运行一段时间后，如果发现计算需要把数据传递给executor上的python，就会启动`path/bin/python -m pyspark.daemon`，没有额外的参数。pyspark.daemon会fork一个进程，然后在子进程里执行pyspark.worker.main函数，数据读写的源头也改为来自socket。实际代码中先会做dup，把socket复制出来提高效率。driver和executor之间通过环境变量和socket传递数据和代码（似乎是pickle序列化），此时的executor会在container_xx_02或03目录内执行。\\n\\n进入py代码后，先构建SparkContext对象，构建过程会查找并执行`spark-submit pyspark-shell`命令，构建一个java的gateway，再通过Py4J包，以类似RPC的方式把py代码通过Gateway发送到jvm，进行spark操作。如果计算过程中需要python的udf，则数据必须发送到work节点，过程是由spark启动python的worker.py进程，并以环境变量的方式把端口告知worker，worker会用socket去连接这个port，并做一系列判断，比如driver和worker的python版本必须一致，计算结束后再用socket发送回spark。理论上只要数据不回传给py，开销只是方法的传递，性能和scala的实现是一样的，如果有数据回传，速度会降低一倍以上。\\n\\n## PySpark内容\\n\\n### 包层次\\n\\n顶层目录pyspark包含SparkConf、SparkContext、RDD等spark的基础概念，包含sql、streaming、ml、mllib等多个子模块。\\n\\n### 流程和关键概念\\n\\n如果是写类SQL功能，流程是套路化的\\n\\n1. 获取SparkConf，设置master和appName。我只用过yarn模式\\n2. 把Conf作为参数传给SparkContext。注意，必须构造context，否则无法和spark通信。Conf可以没有，但考虑要设置的参数很多，用Conf方便，另外还有序列化类参数可传入，默认用pickle序列化py和jvm之间的数据\\n3. 通过Context来获取SparkSession。这个Session是属于pyspark.sql的类，整合了SQLContext和HiveContext等多个SQL会用到的功能\\n\\n拿到SparkSession后，读取文件得到的数据呈现形式就是DataFrame类，这个类具备很多SQL语义的API（因为Session就是sql包下的一个类）。DataFrame可以链式操作，即操作后返回的值大部分情况下仍是DataFrame，如果做了groupBy操作，得到的是GroupedData类型。\\n\\n### PySpark命令\\n\\n执行这个命令，会自动加载shell.py脚本并初始化sc(pyspark.context), spark(pyspark.sql.session，对应原生SparkSession类), sql(spark.sql的别名), sqlCtx/sqlContext(pyspark.sql.context.SQLContext)共4个全局变量。"}'));jctx.push(JSON.parse('{"id": "211016", "tag": "net", "text": "# 以太和IP网之外的一些网络\\n\\n对网络来说，第一层物理层的种类相对较少，就我所知无非是光纤、双绞线、单芯线，受限于物理介质不会有太多花样。但在这些介质上传输信号，就必然要定义信号的标准和传输方式，所以链路层（二层）的协议可谓数不胜数，不过大浪淘沙，现在几乎只剩下802协议，但是回顾曾经丰富多彩的链路协议也能看出通信发展与演化。\\n\\n## 802.x\\n\\n以太网、令牌环以及无线网络都是这个家族的一个子类别，之所以是同一个家族，是因为共同遵守802.2的LLC链路控制协议，MAC地址也是这套规范定义的。\\n\\n以太帧除了承载IP包，还能承载ARP、VLan等。\\n\\n## ATM\\n\\n现在估计知道ATM网的人不多了，它采用的信元交换理念（cell switch），和电路交换和包交换都不一样。ATM网协议比TCP/IP协议复杂，也完善的多，基于电信思维制定的ATM网明显比基于计算机专家搞的TCP/IP协议完美太多。论技术，ATM协议绝对更适合通信未来发展，采用虚链路的连接方式，QOS有保障，带宽有保障，传输利用率也更高更稳定，整个网络的流量管理更强大，网络可控性高太多，对现在的流媒体等应用绝对更友好，基于ATM网的上层应用应该就简单很多，而不用像面对TCP/IP协议一样需要自己考虑网络稳定性，而且更强的网络控制和流量管理能力，可以大幅度降低大流量下的网络并发难度，减少现在因为突发流量导致网络崩溃。\\n\\nATM网络虽复杂，但是应用层绝对简单，面对用户应该比TCP/IP协议友好很多。其实TCP/IP协议表面看很简单，然而如果真正自己部署，要运营维护好难度相当高，因为自主性太强，灵活度太高，用户需要自己面对很多灵活的规划部署，这其实相当有挑战性。用TCP/IP协议构建一个小网可能很简单，然而网络复杂一点，就相当有难度。至于成本问题，我一直认为ATM设备贵只是因为他没机会像TCP/IP网一样得到大规模推广，没有规模应用，成本是无法降低的，如果当年率先得到推广的是ATM网而不是TCP/IP网，那ATM设备绝对可以降低成本，而且以电信思维制定的电信网络，往往都是网络端功能强大而复杂，但是接入终端则易总简单且成本低廉，就像我们曾经的固定电话一样，复杂而昂贵的电信局端设备干了基本绝大多数工作，用户客户端其实简单而廉价，所以ATM网当年倘若可以得到大规模应用，其整体成本不见得真就高昂，而且现在云计算的大规模应用，更是把这种将复杂工作放在后端，以简化终端的思想，其实挺适合ATM的技术思想。\\n\\nATM输就输在时间上，ITU-T基于电信网思维经验制定出一个庞大复杂的ATM协议花费了巨大精力和时间，然而计算机领域的专家，根本就不考虑那么多，只求简单快捷，有问题后面再迭代修补，结果标准还没定产品已经跑前面去了，以实战替代标准，所以随着TCP/IP协议的一统江湖，却越来越显示出IP协议在面对流媒体，语音，视频电话等应用时的力不从心，通过在IP协议上修修补补，以求弥补TCP/IP协议的不足，然而本质问题解决不了，只能尽力优化，所以导致为了适应新应用需求，整个TCP/IP协议其实越来越复杂，越来越庞大，虽然光传输的兴起极大的解决了带宽问题和部分QOS问题，然而现实中传输带宽用不是无线的，QOS问题不可能全寄托于传输链路没问题。今天各种应用大爆发，全网融合以IP协议一统天下，然而当年那个天赋异禀却时运不济的ATM只能叹息生不逢时。"}'));jctx.push(JSON.parse('{"id": "211102", "tag": "lang", "text": "# 几种语言的包加载和管理机制\\n\\n## Python和Lua\\n\\n算是比较经典的中心化包管理和分发机制，官方或半官方地提供中央仓库，本地开发需要包时从中央仓库下载到本地的某个公共目录，然后各个项目都从本地公共目录引用（但不会复制到项目下）。比较有意的是，中心仓库可以保存同一个包的多个版本，也可以指定版本下载到本地，但却只能保存一个版本，换版本只能采用覆盖机制。我所知的大部分90年代的动态语言都是这个机制。\\n\\n## Go\\n\\n设计初衷是分布式库管理，下载包就是很原始的去各种网站获取，于是就有了代理方把各种常用的库进行汇总，虽然是代理但间接担当了中心仓库的功能。\\n\\nGo的本地仓，通过将库名和版本号分成两级目录方式，保存了同一个库的所有版本内容，但是代价是v2及以上版本的库和v1库被认为是两个不同的库。\\n\\n## Java\\n\\n总体来说包管理和Go的机制有点像，官方没有考虑过包管理机制，由社区逐渐开发完善。支持在本地缓存保存多版本，最终在具体项目则引入对应版本的包。\\n\\n## PHP\\n\\n相比其它语言，2012年发展出的包管理软件composer算是比较晚的，因此也受了js的npm和ruby的bundle很多影响。由于语言在加载特性上也更少，并不适合作为全局工具，因此更偏向项目级，默认是对某个项目的包管理，也导致多个项目间的代码重复问题。当然composer的global命令也提供本地的公用仓，但毕竟加载机制相比其它语言弱一些，要依赖额外的文件，总有些不完备的感觉。"}'));jctx.push(JSON.parse('{"id": "211115", "tag": "os", "text": "# 搭建最小化的Linux系统\\n\\n有个很有名的发行版Linux From Scratch，非常地繁琐，我们可以从一个近似的形态去一窥究竟，也从中了解很多和二进制执行相关的内容。\\n\\n看过toybox作者给aboriginal写的介绍可知，最小化的系统只要具备4个文件就可以运行：linux、toybox、musl、tcc。linux作为内核没什么要说的，其它3个值得一说\\n\\n* toybox: 另一个同样定位但更强的软件是busybox，这几乎是惟一的应用层全静态链接软件，不依赖libc，只要选对CPU指令集，就可以在主机工作。为什么全静态链接如此重要，稍后解释\\n* musl: 虽然看起来只是个C库，但同时它也是个动态加载器\\n* tcc: 编译器自然是少不了的，在编译的时候可以指定interp的路径，可以适配不同系统的动态加载器名\\n\\n极简环境可以从Android的终端开始进行模拟，首先在这个终端中放入busybox，至少具备了各种操作能力。\\n\\n## 遇到的问题\\n\\n在低版本安卓编译的程序，到版本7后，因为要求可执行程序必须用*-fPIE*方式编译，通常动态库为了动态加载到多个不同进程，都会添加-fPIC标记，但执行程序本身是独立的虚假内存空间，可能出于安全的考虑吧，不是PIE编译的话就不能运行了。"}'));jctx.push(JSON.parse('{"id": "211218", "tag": "os", "text": "# 内存使用的观察和理解\\n\\n## 内存使用表现\\n\\n进程能使用的内存肯定是有上限的，如果慢慢增长，VSZ会持续增长，RSS会到一定量开始波动，但最终还是会因超限被内核kill掉。如果突然申请大量内存，会更早地被kill。VSZ一旦增长，就不会再减少，即使用不到，也会保持这个大小。\\n\\n比如一台8G内存的安卓7.1，每次分配50M内存，VSZ在接近4G、RSS接近3G时退出，但如果调大成先1.25G再750M，即使还不到2G的VSZ也会被kill。\\n\\n## free命令输出\\n\\n为什么 free 命令不直接称为 cache 而非要写成 buff/cache？ 这是因为缓冲区和页高速缓存的实现并非天生就是统一的。在 linux 内核 2.4 中才将它们统一。更早的内核中有两个独立的磁盘缓存：页高速缓存和缓冲区高速缓存。前者缓存页面，后者缓存缓冲区。当你知道了这些故事之后，输出中列的名称可能已经不再重要了。\\n\\n## 用ulimit限制\\n\\nVMEM和AS同义词，AS表示Area Space。python3.10如果只设置soft上限，超过后会收到异常但不会被kill。如果设置内存阈值时低于当前进程使用量，会收到SegmentFault错误然后退出。ulimit有soft和hard两个值，在控制上二者并没有区别，都会限制资源的使用，区别是：\\n\\n1. 无论何时，soft总是小于等于hard\\n2. 无论是超过了soft还是hard，操作都会被拒绝。结合第一点，这句话等价于：超过了soft限制，操作会被拒绝\\n3. 一个process可以修改当前process的soft或hard。但有一些要求：\\n * 修改后soft不能超过hard。也就是说soft增大时，不能超过hard；hard降低到比当前soft还小，那么soft也会随之降低。\\n * 非root或root进程都可以将soft可以在[0-hard]的范围内任意增加或降低。\\n * 非root进程可以降低hard，但不能增加hard。即nofile原来是1000，修改为了900，在修改为1000是不可能的。（单向，只能降不能升）\\n * root进程可以任意修改hard值。\\n\\nbash内建的ulimit默认显示soft，修改时同时影响soft和hard。"}'));jctx.push(JSON.parse('{"id": "211222", "tag": "data", "text": "# SQL的JOIN种类与选择\\n\\n## JOIN关联和WHERE谓词\\n\\n关系代数鼓励把重复的数据拆分，必然导致查询时要把分开的表再合并起来，这个合并的动作在关系代数里称为JOIN连接。连接分交叉连接（再细分出内连接）和外连接（再细分出左连接、右连接、全连接）。很重要的区别是交叉连接时，两张表是对等关系，而外连接有关注表和补充表的区分。回顾一下SQL规范，\\n\\n* SQL89时没有明确的JOIN语法，而是用逗号实现CROSS连接。\\n* SQL92时，出现JOIN。由于CROSS JOIN的语义就是笛卡尔积，因此不能有ON条件；而INNER JOIN是笛卡尔积的过滤，必须有ON条件。但MySQL实现得不规范，CROSS，INNER是等价的。JOIN是INNER的简写形式，自然也等价。此时的外连接语法是在从表后面带上`(+)`\\n* SQL99出现了LEFT和RIGHT连接，而且允许多张表用多个JOIN语句分段写，可读性更好。也因此目前常见的写法都是按SQL99写的\\n\\n交叉连接可以简写为 FROM a , b，结果是所有连接中最大的，实际应用一般都会选INNER，即带了ON条件。**外连接必须有ON语句**。一开始我经常把ON语句误写作WHERE，看其他人的代码，也发现这种错误，说明这对SQL掌握不深的人来说，可能是普遍现象，详细剖析下这两个关键字的语义区别。\\n\\n从简单的单表查询可知，WHERE是对结果表做过滤的谓词。JOIN动作是针对两张表的笛卡尔积，为了满足只取特定的JOIN结果，引入了ON谓词，专门用于多表JOIN过程中的判定，所以虽然WHERE和ON后面都可以跟比较语句，但两者的作用阶段是不同的。如果不用ON，只用WHERE最终也能得到正确结果，但是理论上一定会带来性能的额外开销：前面提到WHERE是针对单张表，意味着JOIN必须生成所有的结果集，得到这个结果集后，才能做WHERE过滤，这就会导致中间结果集过大，而ON恰恰能解决生成结果表过程匹配的问题。另外前面提到了优化器会把WHERE动作前置，但是并不会把WHERE条件作用于JOIN的过程中，所以说ON是JOIN的伴生动作，而WHERE是完全独立的另一个阶段，这两个阶段的顺序可以调换，但绝不会融合。\\n\\n连接首先分交叉连接和外连接，两者结果的约束是很大的。交叉连接的结果数是两张表的积，而外连接则是以一张表为准。\\n\\n外连接细分了LEFT、RIGHT、FULL这3种连接，LEFT OUTER JOIN可以简写成LEFT JOIN。左右只是方向不同，只需要实现一种就可以。左连接后面的限定条件*可能不生效*，结果既包含符合满足限定的连接行，也包含不满足限定的左(或右)行，这些不满足限定的行会由NULL来填充。这正是NULL必须存在的理论依据。所以即使表定义的某列规定了NOT NULL，但在连接结果还是会出现NULL，无法避免。两张表的LEFT JOIN的意义不太明显，如果有多张表会更好理解。\\n\\n考虑学生选课场景，学生和课之间是多对多的关系，表s记录了学号和学生的详细信息，表c记录了课程信息，表sc记录了学号和课程号的关联，如果要还原出学生姓名和课程名字，用这句\\n\\n```\\nselect s.Name,C.Cname from student_course as sc left join student as s on s.Sno=sc.Sno left join course as c on c.Cno=sc.Cno\\n```\\n\\n在计算过程中，用sc表作为左连接的左表，先替换学生信息并保持住课程的信息(暂时还无意义)，等第二次左连接的时候，用课程信息替换掉上一次左连接的内容，最终的select结果中不保存sc的任何内容。\\n\\n## JOIN的实现算法\\n\\n有单机和分布式，但是单机是基础，如下3种\\n\\n1. Nest Loop Join: 最简单但性能也最低，拿左表的每一行，从右表循环匹配，复杂度O(MxN)。过程中可以利用右表的索引来加速。\\n2. Sort Merge Join: 将两张表分别进行排序，然后再扫描的时候，因为顺序已经固定，所以就不需要做全表扫描，因此连接的复杂度是O(M+N)。不过考虑到对两张表排序的成本, 不能过分乐观。\\n3. Hash Join: 将小表的joinkey和关联内容提取出来，对joinkey列做hash，得到中间表保在在内存，对大表做scan并按同样的hash去内存中找到匹配记录\\n\\n对于常见的等值连接来说，如果小表的内容足够小，都会采用Hash的方式。要注意的是，这个足够小，并不是仅指joinkey，而是要把关联的内容一起算上看总大小。\\n\\nNest Loop尽管复杂度高，但在不等值连接的时候一般都用这种方式，因为Sort Merge要求表必须做排序，而排序的成本不低，所以权横后还是会选择用的Nest Loop。\\n\\n分布式场景怎么又增加了shuffle和broadcast这两种策略，和单机版组合理论上一共有6种策略。但是spark放弃了broadcost和sort merge组合，比hash性能不足，能力上又不如NestLoop，因此最终就只有5种策略。\\n\\n## semi和anti\\n\\n这两种都是从子查询优化中演化出来的，也间接说明原生几种join的表达力不足。\\n\\nleft semi join表示半的语义，具体有这几条\\n\\n1. 只能select左表数据，这也是semi最核心的含义\\n2. 结果不会受右表关联重复数据的影响，从第一点可以看出，右表只是用于关联，不参与结果构建，也就不会导致重复\\n3. 必须搭配left/right其中一种，不能单独semi，否则无法确定取哪一半\\n\\nanti表示的反，等效与先left再取右边为null，但写起来方便。可以left anti join，也可以直接t1 anti join t2取t1有而t2没有的数据。\\n\\n这两种更像子查询优化而不是独立语义，所以没在标准中找到，但部分实现会支持。"}'));jctx.push(JSON.parse('{"id": "211226", "tag": "os", "text": "# SU的执行过程与用户登陆机制\\n\\n起因是在ssh中执行\\"su xx;whoami\\"被卡住无法返回，于是看了源码后解开疑问。\\n\\nsu切换用户的核心逻辑如下\\n\\n```\\nfork();\\nif (pid==0) {\\n  setuid();\\n  exec(command);\\n}else {\\n  wait();\\n}\\n```\\n\\n解读一下就是su会创建子进程，父进程会等待子进程结束才会返回，而子进程默认执行的命令是登陆shell然后开始等待用户输入，对于ssh远程执行命令的我们来说显然不是想要的，办法就是\\"su xx -c \'command\'\\"，利用-c选项指定子进程要执行的命令，执行完结束回到主进程，就不会阻塞远程执行了。\\n\\n在分析的过程中，又引申出一些新的点\\n\\n如果一个用户在passwd配置的是nologin，执行su会报错，原因同上，默认不带参数触发了调用shell，但用户又是nologin，于是报错。这种用户只是用于配合特定软件执行功能。\\n\\n计算密码用到的crypt函数在unistd.h和crypt.h都有声明，但是只include unistd.h编译会告警，执行更是会core dump。原来是unistd.h被条件宏保护起来，于是编译器找不到声明，默认返回int，这就和定义不符，进而导致执行时core dump。"}'));jctx.push(JSON.parse('{"id": "220115", "tag": "lang", "text": "# Python的数据科学相关库介绍\\n\\nPython在数据科学领域能取得如此成功，离不开支撑它的众多库，但很多人即使用了这些库很久也不清楚这些库的历史和渊源。\\n\\n最早也是最基础的，应该是NumPy了，其前身发起于1995年的Numeric库（当时Python才面世6年），创始人Guido van Rossum也在其中扩充了Python语法（尤其是数组索引方式）。在演进的过程中，出现和竞品Numarray，Numeric在小规模上速度较快，而Numarray适合大量的数据。显然这种情况并不是大家想看到的，于是Travis Oliphant对这两个库做了统一，并最终在2006年发布了NumPy的1.0版本并持续演化至今。\\n\\nNumPy主要的功能是向量和矩阵运算，然而学术界的需求显然不止于此，于是2001年，Travis Oliphant, Eric Jones, Pearu Peterson等人将一些基于Numeric库的科学计算的程序，以SciPy的名字作为一个整体发布。随后不久IPython和Matplotlib也陆续发布，整个数据分析的生态就此奠定。2014年从IPython分出来的Jupyter也同样是数据分析的利器。\\n\\n大概是觉得NumPy还不够快，Oliphant在2012年启动Numba项目做jit加速。顺便说一句，Oliphant还是Anaconda的联合创始人，Numba也是Anaconda的资助项目。\\n\\n如果说NumPy/SciPy这一支是源于学术界的科学计算，另一个同样有名的库Pandas则源起自Wes McKinney于2008年在AQR资本管理公司做量化分析的工作需求，因此不仅具有强大数据提取、分析功能，还有众多的外部数据接入功能。\\n\\n为了追求性能，这些库都用了C或Cython实现，NumPy这一支由于和科学计算更强相关，还依赖BLAS/LAPACK这样的线性代数专用库。通常编译的NumPy会使用openblas，而Anaconda会采用inte免费提供性能更好的libmkl库实现BLAS接口（但不开源）。\\n\\n机器学习是科学计算和量化分析之外，另一个数据科学的重镇，David Cournapeau在2007年启动的scikits.learn项目，从名字就能看出是SciPy Toolkit，这个系列最有名的两个包是scikit-learn和scikit-image。顺带说一句，scikit-learn在Python语言中，是以import sklearn方式导入，导入名和包名不完全一样。\\n\\n前面提到这些库的底层实现用了C或Cython，这个Cython和平时用的CPython一字之差，是一个有着类似Python语法，但又有所扩充的语言。Cython语言的理念源于2002年的Pyrex（一个更好地编写Python扩展模块的语言），在2007年的时候，SageMath库的开发者不满于Pyrex的一些限制，提交了补丁给Pyrex的作者Greg Ewing，但被Ewing拒绝。于是Sage的开发者们fork出了SageX和Sage一起发布，但不久后他们发现单独的SageX很受欢迎，于是就把SageX剥离出来，并合并了lxml库，重新命名为Cython发展至今，而Pyrex在2010年发布了0.9.9后不再有新版本。使用Cython语法写的代码，最终会被C语言编译器生成二进制代码，在优化了性能的同时，还提供了相较C扩展Python模块更简单的写法。"}'));jctx.push(JSON.parse('{"id": "220201", "tag": "tool", "text": "# 压缩技术浅谈\\n\\n凡涉及存储和传输，就一定会涉及压缩，不同领域的需求和特点也各不同\\n\\n## 文本\\n\\n目前我们日常使用的各种压缩软件，追根溯源都是LZ77算法的衍生。看名字就知道它是Lempel和Ziv在1977年发明的算法。它是基于字典编码理论的一种实现，细分静态词典和动态词典，静态编码指编码器事先准备好词典，如果文本中的词不在词典中，则不进行压缩；动态词典则基于对文本的统计，LZ77是动态词典的开创者，同时也是当今各种泛用形文本压缩算法的原型。\\n\\nLZ77算法有滑动窗口和前向缓冲（Lookahead Buffer）两个概念，先读入的会放入滑动窗口，并作为动态词典的样本，同时对后续的文本尝试匹配，匹配成功则进行替换，不成功则进入滑动窗口用于后续替换，如此迭代直到整个文本被处理完。后来的研究者基于LZ77的理念，在实现细节上做了很多优化，也形成了如今种类繁多的改进算法。\\n\\n基于LZ77的理念，就比较好理解为什么许多软件会有多个最快压缩和最大压缩的级别可选，核心就是通过控制滑动窗口的大小和匹配的阈值来调节计算过程。比如大数据领域的Snappy算法就是控制匹配长度的下限为4来提升压缩速度，另外它还设置了每个压缩块长度32k，块之间互相独立，因此只用2个字节就能表示块中的偏移，滑动窗口每次移动4字节而不是LZ77的1字节，种种优化措施下来，Snappy的压缩速度非常可观。另一种用于互联网的Brotli算法，加入预定义字典的方式（有点动静结合的意思），提升压缩率。\\n\\n## 声音和图像\\n\\n由于人类自身感官的限制，声音和图像在压缩过程中是允许丢失一定精度（其实在数字化采样的时候，原始精度就已经丢失了），就有了无损与有损的划分。加之采样又有整数采样和浮点采样，所以音视频的压缩算法比文本要丰富得多。\\n\\n以音频采样为例，无损领域有两个非常有名的编码格式APE和FLAC，后者就只使用整数采样，又因为音频播放器往往都会用DSP解码，只使用整形对DSP来说无疑极大降低了硬件的要求，这也是FLAC现在比APE更主流的一个小因素。\\n\\n## zip文件头\\n\\nzip作为压缩格式虽然不是压缩比最高，但由于其诞生年代早没有专利保护，受到了操作系统和各种开源社区的广泛支持。有次遇到被7z压缩的文件用zip解压，报错PK版本过低，原来是magichead后面会有两个字节表示所需要解压软件的最低版本。而PK正是zip的发明者Phil Katz的首字母。"}'));jctx.push(JSON.parse('{"id": "220204", "tag": "net", "text": "# 分布式哈希技术摘录\\n\\n简称DHT，是一种广泛应用在分布式存储和P2P网络的技术概念，具体实现方式有多种。最初的4种实现CAN（内容可定址网络）、Chord、Pastry、Tapestry都发表于2001年，从此以后该领域的研究就日渐深入。\\n\\nDHT由于离散性、伸缩性、容错性的特性，有个关键的技术点：任一个节点只需要与系统中的部分节点沟通，当成员改变时，只有一部分工作必须要完成（数据或键的发送、刷新哈希表）。\\n\\n技术构成上，基础抽象是键空间，键空间分区则将键空间分成数个区域，整个系统中的节点被分到键空间的某个分区。分布式系统必然有频繁的节点进入和离开，就需要一种算法来减少节点变化对系统的影响，业界比较成熟的有3种\\n\\n1. 一致性哈希 consistent hash\\n2. 最高随机权重哈希 rendezvous hash\\n3. 近邻匹配哈希 locality preserving hash"}'));jctx.push(JSON.parse('{"id": "220312", "tag": "data", "text": "# 分布式计算在Spark上的实现\\n\\n分布式计算是个很早的课题，在一个集群环境下，必然会利用多个节点共同计算，注意不是同时计算，因为数据会有倾斜，只是会尽可能多地把节点利用起来。当前技术在对待多个节点的身份并不对等，都会分为主从类型，各自叫法不同\\n\\n| - | hadoop | spark | flink |\\n| ---- | ---- | ---- | ---- |\\n| 主节点 | JobTracker | Driver | JobManager |\\n| 从节点 | TaskTracker | Executor | TaskManager |\\n\\n## MapReduce与shuffle\\n\\nHadoop普及了MapReduce概念，其实map和reduce是很大的概念，Spark在宣传上最大的特点是RDD，但计算模型仍然可以划分为map和reduce两个阶段。经常在Spark听到shuffle术语，其实Hadoop也有这个概念。它是数据在Map Task和Reduce Task之间流动时的一种重新分配，是否进行shuffle由数据的依赖关系决定。shuffle有以下3种\\n\\n* 流式shuffle：左端Task每当处理完成一条数据，就序列化到缓存，并立刻传送给右端的Task。\\n* 批式shuffle：左端Task每当处理完成一条，序列化到缓存（缓存不够需要压到磁盘），但并不立刻传送给右端的Task，而是等到所有数据处理完成之后才传送给右端的Task。Hadoop和Spark采用的模式与此类似，不过是右端主动来取，而不是左端主动发送。\\n* 兼容shuffle：左端Task每当处理完成一条，序列化到缓存，等到缓存满了之后再传送给右端的Task。\\n\\n理论上说，在兼容shuffle模式下，如果缓存仅容纳一条记录，那么就是流式shuffle；如果缓存无限大，那么就是批式shuffle。实际中，通过设置缓存块超时值：超时值为0，则为流式处理，超时值无限大，则为批式处理。Flink可以设置数据传输的模式。\\n\\n## 内存划分\\n\\nHadoop饱受诟病的是节点间的数据交换依赖HDFS，节点把数据落盘导致速度缓慢，Spark和Flink都以不同的方式来解决该问题\\n\\n| - | 负责执行的内存块 | 负责缓存的内存块 | 其它内存块 |\\n| --- | --- | --- | --- |\\n| Spark | Execution Memory | Storage Memory | other |\\n| Flink | Memory Manager | Network Buffer Pool | Remaining Heap |\\n\\n其中负责缓存的内存块就是上一个节点计算完成并等待下一个节点来取数的的暂存区域，SparK由下游Task来取数据，而Flink是上游主动向下游发送数据，如果下游没有空间上游就不推送同时也会停止消费。因此Flink天然没有反压的问题。\\n\\n## 计算的序列化\\n\\n分布式计算的关键是调配代码和数据，由于数据量远大于代码，因此核心是**代码分发到各个数据节点**。由于计算的灵活性加上节点处理器的不确定性，要求代码是平台无关且可灵活序列化，在MR时代采用分发Jar来实现计算的分布，而Spark则利用Scala语言更进一步实现函数的分发。Spark为了扩大使用面，和Python做了深度整合，因此也必然要求Python代码能以函数为粒度实现编译和分发。Python原生的序列化库Pickle会把函数和类以引用的方式序列化，这在分布式环境下显然是不够的，于是最早由PiCloud公司（13年合并到了DropBox）扩展实现了CloudPickle库，它能将函数和类序列化成值，解决了分布式环境下的分发问题，当时的CloudPickle只能序列化Py2，Spark继续扩展使它能支持Py3和PyPy。\\n\\n理论上CloudPickle可以序列化任意Python对象，但Spark的计算框架要求Driver和Executor各司其职，因此不允许Python对SparkContext序列化（自然也就不允许对SparkSession序列化），具体的方式是在`__getnewargs__`方法抛异常来提示用户。这也解开了我最初对collect函数返回结果给Driver的疑问，既然collect不能在Executor调用，那么collect的发起者只能是Driver，结果当然也返回Driver。\\n\\nSpark和Python的交互在进程级别是socket通信加Arrow的内存列式存储，而语言层面则是udf装饰器，udf有几个重要的参数：函数本体、返回类型、执行类型和是否确定性。前两个很直观，解释下后两个参数。\\n\\nPySpark的执行类型有`BATCHED_SQL`、`SCALAR_PANDAS`、`GROUP_MAP`、`GROUP_AGG`、`WINDOW_MAP`多种。BATCHED是最简单的Row-at-a-time，而后面几种则是对Column或DataFrame进行处理与合并，效率会高一些。而确定性则是一个比较冷门的概念，输入输出确定的函数称为确定性，而即使输入确定输出也不确定的则称为不确定性，典型的如日期函数或统计总量。之所以要特意强调这点，是因为执行器会对确定的udf做一些优化合并，如果写的udf是非确定性但引擎不知道，可能会引起结果不正确。这个是理论上的解读，我没有实际遇到过，没有很深的理解。"}'));jctx.push(JSON.parse('{"id": "220405", "tag": "os", "text": "# Kubernetes笔记\\n\\nk8s不仅是软件，它还是虚拟化软件的组织体系，它定义了运行时、网络、存储的接口，自身实现则专注于容器的调度。\\n\\n## 体系标准\\n\\n* CRI: 包含运行时和镜像两个子集，由于k8s晚于docker，所以CRI规范和docker推出的OCI是兼容的\\n* CNI: 比较有名的有flanel和calico，据说flanel最简单，calico更灵活，我只见过calico，还要继续研究\\n* CSI: 不确定k8s自身的PV/PVC/StorageClass是否属于这个体系，只知道topolvm是一种实现\\n\\n## 基本概念\\n\\nPod是k8s的最小单元，将多个容器封装在一个整体，在Pod中Linux的各种namespace以及存储卷是共享的。Pod是豆荚的意思，每个容器则是一个豆子，多个豆子共同包裏在豆荚内，形象生动。\\n\\nk8s有JSON和YAML两种描述格式，JSON用于API，暂时还不了解。YAML则是配管。做helm应用模板是个高层封装，由于包含了很多内容不易理解，但最基础的内容并不复杂。YAML文件包含4个部分\\n\\n* apiVersion: 不考虑复杂特性填v1，但其实有不少于8个可选项\\n* kind: 类型非常丰富，而且当apiVersion变化后，取值范围也不一样\\n* metadata: 是个复合值，不可缺少的是name属性\\n* spec: 也是个复合值，属性最多的段。helm模板做的各种封装也针对spec\\n\\n## kind\\n\\n* Pod: 似乎生产环境不会用，必须太基础，但从学习的角度，这是k8s的第一步\\n* Service: 将一个或多个Pod封装，提供稳定的服务。包括Pod间负载均衡，服务级虚拟地址（但只限本机访问）\\n* ReplicaSet/Depolyment: Pod难免会挂掉，这种模式就保证了始终能运行指定数量的Pod\\n* StatefulSet: 相比Depolyment增加了持久化数据的能力。和Deployment是主要应用于生产环境的类型\\n* ReplicationController\\n* PersistentVolume/PersistentVolumeClaim: \\n\\nkubectl作用在整个集群上，找到某个pod在哪台物理机，就可以在那台机上用docker进入。"}'));jctx.push(JSON.parse('{"id": "220421", "tag": "data", "text": "# Flink引擎学习\\n\\n## 数据集\\n\\nFlink和Spark都采用了数据集（算子）+SQL方式提供编程接口，SQL上手简单但能力受限，而数据模型则相对难学但也更强大。\\n\\n|  |  基础会话（构建数据集） | 表会话（可执行SQL） | 数据集类型 |\\n| --- | --- | --- | --- |\\n| Spark | SparkContext | SparkSession | RDD |\\n| Flink | StreamExecutionEnvironment | StreamTableEnvironment | DataStream |\\n\\n既然是数据集，肯定就有数据来源，可以从文件或表映射，也可以从无限流的连接映射出来，一旦映射后就只能基于这个原始的映射源计算。\\n\\n而SQL语句都不依赖数据集，属于会话级的接口，因为SQL是在一段文本中操作多个数据源，所以显然不会被绑定到某个特定的数据集。\\n\\nStreamTableEnvironment能提供Table和DataStream之间的互转。同样的，基本废弃不用的BatchTableEnvironment则提供了DataSet和Table的互转能力，只是随着DataSet的逐渐消亡，可以不用管这种运行环境。\\n\\n从Flink 1.9开始有两种planner：old 和 blink。blink实现了流批一体，因此将批处理视为流式处理的特殊情况。所以blink不支持表和DataSet之间的转换，批处理作业将不转换为DataSet应用程序，而是跟流处理一样，转换为DataStream程序来处理。因为流批统一，Blink planner也不支持BatchTableSource，而使用有界的StreamTableSource代替。\\n\\nTable 总是与特定的 TableEnvironment 绑定。不能在同一条查询中使用不同 TableEnvironment 中的表，例如对它们进行 join 或 union 操作。\\n\\nTable API中表到DataStream有两种模式：\\n\\n* 追加模式（Append Mode）：用于表只会被插入（Insert）操作更改的场景。\\n* 撤回模式（Retract Mode）:用于任何场景。有些类似于更新模式中Retract模式，它只有Insert和Delete两类操作。得到的数据会增加一个Boolean类型的标识位（返回的第一个字段），用它来表示到底是新增的数据（Insert），还是被删除的数据（老数据，Delete）。\\n\\n## 运行时与调度\\n\\n采用经典的Master-Work模型，Master会创建App进程，包含了三个组件，Dispatcher、ResourceManager和JobManager。Dispatch接收客户端请求，并创建出Job。Job根据任务生成Graph并向Resource申请资源。Resource有多种实现，可以是Local，也可以借由Yarn或K8S管理资源。\\n\\n每个Work（TaskManager）是一个JVM进程，进程中的task将共享TCP连接和心跳消息。启动的TaskExecutor跑在空闲的TaskSlot（线程）上，一个拥有3个slot的Task，会将内存平均分成三份给每个slot，slot数量通常和CPU数相同。Executor和Slot都通过Resource来分配。\\n\\n由于流批一体，Flink的调度策略也适用于不同类型的计算，有三种实现：\\n\\n* Eager：适用于流计算，同时调度所有的task，对数据不终结的流而言，这种方式很自然\\n* LazyFromSources：适用于批处理，当上游数据处理完，调度下游数据。如果不lazy的话，计算效率会差\\n* PipelinedRegion：以流水线的局部为粒度进行调度\\n\\n### 数据传输\\n\\nRegion要解决什么问题？这就要回到适合流批作业的不同数据传输机制（shuffle）\\n\\n* Pipeline： 上下游Task之间直接通过Netty进行网络传输，因此需要上下游同时运行，适合流。又细分了是否有Bounded模式，区别在于是否限制网络缓冲的数量\\n* Blocking： 上游Task会首先将数据进行缓存，下游Task去取数时上游作业甚至可以停掉，互相不依赖对方的存活，适合批\\n\\n基于这两种类型的传输，Flink将ExecutionGraph中使用Pipeline方式的Task子图叫做Region，从而将整个Graph划分为多个子图。\\n\\nPipeline方式也存在缓存，但又要考虑实时性，于是就有了基于信用的流量控制机制（Credit-Based），来降低延迟，工作原理：\\n\\n1. 发送端将自己缓冲区积压的数据大小加入到发送的数据当中，一并发给接收端\\n2. 接收端接收到发送端发过来数据之后，根据其缓冲区积压的数据大小，生成一个信用值，并将信用值返回给发送端\\n3. 发送端会根据信用值所限定的范围，尽可能的多传输缓冲区数据\\n\\n如此，每个发送端都被授予一个信用值，如果某发送端数据积压过多，那么它所被授予的信用值，就能够使之尽量多发送数据，从而减少积压量，这种机制会在出现数据倾斜时很好的分配网络资源。\\n\\n除了基于信用的机制外，任务链机制更能直接减少数据传输的开销，如果上下游两个Task的并行度相同并且满足其它条件，会将这两个Task合并，直接在内存中复用数据。\\n"}'));jctx.push(JSON.parse('{"id": "220721", "tag": "data", "text": "# spark性能调优记录\\n\\n## 资源配置\\n\\n和运行速度相关度最大的是instance数量，我做的业务因为数据量在千万以内，内存只有6G，实例数只会分配个位数。实测发现2个比1个提升明显（至少50%以上），3个比2个有提升但幅度开始减少（30%左右），再往上提升就更少了。而内存在保证不OOM的情况下，多给也只会减少JVM的GC时间，对性能没什么提升。\\n\\n## udf和udtf\\n\\n同行逻辑最初的版本是用udf做，尽管经过数次优化，但始终有内存占用过大问题，计算过程是先对点位分组，然后把每组的数据`collect_list`后交给udf来计算，pyspark的udf每次传递100条数据，到了这个逻辑传递的其实是100个分组，内存肯定很高。但细想会发现这其实这是个标准的udtf过程，于是想到换用udtf每次传递1个分组，内存肯定可以降下来。开始还担心由于传递次数变多，而且udtf得到的是pandas dataframe，需要转换成原生的list，会有性能下降，实测不仅内存确实减少，而且性能提升2倍左右。\\n\\n这就涉及一个apache的跨项目的arrow库，所传随着大数据组件越来越多，组件间的数据传递成为一个大的开销，社区当然有人意识到这个问题，于是组织起来开发了arrow这个高效的序列化库，经过arrow序列化后的库，不需要反序列化，收到后放到内存就能直接用，udtf利用了arrow库，而udf并没有，说真的arrow对性能有这么大的提升，真的是没有想到。\\n\\n换成udtf后在k8s会遇到程序终止问题，查看了instance内存，虚拟内存竟然用了9G。经人指点发现是numpy的内存占用受`OMP_NUM_THREADS`影响，默认和CPU核数一样，服务器40核所以内存占用极大。但是我开始验的时候，导入numpy只会多出200M左右的虚拟内存，过了一天意识到验证用的是anaconda，而pyspark是开源的python，开源版numpy依赖的openblas会依赖OpenMP，从环境变量名也可以看出就是OpenMP的行为，而anaconda的并行库是intel的MKL，不会根据CPU核创建这么多线程。\\n\\nPySpark内存的使用分3部分\\n\\n* jvm: 主要计算在这里完成\\n* overhead: 发生shuffle时，netty要用这块内存缓存网络数据\\n* python: 使用udf或rdd会占用\\n\\n## 查看UI\\n\\n正在运行中的代码，第一个job页会显示active job，下面还会有很多complete job。每个job会被分拆成一到多个task，task又会分到不同的instance执行，所以job执行完就表示代码中的一段逻辑完全运行完成，不用担心是否只是部分instance运行完。看tasks往往会看到很多标记了skipped，这里有很多原因：一方面可能是数据被缓存，所以跳过，另一方面也可能是数据倾斜，让引擎以为需要这么多task，但实际执行后发现没有数据，于是就跳过了。job和代码的映射关系还不清楚，但只要代码不改，job的数量就不会变化。"}'));jctx.push(JSON.parse('{"id": "221019", "tag": "lang", "text": "# promise和future的区别\\n\\npromise/future是指差不多的东西，只是不同语言的叫法不同。少数语言可能同时有promise/future并有差异，如果同时有两者，一般future指获取值的能力（只读视图），可翻译为「期值」（future作为金融术语即为「期货」），promise指设置值的能力，可翻译为「约定」。这些术语与cancel没有关系。（这个误解可能来自于早期的DOM Future草案有cancel而后来改名为Promise时同时删去了cancel？）\\n\\n为什么promise不支持cancel？从用例需求的角度，当然是有cancel和progress的需求的，所以原本DOM future的草案里也有这些能力，但JS标准化要考虑的问题比较多。绝大多数时候只会推进大家有一致意见的东西。像cancel的能力后来DOM是改用了AbortSignal机制，估计将来JS也是会标准化的（虽然已经延宕了很久，目前也还不知道到底什么时候会推进）。而progress的能力则由DOM ProgressEvent来完成了。\\n\\n早期JS社区的某些promise库则使用promise/deferred来表示future/promise。JS后来流行并标准化的promise的设计是两种能力的合体，promise本身的接口（then）提供获取值的能力，而promise构造器工厂中的resolve/reject函数提供设置值的能力，不再有单独的deferred接口。\\n\\n对于合体型的promise/future概念，我提出了「期约」作为译名（一个原因是「期约」作为「期/约」的合体可对应future/promise的合体，这样就不必在不同语言中因为采用future还是promise作为术语的不同而译名也不同），为《 JavaScript高级程序设计（第4版）》中译本所采用。\\n\\n在 Promise 提出之前，除了规范里存在事件循环，普通前端是基本不讨论事件循环这个概念的，那就更不用说 microtask 了。\\n\\n的确是 Promise 让这两个知识点成为焦点，为了解释那些代码执行顺序问题。但 microtask 是要比 Promise 的提出更早一些，最早它是为了定义 MutationObserver 的行为而产生的，只存在于 HTML 和 DOM 规范里。\\n\\n在 ES6 里想要给 JS 加上异步的时候，最早也不是为了 Promise，而是 Object.observe()， V8 为实现 Object.observe 加上了类似 microtask queue 的机制，当时 ES6 没有打算加 Promise，而是 DOM 规范想要加一个类似功能的名为 Future 的东西，后来决定直接加在 JS 里，为了 nodejs 里也能用，改名 Promise，DOM 里就不搞了。"}'));jctx.push(JSON.parse('{"id": "221119", "tag": "lang", "text": "# continuation的理解\\n\\nScheme 和SmallTalk并不采用堆栈来保存上下文，而是将这些信息保存在continuation记录中。这些continuation记录和堆栈的Frame的区别在于，它不采用后入先出的线性方式，所有continuation记录被组成一棵树（或者图），从一个函数调用另一个函数就等于给当前节点生成一个子节点，然后把系统寄存器移动到这个子节点。一个函数的退出等于从当前节点退回到父节点。这些节点的空间回收是由垃圾回收器(garbage collection)来管理。如果没有引用这个continuation记录，则它就是可以被删除的。这样的调用方式和堆栈方式相比，它可以在一个函数内的任何位置储存自己的上下文信息，然后，在以后某个适当的时刻，从其它的任何一个函数里面返回到自己现在的位置。\\n\\n由于每次延续被恢复的位置不同，可以理解为函数拥有了多个不同的入口点，从这个角度可以和协程一起理解。 [[协程剖析]]\\n\\nPython的yield教程都说是生成器，思考其实质，函数的上下文被保护，从而可以被多次调用，精神层面和continuation是一脉相承，而且加入了send和throw函数，也更方便易用。\\n\\nlua表面上只有协程，但其实和continuation是相通的。[[Lua的Continuation]]"}'));jctx.push(JSON.parse('{"id": "221122", "tag": "tool", "text": "# 打包软件的故事\\n\\n起因是想解压rpm和deb包，发现并不是zip压缩，rpm需要rpm2cpio工具转成cpio做进一步处理，而deb要用ar x命令解压得到内容。cpio和ar都不是最常见的打包软件，于是诱发我去了解背后的原委。\\n\\n最为人熟知的打包软件应该是tar了，有史可查最早在1978年随着system 7发布，后来也搭载在III和V以及BSD一起发布。tar会递归地遍历目录然后打包，这个递归动作不能取消，由于命令行操作的便利性，tar成了最流行的打包工具。tar有很多变体，支持的格式不尽相同，后来出了POSIX规范，至少我没有遇到需要特定版本的tar才能解析的问题。\\n\\ncpio是copy in copy out的简称，不支持递归查找源始文件，所以不适合命令行，通常提供文件清单或配合find一起用。常见的似乎只有rpm和initrd会用cpio方式。\\n\\n如果说tar和cpio还算打包软件，ar则更多的归属到编译体系。ar最常见的用法，是把多个.o文件合并成.a，并用ranlib给.a添加符号索引，进而加快链接速度。具备把多文件合并的功能，更偏向cpio的定位。把deb文件解开后，得到数个tar文件，不明白为什么会选择这种方式。"}'));jctx.push(JSON.parse('{"id": "221123", "tag": "os", "text": "# 修复操作系统问题记录\\n\\n## 忘记root密码\\n\\n只适用于centos，在选择内核列表时，按e进入编辑模式，在linux16命令的参数中加入init=/bin/sh进入单用户模式，执行mount remount后，用passwd可以重置，最后用exec /sbin/init重启。"}'));jctx.push(JSON.parse('{"id": "221201", "tag": "security", "text": "# 公私钥格式的认识\\n\\n公私钥对做为一个概念，最后一定会有形式用来记录与传输，以RSA为例展开讲讲。\\n\\nRSA公钥由n和e两个数字构成，e通常是65537，重要的是n，这是一个非常大的质数。一些函数库会用类甚至数组来表示RSA公钥。但这只是内存中的表示，并不适合序列化，又分ssh和ssl两个流派，而ssh的两个版本又不同。\\n\\n## SSH-1\\n\\nSSH 1协议只支持 RSA 算法，所以公钥也为RSA特化，格式为所有字段以单个空格符分隔，各字段依次为选项、位数、指数、系数、注释。第一个字段是可选的，表示该条目（行）是否以数字开头，选项字段不会以数字开头。最后一个字段注释，如果在生成密钥时没有给定注释，默认注释为密钥的创建者，注释仅仅是提供给用户查看密钥时作为一个辨识标记，在 SSH 使用中没有任何作用。\\n\\n```\\n2048 65537 1234 username@hostname\\n```\\n\\n## SSH-2\\n\\n非对称加密肯定不能局限于RSA，所以公钥格式也做了改变。所有字段仍以单个空格符分隔，各字段依次为选项、密钥类型（keytype）、base64编码后的密钥、注释。第一个字段是可选的，表示该条目（行）是否以数字开头，选项字段不会以数字开头。最后一个字段注释同样只起提示作用。\\n\\n密钥类型（keytype）可能是 ecdsa-sha2-nistp256, ecdsa-sha2-nistp384, ecdsa-sha2-nistp521, ssh-ed25519, ssh-dss 或 ssh-rsa。\\n\\n```\\nssh-rsa AAAAB3 username@hostname\\n```\\n\\n除这种格式外，ssh还支持IETF SECSH 公钥格式，像这样\\n\\n```\\n---- BEGIN SSH2 PUBLIC KEY ----\\nAAAAB3 username@hostname\\n---- END SSH2 PUBLIC KEY ----\\n```\\n\\n## SSL\\n\\nssl工具的默认编码方式默认就是这种带BEGIN和END页眉页脚的块，块的内容称为PEM格式Privacy Enhanced Mail，是一种特殊的base64。从两端可以很清楚的看出内容的类型。RSA公钥类型是RSA PUBLIC KEY。没有任何前缀的PUBLIC KEY则代表X509公钥。\\n\\n## PKCS#8\\n\\n私钥可以用PKCS8方式存储。私钥首先会使用PKCS#5的标准进行加密，然后将其进行base64编码，转换成为PEM格式进行存储。\\n\\n## Java语境下的keystore与truststore\\n\\nSSL/TLS通信时，会用到密钥库（keystore）和信任库（truststore）。\\n\\n* KeyStore-密钥库\\n\\nKeyStore存储私钥和相关的证书，或者相关的证书链（由客户证书和一个或多个证书颁发机构CA证书组成）。它通常用于表明通信一方的身份。\\n\\n* TrustStore-信任库\\n\\nTrustStore则相反，密钥库通常用于保存标识自身身份的证书，而信任库用于保存识别他人(第三方)身份的证书，用于校验与我们通信的第三方是否可信。\\n\\nJava的密钥库机制有5种格式：JKS(java key store)、PKCS12(前身是微软的.pfx，也有.p12)、JCEKS、BKS、UBER。前两种比较常见，JDK8之前，默认格式为私有的JKS；从JDK9开始，默认格式为开放的PKCS12。\\n\\njks是java用的存储密钥的容器。可以同时容纳n个公钥或私钥，后缀一般是.jks或者.keystore或.truststore等，各个公司或机构叫法不同而已。不管什么后缀，它还是一个容器，比如把只包含\\"受信任的公钥\\"的容器存成.truststore文件等。\\n\\n用jdk/bin目录下的keytool对其进行查看，导入，导出，删除，修改密码等各种操作。也可以对jks文件加密码，输入正确才可以操作此容器中密钥。\\n\\n## 文件体现\\n\\n配置Web Server时往往也要有Private Key File和Certificate File，可以分开也可以用cat或openssl合并为1个pem或pfx文件。客户端通常不配置，因为加密由服务端的Private Key决定，但有些客户端会不信任服务端提供的Certificate，此时必须在客户端也配置相同的文件。\\n\\n遇到过一个问题，想通过hive外部表的方式向ES写数据，但开源的jar包连接开启https的ES总是报错，原因是不信任服务端证书。在python中通过关闭SSL认证规避了该问题，但jar包并没有提供关闭SSL认证功能。最终只能下载服务端的证书，并配置truststore路径才通过。\\n\\n## 题外话\\n\\n虽然ssh的公钥格式自成一派，但它的私钥却遵循了PEM格式，标识符OPENSSH PRIVATE KEY。也意味着openssl工具可以操作ssh私钥。\\n\\nPKCS是Public-Key Cryptography Standards的意思，它是RSA公司提出的公司私有规范，共15条。但由于RSA公司的行业影响力大，部分规范也被RFC和openssl软件支持。除了#8外，#7和#12是影响很大的标准，PKCS12可以看做是PKCS7的扩展，在PKCS12中可以存储证书，私钥或者CRL。和PKCS7相比，PKCS12可以额外存储私钥。"}'));jctx.push(JSON.parse('{"id": "221218", "tag": "net", "text": "# 对netcat的探索\\n\\n有些很弱的主机无法安装sshd，又需要远程操作时，完全可以用nc。\\n\\n大多数教程讲nc用GNU版本，用-e选项就能反弹shell，但为了学习原理，不妨用更原始的下面这种方式。\\n\\n`cat tmpf | bash 2>&1 | /system/bin/toybox nc -l -p 6666 > tmpf`\\n\\n即使是toybox自带的nc，都能正常工作。来解释下原理。\\n\\nnc是把cat的功能应用在socket上，而cat的原意除了打印，首先是用来concatenate files。平时我们操作的是文件，但在nc的场景，更重要的是concatenate socket and stdin/out。所以我们倒着看上面的命令，nc监听端口后，将来自这个端口的输入输出消息，和终端的stdin/out绑定；绑定后再重定向到fifo文件。\\n\\n其实真正要绑定的是nc监听的端口和shell，但管道符只能单向流，所以最开始引入fifo文件，利用cat把fifo的输出端绑给shell，最后的时候把fifo的输入端绑给nc，借fifo把nc和shell间的双向循环变成形式上的三角循环，虽然不够优雅，却非常巧妙。"}'));jctx.push(JSON.parse('{"id": "230208", "tag": "web", "text": "# 两个小微JS库的使用\\n\\n因为网站重构，本来不想使用JS用了htmx库，奈何实在拉胯，只得重新用JS，但不想用太复杂的库遂选了两个，一个MVVM一个类jQuery库，记录一些JS的惯用法。\\n\\n## psQuery\\n\\n说说$变量的构造，在库的开始定义一个单变量的函数，在函数定义完成后惯例性的调用，此时传入this参数（对应window）。然后在代码中用了句`n.$||(n.$=t)`。这个n就是this，t则是构建好的类jQuery对象，先判断全局是否已经定义$变量，没有就把自己挂接上去。\\n\\n最终还是借助GPT的帮助，用XMLHttpRequest实现自己的功能。无非就是构建XHR对象，并用open/set方法设置是否异步和参数，最后通过send真正触发动作。\\n\\n## DB.js\\n\\nMVVM库，希望监听的DOM元素增加类似`db=\\"text:spanText,class:red\\"`属性。当你手动执行DB.scanHTML后，会扫描document所有节点，如果有db属性就会用DB.observable转化成可监听对象，然后把db属性去掉。接下来操作js对象就能自动触发DOM元素的变化。只要保证js的对象名，和db属性某个冒号后的名字一样，就能绑定。\\n\\n单纯的绑定没大价值，有意义的是compute属性，实现了一个元素依赖其它元素的自动更新。依然借鉴思路，实现了一个简化DOM元素访问函数。\\n"}'));jctx.push(JSON.parse('{"id": "230601", "tag": "net", "text": "# CDN的来源与应用\\n\\n万维网自1990年推出以来，已从简单的客户端服务器模型演变为复杂的分布式体系结构，在演化过程中，CDN是其中很重要的基础设施。最早的CDN公司Akamai诞生于1998年，虽然经历了二十多年的发展，但是至今没有形成完整的范，各家的具体实现也不一样。CDN的核心点有两个，一个是缓存，一个是回源。\\n\\n* 缓存：就是把资源复制一份到CDN服务器上的过程，缓存的管理需要协议，主要有ICP、HTCP、CARP。\\n* 回源：当CDN发现自己没有这个资源（一般是缓存的数据过期了），转头向根服务器（或者它的上层服务器）去要这个资源的过程。\\n\\n## CDN协议\\n\\nICP(internet cache protocol)：最初的缓存控制协议，参考RFC2186。基于UDP协议实现的轻量级的缓存内部通信协议，被用于在Cache服务器之间相互查询web资源信息，以确定当前被请求的资源是否在其他服务器上。一个缓存服务器发送ICP请求给它的邻居，邻居会用ICP消息响应，如果有的话就是HIT无就是MISS。\\n\\nHTCP(hypertext caching protocol)：RFC2756，管理一组http cache服务器并监控相关的缓存活动。该协议机制与ICP类似，都是通过向邻居服务器发送查询请求并获得应答来反映web对象在集群中的缓存情况。但设计ICP协议时考虑的是HTTP/0.9协议，查询资源是否存在时只允许缓存发送URL。HTTP版本1.0和1.1引入了很多新的请求首部，这些首部可以和URL一起用来确定文件是否匹配。只在请求中发送URL可能无法得到精确的响应，而HTCP允许兄弟缓存之间通过URL和所有的请求及响应首部来相互查询文档是否存在，以降低错误命中的可能。另外HTCP还允许兄弟缓存监视或请求在对方的缓存中添加或删除所选中的文档，并修改对方已缓存文档的缓存策略。\\n\\nCARP(cache array routinig protocol)：CARP是ICP的一个替代品，通过建立HASH函数用于划分cache服务器集群的URL空间，通过HASH算法将用户对URL的请求准确路由到服务器阵列中的任一成员上，消除了阵列中重复缓存数据，实现了对cache资源的高效定位。CARP和ICP都允许管理者通过使用多个代理服务器来提高性能。优势：\\n\\n1. 无需资源查询和应答的过程，降低网络传输开销\\n2. 消除了重复缓存数据，每份url保存一份，节约空间\\n3. 具有更好的扩展性，可以灵活的增删服务器节点\\n\\n额外说一句，CARP也是共享地址冗余协议的缩写（Common Address Redundancy Protocol），是一种能让多台网上主机共享同一个IP地址的协议。它的设计目标在于为故障移转（failover）提供冗余的主机作为备援。\\n"}'));jctx.push(JSON.parse('{"id": "230625", "tag": "tool", "text": "# Markdown的渊源与流派\\n\\n## 历史与标准\\n\\nJohn Gruber和Aaron Swartz（测试）于2004年发明了Makrdown编辑格式，它最初是定位给web写作者，因此首要的功能就是markdown到html转换。由于简洁的设计，在网络上受到极大的追捧，因为面向html的设计初衷，它的元素也分为块级元素和行内元素。开始的功能并不完整，其实这也不是什么问题，但是Gruber认为没有一种规范能满足所有人的需求，也不愿意扩展Markdown语法，在发布同年的12月，版本更新到1.0.1就不再迭代。后来社区想成立一个standard markdown的论坛也被他拒绝了。最终导致了Markdown演变到今天，虽然已是互联网最流行的书写格式，但五花八门的扩展也始终是一个无法消除的问题。\\n\\nGruber定义了一套非形式化的语法，并且提供了markdown.pl脚本来验证格式的正确性，但毕竟不是严谨的定义。从2012年开始Jeff Atwood就提议要标准化地描述Markdown格式，最终在2014年，由UC Berkley的哲学教授John MacFarlane作为主要编写者，共同确定CommonMark成了至今最完整和详实的规范定义，虽然没有达到1.0，但已经被众多网站接受。CommonMark和其它流派不同，并不强调功能的扩展，而在明确定义诸如优先级、缩进、嵌套等容易引起歧义的地方。\\n\\n## 各种流派\\n\\n虽然有众多的扩展变体，RFC7764还是记录了几个比较流行的方言\\n\\n### GitHub Flavored Markdown\\n\\nGitHub在2017年发布了基于CommonMark，有形式化描述的扩展标准。这个也许是接受度最广，甚至个人觉得有可能成为事实标准的增强版。\\n\\n### PHP Markdown Extra\\n\\n虽然名字带了PHP，但也有Ruby(Maruku)和Python Markdown实现。区块代码和表格的扩展语法和GFM一样，接受度也比较高。\\n\\n### Pandoc\\n\\n与其说是一种markdown流派，更确切的定义是格式转换界的顶峰，作者就是上文提到的CommonMark的发起者MacFarlane。它使用的语法和GFM不太一样，其扩展语法格式的流行程度远不如这个软件本身。\\n\\n### Kramdown\\n\\n据作者自称是最快的纯Ruby实现，支持输出LaTeX，同时还支持XML2RFC格式，我猜是不是因为这个特性所以被RFC收录了。\\n\\n## 语法体会\\n\\n开始使用tiddly，需要把md的语法平转成WikiText，为此还写了个小工具。好在除了标题和有序列表外，我自己常用的都可以做到一样，但还是对以往写的内容做了些调整\\n\\n1. 标题用#语法，不要用==或--，因为后者在标题行的后一行，转换时会稍麻烦\\n1. 行内引用和块引用的区别是，块引用在code标签外面还包了一层pre标签，由此改样式必须要配置pre code父子语法 [[CSS的一些理解]]\\n1. 少用md的`*word*`语法，浏览器默认的斜体样式渲染中文不好，且容易误匹配\\n1. 用了md至少5年以上，才知道引用语法是>"}'));jctx.push(JSON.parse('{"id": "231101", "tag": "web", "text": "# 不合时宜的CSS\\n\\n在Web领域HTML/CSS/JavaScript三者各司其职似乎被广泛认可，三剑客各自独立产生，最终又一起提供页面能力，人们自然要给这样一种组合方式一个说辞，于是便产生了现在广为接受的分层说法。理念很美好但它们其实都有互相重叠的地方，而且三者间的互操作性其实并不好。但为什么传统的GUI编程却没有一个采用这种方式呢？\\n\\n看Java Swing、Andorid、Flutter等方案，或者是纯代码，或者是轻度引入某种布局DSL，至少GUI领域不认为布局、样式、逻辑要严格分离，更多的是统一在一起，由一个体系进行描述。或许回答这个问题还是从历史中找答案。\\n\\nHTML的首个版本出现于1991年，彼时它被发明的初衷还是文档显示和链接，不需用户交互能力，渲染结果完全交给终端软件。1993年6月，Robert Raisch在www-talk的邮件列表给了一个提案，用一种名为RRP的方式来指定元素样式。但是Mosaic浏览器并没有接受该提案。之后围绕着样式语言的定义经过了很多讨论，甚至出现过一个叫DSSSL的类scheme语法的图灵完备方案，最终经多方博弈后，终于在1996年11月发布了CSS规范的第一版，然后由于实现的复杂性，直到2000年3月才有浏览器完整支持它。而JS则是1995年12月首次推向市场。虽然看起来JS比CSS要早，但JS只是NetScape/Brendan Eich的单一行为，而CSS的讨论时间和牵涉方要充分得多。\\n\\n随着Web应用愈发普遍，Web早已不再只是文档展现，而是事实上的应用化了，而且应用的规模还明显变得越来越复杂。从这个角度重新审视，再将三者按功能分层就显得有些不合时宜，这也是20年代以来前端组件化被普遍认可，CSS也更为的作为组件的一个切面而不是单独的一层。\\n\\nCSS的值通过HTML的class属性起作用，但class在设计之初其实承载了更通用的功能，并不是为仅用于CSS。随着HTML5定义了更多的语义化标签，一定程度上削弱了class的设计目的，而组件化时代class的表意作用进一步削弱，才演变成今天这种只用于附加CSS的功能。\\n"}'));jctx.push(JSON.parse('{"id": "231110", "tag": "web", "text": "# DOM理解\\n\\nJS作为一门编程语言，想要操作文本形式的HTML，必然要把HTML结构化，DOM就是将HTML的文本进行标准化的产物。由于HTML天然的树状层级特性，转化为DOM是很自然的，但这不代表两者等价，这里就展开谈谈一些概念和细节。\\n\\n## 节点Node和元素Element的异同\\n\\n一句话概括：结点不一定是元素，而1个元素一定是1个结点。\\n\\n节点有nodeType属性，最常见的有：1元素、2属性、3文本，还有别的类型，比如代表整个HTML的document节点，类型是9。还有注释(8)、!DOCTYPE(10)等类型。\\n\\n元素是编程时打交道最多的，入门课程就会学的getElementById方法，从名字就告诉我们获取的是DOM元素，基于某个元素，通过childNodes获取到元素下的子节点。一个简单的P元素只有1个类型为Text的child节点。\\n\\nDOM建立在JS语言上，因此有类型（而HTML由于是文本，可以认为只有string一种类型）。结合前面提到的概念，类型体系是这样\\n\\n```\\nObject -> EventTarget -> Node -> Element -> HTMLElement -> HTMLInputElement\\n```\\n\\n## HTML attribute和DOM property\\n\\n两者大多数时候可以不区分地使用，列举一些主要的差异\\n\\n1. 写HTML时，可以给元素设置非标的attribute，比如`<p foo=\\"bar\\">`是合法的；但是这些非标attribute在映射为DOM时，如果用.foo访问会得到undefined，但可以用.getAttribute(\\"foo\\")得到值。自定义attribute按照HTML5规范，建议命名成`data-*`，也有些项目会命名成`x-*`。\\n1. HTML以宽松著称，因此大小写不敏感，但DOM既然基于JS，肯定要区分大小写，在上面的例子中，由于foo是在HTML中定义的，所以大小写不敏感，用.getAttribute(\\"FOO\\")也能得到值。\\n1. attribute和property会自动同步，但input.value是唯一的例外，它的同步是单身的attribute -> property，只修改.value不会改变attribute。\\n"}'));jctx.push(JSON.parse('{"id": "231229", "tag": "data", "text": "# 离线工具实现流式计算的实践\\n\\n## 离线计算的缺陷\\n\\n传统的处理逻辑是：每日凌晨以后开始对上一个自然日的数据进行归档、计算，并在白天之前完成计算。也许对互联网公司的业务场景，这样是合适且够用的，但到了感知数据场景，存在几个严重的不足\\n\\n1. 数据必然有延迟，导致每日凌晨以后，上一个自然日的数据往往没有齐备，这时启动计算肯定是不完备的\\n2. 数据计算部署在甲方且没有运维，一旦某天异常中断，下一次自动触发的计算结果会不正确\\n\\n用流计算能解决这两个问题吗？理论上可以，但这又牵涉到团队技能栈、计算资源开销、切换等许多问题，加上数据计算(hadoop)和数据使用(ES/MySQL)在不同的存储，而且数量都很大，更新的成本很高。\\n\\n## 解决思路\\n\\n观察传统离线计算，是一种典型的无状态计算。每一次计算在固定时间被触发，且不知道上一次的计算状态。因此要从无状态向有状态切换，即每次的计算必须要知道上一次的计算条件，并延续计算，而不是被调度器的trigger_time定义的计算。\\n\\n为了支持任意时间打断计算并恢复，一天一次触发会导致较多的空等时间，如果改为N小时一次，又会引发数据重算的问题，比较复杂。先讨论从无状态改为有状态的尝试。\\n\\n## 项目实践\\n\\n经过技战法和感知数智的实践，已经在一天一次的调度方式下解决了开头所列的两个问题。\\n\\n外部存储选什么？常见的MySQL、Redis都会增加部署资源，考虑到读写便利性和记录的数量不大，使用ZNode来存储上一次计算状态。\\n\\n为做到有状态，需要记录两种数据\\n\\n1. 上一次计算的输入数量。如果下个周期输入的增幅达成一定阈值，要触发那天的重算\\n2. 上一次计算成功与否。显然如果失败的任务，下个周期也要触发重算\\n\\n结合这两个特性，我把它命名为：自动补数据&自动续跑。上一次输入量或这次更新后的量，记录在lastrun路径；这一次要运行哪几天以及运行成功与否，记录在run_days路径。两个变量互为补充，必须同时修改。由于数仓结果还需要推送到集市层，后来又加了integrate路径，但本质和run_days是一样的。所以只要理解前两个就行。\\n\\n基本理念不难，但落地时由于要对画布进行切分，加上每个ZNode的存储有上限，就导致最终的实现非常复杂。\\n"}'));jctx.push(JSON.parse('{"id": "240129", "tag": "mine", "text": "# 传统机器学习分类\\n\\n虽然ML已经日渐式微，但了解其思想才能更好地理解现在的方向。机器学习的目的有三大类：回归、分类、聚类。再辅以配套技术：降维、模型选择和预处理。\\n\\n## 有监督-回归线性回归逻辑回归\\n\\n## 有监督-分类\\n\\n* KNN决策树\\n* 支持向量机\\n* SVM和朴素贝叶斯\\n\\n## 无监督-聚类K-means\\n\\n## 集成学习\\n\\n将多个弱模型整合成一个强模型，有bagging和boosting两个流派\\n\\n## bagging派之随机森林\\n\\n## boosting派之XGBoost其实还有AdaBoost和GBDT，但XGBoost最有名\\n\\n## 强化学习\\n\\n在人工智能领域属于少见的行为主义学派（控制论）。实现时与神经网络关联很深，似乎只有AlphaGo成功了，似乎出了游戏领域没有成功的例子\\n"}'));jctx.push(JSON.parse('{"id": "240315", "tag": "mine", "text": "# 对大模型与的理解与思考\\n\\n23年12月意外地被拉进大模型项目后大约跟了3个月，不得已学着理解这其中一些概念，一些不成熟的思考\\n\\n## 传统NLP任务\\n\\n通常分为三类:\\n\\n* NLU(文本分类,分词,句法分析,信息抽取等)\\n* 有条件生成任务(seq-seq,如翻译任务,QA)\\n* 无条件生成任务(用预训练模型直接生成内容)\\n\\n预训练模型也分为三类,分别在前面三种任务中表现良好.分别是:\\n\\n* 编码解码 T5\\n* 自编码 BERT\\n* 自回归 GPT\\n\\n语言理解,计算机科学把 nlp 分为 nlu 和 nlg,我们大脑的皮层有布洛卡区和韦尼克区,布洛卡区对应的是 nlg 而韦尼克区对应的 nlu\\n\\n婴儿在学习语言的时候,是把声音的刺激和实物还有他的感受融合在一起,所以在这种情况下,如果是双语并行刺激,形成的布洛卡区是一个区域.但是等他长到了小学以后,他在已经有唯一母语的情况下去学习其他外语,是用文字或者声音的方式去和母语建立关联,这种情况下,布洛卡区是两个挨得很近,但独立的区域 \\n\\n## 模型相关概念\\n\\n早期模型的权重和激活参数（tensor）是用PyTorch的pickle保存，比如`W4A8`方案就表示模型权重（Weight）量化到4位，激活值（Active，即模型的输入和输出）量化到8位。现在主流的有huggingface设计的safetensor和ggml定义的gguf。\\n\\n### 模型格式\\n\\nsafetensor支持五种框架：pytorch、TensorFlow、flax（jax）、paddle（paddlepaddle）、numpy。这些框架训练过程各异，导致各框架的模型格式不一致，无法方便地交换。于是提出了ONNX格式希望能作为一种大一统的模型格式，但实际使用时还是要修改一些源码，比如torch的view要改成squeeze，或是HF的transform要把tuple换成tensor。\\n\\n阿里提出将llm模型的跨平台部署抽象为4部分\\n\\n1. tokenizer 它是处理自然语言输入的关键，够将原始文本转换为模型能理解的格式\\n2. embedding 为了节约内存，引入了disk embedding\\n3. blocks 由于LLM的主干网络由一系列连续的block组成，每个block的核心计算部分是Attention，它最主要的两个计算操作分别是Linear（线性化）和MatMul（矩阵乘），除此之外还伴随诸如split、concat和transpose等内存操作，统称为Memory算子\\n4. lm\\n\\n### 规模与量化\\n\\n流行的大型语言模型（LLM）中，线性层的权重数量常常包含数十亿个参数。比如70亿参数（7b）的模型，采用16位浮点（fp16）存储，需要`7G*2Byte=14G`内存空间。必须采取措施来压缩这些权重，因此有了量化技术。幸运的是，LLM中的线性层权重之间的差异相对较小，这使得它们非常适合进行低比特量化——即使用较少的比特表示每个权重值。即使经过量化，计算结果仍能保持与原始浮点计算高度一致，这表明量化对模型性能的影响很小。因此选用Q4_0量化，大小是`7G*0.5Byte=4G`。量化由框架和硬件共同决定，至少有十多种，我所知常见的有fp16/int8/int4。\\n\\n模型的核心结构是张量，我下载过1B的模型文件只有200个张量，平均每个张量的参数有500万之多。\\n\\n### 训练和推理\\n\\n用户代码  -> AI框架（PyTorch/Tensorflow/Caffe等）-> CUDA lib -> Driver -> 显卡\\n\\n* 训练过程： 前向传播  -> 后向传播 -> 梯度更新。（迭代重复）\\n* 推理过程： 前向传播 。 （迭代重复）\\n\\n推理只是完成了训练的一部分内容，当然推理还可以剪枝、压缩让前向传播更快。但总体而言完成一次迭代（同batch_size），训练需要的运算量更多，但前向传播的底层运算基本相同。\\n\\ntensor core和cuda core 都是运算单元，是硬件名词，其主要的差异是算力和运算场景。场景：cuda core是全能通吃型的浮点运算单元，tensor core专门为深度学习矩阵运算设计。算力：在高精度矩阵运算上 tensor cores吊打cuda cores。\\n\\n2010年英伟达发布的Fermi架构，是第一个完整的GPU架构。其计算核心由16个SM（Stream Multiprocesser）组成，每个SM包含2个线程束（Warp），16组加载存储单元（LD/ST）和4个特殊函数单元（SFU）组成。最核心的是，每个线程束包含16个Cuda Core组成，每一个Cuda Core包含了一个整数运算单元integer arithmetic logic unit (ALU) 和一个浮点运算单元floating point unit (FPU)。然后，这个core能进行一种fused multiply-add (FMA)的操作，通俗一点就是一个加乘操作的融合。特点：在不掉精度的情况下，单指令完成乘加操作，并且这个是支持32-bit精度。更通俗一点，就是深度学习里面的操作变快了。\\n\\nTuring架构Tensor核心中设计添加了INT8和INT4精度模式，以推断可以容忍量化的工作负载。而Ampere架构GA10x GPU中的新第三代Tensor Core架构可加速更多数据类型，并包括新的稀疏性功能。\\n\\n使用Tensor核的两个CUDA库是cuBLAS和cuDNN。cuBLAS使用张量核加速GEMM计算（GEMM是矩阵-矩阵乘法的BLAS术语）；cuDNN使用张量核加速卷积和递归神经网络（RNNs）。\\n\\nLLM推理可以被分为两个阶段：prefill(context)和decode(generate)。在prefill阶段，输入一个包含m个token的提示（prompt），执行batch为m的推理，此时由于是初始输入，没有kv-cache的需求，得到了首个token的输出。接着，在decode阶段，以上一轮的输出token作为输入，进行batch的推理，这时kv-cache的长度变为m+n，其中n代表之前已生成的token数量。单个block的耗时分析显示：\\n\\n1. prefill阶段，Linear算子的耗时占比相对稳定，超过了93%，而MatMul和Memory算子的耗时占比分别约为3%和2%；\\n2. decode阶段，随着m+n的增长，Linear算子的时间占比有所下降，而MatMul和Memory算子的占比有所上升。尽管如此，在多数情况下，耗时主要集中在Linear算子上。\\n\\nLinear计算主要分为两个阶段：prefill阶段处理大量输入数据，使用矩阵乘法（GEMM），是计算密集过程，需要用SIMD优化；模型解码（decode）阶段时，使用矩阵向量乘法（GEMV），访存的效率变得更加关键。\\n"}'));jctx.push(JSON.parse('{"id": "240529", "tag": "data", "text": "# 数仓到集市层的同步\\n\\n最近做doris的预研，比较同步ES的区别，总结下来主要有3种模式\\n\\n## insert\\n\\n最简单的模式，应用场景是不变的流水数据，每种数据库都支持，区别在于分区键有没有限制。比如doris要求必须用datetime类型切日表，但hive源表没有相应的类型，为此还要改造数仓表。\\n\\n## upsert\\n\\n通过相同的主键实现覆盖，速度相比insert往往会慢一些，ES的upsert速度大约是insert的1/3\\n\\n## AB表切换\\n\\n是一种思想，哪怕DB原生不支持也能通过手动模拟，简单做法就是推送完成后，向另一个flag表写入标记。ES原生支持alias操作，使AB切换更便捷。\\n"}'));jctx.push(JSON.parse('{"id": "240607", "tag": "web", "text": "# 使用algernon开发web\\n\\n这个软件集成了非常多功能，挑几块重点的说\\n\\n1. 自带多种简化前端开发的模板，比如简化html的amber/pongo2，简化css的scss，还集成了jsx转换器\\n2. 支持lua/teal开发类CGI的动态处理能力\\n3. 集成bolt数据库，并且在lua可以方便使用。虽然只有kv存储能力，但也能做一些简单应用。同时也支持外部数据库，似乎仍然是kv，所以并不怎么在意\\n\\n## 启动参数\\n\\n调试过程使用`-e`，不缓存代码，可以随时刷新。\\n\\n部署阶段，指定--boltdb路径，`-s`不进交互模式。\\n\\n## 利用lua/bolt能力\\n\\n我选择它主要就是这两块能力。bolt集成到lua有以下4种数据结构，但都不具备模糊检索能力\\n\\n* Set: 好处是提供`getall()`方法，或许配合kv结构能多些便利？\\n* List: 是个链表，并不能按下标索引，且只能追加不能删除，典型场景可能是评论区内容\\n* HashMap/KeyValue: 区别是前者唯一支持多租户实例，后者多一个`inc()`方法\\n\\n表面上HashMap是唯一支持多租户实例，但由于每次获取数据结构时都要指定名称，其实仍可以变相实现多租户。可能作者推荐是Set/List/KeyValue用于全局管理用户或配置，HashMap存储每个用户的数据。\\n\\n应答请求\\n\\n* formdata(): 如果只记一个方法，就是这个。把GET/POST的参数转成table\\n* method(): 区分请求来自GET还是POST\\n* content/setheader: 默认值基本够用，如果不够再设置\\n\\n内嵌数据机制\\n\\n* data.lua: 初始化阶段，对页面进行变量替换（非交互式）。不仅能引用变量，也能调用函数。比如amber使用`#{var}`引用变量，`#{foo()}`调用函数。\\n\\n### 多用户认证\\n\\n如果启用固定数据库（比如bolt），就能实现用户效果，默认24小时超期，使用了3个数据对象\\n\\n* Set(\\"usernames\\"): 保存用户列表\\n* Set(\\"unconfirmed\\"): 不太懂\\n* HashMap(\\"users\\"): 用户完整信息\\n\\n登陆后的用户，可以打开`/data`, `/repo`, `/admin`前缀的URL，比如/data1或/repo2，否则系统会提示无权限。\\n\\n提供了比预期多得多的API，我觉得只要用其中几个就够了\\n\\n* AddUser 向数据库添加初始用户，初始化一次，必须\\n* Login 同时设置server和cookie，比SetLoggedIn方便，必须\\n* UsernameCookie 检查此次请求来源是否有用户权限，必须\\n* SetCookieTimeout 延长默认1天的超时时间，Login后使用，建议\\n* SetAdminStatus 只是开启/admin路径权限，备选\\n\\n说下踩坑史，试过用IsLoggedIn判断，但这个函数是检测server是否有登陆记录，导致在一个浏览器登陆会误判所有客户都已登陆。改成UsernameCookie实现每个终端独立检测。server端和cookie两重登陆是常用方式，server实现为一处登陆处处可见，而cookie则针对每次会话，也能实现一处登陆将其它顶出的效果\\n\\n## 前端开发便利工具\\n\\namber/scss确实能极大简少代码编写量，我也投了些时间研究过这些。可惜我本职毕竟不是前端，也就没有记录下来。如果未来还会继续，就写到这后面吧。\\n\\n## 缺陷\\n\\n1. 只接受x-www-form-urlencoded类型的ajax请求，不能解析json。\\n2. Set和KeyValue如果同名，数据会串，似乎二者底层有共享，安全起见还是用不同名字稳妥\\n"}'));jctx.push(JSON.parse('{"id": "240613", "tag": "lang", "text": "# 学elixir\\n\\n## mix使用\\n\\n国内源`mix hex.config  mirror_url https://hexpm.upyun.com`\\n\\n纯ex项目 - mix new xxx\\n\\n根目录有 mix.exs,用于指定项目依赖和打包指令.增加依赖\\n\\n```\\ndefp deps do\\n    [\\n      {:plug, \\"~> 1.15.3\\"},\\n      {:plug_cowboy, \\"~> 1.0\\"}\\n    ]\\nend\\n```\\n\\n执行`HEX_UNSAFE_HTTPS=1 mix deps.get`  前面的 unsafe 不确定有没有用,可能会警告但总归能下载.\\n\\n`~>` 操作符又叫 \\"twiddle-wakka\\" 或 \\"approximately greater than\\" 表示大致大于,非常精确\\n\\nlib/是代码目录,deps/是下载的依赖库,test/则是测试.\\n\\n打包产生的 app 文件是个 erlang 格式的纯文本,use Application 表示是 OTP 应用\\n\\n## 基础知识\\n\\n* 原子类型(符号) :foo,冒号在前\\n* map 类型 `%{foo: \\"bar\\", hello: \\"world\\"} == %{:foo => \\"bar\\", :hello => \\"world\\"}` \'\'容易混淆的点 foo: 和 :foo =>等价\'\' 冒号在后面,是原子加上映射符的语法糖,由于和原子有关系,所以仍然用冒号,只是放在后面\\n\\n## 安装 phoeix 框架 - 依赖 pg,太重\\n\\n安装 hex 模块`mix local.hex`,但似乎网络受限,提示下载 ez 包后离线安装,其实 ez 就是 zip 包,安装后会在~/.mix 目录下解压若干个编译后的 beam 文件.rebar 也要手动装\\n\\n`mix hex.config unsafe_https true` 关 ssl 校验\\n"}'));jctx.push(JSON.parse('{"id": "240625", "tag": "lang", "text": "# 学react\\n\\n## 概念与用法\\n\\nreact理念是创建VDOM，并以最快的速度(最小的代价)render出来，不负责页面布局，也没有刻意追求data drive。\\n\\n什么是VDOM？最简化的理解是JS对象，包含tag,props(必选),children(可选)。\\n\\nVDOM可以是最简单的只有tag(使用createElement实例化)，其它属性都是空的对象；也可以包含若干个children构成容器。\\n\\n* 最简单空对象 `VDOM(\'p\', {})`\\n* 带值的简单对象 `VDOM(\'div\', {}, \\"p1\\", \\"p2\\", \\"p3\\")`\\n* div嵌套input，且配置了监听回调的复杂对象 `VDOM(\'div\', {}, DOM(\'input\', {oninput:fn1}))`\\n\\nrendor可以在指定的根DOM元素的末尾追加或移除末尾的子元素，遗憾的是可能我用的是精简版，只能追加一个子元素，删除自然也只能删被追加的元素。\\n\\nES6引入module概念，script标签有module和importmap可选。module隐含defer，在DOM加载完成后触发。\\n\\n## 函数解析\\n\\n抛开渲染的html不讲，自定义组件继承自Component，最后用render渲染组件。通过TinyReact学习，外部函数\\n\\n* createVDOM: 创建包含多个子元素时，children是array，实例化时也会用forEach依次实例化出来\\n* render(vdom, realdom): 计算VDOM前后的diff，diff有create/remove/update类型，做patch操作\\n\\n内部函数\\n\\n* diff: 最难也最关键，前后tag类型相同触发diffProps，否则用新tag替换掉老tag\\n* patch: 如果diff涉及create或update，调用createDOM创建真实对象\\n\\nprops是怎么做到放在这个对象里属性，可以赋值给任意DOM元素？核心这句:\\n\\n`forEach(key => {dom[key]=props[key]}`\\n"}'));jctx.push(JSON.parse('{"id": "240711", "tag": "web", "text": "# 学WebAssembly\\n\\nWASM最初是一种指令格式，渐渐地对应一种磁盘上的文件格式，或者也可以把它当作一种类似容器镜像的东西。可以运行在浏览器或专门的WASM运行时上。\\n\\n由于WASM是一种编译结果，很自然的各种编程语言都可以生成WASM格式文件，不同语言生成的WASM大小就天差地别，以go语言为例，使用*GOOS=js GOARCH=wasm go build*指令就能以跨平台的方式生成wasm文件，这个文件在1.5M甚至更大。所以更多的时候，会用别的语言来生成WASM。\\n\\nHTML要加载WASM通常要通过js桥接，用js的fetch获取wasm文件，WASM文件内部按**module**为静态单位组织。文件获取后，用window.WebAssembly模块来加载和执行，这个步骤称为instantiate。\\n\\n各种术语\\n\\n* WAT Text\\n* WASI\\n* WAPM 包管理\\n"}'));jctx.push(JSON.parse('{"id": "240716", "tag": "web", "text": "# CSS框架学习笔记\\n\\n不能和编程语言的框架类比，更像是一套工具集或是一种惯用法的集合。记录pico.css的要点\\n\\n## 伪类伪元素和定义变量\\n\\n开头是这样一段代码\\n\\n```\\n:root {\\n  --pico-spacing: 1rem;\\n}\\n```\\n\\n`:root`是伪类，特指根元素也就是html。--开头是变量后，在后面可以用var(--pico)取值。整段表示对html全局定义下列变量，方便后续使用。\\n\\n一个`:`开头的往往是伪类，两个冒号开头是伪元素。还有似乎是厂商专属`::-webkit`或`::moz`。看这个例子\\n\\n```\\n:where(nav li)::before {\\n    float: left;\\n    content: \\"-\\"\\n}\\n```\\n\\n`:where`是比较新的伪类，用于选择具有子孙关系的元素；`::before`则是伪元素，整个连一起看就是选中nav下的li，然后在每个li的左侧加一个\\"-\\"\\n\\n## 属性选择器\\n\\n先看css中的定义\\n\\n```\\n[data-tooltip] {\\n    position: relative;\\n}\\n```\\n\\n按规范，HTML元素可以自由添加`data-`前缀的属性，不管值是什么，上述的选择器都能生效。比如`<p data-tooltip=\\"123\\">hello</p>`。\\n\\n如果写成`[data-tooltip=hi]`，表示值必须是`hi`才能生效。\\n\\n### 多属性语法\\n\\n如果是两个及以上的方括号，要怎么理解？如果是两个连在一起`[a][b]`，相当于and，既一个元素同时具有这两种属性时生效。\\n\\n如果是通过逗号连在一起`[a],[b]`，则表示两个连续元素，分别有a和b属性时生效。比如`<button a><input b>`"}'));}var config_txt=`
{"edit":true,
 "tagtr":{
  "os":"操作系统","net":"网络原理","security":"加密与安全",
  "protocol":"通信协议","web":"Web开发","mine":"数据挖掘",
  "lang":"编程语言","tool":"软件工具使用","data":"数据库技术",

  "design":"软件设计","think":"所思所想","book":"读书笔记"
  ,"his":"历史寻味"
 }
}`;var config=JSON.parse(config_txt);
function _uniid(base){return `u${base}${Math.round(Math.random()*65536)}`}
function renderText(txt){
  if ("#"==txt[0]){return marked.parse(txt.replace(/\[\[([^\] ]+)\]\]/g, "*$1*"))}
  else {return `<p>${txt.replace(/\n/g, "<br/>")}</p>`}}
function dumpobj(e){var t= typeof e;for (let i in e){t=t+`\n${i} : ${e[i]}`};alert(t)}
function _ttl_of_text(txt){var sp= "#"==txt[0]?2:0;return txt.substring(sp, txt.indexOf("\n"))}
function _close_btn(uid){return `<input value="close" type=button onclick="$tm.ev_rmnode('${uid}')"/>`}
function saveFile(flname, txt){
  var a = document.createElement('a')
  a.download = flname
  a.href = URL.createObjectURL(new Blob([txt], {type: 'text/plain'}))
  a.click()
}
function createTitleLink(ttl, i){
  if (i!=undefined) {
	return `<p class="s_item" onclick="$tm.ev_shwCard(${i})">${ttl}</p>`
  }else {return `<p>ERR LINK: ${ttl}</p>`}
}
function createAllTopH(){
  var toph=""
  for (let t in tag2ttl){
	var showh = config.tagtr[t]?config.tagtr[t]:t
	toph+=`<h2 onclick="$tm.ev_shwHd('${t}')">${showh}</h2>`
  }
  return toph
}
function createCata(tag){
  var div = document.createElement('div')
  uniid=_uniid(tag)
  div.id=uniid
  div.className="card sec_pad"
  tag2ttl[tag].sort()
  var ttl_lnk=""
  for (let ttl of tag2ttl[tag]){
	ttl_lnk+=createTitleLink(ttl, ttl2idx[ttl])
  }
  ttl_lnk+=`<hr />${config.tagtr[tag]?config.tagtr[tag]:tag}${tag2ttl[tag].length}篇${_close_btn(uniid)}`
  div.innerHTML=ttl_lnk
  return div
}
function createCard(art, idx){
  var div = document.createElement('div')
  var uniid = _uniid(art["id"])
  div.id=uniid
  div.className="card art_pad"
  var ttl=_ttl_of_text(art["text"])
  var lnkelem=""
  if (lnkmap[ttl]){
	let lst=lnkmap[ttl].split(",")
	for (let v of lst){
	  lnkelem+=createTitleLink(v, ttl2idx[v])
	}
  }
  var edtbtn = config.edit?`<input value="edit" type=button onclick="$tm.ev_shwEdt(${idx})"/>`:"";
  var tag= art["tag"]=="unknown"?"":`_${art["tag"]}`
  div.innerHTML=renderText(art["text"])+`<hr />${art["id"]}${tag}
	${lnkelem}
	${edtbtn}
	${_close_btn(uniid)}`
  return div
}
function insert_div(target, div){
  document.getElementById(target).before(div)
  window.scrollTo({"left": div.offsetLeft, "top": div.offsetTop, behavior: "smooth"})
}
function _find_bykwd(kwd) {
  var ret = []
  var kl = kwd.split(/\s+/)
  var klen = kl.length
  for (let i in jctx) {
    var mc=0, mp, mt=""
    for (let j=0;j<klen;j++){
	  if (0==kl[j].length){mc++;continue}
	  var txt = jctx[i]["text"]
	  if (128>kl[j].charCodeAt(0)) {/*ignoreCase english*/
	    mp = txt.search(RegExp(kl[j],"i"))
	  } else {
		mp = txt.indexOf(kl[j])
	  }
	  mc += mp>=0?1:0
	  mt += mp>=0?`${txt.slice(Math.max(mp-5, 0),mp)}<span class="kwd_em">${kl[j]}</span>${txt.slice(mp+kl[j].length, mp+kl[j].length+6)} `:""
	}
    if (mc==klen) {ret.push([i, mt])}
  }
  return ret
}
var tmout
var ttl2idx={}
var tag2ttl={}
var lnkmap={}
// event function definition
top.$tm.ev_findkwd=function(){
  function _search() {
    var kwd = document.getElementById("kwd").value
    if (kwd.length==0) {document.getElementById("kwd_show").innerHTML ="";return}
    var lst = _find_bykwd(kwd)
    var jmp_ttl = ""
    for (let pr of lst){
	  let i=pr[0], mt=pr[1]
      let ttl = _ttl_of_text(jctx[i]["text"])
      jmp_ttl += createTitleLink(ttl, i)+mt
    }
    document.getElementById("kwd_show").innerHTML = jmp_ttl
  }
  clearTimeout(tmout)
  tmout=setTimeout(_search, 250)
}
top.$tm.ev_rmnode=function(id){var n=document.getElementById(id);n.remove()}
top.$tm.ev_save=function(idx, taid){
  var art = jctx[idx]
  var ta = document.getElementById(taid)
  saveFile(`${art["id"]}_${art["tag"]}.md`, ta.value)
}
top.$tm.ev_chgVorE=function(mdid){
  var md = document.getElementById(mdid)
  if (md.style.display=="none"){
	md.style.display="block"
  } else {
	md.style.display="none"
  }
}
top.$tm.ev_shwCard=function(idx){
  var div = createCard(jctx[idx], idx)
  insert_div("kwd_show", div)
}
top.$tm.ev_shwHd=function(tag) {
  var div = createCata(tag)
  insert_div("eTopTag", div)
}
top.$tm.ev_shwEdt=function(idx){
  var div = document.createElement('div')
  var art = jctx[idx]
  var uniid = _uniid(art["id"])
  div.id=uniid
  div.className="card art_pad edit_zone"
  var spid = _uniid("sp"+art["id"])
  var taid = _uniid("ta"+art["id"])
  var mdid = _uniid("dv"+art["id"])
  div.innerHTML=`<span style="color: blue">Draft Zone</span>
	<div style="display: flex">
	<div class="auto_high sd_by_sd">
	  <span id="${spid}" class="auto_high"></span>
	  <textarea id="${taid}" class="auto_high"></textarea>
	</div>
	<div id="${mdid}" style="display: none" class="sd_by_sd prv_pad"></div>
	</div>
	<hr />
	<input value="preview" type=button onclick="$tm.ev_chgVorE('${mdid}')"/>
	<input value="save" type=button onclick="$tm.ev_save(${idx}, '${taid}')" />
	${_close_btn(uniid)}`
  insert_div("kwd_show", div)
  var ta = document.getElementById(taid)
  ta.value = art["text"]
  document.getElementById(mdid).innerHTML = renderText(ta.value)
  ta.addEventListener('input', function(ev){
	document.getElementById(mdid).innerHTML=renderText(ev.target.value)
  })
  // textarea height auto to rext
  var d_span = document.getElementById(spid)
  var d_area = document.getElementById(taid)
  d_span.innerHTML = d_area.value+' ';
  d_area.addEventListener('input', function(e) {
    d_span.innerHTML = d_area.value+' ';
  })
}
top.$tm.ev_boot=function(){
  load_jctx()
  for (let i in jctx) {
    let ttl = _ttl_of_text(jctx[i]["text"]); ttl2idx[ttl]=i
    let tag = jctx[i]["tag"]
	if (!tag2ttl[tag]) {tag2ttl[tag]=[]};tag2ttl[tag].push(ttl)
	let lnk=jctx[i]["text"].match(/\[\[[^\] ]+\]\]/g)
    if (lnk){
	  for (let v of lnk) {
		let to_lk=v.slice(2, -2)
		if (lnkmap[ttl]===undefined){lnkmap[ttl]=to_lk}
		else {if (-1==lnkmap[ttl].indexOf(to_lk)){lnkmap[ttl]+=`,${to_lk}`} }
		if (lnkmap[to_lk]===undefined){lnkmap[to_lk]=ttl}
		else {if (-1==lnkmap[to_lk].indexOf(ttl)){lnkmap[to_lk]+=`,${ttl}`}}
	  }
    }
  }
  document.getElementById("eTopTag").innerHTML=createAllTopH()
  var dt = new Date();
  document.getElementById("eFter").innerHTML=`Generated at 2024/07/21, 共${jctx.length}篇笔记<br />© 2014 - ${dt.getFullYear()} 由mytid强力驱动`
}
})(this);
//markdown
!function(e,t){"object"==typeof exports&&"undefined"!=typeof module?module.exports=t():"function"==typeof define&&define.amd?define(t):(e=e||self).marked=t()}(this,function(){"use strict";function s(e,t){for(var n=0;n<t.length;n++){var r=t[n];r.enumerable=r.enumerable||!1,r.configurable=!0,"value"in r&&(r.writable=!0),Object.defineProperty(e,r.key,r)}}function i(e,t){(null==t||t>e.length)&&(t=e.length);for(var n=0,r=new Array(t);n<t;n++)r[n]=e[n];return r}function g(e,t){var n;if("undefined"!=typeof Symbol&&null!=e[Symbol.iterator])return(n=e[Symbol.iterator]()).next.bind(n);if(Array.isArray(e)||(n=function(e,t){if(e){if("string"==typeof e)return i(e,t);var n=Object.prototype.toString.call(e).slice(8,-1);return"Object"===n&&e.constructor&&(n=e.constructor.name),"Map"===n||"Set"===n?Array.from(e):"Arguments"===n||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)?i(e,t):void 0}}(e))||t&&e&&"number"==typeof e.length){n&&(e=n);var r=0;return function(){return r>=e.length?{done:!0}:{done:!1,value:e[r++]}}}throw new TypeError("Invalid attempt to iterate non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}function n(e){return c[e]}var e,t=(function(t){function e(){return{baseUrl:null,breaks:!1,gfm:!0,headerIds:!0,headerPrefix:"",highlight:null,langPrefix:"language-",mangle:!0,pedantic:!1,renderer:null,sanitize:!1,sanitizer:null,silent:!1,smartLists:!1,smartypants:!1,tokenizer:null,walkTokens:null,xhtml:!1}}t.exports={defaults:e(),getDefaults:e,changeDefaults:function(e){t.exports.defaults=e}}}(e={exports:{}}),e.exports),r=(t.defaults,t.getDefaults,t.changeDefaults,/[&<>"']/),l=/[&<>"']/g,a=/[<>"']|&(?!#?\w+;)/,o=/[<>"']|&(?!#?\w+;)/g,c={"&":"&amp;","<":"&lt;",">":"&gt;",'"':"&quot;","'":"&#39;"};var u=/&(#(?:\d+)|(?:#x[0-9A-Fa-f]+)|(?:\w+));?/gi;function p(e){return e.replace(u,function(e,t){return"colon"===(t=t.toLowerCase())?":":"#"===t.charAt(0)?"x"===t.charAt(1)?String.fromCharCode(parseInt(t.substring(2),16)):String.fromCharCode(+t.substring(1)):""})}var h=/(^|[^\[])\^/g;var f=/[^\w:]/g,d=/^$|^[a-z][a-z0-9+.-]*:|^[?#]/i;var k={},b=/^[^:]+:\/*[^/]*$/,m=/^([^:]+:)[\s\S]*$/,x=/^([^:]+:\/*[^/]*)[\s\S]*$/;function v(e,t){k[" "+e]||(b.test(e)?k[" "+e]=e+"/":k[" "+e]=w(e,"/",!0));var n=-1===(e=k[" "+e]).indexOf(":");return"//"===t.substring(0,2)?n?t:e.replace(m,"$1")+t:"/"===t.charAt(0)?n?t:e.replace(x,"$1")+t:e+t}function w(e,t,n){var r=e.length;if(0===r)return"";for(var i=0;i<r;){var s=e.charAt(r-i-1);if(s!==t||n){if(s===t||!n)break;i++}else i++}return e.substr(0,r-i)}var _=function(e,t){if(t){if(r.test(e))return e.replace(l,n)}else if(a.test(e))return e.replace(o,n);return e},y=p,z=function(n,e){n=n.source||n,e=e||"";var r={replace:function(e,t){return t=(t=t.source||t).replace(h,"$1"),n=n.replace(e,t),r},getRegex:function(){return new RegExp(n,e)}};return r},S=function(e,t,n){if(e){var r;try{r=decodeURIComponent(p(n)).replace(f,"").toLowerCase()}catch(e){return null}if(0===r.indexOf("javascript:")||0===r.indexOf("vbscript:")||0===r.indexOf("data:"))return null}t&&!d.test(n)&&(n=v(t,n));try{n=encodeURI(n).replace(/%25/g,"%")}catch(e){return null}return n},$={exec:function(){}},A=function(e){for(var t,n,r=1;r<arguments.length;r++)for(n in t=arguments[r])Object.prototype.hasOwnProperty.call(t,n)&&(e[n]=t[n]);return e},R=function(e,t){var n=e.replace(/\|/g,function(e,t,n){for(var r=!1,i=t;0<=--i&&"\\"===n[i];)r=!r;return r?"|":" |"}).split(/ \|/),r=0;if(n.length>t)n.splice(t);else for(;n.length<t;)n.push("");for(;r<n.length;r++)n[r]=n[r].trim().replace(/\\\|/g,"|");return n},T=function(e,t){if(-1===e.indexOf(t[1]))return-1;for(var n=e.length,r=0,i=0;i<n;i++)if("\\"===e[i])i++;else if(e[i]===t[0])r++;else if(e[i]===t[1]&&--r<0)return i;return-1},I=function(e){e&&e.sanitize&&!e.silent&&console.warn("marked(): sanitize and sanitizer parameters are deprecated since version 0.7.0, should not be used and will be removed in the future. Read more here: https://marked.js.org/#/USING_ADVANCED.md#options")},Z=t.defaults,q=w,O=R,C=_,U=T;function j(e,t,n){var r=t.href,i=t.title?C(t.title):null,s=e[1].replace(/\\([\[\]])/g,"$1");return"!"!==e[0].charAt(0)?{type:"link",raw:n,href:r,title:i,text:s}:{type:"image",raw:n,href:r,title:i,text:C(s)}}var E=function(){function e(e){this.options=e||Z}var t=e.prototype;return t.space=function(e){var t=this.rules.block.newline.exec(e);if(t)return 1<t[0].length?{type:"space",raw:t[0]}:{raw:"\n"}},t.code=function(e,t){var n=this.rules.block.code.exec(e);if(n){var r=t[t.length-1];if(r&&"paragraph"===r.type)return{raw:n[0],text:n[0].trimRight()};var i=n[0].replace(/^ {4}/gm,"");return{type:"code",raw:n[0],codeBlockStyle:"indented",text:this.options.pedantic?i:q(i,"\n")}}},t.fences=function(e){var t=this.rules.block.fences.exec(e);if(t){var n=t[0],r=function(e,t){var n=e.match(/^(\s+)(?:```)/);if(null===n)return t;var r=n[1];return t.split("\n").map(function(e){var t=e.match(/^\s+/);return null!==t&&t[0].length>=r.length?e.slice(r.length):e}).join("\n")}(n,t[3]||"");return{type:"code",raw:n,lang:t[2]?t[2].trim():t[2],text:r}}},t.heading=function(e){var t=this.rules.block.heading.exec(e);if(t)return{type:"heading",raw:t[0],depth:t[1].length,text:t[2]}},t.nptable=function(e){var t=this.rules.block.nptable.exec(e);if(t){var n={type:"table",header:O(t[1].replace(/^ *| *\| *$/g,"")),align:t[2].replace(/^ *|\| *$/g,"").split(/ *\| */),cells:t[3]?t[3].replace(/\n$/,"").split("\n"):[],raw:t[0]};if(n.header.length===n.align.length){for(var r=n.align.length,i=0;i<r;i++)/^ *-+: *$/.test(n.align[i])?n.align[i]="right":/^ *:-+: *$/.test(n.align[i])?n.align[i]="center":/^ *:-+ *$/.test(n.align[i])?n.align[i]="left":n.align[i]=null;for(r=n.cells.length,i=0;i<r;i++)n.cells[i]=O(n.cells[i],n.header.length);return n}}},t.hr=function(e){var t=this.rules.block.hr.exec(e);if(t)return{type:"hr",raw:t[0]}},t.blockquote=function(e){var t=this.rules.block.blockquote.exec(e);if(t){var n=t[0].replace(/^ *> ?/gm,"");return{type:"blockquote",raw:t[0],text:n}}},t.list=function(e){var t=this.rules.block.list.exec(e);if(t){for(var n,r,i,s,l,a,o,c=t[0],u=t[2],p=1<u.length,h=")"===u[u.length-1],g={type:"list",raw:c,ordered:p,start:p?+u.slice(0,-1):"",loose:!1,items:[]},f=t[0].match(this.rules.block.item),d=!1,k=f.length,b=0;b<k;b++)r=(c=n=f[b]).length,~(n=n.replace(/^ *([*+-]|\d+[.)]) */,"")).indexOf("\n ")&&(r-=n.length,n=this.options.pedantic?n.replace(/^ {1,4}/gm,""):n.replace(new RegExp("^ {1,"+r+"}","gm"),"")),b!==k-1&&(i=this.rules.block.bullet.exec(f[b+1])[0],(p?1===i.length||!h&&")"===i[i.length-1]:1<i.length||this.options.smartLists&&i!==u)&&(s=f.slice(b+1).join("\n"),g.raw=g.raw.substring(0,g.raw.length-s.length),b=k-1)),l=d||/\n\n(?!\s*$)/.test(n),b!==k-1&&(d="\n"===n.charAt(n.length-1),l=l||d),l&&(g.loose=!0),o=void 0,(a=/^\[[ xX]\] /.test(n))&&(o=" "!==n[1],n=n.replace(/^\[[ xX]\] +/,"")),g.items.push({type:"list_item",raw:c,task:a,checked:o,loose:l,text:n});return g}},t.html=function(e){var t=this.rules.block.html.exec(e);if(t)return{type:this.options.sanitize?"paragraph":"html",raw:t[0],pre:!this.options.sanitizer&&("pre"===t[1]||"script"===t[1]||"style"===t[1]),text:this.options.sanitize?this.options.sanitizer?this.options.sanitizer(t[0]):C(t[0]):t[0]}},t.def=function(e){var t=this.rules.block.def.exec(e);if(t)return t[3]&&(t[3]=t[3].substring(1,t[3].length-1)),{tag:t[1].toLowerCase().replace(/\s+/g," "),raw:t[0],href:t[2],title:t[3]}},t.table=function(e){var t=this.rules.block.table.exec(e);if(t){var n={type:"table",header:O(t[1].replace(/^ *| *\| *$/g,"")),align:t[2].replace(/^ *|\| *$/g,"").split(/ *\| */),cells:t[3]?t[3].replace(/\n$/,"").split("\n"):[]};if(n.header.length===n.align.length){n.raw=t[0];for(var r=n.align.length,i=0;i<r;i++)/^ *-+: *$/.test(n.align[i])?n.align[i]="right":/^ *:-+: *$/.test(n.align[i])?n.align[i]="center":/^ *:-+ *$/.test(n.align[i])?n.align[i]="left":n.align[i]=null;for(r=n.cells.length,i=0;i<r;i++)n.cells[i]=O(n.cells[i].replace(/^ *\| *| *\| *$/g,""),n.header.length);return n}}},t.lheading=function(e){var t=this.rules.block.lheading.exec(e);if(t)return{type:"heading",raw:t[0],depth:"="===t[2].charAt(0)?1:2,text:t[1]}},t.paragraph=function(e){var t=this.rules.block.paragraph.exec(e);if(t)return{type:"paragraph",raw:t[0],text:"\n"===t[1].charAt(t[1].length-1)?t[1].slice(0,-1):t[1]}},t.text=function(e,t){var n=this.rules.block.text.exec(e);if(n){var r=t[t.length-1];return r&&"text"===r.type?{raw:n[0],text:n[0]}:{type:"text",raw:n[0],text:n[0]}}},t.escape=function(e){var t=this.rules.inline.escape.exec(e);if(t)return{type:"escape",raw:t[0],text:C(t[1])}},t.tag=function(e,t,n){var r=this.rules.inline.tag.exec(e);if(r)return!t&&/^<a /i.test(r[0])?t=!0:t&&/^<\/a>/i.test(r[0])&&(t=!1),!n&&/^<(pre|code|kbd|script)(\s|>)/i.test(r[0])?n=!0:n&&/^<\/(pre|code|kbd|script)(\s|>)/i.test(r[0])&&(n=!1),{type:this.options.sanitize?"text":"html",raw:r[0],inLink:t,inRawBlock:n,text:this.options.sanitize?this.options.sanitizer?this.options.sanitizer(r[0]):C(r[0]):r[0]}},t.link=function(e){var t=this.rules.inline.link.exec(e);if(t){var n,r=U(t[2],"()");-1<r&&(n=(0===t[0].indexOf("!")?5:4)+t[1].length+r,t[2]=t[2].substring(0,r),t[0]=t[0].substring(0,n).trim(),t[3]="");var i,s=t[2],l="";return l=this.options.pedantic?(i=/^([^'"]*[^\s])\s+(['"])(.*)\2/.exec(s),i?(s=i[1],i[3]):""):t[3]?t[3].slice(1,-1):"",j(t,{href:(s=s.trim().replace(/^<([\s\S]*)>$/,"$1"))?s.replace(this.rules.inline._escapes,"$1"):s,title:l?l.replace(this.rules.inline._escapes,"$1"):l},t[0])}},t.reflink=function(e,t){var n;if((n=this.rules.inline.reflink.exec(e))||(n=this.rules.inline.nolink.exec(e))){var r=(n[2]||n[1]).replace(/\s+/g," ");if((r=t[r.toLowerCase()])&&r.href)return j(n,r,n[0]);var i=n[0].charAt(0);return{type:"text",raw:i,text:i}}},t.strong=function(e,t,n){void 0===n&&(n="");var r=this.rules.inline.strong.start.exec(e);if(r&&(!r[1]||r[1]&&(""===n||this.rules.inline.punctuation.exec(n)))){t=t.slice(-1*e.length);var i,s="**"===r[0]?this.rules.inline.strong.endAst:this.rules.inline.strong.endUnd;for(s.lastIndex=0;null!=(r=s.exec(t));)if(i=this.rules.inline.strong.middle.exec(t.slice(0,r.index+3)))return{type:"strong",raw:e.slice(0,i[0].length),text:e.slice(2,i[0].length-2)}}},t.em=function(e,t,n){void 0===n&&(n="");var r=this.rules.inline.em.start.exec(e);if(r&&(!r[1]||r[1]&&(""===n||this.rules.inline.punctuation.exec(n)))){t=t.slice(-1*e.length);var i,s="*"===r[0]?this.rules.inline.em.endAst:this.rules.inline.em.endUnd;for(s.lastIndex=0;null!=(r=s.exec(t));)if(i=this.rules.inline.em.middle.exec(t.slice(0,r.index+2)))return{type:"em",raw:e.slice(0,i[0].length),text:e.slice(1,i[0].length-1)}}},t.codespan=function(e){var t=this.rules.inline.code.exec(e);if(t){var n=t[2].replace(/\n/g," "),r=/[^ ]/.test(n),i=n.startsWith(" ")&&n.endsWith(" ");return r&&i&&(n=n.substring(1,n.length-1)),n=C(n,!0),{type:"codespan",raw:t[0],text:n}}},t.br=function(e){var t=this.rules.inline.br.exec(e);if(t)return{type:"br",raw:t[0]}},t.del=function(e){var t=this.rules.inline.del.exec(e);if(t)return{type:"del",raw:t[0],text:t[1]}},t.autolink=function(e,t){var n=this.rules.inline.autolink.exec(e);if(n){var r,i="@"===n[2]?"mailto:"+(r=C(this.options.mangle?t(n[1]):n[1])):r=C(n[1]);return{type:"link",raw:n[0],text:r,href:i,tokens:[{type:"text",raw:r,text:r}]}}},t.url=function(e,t){var n,r,i,s;if(n=this.rules.inline.url.exec(e)){if("@"===n[2])i="mailto:"+(r=C(this.options.mangle?t(n[0]):n[0]));else{for(;s=n[0],n[0]=this.rules.inline._backpedal.exec(n[0])[0],s!==n[0];);r=C(n[0]),i="www."===n[1]?"http://"+r:r}return{type:"link",raw:n[0],text:r,href:i,tokens:[{type:"text",raw:r,text:r}]}}},t.inlineText=function(e,t,n){var r=this.rules.inline.text.exec(e);if(r){var i=t?this.options.sanitize?this.options.sanitizer?this.options.sanitizer(r[0]):C(r[0]):r[0]:C(this.options.smartypants?n(r[0]):r[0]);return{type:"text",raw:r[0],text:i}}},e}(),D=$,L=z,P=A,B={newline:/^\n+/,code:/^( {4}[^\n]+\n*)+/,fences:/^ {0,3}(`{3,}(?=[^`\n]*\n)|~{3,})([^\n]*)\n(?:|([\s\S]*?)\n)(?: {0,3}\1[~`]* *(?:\n+|$)|$)/,hr:/^ {0,3}((?:- *){3,}|(?:_ *){3,}|(?:\* *){3,})(?:\n+|$)/,heading:/^ {0,3}(#{1,6}) +([^\n]*?)(?: +#+)? *(?:\n+|$)/,blockquote:/^( {0,3}> ?(paragraph|[^\n]*)(?:\n|$))+/,list:/^( {0,3})(bull) [\s\S]+?(?:hr|def|\n{2,}(?! )(?!\1bull )\n*|\s*$)/,html:"^ {0,3}(?:<(script|pre|style)[\\s>][\\s\\S]*?(?:</\\1>[^\\n]*\\n+|$)|comment[^\\n]*(\\n+|$)|<\\?[\\s\\S]*?\\?>\\n*|<![A-Z][\\s\\S]*?>\\n*|<!\\[CDATA\\[[\\s\\S]*?\\]\\]>\\n*|</?(tag)(?: +|\\n|/?>)[\\s\\S]*?(?:\\n{2,}|$)|<(?!script|pre|style)([a-z][\\w-]*)(?:attribute)*? */?>(?=[ \\t]*(?:\\n|$))[\\s\\S]*?(?:\\n{2,}|$)|</(?!script|pre|style)[a-z][\\w-]*\\s*>(?=[ \\t]*(?:\\n|$))[\\s\\S]*?(?:\\n{2,}|$))",def:/^ {0,3}\[(label)\]: *\n? *<?([^\s>]+)>?(?:(?: +\n? *| *\n *)(title))? *(?:\n+|$)/,nptable:D,table:D,lheading:/^([^\n]+)\n {0,3}(=+|-+) *(?:\n+|$)/,_paragraph:/^([^\n]+(?:\n(?!hr|heading|lheading|blockquote|fences|list|html)[^\n]+)*)/,text:/^[^\n]+/,_label:/(?!\s*\])(?:\\[\[\]]|[^\[\]])+/,_title:/(?:"(?:\\"?|[^"\\])*"|'[^'\n]*(?:\n[^'\n]+)*\n?'|\([^()]*\))/};B.def=L(B.def).replace("label",B._label).replace("title",B._title).getRegex(),B.bullet=/(?:[*+-]|\d{1,9}[.)])/,B.item=/^( *)(bull) ?[^\n]*(?:\n(?!\1bull ?)[^\n]*)*/,B.item=L(B.item,"gm").replace(/bull/g,B.bullet).getRegex(),B.list=L(B.list).replace(/bull/g,B.bullet).replace("hr","\\n+(?=\\1?(?:(?:- *){3,}|(?:_ *){3,}|(?:\\* *){3,})(?:\\n+|$))").replace("def","\\n+(?="+B.def.source+")").getRegex(),B._tag="address|article|aside|base|basefont|blockquote|body|caption|center|col|colgroup|dd|details|dialog|dir|div|dl|dt|fieldset|figcaption|figure|footer|form|frame|frameset|h[1-6]|head|header|hr|html|iframe|legend|li|link|main|menu|menuitem|meta|nav|noframes|ol|optgroup|option|p|param|section|source|summary|table|tbody|td|tfoot|th|thead|title|tr|track|ul",B._comment=/<!--(?!-?>)[\s\S]*?-->/,B.html=L(B.html,"i").replace("comment",B._comment).replace("tag",B._tag).replace("attribute",/ +[a-zA-Z:_][\w.:-]*(?: *= *"[^"\n]*"| *= *'[^'\n]*'| *= *[^\s"'=<>`]+)?/).getRegex(),B.paragraph=L(B._paragraph).replace("hr",B.hr).replace("heading"," {0,3}#{1,6} ").replace("|lheading","").replace("blockquote"," {0,3}>").replace("fences"," {0,3}(?:`{3,}(?=[^`\\n]*\\n)|~{3,})[^\\n]*\\n").replace("list"," {0,3}(?:[*+-]|1[.)]) ").replace("html","</?(?:tag)(?: +|\\n|/?>)|<(?:script|pre|style|!--)").replace("tag",B._tag).getRegex(),B.blockquote=L(B.blockquote).replace("paragraph",B.paragraph).getRegex(),B.normal=P({},B),B.gfm=P({},B.normal,{nptable:"^ *([^|\\n ].*\\|.*)\\n *([-:]+ *\\|[-| :]*)(?:\\n((?:(?!\\n|hr|heading|blockquote|code|fences|list|html).*(?:\\n|$))*)\\n*|$)",table:"^ *\\|(.+)\\n *\\|?( *[-:]+[-| :]*)(?:\\n *((?:(?!\\n|hr|heading|blockquote|code|fences|list|html).*(?:\\n|$))*)\\n*|$)"}),B.gfm.nptable=L(B.gfm.nptable).replace("hr",B.hr).replace("heading"," {0,3}#{1,6} ").replace("blockquote"," {0,3}>").replace("code"," {4}[^\\n]").replace("fences"," {0,3}(?:`{3,}(?=[^`\\n]*\\n)|~{3,})[^\\n]*\\n").replace("list"," {0,3}(?:[*+-]|1[.)]) ").replace("html","</?(?:tag)(?: +|\\n|/?>)|<(?:script|pre|style|!--)").replace("tag",B._tag).getRegex(),B.gfm.table=L(B.gfm.table).replace("hr",B.hr).replace("heading"," {0,3}#{1,6} ").replace("blockquote"," {0,3}>").replace("code"," {4}[^\\n]").replace("fences"," {0,3}(?:`{3,}(?=[^`\\n]*\\n)|~{3,})[^\\n]*\\n").replace("list"," {0,3}(?:[*+-]|1[.)]) ").replace("html","</?(?:tag)(?: +|\\n|/?>)|<(?:script|pre|style|!--)").replace("tag",B._tag).getRegex(),B.pedantic=P({},B.normal,{html:L("^ *(?:comment *(?:\\n|\\s*$)|<(tag)[\\s\\S]+?</\\1> *(?:\\n{2,}|\\s*$)|<tag(?:\"[^\"]*\"|'[^']*'|\\s[^'\"/>\\s]*)*?/?> *(?:\\n{2,}|\\s*$))").replace("comment",B._comment).replace(/tag/g,"(?!(?:a|em|strong|small|s|cite|q|dfn|abbr|data|time|code|var|samp|kbd|sub|sup|i|b|u|mark|ruby|rt|rp|bdi|bdo|span|br|wbr|ins|del|img)\\b)\\w+(?!:|[^\\w\\s@]*@)\\b").getRegex(),def:/^ *\[([^\]]+)\]: *<?([^\s>]+)>?(?: +(["(][^\n]+[")]))? *(?:\n+|$)/,heading:/^ *(#{1,6}) *([^\n]+?) *(?:#+ *)?(?:\n+|$)/,fences:D,paragraph:L(B.normal._paragraph).replace("hr",B.hr).replace("heading"," *#{1,6} *[^\n]").replace("lheading",B.lheading).replace("blockquote"," {0,3}>").replace("|fences","").replace("|list","").replace("|html","").getRegex()});var F={escape:/^\\([!"#$%&'()*+,\-./:;<=>?@\[\]\\^_`{|}~])/,autolink:/^<(scheme:[^\s\x00-\x1f<>]*|email)>/,url:D,tag:"^comment|^</[a-zA-Z][\\w:-]*\\s*>|^<[a-zA-Z][\\w-]*(?:attribute)*?\\s*/?>|^<\\?[\\s\\S]*?\\?>|^<![a-zA-Z]+\\s[\\s\\S]*?>|^<!\\[CDATA\\[[\\s\\S]*?\\]\\]>",link:/^!?\[(label)\]\(\s*(href)(?:\s+(title))?\s*\)/,reflink:/^!?\[(label)\]\[(?!\s*\])((?:\\[\[\]]?|[^\[\]\\])+)\]/,nolink:/^!?\[(?!\s*\])((?:\[[^\[\]]*\]|\\[\[\]]|[^\[\]])*)\](?:\[\])?/,reflinkSearch:"reflink|nolink(?!\\()",strong:{start:/^(?:(\*\*(?=[*punctuation]))|\*\*)(?![\s])|__/,middle:/^\*\*(?:(?:(?!overlapSkip)(?:[^*]|\\\*)|overlapSkip)|\*(?:(?!overlapSkip)(?:[^*]|\\\*)|overlapSkip)*?\*)+?\*\*$|^__(?![\s])((?:(?:(?!overlapSkip)(?:[^_]|\\_)|overlapSkip)|_(?:(?!overlapSkip)(?:[^_]|\\_)|overlapSkip)*?_)+?)__$/,endAst:/[^punctuation\s]\*\*(?!\*)|[punctuation]\*\*(?!\*)(?:(?=[punctuation\s]|$))/,endUnd:/[^\s]__(?!_)(?:(?=[punctuation\s])|$)/},em:{start:/^(?:(\*(?=[punctuation]))|\*)(?![*\s])|_/,middle:/^\*(?:(?:(?!overlapSkip)(?:[^*]|\\\*)|overlapSkip)|\*(?:(?!overlapSkip)(?:[^*]|\\\*)|overlapSkip)*?\*)+?\*$|^_(?![_\s])(?:(?:(?!overlapSkip)(?:[^_]|\\_)|overlapSkip)|_(?:(?!overlapSkip)(?:[^_]|\\_)|overlapSkip)*?_)+?_$/,endAst:/[^punctuation\s]\*(?!\*)|[punctuation]\*(?!\*)(?:(?=[punctuation\s]|$))/,endUnd:/[^\s]_(?!_)(?:(?=[punctuation\s])|$)/},code:/^(`+)([^`]|[^`][\s\S]*?[^`])\1(?!`)/,br:/^( {2,}|\\)\n(?!\s*$)/,del:D,text:/^(`+|[^`])(?:[\s\S]*?(?:(?=[\\<!\[`*]|\b_|$)|[^ ](?= {2,}\n))|(?= {2,}\n))/,punctuation:/^([\s*punctuation])/,_punctuation:"!\"#$%&'()+\\-.,/:;<=>?@\\[\\]`^{|}~"};F.punctuation=L(F.punctuation).replace(/punctuation/g,F._punctuation).getRegex(),F._blockSkip="\\[[^\\]]*?\\]\\([^\\)]*?\\)|`[^`]*?`|<[^>]*?>",F._overlapSkip="__[^_]*?__|\\*\\*\\[^\\*\\]*?\\*\\*",F.em.start=L(F.em.start).replace(/punctuation/g,F._punctuation).getRegex(),F.em.middle=L(F.em.middle).replace(/punctuation/g,F._punctuation).replace(/overlapSkip/g,F._overlapSkip).getRegex(),F.em.endAst=L(F.em.endAst,"g").replace(/punctuation/g,F._punctuation).getRegex(),F.em.endUnd=L(F.em.endUnd,"g").replace(/punctuation/g,F._punctuation).getRegex(),F.strong.start=L(F.strong.start).replace(/punctuation/g,F._punctuation).getRegex(),F.strong.middle=L(F.strong.middle).replace(/punctuation/g,F._punctuation).replace(/blockSkip/g,F._blockSkip).getRegex(),F.strong.endAst=L(F.strong.endAst,"g").replace(/punctuation/g,F._punctuation).getRegex(),F.strong.endUnd=L(F.strong.endUnd,"g").replace(/punctuation/g,F._punctuation).getRegex(),F.blockSkip=L(F._blockSkip,"g").getRegex(),F.overlapSkip=L(F._overlapSkip,"g").getRegex(),F._escapes=/\\([!"#$%&'()*+,\-./:;<=>?@\[\]\\^_`{|}~])/g,F._scheme=/[a-zA-Z][a-zA-Z0-9+.-]{1,31}/,F._email=/[a-zA-Z0-9.!#$%&'*+/=?^_`{|}~-]+(@)[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\.[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)+(?![-_])/,F.autolink=L(F.autolink).replace("scheme",F._scheme).replace("email",F._email).getRegex(),F._attribute=/\s+[a-zA-Z:_][\w.:-]*(?:\s*=\s*"[^"]*"|\s*=\s*'[^']*'|\s*=\s*[^\s"'=<>`]+)?/,F.tag=L(F.tag).replace("comment",B._comment).replace("attribute",F._attribute).getRegex(),F._label=/(?:\[(?:\\.|[^\[\]\\])*\]|\\.|`[^`]*`|[^\[\]\\`])*?/,F._href=/<(?:\\[<>]?|[^\s<>\\])*>|[^\s\x00-\x1f]*/,F._title=/"(?:\\"?|[^"\\])*"|'(?:\\'?|[^'\\])*'|\((?:\\\)?|[^)\\])*\)/,F.link=L(F.link).replace("label",F._label).replace("href",F._href).replace("title",F._title).getRegex(),F.reflink=L(F.reflink).replace("label",F._label).getRegex(),F.reflinkSearch=L(F.reflinkSearch,"g").replace("reflink",F.reflink).replace("nolink",F.nolink).getRegex(),F.normal=P({},F),F.pedantic=P({},F.normal,{strong:{start:/^__|\*\*/,middle:/^__(?=\S)([\s\S]*?\S)__(?!_)|^\*\*(?=\S)([\s\S]*?\S)\*\*(?!\*)/,endAst:/\*\*(?!\*)/g,endUnd:/__(?!_)/g},em:{start:/^_|\*/,middle:/^()\*(?=\S)([\s\S]*?\S)\*(?!\*)|^_(?=\S)([\s\S]*?\S)_(?!_)/,endAst:/\*(?!\*)/g,endUnd:/_(?!_)/g},link:L(/^!?\[(label)\]\((.*?)\)/).replace("label",F._label).getRegex(),reflink:L(/^!?\[(label)\]\s*\[([^\]]*)\]/).replace("label",F._label).getRegex()}),F.gfm=P({},F.normal,{escape:L(F.escape).replace("])","~|])").getRegex(),_extended_email:/[A-Za-z0-9._+-]+(@)[a-zA-Z0-9-_]+(?:\.[a-zA-Z0-9-_]*[a-zA-Z0-9])+(?![-_])/,url:/^((?:ftp|https?):\/\/|www\.)(?:[a-zA-Z0-9\-]+\.?)+[^\s<]*|^email/,_backpedal:/(?:[^?!.,:;*_~()&]+|\([^)]*\)|&(?![a-zA-Z0-9]+;$)|[?!.,:;*_~)]+(?!$))+/,del:/^~+(?=\S)([\s\S]*?\S)~+/,text:/^(`+|[^`])(?:[\s\S]*?(?:(?=[\\<!\[`*~]|\b_|https?:\/\/|ftp:\/\/|www\.|$)|[^ ](?= {2,}\n)|[^a-zA-Z0-9.!#$%&'*+\/=?_`{\|}~-](?=[a-zA-Z0-9.!#$%&'*+\/=?_`{\|}~-]+@))|(?= {2,}\n|[a-zA-Z0-9.!#$%&'*+\/=?_`{\|}~-]+@))/}),F.gfm.url=L(F.gfm.url,"i").replace("email",F.gfm._extended_email).getRegex(),F.breaks=P({},F.gfm,{br:L(F.br).replace("{2,}","*").getRegex(),text:L(F.gfm.text).replace("\\b_","\\b_| {2,}\\n").replace(/\{2,\}/g,"*").getRegex()});var M={block:B,inline:F},N=t.defaults,W=M.block,X=M.inline;function G(e){return e.replace(/---/g,"—").replace(/--/g,"–").replace(/(^|[-\u2014/(\[{"\s])'/g,"$1‘").replace(/'/g,"’").replace(/(^|[-\u2014/(\[{\u2018\s])"/g,"$1“").replace(/"/g,"”").replace(/\.{3}/g,"…")}function V(e){for(var t,n="",r=e.length,i=0;i<r;i++)t=e.charCodeAt(i),.5<Math.random()&&(t="x"+t.toString(16)),n+="&#"+t+";";return n}var H=function(){function n(e){this.tokens=[],this.tokens.links=Object.create(null),this.options=e||N,this.options.tokenizer=this.options.tokenizer||new E,this.tokenizer=this.options.tokenizer,this.tokenizer.options=this.options;var t={block:W.normal,inline:X.normal};this.options.pedantic?(t.block=W.pedantic,t.inline=X.pedantic):this.options.gfm&&(t.block=W.gfm,this.options.breaks?t.inline=X.breaks:t.inline=X.gfm),this.tokenizer.rules=t}n.lex=function(e,t){return new n(t).lex(e)};var e,t,r,i=n.prototype;return i.lex=function(e){return e=e.replace(/\r\n|\r/g,"\n").replace(/\t/g,"    "),this.blockTokens(e,this.tokens,!0),this.inline(this.tokens),this.tokens},i.blockTokens=function(e,t,n){var r,i,s,l;for(void 0===t&&(t=[]),void 0===n&&(n=!0),e=e.replace(/^ +$/gm,"");e;)if(r=this.tokenizer.space(e))e=e.substring(r.raw.length),r.type&&t.push(r);else if(r=this.tokenizer.code(e,t))e=e.substring(r.raw.length),r.type?t.push(r):((l=t[t.length-1]).raw+="\n"+r.raw,l.text+="\n"+r.text);else if(r=this.tokenizer.fences(e))e=e.substring(r.raw.length),t.push(r);else if(r=this.tokenizer.heading(e))e=e.substring(r.raw.length),t.push(r);else if(r=this.tokenizer.nptable(e))e=e.substring(r.raw.length),t.push(r);else if(r=this.tokenizer.hr(e))e=e.substring(r.raw.length),t.push(r);else if(r=this.tokenizer.blockquote(e))e=e.substring(r.raw.length),r.tokens=this.blockTokens(r.text,[],n),t.push(r);else if(r=this.tokenizer.list(e)){for(e=e.substring(r.raw.length),s=r.items.length,i=0;i<s;i++)r.items[i].tokens=this.blockTokens(r.items[i].text,[],!1);t.push(r)}else if(r=this.tokenizer.html(e))e=e.substring(r.raw.length),t.push(r);else if(n&&(r=this.tokenizer.def(e)))e=e.substring(r.raw.length),this.tokens.links[r.tag]||(this.tokens.links[r.tag]={href:r.href,title:r.title});else if(r=this.tokenizer.table(e))e=e.substring(r.raw.length),t.push(r);else if(r=this.tokenizer.lheading(e))e=e.substring(r.raw.length),t.push(r);else if(n&&(r=this.tokenizer.paragraph(e)))e=e.substring(r.raw.length),t.push(r);else if(r=this.tokenizer.text(e,t))e=e.substring(r.raw.length),r.type?t.push(r):((l=t[t.length-1]).raw+="\n"+r.raw,l.text+="\n"+r.text);else if(e){var a="Infinite loop on byte: "+e.charCodeAt(0);if(this.options.silent){console.error(a);break}throw new Error(a)}return t},i.inline=function(e){for(var t,n,r,i,s,l=e.length,a=0;a<l;a++)switch((s=e[a]).type){case"paragraph":case"text":case"heading":s.tokens=[],this.inlineTokens(s.text,s.tokens);break;case"table":for(s.tokens={header:[],cells:[]},r=s.header.length,t=0;t<r;t++)s.tokens.header[t]=[],this.inlineTokens(s.header[t],s.tokens.header[t]);for(r=s.cells.length,t=0;t<r;t++)for(i=s.cells[t],s.tokens.cells[t]=[],n=0;n<i.length;n++)s.tokens.cells[t][n]=[],this.inlineTokens(i[n],s.tokens.cells[t][n]);break;case"blockquote":this.inline(s.tokens);break;case"list":for(r=s.items.length,t=0;t<r;t++)this.inline(s.items[t].tokens)}return e},i.inlineTokens=function(e,t,n,r,i){var s;void 0===t&&(t=[]),void 0===n&&(n=!1),void 0===r&&(r=!1),void 0===i&&(i="");var l,a=e;if(this.tokens.links){var o=Object.keys(this.tokens.links);if(0<o.length)for(;null!=(l=this.tokenizer.rules.inline.reflinkSearch.exec(a));)o.includes(l[0].slice(l[0].lastIndexOf("[")+1,-1))&&(a=a.slice(0,l.index)+"["+"a".repeat(l[0].length-2)+"]"+a.slice(this.tokenizer.rules.inline.reflinkSearch.lastIndex))}for(;null!=(l=this.tokenizer.rules.inline.blockSkip.exec(a));)a=a.slice(0,l.index)+"["+"a".repeat(l[0].length-2)+"]"+a.slice(this.tokenizer.rules.inline.blockSkip.lastIndex);for(;e;)if(s=this.tokenizer.escape(e))e=e.substring(s.raw.length),t.push(s);else if(s=this.tokenizer.tag(e,n,r))e=e.substring(s.raw.length),n=s.inLink,r=s.inRawBlock,t.push(s);else if(s=this.tokenizer.link(e))e=e.substring(s.raw.length),"link"===s.type&&(s.tokens=this.inlineTokens(s.text,[],!0,r)),t.push(s);else if(s=this.tokenizer.reflink(e,this.tokens.links))e=e.substring(s.raw.length),"link"===s.type&&(s.tokens=this.inlineTokens(s.text,[],!0,r)),t.push(s);else if(s=this.tokenizer.strong(e,a,i))e=e.substring(s.raw.length),s.tokens=this.inlineTokens(s.text,[],n,r),t.push(s);else if(s=this.tokenizer.em(e,a,i))e=e.substring(s.raw.length),s.tokens=this.inlineTokens(s.text,[],n,r),t.push(s);else if(s=this.tokenizer.codespan(e))e=e.substring(s.raw.length),t.push(s);else if(s=this.tokenizer.br(e))e=e.substring(s.raw.length),t.push(s);else if(s=this.tokenizer.del(e))e=e.substring(s.raw.length),s.tokens=this.inlineTokens(s.text,[],n,r),t.push(s);else if(s=this.tokenizer.autolink(e,V))e=e.substring(s.raw.length),t.push(s);else if(n||!(s=this.tokenizer.url(e,V))){if(s=this.tokenizer.inlineText(e,r,G))e=e.substring(s.raw.length),i=s.raw.slice(-1),t.push(s);else if(e){var c="Infinite loop on byte: "+e.charCodeAt(0);if(this.options.silent){console.error(c);break}throw new Error(c)}}else e=e.substring(s.raw.length),t.push(s);return t},e=n,r=[{key:"rules",get:function(){return{block:W,inline:X}}}],(t=null)&&s(e.prototype,t),r&&s(e,r),n}(),J=t.defaults,K=S,Q=_,Y=function(){function e(e){this.options=e||J}var t=e.prototype;return t.code=function(e,t,n){var r,i=(t||"").match(/\S*/)[0];return!this.options.highlight||null!=(r=this.options.highlight(e,i))&&r!==e&&(n=!0,e=r),i?'<pre><code class="'+this.options.langPrefix+Q(i,!0)+'">'+(n?e:Q(e,!0))+"</code></pre>\n":"<pre><code>"+(n?e:Q(e,!0))+"</code></pre>\n"},t.blockquote=function(e){return"<blockquote>\n"+e+"</blockquote>\n"},t.html=function(e){return e},t.heading=function(e,t,n,r){return this.options.headerIds?"<h"+t+' id="'+this.options.headerPrefix+r.slug(n)+'">'+e+"</h"+t+">\n":"<h"+t+">"+e+"</h"+t+">\n"},t.hr=function(){return this.options.xhtml?"<hr/>\n":"<hr>\n"},t.list=function(e,t,n){var r=t?"ol":"ul";return"<"+r+(t&&1!==n?' start="'+n+'"':"")+">\n"+e+"</"+r+">\n"},t.listitem=function(e){return"<li>"+e+"</li>\n"},t.checkbox=function(e){return"<input "+(e?'checked="" ':"")+'disabled="" type="checkbox"'+(this.options.xhtml?" /":"")+"> "},t.paragraph=function(e){return"<p>"+e+"</p>\n"},t.table=function(e,t){return"<table>\n<thead>\n"+e+"</thead>\n"+(t=t&&"<tbody>"+t+"</tbody>")+"</table>\n"},t.tablerow=function(e){return"<tr>\n"+e+"</tr>\n"},t.tablecell=function(e,t){var n=t.header?"th":"td";return(t.align?"<"+n+' align="'+t.align+'">':"<"+n+">")+e+"</"+n+">\n"},t.strong=function(e){return"<strong>"+e+"</strong>"},t.em=function(e){return"<em>"+e+"</em>"},t.codespan=function(e){return"<code>"+e+"</code>"},t.br=function(){return this.options.xhtml?"<br/>":"<br>"},t.del=function(e){return"<del>"+e+"</del>"},t.link=function(e,t,n){if(null===(e=K(this.options.sanitize,this.options.baseUrl,e)))return n;var r='<a href="'+Q(e)+'"';return t&&(r+=' title="'+t+'"'),r+=">"+n+"</a>"},t.image=function(e,t,n){if(null===(e=K(this.options.sanitize,this.options.baseUrl,e)))return n;var r='<img src="'+e+'" alt="'+n+'"';return t&&(r+=' title="'+t+'"'),r+=this.options.xhtml?"/>":">"},t.text=function(e){return e},e}(),ee=function(){function e(){}var t=e.prototype;return t.strong=function(e){return e},t.em=function(e){return e},t.codespan=function(e){return e},t.del=function(e){return e},t.html=function(e){return e},t.text=function(e){return e},t.link=function(e,t,n){return""+n},t.image=function(e,t,n){return""+n},t.br=function(){return""},e}(),te=function(){function e(){this.seen={}}return e.prototype.slug=function(e){var t=e.toLowerCase().trim().replace(/<[!\/a-z].*?>/gi,"").replace(/[\u2000-\u206F\u2E00-\u2E7F\\'!"#$%&()*+,./:;<=>?@[\]^`{|}~]/g,"").replace(/\s/g,"-");if(this.seen.hasOwnProperty(t))for(var n=t;this.seen[n]++,t=n+"-"+this.seen[n],this.seen.hasOwnProperty(t););return this.seen[t]=0,t},e}(),ne=t.defaults,re=y,ie=function(){function n(e){this.options=e||ne,this.options.renderer=this.options.renderer||new Y,this.renderer=this.options.renderer,this.renderer.options=this.options,this.textRenderer=new ee,this.slugger=new te}n.parse=function(e,t){return new n(t).parse(e)};var e=n.prototype;return e.parse=function(e,t){void 0===t&&(t=!0);for(var n,r,i,s,l,a,o,c,u,p,h,g,f,d,k,b,m,x="",v=e.length,w=0;w<v;w++)switch((u=e[w]).type){case"space":continue;case"hr":x+=this.renderer.hr();continue;case"heading":x+=this.renderer.heading(this.parseInline(u.tokens),u.depth,re(this.parseInline(u.tokens,this.textRenderer)),this.slugger);continue;case"code":x+=this.renderer.code(u.text,u.lang,u.escaped);continue;case"table":for(a=o="",i=u.header.length,n=0;n<i;n++)a+=this.renderer.tablecell(this.parseInline(u.tokens.header[n]),{header:!0,align:u.align[n]});for(o+=this.renderer.tablerow(a),c="",i=u.cells.length,n=0;n<i;n++){for(a="",s=(l=u.tokens.cells[n]).length,r=0;r<s;r++)a+=this.renderer.tablecell(this.parseInline(l[r]),{header:!1,align:u.align[r]});c+=this.renderer.tablerow(a)}x+=this.renderer.table(o,c);continue;case"blockquote":c=this.parse(u.tokens),x+=this.renderer.blockquote(c);continue;case"list":for(p=u.ordered,h=u.start,g=u.loose,i=u.items.length,c="",n=0;n<i;n++)k=(d=u.items[n]).checked,b=d.task,f="",d.task&&(m=this.renderer.checkbox(k),g?0<d.tokens.length&&"text"===d.tokens[0].type?(d.tokens[0].text=m+" "+d.tokens[0].text,d.tokens[0].tokens&&0<d.tokens[0].tokens.length&&"text"===d.tokens[0].tokens[0].type&&(d.tokens[0].tokens[0].text=m+" "+d.tokens[0].tokens[0].text)):d.tokens.unshift({type:"text",text:m}):f+=m),f+=this.parse(d.tokens,g),c+=this.renderer.listitem(f,b,k);x+=this.renderer.list(c,p,h);continue;case"html":x+=this.renderer.html(u.text);continue;case"paragraph":x+=this.renderer.paragraph(this.parseInline(u.tokens));continue;case"text":for(c=u.tokens?this.parseInline(u.tokens):u.text;w+1<v&&"text"===e[w+1].type;)c+="\n"+((u=e[++w]).tokens?this.parseInline(u.tokens):u.text);x+=t?this.renderer.paragraph(c):c;continue;default:var _='Token with "'+u.type+'" type was not found.';if(this.options.silent)return void console.error(_);throw new Error(_)}return x},e.parseInline=function(e,t){t=t||this.renderer;for(var n,r="",i=e.length,s=0;s<i;s++)switch((n=e[s]).type){case"escape":r+=t.text(n.text);break;case"html":r+=t.html(n.text);break;case"link":r+=t.link(n.href,n.title,this.parseInline(n.tokens,t));break;case"image":r+=t.image(n.href,n.title,n.text);break;case"strong":r+=t.strong(this.parseInline(n.tokens,t));break;case"em":r+=t.em(this.parseInline(n.tokens,t));break;case"codespan":r+=t.codespan(n.text);break;case"br":r+=t.br();break;case"del":r+=t.del(this.parseInline(n.tokens,t));break;case"text":r+=t.text(n.text);break;default:var l='Token with "'+n.type+'" type was not found.';if(this.options.silent)return void console.error(l);throw new Error(l)}return r},n}(),se=A,le=I,ae=_,oe=t.getDefaults,ce=t.changeDefaults,ue=t.defaults;function pe(e,n,r){if(null==e)throw new Error("marked(): input parameter is undefined or null");if("string"!=typeof e)throw new Error("marked(): input parameter is of type "+Object.prototype.toString.call(e)+", string expected");if("function"==typeof n&&(r=n,n=null),n=se({},pe.defaults,n||{}),le(n),r){var i,s=n.highlight;try{i=H.lex(e,n)}catch(e){return r(e)}var l=function(t){var e;if(!t)try{e=ie.parse(i,n)}catch(e){t=e}return n.highlight=s,t?r(t):r(null,e)};if(!s||s.length<3)return l();if(delete n.highlight,!i.length)return l();var a=0;return pe.walkTokens(i,function(n){"code"===n.type&&(a++,setTimeout(function(){s(n.text,n.lang,function(e,t){if(e)return l(e);null!=t&&t!==n.text&&(n.text=t,n.escaped=!0),0===--a&&l()})},0))}),void(0===a&&l())}try{var t=H.lex(e,n);return n.walkTokens&&pe.walkTokens(t,n.walkTokens),ie.parse(t,n)}catch(e){if(e.message+="\nPlease report this to https://github.com/markedjs/marked.",n.silent)return"<p>An error occurred:</p><pre>"+ae(e.message+"",!0)+"</pre>";throw e}}return pe.options=pe.setOptions=function(e){return se(pe.defaults,e),ce(pe.defaults),pe},pe.getDefaults=oe,pe.defaults=ue,pe.use=function(a){var t,n=se({},a);a.renderer&&function(){function e(i){var s=l[i];l[i]=function(){for(var e=arguments.length,t=new Array(e),n=0;n<e;n++)t[n]=arguments[n];var r=a.renderer[i].apply(l,t);return!1===r&&(r=s.apply(l,t)),r}}var l=pe.defaults.renderer||new Y;for(var t in a.renderer)e(t);n.renderer=l}(),a.tokenizer&&function(){function e(i){var s=l[i];l[i]=function(){for(var e=arguments.length,t=new Array(e),n=0;n<e;n++)t[n]=arguments[n];var r=a.tokenizer[i].apply(l,t);return!1===r&&(r=s.apply(l,t)),r}}var l=pe.defaults.tokenizer||new E;for(var t in a.tokenizer)e(t);n.tokenizer=l}(),a.walkTokens&&(t=pe.defaults.walkTokens,n.walkTokens=function(e){a.walkTokens(e),t&&t(e)}),pe.setOptions(n)},pe.walkTokens=function(e,t){for(var n,r=g(e);!(n=r()).done;){var i=n.value;switch(t(i),i.type){case"table":for(var s,l=g(i.tokens.header);!(s=l()).done;){var a=s.value;pe.walkTokens(a,t)}for(var o,c=g(i.tokens.cells);!(o=c()).done;)for(var u,p=g(o.value);!(u=p()).done;){var h=u.value;pe.walkTokens(h,t)}break;case"list":pe.walkTokens(i.items,t);break;default:i.tokens&&pe.walkTokens(i.tokens,t)}}},pe.Parser=ie,pe.parser=ie.parse,pe.Renderer=Y,pe.TextRenderer=ee,pe.Lexer=H,pe.lexer=H.lex,pe.Tokenizer=E,pe.Slugger=te,pe.parse=pe});/*! jQuery v3.6.1 | (c) OpenJS Foundation and other contributors | jquery.org/license */
</script>
</head>
<body onload="$tm.ev_boot()">
<nav><h1>CardMemo1</h1> <label><input id="kwd" type="search" oninput="$tm.ev_findkwd()" placeholder="search"></label>
</nav>

<div class="card kwd_pad" id="kwd_show"></div>

<section id="eTopTag" class="card sec_pad">
</section>

<footer id="eFter" class="footer"></footer>
</body></html>
