<!doctype html><html lang=zh-ch>
<head>
<meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1">
<title>PySpark分析 | 蛙二的思考</title>
<meta property="og:title" content="PySpark分析 - 蛙二的思考">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2021-07-21T12:00:00+08:00">
<meta property="article:modified_time" content="2021-07-21T12:00:00+08:00">
<meta name=Keywords content>
<meta name=description content="PySpark分析">
<meta name=author content>
<meta property="og:url" content="/post/210721/">
<link rel="shortcut icon" href=/favicon.ico type=image/x-icon>
<link rel=stylesheet href=/css/normalize.css>
<link rel=stylesheet href=/css/style.css>
<script type=text/javascript src=//cdn.bootcdn.net/ajax/libs/jquery/3.4.1/jquery.min.js></script>
</head>
<body>
<header id=header class=clearfix>
<div class=container>
<div class=col-group>
<div class=site-name>
<a id=logo href>
蛙二的思考
</a>
</div>
<div>
<nav id=nav-menu class=clearfix>
<a class=current href>首页</a>
</nav>
</div>
</div>
</div>
</header>
<div id=body>
<div class=container>
<div class=col-group>
<div class=col-8 id=main>
<div class=res-cons>
<article class=post>
<header>
<h1 class=post-title>PySpark分析</h1>
</header>
<date class="post-meta meta-date">
2021年7月21日
</date>
<div class=post-content>
<h2 id=执行过程>执行过程</h2>
<p>常用的有local和yarn两种模式，写代码或调错阶段，无特殊情况用local，速度快很多。</p>
<p>pyspark和scala的spark不同在于，某些情况下数据会从jvm回传给py，这个回传的过程是怎么样的？首先，Spark会先把所有py文件放到此次任务driver端所在的节点，比如我的环境放在 /yarn/nodemanager/usercache/xxx/appcache/application_xx/container_xx_01/main.py 目录，启动py的命令是<code>path/bin/python main.py --arg=xx</code>。同时spark会在driver放一个pyspark.zip，解决Py与spark集群通信的问题。driver端任务运行一段时间后，如果发现计算需要把数据传递给executor上的python，就会启动<code>path/bin/python -m pyspark.daemon</code>，没有额外的参数。pyspark.daemon会fork一个进程，然后在子进程里执行pyspark.worker.main函数，数据读写的源头也改为来自socket。实际代码中先会做dup，把socket复制出来提高效率。driver和executor之间通过环境变量和socket传递数据和代码（似乎是pickle序列化），此时的executor会在container_xx_02或03目录内执行。</p>
<p>进入py代码后，先构建SparkContext对象，构建过程会查找并执行<code>spark-submit pyspark-shell</code>命令，构建一个java的gateway，再通过Py4J包，以类似RPC的方式把py代码通过Gateway发送到jvm，进行spark操作。如果计算过程中需要python的udf，则数据必须发送到work节点，过程是由spark启动python的worker.py进程，并以环境变量的方式把端口告知worker，worker会用socket去连接这个port，并做一系列判断，比如driver和worker的python版本必须一致，计算结束后再用socket发送回spark。理论上只要数据不回传给py，开销只是方法的传递，性能和scala的实现是一样的，如果有数据回传，速度会降低一倍以上。</p>
<h2 id=pyspark内容>PySpark内容</h2>
<h3 id=包层次>包层次</h3>
<p>顶层目录pyspark包含SparkConf、SparkContext、RDD等spark的基础概念，包含sql、streaming、ml、mllib等多个子模块。</p>
<h3 id=流程和关键概念>流程和关键概念</h3>
<p>如果是写类SQL功能，流程是套路化的</p>
<ol>
<li>获取SparkConf，设置master和appName。我只用过yarn模式</li>
<li>把Conf作为参数传给SparkContext。注意，必须构造context，否则无法和spark通信。Conf可以没有，但考虑要设置的参数很多，用Conf方便，另外还有序列化类参数可传入，默认用pickle序列化py和jvm之间的数据</li>
<li>通过Context来获取SparkSession。这个Session是属于pyspark.sql的类，整合了SQLContext和HiveContext等多个SQL会用到的功能</li>
</ol>
<p>拿到SparkSession后，读取文件得到的数据呈现形式就是DataFrame类，这个类具备很多SQL语义的API（因为Session就是sql包下的一个类）。DataFrame可以链式操作，即操作后返回的值大部分情况下仍是DataFrame，如果做了groupBy操作，得到的是GroupedData类型。</p>
<h3 id=pyspark命令>pyspark命令</h3>
<p>执行这个命令，会自动加载shell.py脚本并初始化sc(pyspark.context), spark(pyspark.sql.session，对应原生SparkSession类), sql(spark.sql的别名), sqlCtx/sqlContext(pyspark.sql.context.SQLContext)共4个全局变量。</p>
</div>
<div class="post-meta meta-tags">
没有标签
</div>
</article>
</div>
<footer id=footer>
<div>
&copy; 2021 <a href>蛙二的思考 By </a>
</div>
<br>
<div>
<div class=github-badge>
<a href=https://gohugo.io/ target=_black rel=nofollow><span class=badge-subject>Powered by</span><span class="badge-value bg-blue">Hugo</span></a>
</div>
<div class=github-badge>
<a href=https://www.flysnow.org/ target=_black><span class=badge-subject>Design by</span><span class="badge-value bg-brightgreen">蛙二</span></a>
</div>
<div class=github-badge>
<a href=https://github.com/flysnow-org/maupassant-hugo target=_black><span class=badge-subject>Theme</span><span class="badge-value bg-yellowgreen">Maupassant</span></a>
</div>
</div>
</footer>
<script type=text/javascript>window.MathJax={tex2jax:{inlineMath:[['$','$']],processEscapes:!0}}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script>
<a id=rocket href=#top></a>
<script type=text/javascript src="/js/totop.js?v=0.0.0" async></script>
</div>
<div id=secondary>
<section class=widget>
<form id=search action=//www.google.com/search method=get accept-charset=utf-8 target=_blank _lpchecked=1>
<input type=text name=q maxlength=20 placeholder=Search>
<input type=hidden name=sitesearch>
<button type=submit class="submit icon-search"></button>
</form>
</section>
<section class=widget>
<h3 class=widget-title>最近文章</h3>
<ul class=widget-list>
<li>
<a href=/post/210901/ title=对昼伏夜出和朝九晚五两个技战法的分析>对昼伏夜出和朝九晚五两个技战法的分析</a>
</li>
<li>
<a href=/post/210729/ title=git的远程访问辨析>git的远程访问辨析</a>
</li>
<li>
<a href=/post/210721/ title=PySpark分析>PySpark分析</a>
</li>
<li>
<a href=/post/210614/ title=erlang和其上的扩展语言>erlang和其上的扩展语言</a>
</li>
<li>
<a href=/post/210613/ title=lisp编程与结构化思想>lisp编程与结构化思想</a>
</li>
<li>
<a href=/post/210611/ title=理解shell的换行和打印>理解shell的换行和打印</a>
</li>
<li>
<a href=/post/210421/ title=vim的自定义扩展>vim的自定义扩展</a>
</li>
<li>
<a href=/post/210404/ title=数据库的执行优化>数据库的执行优化</a>
</li>
<li>
<a href=/post/210322/ title=对公有云上数仓的调研>对公有云上数仓的调研</a>
</li>
<li>
<a href=/post/210216/ title=hadoop体系理解>hadoop体系理解</a>
</li>
</ul>
</section>
<section class=widget>
<h3 class=widget-title><a href=/categories/>分类</a></h3>
<ul class=widget-list>
</ul>
</section>
<section class=widget>
<h3 class=widget-title><a href=/tags/>标签</a></h3>
<div class=tagcloud>
</div>
</section>
<section class=widget>
<h3 class=widget-title>其它</h3>
<ul class=widget-list>
<li><a href=index.xml>文章 RSS</a></li>
</ul>
</section>
</div>
</div>
</div>
</div>
</body>
</html>